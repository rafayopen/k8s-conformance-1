Dec  3 19:39:02.205: INFO: Overriding default scale value of zero to 1
Dec  3 19:39:02.205: INFO: Overriding default milliseconds value of zero to 5000
I1203 19:39:02.973345      19 test_context.go:385] Using a temporary kubeconfig file from in-cluster config : /tmp/kubeconfig-166913721
I1203 19:39:02.973514      19 e2e.go:304] Starting e2e run "161a3e08-f733-11e8-8d0a-02420af40402" on Ginkgo node 1
Running Suite: Kubernetes e2e suite
===================================
Random Seed: 1543865941 - Will randomize all specs
Will run 188 of 1814 specs

Dec  3 19:39:03.306: INFO: >>> kubeConfig: /tmp/kubeconfig-166913721
Dec  3 19:39:03.329: INFO: Waiting up to 30m0s for all (but 0) nodes to be schedulable
Dec  3 19:39:03.343: INFO: Waiting up to 10m0s for all pods (need at least 0) in namespace 'kube-system' to be running and ready
Dec  3 19:39:03.379: INFO: 8 / 8 pods in namespace 'kube-system' are running and ready (0 seconds elapsed)
Dec  3 19:39:03.379: INFO: expected 1 pod replicas in namespace 'kube-system', 1 are Running and Ready.
Dec  3 19:39:03.379: INFO: Waiting up to 5m0s for all daemonsets in namespace 'kube-system' to start
Dec  3 19:39:03.391: INFO: 3 / 3 pods ready in namespace 'kube-system' in daemonset 'csi-do-node' (0 seconds elapsed)
Dec  3 19:39:03.391: INFO: e2e test version: v1.12.1
Dec  3 19:39:03.392: INFO: kube-apiserver version: v1.12.3
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 19:39:03.393: INFO: >>> kubeConfig: /tmp/kubeconfig-166913721
STEP: Building a namespace api object, basename projected
Dec  3 19:39:03.496: INFO: No PodSecurityPolicies found; assuming PodSecurityPolicy is disabled.
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating the pod
Dec  3 19:39:12.060: INFO: Successfully updated pod "annotationupdate16ef5d95-f733-11e8-8d0a-02420af40402"
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 19:39:14.079: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-j9xf8" for this suite.
Dec  3 19:39:36.093: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 19:39:36.182: INFO: namespace: e2e-tests-projected-j9xf8, resource: bindings, ignored listing per whitelist
Dec  3 19:39:36.184: INFO: namespace e2e-tests-projected-j9xf8 deletion completed in 22.101953079s

• [SLOW TEST:32.791 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 19:39:36.186: INFO: >>> kubeConfig: /tmp/kubeconfig-166913721
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-http in namespace e2e-tests-container-probe-v599n
Dec  3 19:39:40.300: INFO: Started pod liveness-http in namespace e2e-tests-container-probe-v599n
STEP: checking the pod's current state and verifying that restartCount is present
Dec  3 19:39:40.302: INFO: Initial restart count of pod liveness-http is 0
Dec  3 19:40:02.348: INFO: Restart count of pod e2e-tests-container-probe-v599n/liveness-http is now 1 (22.045903343s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 19:40:02.357: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-v599n" for this suite.
Dec  3 19:40:08.377: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 19:40:08.459: INFO: namespace: e2e-tests-container-probe-v599n, resource: bindings, ignored listing per whitelist
Dec  3 19:40:08.471: INFO: namespace e2e-tests-container-probe-v599n deletion completed in 6.106825075s

• [SLOW TEST:32.285 seconds]
[k8s.io] Probing container
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 19:40:08.471: INFO: >>> kubeConfig: /tmp/kubeconfig-166913721
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Dec  3 19:40:08.547: INFO: Waiting up to 5m0s for pod "downwardapi-volume-3db3feb9-f733-11e8-8d0a-02420af40402" in namespace "e2e-tests-downward-api-nnfpm" to be "success or failure"
Dec  3 19:40:08.558: INFO: Pod "downwardapi-volume-3db3feb9-f733-11e8-8d0a-02420af40402": Phase="Pending", Reason="", readiness=false. Elapsed: 10.959375ms
Dec  3 19:40:10.563: INFO: Pod "downwardapi-volume-3db3feb9-f733-11e8-8d0a-02420af40402": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.015855309s
STEP: Saw pod success
Dec  3 19:40:10.563: INFO: Pod "downwardapi-volume-3db3feb9-f733-11e8-8d0a-02420af40402" satisfied condition "success or failure"
Dec  3 19:40:10.566: INFO: Trying to get logs from node hungry-keller-3o9a pod downwardapi-volume-3db3feb9-f733-11e8-8d0a-02420af40402 container client-container: <nil>
STEP: delete the pod
Dec  3 19:40:10.588: INFO: Waiting for pod downwardapi-volume-3db3feb9-f733-11e8-8d0a-02420af40402 to disappear
Dec  3 19:40:10.592: INFO: Pod downwardapi-volume-3db3feb9-f733-11e8-8d0a-02420af40402 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 19:40:10.592: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-nnfpm" for this suite.
Dec  3 19:40:16.608: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 19:40:16.671: INFO: namespace: e2e-tests-downward-api-nnfpm, resource: bindings, ignored listing per whitelist
Dec  3 19:40:16.689: INFO: namespace e2e-tests-downward-api-nnfpm deletion completed in 6.093673099s

• [SLOW TEST:8.218 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[k8s.io] Pods 
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 19:40:16.689: INFO: >>> kubeConfig: /tmp/kubeconfig-166913721
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Dec  3 19:40:21.293: INFO: Successfully updated pod "pod-update-4299d1af-f733-11e8-8d0a-02420af40402"
STEP: verifying the updated pod is in kubernetes
Dec  3 19:40:21.298: INFO: Pod update OK
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 19:40:21.298: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-2sjvm" for this suite.
Dec  3 19:40:43.327: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 19:40:43.389: INFO: namespace: e2e-tests-pods-2sjvm, resource: bindings, ignored listing per whitelist
Dec  3 19:40:43.413: INFO: namespace e2e-tests-pods-2sjvm deletion completed in 22.112033137s

• [SLOW TEST:26.724 seconds]
[k8s.io] Pods
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 19:40:43.413: INFO: >>> kubeConfig: /tmp/kubeconfig-166913721
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Dec  3 19:40:43.489: INFO: Waiting up to 5m0s for pod "downwardapi-volume-52879a67-f733-11e8-8d0a-02420af40402" in namespace "e2e-tests-projected-49m62" to be "success or failure"
Dec  3 19:40:43.498: INFO: Pod "downwardapi-volume-52879a67-f733-11e8-8d0a-02420af40402": Phase="Pending", Reason="", readiness=false. Elapsed: 9.680434ms
Dec  3 19:40:45.503: INFO: Pod "downwardapi-volume-52879a67-f733-11e8-8d0a-02420af40402": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013927045s
Dec  3 19:40:47.507: INFO: Pod "downwardapi-volume-52879a67-f733-11e8-8d0a-02420af40402": Phase="Pending", Reason="", readiness=false. Elapsed: 4.018010194s
Dec  3 19:40:49.713: INFO: Pod "downwardapi-volume-52879a67-f733-11e8-8d0a-02420af40402": Phase="Pending", Reason="", readiness=false. Elapsed: 6.224468812s
Dec  3 19:40:51.717: INFO: Pod "downwardapi-volume-52879a67-f733-11e8-8d0a-02420af40402": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.228570342s
STEP: Saw pod success
Dec  3 19:40:51.717: INFO: Pod "downwardapi-volume-52879a67-f733-11e8-8d0a-02420af40402" satisfied condition "success or failure"
Dec  3 19:40:51.725: INFO: Trying to get logs from node hungry-keller-3o9a pod downwardapi-volume-52879a67-f733-11e8-8d0a-02420af40402 container client-container: <nil>
STEP: delete the pod
Dec  3 19:40:51.744: INFO: Waiting for pod downwardapi-volume-52879a67-f733-11e8-8d0a-02420af40402 to disappear
Dec  3 19:40:51.748: INFO: Pod downwardapi-volume-52879a67-f733-11e8-8d0a-02420af40402 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 19:40:51.748: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-49m62" for this suite.
Dec  3 19:40:57.762: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 19:40:57.841: INFO: namespace: e2e-tests-projected-49m62, resource: bindings, ignored listing per whitelist
Dec  3 19:40:57.857: INFO: namespace e2e-tests-projected-49m62 deletion completed in 6.106536827s

• [SLOW TEST:14.444 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] Projected 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 19:40:57.858: INFO: >>> kubeConfig: /tmp/kubeconfig-166913721
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Dec  3 19:40:57.934: INFO: Waiting up to 5m0s for pod "downwardapi-volume-5b23ef0c-f733-11e8-8d0a-02420af40402" in namespace "e2e-tests-projected-nplcc" to be "success or failure"
Dec  3 19:40:57.944: INFO: Pod "downwardapi-volume-5b23ef0c-f733-11e8-8d0a-02420af40402": Phase="Pending", Reason="", readiness=false. Elapsed: 9.881458ms
Dec  3 19:40:59.947: INFO: Pod "downwardapi-volume-5b23ef0c-f733-11e8-8d0a-02420af40402": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.013595287s
STEP: Saw pod success
Dec  3 19:40:59.947: INFO: Pod "downwardapi-volume-5b23ef0c-f733-11e8-8d0a-02420af40402" satisfied condition "success or failure"
Dec  3 19:40:59.950: INFO: Trying to get logs from node hungry-keller-3o9a pod downwardapi-volume-5b23ef0c-f733-11e8-8d0a-02420af40402 container client-container: <nil>
STEP: delete the pod
Dec  3 19:40:59.970: INFO: Waiting for pod downwardapi-volume-5b23ef0c-f733-11e8-8d0a-02420af40402 to disappear
Dec  3 19:40:59.974: INFO: Pod downwardapi-volume-5b23ef0c-f733-11e8-8d0a-02420af40402 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 19:40:59.975: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-nplcc" for this suite.
Dec  3 19:41:05.987: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 19:41:06.016: INFO: namespace: e2e-tests-projected-nplcc, resource: bindings, ignored listing per whitelist
Dec  3 19:41:06.080: INFO: namespace e2e-tests-projected-nplcc deletion completed in 6.102755043s

• [SLOW TEST:8.222 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 19:41:06.081: INFO: >>> kubeConfig: /tmp/kubeconfig-166913721
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0666 on node default medium
Dec  3 19:41:06.165: INFO: Waiting up to 5m0s for pod "pod-600be643-f733-11e8-8d0a-02420af40402" in namespace "e2e-tests-emptydir-8bcfl" to be "success or failure"
Dec  3 19:41:06.180: INFO: Pod "pod-600be643-f733-11e8-8d0a-02420af40402": Phase="Pending", Reason="", readiness=false. Elapsed: 15.069982ms
Dec  3 19:41:08.183: INFO: Pod "pod-600be643-f733-11e8-8d0a-02420af40402": Phase="Pending", Reason="", readiness=false. Elapsed: 2.018594416s
Dec  3 19:41:10.187: INFO: Pod "pod-600be643-f733-11e8-8d0a-02420af40402": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.022556113s
STEP: Saw pod success
Dec  3 19:41:10.187: INFO: Pod "pod-600be643-f733-11e8-8d0a-02420af40402" satisfied condition "success or failure"
Dec  3 19:41:10.190: INFO: Trying to get logs from node hungry-keller-3o9a pod pod-600be643-f733-11e8-8d0a-02420af40402 container test-container: <nil>
STEP: delete the pod
Dec  3 19:41:10.221: INFO: Waiting for pod pod-600be643-f733-11e8-8d0a-02420af40402 to disappear
Dec  3 19:41:10.231: INFO: Pod pod-600be643-f733-11e8-8d0a-02420af40402 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 19:41:10.232: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-8bcfl" for this suite.
Dec  3 19:41:16.246: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 19:41:16.285: INFO: namespace: e2e-tests-emptydir-8bcfl, resource: bindings, ignored listing per whitelist
Dec  3 19:41:16.343: INFO: namespace e2e-tests-emptydir-8bcfl deletion completed in 6.10749332s

• [SLOW TEST:10.262 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[k8s.io] Docker Containers 
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 19:41:16.343: INFO: >>> kubeConfig: /tmp/kubeconfig-166913721
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test use defaults
Dec  3 19:41:16.418: INFO: Waiting up to 5m0s for pod "client-containers-66286d20-f733-11e8-8d0a-02420af40402" in namespace "e2e-tests-containers-nr5f4" to be "success or failure"
Dec  3 19:41:16.429: INFO: Pod "client-containers-66286d20-f733-11e8-8d0a-02420af40402": Phase="Pending", Reason="", readiness=false. Elapsed: 10.563792ms
Dec  3 19:41:18.433: INFO: Pod "client-containers-66286d20-f733-11e8-8d0a-02420af40402": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014325527s
Dec  3 19:41:20.436: INFO: Pod "client-containers-66286d20-f733-11e8-8d0a-02420af40402": Phase="Pending", Reason="", readiness=false. Elapsed: 4.018110599s
Dec  3 19:41:22.440: INFO: Pod "client-containers-66286d20-f733-11e8-8d0a-02420af40402": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.02207769s
STEP: Saw pod success
Dec  3 19:41:22.440: INFO: Pod "client-containers-66286d20-f733-11e8-8d0a-02420af40402" satisfied condition "success or failure"
Dec  3 19:41:22.443: INFO: Trying to get logs from node hungry-keller-3o9a pod client-containers-66286d20-f733-11e8-8d0a-02420af40402 container test-container: <nil>
STEP: delete the pod
Dec  3 19:41:22.469: INFO: Waiting for pod client-containers-66286d20-f733-11e8-8d0a-02420af40402 to disappear
Dec  3 19:41:22.473: INFO: Pod client-containers-66286d20-f733-11e8-8d0a-02420af40402 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 19:41:22.473: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-nr5f4" for this suite.
Dec  3 19:41:28.491: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 19:41:28.565: INFO: namespace: e2e-tests-containers-nr5f4, resource: bindings, ignored listing per whitelist
Dec  3 19:41:28.602: INFO: namespace e2e-tests-containers-nr5f4 deletion completed in 6.125399419s

• [SLOW TEST:12.259 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts 
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 19:41:28.602: INFO: >>> kubeConfig: /tmp/kubeconfig-166913721
STEP: Building a namespace api object, basename svcaccounts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should mount an API token into pods  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: getting the auto-created API token
STEP: Creating a pod to test consume service account token
Dec  3 19:41:29.198: INFO: Waiting up to 5m0s for pod "pod-service-account-6dc65612-f733-11e8-8d0a-02420af40402-5k2h9" in namespace "e2e-tests-svcaccounts-m2rr9" to be "success or failure"
Dec  3 19:41:29.211: INFO: Pod "pod-service-account-6dc65612-f733-11e8-8d0a-02420af40402-5k2h9": Phase="Pending", Reason="", readiness=false. Elapsed: 13.873486ms
Dec  3 19:41:31.215: INFO: Pod "pod-service-account-6dc65612-f733-11e8-8d0a-02420af40402-5k2h9": Phase="Pending", Reason="", readiness=false. Elapsed: 2.017439989s
Dec  3 19:41:33.218: INFO: Pod "pod-service-account-6dc65612-f733-11e8-8d0a-02420af40402-5k2h9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.020877984s
STEP: Saw pod success
Dec  3 19:41:33.218: INFO: Pod "pod-service-account-6dc65612-f733-11e8-8d0a-02420af40402-5k2h9" satisfied condition "success or failure"
Dec  3 19:41:33.221: INFO: Trying to get logs from node hungry-keller-3o9a pod pod-service-account-6dc65612-f733-11e8-8d0a-02420af40402-5k2h9 container token-test: <nil>
STEP: delete the pod
Dec  3 19:41:33.243: INFO: Waiting for pod pod-service-account-6dc65612-f733-11e8-8d0a-02420af40402-5k2h9 to disappear
Dec  3 19:41:33.247: INFO: Pod pod-service-account-6dc65612-f733-11e8-8d0a-02420af40402-5k2h9 no longer exists
STEP: Creating a pod to test consume service account root CA
Dec  3 19:41:33.252: INFO: Waiting up to 5m0s for pod "pod-service-account-6dc65612-f733-11e8-8d0a-02420af40402-85bxg" in namespace "e2e-tests-svcaccounts-m2rr9" to be "success or failure"
Dec  3 19:41:33.261: INFO: Pod "pod-service-account-6dc65612-f733-11e8-8d0a-02420af40402-85bxg": Phase="Pending", Reason="", readiness=false. Elapsed: 9.063445ms
Dec  3 19:41:35.265: INFO: Pod "pod-service-account-6dc65612-f733-11e8-8d0a-02420af40402-85bxg": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012533364s
Dec  3 19:41:37.268: INFO: Pod "pod-service-account-6dc65612-f733-11e8-8d0a-02420af40402-85bxg": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.016052114s
STEP: Saw pod success
Dec  3 19:41:37.268: INFO: Pod "pod-service-account-6dc65612-f733-11e8-8d0a-02420af40402-85bxg" satisfied condition "success or failure"
Dec  3 19:41:37.271: INFO: Trying to get logs from node hungry-keller-3o9e pod pod-service-account-6dc65612-f733-11e8-8d0a-02420af40402-85bxg container root-ca-test: <nil>
STEP: delete the pod
Dec  3 19:41:37.309: INFO: Waiting for pod pod-service-account-6dc65612-f733-11e8-8d0a-02420af40402-85bxg to disappear
Dec  3 19:41:37.313: INFO: Pod pod-service-account-6dc65612-f733-11e8-8d0a-02420af40402-85bxg no longer exists
STEP: Creating a pod to test consume service account namespace
Dec  3 19:41:37.318: INFO: Waiting up to 5m0s for pod "pod-service-account-6dc65612-f733-11e8-8d0a-02420af40402-ml5ww" in namespace "e2e-tests-svcaccounts-m2rr9" to be "success or failure"
Dec  3 19:41:37.327: INFO: Pod "pod-service-account-6dc65612-f733-11e8-8d0a-02420af40402-ml5ww": Phase="Pending", Reason="", readiness=false. Elapsed: 9.511607ms
Dec  3 19:41:39.334: INFO: Pod "pod-service-account-6dc65612-f733-11e8-8d0a-02420af40402-ml5ww": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.016132738s
STEP: Saw pod success
Dec  3 19:41:39.334: INFO: Pod "pod-service-account-6dc65612-f733-11e8-8d0a-02420af40402-ml5ww" satisfied condition "success or failure"
Dec  3 19:41:39.337: INFO: Trying to get logs from node hungry-keller-3o9a pod pod-service-account-6dc65612-f733-11e8-8d0a-02420af40402-ml5ww container namespace-test: <nil>
STEP: delete the pod
Dec  3 19:41:39.360: INFO: Waiting for pod pod-service-account-6dc65612-f733-11e8-8d0a-02420af40402-ml5ww to disappear
Dec  3 19:41:39.364: INFO: Pod pod-service-account-6dc65612-f733-11e8-8d0a-02420af40402-ml5ww no longer exists
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 19:41:39.365: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-svcaccounts-m2rr9" for this suite.
Dec  3 19:41:45.383: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 19:41:45.449: INFO: namespace: e2e-tests-svcaccounts-m2rr9, resource: bindings, ignored listing per whitelist
Dec  3 19:41:45.476: INFO: namespace e2e-tests-svcaccounts-m2rr9 deletion completed in 6.104414347s

• [SLOW TEST:16.875 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:22
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 19:41:45.477: INFO: >>> kubeConfig: /tmp/kubeconfig-166913721
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: setting up watch
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: verifying pod creation was observed
Dec  3 19:41:47.590: INFO: running pod: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-submit-remove-7787465c-f733-11e8-8d0a-02420af40402", GenerateName:"", Namespace:"e2e-tests-pods-cnt2r", SelfLink:"/api/v1/namespaces/e2e-tests-pods-cnt2r/pods/pod-submit-remove-7787465c-f733-11e8-8d0a-02420af40402", UID:"7789a0cc-f733-11e8-8af3-a28d93e01224", ResourceVersion:"2900", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63679462905, loc:(*time.Location)(0x6c43b60)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"554702694"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Initializers:(*v1.Initializers)(nil), Finalizers:[]string(nil), ClusterName:""}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"default-token-2g82q", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(0xc4209a0b00), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil)}}}, InitContainers:[]v1.Container(nil), Containers:[]v1.Container{v1.Container{Name:"nginx", Image:"docker.io/library/nginx:1.14-alpine", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-2g82q", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc4209b6c58), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"hungry-keller-3o9a", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc421f9ef60), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc4209b6c90)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc4209b6cb0)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc4209b6cb8), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil)}, Status:v1.PodStatus{Phase:"Running", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63679462905, loc:(*time.Location)(0x6c43b60)}}, Reason:"", Message:""}, v1.PodCondition{Type:"Ready", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63679462907, loc:(*time.Location)(0x6c43b60)}}, Reason:"", Message:""}, v1.PodCondition{Type:"ContainersReady", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63679462907, loc:(*time.Location)(0x6c43b60)}}, Reason:"", Message:""}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63679462905, loc:(*time.Location)(0x6c43b60)}}, Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"10.136.91.235", PodIP:"10.244.72.3", StartTime:(*v1.Time)(0xc4211f0320), InitContainerStatuses:[]v1.ContainerStatus(nil), ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"nginx", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(0xc4211f0340), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:true, RestartCount:0, Image:"nginx:1.14-alpine", ImageID:"docker-pullable://nginx@sha256:3c1380fd5f6f0e4c468a922ed6331831e60cea9db317b8ac4a8ad36335e53bbd", ContainerID:"docker://e7ad1450f517dbe5ac4f52882e73bc851f180126dae56b3fd88992640a56b460"}}, QOSClass:"BestEffort"}}
STEP: deleting the pod gracefully
STEP: verifying the kubelet observed the termination notice
STEP: verifying pod deletion was observed
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 19:41:54.710: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-cnt2r" for this suite.
Dec  3 19:42:00.725: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 19:42:00.750: INFO: namespace: e2e-tests-pods-cnt2r, resource: bindings, ignored listing per whitelist
Dec  3 19:42:00.811: INFO: namespace e2e-tests-pods-cnt2r deletion completed in 6.09673342s

• [SLOW TEST:15.335 seconds]
[k8s.io] Pods
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Downward API 
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 19:42:00.813: INFO: >>> kubeConfig: /tmp/kubeconfig-166913721
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Dec  3 19:42:00.886: INFO: Waiting up to 5m0s for pod "downward-api-80a988f8-f733-11e8-8d0a-02420af40402" in namespace "e2e-tests-downward-api-jfpfd" to be "success or failure"
Dec  3 19:42:00.895: INFO: Pod "downward-api-80a988f8-f733-11e8-8d0a-02420af40402": Phase="Pending", Reason="", readiness=false. Elapsed: 8.598281ms
Dec  3 19:42:02.899: INFO: Pod "downward-api-80a988f8-f733-11e8-8d0a-02420af40402": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.012573955s
STEP: Saw pod success
Dec  3 19:42:02.899: INFO: Pod "downward-api-80a988f8-f733-11e8-8d0a-02420af40402" satisfied condition "success or failure"
Dec  3 19:42:02.902: INFO: Trying to get logs from node hungry-keller-3o9a pod downward-api-80a988f8-f733-11e8-8d0a-02420af40402 container dapi-container: <nil>
STEP: delete the pod
Dec  3 19:42:02.924: INFO: Waiting for pod downward-api-80a988f8-f733-11e8-8d0a-02420af40402 to disappear
Dec  3 19:42:02.931: INFO: Pod downward-api-80a988f8-f733-11e8-8d0a-02420af40402 no longer exists
[AfterEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 19:42:02.931: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-jfpfd" for this suite.
Dec  3 19:42:08.943: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 19:42:08.960: INFO: namespace: e2e-tests-downward-api-jfpfd, resource: bindings, ignored listing per whitelist
Dec  3 19:42:09.032: INFO: namespace e2e-tests-downward-api-jfpfd deletion completed in 6.098744572s

• [SLOW TEST:8.220 seconds]
[sig-api-machinery] Downward API
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 19:42:09.033: INFO: >>> kubeConfig: /tmp/kubeconfig-166913721
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-85914536-f733-11e8-8d0a-02420af40402
STEP: Creating a pod to test consume configMaps
Dec  3 19:42:09.118: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-8591d90e-f733-11e8-8d0a-02420af40402" in namespace "e2e-tests-projected-lx7hm" to be "success or failure"
Dec  3 19:42:09.131: INFO: Pod "pod-projected-configmaps-8591d90e-f733-11e8-8d0a-02420af40402": Phase="Pending", Reason="", readiness=false. Elapsed: 12.556648ms
Dec  3 19:42:11.135: INFO: Pod "pod-projected-configmaps-8591d90e-f733-11e8-8d0a-02420af40402": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.016292516s
STEP: Saw pod success
Dec  3 19:42:11.135: INFO: Pod "pod-projected-configmaps-8591d90e-f733-11e8-8d0a-02420af40402" satisfied condition "success or failure"
Dec  3 19:42:11.138: INFO: Trying to get logs from node hungry-keller-3o9a pod pod-projected-configmaps-8591d90e-f733-11e8-8d0a-02420af40402 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Dec  3 19:42:11.162: INFO: Waiting for pod pod-projected-configmaps-8591d90e-f733-11e8-8d0a-02420af40402 to disappear
Dec  3 19:42:11.170: INFO: Pod pod-projected-configmaps-8591d90e-f733-11e8-8d0a-02420af40402 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 19:42:11.170: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-lx7hm" for this suite.
Dec  3 19:42:17.184: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 19:42:17.243: INFO: namespace: e2e-tests-projected-lx7hm, resource: bindings, ignored listing per whitelist
Dec  3 19:42:17.275: INFO: namespace e2e-tests-projected-lx7hm deletion completed in 6.102570303s

• [SLOW TEST:8.242 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected 
  should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 19:42:17.275: INFO: >>> kubeConfig: /tmp/kubeconfig-166913721
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Dec  3 19:42:17.352: INFO: Waiting up to 5m0s for pod "downwardapi-volume-8a7992fe-f733-11e8-8d0a-02420af40402" in namespace "e2e-tests-projected-rjz67" to be "success or failure"
Dec  3 19:42:17.363: INFO: Pod "downwardapi-volume-8a7992fe-f733-11e8-8d0a-02420af40402": Phase="Pending", Reason="", readiness=false. Elapsed: 11.486954ms
Dec  3 19:42:19.366: INFO: Pod "downwardapi-volume-8a7992fe-f733-11e8-8d0a-02420af40402": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.014757551s
STEP: Saw pod success
Dec  3 19:42:19.366: INFO: Pod "downwardapi-volume-8a7992fe-f733-11e8-8d0a-02420af40402" satisfied condition "success or failure"
Dec  3 19:42:19.369: INFO: Trying to get logs from node hungry-keller-3o9a pod downwardapi-volume-8a7992fe-f733-11e8-8d0a-02420af40402 container client-container: <nil>
STEP: delete the pod
Dec  3 19:42:19.387: INFO: Waiting for pod downwardapi-volume-8a7992fe-f733-11e8-8d0a-02420af40402 to disappear
Dec  3 19:42:19.575: INFO: Pod downwardapi-volume-8a7992fe-f733-11e8-8d0a-02420af40402 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 19:42:19.575: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-rjz67" for this suite.
Dec  3 19:42:25.593: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 19:42:25.636: INFO: namespace: e2e-tests-projected-rjz67, resource: bindings, ignored listing per whitelist
Dec  3 19:42:25.689: INFO: namespace e2e-tests-projected-rjz67 deletion completed in 6.109456682s

• [SLOW TEST:8.413 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 19:42:25.689: INFO: >>> kubeConfig: /tmp/kubeconfig-166913721
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0644 on node default medium
Dec  3 19:42:25.812: INFO: Waiting up to 5m0s for pod "pod-8f850dea-f733-11e8-8d0a-02420af40402" in namespace "e2e-tests-emptydir-nfmrd" to be "success or failure"
Dec  3 19:42:25.821: INFO: Pod "pod-8f850dea-f733-11e8-8d0a-02420af40402": Phase="Pending", Reason="", readiness=false. Elapsed: 8.54746ms
Dec  3 19:42:27.824: INFO: Pod "pod-8f850dea-f733-11e8-8d0a-02420af40402": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.012261703s
STEP: Saw pod success
Dec  3 19:42:27.824: INFO: Pod "pod-8f850dea-f733-11e8-8d0a-02420af40402" satisfied condition "success or failure"
Dec  3 19:42:27.827: INFO: Trying to get logs from node hungry-keller-3o9a pod pod-8f850dea-f733-11e8-8d0a-02420af40402 container test-container: <nil>
STEP: delete the pod
Dec  3 19:42:27.849: INFO: Waiting for pod pod-8f850dea-f733-11e8-8d0a-02420af40402 to disappear
Dec  3 19:42:27.853: INFO: Pod pod-8f850dea-f733-11e8-8d0a-02420af40402 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 19:42:27.853: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-nfmrd" for this suite.
Dec  3 19:42:34.073: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 19:42:34.092: INFO: namespace: e2e-tests-emptydir-nfmrd, resource: bindings, ignored listing per whitelist
Dec  3 19:42:34.166: INFO: namespace e2e-tests-emptydir-nfmrd deletion completed in 6.111306397s

• [SLOW TEST:8.477 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 19:42:34.166: INFO: >>> kubeConfig: /tmp/kubeconfig-166913721
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:293
[It] should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a replication controller
Dec  3 19:42:34.231: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-166913721 create -f - --namespace=e2e-tests-kubectl-4fcgb'
Dec  3 19:42:34.609: INFO: stderr: ""
Dec  3 19:42:34.609: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Dec  3 19:42:34.609: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-166913721 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-4fcgb'
Dec  3 19:42:34.730: INFO: stderr: ""
Dec  3 19:42:34.730: INFO: stdout: "update-demo-nautilus-7tz8c update-demo-nautilus-wknh4 "
Dec  3 19:42:34.730: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-166913721 get pods update-demo-nautilus-7tz8c -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-4fcgb'
Dec  3 19:42:34.826: INFO: stderr: ""
Dec  3 19:42:34.826: INFO: stdout: ""
Dec  3 19:42:34.826: INFO: update-demo-nautilus-7tz8c is created but not running
Dec  3 19:42:39.827: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-166913721 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-4fcgb'
Dec  3 19:42:39.954: INFO: stderr: ""
Dec  3 19:42:39.954: INFO: stdout: "update-demo-nautilus-7tz8c update-demo-nautilus-wknh4 "
Dec  3 19:42:39.954: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-166913721 get pods update-demo-nautilus-7tz8c -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-4fcgb'
Dec  3 19:42:40.057: INFO: stderr: ""
Dec  3 19:42:40.057: INFO: stdout: "true"
Dec  3 19:42:40.057: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-166913721 get pods update-demo-nautilus-7tz8c -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-4fcgb'
Dec  3 19:42:40.162: INFO: stderr: ""
Dec  3 19:42:40.162: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Dec  3 19:42:40.162: INFO: validating pod update-demo-nautilus-7tz8c
Dec  3 19:42:40.171: INFO: got data: {
  "image": "nautilus.jpg"
}

Dec  3 19:42:40.171: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Dec  3 19:42:40.171: INFO: update-demo-nautilus-7tz8c is verified up and running
Dec  3 19:42:40.171: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-166913721 get pods update-demo-nautilus-wknh4 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-4fcgb'
Dec  3 19:42:40.274: INFO: stderr: ""
Dec  3 19:42:40.274: INFO: stdout: "true"
Dec  3 19:42:40.274: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-166913721 get pods update-demo-nautilus-wknh4 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-4fcgb'
Dec  3 19:42:40.380: INFO: stderr: ""
Dec  3 19:42:40.380: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Dec  3 19:42:40.381: INFO: validating pod update-demo-nautilus-wknh4
Dec  3 19:42:40.387: INFO: got data: {
  "image": "nautilus.jpg"
}

Dec  3 19:42:40.387: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Dec  3 19:42:40.387: INFO: update-demo-nautilus-wknh4 is verified up and running
STEP: using delete to clean up resources
Dec  3 19:42:40.387: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-166913721 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-4fcgb'
Dec  3 19:42:40.497: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Dec  3 19:42:40.497: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Dec  3 19:42:40.497: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-166913721 get rc,svc -l name=update-demo --no-headers --namespace=e2e-tests-kubectl-4fcgb'
Dec  3 19:42:40.642: INFO: stderr: "No resources found.\n"
Dec  3 19:42:40.642: INFO: stdout: ""
Dec  3 19:42:40.642: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-166913721 get pods -l name=update-demo --namespace=e2e-tests-kubectl-4fcgb -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Dec  3 19:42:40.758: INFO: stderr: ""
Dec  3 19:42:40.758: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 19:42:40.758: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-4fcgb" for this suite.
Dec  3 19:43:02.772: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 19:43:02.797: INFO: namespace: e2e-tests-kubectl-4fcgb, resource: bindings, ignored listing per whitelist
Dec  3 19:43:02.867: INFO: namespace e2e-tests-kubectl-4fcgb deletion completed in 22.105721993s

• [SLOW TEST:28.701 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Update Demo
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create and stop a replication controller  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run default 
  should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 19:43:02.868: INFO: >>> kubeConfig: /tmp/kubeconfig-166913721
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Kubectl run default
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1210
[It] should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Dec  3 19:43:02.932: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-166913721 run e2e-test-nginx-deployment --image=docker.io/library/nginx:1.14-alpine --namespace=e2e-tests-kubectl-b82tf'
Dec  3 19:43:03.070: INFO: stderr: "kubectl run --generator=deployment/apps.v1beta1 is DEPRECATED and will be removed in a future version. Use kubectl create instead.\n"
Dec  3 19:43:03.070: INFO: stdout: "deployment.apps/e2e-test-nginx-deployment created\n"
STEP: verifying the pod controlled by e2e-test-nginx-deployment gets created
[AfterEach] [k8s.io] Kubectl run default
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1216
Dec  3 19:43:05.092: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-166913721 delete deployment e2e-test-nginx-deployment --namespace=e2e-tests-kubectl-b82tf'
Dec  3 19:43:05.228: INFO: stderr: ""
Dec  3 19:43:05.228: INFO: stdout: "deployment.extensions \"e2e-test-nginx-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 19:43:05.228: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-b82tf" for this suite.
Dec  3 19:43:11.256: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 19:43:11.316: INFO: namespace: e2e-tests-kubectl-b82tf, resource: bindings, ignored listing per whitelist
Dec  3 19:43:11.343: INFO: namespace e2e-tests-kubectl-b82tf deletion completed in 6.104022393s

• [SLOW TEST:8.475 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run default
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create an rc or deployment from an image  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 19:43:11.346: INFO: >>> kubeConfig: /tmp/kubeconfig-166913721
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:98
[It] should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Dec  3 19:43:11.431: INFO: Requires at least 2 nodes (not -1)
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:64
Dec  3 19:43:11.438: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-bbdgp/daemonsets","resourceVersion":"3230"},"items":null}

Dec  3 19:43:11.442: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-bbdgp/pods","resourceVersion":"3230"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 19:43:11.459: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-bbdgp" for this suite.
Dec  3 19:43:17.473: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 19:43:17.494: INFO: namespace: e2e-tests-daemonsets-bbdgp, resource: bindings, ignored listing per whitelist
Dec  3 19:43:17.563: INFO: namespace e2e-tests-daemonsets-bbdgp deletion completed in 6.100746133s

S [SKIPPING] [6.217 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should rollback without unnecessary restarts [Conformance] [It]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699

  Dec  3 19:43:11.431: Requires at least 2 nodes (not -1)

  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/util.go:292
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] Projected 
  should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 19:43:17.563: INFO: >>> kubeConfig: /tmp/kubeconfig-166913721
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Dec  3 19:43:17.645: INFO: Waiting up to 5m0s for pod "downwardapi-volume-ae6a46b0-f733-11e8-8d0a-02420af40402" in namespace "e2e-tests-projected-ql6bf" to be "success or failure"
Dec  3 19:43:17.652: INFO: Pod "downwardapi-volume-ae6a46b0-f733-11e8-8d0a-02420af40402": Phase="Pending", Reason="", readiness=false. Elapsed: 6.798023ms
Dec  3 19:43:19.656: INFO: Pod "downwardapi-volume-ae6a46b0-f733-11e8-8d0a-02420af40402": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010740877s
STEP: Saw pod success
Dec  3 19:43:19.656: INFO: Pod "downwardapi-volume-ae6a46b0-f733-11e8-8d0a-02420af40402" satisfied condition "success or failure"
Dec  3 19:43:19.658: INFO: Trying to get logs from node hungry-keller-3o9a pod downwardapi-volume-ae6a46b0-f733-11e8-8d0a-02420af40402 container client-container: <nil>
STEP: delete the pod
Dec  3 19:43:19.680: INFO: Waiting for pod downwardapi-volume-ae6a46b0-f733-11e8-8d0a-02420af40402 to disappear
Dec  3 19:43:20.261: INFO: Pod downwardapi-volume-ae6a46b0-f733-11e8-8d0a-02420af40402 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 19:43:20.261: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-ql6bf" for this suite.
Dec  3 19:43:26.294: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 19:43:26.350: INFO: namespace: e2e-tests-projected-ql6bf, resource: bindings, ignored listing per whitelist
Dec  3 19:43:26.405: INFO: namespace e2e-tests-projected-ql6bf deletion completed in 6.125508869s

• [SLOW TEST:8.841 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Guestbook application 
  should create and stop a working application  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 19:43:26.405: INFO: >>> kubeConfig: /tmp/kubeconfig-166913721
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should create and stop a working application  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating all guestbook components
Dec  3 19:43:26.525: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-slave
  labels:
    app: redis
    role: slave
    tier: backend
spec:
  ports:
  - port: 6379
  selector:
    app: redis
    role: slave
    tier: backend

Dec  3 19:43:26.525: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-166913721 create -f - --namespace=e2e-tests-kubectl-642p9'
Dec  3 19:43:26.736: INFO: stderr: ""
Dec  3 19:43:26.736: INFO: stdout: "service/redis-slave created\n"
Dec  3 19:43:26.736: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-master
  labels:
    app: redis
    role: master
    tier: backend
spec:
  ports:
  - port: 6379
    targetPort: 6379
  selector:
    app: redis
    role: master
    tier: backend

Dec  3 19:43:26.736: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-166913721 create -f - --namespace=e2e-tests-kubectl-642p9'
Dec  3 19:43:26.948: INFO: stderr: ""
Dec  3 19:43:26.948: INFO: stdout: "service/redis-master created\n"
Dec  3 19:43:26.948: INFO: apiVersion: v1
kind: Service
metadata:
  name: frontend
  labels:
    app: guestbook
    tier: frontend
spec:
  # if your cluster supports it, uncomment the following to automatically create
  # an external load-balanced IP for the frontend service.
  # type: LoadBalancer
  ports:
  - port: 80
  selector:
    app: guestbook
    tier: frontend

Dec  3 19:43:26.948: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-166913721 create -f - --namespace=e2e-tests-kubectl-642p9'
Dec  3 19:43:27.157: INFO: stderr: ""
Dec  3 19:43:27.157: INFO: stdout: "service/frontend created\n"
Dec  3 19:43:27.157: INFO: apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: frontend
spec:
  replicas: 3
  template:
    metadata:
      labels:
        app: guestbook
        tier: frontend
    spec:
      containers:
      - name: php-redis
        image: gcr.io/google-samples/gb-frontend:v6
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access environment variables to find service host
          # info, comment out the 'value: dns' line above, and uncomment the
          # line below:
          # value: env
        ports:
        - containerPort: 80

Dec  3 19:43:27.157: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-166913721 create -f - --namespace=e2e-tests-kubectl-642p9'
Dec  3 19:43:27.395: INFO: stderr: ""
Dec  3 19:43:27.395: INFO: stdout: "deployment.extensions/frontend created\n"
Dec  3 19:43:27.395: INFO: apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: redis-master
spec:
  replicas: 1
  template:
    metadata:
      labels:
        app: redis
        role: master
        tier: backend
    spec:
      containers:
      - name: master
        image: gcr.io/kubernetes-e2e-test-images/redis:1.0
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        ports:
        - containerPort: 6379

Dec  3 19:43:27.395: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-166913721 create -f - --namespace=e2e-tests-kubectl-642p9'
Dec  3 19:43:27.624: INFO: stderr: ""
Dec  3 19:43:27.624: INFO: stdout: "deployment.extensions/redis-master created\n"
Dec  3 19:43:27.624: INFO: apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: redis-slave
spec:
  replicas: 2
  template:
    metadata:
      labels:
        app: redis
        role: slave
        tier: backend
    spec:
      containers:
      - name: slave
        image: gcr.io/google-samples/gb-redisslave:v3
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access an environment variable to find the master
          # service's host, comment out the 'value: dns' line above, and
          # uncomment the line below:
          # value: env
        ports:
        - containerPort: 6379

Dec  3 19:43:27.624: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-166913721 create -f - --namespace=e2e-tests-kubectl-642p9'
Dec  3 19:43:27.856: INFO: stderr: ""
Dec  3 19:43:27.856: INFO: stdout: "deployment.extensions/redis-slave created\n"
STEP: validating guestbook app
Dec  3 19:43:27.856: INFO: Waiting for all frontend pods to be Running.
Dec  3 19:43:42.906: INFO: Waiting for frontend to serve content.
Dec  3 19:43:42.929: INFO: Trying to add a new entry to the guestbook.
Dec  3 19:43:42.940: INFO: Verifying that added entry can be retrieved.
Dec  3 19:43:42.957: INFO: Failed to get response from guestbook. err: <nil>, response: {"data": ""}
STEP: using delete to clean up resources
Dec  3 19:43:47.974: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-166913721 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-642p9'
Dec  3 19:43:48.110: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Dec  3 19:43:48.110: INFO: stdout: "service \"redis-slave\" force deleted\n"
STEP: using delete to clean up resources
Dec  3 19:43:48.111: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-166913721 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-642p9'
Dec  3 19:43:48.268: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Dec  3 19:43:48.268: INFO: stdout: "service \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
Dec  3 19:43:48.269: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-166913721 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-642p9'
Dec  3 19:43:48.465: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Dec  3 19:43:48.465: INFO: stdout: "service \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Dec  3 19:43:48.465: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-166913721 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-642p9'
Dec  3 19:43:48.613: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Dec  3 19:43:48.613: INFO: stdout: "deployment.extensions \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Dec  3 19:43:48.613: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-166913721 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-642p9'
Dec  3 19:43:48.759: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Dec  3 19:43:48.759: INFO: stdout: "deployment.extensions \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
Dec  3 19:43:48.759: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-166913721 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-642p9'
Dec  3 19:43:48.903: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Dec  3 19:43:48.903: INFO: stdout: "deployment.extensions \"redis-slave\" force deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 19:43:48.903: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-642p9" for this suite.
Dec  3 19:44:28.936: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 19:44:28.959: INFO: namespace: e2e-tests-kubectl-642p9, resource: bindings, ignored listing per whitelist
Dec  3 19:44:29.043: INFO: namespace e2e-tests-kubectl-642p9 deletion completed in 40.13039932s

• [SLOW TEST:62.639 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Guestbook application
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create and stop a working application  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 19:44:29.043: INFO: >>> kubeConfig: /tmp/kubeconfig-166913721
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
Dec  3 19:44:29.112: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 19:44:33.131: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-init-container-bgfjm" for this suite.
Dec  3 19:44:39.146: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 19:44:39.223: INFO: namespace: e2e-tests-init-container-bgfjm, resource: bindings, ignored listing per whitelist
Dec  3 19:44:39.312: INFO: namespace e2e-tests-init-container-bgfjm deletion completed in 6.17790773s

• [SLOW TEST:10.269 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 19:44:39.312: INFO: >>> kubeConfig: /tmp/kubeconfig-166913721
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-fmzlz
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Dec  3 19:44:39.416: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Dec  3 19:45:03.648: INFO: ExecWithOptions {Command:[/bin/sh -c echo 'hostName' | timeout -t 2 nc -w 1 -u 10.244.1.4 8081 | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-fmzlz PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec  3 19:45:03.648: INFO: >>> kubeConfig: /tmp/kubeconfig-166913721
Dec  3 19:45:04.808: INFO: Found all expected endpoints: [netserver-0]
Dec  3 19:45:04.813: INFO: ExecWithOptions {Command:[/bin/sh -c echo 'hostName' | timeout -t 2 nc -w 1 -u 10.244.72.3 8081 | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-fmzlz PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec  3 19:45:04.813: INFO: >>> kubeConfig: /tmp/kubeconfig-166913721
Dec  3 19:45:05.976: INFO: Found all expected endpoints: [netserver-1]
Dec  3 19:45:05.980: INFO: ExecWithOptions {Command:[/bin/sh -c echo 'hostName' | timeout -t 2 nc -w 1 -u 10.244.4.3 8081 | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-fmzlz PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec  3 19:45:05.980: INFO: >>> kubeConfig: /tmp/kubeconfig-166913721
Dec  3 19:45:07.150: INFO: Found all expected endpoints: [netserver-2]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 19:45:07.150: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-fmzlz" for this suite.
Dec  3 19:45:29.165: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 19:45:29.197: INFO: namespace: e2e-tests-pod-network-test-fmzlz, resource: bindings, ignored listing per whitelist
Dec  3 19:45:29.258: INFO: namespace e2e-tests-pod-network-test-fmzlz deletion completed in 22.104010765s

• [SLOW TEST:49.945 seconds]
[sig-network] Networking
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: udp [NodeConformance] [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 19:45:29.258: INFO: >>> kubeConfig: /tmp/kubeconfig-166913721
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test env composition
Dec  3 19:45:29.330: INFO: Waiting up to 5m0s for pod "var-expansion-fce7cb77-f733-11e8-8d0a-02420af40402" in namespace "e2e-tests-var-expansion-cpd54" to be "success or failure"
Dec  3 19:45:29.343: INFO: Pod "var-expansion-fce7cb77-f733-11e8-8d0a-02420af40402": Phase="Pending", Reason="", readiness=false. Elapsed: 13.634682ms
Dec  3 19:45:31.347: INFO: Pod "var-expansion-fce7cb77-f733-11e8-8d0a-02420af40402": Phase="Pending", Reason="", readiness=false. Elapsed: 2.017173488s
Dec  3 19:45:33.351: INFO: Pod "var-expansion-fce7cb77-f733-11e8-8d0a-02420af40402": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.021301325s
STEP: Saw pod success
Dec  3 19:45:33.351: INFO: Pod "var-expansion-fce7cb77-f733-11e8-8d0a-02420af40402" satisfied condition "success or failure"
Dec  3 19:45:33.354: INFO: Trying to get logs from node hungry-keller-3o9a pod var-expansion-fce7cb77-f733-11e8-8d0a-02420af40402 container dapi-container: <nil>
STEP: delete the pod
Dec  3 19:45:33.374: INFO: Waiting for pod var-expansion-fce7cb77-f733-11e8-8d0a-02420af40402 to disappear
Dec  3 19:45:33.381: INFO: Pod var-expansion-fce7cb77-f733-11e8-8d0a-02420af40402 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 19:45:33.381: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-var-expansion-cpd54" for this suite.
Dec  3 19:45:39.393: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 19:45:39.469: INFO: namespace: e2e-tests-var-expansion-cpd54, resource: bindings, ignored listing per whitelist
Dec  3 19:45:39.480: INFO: namespace e2e-tests-var-expansion-cpd54 deletion completed in 6.096605911s

• [SLOW TEST:10.222 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl expose 
  should create services for rc  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 19:45:39.480: INFO: >>> kubeConfig: /tmp/kubeconfig-166913721
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should create services for rc  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating Redis RC
Dec  3 19:45:39.547: INFO: namespace e2e-tests-kubectl-nkcj8
Dec  3 19:45:39.547: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-166913721 create -f - --namespace=e2e-tests-kubectl-nkcj8'
Dec  3 19:45:39.764: INFO: stderr: ""
Dec  3 19:45:39.764: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
Dec  3 19:45:40.768: INFO: Selector matched 1 pods for map[app:redis]
Dec  3 19:45:40.768: INFO: Found 0 / 1
Dec  3 19:45:41.768: INFO: Selector matched 1 pods for map[app:redis]
Dec  3 19:45:41.769: INFO: Found 0 / 1
Dec  3 19:45:42.768: INFO: Selector matched 1 pods for map[app:redis]
Dec  3 19:45:42.768: INFO: Found 0 / 1
Dec  3 19:45:43.768: INFO: Selector matched 1 pods for map[app:redis]
Dec  3 19:45:43.768: INFO: Found 0 / 1
Dec  3 19:45:44.768: INFO: Selector matched 1 pods for map[app:redis]
Dec  3 19:45:44.768: INFO: Found 0 / 1
Dec  3 19:45:45.768: INFO: Selector matched 1 pods for map[app:redis]
Dec  3 19:45:45.768: INFO: Found 0 / 1
Dec  3 19:45:46.768: INFO: Selector matched 1 pods for map[app:redis]
Dec  3 19:45:46.768: INFO: Found 0 / 1
Dec  3 19:45:47.774: INFO: Selector matched 1 pods for map[app:redis]
Dec  3 19:45:47.775: INFO: Found 0 / 1
Dec  3 19:45:48.768: INFO: Selector matched 1 pods for map[app:redis]
Dec  3 19:45:48.768: INFO: Found 1 / 1
Dec  3 19:45:48.768: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Dec  3 19:45:48.771: INFO: Selector matched 1 pods for map[app:redis]
Dec  3 19:45:48.771: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Dec  3 19:45:48.771: INFO: wait on redis-master startup in e2e-tests-kubectl-nkcj8 
Dec  3 19:45:48.771: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-166913721 logs redis-master-rkn6f redis-master --namespace=e2e-tests-kubectl-nkcj8'
Dec  3 19:45:48.911: INFO: stderr: ""
Dec  3 19:45:48.911: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 03 Dec 19:45:47.116 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 03 Dec 19:45:47.116 # Server started, Redis version 3.2.12\n1:M 03 Dec 19:45:47.116 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 03 Dec 19:45:47.116 * The server is now ready to accept connections on port 6379\n"
STEP: exposing RC
Dec  3 19:45:48.911: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-166913721 expose rc redis-master --name=rm2 --port=1234 --target-port=6379 --namespace=e2e-tests-kubectl-nkcj8'
Dec  3 19:45:49.060: INFO: stderr: ""
Dec  3 19:45:49.060: INFO: stdout: "service/rm2 exposed\n"
Dec  3 19:45:49.069: INFO: Service rm2 in namespace e2e-tests-kubectl-nkcj8 found.
STEP: exposing service
Dec  3 19:45:51.075: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-166913721 expose service rm2 --name=rm3 --port=2345 --target-port=6379 --namespace=e2e-tests-kubectl-nkcj8'
Dec  3 19:45:51.230: INFO: stderr: ""
Dec  3 19:45:51.230: INFO: stdout: "service/rm3 exposed\n"
Dec  3 19:45:51.237: INFO: Service rm3 in namespace e2e-tests-kubectl-nkcj8 found.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 19:45:53.243: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-nkcj8" for this suite.
Dec  3 19:46:15.256: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 19:46:15.305: INFO: namespace: e2e-tests-kubectl-nkcj8, resource: bindings, ignored listing per whitelist
Dec  3 19:46:15.387: INFO: namespace e2e-tests-kubectl-nkcj8 deletion completed in 22.141386857s

• [SLOW TEST:35.907 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl expose
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create services for rc  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with projected pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 19:46:15.388: INFO: >>> kubeConfig: /tmp/kubeconfig-166913721
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with projected pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-projected-nv8p
STEP: Creating a pod to test atomic-volume-subpath
Dec  3 19:46:15.489: INFO: Waiting up to 5m0s for pod "pod-subpath-test-projected-nv8p" in namespace "e2e-tests-subpath-4z7f4" to be "success or failure"
Dec  3 19:46:15.503: INFO: Pod "pod-subpath-test-projected-nv8p": Phase="Pending", Reason="", readiness=false. Elapsed: 14.407008ms
Dec  3 19:46:17.507: INFO: Pod "pod-subpath-test-projected-nv8p": Phase="Pending", Reason="", readiness=false. Elapsed: 2.018430294s
Dec  3 19:46:19.512: INFO: Pod "pod-subpath-test-projected-nv8p": Phase="Running", Reason="", readiness=false. Elapsed: 4.02263507s
Dec  3 19:46:21.515: INFO: Pod "pod-subpath-test-projected-nv8p": Phase="Running", Reason="", readiness=false. Elapsed: 6.026458948s
Dec  3 19:46:23.519: INFO: Pod "pod-subpath-test-projected-nv8p": Phase="Running", Reason="", readiness=false. Elapsed: 8.030497582s
Dec  3 19:46:25.523: INFO: Pod "pod-subpath-test-projected-nv8p": Phase="Running", Reason="", readiness=false. Elapsed: 10.034382455s
Dec  3 19:46:27.527: INFO: Pod "pod-subpath-test-projected-nv8p": Phase="Running", Reason="", readiness=false. Elapsed: 12.038273705s
Dec  3 19:46:29.593: INFO: Pod "pod-subpath-test-projected-nv8p": Phase="Running", Reason="", readiness=false. Elapsed: 14.103861984s
Dec  3 19:46:31.597: INFO: Pod "pod-subpath-test-projected-nv8p": Phase="Running", Reason="", readiness=false. Elapsed: 16.107588673s
Dec  3 19:46:33.630: INFO: Pod "pod-subpath-test-projected-nv8p": Phase="Running", Reason="", readiness=false. Elapsed: 18.141174759s
Dec  3 19:46:35.634: INFO: Pod "pod-subpath-test-projected-nv8p": Phase="Running", Reason="", readiness=false. Elapsed: 20.145507102s
Dec  3 19:46:37.639: INFO: Pod "pod-subpath-test-projected-nv8p": Phase="Running", Reason="", readiness=false. Elapsed: 22.149664829s
Dec  3 19:46:39.646: INFO: Pod "pod-subpath-test-projected-nv8p": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.157340246s
STEP: Saw pod success
Dec  3 19:46:39.646: INFO: Pod "pod-subpath-test-projected-nv8p" satisfied condition "success or failure"
Dec  3 19:46:39.662: INFO: Trying to get logs from node hungry-keller-3o9e pod pod-subpath-test-projected-nv8p container test-container-subpath-projected-nv8p: <nil>
STEP: delete the pod
Dec  3 19:46:39.689: INFO: Waiting for pod pod-subpath-test-projected-nv8p to disappear
Dec  3 19:46:39.693: INFO: Pod pod-subpath-test-projected-nv8p no longer exists
STEP: Deleting pod pod-subpath-test-projected-nv8p
Dec  3 19:46:39.693: INFO: Deleting pod "pod-subpath-test-projected-nv8p" in namespace "e2e-tests-subpath-4z7f4"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 19:46:39.695: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-4z7f4" for this suite.
Dec  3 19:46:45.710: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 19:46:45.768: INFO: namespace: e2e-tests-subpath-4z7f4, resource: bindings, ignored listing per whitelist
Dec  3 19:46:45.798: INFO: namespace e2e-tests-subpath-4z7f4 deletion completed in 6.099443036s

• [SLOW TEST:30.410 seconds]
[sig-storage] Subpath
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with projected pod [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 19:46:45.798: INFO: >>> kubeConfig: /tmp/kubeconfig-166913721
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-2a882dfb-f734-11e8-8d0a-02420af40402
STEP: Creating a pod to test consume secrets
Dec  3 19:46:45.883: INFO: Waiting up to 5m0s for pod "pod-secrets-2a88ebb6-f734-11e8-8d0a-02420af40402" in namespace "e2e-tests-secrets-r27rt" to be "success or failure"
Dec  3 19:46:45.899: INFO: Pod "pod-secrets-2a88ebb6-f734-11e8-8d0a-02420af40402": Phase="Pending", Reason="", readiness=false. Elapsed: 15.19623ms
Dec  3 19:46:47.903: INFO: Pod "pod-secrets-2a88ebb6-f734-11e8-8d0a-02420af40402": Phase="Pending", Reason="", readiness=false. Elapsed: 2.019069441s
Dec  3 19:46:49.907: INFO: Pod "pod-secrets-2a88ebb6-f734-11e8-8d0a-02420af40402": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.023032495s
STEP: Saw pod success
Dec  3 19:46:49.907: INFO: Pod "pod-secrets-2a88ebb6-f734-11e8-8d0a-02420af40402" satisfied condition "success or failure"
Dec  3 19:46:49.909: INFO: Trying to get logs from node hungry-keller-3o9a pod pod-secrets-2a88ebb6-f734-11e8-8d0a-02420af40402 container secret-volume-test: <nil>
STEP: delete the pod
Dec  3 19:46:49.930: INFO: Waiting for pod pod-secrets-2a88ebb6-f734-11e8-8d0a-02420af40402 to disappear
Dec  3 19:46:49.934: INFO: Pod pod-secrets-2a88ebb6-f734-11e8-8d0a-02420af40402 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 19:46:49.934: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-r27rt" for this suite.
Dec  3 19:46:55.948: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 19:46:56.015: INFO: namespace: e2e-tests-secrets-r27rt, resource: bindings, ignored listing per whitelist
Dec  3 19:46:56.047: INFO: namespace e2e-tests-secrets-r27rt deletion completed in 6.10948551s

• [SLOW TEST:10.249 seconds]
[sig-storage] Secrets
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 19:46:56.048: INFO: >>> kubeConfig: /tmp/kubeconfig-166913721
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name projected-secret-test-30a359a1-f734-11e8-8d0a-02420af40402
STEP: Creating a pod to test consume secrets
Dec  3 19:46:56.127: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-30a3f4db-f734-11e8-8d0a-02420af40402" in namespace "e2e-tests-projected-tm59z" to be "success or failure"
Dec  3 19:46:56.140: INFO: Pod "pod-projected-secrets-30a3f4db-f734-11e8-8d0a-02420af40402": Phase="Pending", Reason="", readiness=false. Elapsed: 12.605449ms
Dec  3 19:46:58.143: INFO: Pod "pod-projected-secrets-30a3f4db-f734-11e8-8d0a-02420af40402": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.015906969s
STEP: Saw pod success
Dec  3 19:46:58.144: INFO: Pod "pod-projected-secrets-30a3f4db-f734-11e8-8d0a-02420af40402" satisfied condition "success or failure"
Dec  3 19:46:58.146: INFO: Trying to get logs from node hungry-keller-3o9a pod pod-projected-secrets-30a3f4db-f734-11e8-8d0a-02420af40402 container secret-volume-test: <nil>
STEP: delete the pod
Dec  3 19:46:58.168: INFO: Waiting for pod pod-projected-secrets-30a3f4db-f734-11e8-8d0a-02420af40402 to disappear
Dec  3 19:46:58.172: INFO: Pod pod-projected-secrets-30a3f4db-f734-11e8-8d0a-02420af40402 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 19:46:58.172: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-tm59z" for this suite.
Dec  3 19:47:04.186: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 19:47:04.229: INFO: namespace: e2e-tests-projected-tm59z, resource: bindings, ignored listing per whitelist
Dec  3 19:47:04.273: INFO: namespace e2e-tests-projected-tm59z deletion completed in 6.096851133s

• [SLOW TEST:8.225 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl rolling-update 
  should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 19:47:04.273: INFO: >>> kubeConfig: /tmp/kubeconfig-166913721
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1306
[It] should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Dec  3 19:47:04.350: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-166913721 run e2e-test-nginx-rc --image=docker.io/library/nginx:1.14-alpine --generator=run/v1 --namespace=e2e-tests-kubectl-tbg49'
Dec  3 19:47:04.475: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl create instead.\n"
Dec  3 19:47:04.475: INFO: stdout: "replicationcontroller/e2e-test-nginx-rc created\n"
STEP: verifying the rc e2e-test-nginx-rc was created
Dec  3 19:47:04.512: INFO: Waiting for rc e2e-test-nginx-rc to stabilize, generation 1 observed generation 1 spec.replicas 1 status.replicas 0
STEP: rolling-update to same image controller
Dec  3 19:47:04.543: INFO: scanned /root for discovery docs: <nil>
Dec  3 19:47:04.543: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-166913721 rolling-update e2e-test-nginx-rc --update-period=1s --image=docker.io/library/nginx:1.14-alpine --image-pull-policy=IfNotPresent --namespace=e2e-tests-kubectl-tbg49'
Dec  3 19:47:20.571: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Dec  3 19:47:20.571: INFO: stdout: "Created e2e-test-nginx-rc-cf186648a5a1494c64c2ddf9e8ec8aba\nScaling up e2e-test-nginx-rc-cf186648a5a1494c64c2ddf9e8ec8aba from 0 to 1, scaling down e2e-test-nginx-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-nginx-rc-cf186648a5a1494c64c2ddf9e8ec8aba up to 1\nScaling e2e-test-nginx-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-nginx-rc\nRenaming e2e-test-nginx-rc-cf186648a5a1494c64c2ddf9e8ec8aba to e2e-test-nginx-rc\nreplicationcontroller/e2e-test-nginx-rc rolling updated\n"
Dec  3 19:47:20.571: INFO: stdout: "Created e2e-test-nginx-rc-cf186648a5a1494c64c2ddf9e8ec8aba\nScaling up e2e-test-nginx-rc-cf186648a5a1494c64c2ddf9e8ec8aba from 0 to 1, scaling down e2e-test-nginx-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-nginx-rc-cf186648a5a1494c64c2ddf9e8ec8aba up to 1\nScaling e2e-test-nginx-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-nginx-rc\nRenaming e2e-test-nginx-rc-cf186648a5a1494c64c2ddf9e8ec8aba to e2e-test-nginx-rc\nreplicationcontroller/e2e-test-nginx-rc rolling updated\n"
STEP: waiting for all containers in run=e2e-test-nginx-rc pods to come up.
Dec  3 19:47:20.571: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-166913721 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l run=e2e-test-nginx-rc --namespace=e2e-tests-kubectl-tbg49'
Dec  3 19:47:20.677: INFO: stderr: ""
Dec  3 19:47:20.677: INFO: stdout: "e2e-test-nginx-rc-cf186648a5a1494c64c2ddf9e8ec8aba-vrlp2 "
Dec  3 19:47:20.677: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-166913721 get pods e2e-test-nginx-rc-cf186648a5a1494c64c2ddf9e8ec8aba-vrlp2 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "e2e-test-nginx-rc") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-tbg49'
Dec  3 19:47:20.789: INFO: stderr: ""
Dec  3 19:47:20.789: INFO: stdout: "true"
Dec  3 19:47:20.789: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-166913721 get pods e2e-test-nginx-rc-cf186648a5a1494c64c2ddf9e8ec8aba-vrlp2 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "e2e-test-nginx-rc"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-tbg49'
Dec  3 19:47:20.905: INFO: stderr: ""
Dec  3 19:47:20.905: INFO: stdout: "nginx:1.14-alpine"
Dec  3 19:47:20.905: INFO: e2e-test-nginx-rc-cf186648a5a1494c64c2ddf9e8ec8aba-vrlp2 is verified up and running
[AfterEach] [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1312
Dec  3 19:47:20.905: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-166913721 delete rc e2e-test-nginx-rc --namespace=e2e-tests-kubectl-tbg49'
Dec  3 19:47:21.048: INFO: stderr: ""
Dec  3 19:47:21.048: INFO: stdout: "replicationcontroller \"e2e-test-nginx-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 19:47:21.048: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-tbg49" for this suite.
Dec  3 19:47:43.065: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 19:47:43.127: INFO: namespace: e2e-tests-kubectl-tbg49, resource: bindings, ignored listing per whitelist
Dec  3 19:47:43.163: INFO: namespace e2e-tests-kubectl-tbg49 deletion completed in 22.110880131s

• [SLOW TEST:38.890 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should support rolling-update to same image  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 19:47:43.164: INFO: >>> kubeConfig: /tmp/kubeconfig-166913721
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the pods
STEP: Gathering metrics
W1203 19:48:23.269486      19 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Dec  3 19:48:23.269: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 19:48:23.269: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-4pnvs" for this suite.
Dec  3 19:48:29.283: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 19:48:29.335: INFO: namespace: e2e-tests-gc-4pnvs, resource: bindings, ignored listing per whitelist
Dec  3 19:48:29.390: INFO: namespace e2e-tests-gc-4pnvs deletion completed in 6.118068297s

• [SLOW TEST:46.226 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 19:48:29.391: INFO: >>> kubeConfig: /tmp/kubeconfig-166913721
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with configmap pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-configmap-n4f7
STEP: Creating a pod to test atomic-volume-subpath
Dec  3 19:48:29.528: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-n4f7" in namespace "e2e-tests-subpath-jhgs7" to be "success or failure"
Dec  3 19:48:29.542: INFO: Pod "pod-subpath-test-configmap-n4f7": Phase="Pending", Reason="", readiness=false. Elapsed: 14.516281ms
Dec  3 19:48:31.546: INFO: Pod "pod-subpath-test-configmap-n4f7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.018338713s
Dec  3 19:48:33.550: INFO: Pod "pod-subpath-test-configmap-n4f7": Phase="Running", Reason="", readiness=false. Elapsed: 4.022027648s
Dec  3 19:48:35.554: INFO: Pod "pod-subpath-test-configmap-n4f7": Phase="Running", Reason="", readiness=false. Elapsed: 6.025682467s
Dec  3 19:48:37.562: INFO: Pod "pod-subpath-test-configmap-n4f7": Phase="Running", Reason="", readiness=false. Elapsed: 8.034068885s
Dec  3 19:48:39.566: INFO: Pod "pod-subpath-test-configmap-n4f7": Phase="Running", Reason="", readiness=false. Elapsed: 10.037761485s
Dec  3 19:48:41.569: INFO: Pod "pod-subpath-test-configmap-n4f7": Phase="Running", Reason="", readiness=false. Elapsed: 12.041400068s
Dec  3 19:48:43.574: INFO: Pod "pod-subpath-test-configmap-n4f7": Phase="Running", Reason="", readiness=false. Elapsed: 14.045878874s
Dec  3 19:48:45.577: INFO: Pod "pod-subpath-test-configmap-n4f7": Phase="Running", Reason="", readiness=false. Elapsed: 16.04951495s
Dec  3 19:48:47.582: INFO: Pod "pod-subpath-test-configmap-n4f7": Phase="Running", Reason="", readiness=false. Elapsed: 18.053675412s
Dec  3 19:48:49.590: INFO: Pod "pod-subpath-test-configmap-n4f7": Phase="Running", Reason="", readiness=false. Elapsed: 20.062314637s
Dec  3 19:48:51.594: INFO: Pod "pod-subpath-test-configmap-n4f7": Phase="Running", Reason="", readiness=false. Elapsed: 22.066308614s
Dec  3 19:48:53.598: INFO: Pod "pod-subpath-test-configmap-n4f7": Phase="Running", Reason="", readiness=false. Elapsed: 24.069987019s
Dec  3 19:48:55.602: INFO: Pod "pod-subpath-test-configmap-n4f7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 26.074388276s
STEP: Saw pod success
Dec  3 19:48:55.602: INFO: Pod "pod-subpath-test-configmap-n4f7" satisfied condition "success or failure"
Dec  3 19:48:55.605: INFO: Trying to get logs from node hungry-keller-3o9a pod pod-subpath-test-configmap-n4f7 container test-container-subpath-configmap-n4f7: <nil>
STEP: delete the pod
Dec  3 19:48:55.629: INFO: Waiting for pod pod-subpath-test-configmap-n4f7 to disappear
Dec  3 19:48:55.636: INFO: Pod pod-subpath-test-configmap-n4f7 no longer exists
STEP: Deleting pod pod-subpath-test-configmap-n4f7
Dec  3 19:48:55.636: INFO: Deleting pod "pod-subpath-test-configmap-n4f7" in namespace "e2e-tests-subpath-jhgs7"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 19:48:55.639: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-jhgs7" for this suite.
Dec  3 19:49:01.659: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 19:49:01.711: INFO: namespace: e2e-tests-subpath-jhgs7, resource: bindings, ignored listing per whitelist
Dec  3 19:49:01.753: INFO: namespace e2e-tests-subpath-jhgs7 deletion completed in 6.108821018s

• [SLOW TEST:32.362 seconds]
[sig-storage] Subpath
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with configmap pod [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 19:49:01.753: INFO: >>> kubeConfig: /tmp/kubeconfig-166913721
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0644 on node default medium
Dec  3 19:49:01.833: INFO: Waiting up to 5m0s for pod "pod-7b910c62-f734-11e8-8d0a-02420af40402" in namespace "e2e-tests-emptydir-mgx9x" to be "success or failure"
Dec  3 19:49:01.848: INFO: Pod "pod-7b910c62-f734-11e8-8d0a-02420af40402": Phase="Pending", Reason="", readiness=false. Elapsed: 14.32142ms
Dec  3 19:49:03.852: INFO: Pod "pod-7b910c62-f734-11e8-8d0a-02420af40402": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.018303805s
STEP: Saw pod success
Dec  3 19:49:03.852: INFO: Pod "pod-7b910c62-f734-11e8-8d0a-02420af40402" satisfied condition "success or failure"
Dec  3 19:49:03.854: INFO: Trying to get logs from node hungry-keller-3o9a pod pod-7b910c62-f734-11e8-8d0a-02420af40402 container test-container: <nil>
STEP: delete the pod
Dec  3 19:49:03.880: INFO: Waiting for pod pod-7b910c62-f734-11e8-8d0a-02420af40402 to disappear
Dec  3 19:49:03.884: INFO: Pod pod-7b910c62-f734-11e8-8d0a-02420af40402 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 19:49:03.884: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-mgx9x" for this suite.
Dec  3 19:49:09.933: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 19:49:09.968: INFO: namespace: e2e-tests-emptydir-mgx9x, resource: bindings, ignored listing per whitelist
Dec  3 19:49:10.029: INFO: namespace e2e-tests-emptydir-mgx9x deletion completed in 6.141859128s

• [SLOW TEST:8.276 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[k8s.io] Probing container 
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 19:49:10.030: INFO: >>> kubeConfig: /tmp/kubeconfig-166913721
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-exec in namespace e2e-tests-container-probe-j7qjv
Dec  3 19:49:14.118: INFO: Started pod liveness-exec in namespace e2e-tests-container-probe-j7qjv
STEP: checking the pod's current state and verifying that restartCount is present
Dec  3 19:49:14.121: INFO: Initial restart count of pod liveness-exec is 0
Dec  3 19:50:06.222: INFO: Restart count of pod e2e-tests-container-probe-j7qjv/liveness-exec is now 1 (52.101205092s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 19:50:06.233: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-j7qjv" for this suite.
Dec  3 19:50:12.248: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 19:50:12.268: INFO: namespace: e2e-tests-container-probe-j7qjv, resource: bindings, ignored listing per whitelist
Dec  3 19:50:12.339: INFO: namespace e2e-tests-container-probe-j7qjv deletion completed in 6.102038722s

• [SLOW TEST:62.310 seconds]
[k8s.io] Probing container
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 19:50:12.341: INFO: >>> kubeConfig: /tmp/kubeconfig-166913721
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:83
[It] should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating service multi-endpoint-test in namespace e2e-tests-services-hfszk
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-hfszk to expose endpoints map[]
Dec  3 19:50:12.446: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-hfszk exposes endpoints map[] (10.903733ms elapsed)
STEP: Creating pod pod1 in namespace e2e-tests-services-hfszk
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-hfszk to expose endpoints map[pod1:[100]]
Dec  3 19:50:15.516: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-hfszk exposes endpoints map[pod1:[100]] (3.057333039s elapsed)
STEP: Creating pod pod2 in namespace e2e-tests-services-hfszk
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-hfszk to expose endpoints map[pod1:[100] pod2:[101]]
Dec  3 19:50:17.561: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-hfszk exposes endpoints map[pod1:[100] pod2:[101]] (2.039656347s elapsed)
STEP: Deleting pod pod1 in namespace e2e-tests-services-hfszk
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-hfszk to expose endpoints map[pod2:[101]]
Dec  3 19:50:17.596: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-hfszk exposes endpoints map[pod2:[101]] (29.533008ms elapsed)
STEP: Deleting pod pod2 in namespace e2e-tests-services-hfszk
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-hfszk to expose endpoints map[]
Dec  3 19:50:17.612: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-hfszk exposes endpoints map[] (9.745471ms elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 19:50:17.638: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-services-hfszk" for this suite.
Dec  3 19:50:39.655: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 19:50:39.742: INFO: namespace: e2e-tests-services-hfszk, resource: bindings, ignored listing per whitelist
Dec  3 19:50:39.748: INFO: namespace e2e-tests-services-hfszk deletion completed in 22.106620411s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:88

• [SLOW TEST:27.408 seconds]
[sig-network] Services
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run deployment 
  should create a deployment from an image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 19:50:39.750: INFO: >>> kubeConfig: /tmp/kubeconfig-166913721
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Kubectl run deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1347
[It] should create a deployment from an image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Dec  3 19:50:39.817: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-166913721 run e2e-test-nginx-deployment --image=docker.io/library/nginx:1.14-alpine --generator=deployment/v1beta1 --namespace=e2e-tests-kubectl-8tt5x'
Dec  3 19:50:39.947: INFO: stderr: "kubectl run --generator=deployment/v1beta1 is DEPRECATED and will be removed in a future version. Use kubectl create instead.\n"
Dec  3 19:50:39.947: INFO: stdout: "deployment.extensions/e2e-test-nginx-deployment created\n"
STEP: verifying the deployment e2e-test-nginx-deployment was created
STEP: verifying the pod controlled by deployment e2e-test-nginx-deployment was created
[AfterEach] [k8s.io] Kubectl run deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1352
Dec  3 19:50:41.984: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-166913721 delete deployment e2e-test-nginx-deployment --namespace=e2e-tests-kubectl-8tt5x'
Dec  3 19:50:42.106: INFO: stderr: ""
Dec  3 19:50:42.106: INFO: stdout: "deployment.extensions \"e2e-test-nginx-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 19:50:42.106: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-8tt5x" for this suite.
Dec  3 19:50:48.130: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 19:50:48.183: INFO: namespace: e2e-tests-kubectl-8tt5x, resource: bindings, ignored listing per whitelist
Dec  3 19:50:48.227: INFO: namespace e2e-tests-kubectl-8tt5x deletion completed in 6.115072074s

• [SLOW TEST:8.478 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create a deployment from an image  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] Projected 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 19:50:48.227: INFO: >>> kubeConfig: /tmp/kubeconfig-166913721
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Dec  3 19:50:48.332: INFO: Waiting up to 5m0s for pod "downwardapi-volume-bb0b4f9a-f734-11e8-8d0a-02420af40402" in namespace "e2e-tests-projected-ntm85" to be "success or failure"
Dec  3 19:50:48.344: INFO: Pod "downwardapi-volume-bb0b4f9a-f734-11e8-8d0a-02420af40402": Phase="Pending", Reason="", readiness=false. Elapsed: 11.939167ms
Dec  3 19:50:50.348: INFO: Pod "downwardapi-volume-bb0b4f9a-f734-11e8-8d0a-02420af40402": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015878321s
Dec  3 19:50:52.352: INFO: Pod "downwardapi-volume-bb0b4f9a-f734-11e8-8d0a-02420af40402": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.019620612s
STEP: Saw pod success
Dec  3 19:50:52.352: INFO: Pod "downwardapi-volume-bb0b4f9a-f734-11e8-8d0a-02420af40402" satisfied condition "success or failure"
Dec  3 19:50:52.354: INFO: Trying to get logs from node hungry-keller-3o9a pod downwardapi-volume-bb0b4f9a-f734-11e8-8d0a-02420af40402 container client-container: <nil>
STEP: delete the pod
Dec  3 19:50:52.375: INFO: Waiting for pod downwardapi-volume-bb0b4f9a-f734-11e8-8d0a-02420af40402 to disappear
Dec  3 19:50:52.381: INFO: Pod downwardapi-volume-bb0b4f9a-f734-11e8-8d0a-02420af40402 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 19:50:52.381: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-ntm85" for this suite.
Dec  3 19:50:58.394: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 19:50:58.475: INFO: namespace: e2e-tests-projected-ntm85, resource: bindings, ignored listing per whitelist
Dec  3 19:50:58.495: INFO: namespace e2e-tests-projected-ntm85 deletion completed in 6.111202472s

• [SLOW TEST:10.268 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 19:50:58.496: INFO: >>> kubeConfig: /tmp/kubeconfig-166913721
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0666 on node default medium
Dec  3 19:50:58.581: INFO: Waiting up to 5m0s for pod "pod-c12712dc-f734-11e8-8d0a-02420af40402" in namespace "e2e-tests-emptydir-m8mj6" to be "success or failure"
Dec  3 19:50:58.593: INFO: Pod "pod-c12712dc-f734-11e8-8d0a-02420af40402": Phase="Pending", Reason="", readiness=false. Elapsed: 11.285846ms
Dec  3 19:51:00.596: INFO: Pod "pod-c12712dc-f734-11e8-8d0a-02420af40402": Phase="Running", Reason="", readiness=true. Elapsed: 2.014842499s
Dec  3 19:51:02.604: INFO: Pod "pod-c12712dc-f734-11e8-8d0a-02420af40402": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.022590511s
STEP: Saw pod success
Dec  3 19:51:02.604: INFO: Pod "pod-c12712dc-f734-11e8-8d0a-02420af40402" satisfied condition "success or failure"
Dec  3 19:51:02.607: INFO: Trying to get logs from node hungry-keller-3o9a pod pod-c12712dc-f734-11e8-8d0a-02420af40402 container test-container: <nil>
STEP: delete the pod
Dec  3 19:51:02.627: INFO: Waiting for pod pod-c12712dc-f734-11e8-8d0a-02420af40402 to disappear
Dec  3 19:51:02.632: INFO: Pod pod-c12712dc-f734-11e8-8d0a-02420af40402 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 19:51:02.632: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-m8mj6" for this suite.
Dec  3 19:51:08.645: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 19:51:08.671: INFO: namespace: e2e-tests-emptydir-m8mj6, resource: bindings, ignored listing per whitelist
Dec  3 19:51:08.741: INFO: namespace e2e-tests-emptydir-m8mj6 deletion completed in 6.10555857s

• [SLOW TEST:10.246 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 19:51:08.742: INFO: >>> kubeConfig: /tmp/kubeconfig-166913721
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Dec  3 19:51:08.834: INFO: Waiting up to 5m0s for pod "downwardapi-volume-c740dd0b-f734-11e8-8d0a-02420af40402" in namespace "e2e-tests-downward-api-xtpm5" to be "success or failure"
Dec  3 19:51:08.843: INFO: Pod "downwardapi-volume-c740dd0b-f734-11e8-8d0a-02420af40402": Phase="Pending", Reason="", readiness=false. Elapsed: 8.561044ms
Dec  3 19:51:10.847: INFO: Pod "downwardapi-volume-c740dd0b-f734-11e8-8d0a-02420af40402": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012219743s
Dec  3 19:51:12.850: INFO: Pod "downwardapi-volume-c740dd0b-f734-11e8-8d0a-02420af40402": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.015851157s
STEP: Saw pod success
Dec  3 19:51:12.850: INFO: Pod "downwardapi-volume-c740dd0b-f734-11e8-8d0a-02420af40402" satisfied condition "success or failure"
Dec  3 19:51:12.854: INFO: Trying to get logs from node hungry-keller-3o9a pod downwardapi-volume-c740dd0b-f734-11e8-8d0a-02420af40402 container client-container: <nil>
STEP: delete the pod
Dec  3 19:51:12.877: INFO: Waiting for pod downwardapi-volume-c740dd0b-f734-11e8-8d0a-02420af40402 to disappear
Dec  3 19:51:12.879: INFO: Pod downwardapi-volume-c740dd0b-f734-11e8-8d0a-02420af40402 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 19:51:12.880: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-xtpm5" for this suite.
Dec  3 19:51:18.894: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 19:51:18.969: INFO: namespace: e2e-tests-downward-api-xtpm5, resource: bindings, ignored listing per whitelist
Dec  3 19:51:18.978: INFO: namespace e2e-tests-downward-api-xtpm5 deletion completed in 6.094854372s

• [SLOW TEST:10.236 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] Secrets 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 19:51:18.979: INFO: >>> kubeConfig: /tmp/kubeconfig-166913721
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-cd5aa317-f734-11e8-8d0a-02420af40402
STEP: Creating a pod to test consume secrets
Dec  3 19:51:19.052: INFO: Waiting up to 5m0s for pod "pod-secrets-cd5b1a83-f734-11e8-8d0a-02420af40402" in namespace "e2e-tests-secrets-c5d4c" to be "success or failure"
Dec  3 19:51:19.062: INFO: Pod "pod-secrets-cd5b1a83-f734-11e8-8d0a-02420af40402": Phase="Pending", Reason="", readiness=false. Elapsed: 9.861797ms
Dec  3 19:51:21.065: INFO: Pod "pod-secrets-cd5b1a83-f734-11e8-8d0a-02420af40402": Phase="Running", Reason="", readiness=true. Elapsed: 2.013624902s
Dec  3 19:51:23.070: INFO: Pod "pod-secrets-cd5b1a83-f734-11e8-8d0a-02420af40402": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.018069966s
STEP: Saw pod success
Dec  3 19:51:23.070: INFO: Pod "pod-secrets-cd5b1a83-f734-11e8-8d0a-02420af40402" satisfied condition "success or failure"
Dec  3 19:51:23.073: INFO: Trying to get logs from node hungry-keller-3o9a pod pod-secrets-cd5b1a83-f734-11e8-8d0a-02420af40402 container secret-volume-test: <nil>
STEP: delete the pod
Dec  3 19:51:23.095: INFO: Waiting for pod pod-secrets-cd5b1a83-f734-11e8-8d0a-02420af40402 to disappear
Dec  3 19:51:23.100: INFO: Pod pod-secrets-cd5b1a83-f734-11e8-8d0a-02420af40402 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 19:51:23.100: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-c5d4c" for this suite.
Dec  3 19:51:29.116: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 19:51:29.157: INFO: namespace: e2e-tests-secrets-c5d4c, resource: bindings, ignored listing per whitelist
Dec  3 19:51:29.198: INFO: namespace e2e-tests-secrets-c5d4c deletion completed in 6.09377539s

• [SLOW TEST:10.219 seconds]
[sig-storage] Secrets
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 19:51:29.198: INFO: >>> kubeConfig: /tmp/kubeconfig-166913721
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-map-d38bd6cc-f734-11e8-8d0a-02420af40402
STEP: Creating a pod to test consume secrets
Dec  3 19:51:29.442: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-d38c69a6-f734-11e8-8d0a-02420af40402" in namespace "e2e-tests-projected-wjz5t" to be "success or failure"
Dec  3 19:51:29.453: INFO: Pod "pod-projected-secrets-d38c69a6-f734-11e8-8d0a-02420af40402": Phase="Pending", Reason="", readiness=false. Elapsed: 11.720831ms
Dec  3 19:51:31.457: INFO: Pod "pod-projected-secrets-d38c69a6-f734-11e8-8d0a-02420af40402": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015409431s
Dec  3 19:51:33.461: INFO: Pod "pod-projected-secrets-d38c69a6-f734-11e8-8d0a-02420af40402": Phase="Pending", Reason="", readiness=false. Elapsed: 4.018901879s
Dec  3 19:51:35.464: INFO: Pod "pod-projected-secrets-d38c69a6-f734-11e8-8d0a-02420af40402": Phase="Pending", Reason="", readiness=false. Elapsed: 6.022426253s
Dec  3 19:51:37.467: INFO: Pod "pod-projected-secrets-d38c69a6-f734-11e8-8d0a-02420af40402": Phase="Pending", Reason="", readiness=false. Elapsed: 8.0257286s
Dec  3 19:51:39.471: INFO: Pod "pod-projected-secrets-d38c69a6-f734-11e8-8d0a-02420af40402": Phase="Succeeded", Reason="", readiness=false. Elapsed: 10.029184853s
STEP: Saw pod success
Dec  3 19:51:39.471: INFO: Pod "pod-projected-secrets-d38c69a6-f734-11e8-8d0a-02420af40402" satisfied condition "success or failure"
Dec  3 19:51:39.473: INFO: Trying to get logs from node hungry-keller-3o9a pod pod-projected-secrets-d38c69a6-f734-11e8-8d0a-02420af40402 container projected-secret-volume-test: <nil>
STEP: delete the pod
Dec  3 19:51:39.498: INFO: Waiting for pod pod-projected-secrets-d38c69a6-f734-11e8-8d0a-02420af40402 to disappear
Dec  3 19:51:39.503: INFO: Pod pod-projected-secrets-d38c69a6-f734-11e8-8d0a-02420af40402 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 19:51:39.503: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-wjz5t" for this suite.
Dec  3 19:51:45.518: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 19:51:45.537: INFO: namespace: e2e-tests-projected-wjz5t, resource: bindings, ignored listing per whitelist
Dec  3 19:51:45.618: INFO: namespace e2e-tests-projected-wjz5t deletion completed in 6.112227898s

• [SLOW TEST:16.421 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 19:51:45.619: INFO: >>> kubeConfig: /tmp/kubeconfig-166913721
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Dec  3 19:51:45.699: INFO: Creating deployment "test-recreate-deployment"
Dec  3 19:51:45.705: INFO: Waiting deployment "test-recreate-deployment" to be updated to revision 1
Dec  3 19:51:45.755: INFO: deployment "test-recreate-deployment" doesn't have the required revision set
Dec  3 19:51:47.763: INFO: Waiting deployment "test-recreate-deployment" to complete
Dec  3 19:51:47.766: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63679463505, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63679463505, loc:(*time.Location)(0x6c43b60)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63679463505, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63679463505, loc:(*time.Location)(0x6c43b60)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-recreate-deployment-79f694ff59\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec  3 19:51:49.769: INFO: Triggering a new rollout for deployment "test-recreate-deployment"
Dec  3 19:51:49.778: INFO: Updating deployment test-recreate-deployment
Dec  3 19:51:49.779: INFO: Watching deployment "test-recreate-deployment" to verify that new pods will not run with olds pods
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Dec  3 19:51:49.876: INFO: Deployment "test-recreate-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment,GenerateName:,Namespace:e2e-tests-deployment-crlnx,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-crlnx/deployments/test-recreate-deployment,UID:dd3ea75e-f734-11e8-8af3-a28d93e01224,ResourceVersion:5132,Generation:2,CreationTimestamp:2018-12-03 19:51:45 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},Strategy:DeploymentStrategy{Type:Recreate,RollingUpdate:nil,},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:0,UnavailableReplicas:1,Conditions:[{Available False 2018-12-03 19:51:49 +0000 UTC 2018-12-03 19:51:49 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.} {Progressing True 2018-12-03 19:51:49 +0000 UTC 2018-12-03 19:51:45 +0000 UTC ReplicaSetUpdated ReplicaSet "test-recreate-deployment-7cf749666b" is progressing.}],ReadyReplicas:0,CollisionCount:nil,},}

Dec  3 19:51:49.880: INFO: New ReplicaSet "test-recreate-deployment-7cf749666b" of Deployment "test-recreate-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-7cf749666b,GenerateName:,Namespace:e2e-tests-deployment-crlnx,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-crlnx/replicasets/test-recreate-deployment-7cf749666b,UID:dfb31995-f734-11e8-8af3-a28d93e01224,ResourceVersion:5130,Generation:1,CreationTimestamp:2018-12-03 19:51:49 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 7cf749666b,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 1,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment test-recreate-deployment dd3ea75e-f734-11e8-8af3-a28d93e01224 0xc4224d1c37 0xc4224d1c38}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 7cf749666b,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 7cf749666b,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Dec  3 19:51:49.880: INFO: All old ReplicaSets of Deployment "test-recreate-deployment":
Dec  3 19:51:49.880: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-79f694ff59,GenerateName:,Namespace:e2e-tests-deployment-crlnx,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-crlnx/replicasets/test-recreate-deployment-79f694ff59,UID:dd3f74f4-f734-11e8-8af3-a28d93e01224,ResourceVersion:5121,Generation:2,CreationTimestamp:2018-12-03 19:51:45 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 79f694ff59,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 1,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-recreate-deployment dd3ea75e-f734-11e8-8af3-a28d93e01224 0xc4224d1b87 0xc4224d1b88}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 79f694ff59,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 79f694ff59,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Dec  3 19:51:49.883: INFO: Pod "test-recreate-deployment-7cf749666b-d7ztt" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-7cf749666b-d7ztt,GenerateName:test-recreate-deployment-7cf749666b-,Namespace:e2e-tests-deployment-crlnx,SelfLink:/api/v1/namespaces/e2e-tests-deployment-crlnx/pods/test-recreate-deployment-7cf749666b-d7ztt,UID:dfb466ac-f734-11e8-8af3-a28d93e01224,ResourceVersion:5133,Generation:0,CreationTimestamp:2018-12-03 19:51:49 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 7cf749666b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet test-recreate-deployment-7cf749666b dfb31995-f734-11e8-8af3-a28d93e01224 0xc421e0f257 0xc421e0f258}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-tzbw9 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-tzbw9,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-tzbw9 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:hungry-keller-3o9a,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc421e0f2c0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421e0f2e0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-03 19:51:49 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-03 19:51:49 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-03 19:51:49 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-03 19:51:49 +0000 UTC  }],Message:,Reason:,HostIP:10.136.91.235,PodIP:,StartTime:2018-12-03 19:51:49 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 19:51:49.883: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-crlnx" for this suite.
Dec  3 19:51:55.898: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 19:51:55.926: INFO: namespace: e2e-tests-deployment-crlnx, resource: bindings, ignored listing per whitelist
Dec  3 19:51:56.001: INFO: namespace e2e-tests-deployment-crlnx deletion completed in 6.112772931s

• [SLOW TEST:10.382 seconds]
[sig-apps] Deployment
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] version v1
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 19:51:56.002: INFO: >>> kubeConfig: /tmp/kubeconfig-166913721
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: starting an echo server on multiple ports
STEP: creating replication controller proxy-service-2ppp2 in namespace e2e-tests-proxy-pgqn9
I1203 19:51:56.156350      19 runners.go:180] Created replication controller with name: proxy-service-2ppp2, namespace: e2e-tests-proxy-pgqn9, replica count: 1
I1203 19:51:57.206770      19 runners.go:180] proxy-service-2ppp2 Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1203 19:51:58.206957      19 runners.go:180] proxy-service-2ppp2 Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1203 19:51:59.207161      19 runners.go:180] proxy-service-2ppp2 Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1203 19:52:00.207482      19 runners.go:180] proxy-service-2ppp2 Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1203 19:52:01.207694      19 runners.go:180] proxy-service-2ppp2 Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1203 19:52:02.207910      19 runners.go:180] proxy-service-2ppp2 Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I1203 19:52:03.208151      19 runners.go:180] proxy-service-2ppp2 Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I1203 19:52:04.208396      19 runners.go:180] proxy-service-2ppp2 Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I1203 19:52:05.208657      19 runners.go:180] proxy-service-2ppp2 Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Dec  3 19:52:05.211: INFO: setup took 9.093811744s, starting test cases
STEP: running 16 cases, 20 attempts per case, 320 total attempts
Dec  3 19:52:05.236: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-pgqn9/pods/http:proxy-service-2ppp2-d42rk:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-pgqn9/pods/http:proxy-service-2ppp2-d42rk:1080/proxy/... (200; 24.722837ms)
Dec  3 19:52:05.238: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-pgqn9/pods/proxy-service-2ppp2-d42rk/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-pgqn9/pods/proxy-service-2ppp2-d42rk/proxy/rewriteme"... (200; 26.141381ms)
Dec  3 19:52:05.238: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-pgqn9/services/proxy-service-2ppp2:portname2/proxy/: bar (200; 26.500549ms)
Dec  3 19:52:05.238: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-pgqn9/pods/http:proxy-service-2ppp2-d42rk:162/proxy/: bar (200; 26.690338ms)
Dec  3 19:52:05.242: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-pgqn9/pods/proxy-service-2ppp2-d42rk:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-pgqn9/pods/proxy-service-2ppp2-d42rk:1080/proxy/rewri... (200; 30.54028ms)
Dec  3 19:52:05.243: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-pgqn9/pods/proxy-service-2ppp2-d42rk:160/proxy/: foo (200; 30.883059ms)
Dec  3 19:52:05.244: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-pgqn9/pods/proxy-service-2ppp2-d42rk:162/proxy/: bar (200; 32.188666ms)
Dec  3 19:52:05.244: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-pgqn9/services/http:proxy-service-2ppp2:portname2/proxy/: bar (200; 32.515898ms)
Dec  3 19:52:05.246: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-pgqn9/services/http:proxy-service-2ppp2:portname1/proxy/: foo (200; 34.397038ms)
Dec  3 19:52:05.246: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-pgqn9/pods/http:proxy-service-2ppp2-d42rk:160/proxy/: foo (200; 34.538673ms)
Dec  3 19:52:05.246: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-pgqn9/services/proxy-service-2ppp2:portname1/proxy/: foo (200; 34.514132ms)
Dec  3 19:52:05.247: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-pgqn9/pods/https:proxy-service-2ppp2-d42rk:462/proxy/: tls qux (200; 34.961719ms)
Dec  3 19:52:05.248: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-pgqn9/services/https:proxy-service-2ppp2:tlsportname2/proxy/: tls qux (200; 35.699068ms)
Dec  3 19:52:05.248: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-pgqn9/pods/https:proxy-service-2ppp2-d42rk:460/proxy/: tls baz (200; 36.68536ms)
Dec  3 19:52:05.251: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-pgqn9/pods/https:proxy-service-2ppp2-d42rk:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-pgqn9/pods/https:proxy-service-2ppp2-d42rk:443/proxy/... (200; 38.69046ms)
Dec  3 19:52:05.251: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-pgqn9/services/https:proxy-service-2ppp2:tlsportname1/proxy/: tls baz (200; 39.210726ms)
Dec  3 19:52:05.269: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-pgqn9/pods/https:proxy-service-2ppp2-d42rk:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-pgqn9/pods/https:proxy-service-2ppp2-d42rk:443/proxy/... (200; 18.204455ms)
Dec  3 19:52:05.273: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-pgqn9/pods/proxy-service-2ppp2-d42rk:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-pgqn9/pods/proxy-service-2ppp2-d42rk:1080/proxy/rewri... (200; 21.545079ms)
Dec  3 19:52:05.274: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-pgqn9/pods/https:proxy-service-2ppp2-d42rk:460/proxy/: tls baz (200; 23.249413ms)
Dec  3 19:52:05.276: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-pgqn9/services/proxy-service-2ppp2:portname2/proxy/: bar (200; 23.845669ms)
Dec  3 19:52:05.276: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-pgqn9/pods/http:proxy-service-2ppp2-d42rk:160/proxy/: foo (200; 24.294324ms)
Dec  3 19:52:05.276: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-pgqn9/pods/proxy-service-2ppp2-d42rk:162/proxy/: bar (200; 24.244915ms)
Dec  3 19:52:05.276: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-pgqn9/services/proxy-service-2ppp2:portname1/proxy/: foo (200; 24.834036ms)
Dec  3 19:52:05.276: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-pgqn9/services/http:proxy-service-2ppp2:portname1/proxy/: foo (200; 24.199849ms)
Dec  3 19:52:05.276: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-pgqn9/services/http:proxy-service-2ppp2:portname2/proxy/: bar (200; 24.760198ms)
Dec  3 19:52:05.278: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-pgqn9/services/https:proxy-service-2ppp2:tlsportname1/proxy/: tls baz (200; 26.976469ms)
Dec  3 19:52:05.281: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-pgqn9/pods/proxy-service-2ppp2-d42rk/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-pgqn9/pods/proxy-service-2ppp2-d42rk/proxy/rewriteme"... (200; 28.915072ms)
Dec  3 19:52:05.281: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-pgqn9/pods/http:proxy-service-2ppp2-d42rk:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-pgqn9/pods/http:proxy-service-2ppp2-d42rk:1080/proxy/... (200; 28.889359ms)
Dec  3 19:52:05.281: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-pgqn9/services/https:proxy-service-2ppp2:tlsportname2/proxy/: tls qux (200; 29.732296ms)
Dec  3 19:52:05.281: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-pgqn9/pods/https:proxy-service-2ppp2-d42rk:462/proxy/: tls qux (200; 29.175507ms)
Dec  3 19:52:05.281: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-pgqn9/pods/http:proxy-service-2ppp2-d42rk:162/proxy/: bar (200; 29.550744ms)
Dec  3 19:52:05.281: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-pgqn9/pods/proxy-service-2ppp2-d42rk:160/proxy/: foo (200; 29.63684ms)
Dec  3 19:52:05.300: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-pgqn9/pods/proxy-service-2ppp2-d42rk/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-pgqn9/pods/proxy-service-2ppp2-d42rk/proxy/rewriteme"... (200; 18.907667ms)
Dec  3 19:52:05.300: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-pgqn9/pods/https:proxy-service-2ppp2-d42rk:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-pgqn9/pods/https:proxy-service-2ppp2-d42rk:443/proxy/... (200; 18.669818ms)
Dec  3 19:52:05.302: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-pgqn9/services/https:proxy-service-2ppp2:tlsportname2/proxy/: tls qux (200; 20.3172ms)
Dec  3 19:52:05.305: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-pgqn9/pods/http:proxy-service-2ppp2-d42rk:160/proxy/: foo (200; 23.024083ms)
Dec  3 19:52:05.306: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-pgqn9/pods/https:proxy-service-2ppp2-d42rk:460/proxy/: tls baz (200; 24.440863ms)
Dec  3 19:52:05.307: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-pgqn9/pods/http:proxy-service-2ppp2-d42rk:162/proxy/: bar (200; 25.16092ms)
Dec  3 19:52:05.307: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-pgqn9/services/http:proxy-service-2ppp2:portname1/proxy/: foo (200; 24.487148ms)
Dec  3 19:52:05.307: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-pgqn9/pods/proxy-service-2ppp2-d42rk:162/proxy/: bar (200; 25.609335ms)
Dec  3 19:52:05.308: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-pgqn9/services/http:proxy-service-2ppp2:portname2/proxy/: bar (200; 25.85544ms)
Dec  3 19:52:05.309: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-pgqn9/pods/proxy-service-2ppp2-d42rk:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-pgqn9/pods/proxy-service-2ppp2-d42rk:1080/proxy/rewri... (200; 27.053412ms)
Dec  3 19:52:05.310: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-pgqn9/services/https:proxy-service-2ppp2:tlsportname1/proxy/: tls baz (200; 27.495632ms)
Dec  3 19:52:05.310: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-pgqn9/pods/http:proxy-service-2ppp2-d42rk:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-pgqn9/pods/http:proxy-service-2ppp2-d42rk:1080/proxy/... (200; 27.015188ms)
Dec  3 19:52:05.310: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-pgqn9/pods/https:proxy-service-2ppp2-d42rk:462/proxy/: tls qux (200; 26.955941ms)
Dec  3 19:52:05.310: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-pgqn9/services/proxy-service-2ppp2:portname1/proxy/: foo (200; 26.882424ms)
Dec  3 19:52:05.310: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-pgqn9/pods/proxy-service-2ppp2-d42rk:160/proxy/: foo (200; 27.415227ms)
Dec  3 19:52:05.310: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-pgqn9/services/proxy-service-2ppp2:portname2/proxy/: bar (200; 27.915488ms)
Dec  3 19:52:05.337: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-pgqn9/pods/proxy-service-2ppp2-d42rk/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-pgqn9/pods/proxy-service-2ppp2-d42rk/proxy/rewriteme"... (200; 25.239727ms)
Dec  3 19:52:05.337: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-pgqn9/pods/http:proxy-service-2ppp2-d42rk:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-pgqn9/pods/http:proxy-service-2ppp2-d42rk:1080/proxy/... (200; 25.223074ms)
Dec  3 19:52:05.337: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-pgqn9/pods/proxy-service-2ppp2-d42rk:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-pgqn9/pods/proxy-service-2ppp2-d42rk:1080/proxy/rewri... (200; 25.393521ms)
Dec  3 19:52:05.337: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-pgqn9/pods/https:proxy-service-2ppp2-d42rk:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-pgqn9/pods/https:proxy-service-2ppp2-d42rk:443/proxy/... (200; 26.617425ms)
Dec  3 19:52:05.337: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-pgqn9/services/https:proxy-service-2ppp2:tlsportname1/proxy/: tls baz (200; 26.247419ms)
Dec  3 19:52:05.337: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-pgqn9/services/https:proxy-service-2ppp2:tlsportname2/proxy/: tls qux (200; 26.892168ms)
Dec  3 19:52:05.338: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-pgqn9/pods/http:proxy-service-2ppp2-d42rk:162/proxy/: bar (200; 26.969965ms)
Dec  3 19:52:05.338: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-pgqn9/pods/http:proxy-service-2ppp2-d42rk:160/proxy/: foo (200; 27.440808ms)
Dec  3 19:52:05.338: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-pgqn9/services/http:proxy-service-2ppp2:portname1/proxy/: foo (200; 27.946227ms)
Dec  3 19:52:05.338: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-pgqn9/pods/proxy-service-2ppp2-d42rk:162/proxy/: bar (200; 27.359103ms)
Dec  3 19:52:05.338: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-pgqn9/pods/https:proxy-service-2ppp2-d42rk:460/proxy/: tls baz (200; 27.83682ms)
Dec  3 19:52:05.338: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-pgqn9/pods/https:proxy-service-2ppp2-d42rk:462/proxy/: tls qux (200; 26.692558ms)
Dec  3 19:52:05.339: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-pgqn9/pods/proxy-service-2ppp2-d42rk:160/proxy/: foo (200; 27.710916ms)
Dec  3 19:52:05.339: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-pgqn9/services/proxy-service-2ppp2:portname2/proxy/: bar (200; 27.754217ms)
Dec  3 19:52:05.339: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-pgqn9/services/proxy-service-2ppp2:portname1/proxy/: foo (200; 27.771288ms)
Dec  3 19:52:05.340: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-pgqn9/services/http:proxy-service-2ppp2:portname2/proxy/: bar (200; 28.867421ms)
Dec  3 19:52:05.362: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-pgqn9/pods/proxy-service-2ppp2-d42rk:162/proxy/: bar (200; 22.28786ms)
Dec  3 19:52:05.362: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-pgqn9/pods/https:proxy-service-2ppp2-d42rk:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-pgqn9/pods/https:proxy-service-2ppp2-d42rk:443/proxy/... (200; 22.048354ms)
Dec  3 19:52:05.363: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-pgqn9/pods/http:proxy-service-2ppp2-d42rk:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-pgqn9/pods/http:proxy-service-2ppp2-d42rk:1080/proxy/... (200; 23.208786ms)
Dec  3 19:52:05.364: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-pgqn9/services/http:proxy-service-2ppp2:portname2/proxy/: bar (200; 24.091491ms)
Dec  3 19:52:05.364: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-pgqn9/pods/http:proxy-service-2ppp2-d42rk:160/proxy/: foo (200; 24.03161ms)
Dec  3 19:52:05.365: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-pgqn9/services/proxy-service-2ppp2:portname1/proxy/: foo (200; 24.433477ms)
Dec  3 19:52:05.366: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-pgqn9/pods/proxy-service-2ppp2-d42rk:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-pgqn9/pods/proxy-service-2ppp2-d42rk:1080/proxy/rewri... (200; 26.04949ms)
Dec  3 19:52:05.366: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-pgqn9/services/https:proxy-service-2ppp2:tlsportname2/proxy/: tls qux (200; 26.460691ms)
Dec  3 19:52:05.367: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-pgqn9/services/https:proxy-service-2ppp2:tlsportname1/proxy/: tls baz (200; 26.484132ms)
Dec  3 19:52:05.367: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-pgqn9/pods/proxy-service-2ppp2-d42rk/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-pgqn9/pods/proxy-service-2ppp2-d42rk/proxy/rewriteme"... (200; 26.314903ms)
Dec  3 19:52:05.367: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-pgqn9/pods/proxy-service-2ppp2-d42rk:160/proxy/: foo (200; 26.811272ms)
Dec  3 19:52:05.367: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-pgqn9/pods/https:proxy-service-2ppp2-d42rk:462/proxy/: tls qux (200; 26.989631ms)
Dec  3 19:52:05.367: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-pgqn9/pods/https:proxy-service-2ppp2-d42rk:460/proxy/: tls baz (200; 26.798539ms)
Dec  3 19:52:05.367: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-pgqn9/pods/http:proxy-service-2ppp2-d42rk:162/proxy/: bar (200; 27.003592ms)
Dec  3 19:52:05.367: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-pgqn9/services/http:proxy-service-2ppp2:portname1/proxy/: foo (200; 27.219623ms)
Dec  3 19:52:05.368: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-pgqn9/services/proxy-service-2ppp2:portname2/proxy/: bar (200; 27.576919ms)
Dec  3 19:52:05.386: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-pgqn9/pods/https:proxy-service-2ppp2-d42rk:460/proxy/: tls baz (200; 17.910355ms)
Dec  3 19:52:05.386: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-pgqn9/pods/https:proxy-service-2ppp2-d42rk:462/proxy/: tls qux (200; 18.029672ms)
Dec  3 19:52:05.390: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-pgqn9/services/proxy-service-2ppp2:portname2/proxy/: bar (200; 22.615494ms)
Dec  3 19:52:05.390: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-pgqn9/pods/https:proxy-service-2ppp2-d42rk:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-pgqn9/pods/https:proxy-service-2ppp2-d42rk:443/proxy/... (200; 22.589463ms)
Dec  3 19:52:05.392: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-pgqn9/pods/http:proxy-service-2ppp2-d42rk:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-pgqn9/pods/http:proxy-service-2ppp2-d42rk:1080/proxy/... (200; 24.388215ms)
Dec  3 19:52:05.393: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-pgqn9/pods/proxy-service-2ppp2-d42rk/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-pgqn9/pods/proxy-service-2ppp2-d42rk/proxy/rewriteme"... (200; 24.730285ms)
Dec  3 19:52:05.393: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-pgqn9/pods/proxy-service-2ppp2-d42rk:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-pgqn9/pods/proxy-service-2ppp2-d42rk:1080/proxy/rewri... (200; 24.757561ms)
Dec  3 19:52:05.394: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-pgqn9/pods/http:proxy-service-2ppp2-d42rk:162/proxy/: bar (200; 25.780757ms)
Dec  3 19:52:05.394: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-pgqn9/pods/proxy-service-2ppp2-d42rk:162/proxy/: bar (200; 25.873864ms)
Dec  3 19:52:05.394: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-pgqn9/pods/http:proxy-service-2ppp2-d42rk:160/proxy/: foo (200; 25.904868ms)
Dec  3 19:52:05.394: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-pgqn9/pods/proxy-service-2ppp2-d42rk:160/proxy/: foo (200; 25.895407ms)
Dec  3 19:52:05.394: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-pgqn9/services/https:proxy-service-2ppp2:tlsportname2/proxy/: tls qux (200; 26.146367ms)
Dec  3 19:52:05.395: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-pgqn9/services/proxy-service-2ppp2:portname1/proxy/: foo (200; 26.673939ms)
Dec  3 19:52:05.395: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-pgqn9/services/http:proxy-service-2ppp2:portname1/proxy/: foo (200; 26.634229ms)
Dec  3 19:52:05.395: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-pgqn9/services/http:proxy-service-2ppp2:portname2/proxy/: bar (200; 27.021648ms)
Dec  3 19:52:05.395: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-pgqn9/services/https:proxy-service-2ppp2:tlsportname1/proxy/: tls baz (200; 27.339448ms)
Dec  3 19:52:05.420: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-pgqn9/pods/proxy-service-2ppp2-d42rk:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-pgqn9/pods/proxy-service-2ppp2-d42rk:1080/proxy/rewri... (200; 24.499568ms)
Dec  3 19:52:05.420: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-pgqn9/pods/https:proxy-service-2ppp2-d42rk:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-pgqn9/pods/https:proxy-service-2ppp2-d42rk:443/proxy/... (200; 24.576174ms)
Dec  3 19:52:05.420: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-pgqn9/pods/http:proxy-service-2ppp2-d42rk:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-pgqn9/pods/http:proxy-service-2ppp2-d42rk:1080/proxy/... (200; 24.799076ms)
Dec  3 19:52:05.420: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-pgqn9/pods/proxy-service-2ppp2-d42rk/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-pgqn9/pods/proxy-service-2ppp2-d42rk/proxy/rewriteme"... (200; 24.808559ms)
Dec  3 19:52:05.420: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-pgqn9/pods/https:proxy-service-2ppp2-d42rk:460/proxy/: tls baz (200; 24.914443ms)
Dec  3 19:52:05.420: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-pgqn9/pods/https:proxy-service-2ppp2-d42rk:462/proxy/: tls qux (200; 24.871256ms)
Dec  3 19:52:05.422: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-pgqn9/services/http:proxy-service-2ppp2:portname1/proxy/: foo (200; 26.380638ms)
Dec  3 19:52:05.422: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-pgqn9/pods/http:proxy-service-2ppp2-d42rk:162/proxy/: bar (200; 26.203014ms)
Dec  3 19:52:05.422: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-pgqn9/pods/proxy-service-2ppp2-d42rk:162/proxy/: bar (200; 26.315071ms)
Dec  3 19:52:05.422: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-pgqn9/pods/proxy-service-2ppp2-d42rk:160/proxy/: foo (200; 26.25454ms)
Dec  3 19:52:05.422: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-pgqn9/services/proxy-service-2ppp2:portname2/proxy/: bar (200; 26.874705ms)
Dec  3 19:52:05.422: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-pgqn9/pods/http:proxy-service-2ppp2-d42rk:160/proxy/: foo (200; 27.10674ms)
Dec  3 19:52:05.423: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-pgqn9/services/https:proxy-service-2ppp2:tlsportname2/proxy/: tls qux (200; 27.310138ms)
Dec  3 19:52:05.423: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-pgqn9/services/https:proxy-service-2ppp2:tlsportname1/proxy/: tls baz (200; 28.179467ms)
Dec  3 19:52:05.424: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-pgqn9/services/proxy-service-2ppp2:portname1/proxy/: foo (200; 28.429527ms)
Dec  3 19:52:05.424: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-pgqn9/services/http:proxy-service-2ppp2:portname2/proxy/: bar (200; 28.249727ms)
Dec  3 19:52:05.440: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-pgqn9/pods/https:proxy-service-2ppp2-d42rk:460/proxy/: tls baz (200; 15.914429ms)
Dec  3 19:52:05.443: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-pgqn9/pods/http:proxy-service-2ppp2-d42rk:162/proxy/: bar (200; 19.317555ms)
Dec  3 19:52:05.443: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-pgqn9/pods/https:proxy-service-2ppp2-d42rk:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-pgqn9/pods/https:proxy-service-2ppp2-d42rk:443/proxy/... (200; 19.413003ms)
Dec  3 19:52:05.445: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-pgqn9/pods/https:proxy-service-2ppp2-d42rk:462/proxy/: tls qux (200; 21.375235ms)
Dec  3 19:52:05.445: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-pgqn9/services/https:proxy-service-2ppp2:tlsportname1/proxy/: tls baz (200; 21.65218ms)
Dec  3 19:52:05.446: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-pgqn9/pods/http:proxy-service-2ppp2-d42rk:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-pgqn9/pods/http:proxy-service-2ppp2-d42rk:1080/proxy/... (200; 22.1994ms)
Dec  3 19:52:05.446: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-pgqn9/pods/proxy-service-2ppp2-d42rk:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-pgqn9/pods/proxy-service-2ppp2-d42rk:1080/proxy/rewri... (200; 22.49728ms)
Dec  3 19:52:05.446: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-pgqn9/pods/proxy-service-2ppp2-d42rk/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-pgqn9/pods/proxy-service-2ppp2-d42rk/proxy/rewriteme"... (200; 22.484598ms)
Dec  3 19:52:05.447: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-pgqn9/pods/proxy-service-2ppp2-d42rk:162/proxy/: bar (200; 22.725487ms)
Dec  3 19:52:05.447: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-pgqn9/services/proxy-service-2ppp2:portname1/proxy/: foo (200; 22.862895ms)
Dec  3 19:52:05.447: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-pgqn9/pods/http:proxy-service-2ppp2-d42rk:160/proxy/: foo (200; 22.976554ms)
Dec  3 19:52:05.447: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-pgqn9/services/proxy-service-2ppp2:portname2/proxy/: bar (200; 23.086953ms)
Dec  3 19:52:05.448: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-pgqn9/services/https:proxy-service-2ppp2:tlsportname2/proxy/: tls qux (200; 23.651966ms)
Dec  3 19:52:05.448: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-pgqn9/services/http:proxy-service-2ppp2:portname1/proxy/: foo (200; 24.203629ms)
Dec  3 19:52:05.448: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-pgqn9/pods/proxy-service-2ppp2-d42rk:160/proxy/: foo (200; 24.158878ms)
Dec  3 19:52:05.448: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-pgqn9/services/http:proxy-service-2ppp2:portname2/proxy/: bar (200; 24.210176ms)
Dec  3 19:52:05.467: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-pgqn9/pods/http:proxy-service-2ppp2-d42rk:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-pgqn9/pods/http:proxy-service-2ppp2-d42rk:1080/proxy/... (200; 18.257706ms)
Dec  3 19:52:05.470: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-pgqn9/pods/proxy-service-2ppp2-d42rk:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-pgqn9/pods/proxy-service-2ppp2-d42rk:1080/proxy/rewri... (200; 21.60211ms)
Dec  3 19:52:05.470: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-pgqn9/pods/https:proxy-service-2ppp2-d42rk:460/proxy/: tls baz (200; 22.009633ms)
Dec  3 19:52:05.472: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-pgqn9/services/http:proxy-service-2ppp2:portname2/proxy/: bar (200; 23.248257ms)
Dec  3 19:52:05.474: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-pgqn9/services/https:proxy-service-2ppp2:tlsportname1/proxy/: tls baz (200; 25.136128ms)
Dec  3 19:52:05.474: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-pgqn9/pods/proxy-service-2ppp2-d42rk/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-pgqn9/pods/proxy-service-2ppp2-d42rk/proxy/rewriteme"... (200; 25.561327ms)
Dec  3 19:52:05.475: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-pgqn9/services/https:proxy-service-2ppp2:tlsportname2/proxy/: tls qux (200; 25.872976ms)
Dec  3 19:52:05.475: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-pgqn9/pods/https:proxy-service-2ppp2-d42rk:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-pgqn9/pods/https:proxy-service-2ppp2-d42rk:443/proxy/... (200; 26.057848ms)
Dec  3 19:52:05.475: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-pgqn9/pods/http:proxy-service-2ppp2-d42rk:162/proxy/: bar (200; 26.603542ms)
Dec  3 19:52:05.476: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-pgqn9/pods/https:proxy-service-2ppp2-d42rk:462/proxy/: tls qux (200; 26.714861ms)
Dec  3 19:52:05.476: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-pgqn9/pods/http:proxy-service-2ppp2-d42rk:160/proxy/: foo (200; 26.712159ms)
Dec  3 19:52:05.476: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-pgqn9/pods/proxy-service-2ppp2-d42rk:160/proxy/: foo (200; 26.888623ms)
Dec  3 19:52:05.476: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-pgqn9/pods/proxy-service-2ppp2-d42rk:162/proxy/: bar (200; 27.357447ms)
Dec  3 19:52:05.476: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-pgqn9/services/proxy-service-2ppp2:portname2/proxy/: bar (200; 27.412681ms)
Dec  3 19:52:05.476: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-pgqn9/services/proxy-service-2ppp2:portname1/proxy/: foo (200; 27.271107ms)
Dec  3 19:52:05.476: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-pgqn9/services/http:proxy-service-2ppp2:portname1/proxy/: foo (200; 27.482681ms)
Dec  3 19:52:05.499: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-pgqn9/pods/http:proxy-service-2ppp2-d42rk:160/proxy/: foo (200; 21.296609ms)
Dec  3 19:52:05.500: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-pgqn9/pods/http:proxy-service-2ppp2-d42rk:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-pgqn9/pods/http:proxy-service-2ppp2-d42rk:1080/proxy/... (200; 23.415458ms)
Dec  3 19:52:05.500: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-pgqn9/pods/proxy-service-2ppp2-d42rk/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-pgqn9/pods/proxy-service-2ppp2-d42rk/proxy/rewriteme"... (200; 23.546011ms)
Dec  3 19:52:05.501: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-pgqn9/services/proxy-service-2ppp2:portname2/proxy/: bar (200; 24.712994ms)
Dec  3 19:52:05.501: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-pgqn9/services/http:proxy-service-2ppp2:portname2/proxy/: bar (200; 23.368153ms)
Dec  3 19:52:05.501: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-pgqn9/services/http:proxy-service-2ppp2:portname1/proxy/: foo (200; 24.620954ms)
Dec  3 19:52:05.502: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-pgqn9/pods/http:proxy-service-2ppp2-d42rk:162/proxy/: bar (200; 23.379493ms)
Dec  3 19:52:05.503: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-pgqn9/services/https:proxy-service-2ppp2:tlsportname2/proxy/: tls qux (200; 25.936432ms)
Dec  3 19:52:05.503: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-pgqn9/pods/proxy-service-2ppp2-d42rk:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-pgqn9/pods/proxy-service-2ppp2-d42rk:1080/proxy/rewri... (200; 25.450366ms)
Dec  3 19:52:05.504: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-pgqn9/services/https:proxy-service-2ppp2:tlsportname1/proxy/: tls baz (200; 26.228499ms)
Dec  3 19:52:05.504: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-pgqn9/pods/https:proxy-service-2ppp2-d42rk:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-pgqn9/pods/https:proxy-service-2ppp2-d42rk:443/proxy/... (200; 26.862398ms)
Dec  3 19:52:05.504: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-pgqn9/pods/proxy-service-2ppp2-d42rk:160/proxy/: foo (200; 26.038464ms)
Dec  3 19:52:05.504: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-pgqn9/pods/proxy-service-2ppp2-d42rk:162/proxy/: bar (200; 26.398731ms)
Dec  3 19:52:05.504: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-pgqn9/pods/https:proxy-service-2ppp2-d42rk:460/proxy/: tls baz (200; 26.888488ms)
Dec  3 19:52:05.504: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-pgqn9/pods/https:proxy-service-2ppp2-d42rk:462/proxy/: tls qux (200; 27.246787ms)
Dec  3 19:52:05.505: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-pgqn9/services/proxy-service-2ppp2:portname1/proxy/: foo (200; 27.939314ms)
Dec  3 19:52:05.529: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-pgqn9/pods/proxy-service-2ppp2-d42rk:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-pgqn9/pods/proxy-service-2ppp2-d42rk:1080/proxy/rewri... (200; 23.438704ms)
Dec  3 19:52:05.529: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-pgqn9/pods/https:proxy-service-2ppp2-d42rk:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-pgqn9/pods/https:proxy-service-2ppp2-d42rk:443/proxy/... (200; 23.663333ms)
Dec  3 19:52:05.529: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-pgqn9/pods/proxy-service-2ppp2-d42rk/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-pgqn9/pods/proxy-service-2ppp2-d42rk/proxy/rewriteme"... (200; 23.668053ms)
Dec  3 19:52:05.529: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-pgqn9/pods/https:proxy-service-2ppp2-d42rk:460/proxy/: tls baz (200; 23.988351ms)
Dec  3 19:52:05.529: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-pgqn9/services/https:proxy-service-2ppp2:tlsportname2/proxy/: tls qux (200; 24.074187ms)
Dec  3 19:52:05.532: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-pgqn9/services/http:proxy-service-2ppp2:portname2/proxy/: bar (200; 26.206174ms)
Dec  3 19:52:05.532: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-pgqn9/pods/proxy-service-2ppp2-d42rk:160/proxy/: foo (200; 26.174348ms)
Dec  3 19:52:05.532: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-pgqn9/pods/http:proxy-service-2ppp2-d42rk:160/proxy/: foo (200; 26.137843ms)
Dec  3 19:52:05.532: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-pgqn9/pods/proxy-service-2ppp2-d42rk:162/proxy/: bar (200; 26.553491ms)
Dec  3 19:52:05.532: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-pgqn9/pods/https:proxy-service-2ppp2-d42rk:462/proxy/: tls qux (200; 26.577666ms)
Dec  3 19:52:05.532: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-pgqn9/pods/http:proxy-service-2ppp2-d42rk:162/proxy/: bar (200; 26.818286ms)
Dec  3 19:52:05.533: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-pgqn9/services/http:proxy-service-2ppp2:portname1/proxy/: foo (200; 27.538569ms)
Dec  3 19:52:05.533: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-pgqn9/services/proxy-service-2ppp2:portname2/proxy/: bar (200; 27.782739ms)
Dec  3 19:52:05.534: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-pgqn9/pods/http:proxy-service-2ppp2-d42rk:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-pgqn9/pods/http:proxy-service-2ppp2-d42rk:1080/proxy/... (200; 28.187483ms)
Dec  3 19:52:05.534: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-pgqn9/services/https:proxy-service-2ppp2:tlsportname1/proxy/: tls baz (200; 28.414687ms)
Dec  3 19:52:05.534: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-pgqn9/services/proxy-service-2ppp2:portname1/proxy/: foo (200; 28.772479ms)
Dec  3 19:52:05.552: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-pgqn9/pods/http:proxy-service-2ppp2-d42rk:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-pgqn9/pods/http:proxy-service-2ppp2-d42rk:1080/proxy/... (200; 17.772649ms)
Dec  3 19:52:05.558: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-pgqn9/pods/proxy-service-2ppp2-d42rk:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-pgqn9/pods/proxy-service-2ppp2-d42rk:1080/proxy/rewri... (200; 23.089752ms)
Dec  3 19:52:05.558: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-pgqn9/pods/proxy-service-2ppp2-d42rk/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-pgqn9/pods/proxy-service-2ppp2-d42rk/proxy/rewriteme"... (200; 22.996568ms)
Dec  3 19:52:05.558: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-pgqn9/pods/https:proxy-service-2ppp2-d42rk:462/proxy/: tls qux (200; 23.780645ms)
Dec  3 19:52:05.558: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-pgqn9/pods/https:proxy-service-2ppp2-d42rk:460/proxy/: tls baz (200; 24.005777ms)
Dec  3 19:52:05.559: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-pgqn9/pods/https:proxy-service-2ppp2-d42rk:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-pgqn9/pods/https:proxy-service-2ppp2-d42rk:443/proxy/... (200; 24.278218ms)
Dec  3 19:52:05.559: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-pgqn9/pods/proxy-service-2ppp2-d42rk:162/proxy/: bar (200; 24.775721ms)
Dec  3 19:52:05.559: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-pgqn9/pods/http:proxy-service-2ppp2-d42rk:160/proxy/: foo (200; 24.845693ms)
Dec  3 19:52:05.559: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-pgqn9/pods/proxy-service-2ppp2-d42rk:160/proxy/: foo (200; 24.733674ms)
Dec  3 19:52:05.560: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-pgqn9/services/proxy-service-2ppp2:portname2/proxy/: bar (200; 25.336575ms)
Dec  3 19:52:05.560: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-pgqn9/services/https:proxy-service-2ppp2:tlsportname1/proxy/: tls baz (200; 25.591297ms)
Dec  3 19:52:05.560: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-pgqn9/services/https:proxy-service-2ppp2:tlsportname2/proxy/: tls qux (200; 26.026071ms)
Dec  3 19:52:05.561: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-pgqn9/services/http:proxy-service-2ppp2:portname2/proxy/: bar (200; 26.987662ms)
Dec  3 19:52:05.562: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-pgqn9/services/http:proxy-service-2ppp2:portname1/proxy/: foo (200; 26.720536ms)
Dec  3 19:52:05.562: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-pgqn9/services/proxy-service-2ppp2:portname1/proxy/: foo (200; 26.781203ms)
Dec  3 19:52:05.562: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-pgqn9/pods/http:proxy-service-2ppp2-d42rk:162/proxy/: bar (200; 26.676165ms)
Dec  3 19:52:05.583: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-pgqn9/pods/https:proxy-service-2ppp2-d42rk:460/proxy/: tls baz (200; 21.447492ms)
Dec  3 19:52:05.584: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-pgqn9/pods/https:proxy-service-2ppp2-d42rk:462/proxy/: tls qux (200; 22.471292ms)
Dec  3 19:52:05.584: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-pgqn9/pods/proxy-service-2ppp2-d42rk/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-pgqn9/pods/proxy-service-2ppp2-d42rk/proxy/rewriteme"... (200; 22.692943ms)
Dec  3 19:52:05.586: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-pgqn9/services/https:proxy-service-2ppp2:tlsportname2/proxy/: tls qux (200; 24.252328ms)
Dec  3 19:52:05.586: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-pgqn9/pods/http:proxy-service-2ppp2-d42rk:162/proxy/: bar (200; 24.327991ms)
Dec  3 19:52:05.586: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-pgqn9/pods/http:proxy-service-2ppp2-d42rk:160/proxy/: foo (200; 24.270157ms)
Dec  3 19:52:05.586: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-pgqn9/services/proxy-service-2ppp2:portname1/proxy/: foo (200; 24.282023ms)
Dec  3 19:52:05.586: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-pgqn9/services/proxy-service-2ppp2:portname2/proxy/: bar (200; 24.434486ms)
Dec  3 19:52:05.587: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-pgqn9/pods/proxy-service-2ppp2-d42rk:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-pgqn9/pods/proxy-service-2ppp2-d42rk:1080/proxy/rewri... (200; 25.294088ms)
Dec  3 19:52:05.587: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-pgqn9/services/http:proxy-service-2ppp2:portname2/proxy/: bar (200; 25.786818ms)
Dec  3 19:52:05.589: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-pgqn9/pods/proxy-service-2ppp2-d42rk:162/proxy/: bar (200; 26.626517ms)
Dec  3 19:52:05.589: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-pgqn9/pods/https:proxy-service-2ppp2-d42rk:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-pgqn9/pods/https:proxy-service-2ppp2-d42rk:443/proxy/... (200; 26.707093ms)
Dec  3 19:52:05.589: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-pgqn9/pods/http:proxy-service-2ppp2-d42rk:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-pgqn9/pods/http:proxy-service-2ppp2-d42rk:1080/proxy/... (200; 26.930483ms)
Dec  3 19:52:05.589: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-pgqn9/services/https:proxy-service-2ppp2:tlsportname1/proxy/: tls baz (200; 27.015796ms)
Dec  3 19:52:05.589: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-pgqn9/pods/proxy-service-2ppp2-d42rk:160/proxy/: foo (200; 27.388581ms)
Dec  3 19:52:05.590: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-pgqn9/services/http:proxy-service-2ppp2:portname1/proxy/: foo (200; 27.791126ms)
Dec  3 19:52:05.615: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-pgqn9/pods/http:proxy-service-2ppp2-d42rk:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-pgqn9/pods/http:proxy-service-2ppp2-d42rk:1080/proxy/... (200; 24.7879ms)
Dec  3 19:52:05.615: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-pgqn9/pods/https:proxy-service-2ppp2-d42rk:462/proxy/: tls qux (200; 24.838541ms)
Dec  3 19:52:05.616: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-pgqn9/pods/https:proxy-service-2ppp2-d42rk:460/proxy/: tls baz (200; 25.249782ms)
Dec  3 19:52:05.616: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-pgqn9/pods/proxy-service-2ppp2-d42rk/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-pgqn9/pods/proxy-service-2ppp2-d42rk/proxy/rewriteme"... (200; 25.52345ms)
Dec  3 19:52:05.616: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-pgqn9/pods/https:proxy-service-2ppp2-d42rk:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-pgqn9/pods/https:proxy-service-2ppp2-d42rk:443/proxy/... (200; 25.502777ms)
Dec  3 19:52:05.616: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-pgqn9/pods/proxy-service-2ppp2-d42rk:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-pgqn9/pods/proxy-service-2ppp2-d42rk:1080/proxy/rewri... (200; 25.733842ms)
Dec  3 19:52:05.617: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-pgqn9/pods/proxy-service-2ppp2-d42rk:162/proxy/: bar (200; 26.712034ms)
Dec  3 19:52:05.617: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-pgqn9/pods/http:proxy-service-2ppp2-d42rk:160/proxy/: foo (200; 26.413309ms)
Dec  3 19:52:05.617: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-pgqn9/services/proxy-service-2ppp2:portname2/proxy/: bar (200; 27.076135ms)
Dec  3 19:52:05.617: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-pgqn9/pods/proxy-service-2ppp2-d42rk:160/proxy/: foo (200; 26.517479ms)
Dec  3 19:52:05.618: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-pgqn9/services/http:proxy-service-2ppp2:portname1/proxy/: foo (200; 26.963016ms)
Dec  3 19:52:05.618: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-pgqn9/pods/http:proxy-service-2ppp2-d42rk:162/proxy/: bar (200; 27.258271ms)
Dec  3 19:52:05.618: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-pgqn9/services/https:proxy-service-2ppp2:tlsportname1/proxy/: tls baz (200; 27.633214ms)
Dec  3 19:52:05.619: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-pgqn9/services/https:proxy-service-2ppp2:tlsportname2/proxy/: tls qux (200; 28.527609ms)
Dec  3 19:52:05.619: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-pgqn9/services/http:proxy-service-2ppp2:portname2/proxy/: bar (200; 28.570326ms)
Dec  3 19:52:05.619: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-pgqn9/services/proxy-service-2ppp2:portname1/proxy/: foo (200; 28.358116ms)
Dec  3 19:52:05.638: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-pgqn9/pods/https:proxy-service-2ppp2-d42rk:462/proxy/: tls qux (200; 18.385358ms)
Dec  3 19:52:05.640: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-pgqn9/pods/proxy-service-2ppp2-d42rk:160/proxy/: foo (200; 19.868196ms)
Dec  3 19:52:05.640: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-pgqn9/pods/proxy-service-2ppp2-d42rk:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-pgqn9/pods/proxy-service-2ppp2-d42rk:1080/proxy/rewri... (200; 20.057611ms)
Dec  3 19:52:05.641: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-pgqn9/pods/http:proxy-service-2ppp2-d42rk:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-pgqn9/pods/http:proxy-service-2ppp2-d42rk:1080/proxy/... (200; 20.801853ms)
Dec  3 19:52:05.641: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-pgqn9/pods/https:proxy-service-2ppp2-d42rk:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-pgqn9/pods/https:proxy-service-2ppp2-d42rk:443/proxy/... (200; 21.809785ms)
Dec  3 19:52:05.641: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-pgqn9/pods/https:proxy-service-2ppp2-d42rk:460/proxy/: tls baz (200; 21.830416ms)
Dec  3 19:52:05.643: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-pgqn9/services/http:proxy-service-2ppp2:portname2/proxy/: bar (200; 23.585008ms)
Dec  3 19:52:05.643: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-pgqn9/pods/proxy-service-2ppp2-d42rk:162/proxy/: bar (200; 23.428835ms)
Dec  3 19:52:05.643: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-pgqn9/pods/http:proxy-service-2ppp2-d42rk:160/proxy/: foo (200; 23.518781ms)
Dec  3 19:52:05.645: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-pgqn9/services/https:proxy-service-2ppp2:tlsportname2/proxy/: tls qux (200; 25.443569ms)
Dec  3 19:52:05.645: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-pgqn9/pods/proxy-service-2ppp2-d42rk/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-pgqn9/pods/proxy-service-2ppp2-d42rk/proxy/rewriteme"... (200; 24.630773ms)
Dec  3 19:52:05.645: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-pgqn9/services/http:proxy-service-2ppp2:portname1/proxy/: foo (200; 24.958783ms)
Dec  3 19:52:05.645: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-pgqn9/pods/http:proxy-service-2ppp2-d42rk:162/proxy/: bar (200; 25.105142ms)
Dec  3 19:52:05.645: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-pgqn9/services/https:proxy-service-2ppp2:tlsportname1/proxy/: tls baz (200; 25.791681ms)
Dec  3 19:52:05.646: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-pgqn9/services/proxy-service-2ppp2:portname2/proxy/: bar (200; 26.437045ms)
Dec  3 19:52:05.646: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-pgqn9/services/proxy-service-2ppp2:portname1/proxy/: foo (200; 26.208217ms)
Dec  3 19:52:05.666: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-pgqn9/pods/https:proxy-service-2ppp2-d42rk:460/proxy/: tls baz (200; 19.682823ms)
Dec  3 19:52:05.666: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-pgqn9/pods/http:proxy-service-2ppp2-d42rk:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-pgqn9/pods/http:proxy-service-2ppp2-d42rk:1080/proxy/... (200; 19.501125ms)
Dec  3 19:52:05.669: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-pgqn9/pods/proxy-service-2ppp2-d42rk:162/proxy/: bar (200; 23.17259ms)
Dec  3 19:52:05.670: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-pgqn9/pods/http:proxy-service-2ppp2-d42rk:160/proxy/: foo (200; 23.067139ms)
Dec  3 19:52:05.671: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-pgqn9/pods/https:proxy-service-2ppp2-d42rk:462/proxy/: tls qux (200; 23.943433ms)
Dec  3 19:52:05.671: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-pgqn9/services/proxy-service-2ppp2:portname1/proxy/: foo (200; 24.938488ms)
Dec  3 19:52:05.671: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-pgqn9/pods/http:proxy-service-2ppp2-d42rk:162/proxy/: bar (200; 24.504226ms)
Dec  3 19:52:05.671: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-pgqn9/services/https:proxy-service-2ppp2:tlsportname2/proxy/: tls qux (200; 24.856198ms)
Dec  3 19:52:05.672: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-pgqn9/services/proxy-service-2ppp2:portname2/proxy/: bar (200; 24.975791ms)
Dec  3 19:52:05.673: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-pgqn9/services/https:proxy-service-2ppp2:tlsportname1/proxy/: tls baz (200; 26.866099ms)
Dec  3 19:52:05.674: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-pgqn9/pods/proxy-service-2ppp2-d42rk/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-pgqn9/pods/proxy-service-2ppp2-d42rk/proxy/rewriteme"... (200; 26.958238ms)
Dec  3 19:52:05.674: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-pgqn9/pods/proxy-service-2ppp2-d42rk:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-pgqn9/pods/proxy-service-2ppp2-d42rk:1080/proxy/rewri... (200; 26.903642ms)
Dec  3 19:52:05.674: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-pgqn9/pods/https:proxy-service-2ppp2-d42rk:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-pgqn9/pods/https:proxy-service-2ppp2-d42rk:443/proxy/... (200; 26.775532ms)
Dec  3 19:52:05.674: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-pgqn9/pods/proxy-service-2ppp2-d42rk:160/proxy/: foo (200; 27.092775ms)
Dec  3 19:52:05.674: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-pgqn9/services/http:proxy-service-2ppp2:portname1/proxy/: foo (200; 27.413208ms)
Dec  3 19:52:05.674: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-pgqn9/services/http:proxy-service-2ppp2:portname2/proxy/: bar (200; 27.652679ms)
Dec  3 19:52:05.696: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-pgqn9/pods/proxy-service-2ppp2-d42rk:162/proxy/: bar (200; 22.003485ms)
Dec  3 19:52:05.696: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-pgqn9/pods/http:proxy-service-2ppp2-d42rk:160/proxy/: foo (200; 22.02542ms)
Dec  3 19:52:05.698: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-pgqn9/pods/http:proxy-service-2ppp2-d42rk:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-pgqn9/pods/http:proxy-service-2ppp2-d42rk:1080/proxy/... (200; 24.145162ms)
Dec  3 19:52:05.699: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-pgqn9/pods/https:proxy-service-2ppp2-d42rk:462/proxy/: tls qux (200; 24.158983ms)
Dec  3 19:52:05.699: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-pgqn9/pods/proxy-service-2ppp2-d42rk:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-pgqn9/pods/proxy-service-2ppp2-d42rk:1080/proxy/rewri... (200; 24.250241ms)
Dec  3 19:52:05.699: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-pgqn9/pods/proxy-service-2ppp2-d42rk/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-pgqn9/pods/proxy-service-2ppp2-d42rk/proxy/rewriteme"... (200; 24.501078ms)
Dec  3 19:52:05.699: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-pgqn9/services/https:proxy-service-2ppp2:tlsportname1/proxy/: tls baz (200; 24.962476ms)
Dec  3 19:52:05.699: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-pgqn9/pods/https:proxy-service-2ppp2-d42rk:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-pgqn9/pods/https:proxy-service-2ppp2-d42rk:443/proxy/... (200; 25.013098ms)
Dec  3 19:52:05.700: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-pgqn9/pods/https:proxy-service-2ppp2-d42rk:460/proxy/: tls baz (200; 25.755942ms)
Dec  3 19:52:05.700: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-pgqn9/pods/http:proxy-service-2ppp2-d42rk:162/proxy/: bar (200; 25.829816ms)
Dec  3 19:52:05.700: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-pgqn9/pods/proxy-service-2ppp2-d42rk:160/proxy/: foo (200; 25.879459ms)
Dec  3 19:52:05.700: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-pgqn9/services/http:proxy-service-2ppp2:portname2/proxy/: bar (200; 26.002788ms)
Dec  3 19:52:05.701: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-pgqn9/services/proxy-service-2ppp2:portname2/proxy/: bar (200; 27.085403ms)
Dec  3 19:52:05.701: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-pgqn9/services/proxy-service-2ppp2:portname1/proxy/: foo (200; 27.216516ms)
Dec  3 19:52:05.701: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-pgqn9/services/http:proxy-service-2ppp2:portname1/proxy/: foo (200; 27.168639ms)
Dec  3 19:52:05.702: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-pgqn9/services/https:proxy-service-2ppp2:tlsportname2/proxy/: tls qux (200; 27.362686ms)
Dec  3 19:52:05.723: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-pgqn9/pods/proxy-service-2ppp2-d42rk/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-pgqn9/pods/proxy-service-2ppp2-d42rk/proxy/rewriteme"... (200; 21.269658ms)
Dec  3 19:52:05.723: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-pgqn9/services/https:proxy-service-2ppp2:tlsportname2/proxy/: tls qux (200; 21.279438ms)
Dec  3 19:52:05.726: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-pgqn9/services/proxy-service-2ppp2:portname1/proxy/: foo (200; 24.457202ms)
Dec  3 19:52:05.726: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-pgqn9/pods/proxy-service-2ppp2-d42rk:162/proxy/: bar (200; 24.439063ms)
Dec  3 19:52:05.726: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-pgqn9/pods/http:proxy-service-2ppp2-d42rk:162/proxy/: bar (200; 24.478259ms)
Dec  3 19:52:05.727: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-pgqn9/pods/http:proxy-service-2ppp2-d42rk:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-pgqn9/pods/http:proxy-service-2ppp2-d42rk:1080/proxy/... (200; 24.792066ms)
Dec  3 19:52:05.728: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-pgqn9/pods/proxy-service-2ppp2-d42rk:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-pgqn9/pods/proxy-service-2ppp2-d42rk:1080/proxy/rewri... (200; 25.934137ms)
Dec  3 19:52:05.728: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-pgqn9/pods/https:proxy-service-2ppp2-d42rk:460/proxy/: tls baz (200; 25.616763ms)
Dec  3 19:52:05.729: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-pgqn9/pods/https:proxy-service-2ppp2-d42rk:462/proxy/: tls qux (200; 27.001909ms)
Dec  3 19:52:05.729: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-pgqn9/services/https:proxy-service-2ppp2:tlsportname1/proxy/: tls baz (200; 27.175606ms)
Dec  3 19:52:05.729: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-pgqn9/pods/http:proxy-service-2ppp2-d42rk:160/proxy/: foo (200; 27.159639ms)
Dec  3 19:52:05.730: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-pgqn9/pods/https:proxy-service-2ppp2-d42rk:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-pgqn9/pods/https:proxy-service-2ppp2-d42rk:443/proxy/... (200; 27.651915ms)
Dec  3 19:52:05.730: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-pgqn9/pods/proxy-service-2ppp2-d42rk:160/proxy/: foo (200; 27.973827ms)
Dec  3 19:52:05.730: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-pgqn9/services/http:proxy-service-2ppp2:portname2/proxy/: bar (200; 28.252039ms)
Dec  3 19:52:05.731: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-pgqn9/services/proxy-service-2ppp2:portname2/proxy/: bar (200; 28.816812ms)
Dec  3 19:52:05.731: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-pgqn9/services/http:proxy-service-2ppp2:portname1/proxy/: foo (200; 28.802235ms)
Dec  3 19:52:05.751: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-pgqn9/pods/https:proxy-service-2ppp2-d42rk:460/proxy/: tls baz (200; 20.044041ms)
Dec  3 19:52:05.753: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-pgqn9/pods/https:proxy-service-2ppp2-d42rk:462/proxy/: tls qux (200; 21.811008ms)
Dec  3 19:52:05.755: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-pgqn9/pods/http:proxy-service-2ppp2-d42rk:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-pgqn9/pods/http:proxy-service-2ppp2-d42rk:1080/proxy/... (200; 23.167519ms)
Dec  3 19:52:05.755: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-pgqn9/pods/proxy-service-2ppp2-d42rk/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-pgqn9/pods/proxy-service-2ppp2-d42rk/proxy/rewriteme"... (200; 23.261132ms)
Dec  3 19:52:05.755: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-pgqn9/pods/proxy-service-2ppp2-d42rk:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-pgqn9/pods/proxy-service-2ppp2-d42rk:1080/proxy/rewri... (200; 23.879571ms)
Dec  3 19:52:05.756: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-pgqn9/services/proxy-service-2ppp2:portname2/proxy/: bar (200; 24.742643ms)
Dec  3 19:52:05.756: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-pgqn9/pods/proxy-service-2ppp2-d42rk:160/proxy/: foo (200; 24.634414ms)
Dec  3 19:52:05.756: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-pgqn9/pods/proxy-service-2ppp2-d42rk:162/proxy/: bar (200; 24.832861ms)
Dec  3 19:52:05.756: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-pgqn9/pods/http:proxy-service-2ppp2-d42rk:160/proxy/: foo (200; 24.906818ms)
Dec  3 19:52:05.756: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-pgqn9/services/http:proxy-service-2ppp2:portname2/proxy/: bar (200; 25.388355ms)
Dec  3 19:52:05.758: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-pgqn9/services/https:proxy-service-2ppp2:tlsportname1/proxy/: tls baz (200; 26.797728ms)
Dec  3 19:52:05.758: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-pgqn9/services/https:proxy-service-2ppp2:tlsportname2/proxy/: tls qux (200; 26.200672ms)
Dec  3 19:52:05.758: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-pgqn9/pods/https:proxy-service-2ppp2-d42rk:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-pgqn9/pods/https:proxy-service-2ppp2-d42rk:443/proxy/... (200; 26.150436ms)
Dec  3 19:52:05.758: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-pgqn9/pods/http:proxy-service-2ppp2-d42rk:162/proxy/: bar (200; 26.709001ms)
Dec  3 19:52:05.758: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-pgqn9/services/proxy-service-2ppp2:portname1/proxy/: foo (200; 26.607662ms)
Dec  3 19:52:05.758: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-pgqn9/services/http:proxy-service-2ppp2:portname1/proxy/: foo (200; 26.877597ms)
Dec  3 19:52:05.776: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-pgqn9/pods/https:proxy-service-2ppp2-d42rk:462/proxy/: tls qux (200; 17.778074ms)
Dec  3 19:52:05.782: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-pgqn9/pods/http:proxy-service-2ppp2-d42rk:162/proxy/: bar (200; 23.717346ms)
Dec  3 19:52:05.782: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-pgqn9/services/proxy-service-2ppp2:portname1/proxy/: foo (200; 23.847765ms)
Dec  3 19:52:05.784: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-pgqn9/pods/proxy-service-2ppp2-d42rk:162/proxy/: bar (200; 24.73277ms)
Dec  3 19:52:05.784: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-pgqn9/services/http:proxy-service-2ppp2:portname2/proxy/: bar (200; 25.196687ms)
Dec  3 19:52:05.786: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-pgqn9/pods/proxy-service-2ppp2-d42rk:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-pgqn9/pods/proxy-service-2ppp2-d42rk:1080/proxy/rewri... (200; 27.609836ms)
Dec  3 19:52:05.786: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-pgqn9/services/https:proxy-service-2ppp2:tlsportname1/proxy/: tls baz (200; 27.487084ms)
Dec  3 19:52:05.786: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-pgqn9/pods/http:proxy-service-2ppp2-d42rk:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-pgqn9/pods/http:proxy-service-2ppp2-d42rk:1080/proxy/... (200; 27.662667ms)
Dec  3 19:52:05.787: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-pgqn9/pods/https:proxy-service-2ppp2-d42rk:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-pgqn9/pods/https:proxy-service-2ppp2-d42rk:443/proxy/... (200; 27.820949ms)
Dec  3 19:52:05.787: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-pgqn9/pods/https:proxy-service-2ppp2-d42rk:460/proxy/: tls baz (200; 27.851332ms)
Dec  3 19:52:05.787: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-pgqn9/pods/proxy-service-2ppp2-d42rk/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-pgqn9/pods/proxy-service-2ppp2-d42rk/proxy/rewriteme"... (200; 27.98315ms)
Dec  3 19:52:05.787: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-pgqn9/pods/http:proxy-service-2ppp2-d42rk:160/proxy/: foo (200; 28.212086ms)
Dec  3 19:52:05.787: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-pgqn9/pods/proxy-service-2ppp2-d42rk:160/proxy/: foo (200; 28.606632ms)
Dec  3 19:52:05.788: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-pgqn9/services/http:proxy-service-2ppp2:portname1/proxy/: foo (200; 28.879367ms)
Dec  3 19:52:05.788: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-pgqn9/services/proxy-service-2ppp2:portname2/proxy/: bar (200; 29.331468ms)
Dec  3 19:52:05.788: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-pgqn9/services/https:proxy-service-2ppp2:tlsportname2/proxy/: tls qux (200; 29.240371ms)
STEP: deleting { ReplicationController} proxy-service-2ppp2 in namespace e2e-tests-proxy-pgqn9, will wait for the garbage collector to delete the pods
Dec  3 19:52:05.849: INFO: Deleting { ReplicationController} proxy-service-2ppp2 took: 8.028214ms
Dec  3 19:52:05.949: INFO: Terminating { ReplicationController} proxy-service-2ppp2 pods took: 100.315597ms
[AfterEach] version v1
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 19:52:14.750: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-proxy-pgqn9" for this suite.
Dec  3 19:52:20.765: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 19:52:20.817: INFO: namespace: e2e-tests-proxy-pgqn9, resource: bindings, ignored listing per whitelist
Dec  3 19:52:20.869: INFO: namespace e2e-tests-proxy-pgqn9 deletion completed in 6.115010067s

• [SLOW TEST:24.868 seconds]
[sig-network] Proxy
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy through a service and a pod  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 19:52:20.869: INFO: >>> kubeConfig: /tmp/kubeconfig-166913721
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:98
[It] should run and stop complex daemon [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Dec  3 19:52:20.944: INFO: Creating daemon "daemon-set" with a node selector
STEP: Initially, daemon pods should not be running on any nodes.
Dec  3 19:52:20.960: INFO: Number of nodes with available pods: 0
Dec  3 19:52:20.960: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Change node label to blue, check that daemon pod is launched.
Dec  3 19:52:20.975: INFO: Number of nodes with available pods: 0
Dec  3 19:52:20.975: INFO: Node hungry-keller-3o96 is running more than one daemon pod
Dec  3 19:52:21.979: INFO: Number of nodes with available pods: 0
Dec  3 19:52:21.979: INFO: Node hungry-keller-3o96 is running more than one daemon pod
Dec  3 19:52:22.979: INFO: Number of nodes with available pods: 0
Dec  3 19:52:22.979: INFO: Node hungry-keller-3o96 is running more than one daemon pod
Dec  3 19:52:23.979: INFO: Number of nodes with available pods: 0
Dec  3 19:52:23.979: INFO: Node hungry-keller-3o96 is running more than one daemon pod
Dec  3 19:52:24.980: INFO: Number of nodes with available pods: 1
Dec  3 19:52:24.980: INFO: Number of running nodes: 1, number of available pods: 1
STEP: Update the node label to green, and wait for daemons to be unscheduled
Dec  3 19:52:25.006: INFO: Number of nodes with available pods: 0
Dec  3 19:52:25.006: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Update DaemonSet node selector to green, and change its update strategy to RollingUpdate
Dec  3 19:52:25.040: INFO: Number of nodes with available pods: 0
Dec  3 19:52:25.040: INFO: Node hungry-keller-3o96 is running more than one daemon pod
Dec  3 19:52:26.044: INFO: Number of nodes with available pods: 0
Dec  3 19:52:26.044: INFO: Node hungry-keller-3o96 is running more than one daemon pod
Dec  3 19:52:27.044: INFO: Number of nodes with available pods: 0
Dec  3 19:52:27.044: INFO: Node hungry-keller-3o96 is running more than one daemon pod
Dec  3 19:52:28.044: INFO: Number of nodes with available pods: 0
Dec  3 19:52:28.044: INFO: Node hungry-keller-3o96 is running more than one daemon pod
Dec  3 19:52:29.044: INFO: Number of nodes with available pods: 0
Dec  3 19:52:29.044: INFO: Node hungry-keller-3o96 is running more than one daemon pod
Dec  3 19:52:30.044: INFO: Number of nodes with available pods: 0
Dec  3 19:52:30.044: INFO: Node hungry-keller-3o96 is running more than one daemon pod
Dec  3 19:52:31.044: INFO: Number of nodes with available pods: 0
Dec  3 19:52:31.044: INFO: Node hungry-keller-3o96 is running more than one daemon pod
Dec  3 19:52:32.044: INFO: Number of nodes with available pods: 0
Dec  3 19:52:32.044: INFO: Node hungry-keller-3o96 is running more than one daemon pod
Dec  3 19:52:33.044: INFO: Number of nodes with available pods: 0
Dec  3 19:52:33.045: INFO: Node hungry-keller-3o96 is running more than one daemon pod
Dec  3 19:52:34.044: INFO: Number of nodes with available pods: 0
Dec  3 19:52:34.044: INFO: Node hungry-keller-3o96 is running more than one daemon pod
Dec  3 19:52:35.045: INFO: Number of nodes with available pods: 0
Dec  3 19:52:35.045: INFO: Node hungry-keller-3o96 is running more than one daemon pod
Dec  3 19:52:36.044: INFO: Number of nodes with available pods: 0
Dec  3 19:52:36.044: INFO: Node hungry-keller-3o96 is running more than one daemon pod
Dec  3 19:52:37.044: INFO: Number of nodes with available pods: 0
Dec  3 19:52:37.045: INFO: Node hungry-keller-3o96 is running more than one daemon pod
Dec  3 19:52:38.045: INFO: Number of nodes with available pods: 0
Dec  3 19:52:38.045: INFO: Node hungry-keller-3o96 is running more than one daemon pod
Dec  3 19:52:39.048: INFO: Number of nodes with available pods: 0
Dec  3 19:52:39.048: INFO: Node hungry-keller-3o96 is running more than one daemon pod
Dec  3 19:52:40.044: INFO: Number of nodes with available pods: 0
Dec  3 19:52:40.045: INFO: Node hungry-keller-3o96 is running more than one daemon pod
Dec  3 19:52:41.045: INFO: Number of nodes with available pods: 0
Dec  3 19:52:41.045: INFO: Node hungry-keller-3o96 is running more than one daemon pod
Dec  3 19:52:42.044: INFO: Number of nodes with available pods: 0
Dec  3 19:52:42.044: INFO: Node hungry-keller-3o96 is running more than one daemon pod
Dec  3 19:52:43.044: INFO: Number of nodes with available pods: 0
Dec  3 19:52:43.044: INFO: Node hungry-keller-3o96 is running more than one daemon pod
Dec  3 19:52:44.044: INFO: Number of nodes with available pods: 0
Dec  3 19:52:44.044: INFO: Node hungry-keller-3o96 is running more than one daemon pod
Dec  3 19:52:45.045: INFO: Number of nodes with available pods: 0
Dec  3 19:52:45.045: INFO: Node hungry-keller-3o96 is running more than one daemon pod
Dec  3 19:52:46.045: INFO: Number of nodes with available pods: 0
Dec  3 19:52:46.045: INFO: Node hungry-keller-3o96 is running more than one daemon pod
Dec  3 19:52:47.045: INFO: Number of nodes with available pods: 0
Dec  3 19:52:47.045: INFO: Node hungry-keller-3o96 is running more than one daemon pod
Dec  3 19:52:48.044: INFO: Number of nodes with available pods: 0
Dec  3 19:52:48.045: INFO: Node hungry-keller-3o96 is running more than one daemon pod
Dec  3 19:52:49.046: INFO: Number of nodes with available pods: 0
Dec  3 19:52:49.046: INFO: Node hungry-keller-3o96 is running more than one daemon pod
Dec  3 19:52:50.045: INFO: Number of nodes with available pods: 0
Dec  3 19:52:50.045: INFO: Node hungry-keller-3o96 is running more than one daemon pod
Dec  3 19:52:51.044: INFO: Number of nodes with available pods: 0
Dec  3 19:52:51.045: INFO: Node hungry-keller-3o96 is running more than one daemon pod
Dec  3 19:52:52.044: INFO: Number of nodes with available pods: 0
Dec  3 19:52:52.044: INFO: Node hungry-keller-3o96 is running more than one daemon pod
Dec  3 19:52:53.044: INFO: Number of nodes with available pods: 0
Dec  3 19:52:53.044: INFO: Node hungry-keller-3o96 is running more than one daemon pod
Dec  3 19:52:54.044: INFO: Number of nodes with available pods: 0
Dec  3 19:52:54.044: INFO: Node hungry-keller-3o96 is running more than one daemon pod
Dec  3 19:52:55.044: INFO: Number of nodes with available pods: 0
Dec  3 19:52:55.044: INFO: Node hungry-keller-3o96 is running more than one daemon pod
Dec  3 19:52:56.044: INFO: Number of nodes with available pods: 0
Dec  3 19:52:56.045: INFO: Node hungry-keller-3o96 is running more than one daemon pod
Dec  3 19:52:57.046: INFO: Number of nodes with available pods: 0
Dec  3 19:52:57.046: INFO: Node hungry-keller-3o96 is running more than one daemon pod
Dec  3 19:52:58.045: INFO: Number of nodes with available pods: 0
Dec  3 19:52:58.045: INFO: Node hungry-keller-3o96 is running more than one daemon pod
Dec  3 19:52:59.045: INFO: Number of nodes with available pods: 0
Dec  3 19:52:59.045: INFO: Node hungry-keller-3o96 is running more than one daemon pod
Dec  3 19:53:00.044: INFO: Number of nodes with available pods: 0
Dec  3 19:53:00.044: INFO: Node hungry-keller-3o96 is running more than one daemon pod
Dec  3 19:53:01.044: INFO: Number of nodes with available pods: 0
Dec  3 19:53:01.044: INFO: Node hungry-keller-3o96 is running more than one daemon pod
Dec  3 19:53:02.044: INFO: Number of nodes with available pods: 0
Dec  3 19:53:02.044: INFO: Node hungry-keller-3o96 is running more than one daemon pod
Dec  3 19:53:03.044: INFO: Number of nodes with available pods: 0
Dec  3 19:53:03.044: INFO: Node hungry-keller-3o96 is running more than one daemon pod
Dec  3 19:53:04.045: INFO: Number of nodes with available pods: 0
Dec  3 19:53:04.045: INFO: Node hungry-keller-3o96 is running more than one daemon pod
Dec  3 19:53:05.045: INFO: Number of nodes with available pods: 0
Dec  3 19:53:05.045: INFO: Node hungry-keller-3o96 is running more than one daemon pod
Dec  3 19:53:06.044: INFO: Number of nodes with available pods: 0
Dec  3 19:53:06.044: INFO: Node hungry-keller-3o96 is running more than one daemon pod
Dec  3 19:53:07.045: INFO: Number of nodes with available pods: 0
Dec  3 19:53:07.045: INFO: Node hungry-keller-3o96 is running more than one daemon pod
Dec  3 19:53:08.044: INFO: Number of nodes with available pods: 0
Dec  3 19:53:08.044: INFO: Node hungry-keller-3o96 is running more than one daemon pod
Dec  3 19:53:09.044: INFO: Number of nodes with available pods: 0
Dec  3 19:53:09.045: INFO: Node hungry-keller-3o96 is running more than one daemon pod
Dec  3 19:53:10.044: INFO: Number of nodes with available pods: 0
Dec  3 19:53:10.044: INFO: Node hungry-keller-3o96 is running more than one daemon pod
Dec  3 19:53:11.044: INFO: Number of nodes with available pods: 1
Dec  3 19:53:11.044: INFO: Number of running nodes: 1, number of available pods: 1
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:64
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting {extensions DaemonSet} daemon-set in namespace e2e-tests-daemonsets-7v5g9, will wait for the garbage collector to delete the pods
Dec  3 19:53:11.111: INFO: Deleting {extensions DaemonSet} daemon-set took: 9.538651ms
Dec  3 19:53:11.212: INFO: Terminating {extensions DaemonSet} daemon-set pods took: 100.341689ms
Dec  3 19:53:45.116: INFO: Number of nodes with available pods: 0
Dec  3 19:53:45.116: INFO: Number of running nodes: 0, number of available pods: 0
Dec  3 19:53:45.118: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-7v5g9/daemonsets","resourceVersion":"5420"},"items":null}

Dec  3 19:53:45.120: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-7v5g9/pods","resourceVersion":"5420"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 19:53:45.137: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-7v5g9" for this suite.
Dec  3 19:53:51.151: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 19:53:51.187: INFO: namespace: e2e-tests-daemonsets-7v5g9, resource: bindings, ignored listing per whitelist
Dec  3 19:53:51.243: INFO: namespace e2e-tests-daemonsets-7v5g9 deletion completed in 6.103045962s

• [SLOW TEST:90.374 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 19:53:51.243: INFO: >>> kubeConfig: /tmp/kubeconfig-166913721
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: Gathering metrics
W1203 19:53:57.407303      19 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Dec  3 19:53:57.407: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 19:53:57.407: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-6dn4f" for this suite.
Dec  3 19:54:03.421: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 19:54:03.450: INFO: namespace: e2e-tests-gc-6dn4f, resource: bindings, ignored listing per whitelist
Dec  3 19:54:03.503: INFO: namespace e2e-tests-gc-6dn4f deletion completed in 6.092891935s

• [SLOW TEST:12.260 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[k8s.io] Probing container 
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 19:54:03.503: INFO: >>> kubeConfig: /tmp/kubeconfig-166913721
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 19:55:03.580: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-68x7p" for this suite.
Dec  3 19:55:25.595: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 19:55:25.614: INFO: namespace: e2e-tests-container-probe-68x7p, resource: bindings, ignored listing per whitelist
Dec  3 19:55:25.687: INFO: namespace e2e-tests-container-probe-68x7p deletion completed in 22.103691062s

• [SLOW TEST:82.184 seconds]
[k8s.io] Probing container
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 19:55:25.689: INFO: >>> kubeConfig: /tmp/kubeconfig-166913721
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-http in namespace e2e-tests-container-probe-szxlc
Dec  3 19:55:27.772: INFO: Started pod liveness-http in namespace e2e-tests-container-probe-szxlc
STEP: checking the pod's current state and verifying that restartCount is present
Dec  3 19:55:27.775: INFO: Initial restart count of pod liveness-http is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 19:59:28.385: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-szxlc" for this suite.
Dec  3 19:59:34.406: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 19:59:34.447: INFO: namespace: e2e-tests-container-probe-szxlc, resource: bindings, ignored listing per whitelist
Dec  3 19:59:34.509: INFO: namespace e2e-tests-container-probe-szxlc deletion completed in 6.115139869s

• [SLOW TEST:248.820 seconds]
[k8s.io] Probing container
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 19:59:34.509: INFO: >>> kubeConfig: /tmp/kubeconfig-166913721
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-map-f4beac2d-f735-11e8-8d0a-02420af40402
STEP: Creating a pod to test consume secrets
Dec  3 19:59:34.637: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-f4bf49f9-f735-11e8-8d0a-02420af40402" in namespace "e2e-tests-projected-4wdtg" to be "success or failure"
Dec  3 19:59:34.655: INFO: Pod "pod-projected-secrets-f4bf49f9-f735-11e8-8d0a-02420af40402": Phase="Pending", Reason="", readiness=false. Elapsed: 17.888601ms
Dec  3 19:59:36.659: INFO: Pod "pod-projected-secrets-f4bf49f9-f735-11e8-8d0a-02420af40402": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.021359114s
STEP: Saw pod success
Dec  3 19:59:36.659: INFO: Pod "pod-projected-secrets-f4bf49f9-f735-11e8-8d0a-02420af40402" satisfied condition "success or failure"
Dec  3 19:59:36.662: INFO: Trying to get logs from node hungry-keller-3o9a pod pod-projected-secrets-f4bf49f9-f735-11e8-8d0a-02420af40402 container projected-secret-volume-test: <nil>
STEP: delete the pod
Dec  3 19:59:36.687: INFO: Waiting for pod pod-projected-secrets-f4bf49f9-f735-11e8-8d0a-02420af40402 to disappear
Dec  3 19:59:36.691: INFO: Pod pod-projected-secrets-f4bf49f9-f735-11e8-8d0a-02420af40402 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 19:59:36.691: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-4wdtg" for this suite.
Dec  3 19:59:42.708: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 19:59:42.793: INFO: namespace: e2e-tests-projected-4wdtg, resource: bindings, ignored listing per whitelist
Dec  3 19:59:42.795: INFO: namespace e2e-tests-projected-4wdtg deletion completed in 6.099465377s

• [SLOW TEST:8.286 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 19:59:42.795: INFO: >>> kubeConfig: /tmp/kubeconfig-166913721
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-f9a7c216-f735-11e8-8d0a-02420af40402
STEP: Creating a pod to test consume secrets
Dec  3 19:59:42.881: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-f9a84e00-f735-11e8-8d0a-02420af40402" in namespace "e2e-tests-projected-j9t6j" to be "success or failure"
Dec  3 19:59:42.893: INFO: Pod "pod-projected-secrets-f9a84e00-f735-11e8-8d0a-02420af40402": Phase="Pending", Reason="", readiness=false. Elapsed: 11.744793ms
Dec  3 19:59:44.897: INFO: Pod "pod-projected-secrets-f9a84e00-f735-11e8-8d0a-02420af40402": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.015727616s
STEP: Saw pod success
Dec  3 19:59:44.897: INFO: Pod "pod-projected-secrets-f9a84e00-f735-11e8-8d0a-02420af40402" satisfied condition "success or failure"
Dec  3 19:59:44.900: INFO: Trying to get logs from node hungry-keller-3o9a pod pod-projected-secrets-f9a84e00-f735-11e8-8d0a-02420af40402 container projected-secret-volume-test: <nil>
STEP: delete the pod
Dec  3 19:59:44.923: INFO: Waiting for pod pod-projected-secrets-f9a84e00-f735-11e8-8d0a-02420af40402 to disappear
Dec  3 19:59:44.926: INFO: Pod pod-projected-secrets-f9a84e00-f735-11e8-8d0a-02420af40402 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 19:59:44.926: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-j9t6j" for this suite.
Dec  3 19:59:50.945: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 19:59:50.965: INFO: namespace: e2e-tests-projected-j9t6j, resource: bindings, ignored listing per whitelist
Dec  3 19:59:51.042: INFO: namespace e2e-tests-projected-j9t6j deletion completed in 6.107281332s

• [SLOW TEST:8.247 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl cluster-info 
  should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 19:59:51.042: INFO: >>> kubeConfig: /tmp/kubeconfig-166913721
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: validating cluster-info
Dec  3 19:59:51.118: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-166913721 cluster-info'
Dec  3 19:59:51.364: INFO: stderr: ""
Dec  3 19:59:51.364: INFO: stdout: "\x1b[0;32mKubernetes master\x1b[0m is running at \x1b[0;33mhttps://10.245.0.1:443\x1b[0m\n\x1b[0;32mKubeDNS\x1b[0m is running at \x1b[0;33mhttps://10.245.0.1:443/api/v1/namespaces/kube-system/services/kube-dns:dns/proxy\x1b[0m\n\nTo further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 19:59:51.364: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-t95n2" for this suite.
Dec  3 19:59:57.380: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 19:59:57.425: INFO: namespace: e2e-tests-kubectl-t95n2, resource: bindings, ignored listing per whitelist
Dec  3 19:59:57.483: INFO: namespace e2e-tests-kubectl-t95n2 deletion completed in 6.11441982s

• [SLOW TEST:6.441 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl cluster-info
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should check if Kubernetes master services is included in cluster-info  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl version 
  should check is all data is printed  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 19:59:57.484: INFO: >>> kubeConfig: /tmp/kubeconfig-166913721
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should check is all data is printed  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Dec  3 19:59:57.580: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-166913721 version'
Dec  3 19:59:57.717: INFO: stderr: ""
Dec  3 19:59:57.717: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"12\", GitVersion:\"v1.12.1\", GitCommit:\"4ed3216f3ec431b140b1d899130a69fc671678f4\", GitTreeState:\"clean\", BuildDate:\"2018-10-05T16:46:06Z\", GoVersion:\"go1.10.4\", Compiler:\"gc\", Platform:\"linux/amd64\"}\nServer Version: version.Info{Major:\"1\", Minor:\"12\", GitVersion:\"v1.12.3\", GitCommit:\"435f92c719f279a3a67808c80521ea17d5715c66\", GitTreeState:\"clean\", BuildDate:\"2018-11-26T12:46:57Z\", GoVersion:\"go1.10.4\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 19:59:57.717: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-4fp5k" for this suite.
Dec  3 20:00:03.732: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 20:00:03.806: INFO: namespace: e2e-tests-kubectl-4fp5k, resource: bindings, ignored listing per whitelist
Dec  3 20:00:03.862: INFO: namespace e2e-tests-kubectl-4fp5k deletion completed in 6.141664292s

• [SLOW TEST:6.378 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl version
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should check is all data is printed  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 20:00:03.862: INFO: >>> kubeConfig: /tmp/kubeconfig-166913721
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0777 on node default medium
Dec  3 20:00:03.963: INFO: Waiting up to 5m0s for pod "pod-0639fe99-f736-11e8-8d0a-02420af40402" in namespace "e2e-tests-emptydir-swbvc" to be "success or failure"
Dec  3 20:00:03.979: INFO: Pod "pod-0639fe99-f736-11e8-8d0a-02420af40402": Phase="Pending", Reason="", readiness=false. Elapsed: 15.695804ms
Dec  3 20:00:05.986: INFO: Pod "pod-0639fe99-f736-11e8-8d0a-02420af40402": Phase="Pending", Reason="", readiness=false. Elapsed: 2.022806886s
Dec  3 20:00:07.990: INFO: Pod "pod-0639fe99-f736-11e8-8d0a-02420af40402": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.026443666s
STEP: Saw pod success
Dec  3 20:00:07.990: INFO: Pod "pod-0639fe99-f736-11e8-8d0a-02420af40402" satisfied condition "success or failure"
Dec  3 20:00:07.992: INFO: Trying to get logs from node hungry-keller-3o9a pod pod-0639fe99-f736-11e8-8d0a-02420af40402 container test-container: <nil>
STEP: delete the pod
Dec  3 20:00:08.015: INFO: Waiting for pod pod-0639fe99-f736-11e8-8d0a-02420af40402 to disappear
Dec  3 20:00:08.019: INFO: Pod pod-0639fe99-f736-11e8-8d0a-02420af40402 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 20:00:08.019: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-swbvc" for this suite.
Dec  3 20:00:14.038: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 20:00:14.116: INFO: namespace: e2e-tests-emptydir-swbvc, resource: bindings, ignored listing per whitelist
Dec  3 20:00:14.135: INFO: namespace e2e-tests-emptydir-swbvc deletion completed in 6.111876641s

• [SLOW TEST:10.273 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Proxy server 
  should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 20:00:14.136: INFO: >>> kubeConfig: /tmp/kubeconfig-166913721
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Starting the proxy
Dec  3 20:00:14.214: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-166913721 proxy --unix-socket=/tmp/kubectl-proxy-unix439442628/test'
STEP: retrieving proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 20:00:14.312: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-lm89h" for this suite.
Dec  3 20:00:20.327: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 20:00:20.406: INFO: namespace: e2e-tests-kubectl-lm89h, resource: bindings, ignored listing per whitelist
Dec  3 20:00:20.457: INFO: namespace e2e-tests-kubectl-lm89h deletion completed in 6.140917731s

• [SLOW TEST:6.321 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Proxy server
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should support --unix-socket=/path  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 20:00:20.458: INFO: >>> kubeConfig: /tmp/kubeconfig-166913721
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-map-101e76d0-f736-11e8-8d0a-02420af40402
STEP: Creating a pod to test consume configMaps
Dec  3 20:00:20.563: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-101efdbd-f736-11e8-8d0a-02420af40402" in namespace "e2e-tests-projected-qwr79" to be "success or failure"
Dec  3 20:00:20.573: INFO: Pod "pod-projected-configmaps-101efdbd-f736-11e8-8d0a-02420af40402": Phase="Pending", Reason="", readiness=false. Elapsed: 10.242835ms
Dec  3 20:00:22.577: INFO: Pod "pod-projected-configmaps-101efdbd-f736-11e8-8d0a-02420af40402": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.014167906s
STEP: Saw pod success
Dec  3 20:00:22.577: INFO: Pod "pod-projected-configmaps-101efdbd-f736-11e8-8d0a-02420af40402" satisfied condition "success or failure"
Dec  3 20:00:22.580: INFO: Trying to get logs from node hungry-keller-3o9a pod pod-projected-configmaps-101efdbd-f736-11e8-8d0a-02420af40402 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Dec  3 20:00:22.608: INFO: Waiting for pod pod-projected-configmaps-101efdbd-f736-11e8-8d0a-02420af40402 to disappear
Dec  3 20:00:22.615: INFO: Pod pod-projected-configmaps-101efdbd-f736-11e8-8d0a-02420af40402 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 20:00:22.615: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-qwr79" for this suite.
Dec  3 20:00:28.642: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 20:00:28.726: INFO: namespace: e2e-tests-projected-qwr79, resource: bindings, ignored listing per whitelist
Dec  3 20:00:28.739: INFO: namespace e2e-tests-projected-qwr79 deletion completed in 6.121026479s

• [SLOW TEST:8.282 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] Projected 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 20:00:28.740: INFO: >>> kubeConfig: /tmp/kubeconfig-166913721
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with configMap that has name projected-configmap-test-upd-150b1771-f736-11e8-8d0a-02420af40402
STEP: Creating the pod
STEP: Updating configmap projected-configmap-test-upd-150b1771-f736-11e8-8d0a-02420af40402
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 20:00:32.880: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-ld8mm" for this suite.
Dec  3 20:00:54.894: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 20:00:54.944: INFO: namespace: e2e-tests-projected-ld8mm, resource: bindings, ignored listing per whitelist
Dec  3 20:00:55.007: INFO: namespace e2e-tests-projected-ld8mm deletion completed in 22.12329881s

• [SLOW TEST:26.267 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 20:00:55.008: INFO: >>> kubeConfig: /tmp/kubeconfig-166913721
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Dec  3 20:00:59.141: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Dec  3 20:00:59.144: INFO: Pod pod-with-prestop-exec-hook still exists
Dec  3 20:01:01.145: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Dec  3 20:01:01.149: INFO: Pod pod-with-prestop-exec-hook still exists
Dec  3 20:01:03.145: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Dec  3 20:01:03.149: INFO: Pod pod-with-prestop-exec-hook still exists
Dec  3 20:01:05.145: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Dec  3 20:01:05.148: INFO: Pod pod-with-prestop-exec-hook still exists
Dec  3 20:01:07.145: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Dec  3 20:01:07.148: INFO: Pod pod-with-prestop-exec-hook still exists
Dec  3 20:01:09.145: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Dec  3 20:01:09.148: INFO: Pod pod-with-prestop-exec-hook still exists
Dec  3 20:01:11.145: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Dec  3 20:01:11.159: INFO: Pod pod-with-prestop-exec-hook still exists
Dec  3 20:01:13.145: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Dec  3 20:01:13.149: INFO: Pod pod-with-prestop-exec-hook still exists
Dec  3 20:01:15.145: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Dec  3 20:01:15.148: INFO: Pod pod-with-prestop-exec-hook still exists
Dec  3 20:01:17.145: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Dec  3 20:01:17.148: INFO: Pod pod-with-prestop-exec-hook still exists
Dec  3 20:01:19.145: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Dec  3 20:01:19.148: INFO: Pod pod-with-prestop-exec-hook still exists
Dec  3 20:01:21.145: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Dec  3 20:01:21.148: INFO: Pod pod-with-prestop-exec-hook still exists
Dec  3 20:01:23.145: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Dec  3 20:01:23.149: INFO: Pod pod-with-prestop-exec-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 20:01:23.161: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-lifecycle-hook-dbcsn" for this suite.
Dec  3 20:01:45.174: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 20:01:45.266: INFO: namespace: e2e-tests-container-lifecycle-hook-dbcsn, resource: bindings, ignored listing per whitelist
Dec  3 20:01:45.272: INFO: namespace e2e-tests-container-lifecycle-hook-dbcsn deletion completed in 22.107958584s

• [SLOW TEST:50.265 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when create a pod with lifecycle hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute prestop exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 20:01:45.274: INFO: >>> kubeConfig: /tmp/kubeconfig-166913721
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test substitution in container's args
Dec  3 20:01:45.356: INFO: Waiting up to 5m0s for pod "var-expansion-42a979d2-f736-11e8-8d0a-02420af40402" in namespace "e2e-tests-var-expansion-96w4h" to be "success or failure"
Dec  3 20:01:45.366: INFO: Pod "var-expansion-42a979d2-f736-11e8-8d0a-02420af40402": Phase="Pending", Reason="", readiness=false. Elapsed: 9.547817ms
Dec  3 20:01:47.370: INFO: Pod "var-expansion-42a979d2-f736-11e8-8d0a-02420af40402": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.013595711s
STEP: Saw pod success
Dec  3 20:01:47.370: INFO: Pod "var-expansion-42a979d2-f736-11e8-8d0a-02420af40402" satisfied condition "success or failure"
Dec  3 20:01:47.373: INFO: Trying to get logs from node hungry-keller-3o9a pod var-expansion-42a979d2-f736-11e8-8d0a-02420af40402 container dapi-container: <nil>
STEP: delete the pod
Dec  3 20:01:47.395: INFO: Waiting for pod var-expansion-42a979d2-f736-11e8-8d0a-02420af40402 to disappear
Dec  3 20:01:47.397: INFO: Pod var-expansion-42a979d2-f736-11e8-8d0a-02420af40402 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 20:01:47.398: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-var-expansion-96w4h" for this suite.
Dec  3 20:01:53.412: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 20:01:53.456: INFO: namespace: e2e-tests-var-expansion-96w4h, resource: bindings, ignored listing per whitelist
Dec  3 20:01:53.497: INFO: namespace e2e-tests-var-expansion-96w4h deletion completed in 6.095754348s

• [SLOW TEST:8.223 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[k8s.io] Probing container 
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 20:01:53.497: INFO: >>> kubeConfig: /tmp/kubeconfig-166913721
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Dec  3 20:02:19.585: INFO: Container started at 2018-12-03 20:01:57 +0000 UTC, pod became ready at 2018-12-03 20:02:18 +0000 UTC
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 20:02:19.585: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-gtwrr" for this suite.
Dec  3 20:02:41.600: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 20:02:41.665: INFO: namespace: e2e-tests-container-probe-gtwrr, resource: bindings, ignored listing per whitelist
Dec  3 20:02:41.693: INFO: namespace e2e-tests-container-probe-gtwrr deletion completed in 22.104358797s

• [SLOW TEST:48.196 seconds]
[k8s.io] Probing container
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 20:02:41.693: INFO: >>> kubeConfig: /tmp/kubeconfig-166913721
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:78
Dec  3 20:02:41.758: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Dec  3 20:02:41.765: INFO: Waiting for terminating namespaces to be deleted...
Dec  3 20:02:41.770: INFO: 
Logging pods the kubelet thinks is on node hungry-keller-3o96 before test
Dec  3 20:02:41.791: INFO: csi-do-node-rt2f8 from kube-system started at 2018-12-03 19:18:39 +0000 UTC (2 container statuses recorded)
Dec  3 20:02:41.791: INFO: 	Container csi-do-plugin ready: true, restart count 0
Dec  3 20:02:41.791: INFO: 	Container driver-registrar ready: true, restart count 2
Dec  3 20:02:41.791: INFO: sonobuoy-systemd-logs-daemon-set-15edf0f0fb534ac8-s4x2r from heptio-sonobuoy started at 2018-12-03 19:38:50 +0000 UTC (2 container statuses recorded)
Dec  3 20:02:41.791: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 0
Dec  3 20:02:41.791: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Dec  3 20:02:41.791: INFO: kube-proxy-hungry-keller-3o96 from kube-system started at <nil> (0 container statuses recorded)
Dec  3 20:02:41.791: INFO: csi-do-controller-0 from kube-system started at 2018-12-03 19:18:27 +0000 UTC (4 container statuses recorded)
Dec  3 20:02:41.791: INFO: 	Container csi-attacher ready: true, restart count 0
Dec  3 20:02:41.791: INFO: 	Container csi-do-plugin ready: true, restart count 0
Dec  3 20:02:41.791: INFO: 	Container csi-provisioner ready: true, restart count 0
Dec  3 20:02:41.791: INFO: 	Container csi-snapshotter ready: true, restart count 2
Dec  3 20:02:41.791: INFO: kube-dns-55cf9576c4-wx9kt from kube-system started at 2018-12-03 19:18:27 +0000 UTC (3 container statuses recorded)
Dec  3 20:02:41.791: INFO: 	Container dnsmasq ready: true, restart count 0
Dec  3 20:02:41.791: INFO: 	Container kubedns ready: true, restart count 0
Dec  3 20:02:41.791: INFO: 	Container sidecar ready: true, restart count 0
Dec  3 20:02:41.791: INFO: 
Logging pods the kubelet thinks is on node hungry-keller-3o9a before test
Dec  3 20:02:41.800: INFO: kube-proxy-hungry-keller-3o9a from kube-system started at <nil> (0 container statuses recorded)
Dec  3 20:02:41.800: INFO: csi-do-node-8zhsm from kube-system started at 2018-12-03 19:18:33 +0000 UTC (2 container statuses recorded)
Dec  3 20:02:41.800: INFO: 	Container csi-do-plugin ready: true, restart count 0
Dec  3 20:02:41.800: INFO: 	Container driver-registrar ready: true, restart count 0
Dec  3 20:02:41.800: INFO: sonobuoy from heptio-sonobuoy started at 2018-12-03 19:38:46 +0000 UTC (1 container statuses recorded)
Dec  3 20:02:41.800: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Dec  3 20:02:41.800: INFO: sonobuoy-systemd-logs-daemon-set-15edf0f0fb534ac8-g5n59 from heptio-sonobuoy started at 2018-12-03 19:38:50 +0000 UTC (2 container statuses recorded)
Dec  3 20:02:41.800: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 0
Dec  3 20:02:41.800: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Dec  3 20:02:41.800: INFO: 
Logging pods the kubelet thinks is on node hungry-keller-3o9e before test
Dec  3 20:02:41.807: INFO: kube-proxy-hungry-keller-3o9e from kube-system started at <nil> (0 container statuses recorded)
Dec  3 20:02:41.807: INFO: csi-do-node-2vwn4 from kube-system started at 2018-12-03 19:18:41 +0000 UTC (2 container statuses recorded)
Dec  3 20:02:41.807: INFO: 	Container csi-do-plugin ready: true, restart count 0
Dec  3 20:02:41.807: INFO: 	Container driver-registrar ready: true, restart count 0
Dec  3 20:02:41.807: INFO: sonobuoy-e2e-job-ef309e1fd8f04e08 from heptio-sonobuoy started at 2018-12-03 19:38:49 +0000 UTC (2 container statuses recorded)
Dec  3 20:02:41.807: INFO: 	Container e2e ready: true, restart count 0
Dec  3 20:02:41.807: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Dec  3 20:02:41.807: INFO: sonobuoy-systemd-logs-daemon-set-15edf0f0fb534ac8-nncfq from heptio-sonobuoy started at 2018-12-03 19:38:50 +0000 UTC (2 container statuses recorded)
Dec  3 20:02:41.807: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 0
Dec  3 20:02:41.807: INFO: 	Container sonobuoy-worker ready: true, restart count 0
[It] validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Trying to launch a pod without a label to get a node which can launch it.
STEP: Explicitly delete pod here to free the resource it takes.
STEP: Trying to apply a random label on the found node.
STEP: verifying the node has the label kubernetes.io/e2e-66b89045-f736-11e8-8d0a-02420af40402 42
STEP: Trying to relaunch the pod, now with labels.
STEP: removing the label kubernetes.io/e2e-66b89045-f736-11e8-8d0a-02420af40402 off the node hungry-keller-3o9a
STEP: verifying the node doesn't have the label kubernetes.io/e2e-66b89045-f736-11e8-8d0a-02420af40402
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 20:02:49.932: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-sched-pred-wbsgt" for this suite.
Dec  3 20:02:57.954: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 20:02:58.039: INFO: namespace: e2e-tests-sched-pred-wbsgt, resource: bindings, ignored listing per whitelist
Dec  3 20:02:58.051: INFO: namespace e2e-tests-sched-pred-wbsgt deletion completed in 8.109818611s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:69

• [SLOW TEST:16.358 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 20:02:58.052: INFO: >>> kubeConfig: /tmp/kubeconfig-166913721
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-6e09ac81-f736-11e8-8d0a-02420af40402
STEP: Creating a pod to test consume configMaps
Dec  3 20:02:58.132: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-6e0a4564-f736-11e8-8d0a-02420af40402" in namespace "e2e-tests-projected-kgl7s" to be "success or failure"
Dec  3 20:02:58.142: INFO: Pod "pod-projected-configmaps-6e0a4564-f736-11e8-8d0a-02420af40402": Phase="Pending", Reason="", readiness=false. Elapsed: 9.671128ms
Dec  3 20:03:00.146: INFO: Pod "pod-projected-configmaps-6e0a4564-f736-11e8-8d0a-02420af40402": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01372542s
Dec  3 20:03:02.153: INFO: Pod "pod-projected-configmaps-6e0a4564-f736-11e8-8d0a-02420af40402": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.020415845s
STEP: Saw pod success
Dec  3 20:03:02.153: INFO: Pod "pod-projected-configmaps-6e0a4564-f736-11e8-8d0a-02420af40402" satisfied condition "success or failure"
Dec  3 20:03:02.156: INFO: Trying to get logs from node hungry-keller-3o9a pod pod-projected-configmaps-6e0a4564-f736-11e8-8d0a-02420af40402 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Dec  3 20:03:02.178: INFO: Waiting for pod pod-projected-configmaps-6e0a4564-f736-11e8-8d0a-02420af40402 to disappear
Dec  3 20:03:02.181: INFO: Pod pod-projected-configmaps-6e0a4564-f736-11e8-8d0a-02420af40402 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 20:03:02.181: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-kgl7s" for this suite.
Dec  3 20:03:08.195: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 20:03:08.266: INFO: namespace: e2e-tests-projected-kgl7s, resource: bindings, ignored listing per whitelist
Dec  3 20:03:08.291: INFO: namespace e2e-tests-projected-kgl7s deletion completed in 6.106755254s

• [SLOW TEST:10.239 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 20:03:08.292: INFO: >>> kubeConfig: /tmp/kubeconfig-166913721
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name cm-test-opt-del-74250762-f736-11e8-8d0a-02420af40402
STEP: Creating configMap with name cm-test-opt-upd-742507b8-f736-11e8-8d0a-02420af40402
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-74250762-f736-11e8-8d0a-02420af40402
STEP: Updating configmap cm-test-opt-upd-742507b8-f736-11e8-8d0a-02420af40402
STEP: Creating configMap with name cm-test-opt-create-742507db-f736-11e8-8d0a-02420af40402
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 20:04:30.982: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-27pzr" for this suite.
Dec  3 20:04:52.997: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 20:04:53.077: INFO: namespace: e2e-tests-configmap-27pzr, resource: bindings, ignored listing per whitelist
Dec  3 20:04:53.083: INFO: namespace e2e-tests-configmap-27pzr deletion completed in 22.096795077s

• [SLOW TEST:104.791 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] version v1
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 20:04:53.084: INFO: >>> kubeConfig: /tmp/kubeconfig-166913721
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Dec  3 20:04:53.158: INFO: (0) /api/v1/nodes/hungry-keller-3o96/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 4.283264ms)
Dec  3 20:04:53.162: INFO: (1) /api/v1/nodes/hungry-keller-3o96/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 3.876094ms)
Dec  3 20:04:53.166: INFO: (2) /api/v1/nodes/hungry-keller-3o96/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 3.898288ms)
Dec  3 20:04:53.170: INFO: (3) /api/v1/nodes/hungry-keller-3o96/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 3.7923ms)
Dec  3 20:04:53.174: INFO: (4) /api/v1/nodes/hungry-keller-3o96/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 4.182741ms)
Dec  3 20:04:53.178: INFO: (5) /api/v1/nodes/hungry-keller-3o96/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 3.877993ms)
Dec  3 20:04:53.182: INFO: (6) /api/v1/nodes/hungry-keller-3o96/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 4.358031ms)
Dec  3 20:04:53.187: INFO: (7) /api/v1/nodes/hungry-keller-3o96/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 4.769737ms)
Dec  3 20:04:53.191: INFO: (8) /api/v1/nodes/hungry-keller-3o96/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 3.946602ms)
Dec  3 20:04:53.195: INFO: (9) /api/v1/nodes/hungry-keller-3o96/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 3.774929ms)
Dec  3 20:04:53.199: INFO: (10) /api/v1/nodes/hungry-keller-3o96/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 4.146186ms)
Dec  3 20:04:53.204: INFO: (11) /api/v1/nodes/hungry-keller-3o96/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 4.400706ms)
Dec  3 20:04:53.212: INFO: (12) /api/v1/nodes/hungry-keller-3o96/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 7.921641ms)
Dec  3 20:04:53.216: INFO: (13) /api/v1/nodes/hungry-keller-3o96/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 4.579306ms)
Dec  3 20:04:53.220: INFO: (14) /api/v1/nodes/hungry-keller-3o96/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 3.962899ms)
Dec  3 20:04:53.224: INFO: (15) /api/v1/nodes/hungry-keller-3o96/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 3.914672ms)
Dec  3 20:04:53.229: INFO: (16) /api/v1/nodes/hungry-keller-3o96/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 4.297431ms)
Dec  3 20:04:53.232: INFO: (17) /api/v1/nodes/hungry-keller-3o96/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 3.817662ms)
Dec  3 20:04:53.237: INFO: (18) /api/v1/nodes/hungry-keller-3o96/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 4.397122ms)
Dec  3 20:04:53.240: INFO: (19) /api/v1/nodes/hungry-keller-3o96/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 3.548983ms)
[AfterEach] version v1
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 20:04:53.241: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-proxy-h4fmf" for this suite.
Dec  3 20:04:59.253: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 20:04:59.269: INFO: namespace: e2e-tests-proxy-h4fmf, resource: bindings, ignored listing per whitelist
Dec  3 20:04:59.344: INFO: namespace e2e-tests-proxy-h4fmf deletion completed in 6.100355033s

• [SLOW TEST:6.260 seconds]
[sig-network] Proxy
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy logs on node using proxy subresource  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 20:04:59.345: INFO: >>> kubeConfig: /tmp/kubeconfig-166913721
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-upd-b65734e4-f736-11e8-8d0a-02420af40402
STEP: Creating the pod
STEP: Waiting for pod with text data
STEP: Waiting for pod with binary data
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 20:05:03.479: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-jmhzr" for this suite.
Dec  3 20:05:25.682: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 20:05:25.731: INFO: namespace: e2e-tests-configmap-jmhzr, resource: bindings, ignored listing per whitelist
Dec  3 20:05:25.780: INFO: namespace e2e-tests-configmap-jmhzr deletion completed in 22.297995445s

• [SLOW TEST:26.436 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] [sig-node] Pods Extended [k8s.io] Pods Set QOS Class 
  should be submitted and removed  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 20:05:25.781: INFO: >>> kubeConfig: /tmp/kubeconfig-166913721
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pods.go:204
[It] should be submitted and removed  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying QOS class is set on the pod
[AfterEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 20:05:26.024: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-q4c7q" for this suite.
Dec  3 20:05:48.042: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 20:05:48.123: INFO: namespace: e2e-tests-pods-q4c7q, resource: bindings, ignored listing per whitelist
Dec  3 20:05:48.141: INFO: namespace e2e-tests-pods-q4c7q deletion completed in 22.112432601s

• [SLOW TEST:22.360 seconds]
[k8s.io] [sig-node] Pods Extended
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should be submitted and removed  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 20:05:48.141: INFO: >>> kubeConfig: /tmp/kubeconfig-166913721
STEP: Building a namespace api object, basename replicaset
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Dec  3 20:05:48.212: INFO: Creating ReplicaSet my-hostname-basic-d36b60cf-f736-11e8-8d0a-02420af40402
Dec  3 20:05:48.223: INFO: Pod name my-hostname-basic-d36b60cf-f736-11e8-8d0a-02420af40402: Found 0 pods out of 1
Dec  3 20:05:53.226: INFO: Pod name my-hostname-basic-d36b60cf-f736-11e8-8d0a-02420af40402: Found 1 pods out of 1
Dec  3 20:05:53.226: INFO: Ensuring a pod for ReplicaSet "my-hostname-basic-d36b60cf-f736-11e8-8d0a-02420af40402" is running
Dec  3 20:05:57.232: INFO: Pod "my-hostname-basic-d36b60cf-f736-11e8-8d0a-02420af40402-jl929" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2018-12-03 20:05:48 +0000 UTC Reason: Message:} {Type:Ready Status:False LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2018-12-03 20:05:48 +0000 UTC Reason:ContainersNotReady Message:containers with unready status: [my-hostname-basic-d36b60cf-f736-11e8-8d0a-02420af40402]} {Type:ContainersReady Status:False LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2018-12-03 20:05:48 +0000 UTC Reason:ContainersNotReady Message:containers with unready status: [my-hostname-basic-d36b60cf-f736-11e8-8d0a-02420af40402]} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2018-12-03 20:05:48 +0000 UTC Reason: Message:}])
Dec  3 20:05:57.232: INFO: Trying to dial the pod
Dec  3 20:06:02.248: INFO: Controller my-hostname-basic-d36b60cf-f736-11e8-8d0a-02420af40402: Got expected result from replica 1 [my-hostname-basic-d36b60cf-f736-11e8-8d0a-02420af40402-jl929]: "my-hostname-basic-d36b60cf-f736-11e8-8d0a-02420af40402-jl929", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 20:06:02.248: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-replicaset-6chvr" for this suite.
Dec  3 20:06:08.262: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 20:06:08.281: INFO: namespace: e2e-tests-replicaset-6chvr, resource: bindings, ignored listing per whitelist
Dec  3 20:06:08.354: INFO: namespace e2e-tests-replicaset-6chvr deletion completed in 6.103447844s

• [SLOW TEST:20.213 seconds]
[sig-apps] ReplicaSet
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 20:06:08.355: INFO: >>> kubeConfig: /tmp/kubeconfig-166913721
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test override command
Dec  3 20:06:08.477: INFO: Waiting up to 5m0s for pod "client-containers-df7e9992-f736-11e8-8d0a-02420af40402" in namespace "e2e-tests-containers-s6xvd" to be "success or failure"
Dec  3 20:06:08.488: INFO: Pod "client-containers-df7e9992-f736-11e8-8d0a-02420af40402": Phase="Pending", Reason="", readiness=false. Elapsed: 11.027546ms
Dec  3 20:06:10.493: INFO: Pod "client-containers-df7e9992-f736-11e8-8d0a-02420af40402": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015338508s
Dec  3 20:06:12.496: INFO: Pod "client-containers-df7e9992-f736-11e8-8d0a-02420af40402": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.019081887s
STEP: Saw pod success
Dec  3 20:06:12.496: INFO: Pod "client-containers-df7e9992-f736-11e8-8d0a-02420af40402" satisfied condition "success or failure"
Dec  3 20:06:12.499: INFO: Trying to get logs from node hungry-keller-3o9a pod client-containers-df7e9992-f736-11e8-8d0a-02420af40402 container test-container: <nil>
STEP: delete the pod
Dec  3 20:06:12.535: INFO: Waiting for pod client-containers-df7e9992-f736-11e8-8d0a-02420af40402 to disappear
Dec  3 20:06:12.539: INFO: Pod client-containers-df7e9992-f736-11e8-8d0a-02420af40402 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 20:06:12.539: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-s6xvd" for this suite.
Dec  3 20:06:18.552: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 20:06:18.570: INFO: namespace: e2e-tests-containers-s6xvd, resource: bindings, ignored listing per whitelist
Dec  3 20:06:18.660: INFO: namespace e2e-tests-containers-s6xvd deletion completed in 6.11773755s

• [SLOW TEST:10.305 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 20:06:18.661: INFO: >>> kubeConfig: /tmp/kubeconfig-166913721
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Dec  3 20:06:26.783: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Dec  3 20:06:26.786: INFO: Pod pod-with-prestop-http-hook still exists
Dec  3 20:06:28.786: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Dec  3 20:06:28.789: INFO: Pod pod-with-prestop-http-hook still exists
Dec  3 20:06:30.786: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Dec  3 20:06:30.789: INFO: Pod pod-with-prestop-http-hook still exists
Dec  3 20:06:32.786: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Dec  3 20:06:32.790: INFO: Pod pod-with-prestop-http-hook still exists
Dec  3 20:06:34.786: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Dec  3 20:06:34.790: INFO: Pod pod-with-prestop-http-hook still exists
Dec  3 20:06:36.786: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Dec  3 20:06:36.790: INFO: Pod pod-with-prestop-http-hook still exists
Dec  3 20:06:38.786: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Dec  3 20:06:38.789: INFO: Pod pod-with-prestop-http-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 20:06:38.800: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-lifecycle-hook-k7kg8" for this suite.
Dec  3 20:07:00.815: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 20:07:00.892: INFO: namespace: e2e-tests-container-lifecycle-hook-k7kg8, resource: bindings, ignored listing per whitelist
Dec  3 20:07:00.899: INFO: namespace e2e-tests-container-lifecycle-hook-k7kg8 deletion completed in 22.094942415s

• [SLOW TEST:42.238 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when create a pod with lifecycle hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute prestop http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl label 
  should update the label on a resource  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 20:07:00.899: INFO: >>> kubeConfig: /tmp/kubeconfig-166913721
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Kubectl label
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1042
STEP: creating the pod
Dec  3 20:07:00.965: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-166913721 create -f - --namespace=e2e-tests-kubectl-84twz'
Dec  3 20:07:01.323: INFO: stderr: ""
Dec  3 20:07:01.323: INFO: stdout: "pod/pause created\n"
Dec  3 20:07:01.323: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [pause]
Dec  3 20:07:01.323: INFO: Waiting up to 5m0s for pod "pause" in namespace "e2e-tests-kubectl-84twz" to be "running and ready"
Dec  3 20:07:01.333: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 9.610915ms
Dec  3 20:07:03.337: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01413972s
Dec  3 20:07:05.341: INFO: Pod "pause": Phase="Running", Reason="", readiness=true. Elapsed: 4.018175424s
Dec  3 20:07:05.341: INFO: Pod "pause" satisfied condition "running and ready"
Dec  3 20:07:05.341: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [pause]
[It] should update the label on a resource  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: adding the label testing-label with value testing-label-value to a pod
Dec  3 20:07:05.341: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-166913721 label pods pause testing-label=testing-label-value --namespace=e2e-tests-kubectl-84twz'
Dec  3 20:07:05.493: INFO: stderr: ""
Dec  3 20:07:05.493: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod has the label testing-label with the value testing-label-value
Dec  3 20:07:05.493: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-166913721 get pod pause -L testing-label --namespace=e2e-tests-kubectl-84twz'
Dec  3 20:07:05.635: INFO: stderr: ""
Dec  3 20:07:05.635: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          4s    testing-label-value\n"
STEP: removing the label testing-label of a pod
Dec  3 20:07:05.635: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-166913721 label pods pause testing-label- --namespace=e2e-tests-kubectl-84twz'
Dec  3 20:07:05.797: INFO: stderr: ""
Dec  3 20:07:05.797: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod doesn't have the label testing-label
Dec  3 20:07:05.797: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-166913721 get pod pause -L testing-label --namespace=e2e-tests-kubectl-84twz'
Dec  3 20:07:05.922: INFO: stderr: ""
Dec  3 20:07:05.922: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          4s    \n"
[AfterEach] [k8s.io] Kubectl label
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1048
STEP: using delete to clean up resources
Dec  3 20:07:05.923: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-166913721 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-84twz'
Dec  3 20:07:06.060: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Dec  3 20:07:06.060: INFO: stdout: "pod \"pause\" force deleted\n"
Dec  3 20:07:06.060: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-166913721 get rc,svc -l name=pause --no-headers --namespace=e2e-tests-kubectl-84twz'
Dec  3 20:07:06.203: INFO: stderr: "No resources found.\n"
Dec  3 20:07:06.204: INFO: stdout: ""
Dec  3 20:07:06.204: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-166913721 get pods -l name=pause --namespace=e2e-tests-kubectl-84twz -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Dec  3 20:07:06.322: INFO: stderr: ""
Dec  3 20:07:06.322: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 20:07:06.323: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-84twz" for this suite.
Dec  3 20:07:12.342: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 20:07:12.434: INFO: namespace: e2e-tests-kubectl-84twz, resource: bindings, ignored listing per whitelist
Dec  3 20:07:12.461: INFO: namespace e2e-tests-kubectl-84twz deletion completed in 6.131033128s

• [SLOW TEST:11.563 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl label
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should update the label on a resource  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 20:07:12.462: INFO: >>> kubeConfig: /tmp/kubeconfig-166913721
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Dec  3 20:07:18.607: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Dec  3 20:07:18.610: INFO: Pod pod-with-poststart-exec-hook still exists
Dec  3 20:07:20.610: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Dec  3 20:07:20.614: INFO: Pod pod-with-poststart-exec-hook still exists
Dec  3 20:07:22.610: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Dec  3 20:07:22.780: INFO: Pod pod-with-poststart-exec-hook still exists
Dec  3 20:07:24.610: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Dec  3 20:07:24.614: INFO: Pod pod-with-poststart-exec-hook still exists
Dec  3 20:07:26.610: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Dec  3 20:07:26.614: INFO: Pod pod-with-poststart-exec-hook still exists
Dec  3 20:07:28.610: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Dec  3 20:07:28.614: INFO: Pod pod-with-poststart-exec-hook still exists
Dec  3 20:07:30.610: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Dec  3 20:07:30.614: INFO: Pod pod-with-poststart-exec-hook still exists
Dec  3 20:07:32.610: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Dec  3 20:07:32.614: INFO: Pod pod-with-poststart-exec-hook still exists
Dec  3 20:07:34.610: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Dec  3 20:07:34.614: INFO: Pod pod-with-poststart-exec-hook still exists
Dec  3 20:07:36.610: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Dec  3 20:07:36.614: INFO: Pod pod-with-poststart-exec-hook still exists
Dec  3 20:07:38.610: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Dec  3 20:07:38.614: INFO: Pod pod-with-poststart-exec-hook still exists
Dec  3 20:07:40.610: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Dec  3 20:07:40.614: INFO: Pod pod-with-poststart-exec-hook still exists
Dec  3 20:07:42.610: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Dec  3 20:07:42.614: INFO: Pod pod-with-poststart-exec-hook still exists
Dec  3 20:07:44.610: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Dec  3 20:07:44.614: INFO: Pod pod-with-poststart-exec-hook still exists
Dec  3 20:07:46.610: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Dec  3 20:07:46.614: INFO: Pod pod-with-poststart-exec-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 20:07:46.614: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-lifecycle-hook-rbv7w" for this suite.
Dec  3 20:08:08.629: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 20:08:08.710: INFO: namespace: e2e-tests-container-lifecycle-hook-rbv7w, resource: bindings, ignored listing per whitelist
Dec  3 20:08:08.727: INFO: namespace e2e-tests-container-lifecycle-hook-rbv7w deletion completed in 22.108653141s

• [SLOW TEST:56.266 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when create a pod with lifecycle hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute poststart exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Projected 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 20:08:08.728: INFO: >>> kubeConfig: /tmp/kubeconfig-166913721
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-27391686-f737-11e8-8d0a-02420af40402
STEP: Creating a pod to test consume configMaps
Dec  3 20:08:08.835: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-2739c1cd-f737-11e8-8d0a-02420af40402" in namespace "e2e-tests-projected-qtnwp" to be "success or failure"
Dec  3 20:08:08.861: INFO: Pod "pod-projected-configmaps-2739c1cd-f737-11e8-8d0a-02420af40402": Phase="Pending", Reason="", readiness=false. Elapsed: 26.196203ms
Dec  3 20:08:10.865: INFO: Pod "pod-projected-configmaps-2739c1cd-f737-11e8-8d0a-02420af40402": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.030091753s
STEP: Saw pod success
Dec  3 20:08:10.865: INFO: Pod "pod-projected-configmaps-2739c1cd-f737-11e8-8d0a-02420af40402" satisfied condition "success or failure"
Dec  3 20:08:10.868: INFO: Trying to get logs from node hungry-keller-3o9a pod pod-projected-configmaps-2739c1cd-f737-11e8-8d0a-02420af40402 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Dec  3 20:08:10.891: INFO: Waiting for pod pod-projected-configmaps-2739c1cd-f737-11e8-8d0a-02420af40402 to disappear
Dec  3 20:08:10.895: INFO: Pod pod-projected-configmaps-2739c1cd-f737-11e8-8d0a-02420af40402 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 20:08:10.895: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-qtnwp" for this suite.
Dec  3 20:08:16.909: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 20:08:16.938: INFO: namespace: e2e-tests-projected-qtnwp, resource: bindings, ignored listing per whitelist
Dec  3 20:08:17.003: INFO: namespace e2e-tests-projected-qtnwp deletion completed in 6.104300228s

• [SLOW TEST:8.275 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Secrets 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 20:08:17.005: INFO: >>> kubeConfig: /tmp/kubeconfig-166913721
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating secret e2e-tests-secrets-4rshn/secret-test-2c2688d6-f737-11e8-8d0a-02420af40402
STEP: Creating a pod to test consume secrets
Dec  3 20:08:17.089: INFO: Waiting up to 5m0s for pod "pod-configmaps-2c270816-f737-11e8-8d0a-02420af40402" in namespace "e2e-tests-secrets-4rshn" to be "success or failure"
Dec  3 20:08:17.106: INFO: Pod "pod-configmaps-2c270816-f737-11e8-8d0a-02420af40402": Phase="Pending", Reason="", readiness=false. Elapsed: 17.644759ms
Dec  3 20:08:19.119: INFO: Pod "pod-configmaps-2c270816-f737-11e8-8d0a-02420af40402": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.030523658s
STEP: Saw pod success
Dec  3 20:08:19.119: INFO: Pod "pod-configmaps-2c270816-f737-11e8-8d0a-02420af40402" satisfied condition "success or failure"
Dec  3 20:08:19.123: INFO: Trying to get logs from node hungry-keller-3o9a pod pod-configmaps-2c270816-f737-11e8-8d0a-02420af40402 container env-test: <nil>
STEP: delete the pod
Dec  3 20:08:19.146: INFO: Waiting for pod pod-configmaps-2c270816-f737-11e8-8d0a-02420af40402 to disappear
Dec  3 20:08:19.151: INFO: Pod pod-configmaps-2c270816-f737-11e8-8d0a-02420af40402 no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 20:08:19.151: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-4rshn" for this suite.
Dec  3 20:08:25.166: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 20:08:25.218: INFO: namespace: e2e-tests-secrets-4rshn, resource: bindings, ignored listing per whitelist
Dec  3 20:08:25.278: INFO: namespace e2e-tests-secrets-4rshn deletion completed in 6.12296861s

• [SLOW TEST:8.273 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:31
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 20:08:25.278: INFO: >>> kubeConfig: /tmp/kubeconfig-166913721
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-map-311662e3-f737-11e8-8d0a-02420af40402
STEP: Creating a pod to test consume secrets
Dec  3 20:08:25.372: INFO: Waiting up to 5m0s for pod "pod-secrets-3116fef2-f737-11e8-8d0a-02420af40402" in namespace "e2e-tests-secrets-vc2pk" to be "success or failure"
Dec  3 20:08:25.393: INFO: Pod "pod-secrets-3116fef2-f737-11e8-8d0a-02420af40402": Phase="Pending", Reason="", readiness=false. Elapsed: 20.236568ms
Dec  3 20:08:27.397: INFO: Pod "pod-secrets-3116fef2-f737-11e8-8d0a-02420af40402": Phase="Pending", Reason="", readiness=false. Elapsed: 2.024271463s
Dec  3 20:08:29.400: INFO: Pod "pod-secrets-3116fef2-f737-11e8-8d0a-02420af40402": Phase="Pending", Reason="", readiness=false. Elapsed: 4.027966107s
Dec  3 20:08:31.404: INFO: Pod "pod-secrets-3116fef2-f737-11e8-8d0a-02420af40402": Phase="Pending", Reason="", readiness=false. Elapsed: 6.032135122s
Dec  3 20:08:33.409: INFO: Pod "pod-secrets-3116fef2-f737-11e8-8d0a-02420af40402": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.036350838s
STEP: Saw pod success
Dec  3 20:08:33.409: INFO: Pod "pod-secrets-3116fef2-f737-11e8-8d0a-02420af40402" satisfied condition "success or failure"
Dec  3 20:08:33.411: INFO: Trying to get logs from node hungry-keller-3o9a pod pod-secrets-3116fef2-f737-11e8-8d0a-02420af40402 container secret-volume-test: <nil>
STEP: delete the pod
Dec  3 20:08:33.431: INFO: Waiting for pod pod-secrets-3116fef2-f737-11e8-8d0a-02420af40402 to disappear
Dec  3 20:08:33.433: INFO: Pod pod-secrets-3116fef2-f737-11e8-8d0a-02420af40402 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 20:08:33.433: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-vc2pk" for this suite.
Dec  3 20:08:39.448: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 20:08:39.487: INFO: namespace: e2e-tests-secrets-vc2pk, resource: bindings, ignored listing per whitelist
Dec  3 20:08:39.569: INFO: namespace e2e-tests-secrets-vc2pk deletion completed in 6.132337983s

• [SLOW TEST:14.291 seconds]
[sig-storage] Secrets
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 20:08:39.569: INFO: >>> kubeConfig: /tmp/kubeconfig-166913721
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-399a33b2-f737-11e8-8d0a-02420af40402
STEP: Creating a pod to test consume configMaps
Dec  3 20:08:39.660: INFO: Waiting up to 5m0s for pod "pod-configmaps-399abbce-f737-11e8-8d0a-02420af40402" in namespace "e2e-tests-configmap-dwglm" to be "success or failure"
Dec  3 20:08:39.672: INFO: Pod "pod-configmaps-399abbce-f737-11e8-8d0a-02420af40402": Phase="Pending", Reason="", readiness=false. Elapsed: 11.262756ms
Dec  3 20:08:41.676: INFO: Pod "pod-configmaps-399abbce-f737-11e8-8d0a-02420af40402": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.015285501s
STEP: Saw pod success
Dec  3 20:08:41.676: INFO: Pod "pod-configmaps-399abbce-f737-11e8-8d0a-02420af40402" satisfied condition "success or failure"
Dec  3 20:08:41.678: INFO: Trying to get logs from node hungry-keller-3o9a pod pod-configmaps-399abbce-f737-11e8-8d0a-02420af40402 container configmap-volume-test: <nil>
STEP: delete the pod
Dec  3 20:08:41.700: INFO: Waiting for pod pod-configmaps-399abbce-f737-11e8-8d0a-02420af40402 to disappear
Dec  3 20:08:41.710: INFO: Pod pod-configmaps-399abbce-f737-11e8-8d0a-02420af40402 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 20:08:41.710: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-dwglm" for this suite.
Dec  3 20:08:47.725: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 20:08:47.789: INFO: namespace: e2e-tests-configmap-dwglm, resource: bindings, ignored listing per whitelist
Dec  3 20:08:47.839: INFO: namespace e2e-tests-configmap-dwglm deletion completed in 6.124568422s

• [SLOW TEST:8.269 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 20:08:47.839: INFO: >>> kubeConfig: /tmp/kubeconfig-166913721
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:98
[It] should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Dec  3 20:08:47.927: INFO: Creating simple daemon set daemon-set
STEP: Check that daemon pods launch on every node of the cluster.
Dec  3 20:08:47.945: INFO: Number of nodes with available pods: 0
Dec  3 20:08:47.945: INFO: Node hungry-keller-3o96 is running more than one daemon pod
Dec  3 20:08:48.954: INFO: Number of nodes with available pods: 0
Dec  3 20:08:48.954: INFO: Node hungry-keller-3o96 is running more than one daemon pod
Dec  3 20:08:49.952: INFO: Number of nodes with available pods: 0
Dec  3 20:08:49.952: INFO: Node hungry-keller-3o96 is running more than one daemon pod
Dec  3 20:08:50.954: INFO: Number of nodes with available pods: 1
Dec  3 20:08:50.954: INFO: Node hungry-keller-3o9a is running more than one daemon pod
Dec  3 20:08:51.954: INFO: Number of nodes with available pods: 1
Dec  3 20:08:51.955: INFO: Node hungry-keller-3o9a is running more than one daemon pod
Dec  3 20:08:52.952: INFO: Number of nodes with available pods: 2
Dec  3 20:08:52.952: INFO: Node hungry-keller-3o9a is running more than one daemon pod
Dec  3 20:08:53.952: INFO: Number of nodes with available pods: 3
Dec  3 20:08:53.952: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Update daemon pods image.
STEP: Check that daemon pods images are updated.
Dec  3 20:08:53.986: INFO: Wrong image for pod: daemon-set-24skz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  3 20:08:53.986: INFO: Wrong image for pod: daemon-set-2cvxn. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  3 20:08:53.986: INFO: Wrong image for pod: daemon-set-xf4c9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  3 20:08:55.010: INFO: Wrong image for pod: daemon-set-24skz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  3 20:08:55.010: INFO: Wrong image for pod: daemon-set-2cvxn. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  3 20:08:55.010: INFO: Wrong image for pod: daemon-set-xf4c9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  3 20:08:56.011: INFO: Wrong image for pod: daemon-set-24skz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  3 20:08:56.011: INFO: Wrong image for pod: daemon-set-2cvxn. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  3 20:08:56.011: INFO: Wrong image for pod: daemon-set-xf4c9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  3 20:08:57.011: INFO: Wrong image for pod: daemon-set-24skz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  3 20:08:57.011: INFO: Wrong image for pod: daemon-set-2cvxn. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  3 20:08:57.011: INFO: Wrong image for pod: daemon-set-xf4c9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  3 20:08:58.011: INFO: Wrong image for pod: daemon-set-24skz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  3 20:08:58.011: INFO: Wrong image for pod: daemon-set-2cvxn. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  3 20:08:58.011: INFO: Wrong image for pod: daemon-set-xf4c9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  3 20:08:59.011: INFO: Wrong image for pod: daemon-set-24skz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  3 20:08:59.011: INFO: Wrong image for pod: daemon-set-2cvxn. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  3 20:08:59.011: INFO: Wrong image for pod: daemon-set-xf4c9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  3 20:09:00.011: INFO: Wrong image for pod: daemon-set-24skz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  3 20:09:00.011: INFO: Wrong image for pod: daemon-set-2cvxn. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  3 20:09:00.011: INFO: Wrong image for pod: daemon-set-xf4c9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  3 20:09:01.012: INFO: Wrong image for pod: daemon-set-24skz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  3 20:09:01.012: INFO: Wrong image for pod: daemon-set-2cvxn. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  3 20:09:01.012: INFO: Wrong image for pod: daemon-set-xf4c9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  3 20:09:02.011: INFO: Wrong image for pod: daemon-set-24skz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  3 20:09:02.011: INFO: Wrong image for pod: daemon-set-2cvxn. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  3 20:09:02.011: INFO: Wrong image for pod: daemon-set-xf4c9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  3 20:09:03.011: INFO: Wrong image for pod: daemon-set-24skz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  3 20:09:03.011: INFO: Wrong image for pod: daemon-set-2cvxn. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  3 20:09:03.011: INFO: Wrong image for pod: daemon-set-xf4c9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  3 20:09:04.011: INFO: Wrong image for pod: daemon-set-24skz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  3 20:09:04.011: INFO: Wrong image for pod: daemon-set-2cvxn. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  3 20:09:04.011: INFO: Wrong image for pod: daemon-set-xf4c9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  3 20:09:05.011: INFO: Wrong image for pod: daemon-set-24skz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  3 20:09:05.011: INFO: Wrong image for pod: daemon-set-2cvxn. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  3 20:09:05.011: INFO: Wrong image for pod: daemon-set-xf4c9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  3 20:09:06.011: INFO: Wrong image for pod: daemon-set-24skz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  3 20:09:06.011: INFO: Wrong image for pod: daemon-set-2cvxn. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  3 20:09:06.011: INFO: Wrong image for pod: daemon-set-xf4c9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  3 20:09:07.011: INFO: Wrong image for pod: daemon-set-24skz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  3 20:09:07.011: INFO: Wrong image for pod: daemon-set-2cvxn. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  3 20:09:07.011: INFO: Wrong image for pod: daemon-set-xf4c9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  3 20:09:08.011: INFO: Wrong image for pod: daemon-set-24skz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  3 20:09:08.011: INFO: Wrong image for pod: daemon-set-2cvxn. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  3 20:09:08.011: INFO: Wrong image for pod: daemon-set-xf4c9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  3 20:09:09.010: INFO: Wrong image for pod: daemon-set-24skz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  3 20:09:09.010: INFO: Wrong image for pod: daemon-set-2cvxn. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  3 20:09:09.010: INFO: Wrong image for pod: daemon-set-xf4c9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  3 20:09:10.010: INFO: Wrong image for pod: daemon-set-24skz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  3 20:09:10.010: INFO: Wrong image for pod: daemon-set-2cvxn. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  3 20:09:10.010: INFO: Wrong image for pod: daemon-set-xf4c9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  3 20:09:11.011: INFO: Wrong image for pod: daemon-set-24skz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  3 20:09:11.011: INFO: Wrong image for pod: daemon-set-2cvxn. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  3 20:09:11.011: INFO: Wrong image for pod: daemon-set-xf4c9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  3 20:09:12.011: INFO: Wrong image for pod: daemon-set-24skz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  3 20:09:12.011: INFO: Wrong image for pod: daemon-set-2cvxn. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  3 20:09:12.011: INFO: Wrong image for pod: daemon-set-xf4c9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  3 20:09:13.010: INFO: Wrong image for pod: daemon-set-24skz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  3 20:09:13.010: INFO: Wrong image for pod: daemon-set-2cvxn. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  3 20:09:13.010: INFO: Wrong image for pod: daemon-set-xf4c9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  3 20:09:14.011: INFO: Wrong image for pod: daemon-set-24skz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  3 20:09:14.011: INFO: Wrong image for pod: daemon-set-2cvxn. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  3 20:09:14.011: INFO: Wrong image for pod: daemon-set-xf4c9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  3 20:09:15.011: INFO: Wrong image for pod: daemon-set-24skz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  3 20:09:15.011: INFO: Wrong image for pod: daemon-set-2cvxn. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  3 20:09:15.011: INFO: Wrong image for pod: daemon-set-xf4c9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  3 20:09:16.011: INFO: Wrong image for pod: daemon-set-24skz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  3 20:09:16.011: INFO: Wrong image for pod: daemon-set-2cvxn. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  3 20:09:16.011: INFO: Wrong image for pod: daemon-set-xf4c9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  3 20:09:17.011: INFO: Wrong image for pod: daemon-set-24skz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  3 20:09:17.011: INFO: Wrong image for pod: daemon-set-2cvxn. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  3 20:09:17.011: INFO: Wrong image for pod: daemon-set-xf4c9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  3 20:09:18.011: INFO: Wrong image for pod: daemon-set-24skz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  3 20:09:18.011: INFO: Wrong image for pod: daemon-set-2cvxn. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  3 20:09:18.011: INFO: Wrong image for pod: daemon-set-xf4c9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  3 20:09:19.011: INFO: Wrong image for pod: daemon-set-24skz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  3 20:09:19.011: INFO: Wrong image for pod: daemon-set-2cvxn. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  3 20:09:19.011: INFO: Wrong image for pod: daemon-set-xf4c9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  3 20:09:20.011: INFO: Wrong image for pod: daemon-set-24skz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  3 20:09:20.011: INFO: Wrong image for pod: daemon-set-2cvxn. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  3 20:09:20.011: INFO: Wrong image for pod: daemon-set-xf4c9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  3 20:09:21.011: INFO: Wrong image for pod: daemon-set-24skz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  3 20:09:21.011: INFO: Wrong image for pod: daemon-set-2cvxn. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  3 20:09:21.011: INFO: Wrong image for pod: daemon-set-xf4c9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  3 20:09:22.011: INFO: Wrong image for pod: daemon-set-24skz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  3 20:09:22.011: INFO: Wrong image for pod: daemon-set-2cvxn. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  3 20:09:22.011: INFO: Wrong image for pod: daemon-set-xf4c9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  3 20:09:23.011: INFO: Wrong image for pod: daemon-set-24skz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  3 20:09:23.011: INFO: Wrong image for pod: daemon-set-2cvxn. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  3 20:09:23.011: INFO: Wrong image for pod: daemon-set-xf4c9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  3 20:09:24.011: INFO: Wrong image for pod: daemon-set-24skz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  3 20:09:24.011: INFO: Wrong image for pod: daemon-set-2cvxn. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  3 20:09:24.011: INFO: Wrong image for pod: daemon-set-xf4c9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  3 20:09:25.011: INFO: Wrong image for pod: daemon-set-24skz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  3 20:09:25.011: INFO: Wrong image for pod: daemon-set-2cvxn. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  3 20:09:25.011: INFO: Wrong image for pod: daemon-set-xf4c9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  3 20:09:26.011: INFO: Wrong image for pod: daemon-set-24skz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  3 20:09:26.011: INFO: Wrong image for pod: daemon-set-2cvxn. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  3 20:09:26.011: INFO: Pod daemon-set-2cvxn is not available
Dec  3 20:09:26.011: INFO: Wrong image for pod: daemon-set-xf4c9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  3 20:09:27.011: INFO: Wrong image for pod: daemon-set-24skz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  3 20:09:27.011: INFO: Wrong image for pod: daemon-set-2cvxn. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  3 20:09:27.011: INFO: Pod daemon-set-2cvxn is not available
Dec  3 20:09:27.011: INFO: Wrong image for pod: daemon-set-xf4c9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  3 20:09:28.011: INFO: Wrong image for pod: daemon-set-24skz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  3 20:09:28.011: INFO: Wrong image for pod: daemon-set-2cvxn. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  3 20:09:28.011: INFO: Pod daemon-set-2cvxn is not available
Dec  3 20:09:28.011: INFO: Wrong image for pod: daemon-set-xf4c9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  3 20:09:29.011: INFO: Wrong image for pod: daemon-set-24skz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  3 20:09:29.011: INFO: Pod daemon-set-rtmjl is not available
Dec  3 20:09:29.011: INFO: Wrong image for pod: daemon-set-xf4c9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  3 20:09:30.011: INFO: Wrong image for pod: daemon-set-24skz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  3 20:09:30.011: INFO: Pod daemon-set-rtmjl is not available
Dec  3 20:09:30.011: INFO: Wrong image for pod: daemon-set-xf4c9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  3 20:09:31.012: INFO: Wrong image for pod: daemon-set-24skz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  3 20:09:31.012: INFO: Pod daemon-set-rtmjl is not available
Dec  3 20:09:31.012: INFO: Wrong image for pod: daemon-set-xf4c9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  3 20:09:32.011: INFO: Wrong image for pod: daemon-set-24skz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  3 20:09:32.011: INFO: Wrong image for pod: daemon-set-xf4c9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  3 20:09:33.011: INFO: Wrong image for pod: daemon-set-24skz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  3 20:09:33.011: INFO: Wrong image for pod: daemon-set-xf4c9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  3 20:09:34.011: INFO: Wrong image for pod: daemon-set-24skz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  3 20:09:34.011: INFO: Wrong image for pod: daemon-set-xf4c9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  3 20:09:35.011: INFO: Wrong image for pod: daemon-set-24skz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  3 20:09:35.011: INFO: Wrong image for pod: daemon-set-xf4c9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  3 20:09:36.011: INFO: Wrong image for pod: daemon-set-24skz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  3 20:09:36.011: INFO: Wrong image for pod: daemon-set-xf4c9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  3 20:09:37.010: INFO: Wrong image for pod: daemon-set-24skz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  3 20:09:37.010: INFO: Wrong image for pod: daemon-set-xf4c9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  3 20:09:38.011: INFO: Wrong image for pod: daemon-set-24skz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  3 20:09:38.011: INFO: Wrong image for pod: daemon-set-xf4c9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  3 20:09:39.010: INFO: Wrong image for pod: daemon-set-24skz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  3 20:09:39.010: INFO: Wrong image for pod: daemon-set-xf4c9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  3 20:09:40.011: INFO: Wrong image for pod: daemon-set-24skz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  3 20:09:40.011: INFO: Wrong image for pod: daemon-set-xf4c9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  3 20:09:41.011: INFO: Wrong image for pod: daemon-set-24skz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  3 20:09:41.011: INFO: Wrong image for pod: daemon-set-xf4c9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  3 20:09:42.011: INFO: Wrong image for pod: daemon-set-24skz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  3 20:09:42.011: INFO: Wrong image for pod: daemon-set-xf4c9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  3 20:09:43.011: INFO: Wrong image for pod: daemon-set-24skz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  3 20:09:43.011: INFO: Wrong image for pod: daemon-set-xf4c9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  3 20:09:44.010: INFO: Wrong image for pod: daemon-set-24skz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  3 20:09:44.010: INFO: Wrong image for pod: daemon-set-xf4c9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  3 20:09:45.011: INFO: Wrong image for pod: daemon-set-24skz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  3 20:09:45.011: INFO: Wrong image for pod: daemon-set-xf4c9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  3 20:09:46.010: INFO: Wrong image for pod: daemon-set-24skz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  3 20:09:46.010: INFO: Wrong image for pod: daemon-set-xf4c9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  3 20:09:47.011: INFO: Wrong image for pod: daemon-set-24skz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  3 20:09:47.011: INFO: Wrong image for pod: daemon-set-xf4c9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  3 20:09:48.011: INFO: Wrong image for pod: daemon-set-24skz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  3 20:09:48.011: INFO: Wrong image for pod: daemon-set-xf4c9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  3 20:09:49.011: INFO: Wrong image for pod: daemon-set-24skz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  3 20:09:49.011: INFO: Wrong image for pod: daemon-set-xf4c9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  3 20:09:50.011: INFO: Wrong image for pod: daemon-set-24skz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  3 20:09:50.011: INFO: Wrong image for pod: daemon-set-xf4c9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  3 20:09:51.011: INFO: Wrong image for pod: daemon-set-24skz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  3 20:09:51.011: INFO: Wrong image for pod: daemon-set-xf4c9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  3 20:09:52.011: INFO: Wrong image for pod: daemon-set-24skz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  3 20:09:52.012: INFO: Wrong image for pod: daemon-set-xf4c9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  3 20:09:53.011: INFO: Wrong image for pod: daemon-set-24skz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  3 20:09:53.011: INFO: Wrong image for pod: daemon-set-xf4c9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  3 20:09:54.010: INFO: Wrong image for pod: daemon-set-24skz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  3 20:09:54.011: INFO: Wrong image for pod: daemon-set-xf4c9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  3 20:09:55.011: INFO: Wrong image for pod: daemon-set-24skz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  3 20:09:55.011: INFO: Wrong image for pod: daemon-set-xf4c9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  3 20:09:56.011: INFO: Wrong image for pod: daemon-set-24skz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  3 20:09:56.011: INFO: Wrong image for pod: daemon-set-xf4c9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  3 20:09:57.011: INFO: Wrong image for pod: daemon-set-24skz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  3 20:09:57.011: INFO: Wrong image for pod: daemon-set-xf4c9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  3 20:09:58.011: INFO: Wrong image for pod: daemon-set-24skz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  3 20:09:58.011: INFO: Wrong image for pod: daemon-set-xf4c9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  3 20:09:59.010: INFO: Wrong image for pod: daemon-set-24skz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  3 20:09:59.010: INFO: Wrong image for pod: daemon-set-xf4c9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  3 20:10:00.010: INFO: Wrong image for pod: daemon-set-24skz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  3 20:10:00.010: INFO: Wrong image for pod: daemon-set-xf4c9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  3 20:10:01.011: INFO: Wrong image for pod: daemon-set-24skz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  3 20:10:01.011: INFO: Wrong image for pod: daemon-set-xf4c9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  3 20:10:02.011: INFO: Wrong image for pod: daemon-set-24skz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  3 20:10:02.011: INFO: Wrong image for pod: daemon-set-xf4c9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  3 20:10:03.011: INFO: Wrong image for pod: daemon-set-24skz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  3 20:10:03.011: INFO: Wrong image for pod: daemon-set-xf4c9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  3 20:10:03.011: INFO: Pod daemon-set-xf4c9 is not available
Dec  3 20:10:04.011: INFO: Wrong image for pod: daemon-set-24skz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  3 20:10:04.011: INFO: Pod daemon-set-dh9l2 is not available
Dec  3 20:10:05.011: INFO: Wrong image for pod: daemon-set-24skz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  3 20:10:05.011: INFO: Pod daemon-set-dh9l2 is not available
Dec  3 20:10:06.011: INFO: Wrong image for pod: daemon-set-24skz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  3 20:10:06.011: INFO: Pod daemon-set-dh9l2 is not available
Dec  3 20:10:07.011: INFO: Wrong image for pod: daemon-set-24skz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  3 20:10:08.011: INFO: Wrong image for pod: daemon-set-24skz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  3 20:10:09.010: INFO: Wrong image for pod: daemon-set-24skz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  3 20:10:10.011: INFO: Wrong image for pod: daemon-set-24skz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  3 20:10:11.010: INFO: Wrong image for pod: daemon-set-24skz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  3 20:10:12.011: INFO: Wrong image for pod: daemon-set-24skz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  3 20:10:13.012: INFO: Wrong image for pod: daemon-set-24skz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  3 20:10:14.011: INFO: Wrong image for pod: daemon-set-24skz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  3 20:10:15.011: INFO: Wrong image for pod: daemon-set-24skz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  3 20:10:16.011: INFO: Wrong image for pod: daemon-set-24skz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  3 20:10:17.011: INFO: Wrong image for pod: daemon-set-24skz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  3 20:10:18.011: INFO: Wrong image for pod: daemon-set-24skz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  3 20:10:19.010: INFO: Wrong image for pod: daemon-set-24skz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  3 20:10:20.011: INFO: Wrong image for pod: daemon-set-24skz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  3 20:10:21.010: INFO: Wrong image for pod: daemon-set-24skz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  3 20:10:22.011: INFO: Wrong image for pod: daemon-set-24skz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  3 20:10:23.020: INFO: Wrong image for pod: daemon-set-24skz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  3 20:10:24.011: INFO: Wrong image for pod: daemon-set-24skz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  3 20:10:25.011: INFO: Wrong image for pod: daemon-set-24skz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  3 20:10:26.034: INFO: Wrong image for pod: daemon-set-24skz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  3 20:10:27.011: INFO: Wrong image for pod: daemon-set-24skz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  3 20:10:28.011: INFO: Wrong image for pod: daemon-set-24skz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  3 20:10:29.010: INFO: Wrong image for pod: daemon-set-24skz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  3 20:10:30.010: INFO: Wrong image for pod: daemon-set-24skz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  3 20:10:31.011: INFO: Wrong image for pod: daemon-set-24skz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  3 20:10:32.010: INFO: Wrong image for pod: daemon-set-24skz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  3 20:10:33.010: INFO: Wrong image for pod: daemon-set-24skz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  3 20:10:34.011: INFO: Wrong image for pod: daemon-set-24skz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  3 20:10:35.011: INFO: Wrong image for pod: daemon-set-24skz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  3 20:10:36.011: INFO: Wrong image for pod: daemon-set-24skz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  3 20:10:37.011: INFO: Wrong image for pod: daemon-set-24skz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  3 20:10:38.011: INFO: Wrong image for pod: daemon-set-24skz. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec  3 20:10:38.011: INFO: Pod daemon-set-24skz is not available
Dec  3 20:10:39.011: INFO: Pod daemon-set-6n7p8 is not available
STEP: Check that daemon pods are still running on every node of the cluster.
Dec  3 20:10:39.020: INFO: Number of nodes with available pods: 2
Dec  3 20:10:39.020: INFO: Node hungry-keller-3o9a is running more than one daemon pod
Dec  3 20:10:40.028: INFO: Number of nodes with available pods: 2
Dec  3 20:10:40.028: INFO: Node hungry-keller-3o9a is running more than one daemon pod
Dec  3 20:10:41.028: INFO: Number of nodes with available pods: 3
Dec  3 20:10:41.028: INFO: Number of running nodes: 3, number of available pods: 3
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:64
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting {extensions DaemonSet} daemon-set in namespace e2e-tests-daemonsets-pwnwk, will wait for the garbage collector to delete the pods
Dec  3 20:10:41.107: INFO: Deleting {extensions DaemonSet} daemon-set took: 11.809436ms
Dec  3 20:10:41.207: INFO: Terminating {extensions DaemonSet} daemon-set pods took: 100.350717ms
Dec  3 20:10:48.711: INFO: Number of nodes with available pods: 0
Dec  3 20:10:48.711: INFO: Number of running nodes: 0, number of available pods: 0
Dec  3 20:10:48.713: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-pwnwk/daemonsets","resourceVersion":"7975"},"items":null}

Dec  3 20:10:48.716: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-pwnwk/pods","resourceVersion":"7975"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 20:10:48.729: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-pwnwk" for this suite.
Dec  3 20:10:54.908: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 20:10:54.967: INFO: namespace: e2e-tests-daemonsets-pwnwk, resource: bindings, ignored listing per whitelist
Dec  3 20:10:54.997: INFO: namespace e2e-tests-daemonsets-pwnwk deletion completed in 6.265469491s

• [SLOW TEST:127.158 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 20:10:54.997: INFO: >>> kubeConfig: /tmp/kubeconfig-166913721
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-map-8a527237-f737-11e8-8d0a-02420af40402
STEP: Creating a pod to test consume configMaps
Dec  3 20:10:55.083: INFO: Waiting up to 5m0s for pod "pod-configmaps-8a530435-f737-11e8-8d0a-02420af40402" in namespace "e2e-tests-configmap-z4jhq" to be "success or failure"
Dec  3 20:10:55.089: INFO: Pod "pod-configmaps-8a530435-f737-11e8-8d0a-02420af40402": Phase="Pending", Reason="", readiness=false. Elapsed: 6.332386ms
Dec  3 20:10:57.093: INFO: Pod "pod-configmaps-8a530435-f737-11e8-8d0a-02420af40402": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010449131s
Dec  3 20:10:59.097: INFO: Pod "pod-configmaps-8a530435-f737-11e8-8d0a-02420af40402": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014598356s
STEP: Saw pod success
Dec  3 20:10:59.097: INFO: Pod "pod-configmaps-8a530435-f737-11e8-8d0a-02420af40402" satisfied condition "success or failure"
Dec  3 20:10:59.100: INFO: Trying to get logs from node hungry-keller-3o9a pod pod-configmaps-8a530435-f737-11e8-8d0a-02420af40402 container configmap-volume-test: <nil>
STEP: delete the pod
Dec  3 20:10:59.124: INFO: Waiting for pod pod-configmaps-8a530435-f737-11e8-8d0a-02420af40402 to disappear
Dec  3 20:10:59.128: INFO: Pod pod-configmaps-8a530435-f737-11e8-8d0a-02420af40402 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 20:10:59.128: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-z4jhq" for this suite.
Dec  3 20:11:05.141: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 20:11:05.172: INFO: namespace: e2e-tests-configmap-z4jhq, resource: bindings, ignored listing per whitelist
Dec  3 20:11:05.245: INFO: namespace e2e-tests-configmap-z4jhq deletion completed in 6.113663679s

• [SLOW TEST:10.249 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] version v1
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 20:11:05.247: INFO: >>> kubeConfig: /tmp/kubeconfig-166913721
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Dec  3 20:11:05.333: INFO: (0) /api/v1/nodes/hungry-keller-3o96:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 4.256695ms)
Dec  3 20:11:05.337: INFO: (1) /api/v1/nodes/hungry-keller-3o96:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 4.08779ms)
Dec  3 20:11:05.341: INFO: (2) /api/v1/nodes/hungry-keller-3o96:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 4.018051ms)
Dec  3 20:11:05.345: INFO: (3) /api/v1/nodes/hungry-keller-3o96:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 3.875705ms)
Dec  3 20:11:05.350: INFO: (4) /api/v1/nodes/hungry-keller-3o96:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 4.642295ms)
Dec  3 20:11:05.354: INFO: (5) /api/v1/nodes/hungry-keller-3o96:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 3.646475ms)
Dec  3 20:11:05.359: INFO: (6) /api/v1/nodes/hungry-keller-3o96:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 4.685013ms)
Dec  3 20:11:05.363: INFO: (7) /api/v1/nodes/hungry-keller-3o96:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 4.022731ms)
Dec  3 20:11:05.367: INFO: (8) /api/v1/nodes/hungry-keller-3o96:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 4.193055ms)
Dec  3 20:11:05.372: INFO: (9) /api/v1/nodes/hungry-keller-3o96:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 4.830592ms)
Dec  3 20:11:05.376: INFO: (10) /api/v1/nodes/hungry-keller-3o96:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 3.975489ms)
Dec  3 20:11:05.380: INFO: (11) /api/v1/nodes/hungry-keller-3o96:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 3.809727ms)
Dec  3 20:11:05.384: INFO: (12) /api/v1/nodes/hungry-keller-3o96:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 3.947012ms)
Dec  3 20:11:05.388: INFO: (13) /api/v1/nodes/hungry-keller-3o96:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 3.960004ms)
Dec  3 20:11:05.392: INFO: (14) /api/v1/nodes/hungry-keller-3o96:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 4.381496ms)
Dec  3 20:11:05.397: INFO: (15) /api/v1/nodes/hungry-keller-3o96:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 4.344788ms)
Dec  3 20:11:05.401: INFO: (16) /api/v1/nodes/hungry-keller-3o96:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 4.231561ms)
Dec  3 20:11:05.405: INFO: (17) /api/v1/nodes/hungry-keller-3o96:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 4.352777ms)
Dec  3 20:11:05.410: INFO: (18) /api/v1/nodes/hungry-keller-3o96:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 4.666202ms)
Dec  3 20:11:05.414: INFO: (19) /api/v1/nodes/hungry-keller-3o96:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 4.230616ms)
[AfterEach] version v1
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 20:11:05.415: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-proxy-m2mfv" for this suite.
Dec  3 20:11:11.434: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 20:11:11.475: INFO: namespace: e2e-tests-proxy-m2mfv, resource: bindings, ignored listing per whitelist
Dec  3 20:11:11.529: INFO: namespace e2e-tests-proxy-m2mfv deletion completed in 6.11111228s

• [SLOW TEST:6.282 seconds]
[sig-network] Proxy
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] Downward API volume 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 20:11:11.529: INFO: >>> kubeConfig: /tmp/kubeconfig-166913721
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating the pod
Dec  3 20:11:14.157: INFO: Successfully updated pod "labelsupdate942dc140-f737-11e8-8d0a-02420af40402"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 20:11:16.179: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-dzcbz" for this suite.
Dec  3 20:11:38.200: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 20:11:38.291: INFO: namespace: e2e-tests-downward-api-dzcbz, resource: bindings, ignored listing per whitelist
Dec  3 20:11:38.316: INFO: namespace e2e-tests-downward-api-dzcbz deletion completed in 22.132778963s

• [SLOW TEST:26.787 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run --rm job 
  should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 20:11:38.316: INFO: >>> kubeConfig: /tmp/kubeconfig-166913721
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: executing a command with run --rm and attach with stdin
Dec  3 20:11:38.384: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-166913721 --namespace=e2e-tests-kubectl-wnf6k run e2e-test-rm-busybox-job --image=docker.io/library/busybox:1.29 --rm=true --generator=job/v1 --restart=OnFailure --attach=true --stdin -- sh -c cat && echo 'stdin closed''
Dec  3 20:11:40.891: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl create instead.\nIf you don't see a command prompt, try pressing enter.\n"
Dec  3 20:11:40.891: INFO: stdout: "abcd1234stdin closed\njob.batch \"e2e-test-rm-busybox-job\" deleted\n"
STEP: verifying the job e2e-test-rm-busybox-job was deleted
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 20:11:42.896: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-wnf6k" for this suite.
Dec  3 20:11:48.964: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 20:11:49.032: INFO: namespace: e2e-tests-kubectl-wnf6k, resource: bindings, ignored listing per whitelist
Dec  3 20:11:49.116: INFO: namespace e2e-tests-kubectl-wnf6k deletion completed in 6.216813508s

• [SLOW TEST:10.800 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run --rm job
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create a job from an image, then delete the job  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-api-machinery] Garbage collector 
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 20:11:49.117: INFO: >>> kubeConfig: /tmp/kubeconfig-166913721
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Dec  3 20:11:49.311: INFO: pod1.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod3", UID:"aaa32097-f737-11e8-8af3-a28d93e01224", Controller:(*bool)(0xc421c2b7b6), BlockOwnerDeletion:(*bool)(0xc421c2b7b7)}}
Dec  3 20:11:49.323: INFO: pod2.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod1", UID:"aa9f8668-f737-11e8-8af3-a28d93e01224", Controller:(*bool)(0xc421c2baba), BlockOwnerDeletion:(*bool)(0xc421c2babb)}}
Dec  3 20:11:49.330: INFO: pod3.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod2", UID:"aaa0e776-f737-11e8-8af3-a28d93e01224", Controller:(*bool)(0xc421c2bf22), BlockOwnerDeletion:(*bool)(0xc421c2bf23)}}
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 20:11:54.392: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-cvlzs" for this suite.
Dec  3 20:12:00.408: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 20:12:00.488: INFO: namespace: e2e-tests-gc-cvlzs, resource: bindings, ignored listing per whitelist
Dec  3 20:12:00.498: INFO: namespace e2e-tests-gc-cvlzs deletion completed in 6.100475279s

• [SLOW TEST:11.381 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run rc 
  should create an rc from an image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 20:12:00.499: INFO: >>> kubeConfig: /tmp/kubeconfig-166913721
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Kubectl run rc
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1246
[It] should create an rc from an image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Dec  3 20:12:00.571: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-166913721 run e2e-test-nginx-rc --image=docker.io/library/nginx:1.14-alpine --generator=run/v1 --namespace=e2e-tests-kubectl-dt9xn'
Dec  3 20:12:00.699: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl create instead.\n"
Dec  3 20:12:00.699: INFO: stdout: "replicationcontroller/e2e-test-nginx-rc created\n"
STEP: verifying the rc e2e-test-nginx-rc was created
STEP: verifying the pod controlled by rc e2e-test-nginx-rc was created
STEP: confirm that you can get logs from an rc
Dec  3 20:12:00.841: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [e2e-test-nginx-rc-4wlm5]
Dec  3 20:12:00.841: INFO: Waiting up to 5m0s for pod "e2e-test-nginx-rc-4wlm5" in namespace "e2e-tests-kubectl-dt9xn" to be "running and ready"
Dec  3 20:12:00.853: INFO: Pod "e2e-test-nginx-rc-4wlm5": Phase="Pending", Reason="", readiness=false. Elapsed: 11.893011ms
Dec  3 20:12:02.856: INFO: Pod "e2e-test-nginx-rc-4wlm5": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01549914s
Dec  3 20:12:04.860: INFO: Pod "e2e-test-nginx-rc-4wlm5": Phase="Running", Reason="", readiness=true. Elapsed: 4.019519244s
Dec  3 20:12:04.860: INFO: Pod "e2e-test-nginx-rc-4wlm5" satisfied condition "running and ready"
Dec  3 20:12:04.860: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [e2e-test-nginx-rc-4wlm5]
Dec  3 20:12:04.860: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-166913721 logs rc/e2e-test-nginx-rc --namespace=e2e-tests-kubectl-dt9xn'
Dec  3 20:12:05.015: INFO: stderr: ""
Dec  3 20:12:05.015: INFO: stdout: ""
[AfterEach] [k8s.io] Kubectl run rc
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1251
Dec  3 20:12:05.015: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-166913721 delete rc e2e-test-nginx-rc --namespace=e2e-tests-kubectl-dt9xn'
Dec  3 20:12:05.175: INFO: stderr: ""
Dec  3 20:12:05.175: INFO: stdout: "replicationcontroller \"e2e-test-nginx-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 20:12:05.175: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-dt9xn" for this suite.
Dec  3 20:12:27.199: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 20:12:27.235: INFO: namespace: e2e-tests-kubectl-dt9xn, resource: bindings, ignored listing per whitelist
Dec  3 20:12:27.287: INFO: namespace e2e-tests-kubectl-dt9xn deletion completed in 22.108053126s

• [SLOW TEST:26.788 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run rc
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create an rc from an image  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 20:12:27.287: INFO: >>> kubeConfig: /tmp/kubeconfig-166913721
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0666 on tmpfs
Dec  3 20:12:27.365: INFO: Waiting up to 5m0s for pod "pod-c15444a8-f737-11e8-8d0a-02420af40402" in namespace "e2e-tests-emptydir-q5dfn" to be "success or failure"
Dec  3 20:12:27.377: INFO: Pod "pod-c15444a8-f737-11e8-8d0a-02420af40402": Phase="Pending", Reason="", readiness=false. Elapsed: 11.604152ms
Dec  3 20:12:29.381: INFO: Pod "pod-c15444a8-f737-11e8-8d0a-02420af40402": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015864867s
Dec  3 20:12:31.385: INFO: Pod "pod-c15444a8-f737-11e8-8d0a-02420af40402": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.019822874s
STEP: Saw pod success
Dec  3 20:12:31.385: INFO: Pod "pod-c15444a8-f737-11e8-8d0a-02420af40402" satisfied condition "success or failure"
Dec  3 20:12:31.387: INFO: Trying to get logs from node hungry-keller-3o9a pod pod-c15444a8-f737-11e8-8d0a-02420af40402 container test-container: <nil>
STEP: delete the pod
Dec  3 20:12:31.423: INFO: Waiting for pod pod-c15444a8-f737-11e8-8d0a-02420af40402 to disappear
Dec  3 20:12:31.427: INFO: Pod pod-c15444a8-f737-11e8-8d0a-02420af40402 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 20:12:31.427: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-q5dfn" for this suite.
Dec  3 20:12:37.445: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 20:12:37.501: INFO: namespace: e2e-tests-emptydir-q5dfn, resource: bindings, ignored listing per whitelist
Dec  3 20:12:37.552: INFO: namespace e2e-tests-emptydir-q5dfn deletion completed in 6.12198832s

• [SLOW TEST:10.265 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] Projected 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 20:12:37.552: INFO: >>> kubeConfig: /tmp/kubeconfig-166913721
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Dec  3 20:12:37.639: INFO: Waiting up to 5m0s for pod "downwardapi-volume-c77257dd-f737-11e8-8d0a-02420af40402" in namespace "e2e-tests-projected-xgrhz" to be "success or failure"
Dec  3 20:12:37.645: INFO: Pod "downwardapi-volume-c77257dd-f737-11e8-8d0a-02420af40402": Phase="Pending", Reason="", readiness=false. Elapsed: 6.740506ms
Dec  3 20:12:39.651: INFO: Pod "downwardapi-volume-c77257dd-f737-11e8-8d0a-02420af40402": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012036474s
Dec  3 20:12:41.655: INFO: Pod "downwardapi-volume-c77257dd-f737-11e8-8d0a-02420af40402": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.016796912s
STEP: Saw pod success
Dec  3 20:12:41.655: INFO: Pod "downwardapi-volume-c77257dd-f737-11e8-8d0a-02420af40402" satisfied condition "success or failure"
Dec  3 20:12:41.658: INFO: Trying to get logs from node hungry-keller-3o9e pod downwardapi-volume-c77257dd-f737-11e8-8d0a-02420af40402 container client-container: <nil>
STEP: delete the pod
Dec  3 20:12:41.680: INFO: Waiting for pod downwardapi-volume-c77257dd-f737-11e8-8d0a-02420af40402 to disappear
Dec  3 20:12:41.685: INFO: Pod downwardapi-volume-c77257dd-f737-11e8-8d0a-02420af40402 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 20:12:41.685: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-xgrhz" for this suite.
Dec  3 20:12:47.699: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 20:12:47.747: INFO: namespace: e2e-tests-projected-xgrhz, resource: bindings, ignored listing per whitelist
Dec  3 20:12:47.802: INFO: namespace e2e-tests-projected-xgrhz deletion completed in 6.113699263s

• [SLOW TEST:10.250 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 20:12:47.803: INFO: >>> kubeConfig: /tmp/kubeconfig-166913721
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0644 on tmpfs
Dec  3 20:12:47.884: INFO: Waiting up to 5m0s for pod "pod-cd8f22eb-f737-11e8-8d0a-02420af40402" in namespace "e2e-tests-emptydir-nkb9c" to be "success or failure"
Dec  3 20:12:47.892: INFO: Pod "pod-cd8f22eb-f737-11e8-8d0a-02420af40402": Phase="Pending", Reason="", readiness=false. Elapsed: 7.642563ms
Dec  3 20:12:49.900: INFO: Pod "pod-cd8f22eb-f737-11e8-8d0a-02420af40402": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.015917055s
STEP: Saw pod success
Dec  3 20:12:49.900: INFO: Pod "pod-cd8f22eb-f737-11e8-8d0a-02420af40402" satisfied condition "success or failure"
Dec  3 20:12:49.903: INFO: Trying to get logs from node hungry-keller-3o9a pod pod-cd8f22eb-f737-11e8-8d0a-02420af40402 container test-container: <nil>
STEP: delete the pod
Dec  3 20:12:49.926: INFO: Waiting for pod pod-cd8f22eb-f737-11e8-8d0a-02420af40402 to disappear
Dec  3 20:12:49.930: INFO: Pod pod-cd8f22eb-f737-11e8-8d0a-02420af40402 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 20:12:49.931: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-nkb9c" for this suite.
Dec  3 20:12:55.944: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 20:12:55.961: INFO: namespace: e2e-tests-emptydir-nkb9c, resource: bindings, ignored listing per whitelist
Dec  3 20:12:56.035: INFO: namespace e2e-tests-emptydir-nkb9c deletion completed in 6.101229551s

• [SLOW TEST:8.233 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] ConfigMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 20:12:56.036: INFO: >>> kubeConfig: /tmp/kubeconfig-166913721
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-upd-d2793d84-f737-11e8-8d0a-02420af40402
STEP: Creating the pod
STEP: Updating configmap configmap-test-upd-d2793d84-f737-11e8-8d0a-02420af40402
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 20:13:02.180: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-hxxvd" for this suite.
Dec  3 20:13:40.194: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 20:13:40.271: INFO: namespace: e2e-tests-configmap-hxxvd, resource: bindings, ignored listing per whitelist
Dec  3 20:13:40.282: INFO: namespace e2e-tests-configmap-hxxvd deletion completed in 38.098091246s

• [SLOW TEST:44.246 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl api-versions 
  should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 20:13:40.282: INFO: >>> kubeConfig: /tmp/kubeconfig-166913721
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: validating api versions
Dec  3 20:13:40.349: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-166913721 api-versions'
Dec  3 20:13:40.450: INFO: stderr: ""
Dec  3 20:13:40.450: INFO: stdout: "admissionregistration.k8s.io/v1beta1\napiextensions.k8s.io/v1beta1\napiregistration.k8s.io/v1\napiregistration.k8s.io/v1beta1\napps/v1\napps/v1beta1\napps/v1beta2\nauthentication.k8s.io/v1\nauthentication.k8s.io/v1beta1\nauthorization.k8s.io/v1\nauthorization.k8s.io/v1beta1\nautoscaling/v1\nautoscaling/v2beta1\nautoscaling/v2beta2\nbatch/v1\nbatch/v1beta1\ncertificates.k8s.io/v1beta1\ncoordination.k8s.io/v1beta1\ncsi.storage.k8s.io/v1alpha1\nevents.k8s.io/v1beta1\nextensions/v1beta1\nnetworking.k8s.io/v1\npolicy/v1beta1\nrbac.authorization.k8s.io/v1\nrbac.authorization.k8s.io/v1beta1\nscheduling.k8s.io/v1beta1\nsnapshot.storage.k8s.io/v1alpha1\nstorage.k8s.io/v1\nstorage.k8s.io/v1beta1\nv1\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 20:13:40.450: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-prpmz" for this suite.
Dec  3 20:13:46.555: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 20:13:46.623: INFO: namespace: e2e-tests-kubectl-prpmz, resource: bindings, ignored listing per whitelist
Dec  3 20:13:46.637: INFO: namespace e2e-tests-kubectl-prpmz deletion completed in 6.092501876s

• [SLOW TEST:6.355 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl api-versions
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should check if v1 is in available api versions  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 20:13:46.637: INFO: >>> kubeConfig: /tmp/kubeconfig-166913721
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-j9nqr
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Dec  3 20:13:46.706: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Dec  3 20:14:08.814: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.244.72.4:8080/dial?request=hostName&protocol=udp&host=10.244.4.3&port=8081&tries=1'] Namespace:e2e-tests-pod-network-test-j9nqr PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec  3 20:14:08.814: INFO: >>> kubeConfig: /tmp/kubeconfig-166913721
Dec  3 20:14:09.058: INFO: Waiting for endpoints: map[]
Dec  3 20:14:09.062: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.244.72.4:8080/dial?request=hostName&protocol=udp&host=10.244.1.4&port=8081&tries=1'] Namespace:e2e-tests-pod-network-test-j9nqr PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec  3 20:14:09.062: INFO: >>> kubeConfig: /tmp/kubeconfig-166913721
Dec  3 20:14:09.325: INFO: Waiting for endpoints: map[]
Dec  3 20:14:09.328: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.244.72.4:8080/dial?request=hostName&protocol=udp&host=10.244.72.3&port=8081&tries=1'] Namespace:e2e-tests-pod-network-test-j9nqr PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec  3 20:14:09.328: INFO: >>> kubeConfig: /tmp/kubeconfig-166913721
Dec  3 20:14:09.587: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 20:14:09.587: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-j9nqr" for this suite.
Dec  3 20:14:31.603: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 20:14:31.684: INFO: namespace: e2e-tests-pod-network-test-j9nqr, resource: bindings, ignored listing per whitelist
Dec  3 20:14:31.694: INFO: namespace e2e-tests-pod-network-test-j9nqr deletion completed in 22.102509104s

• [SLOW TEST:45.057 seconds]
[sig-network] Networking
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: udp [NodeConformance] [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 20:14:31.697: INFO: >>> kubeConfig: /tmp/kubeconfig-166913721
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-np57l
[It] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Initializing watcher for selector baz=blah,foo=bar
STEP: Creating stateful set ss in namespace e2e-tests-statefulset-np57l
STEP: Waiting until all stateful set ss replicas will be running in namespace e2e-tests-statefulset-np57l
Dec  3 20:14:31.797: INFO: Found 0 stateful pods, waiting for 1
Dec  3 20:14:41.802: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will halt with unhealthy stateful pod
Dec  3 20:14:41.805: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-166913721 exec --namespace=e2e-tests-statefulset-np57l ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Dec  3 20:14:42.219: INFO: stderr: ""
Dec  3 20:14:42.219: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Dec  3 20:14:42.219: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Dec  3 20:14:42.223: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Dec  3 20:14:52.227: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Dec  3 20:14:52.227: INFO: Waiting for statefulset status.replicas updated to 0
Dec  3 20:14:52.246: INFO: Verifying statefulset ss doesn't scale past 1 for another 9.999999434s
Dec  3 20:14:53.251: INFO: Verifying statefulset ss doesn't scale past 1 for another 8.992224575s
Dec  3 20:14:54.256: INFO: Verifying statefulset ss doesn't scale past 1 for another 7.987383184s
Dec  3 20:14:55.260: INFO: Verifying statefulset ss doesn't scale past 1 for another 6.983010484s
Dec  3 20:14:56.263: INFO: Verifying statefulset ss doesn't scale past 1 for another 5.979076233s
Dec  3 20:14:57.268: INFO: Verifying statefulset ss doesn't scale past 1 for another 4.975198147s
Dec  3 20:14:58.272: INFO: Verifying statefulset ss doesn't scale past 1 for another 3.97108252s
Dec  3 20:14:59.276: INFO: Verifying statefulset ss doesn't scale past 1 for another 2.966957601s
Dec  3 20:15:00.282: INFO: Verifying statefulset ss doesn't scale past 1 for another 1.962273786s
Dec  3 20:15:01.286: INFO: Verifying statefulset ss doesn't scale past 1 for another 956.526008ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace e2e-tests-statefulset-np57l
Dec  3 20:15:02.290: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-166913721 exec --namespace=e2e-tests-statefulset-np57l ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec  3 20:15:02.646: INFO: stderr: ""
Dec  3 20:15:02.646: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Dec  3 20:15:02.646: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Dec  3 20:15:02.650: INFO: Found 1 stateful pods, waiting for 3
Dec  3 20:15:12.654: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Dec  3 20:15:12.654: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Dec  3 20:15:12.654: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Verifying that stateful set ss was scaled up in order
STEP: Scale down will halt with unhealthy stateful pod
Dec  3 20:15:12.659: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-166913721 exec --namespace=e2e-tests-statefulset-np57l ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Dec  3 20:15:13.000: INFO: stderr: ""
Dec  3 20:15:13.000: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Dec  3 20:15:13.000: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Dec  3 20:15:13.000: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-166913721 exec --namespace=e2e-tests-statefulset-np57l ss-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Dec  3 20:15:13.318: INFO: stderr: ""
Dec  3 20:15:13.318: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Dec  3 20:15:13.318: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Dec  3 20:15:13.319: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-166913721 exec --namespace=e2e-tests-statefulset-np57l ss-2 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Dec  3 20:15:13.652: INFO: stderr: ""
Dec  3 20:15:13.652: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Dec  3 20:15:13.652: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-2: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Dec  3 20:15:13.652: INFO: Waiting for statefulset status.replicas updated to 0
Dec  3 20:15:13.656: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 3
Dec  3 20:15:23.662: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Dec  3 20:15:23.662: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Dec  3 20:15:23.662: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Dec  3 20:15:23.682: INFO: Verifying statefulset ss doesn't scale past 3 for another 9.999999757s
Dec  3 20:15:24.687: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.988594317s
Dec  3 20:15:25.691: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.984539038s
Dec  3 20:15:26.695: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.980407275s
Dec  3 20:15:27.699: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.97605407s
Dec  3 20:15:28.706: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.972163672s
Dec  3 20:15:29.710: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.964533323s
Dec  3 20:15:30.714: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.960874378s
Dec  3 20:15:31.718: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.957246558s
Dec  3 20:15:32.723: INFO: Verifying statefulset ss doesn't scale past 3 for another 953.256158ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacee2e-tests-statefulset-np57l
Dec  3 20:15:33.728: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-166913721 exec --namespace=e2e-tests-statefulset-np57l ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec  3 20:15:34.085: INFO: stderr: ""
Dec  3 20:15:34.085: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Dec  3 20:15:34.085: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Dec  3 20:15:34.085: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-166913721 exec --namespace=e2e-tests-statefulset-np57l ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec  3 20:15:34.405: INFO: stderr: ""
Dec  3 20:15:34.405: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Dec  3 20:15:34.405: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Dec  3 20:15:34.405: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-166913721 exec --namespace=e2e-tests-statefulset-np57l ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec  3 20:15:34.704: INFO: stderr: ""
Dec  3 20:15:34.704: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Dec  3 20:15:34.704: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-2: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Dec  3 20:15:34.704: INFO: Scaling statefulset ss to 0
STEP: Verifying that stateful set ss was scaled down in reverse order
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Dec  3 20:16:04.777: INFO: Deleting all statefulset in ns e2e-tests-statefulset-np57l
Dec  3 20:16:04.780: INFO: Scaling statefulset ss to 0
Dec  3 20:16:04.788: INFO: Waiting for statefulset status.replicas updated to 0
Dec  3 20:16:04.790: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 20:16:04.808: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-np57l" for this suite.
Dec  3 20:16:10.890: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 20:16:10.924: INFO: namespace: e2e-tests-statefulset-np57l, resource: bindings, ignored listing per whitelist
Dec  3 20:16:11.003: INFO: namespace e2e-tests-statefulset-np57l deletion completed in 6.124594949s

• [SLOW TEST:99.306 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 20:16:11.003: INFO: >>> kubeConfig: /tmp/kubeconfig-166913721
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:78
Dec  3 20:16:11.078: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Dec  3 20:16:11.084: INFO: Waiting for terminating namespaces to be deleted...
Dec  3 20:16:11.087: INFO: 
Logging pods the kubelet thinks is on node hungry-keller-3o96 before test
Dec  3 20:16:11.095: INFO: kube-proxy-hungry-keller-3o96 from kube-system started at <nil> (0 container statuses recorded)
Dec  3 20:16:11.095: INFO: csi-do-controller-0 from kube-system started at 2018-12-03 19:18:27 +0000 UTC (4 container statuses recorded)
Dec  3 20:16:11.095: INFO: 	Container csi-attacher ready: true, restart count 0
Dec  3 20:16:11.095: INFO: 	Container csi-do-plugin ready: true, restart count 0
Dec  3 20:16:11.095: INFO: 	Container csi-provisioner ready: true, restart count 0
Dec  3 20:16:11.095: INFO: 	Container csi-snapshotter ready: true, restart count 2
Dec  3 20:16:11.095: INFO: kube-dns-55cf9576c4-wx9kt from kube-system started at 2018-12-03 19:18:27 +0000 UTC (3 container statuses recorded)
Dec  3 20:16:11.095: INFO: 	Container dnsmasq ready: true, restart count 0
Dec  3 20:16:11.095: INFO: 	Container kubedns ready: true, restart count 0
Dec  3 20:16:11.095: INFO: 	Container sidecar ready: true, restart count 0
Dec  3 20:16:11.095: INFO: csi-do-node-rt2f8 from kube-system started at 2018-12-03 19:18:39 +0000 UTC (2 container statuses recorded)
Dec  3 20:16:11.095: INFO: 	Container csi-do-plugin ready: true, restart count 0
Dec  3 20:16:11.095: INFO: 	Container driver-registrar ready: true, restart count 2
Dec  3 20:16:11.095: INFO: sonobuoy-systemd-logs-daemon-set-15edf0f0fb534ac8-s4x2r from heptio-sonobuoy started at 2018-12-03 19:38:50 +0000 UTC (2 container statuses recorded)
Dec  3 20:16:11.095: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 0
Dec  3 20:16:11.095: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Dec  3 20:16:11.095: INFO: 
Logging pods the kubelet thinks is on node hungry-keller-3o9a before test
Dec  3 20:16:11.102: INFO: sonobuoy-systemd-logs-daemon-set-15edf0f0fb534ac8-g5n59 from heptio-sonobuoy started at 2018-12-03 19:38:50 +0000 UTC (2 container statuses recorded)
Dec  3 20:16:11.102: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 0
Dec  3 20:16:11.102: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Dec  3 20:16:11.102: INFO: kube-proxy-hungry-keller-3o9a from kube-system started at <nil> (0 container statuses recorded)
Dec  3 20:16:11.102: INFO: csi-do-node-8zhsm from kube-system started at 2018-12-03 19:18:33 +0000 UTC (2 container statuses recorded)
Dec  3 20:16:11.102: INFO: 	Container csi-do-plugin ready: true, restart count 0
Dec  3 20:16:11.102: INFO: 	Container driver-registrar ready: true, restart count 0
Dec  3 20:16:11.102: INFO: sonobuoy from heptio-sonobuoy started at 2018-12-03 19:38:46 +0000 UTC (1 container statuses recorded)
Dec  3 20:16:11.102: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Dec  3 20:16:11.102: INFO: 
Logging pods the kubelet thinks is on node hungry-keller-3o9e before test
Dec  3 20:16:11.112: INFO: kube-proxy-hungry-keller-3o9e from kube-system started at <nil> (0 container statuses recorded)
Dec  3 20:16:11.112: INFO: csi-do-node-2vwn4 from kube-system started at 2018-12-03 19:18:41 +0000 UTC (2 container statuses recorded)
Dec  3 20:16:11.112: INFO: 	Container csi-do-plugin ready: true, restart count 0
Dec  3 20:16:11.112: INFO: 	Container driver-registrar ready: true, restart count 0
Dec  3 20:16:11.112: INFO: sonobuoy-e2e-job-ef309e1fd8f04e08 from heptio-sonobuoy started at 2018-12-03 19:38:49 +0000 UTC (2 container statuses recorded)
Dec  3 20:16:11.112: INFO: 	Container e2e ready: true, restart count 0
Dec  3 20:16:11.112: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Dec  3 20:16:11.112: INFO: sonobuoy-systemd-logs-daemon-set-15edf0f0fb534ac8-nncfq from heptio-sonobuoy started at 2018-12-03 19:38:50 +0000 UTC (2 container statuses recorded)
Dec  3 20:16:11.112: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 0
Dec  3 20:16:11.112: INFO: 	Container sonobuoy-worker ready: true, restart count 0
[It] validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: verifying the node has the label node hungry-keller-3o96
STEP: verifying the node has the label node hungry-keller-3o9a
STEP: verifying the node has the label node hungry-keller-3o9e
Dec  3 20:16:11.152: INFO: Pod sonobuoy requesting resource cpu=0m on Node hungry-keller-3o9a
Dec  3 20:16:11.152: INFO: Pod sonobuoy-e2e-job-ef309e1fd8f04e08 requesting resource cpu=0m on Node hungry-keller-3o9e
Dec  3 20:16:11.152: INFO: Pod sonobuoy-systemd-logs-daemon-set-15edf0f0fb534ac8-g5n59 requesting resource cpu=0m on Node hungry-keller-3o9a
Dec  3 20:16:11.152: INFO: Pod sonobuoy-systemd-logs-daemon-set-15edf0f0fb534ac8-nncfq requesting resource cpu=0m on Node hungry-keller-3o9e
Dec  3 20:16:11.152: INFO: Pod sonobuoy-systemd-logs-daemon-set-15edf0f0fb534ac8-s4x2r requesting resource cpu=0m on Node hungry-keller-3o96
Dec  3 20:16:11.152: INFO: Pod csi-do-controller-0 requesting resource cpu=0m on Node hungry-keller-3o96
Dec  3 20:16:11.152: INFO: Pod csi-do-node-2vwn4 requesting resource cpu=0m on Node hungry-keller-3o9e
Dec  3 20:16:11.152: INFO: Pod csi-do-node-8zhsm requesting resource cpu=0m on Node hungry-keller-3o9a
Dec  3 20:16:11.152: INFO: Pod csi-do-node-rt2f8 requesting resource cpu=0m on Node hungry-keller-3o96
Dec  3 20:16:11.152: INFO: Pod kube-dns-55cf9576c4-wx9kt requesting resource cpu=260m on Node hungry-keller-3o96
Dec  3 20:16:11.152: INFO: Pod kube-proxy-hungry-keller-3o96 requesting resource cpu=0m on Node hungry-keller-3o96
Dec  3 20:16:11.152: INFO: Pod kube-proxy-hungry-keller-3o9a requesting resource cpu=0m on Node hungry-keller-3o9a
Dec  3 20:16:11.152: INFO: Pod kube-proxy-hungry-keller-3o9e requesting resource cpu=0m on Node hungry-keller-3o9e
STEP: Starting Pods to consume most of the cluster CPU.
STEP: Creating another pod that requires unavailable amount of CPU.
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-46b88d00-f738-11e8-8d0a-02420af40402.156cebec030cfe15], Reason = [Scheduled], Message = [Successfully assigned e2e-tests-sched-pred-7645h/filler-pod-46b88d00-f738-11e8-8d0a-02420af40402 to hungry-keller-3o9e]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-46b88d00-f738-11e8-8d0a-02420af40402.156cebec6bb9c1d2], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-46b88d00-f738-11e8-8d0a-02420af40402.156cebec6f5b4d0f], Reason = [Created], Message = [Created container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-46b88d00-f738-11e8-8d0a-02420af40402.156cebec7eabbe2c], Reason = [Started], Message = [Started container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-46b9af3b-f738-11e8-8d0a-02420af40402.156cebec04935ecd], Reason = [Scheduled], Message = [Successfully assigned e2e-tests-sched-pred-7645h/filler-pod-46b9af3b-f738-11e8-8d0a-02420af40402 to hungry-keller-3o96]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-46b9af3b-f738-11e8-8d0a-02420af40402.156cebec6cbb724d], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-46b9af3b-f738-11e8-8d0a-02420af40402.156cebec71587091], Reason = [Created], Message = [Created container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-46b9af3b-f738-11e8-8d0a-02420af40402.156cebec802517b8], Reason = [Started], Message = [Started container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-46bd5bb9-f738-11e8-8d0a-02420af40402.156cebec057bbebf], Reason = [Scheduled], Message = [Successfully assigned e2e-tests-sched-pred-7645h/filler-pod-46bd5bb9-f738-11e8-8d0a-02420af40402 to hungry-keller-3o9a]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-46bd5bb9-f738-11e8-8d0a-02420af40402.156cebec3a1bab58], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-46bd5bb9-f738-11e8-8d0a-02420af40402.156cebec3d67e92a], Reason = [Created], Message = [Created container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-46bd5bb9-f738-11e8-8d0a-02420af40402.156cebec4e3ad579], Reason = [Started], Message = [Started container]
STEP: Considering event: 
Type = [Warning], Name = [additional-pod.156cebecf647e679], Reason = [FailedScheduling], Message = [0/3 nodes are available: 3 Insufficient cpu.]
STEP: removing the label node off the node hungry-keller-3o9e
STEP: verifying the node doesn't have the label node
STEP: removing the label node off the node hungry-keller-3o96
STEP: verifying the node doesn't have the label node
STEP: removing the label node off the node hungry-keller-3o9a
STEP: verifying the node doesn't have the label node
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 20:16:16.311: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-sched-pred-7645h" for this suite.
Dec  3 20:16:22.349: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 20:16:22.385: INFO: namespace: e2e-tests-sched-pred-7645h, resource: bindings, ignored listing per whitelist
Dec  3 20:16:22.435: INFO: namespace e2e-tests-sched-pred-7645h deletion completed in 6.102627104s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:69

• [SLOW TEST:11.432 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[k8s.io] Pods 
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 20:16:22.436: INFO: >>> kubeConfig: /tmp/kubeconfig-166913721
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Dec  3 20:16:25.039: INFO: Successfully updated pod "pod-update-activedeadlineseconds-4d7ccbc8-f738-11e8-8d0a-02420af40402"
Dec  3 20:16:25.039: INFO: Waiting up to 5m0s for pod "pod-update-activedeadlineseconds-4d7ccbc8-f738-11e8-8d0a-02420af40402" in namespace "e2e-tests-pods-tbghs" to be "terminated due to deadline exceeded"
Dec  3 20:16:25.042: INFO: Pod "pod-update-activedeadlineseconds-4d7ccbc8-f738-11e8-8d0a-02420af40402": Phase="Running", Reason="", readiness=true. Elapsed: 2.731899ms
Dec  3 20:16:27.046: INFO: Pod "pod-update-activedeadlineseconds-4d7ccbc8-f738-11e8-8d0a-02420af40402": Phase="Running", Reason="", readiness=true. Elapsed: 2.006942135s
Dec  3 20:16:29.049: INFO: Pod "pod-update-activedeadlineseconds-4d7ccbc8-f738-11e8-8d0a-02420af40402": Phase="Failed", Reason="DeadlineExceeded", readiness=false. Elapsed: 4.010405305s
Dec  3 20:16:29.050: INFO: Pod "pod-update-activedeadlineseconds-4d7ccbc8-f738-11e8-8d0a-02420af40402" satisfied condition "terminated due to deadline exceeded"
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 20:16:29.050: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-tbghs" for this suite.
Dec  3 20:16:35.063: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 20:16:35.096: INFO: namespace: e2e-tests-pods-tbghs, resource: bindings, ignored listing per whitelist
Dec  3 20:16:35.154: INFO: namespace e2e-tests-pods-tbghs deletion completed in 6.100733709s

• [SLOW TEST:12.718 seconds]
[k8s.io] Pods
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should have monotonically increasing restart count [Slow][NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 20:16:35.154: INFO: >>> kubeConfig: /tmp/kubeconfig-166913721
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should have monotonically increasing restart count [Slow][NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-http in namespace e2e-tests-container-probe-qznj4
Dec  3 20:16:37.304: INFO: Started pod liveness-http in namespace e2e-tests-container-probe-qznj4
STEP: checking the pod's current state and verifying that restartCount is present
Dec  3 20:16:37.307: INFO: Initial restart count of pod liveness-http is 0
Dec  3 20:16:49.346: INFO: Restart count of pod e2e-tests-container-probe-qznj4/liveness-http is now 1 (12.039102s elapsed)
Dec  3 20:17:09.425: INFO: Restart count of pod e2e-tests-container-probe-qznj4/liveness-http is now 2 (32.117757653s elapsed)
Dec  3 20:17:27.457: INFO: Restart count of pod e2e-tests-container-probe-qznj4/liveness-http is now 3 (50.149959103s elapsed)
Dec  3 20:17:49.497: INFO: Restart count of pod e2e-tests-container-probe-qznj4/liveness-http is now 4 (1m12.189981028s elapsed)
Dec  3 20:18:49.611: INFO: Restart count of pod e2e-tests-container-probe-qznj4/liveness-http is now 5 (2m12.3037193s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 20:18:49.646: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-qznj4" for this suite.
Dec  3 20:18:55.662: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 20:18:55.706: INFO: namespace: e2e-tests-container-probe-qznj4, resource: bindings, ignored listing per whitelist
Dec  3 20:18:55.764: INFO: namespace e2e-tests-container-probe-qznj4 deletion completed in 6.112897289s

• [SLOW TEST:140.610 seconds]
[k8s.io] Probing container
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should have monotonically increasing restart count [Slow][NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 20:18:55.765: INFO: >>> kubeConfig: /tmp/kubeconfig-166913721
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Dec  3 20:18:55.895: INFO: Waiting up to 5m0s for pod "downwardapi-volume-a8e91b3a-f738-11e8-8d0a-02420af40402" in namespace "e2e-tests-downward-api-76l6z" to be "success or failure"
Dec  3 20:18:55.905: INFO: Pod "downwardapi-volume-a8e91b3a-f738-11e8-8d0a-02420af40402": Phase="Pending", Reason="", readiness=false. Elapsed: 9.86706ms
Dec  3 20:18:57.908: INFO: Pod "downwardapi-volume-a8e91b3a-f738-11e8-8d0a-02420af40402": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01350215s
Dec  3 20:18:59.912: INFO: Pod "downwardapi-volume-a8e91b3a-f738-11e8-8d0a-02420af40402": Phase="Pending", Reason="", readiness=false. Elapsed: 4.017084688s
Dec  3 20:19:01.915: INFO: Pod "downwardapi-volume-a8e91b3a-f738-11e8-8d0a-02420af40402": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.020785194s
STEP: Saw pod success
Dec  3 20:19:01.916: INFO: Pod "downwardapi-volume-a8e91b3a-f738-11e8-8d0a-02420af40402" satisfied condition "success or failure"
Dec  3 20:19:01.918: INFO: Trying to get logs from node hungry-keller-3o9a pod downwardapi-volume-a8e91b3a-f738-11e8-8d0a-02420af40402 container client-container: <nil>
STEP: delete the pod
Dec  3 20:19:01.943: INFO: Waiting for pod downwardapi-volume-a8e91b3a-f738-11e8-8d0a-02420af40402 to disappear
Dec  3 20:19:01.947: INFO: Pod downwardapi-volume-a8e91b3a-f738-11e8-8d0a-02420af40402 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 20:19:01.947: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-76l6z" for this suite.
Dec  3 20:19:08.000: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 20:19:08.056: INFO: namespace: e2e-tests-downward-api-76l6z, resource: bindings, ignored listing per whitelist
Dec  3 20:19:08.096: INFO: namespace e2e-tests-downward-api-76l6z deletion completed in 6.144832911s

• [SLOW TEST:12.331 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Burst scaling should run to completion even with unhealthy pods [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 20:19:08.097: INFO: >>> kubeConfig: /tmp/kubeconfig-166913721
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-2jxn5
[It] Burst scaling should run to completion even with unhealthy pods [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating stateful set ss in namespace e2e-tests-statefulset-2jxn5
STEP: Waiting until all stateful set ss replicas will be running in namespace e2e-tests-statefulset-2jxn5
Dec  3 20:19:08.265: INFO: Found 0 stateful pods, waiting for 1
Dec  3 20:19:18.270: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will not halt with unhealthy stateful pod
Dec  3 20:19:18.274: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-166913721 exec --namespace=e2e-tests-statefulset-2jxn5 ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Dec  3 20:19:18.645: INFO: stderr: ""
Dec  3 20:19:18.645: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Dec  3 20:19:18.645: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Dec  3 20:19:18.649: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Dec  3 20:19:28.653: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Dec  3 20:19:28.653: INFO: Waiting for statefulset status.replicas updated to 0
Dec  3 20:19:28.680: INFO: Verifying statefulset ss doesn't scale past 3 for another 9.999998877s
Dec  3 20:19:29.685: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.983794281s
Dec  3 20:19:30.747: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.97939164s
Dec  3 20:19:31.919: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.916659496s
Dec  3 20:19:32.924: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.74465283s
Dec  3 20:19:33.929: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.740282857s
Dec  3 20:19:34.933: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.734638919s
Dec  3 20:19:35.945: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.73046028s
Dec  3 20:19:36.949: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.718748177s
Dec  3 20:19:37.953: INFO: Verifying statefulset ss doesn't scale past 3 for another 714.483562ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace e2e-tests-statefulset-2jxn5
Dec  3 20:19:38.958: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-166913721 exec --namespace=e2e-tests-statefulset-2jxn5 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec  3 20:19:39.291: INFO: stderr: ""
Dec  3 20:19:39.291: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Dec  3 20:19:39.291: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Dec  3 20:19:39.291: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-166913721 exec --namespace=e2e-tests-statefulset-2jxn5 ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec  3 20:19:39.648: INFO: stderr: "mv: can't rename '/tmp/index.html': No such file or directory\n"
Dec  3 20:19:39.648: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Dec  3 20:19:39.648: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Dec  3 20:19:39.648: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-166913721 exec --namespace=e2e-tests-statefulset-2jxn5 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec  3 20:19:39.970: INFO: stderr: "mv: can't rename '/tmp/index.html': No such file or directory\n"
Dec  3 20:19:39.970: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Dec  3 20:19:39.970: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-2: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Dec  3 20:19:39.974: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Dec  3 20:19:39.974: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Dec  3 20:19:39.974: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Scale down will not halt with unhealthy stateful pod
Dec  3 20:19:39.978: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-166913721 exec --namespace=e2e-tests-statefulset-2jxn5 ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Dec  3 20:19:40.299: INFO: stderr: ""
Dec  3 20:19:40.299: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Dec  3 20:19:40.299: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Dec  3 20:19:40.299: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-166913721 exec --namespace=e2e-tests-statefulset-2jxn5 ss-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Dec  3 20:19:40.984: INFO: stderr: ""
Dec  3 20:19:40.984: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Dec  3 20:19:40.984: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Dec  3 20:19:40.984: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-166913721 exec --namespace=e2e-tests-statefulset-2jxn5 ss-2 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Dec  3 20:19:41.296: INFO: stderr: ""
Dec  3 20:19:41.296: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Dec  3 20:19:41.296: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-2: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Dec  3 20:19:41.296: INFO: Waiting for statefulset status.replicas updated to 0
Dec  3 20:19:41.315: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 2
Dec  3 20:19:51.322: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Dec  3 20:19:51.322: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Dec  3 20:19:51.322: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Dec  3 20:19:51.345: INFO: POD   NODE                PHASE    GRACE  CONDITIONS
Dec  3 20:19:51.345: INFO: ss-0  hungry-keller-3o9a  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-03 20:19:08 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-03 20:19:40 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-03 20:19:40 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-03 20:19:08 +0000 UTC  }]
Dec  3 20:19:51.345: INFO: ss-1  hungry-keller-3o9e  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-03 20:19:28 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-03 20:19:41 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-03 20:19:41 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-03 20:19:28 +0000 UTC  }]
Dec  3 20:19:51.345: INFO: ss-2  hungry-keller-3o96  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-03 20:19:28 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-03 20:19:41 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-03 20:19:41 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-03 20:19:28 +0000 UTC  }]
Dec  3 20:19:51.345: INFO: 
Dec  3 20:19:51.345: INFO: StatefulSet ss has not reached scale 0, at 3
Dec  3 20:19:52.349: INFO: POD   NODE                PHASE    GRACE  CONDITIONS
Dec  3 20:19:52.349: INFO: ss-0  hungry-keller-3o9a  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-03 20:19:08 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-03 20:19:40 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-03 20:19:40 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-03 20:19:08 +0000 UTC  }]
Dec  3 20:19:52.349: INFO: ss-1  hungry-keller-3o9e  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-03 20:19:28 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-03 20:19:41 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-03 20:19:41 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-03 20:19:28 +0000 UTC  }]
Dec  3 20:19:52.349: INFO: ss-2  hungry-keller-3o96  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-03 20:19:28 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-03 20:19:41 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-03 20:19:41 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-03 20:19:28 +0000 UTC  }]
Dec  3 20:19:52.349: INFO: 
Dec  3 20:19:52.349: INFO: StatefulSet ss has not reached scale 0, at 3
Dec  3 20:19:53.353: INFO: POD   NODE                PHASE    GRACE  CONDITIONS
Dec  3 20:19:53.353: INFO: ss-0  hungry-keller-3o9a  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-03 20:19:08 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-03 20:19:40 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-03 20:19:40 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-03 20:19:08 +0000 UTC  }]
Dec  3 20:19:53.353: INFO: ss-1  hungry-keller-3o9e  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-03 20:19:28 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-03 20:19:41 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-03 20:19:41 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-03 20:19:28 +0000 UTC  }]
Dec  3 20:19:53.353: INFO: ss-2  hungry-keller-3o96  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-03 20:19:28 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-03 20:19:41 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-03 20:19:41 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-03 20:19:28 +0000 UTC  }]
Dec  3 20:19:53.354: INFO: 
Dec  3 20:19:53.354: INFO: StatefulSet ss has not reached scale 0, at 3
Dec  3 20:19:54.357: INFO: POD   NODE                PHASE    GRACE  CONDITIONS
Dec  3 20:19:54.357: INFO: ss-0  hungry-keller-3o9a  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-03 20:19:08 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-03 20:19:40 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-03 20:19:40 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-03 20:19:08 +0000 UTC  }]
Dec  3 20:19:54.357: INFO: ss-1  hungry-keller-3o9e  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-03 20:19:28 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-03 20:19:41 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-03 20:19:41 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-03 20:19:28 +0000 UTC  }]
Dec  3 20:19:54.357: INFO: 
Dec  3 20:19:54.357: INFO: StatefulSet ss has not reached scale 0, at 2
Dec  3 20:19:55.361: INFO: POD   NODE                PHASE    GRACE  CONDITIONS
Dec  3 20:19:55.361: INFO: ss-0  hungry-keller-3o9a  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-03 20:19:08 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-03 20:19:40 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-03 20:19:40 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-03 20:19:08 +0000 UTC  }]
Dec  3 20:19:55.361: INFO: ss-1  hungry-keller-3o9e  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-03 20:19:28 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-03 20:19:41 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-03 20:19:41 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-03 20:19:28 +0000 UTC  }]
Dec  3 20:19:55.361: INFO: 
Dec  3 20:19:55.361: INFO: StatefulSet ss has not reached scale 0, at 2
Dec  3 20:19:56.365: INFO: POD   NODE                PHASE    GRACE  CONDITIONS
Dec  3 20:19:56.365: INFO: ss-0  hungry-keller-3o9a  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-03 20:19:08 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-03 20:19:40 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-03 20:19:40 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-03 20:19:08 +0000 UTC  }]
Dec  3 20:19:56.365: INFO: ss-1  hungry-keller-3o9e  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-03 20:19:28 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-03 20:19:41 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-03 20:19:41 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-03 20:19:28 +0000 UTC  }]
Dec  3 20:19:56.365: INFO: 
Dec  3 20:19:56.365: INFO: StatefulSet ss has not reached scale 0, at 2
Dec  3 20:19:57.370: INFO: POD   NODE                PHASE    GRACE  CONDITIONS
Dec  3 20:19:57.370: INFO: ss-0  hungry-keller-3o9a  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-03 20:19:08 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-03 20:19:40 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-03 20:19:40 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-03 20:19:08 +0000 UTC  }]
Dec  3 20:19:57.370: INFO: ss-1  hungry-keller-3o9e  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-03 20:19:28 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-03 20:19:41 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-03 20:19:41 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-03 20:19:28 +0000 UTC  }]
Dec  3 20:19:57.370: INFO: 
Dec  3 20:19:57.370: INFO: StatefulSet ss has not reached scale 0, at 2
Dec  3 20:19:58.373: INFO: POD   NODE                PHASE    GRACE  CONDITIONS
Dec  3 20:19:58.373: INFO: ss-0  hungry-keller-3o9a  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-03 20:19:08 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-03 20:19:40 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-03 20:19:40 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-03 20:19:08 +0000 UTC  }]
Dec  3 20:19:58.374: INFO: 
Dec  3 20:19:58.374: INFO: StatefulSet ss has not reached scale 0, at 1
Dec  3 20:19:59.377: INFO: POD   NODE                PHASE    GRACE  CONDITIONS
Dec  3 20:19:59.377: INFO: ss-0  hungry-keller-3o9a  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-03 20:19:08 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-03 20:19:40 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-03 20:19:40 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-03 20:19:08 +0000 UTC  }]
Dec  3 20:19:59.377: INFO: 
Dec  3 20:19:59.377: INFO: StatefulSet ss has not reached scale 0, at 1
Dec  3 20:20:00.381: INFO: POD   NODE                PHASE    GRACE  CONDITIONS
Dec  3 20:20:00.382: INFO: ss-0  hungry-keller-3o9a  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-03 20:19:08 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-03 20:19:40 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-03 20:19:40 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-03 20:19:08 +0000 UTC  }]
Dec  3 20:20:00.382: INFO: 
Dec  3 20:20:00.382: INFO: StatefulSet ss has not reached scale 0, at 1
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacee2e-tests-statefulset-2jxn5
Dec  3 20:20:01.386: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-166913721 exec --namespace=e2e-tests-statefulset-2jxn5 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec  3 20:20:01.564: INFO: rc: 1
Dec  3 20:20:01.564: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-166913721 exec --namespace=e2e-tests-statefulset-2jxn5 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  error: unable to upgrade connection: container not found ("nginx")
 [] <nil> 0xc4215401b0 exit status 1 <nil> <nil> true [0xc42121f740 0xc42121f768 0xc42121f780] [0xc42121f740 0xc42121f768 0xc42121f780] [0xc42121f760 0xc42121f778] [0x8fd520 0x8fd520] 0xc4211fd2c0 <nil>}:
Command stdout:

stderr:
error: unable to upgrade connection: container not found ("nginx")

error:
exit status 1

Dec  3 20:20:11.575: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-166913721 exec --namespace=e2e-tests-statefulset-2jxn5 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec  3 20:20:11.709: INFO: rc: 1
Dec  3 20:20:11.709: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-166913721 exec --namespace=e2e-tests-statefulset-2jxn5 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc42151c4b0 exit status 1 <nil> <nil> true [0xc42045d3f8 0xc42045d430 0xc42045d448] [0xc42045d3f8 0xc42045d430 0xc42045d448] [0xc42045d418 0xc42045d440] [0x8fd520 0x8fd520] 0xc4216a30e0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Dec  3 20:20:21.709: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-166913721 exec --namespace=e2e-tests-statefulset-2jxn5 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec  3 20:20:21.815: INFO: rc: 1
Dec  3 20:20:21.815: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-166913721 exec --namespace=e2e-tests-statefulset-2jxn5 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc420f20390 exit status 1 <nil> <nil> true [0xc420804638 0xc420804760 0xc420804870] [0xc420804638 0xc420804760 0xc420804870] [0xc420804728 0xc420804808] [0x8fd520 0x8fd520] 0xc421962240 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Dec  3 20:20:31.815: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-166913721 exec --namespace=e2e-tests-statefulset-2jxn5 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec  3 20:20:31.935: INFO: rc: 1
Dec  3 20:20:31.935: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-166913721 exec --namespace=e2e-tests-statefulset-2jxn5 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc420f20cf0 exit status 1 <nil> <nil> true [0xc420804880 0xc4208049d8 0xc420804a68] [0xc420804880 0xc4208049d8 0xc420804a68] [0xc420804948 0xc420804a30] [0x8fd520 0x8fd520] 0xc4219625a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Dec  3 20:20:41.936: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-166913721 exec --namespace=e2e-tests-statefulset-2jxn5 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec  3 20:20:42.066: INFO: rc: 1
Dec  3 20:20:42.066: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-166913721 exec --namespace=e2e-tests-statefulset-2jxn5 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc420c5e3c0 exit status 1 <nil> <nil> true [0xc42000e108 0xc42000e2b8 0xc42047c2a0] [0xc42000e108 0xc42000e2b8 0xc42047c2a0] [0xc42000e288 0xc42047c120] [0x8fd520 0x8fd520] 0xc4213d0ba0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Dec  3 20:20:52.067: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-166913721 exec --namespace=e2e-tests-statefulset-2jxn5 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec  3 20:20:52.168: INFO: rc: 1
Dec  3 20:20:52.168: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-166913721 exec --namespace=e2e-tests-statefulset-2jxn5 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc420f21200 exit status 1 <nil> <nil> true [0xc420804b30 0xc420804c90 0xc420804cd8] [0xc420804b30 0xc420804c90 0xc420804cd8] [0xc420804c10 0xc420804cc8] [0x8fd520 0x8fd520] 0xc421962c00 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Dec  3 20:21:02.168: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-166913721 exec --namespace=e2e-tests-statefulset-2jxn5 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec  3 20:21:02.273: INFO: rc: 1
Dec  3 20:21:02.273: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-166913721 exec --namespace=e2e-tests-statefulset-2jxn5 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc420c5e780 exit status 1 <nil> <nil> true [0xc42047c3c0 0xc42047c660 0xc42047c7e0] [0xc42047c3c0 0xc42047c660 0xc42047c7e0] [0xc42047c5b8 0xc42047c730] [0x8fd520 0x8fd520] 0xc4213d0cc0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Dec  3 20:21:12.273: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-166913721 exec --namespace=e2e-tests-statefulset-2jxn5 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec  3 20:21:12.384: INFO: rc: 1
Dec  3 20:21:12.384: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-166913721 exec --namespace=e2e-tests-statefulset-2jxn5 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc420f21620 exit status 1 <nil> <nil> true [0xc420804d08 0xc420804db0 0xc420804e48] [0xc420804d08 0xc420804db0 0xc420804e48] [0xc420804d98 0xc420804df0] [0x8fd520 0x8fd520] 0xc4212509c0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Dec  3 20:21:22.384: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-166913721 exec --namespace=e2e-tests-statefulset-2jxn5 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec  3 20:21:22.497: INFO: rc: 1
Dec  3 20:21:22.497: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-166913721 exec --namespace=e2e-tests-statefulset-2jxn5 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc420c5ee10 exit status 1 <nil> <nil> true [0xc42047c7f0 0xc42047ca98 0xc42047cd10] [0xc42047c7f0 0xc42047ca98 0xc42047cd10] [0xc42047ca68 0xc42047cb50] [0x8fd520 0x8fd520] 0xc4213d0de0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Dec  3 20:21:32.498: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-166913721 exec --namespace=e2e-tests-statefulset-2jxn5 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec  3 20:21:32.600: INFO: rc: 1
Dec  3 20:21:32.600: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-166913721 exec --namespace=e2e-tests-statefulset-2jxn5 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc420f21bf0 exit status 1 <nil> <nil> true [0xc420804e68 0xc420804ec0 0xc420804ef8] [0xc420804e68 0xc420804ec0 0xc420804ef8] [0xc420804eb0 0xc420804ee0] [0x8fd520 0x8fd520] 0xc421250ea0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Dec  3 20:21:42.600: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-166913721 exec --namespace=e2e-tests-statefulset-2jxn5 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec  3 20:21:42.687: INFO: rc: 1
Dec  3 20:21:42.687: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-166913721 exec --namespace=e2e-tests-statefulset-2jxn5 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc420f21f80 exit status 1 <nil> <nil> true [0xc420804f28 0xc420804fa0 0xc420804ff8] [0xc420804f28 0xc420804fa0 0xc420804ff8] [0xc420804f80 0xc420804fc8] [0x8fd520 0x8fd520] 0xc4212511a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Dec  3 20:21:52.687: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-166913721 exec --namespace=e2e-tests-statefulset-2jxn5 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec  3 20:21:52.801: INFO: rc: 1
Dec  3 20:21:52.801: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-166913721 exec --namespace=e2e-tests-statefulset-2jxn5 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc420f46600 exit status 1 <nil> <nil> true [0xc42121e000 0xc42121e038 0xc42121e070] [0xc42121e000 0xc42121e038 0xc42121e070] [0xc42121e030 0xc42121e058] [0x8fd520 0x8fd520] 0xc42190e120 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Dec  3 20:22:02.802: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-166913721 exec --namespace=e2e-tests-statefulset-2jxn5 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec  3 20:22:02.901: INFO: rc: 1
Dec  3 20:22:02.901: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-166913721 exec --namespace=e2e-tests-statefulset-2jxn5 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc420f469f0 exit status 1 <nil> <nil> true [0xc42121e078 0xc42121e0b0 0xc42121e0d8] [0xc42121e078 0xc42121e0b0 0xc42121e0d8] [0xc42121e098 0xc42121e0c0] [0x8fd520 0x8fd520] 0xc42190e240 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Dec  3 20:22:12.902: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-166913721 exec --namespace=e2e-tests-statefulset-2jxn5 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec  3 20:22:13.015: INFO: rc: 1
Dec  3 20:22:13.015: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-166913721 exec --namespace=e2e-tests-statefulset-2jxn5 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc420ebe060 exit status 1 <nil> <nil> true [0xc42047ce28 0xc42047d080 0xc42047d2d8] [0xc42047ce28 0xc42047d080 0xc42047d2d8] [0xc42047cfb8 0xc42047d238] [0x8fd520 0x8fd520] 0xc421969080 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Dec  3 20:22:23.015: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-166913721 exec --namespace=e2e-tests-statefulset-2jxn5 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec  3 20:22:23.115: INFO: rc: 1
Dec  3 20:22:23.115: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-166913721 exec --namespace=e2e-tests-statefulset-2jxn5 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc420f465d0 exit status 1 <nil> <nil> true [0xc42121e000 0xc42121e038 0xc42121e070] [0xc42121e000 0xc42121e038 0xc42121e070] [0xc42121e030 0xc42121e058] [0x8fd520 0x8fd520] 0xc421962240 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Dec  3 20:22:33.116: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-166913721 exec --namespace=e2e-tests-statefulset-2jxn5 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec  3 20:22:33.205: INFO: rc: 1
Dec  3 20:22:33.205: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-166913721 exec --namespace=e2e-tests-statefulset-2jxn5 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc420f46a20 exit status 1 <nil> <nil> true [0xc42121e078 0xc42121e0b0 0xc42121e0d8] [0xc42121e078 0xc42121e0b0 0xc42121e0d8] [0xc42121e098 0xc42121e0c0] [0x8fd520 0x8fd520] 0xc4219625a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Dec  3 20:22:43.205: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-166913721 exec --namespace=e2e-tests-statefulset-2jxn5 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec  3 20:22:43.302: INFO: rc: 1
Dec  3 20:22:43.302: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-166913721 exec --namespace=e2e-tests-statefulset-2jxn5 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc420f203c0 exit status 1 <nil> <nil> true [0xc42000e208 0xc42047c008 0xc42047c3c0] [0xc42000e208 0xc42047c008 0xc42047c3c0] [0xc42000e2b8 0xc42047c2a0] [0x8fd520 0x8fd520] 0xc42190e120 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Dec  3 20:22:53.302: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-166913721 exec --namespace=e2e-tests-statefulset-2jxn5 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec  3 20:22:53.411: INFO: rc: 1
Dec  3 20:22:53.411: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-166913721 exec --namespace=e2e-tests-statefulset-2jxn5 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc420f46e70 exit status 1 <nil> <nil> true [0xc42121e0f0 0xc42121e118 0xc42121e158] [0xc42121e0f0 0xc42121e118 0xc42121e158] [0xc42121e100 0xc42121e138] [0x8fd520 0x8fd520] 0xc421962c00 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Dec  3 20:23:03.411: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-166913721 exec --namespace=e2e-tests-statefulset-2jxn5 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec  3 20:23:03.501: INFO: rc: 1
Dec  3 20:23:03.501: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-166913721 exec --namespace=e2e-tests-statefulset-2jxn5 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc4218563c0 exit status 1 <nil> <nil> true [0xc420804638 0xc420804760 0xc420804870] [0xc420804638 0xc420804760 0xc420804870] [0xc420804728 0xc420804808] [0x8fd520 0x8fd520] 0xc4212508a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Dec  3 20:23:13.502: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-166913721 exec --namespace=e2e-tests-statefulset-2jxn5 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec  3 20:23:13.600: INFO: rc: 1
Dec  3 20:23:13.600: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-166913721 exec --namespace=e2e-tests-statefulset-2jxn5 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc420f20d80 exit status 1 <nil> <nil> true [0xc42047c568 0xc42047c718 0xc42047c7f0] [0xc42047c568 0xc42047c718 0xc42047c7f0] [0xc42047c660 0xc42047c7e0] [0x8fd520 0x8fd520] 0xc42190e240 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Dec  3 20:23:23.601: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-166913721 exec --namespace=e2e-tests-statefulset-2jxn5 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec  3 20:23:23.700: INFO: rc: 1
Dec  3 20:23:23.700: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-166913721 exec --namespace=e2e-tests-statefulset-2jxn5 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc420f21290 exit status 1 <nil> <nil> true [0xc42047c898 0xc42047caf8 0xc42047cea8] [0xc42047c898 0xc42047caf8 0xc42047cea8] [0xc42047ca98 0xc42047cd10] [0x8fd520 0x8fd520] 0xc42190e3c0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Dec  3 20:23:33.701: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-166913721 exec --namespace=e2e-tests-statefulset-2jxn5 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec  3 20:23:33.821: INFO: rc: 1
Dec  3 20:23:33.821: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-166913721 exec --namespace=e2e-tests-statefulset-2jxn5 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc421856840 exit status 1 <nil> <nil> true [0xc420804880 0xc4208049d8 0xc420804a68] [0xc420804880 0xc4208049d8 0xc420804a68] [0xc420804948 0xc420804a30] [0x8fd520 0x8fd520] 0xc421250cc0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Dec  3 20:23:43.822: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-166913721 exec --namespace=e2e-tests-statefulset-2jxn5 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec  3 20:23:43.930: INFO: rc: 1
Dec  3 20:23:43.930: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-166913721 exec --namespace=e2e-tests-statefulset-2jxn5 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc421856c90 exit status 1 <nil> <nil> true [0xc420804b30 0xc420804c90 0xc420804cd8] [0xc420804b30 0xc420804c90 0xc420804cd8] [0xc420804c10 0xc420804cc8] [0x8fd520 0x8fd520] 0xc421251140 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Dec  3 20:23:53.930: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-166913721 exec --namespace=e2e-tests-statefulset-2jxn5 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec  3 20:23:54.025: INFO: rc: 1
Dec  3 20:23:54.025: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-166913721 exec --namespace=e2e-tests-statefulset-2jxn5 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc420f216e0 exit status 1 <nil> <nil> true [0xc42047d0a8 0xc42047d480 0xc42047d540] [0xc42047d0a8 0xc42047d480 0xc42047d540] [0xc42047d430 0xc42047d500] [0x8fd520 0x8fd520] 0xc42190e4e0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Dec  3 20:24:04.025: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-166913721 exec --namespace=e2e-tests-statefulset-2jxn5 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec  3 20:24:04.129: INFO: rc: 1
Dec  3 20:24:04.129: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-166913721 exec --namespace=e2e-tests-statefulset-2jxn5 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc420c5e3f0 exit status 1 <nil> <nil> true [0xc4200dc000 0xc4200dc278 0xc4200dc2a8] [0xc4200dc000 0xc4200dc278 0xc4200dc2a8] [0xc4200dc238 0xc4200dc2a0] [0x8fd520 0x8fd520] 0xc421969260 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Dec  3 20:24:14.129: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-166913721 exec --namespace=e2e-tests-statefulset-2jxn5 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec  3 20:24:14.220: INFO: rc: 1
Dec  3 20:24:14.220: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-166913721 exec --namespace=e2e-tests-statefulset-2jxn5 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc4218563f0 exit status 1 <nil> <nil> true [0xc42000e208 0xc420804638 0xc420804760] [0xc42000e208 0xc420804638 0xc420804760] [0xc42000e2b8 0xc420804728] [0x8fd520 0x8fd520] 0xc421962240 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Dec  3 20:24:24.221: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-166913721 exec --namespace=e2e-tests-statefulset-2jxn5 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec  3 20:24:24.371: INFO: rc: 1
Dec  3 20:24:24.371: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-166913721 exec --namespace=e2e-tests-statefulset-2jxn5 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc420f20390 exit status 1 <nil> <nil> true [0xc42047c008 0xc42047c3c0 0xc42047c660] [0xc42047c008 0xc42047c3c0 0xc42047c660] [0xc42047c2a0 0xc42047c5b8] [0x8fd520 0x8fd520] 0xc4212508a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Dec  3 20:24:34.371: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-166913721 exec --namespace=e2e-tests-statefulset-2jxn5 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec  3 20:24:34.470: INFO: rc: 1
Dec  3 20:24:34.470: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-166913721 exec --namespace=e2e-tests-statefulset-2jxn5 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc420f46600 exit status 1 <nil> <nil> true [0xc4200dc000 0xc4200dc278 0xc4200dc2a8] [0xc4200dc000 0xc4200dc278 0xc4200dc2a8] [0xc4200dc238 0xc4200dc2a0] [0x8fd520 0x8fd520] 0xc42190e120 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Dec  3 20:24:44.470: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-166913721 exec --namespace=e2e-tests-statefulset-2jxn5 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec  3 20:24:44.585: INFO: rc: 1
Dec  3 20:24:44.585: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-166913721 exec --namespace=e2e-tests-statefulset-2jxn5 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc420f469f0 exit status 1 <nil> <nil> true [0xc4200dc2d0 0xc4200dc2f0 0xc4200dc358] [0xc4200dc2d0 0xc4200dc2f0 0xc4200dc358] [0xc4200dc2e8 0xc4200dc338] [0x8fd520 0x8fd520] 0xc42190e240 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Dec  3 20:24:54.585: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-166913721 exec --namespace=e2e-tests-statefulset-2jxn5 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec  3 20:24:54.701: INFO: rc: 1
Dec  3 20:24:54.701: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-166913721 exec --namespace=e2e-tests-statefulset-2jxn5 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc421856870 exit status 1 <nil> <nil> true [0xc4208047b8 0xc420804880 0xc4208049d8] [0xc4208047b8 0xc420804880 0xc4208049d8] [0xc420804870 0xc420804948] [0x8fd520 0x8fd520] 0xc4219625a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Dec  3 20:25:04.701: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-166913721 exec --namespace=e2e-tests-statefulset-2jxn5 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec  3 20:25:04.800: INFO: rc: 1
Dec  3 20:25:04.800: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: 
Dec  3 20:25:04.800: INFO: Scaling statefulset ss to 0
Dec  3 20:25:04.810: INFO: Waiting for statefulset status.replicas updated to 0
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Dec  3 20:25:04.813: INFO: Deleting all statefulset in ns e2e-tests-statefulset-2jxn5
Dec  3 20:25:04.815: INFO: Scaling statefulset ss to 0
Dec  3 20:25:04.823: INFO: Waiting for statefulset status.replicas updated to 0
Dec  3 20:25:04.825: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 20:25:04.847: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-2jxn5" for this suite.
Dec  3 20:25:10.864: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 20:25:11.164: INFO: namespace: e2e-tests-statefulset-2jxn5, resource: bindings, ignored listing per whitelist
Dec  3 20:25:11.195: INFO: namespace e2e-tests-statefulset-2jxn5 deletion completed in 6.34392993s

• [SLOW TEST:363.098 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    Burst scaling should run to completion even with unhealthy pods [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 20:25:11.195: INFO: >>> kubeConfig: /tmp/kubeconfig-166913721
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-v9n2k
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Dec  3 20:25:11.273: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Dec  3 20:25:35.379: INFO: ExecWithOptions {Command:[/bin/sh -c timeout -t 15 curl -g -q -s --connect-timeout 1 http://10.244.72.3:8080/hostName | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-v9n2k PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec  3 20:25:35.379: INFO: >>> kubeConfig: /tmp/kubeconfig-166913721
Dec  3 20:25:35.572: INFO: Found all expected endpoints: [netserver-0]
Dec  3 20:25:35.575: INFO: ExecWithOptions {Command:[/bin/sh -c timeout -t 15 curl -g -q -s --connect-timeout 1 http://10.244.1.4:8080/hostName | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-v9n2k PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec  3 20:25:35.576: INFO: >>> kubeConfig: /tmp/kubeconfig-166913721
Dec  3 20:25:35.813: INFO: Found all expected endpoints: [netserver-1]
Dec  3 20:25:35.816: INFO: ExecWithOptions {Command:[/bin/sh -c timeout -t 15 curl -g -q -s --connect-timeout 1 http://10.244.4.3:8080/hostName | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-v9n2k PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec  3 20:25:35.816: INFO: >>> kubeConfig: /tmp/kubeconfig-166913721
Dec  3 20:25:36.051: INFO: Found all expected endpoints: [netserver-2]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 20:25:36.051: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-v9n2k" for this suite.
Dec  3 20:25:58.066: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 20:25:58.105: INFO: namespace: e2e-tests-pod-network-test-v9n2k, resource: bindings, ignored listing per whitelist
Dec  3 20:25:58.181: INFO: namespace e2e-tests-pod-network-test-v9n2k deletion completed in 22.125775348s

• [SLOW TEST:46.986 seconds]
[sig-network] Networking
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: http [NodeConformance] [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-api-machinery] Watchers 
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 20:25:58.182: INFO: >>> kubeConfig: /tmp/kubeconfig-166913721
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a watch on configmaps with label A
STEP: creating a watch on configmaps with label B
STEP: creating a watch on configmaps with label A or B
STEP: creating a configmap with label A and ensuring the correct watchers observe the notification
Dec  3 20:25:58.259: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-gvtlp,SelfLink:/api/v1/namespaces/e2e-tests-watch-gvtlp/configmaps/e2e-watch-test-configmap-a,UID:a4aaf8dd-f739-11e8-8af3-a28d93e01224,ResourceVersion:10285,Generation:0,CreationTimestamp:2018-12-03 20:25:58 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Dec  3 20:25:58.259: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-gvtlp,SelfLink:/api/v1/namespaces/e2e-tests-watch-gvtlp/configmaps/e2e-watch-test-configmap-a,UID:a4aaf8dd-f739-11e8-8af3-a28d93e01224,ResourceVersion:10285,Generation:0,CreationTimestamp:2018-12-03 20:25:58 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: modifying configmap A and ensuring the correct watchers observe the notification
Dec  3 20:26:08.267: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-gvtlp,SelfLink:/api/v1/namespaces/e2e-tests-watch-gvtlp/configmaps/e2e-watch-test-configmap-a,UID:a4aaf8dd-f739-11e8-8af3-a28d93e01224,ResourceVersion:10300,Generation:0,CreationTimestamp:2018-12-03 20:25:58 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Dec  3 20:26:08.267: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-gvtlp,SelfLink:/api/v1/namespaces/e2e-tests-watch-gvtlp/configmaps/e2e-watch-test-configmap-a,UID:a4aaf8dd-f739-11e8-8af3-a28d93e01224,ResourceVersion:10300,Generation:0,CreationTimestamp:2018-12-03 20:25:58 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying configmap A again and ensuring the correct watchers observe the notification
Dec  3 20:26:18.275: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-gvtlp,SelfLink:/api/v1/namespaces/e2e-tests-watch-gvtlp/configmaps/e2e-watch-test-configmap-a,UID:a4aaf8dd-f739-11e8-8af3-a28d93e01224,ResourceVersion:10315,Generation:0,CreationTimestamp:2018-12-03 20:25:58 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Dec  3 20:26:18.276: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-gvtlp,SelfLink:/api/v1/namespaces/e2e-tests-watch-gvtlp/configmaps/e2e-watch-test-configmap-a,UID:a4aaf8dd-f739-11e8-8af3-a28d93e01224,ResourceVersion:10315,Generation:0,CreationTimestamp:2018-12-03 20:25:58 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: deleting configmap A and ensuring the correct watchers observe the notification
Dec  3 20:26:28.282: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-gvtlp,SelfLink:/api/v1/namespaces/e2e-tests-watch-gvtlp/configmaps/e2e-watch-test-configmap-a,UID:a4aaf8dd-f739-11e8-8af3-a28d93e01224,ResourceVersion:10330,Generation:0,CreationTimestamp:2018-12-03 20:25:58 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Dec  3 20:26:28.282: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-gvtlp,SelfLink:/api/v1/namespaces/e2e-tests-watch-gvtlp/configmaps/e2e-watch-test-configmap-a,UID:a4aaf8dd-f739-11e8-8af3-a28d93e01224,ResourceVersion:10330,Generation:0,CreationTimestamp:2018-12-03 20:25:58 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: creating a configmap with label B and ensuring the correct watchers observe the notification
Dec  3 20:26:38.290: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-gvtlp,SelfLink:/api/v1/namespaces/e2e-tests-watch-gvtlp/configmaps/e2e-watch-test-configmap-b,UID:bc86d16d-f739-11e8-8af3-a28d93e01224,ResourceVersion:10345,Generation:0,CreationTimestamp:2018-12-03 20:26:38 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Dec  3 20:26:38.291: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-gvtlp,SelfLink:/api/v1/namespaces/e2e-tests-watch-gvtlp/configmaps/e2e-watch-test-configmap-b,UID:bc86d16d-f739-11e8-8af3-a28d93e01224,ResourceVersion:10345,Generation:0,CreationTimestamp:2018-12-03 20:26:38 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: deleting configmap B and ensuring the correct watchers observe the notification
Dec  3 20:26:48.298: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-gvtlp,SelfLink:/api/v1/namespaces/e2e-tests-watch-gvtlp/configmaps/e2e-watch-test-configmap-b,UID:bc86d16d-f739-11e8-8af3-a28d93e01224,ResourceVersion:10360,Generation:0,CreationTimestamp:2018-12-03 20:26:38 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Dec  3 20:26:48.298: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-gvtlp,SelfLink:/api/v1/namespaces/e2e-tests-watch-gvtlp/configmaps/e2e-watch-test-configmap-b,UID:bc86d16d-f739-11e8-8af3-a28d93e01224,ResourceVersion:10360,Generation:0,CreationTimestamp:2018-12-03 20:26:38 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 20:26:58.298: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-gvtlp" for this suite.
Dec  3 20:27:04.313: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 20:27:04.387: INFO: namespace: e2e-tests-watch-gvtlp, resource: bindings, ignored listing per whitelist
Dec  3 20:27:04.411: INFO: namespace e2e-tests-watch-gvtlp deletion completed in 6.108530171s

• [SLOW TEST:66.229 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-network] Services 
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 20:27:04.411: INFO: >>> kubeConfig: /tmp/kubeconfig-166913721
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:83
[It] should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating service endpoint-test2 in namespace e2e-tests-services-l7cxt
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-l7cxt to expose endpoints map[]
Dec  3 20:27:04.507: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-l7cxt exposes endpoints map[] (9.151285ms elapsed)
STEP: Creating pod pod1 in namespace e2e-tests-services-l7cxt
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-l7cxt to expose endpoints map[pod1:[80]]
Dec  3 20:27:07.590: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-l7cxt exposes endpoints map[pod1:[80]] (3.060034235s elapsed)
STEP: Creating pod pod2 in namespace e2e-tests-services-l7cxt
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-l7cxt to expose endpoints map[pod2:[80] pod1:[80]]
Dec  3 20:27:09.652: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-l7cxt exposes endpoints map[pod1:[80] pod2:[80]] (2.049768801s elapsed)
STEP: Deleting pod pod1 in namespace e2e-tests-services-l7cxt
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-l7cxt to expose endpoints map[pod2:[80]]
Dec  3 20:27:09.678: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-l7cxt exposes endpoints map[pod2:[80]] (19.166296ms elapsed)
STEP: Deleting pod pod2 in namespace e2e-tests-services-l7cxt
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-l7cxt to expose endpoints map[]
Dec  3 20:27:09.694: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-l7cxt exposes endpoints map[] (8.871261ms elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 20:27:09.724: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-services-l7cxt" for this suite.
Dec  3 20:27:15.738: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 20:27:15.798: INFO: namespace: e2e-tests-services-l7cxt, resource: bindings, ignored listing per whitelist
Dec  3 20:27:15.827: INFO: namespace e2e-tests-services-l7cxt deletion completed in 6.097986771s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:88

• [SLOW TEST:11.416 seconds]
[sig-network] Services
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 20:27:15.828: INFO: >>> kubeConfig: /tmp/kubeconfig-166913721
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
Dec  3 20:27:15.896: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 20:27:20.913: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-init-container-lc5fq" for this suite.
Dec  3 20:27:42.929: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 20:27:42.996: INFO: namespace: e2e-tests-init-container-lc5fq, resource: bindings, ignored listing per whitelist
Dec  3 20:27:43.021: INFO: namespace e2e-tests-init-container-lc5fq deletion completed in 22.10335735s

• [SLOW TEST:27.193 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 20:27:43.023: INFO: >>> kubeConfig: /tmp/kubeconfig-166913721
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the rc
STEP: delete the rc
STEP: wait for all pods to be garbage collected
STEP: Gathering metrics
W1203 20:27:53.115411      19 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Dec  3 20:27:53.115: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 20:27:53.115: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-qp9pg" for this suite.
Dec  3 20:27:59.128: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 20:27:59.149: INFO: namespace: e2e-tests-gc-qp9pg, resource: bindings, ignored listing per whitelist
Dec  3 20:27:59.216: INFO: namespace e2e-tests-gc-qp9pg deletion completed in 6.098077591s

• [SLOW TEST:16.193 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 20:27:59.216: INFO: >>> kubeConfig: /tmp/kubeconfig-166913721
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the rs
STEP: Gathering metrics
W1203 20:28:29.365053      19 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Dec  3 20:28:29.365: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 20:28:29.365: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-7z8vf" for this suite.
Dec  3 20:28:35.378: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 20:28:35.473: INFO: namespace: e2e-tests-gc-7z8vf, resource: bindings, ignored listing per whitelist
Dec  3 20:28:35.488: INFO: namespace e2e-tests-gc-7z8vf deletion completed in 6.120690217s

• [SLOW TEST:36.272 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on tmpfs should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 20:28:35.489: INFO: >>> kubeConfig: /tmp/kubeconfig-166913721
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on tmpfs should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir volume type on tmpfs
Dec  3 20:28:35.567: INFO: Waiting up to 5m0s for pod "pod-026c1679-f73a-11e8-8d0a-02420af40402" in namespace "e2e-tests-emptydir-mm4xm" to be "success or failure"
Dec  3 20:28:35.578: INFO: Pod "pod-026c1679-f73a-11e8-8d0a-02420af40402": Phase="Pending", Reason="", readiness=false. Elapsed: 10.56808ms
Dec  3 20:28:37.582: INFO: Pod "pod-026c1679-f73a-11e8-8d0a-02420af40402": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.014826558s
STEP: Saw pod success
Dec  3 20:28:37.582: INFO: Pod "pod-026c1679-f73a-11e8-8d0a-02420af40402" satisfied condition "success or failure"
Dec  3 20:28:37.585: INFO: Trying to get logs from node hungry-keller-3o9a pod pod-026c1679-f73a-11e8-8d0a-02420af40402 container test-container: <nil>
STEP: delete the pod
Dec  3 20:28:37.610: INFO: Waiting for pod pod-026c1679-f73a-11e8-8d0a-02420af40402 to disappear
Dec  3 20:28:37.615: INFO: Pod pod-026c1679-f73a-11e8-8d0a-02420af40402 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 20:28:37.615: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-mm4xm" for this suite.
Dec  3 20:28:43.630: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 20:28:43.688: INFO: namespace: e2e-tests-emptydir-mm4xm, resource: bindings, ignored listing per whitelist
Dec  3 20:28:43.718: INFO: namespace e2e-tests-emptydir-mm4xm deletion completed in 6.099077509s

• [SLOW TEST:8.229 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  volume on tmpfs should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 20:28:43.718: INFO: >>> kubeConfig: /tmp/kubeconfig-166913721
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-ghfxc
[It] should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a new StaefulSet
Dec  3 20:28:43.822: INFO: Found 0 stateful pods, waiting for 3
Dec  3 20:28:53.827: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Dec  3 20:28:53.827: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Dec  3 20:28:53.827: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Updating stateful set template: update image from docker.io/library/nginx:1.14-alpine to docker.io/library/nginx:1.15-alpine
Dec  3 20:28:53.862: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Not applying an update when the partition is greater than the number of replicas
STEP: Performing a canary update
Dec  3 20:28:53.906: INFO: Updating stateful set ss2
Dec  3 20:28:53.959: INFO: Waiting for Pod e2e-tests-statefulset-ghfxc/ss2-2 to have revision ss2-c79899b9 update revision ss2-787997d666
STEP: Restoring Pods to the correct revision when they are deleted
Dec  3 20:29:04.088: INFO: Found 2 stateful pods, waiting for 3
Dec  3 20:29:14.092: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Dec  3 20:29:14.092: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Dec  3 20:29:14.092: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Performing a phased rolling update
Dec  3 20:29:14.119: INFO: Updating stateful set ss2
Dec  3 20:29:14.141: INFO: Waiting for Pod e2e-tests-statefulset-ghfxc/ss2-1 to have revision ss2-c79899b9 update revision ss2-787997d666
Dec  3 20:29:24.175: INFO: Updating stateful set ss2
Dec  3 20:29:24.225: INFO: Waiting for StatefulSet e2e-tests-statefulset-ghfxc/ss2 to complete update
Dec  3 20:29:24.225: INFO: Waiting for Pod e2e-tests-statefulset-ghfxc/ss2-0 to have revision ss2-c79899b9 update revision ss2-787997d666
Dec  3 20:29:34.232: INFO: Waiting for StatefulSet e2e-tests-statefulset-ghfxc/ss2 to complete update
Dec  3 20:29:34.232: INFO: Waiting for Pod e2e-tests-statefulset-ghfxc/ss2-0 to have revision ss2-c79899b9 update revision ss2-787997d666
Dec  3 20:29:44.235: INFO: Waiting for StatefulSet e2e-tests-statefulset-ghfxc/ss2 to complete update
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Dec  3 20:29:54.232: INFO: Deleting all statefulset in ns e2e-tests-statefulset-ghfxc
Dec  3 20:29:54.235: INFO: Scaling statefulset ss2 to 0
Dec  3 20:30:24.266: INFO: Waiting for statefulset status.replicas updated to 0
Dec  3 20:30:24.269: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 20:30:24.352: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-ghfxc" for this suite.
Dec  3 20:30:30.370: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 20:30:30.453: INFO: namespace: e2e-tests-statefulset-ghfxc, resource: bindings, ignored listing per whitelist
Dec  3 20:30:30.467: INFO: namespace e2e-tests-statefulset-ghfxc deletion completed in 6.107247338s

• [SLOW TEST:106.749 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should perform canary updates and phased rolling updates of template modifications [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 20:30:30.468: INFO: >>> kubeConfig: /tmp/kubeconfig-166913721
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Dec  3 20:30:30.539: INFO: Waiting up to 5m0s for pod "downwardapi-volume-46f37297-f73a-11e8-8d0a-02420af40402" in namespace "e2e-tests-downward-api-vj7h7" to be "success or failure"
Dec  3 20:30:30.553: INFO: Pod "downwardapi-volume-46f37297-f73a-11e8-8d0a-02420af40402": Phase="Pending", Reason="", readiness=false. Elapsed: 14.822802ms
Dec  3 20:30:32.560: INFO: Pod "downwardapi-volume-46f37297-f73a-11e8-8d0a-02420af40402": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.021405662s
STEP: Saw pod success
Dec  3 20:30:32.560: INFO: Pod "downwardapi-volume-46f37297-f73a-11e8-8d0a-02420af40402" satisfied condition "success or failure"
Dec  3 20:30:32.562: INFO: Trying to get logs from node hungry-keller-3o9a pod downwardapi-volume-46f37297-f73a-11e8-8d0a-02420af40402 container client-container: <nil>
STEP: delete the pod
Dec  3 20:30:32.585: INFO: Waiting for pod downwardapi-volume-46f37297-f73a-11e8-8d0a-02420af40402 to disappear
Dec  3 20:30:32.589: INFO: Pod downwardapi-volume-46f37297-f73a-11e8-8d0a-02420af40402 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 20:30:32.589: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-vj7h7" for this suite.
Dec  3 20:30:38.602: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 20:30:38.631: INFO: namespace: e2e-tests-downward-api-vj7h7, resource: bindings, ignored listing per whitelist
Dec  3 20:30:38.687: INFO: namespace e2e-tests-downward-api-vj7h7 deletion completed in 6.09546899s

• [SLOW TEST:8.220 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts 
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 20:30:38.688: INFO: >>> kubeConfig: /tmp/kubeconfig-166913721
STEP: Building a namespace api object, basename svcaccounts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: getting the auto-created API token
Dec  3 20:30:39.285: INFO: created pod pod-service-account-defaultsa
Dec  3 20:30:39.285: INFO: pod pod-service-account-defaultsa service account token volume mount: true
Dec  3 20:30:39.293: INFO: created pod pod-service-account-mountsa
Dec  3 20:30:39.293: INFO: pod pod-service-account-mountsa service account token volume mount: true
Dec  3 20:30:39.307: INFO: created pod pod-service-account-nomountsa
Dec  3 20:30:39.307: INFO: pod pod-service-account-nomountsa service account token volume mount: false
Dec  3 20:30:39.321: INFO: created pod pod-service-account-defaultsa-mountspec
Dec  3 20:30:39.321: INFO: pod pod-service-account-defaultsa-mountspec service account token volume mount: true
Dec  3 20:30:39.334: INFO: created pod pod-service-account-mountsa-mountspec
Dec  3 20:30:39.334: INFO: pod pod-service-account-mountsa-mountspec service account token volume mount: true
Dec  3 20:30:39.351: INFO: created pod pod-service-account-nomountsa-mountspec
Dec  3 20:30:39.351: INFO: pod pod-service-account-nomountsa-mountspec service account token volume mount: true
Dec  3 20:30:39.362: INFO: created pod pod-service-account-defaultsa-nomountspec
Dec  3 20:30:39.362: INFO: pod pod-service-account-defaultsa-nomountspec service account token volume mount: false
Dec  3 20:30:39.373: INFO: created pod pod-service-account-mountsa-nomountspec
Dec  3 20:30:39.373: INFO: pod pod-service-account-mountsa-nomountspec service account token volume mount: false
Dec  3 20:30:39.386: INFO: created pod pod-service-account-nomountsa-nomountspec
Dec  3 20:30:39.386: INFO: pod pod-service-account-nomountsa-nomountspec service account token volume mount: false
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 20:30:39.386: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-svcaccounts-f6q6m" for this suite.
Dec  3 20:31:01.426: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 20:31:01.470: INFO: namespace: e2e-tests-svcaccounts-f6q6m, resource: bindings, ignored listing per whitelist
Dec  3 20:31:01.512: INFO: namespace e2e-tests-svcaccounts-f6q6m deletion completed in 22.107713275s

• [SLOW TEST:22.824 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:22
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Downward API 
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 20:31:01.512: INFO: >>> kubeConfig: /tmp/kubeconfig-166913721
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Dec  3 20:31:01.581: INFO: Waiting up to 5m0s for pod "downward-api-59742993-f73a-11e8-8d0a-02420af40402" in namespace "e2e-tests-downward-api-tgx78" to be "success or failure"
Dec  3 20:31:01.593: INFO: Pod "downward-api-59742993-f73a-11e8-8d0a-02420af40402": Phase="Pending", Reason="", readiness=false. Elapsed: 11.880355ms
Dec  3 20:31:03.597: INFO: Pod "downward-api-59742993-f73a-11e8-8d0a-02420af40402": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.015558374s
STEP: Saw pod success
Dec  3 20:31:03.597: INFO: Pod "downward-api-59742993-f73a-11e8-8d0a-02420af40402" satisfied condition "success or failure"
Dec  3 20:31:03.600: INFO: Trying to get logs from node hungry-keller-3o9e pod downward-api-59742993-f73a-11e8-8d0a-02420af40402 container dapi-container: <nil>
STEP: delete the pod
Dec  3 20:31:03.618: INFO: Waiting for pod downward-api-59742993-f73a-11e8-8d0a-02420af40402 to disappear
Dec  3 20:31:03.621: INFO: Pod downward-api-59742993-f73a-11e8-8d0a-02420af40402 no longer exists
[AfterEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 20:31:03.621: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-tgx78" for this suite.
Dec  3 20:31:09.637: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 20:31:09.683: INFO: namespace: e2e-tests-downward-api-tgx78, resource: bindings, ignored listing per whitelist
Dec  3 20:31:09.723: INFO: namespace e2e-tests-downward-api-tgx78 deletion completed in 6.098115365s

• [SLOW TEST:8.211 seconds]
[sig-api-machinery] Downward API
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 20:31:09.723: INFO: >>> kubeConfig: /tmp/kubeconfig-166913721
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Dec  3 20:31:09.797: INFO: Waiting up to 5m0s for pod "downwardapi-volume-5e598d00-f73a-11e8-8d0a-02420af40402" in namespace "e2e-tests-downward-api-zlr72" to be "success or failure"
Dec  3 20:31:09.809: INFO: Pod "downwardapi-volume-5e598d00-f73a-11e8-8d0a-02420af40402": Phase="Pending", Reason="", readiness=false. Elapsed: 12.601556ms
Dec  3 20:31:11.813: INFO: Pod "downwardapi-volume-5e598d00-f73a-11e8-8d0a-02420af40402": Phase="Pending", Reason="", readiness=false. Elapsed: 2.016433964s
Dec  3 20:31:13.818: INFO: Pod "downwardapi-volume-5e598d00-f73a-11e8-8d0a-02420af40402": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.02115913s
STEP: Saw pod success
Dec  3 20:31:13.818: INFO: Pod "downwardapi-volume-5e598d00-f73a-11e8-8d0a-02420af40402" satisfied condition "success or failure"
Dec  3 20:31:13.822: INFO: Trying to get logs from node hungry-keller-3o9a pod downwardapi-volume-5e598d00-f73a-11e8-8d0a-02420af40402 container client-container: <nil>
STEP: delete the pod
Dec  3 20:31:13.849: INFO: Waiting for pod downwardapi-volume-5e598d00-f73a-11e8-8d0a-02420af40402 to disappear
Dec  3 20:31:13.854: INFO: Pod downwardapi-volume-5e598d00-f73a-11e8-8d0a-02420af40402 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 20:31:13.854: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-zlr72" for this suite.
Dec  3 20:31:19.870: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 20:31:19.979: INFO: namespace: e2e-tests-downward-api-zlr72, resource: bindings, ignored listing per whitelist
Dec  3 20:31:19.987: INFO: namespace e2e-tests-downward-api-zlr72 deletion completed in 6.128927448s

• [SLOW TEST:10.265 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 20:31:19.988: INFO: >>> kubeConfig: /tmp/kubeconfig-166913721
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:293
[It] should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the initial replication controller
Dec  3 20:31:20.073: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-166913721 create -f - --namespace=e2e-tests-kubectl-6rxmp'
Dec  3 20:31:20.504: INFO: stderr: ""
Dec  3 20:31:20.504: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Dec  3 20:31:20.505: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-166913721 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-6rxmp'
Dec  3 20:31:20.642: INFO: stderr: ""
Dec  3 20:31:20.642: INFO: stdout: "update-demo-nautilus-khz5m update-demo-nautilus-pvv2h "
Dec  3 20:31:20.642: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-166913721 get pods update-demo-nautilus-khz5m -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-6rxmp'
Dec  3 20:31:20.749: INFO: stderr: ""
Dec  3 20:31:20.749: INFO: stdout: ""
Dec  3 20:31:20.749: INFO: update-demo-nautilus-khz5m is created but not running
Dec  3 20:31:25.750: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-166913721 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-6rxmp'
Dec  3 20:31:25.854: INFO: stderr: ""
Dec  3 20:31:25.854: INFO: stdout: "update-demo-nautilus-khz5m update-demo-nautilus-pvv2h "
Dec  3 20:31:25.855: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-166913721 get pods update-demo-nautilus-khz5m -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-6rxmp'
Dec  3 20:31:25.961: INFO: stderr: ""
Dec  3 20:31:25.961: INFO: stdout: "true"
Dec  3 20:31:25.961: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-166913721 get pods update-demo-nautilus-khz5m -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-6rxmp'
Dec  3 20:31:26.069: INFO: stderr: ""
Dec  3 20:31:26.069: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Dec  3 20:31:26.069: INFO: validating pod update-demo-nautilus-khz5m
Dec  3 20:31:26.077: INFO: got data: {
  "image": "nautilus.jpg"
}

Dec  3 20:31:26.077: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Dec  3 20:31:26.077: INFO: update-demo-nautilus-khz5m is verified up and running
Dec  3 20:31:26.077: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-166913721 get pods update-demo-nautilus-pvv2h -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-6rxmp'
Dec  3 20:31:26.179: INFO: stderr: ""
Dec  3 20:31:26.179: INFO: stdout: "true"
Dec  3 20:31:26.179: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-166913721 get pods update-demo-nautilus-pvv2h -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-6rxmp'
Dec  3 20:31:26.288: INFO: stderr: ""
Dec  3 20:31:26.288: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Dec  3 20:31:26.288: INFO: validating pod update-demo-nautilus-pvv2h
Dec  3 20:31:26.297: INFO: got data: {
  "image": "nautilus.jpg"
}

Dec  3 20:31:26.297: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Dec  3 20:31:26.297: INFO: update-demo-nautilus-pvv2h is verified up and running
STEP: rolling-update to new replication controller
Dec  3 20:31:26.298: INFO: scanned /root for discovery docs: <nil>
Dec  3 20:31:26.298: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-166913721 rolling-update update-demo-nautilus --update-period=1s -f - --namespace=e2e-tests-kubectl-6rxmp'
Dec  3 20:31:45.793: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Dec  3 20:31:45.793: INFO: stdout: "Created update-demo-kitten\nScaling up update-demo-kitten from 0 to 2, scaling down update-demo-nautilus from 2 to 0 (keep 2 pods available, don't exceed 3 pods)\nScaling update-demo-kitten up to 1\nScaling update-demo-nautilus down to 1\nScaling update-demo-kitten up to 2\nScaling update-demo-nautilus down to 0\nUpdate succeeded. Deleting old controller: update-demo-nautilus\nRenaming update-demo-kitten to update-demo-nautilus\nreplicationcontroller/update-demo-nautilus rolling updated\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Dec  3 20:31:45.793: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-166913721 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-6rxmp'
Dec  3 20:31:45.915: INFO: stderr: ""
Dec  3 20:31:45.915: INFO: stdout: "update-demo-kitten-2t8lj update-demo-kitten-fvb9l "
Dec  3 20:31:45.915: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-166913721 get pods update-demo-kitten-2t8lj -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-6rxmp'
Dec  3 20:31:46.145: INFO: stderr: ""
Dec  3 20:31:46.145: INFO: stdout: "true"
Dec  3 20:31:46.145: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-166913721 get pods update-demo-kitten-2t8lj -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-6rxmp'
Dec  3 20:31:46.251: INFO: stderr: ""
Dec  3 20:31:46.251: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
Dec  3 20:31:46.251: INFO: validating pod update-demo-kitten-2t8lj
Dec  3 20:31:46.260: INFO: got data: {
  "image": "kitten.jpg"
}

Dec  3 20:31:46.260: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Dec  3 20:31:46.260: INFO: update-demo-kitten-2t8lj is verified up and running
Dec  3 20:31:46.260: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-166913721 get pods update-demo-kitten-fvb9l -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-6rxmp'
Dec  3 20:31:46.382: INFO: stderr: ""
Dec  3 20:31:46.382: INFO: stdout: "true"
Dec  3 20:31:46.382: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-166913721 get pods update-demo-kitten-fvb9l -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-6rxmp'
Dec  3 20:31:46.486: INFO: stderr: ""
Dec  3 20:31:46.486: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
Dec  3 20:31:46.486: INFO: validating pod update-demo-kitten-fvb9l
Dec  3 20:31:46.504: INFO: got data: {
  "image": "kitten.jpg"
}

Dec  3 20:31:46.504: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Dec  3 20:31:46.504: INFO: update-demo-kitten-fvb9l is verified up and running
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 20:31:46.504: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-6rxmp" for this suite.
Dec  3 20:32:08.534: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 20:32:08.564: INFO: namespace: e2e-tests-kubectl-6rxmp, resource: bindings, ignored listing per whitelist
Dec  3 20:32:08.635: INFO: namespace e2e-tests-kubectl-6rxmp deletion completed in 22.117487858s

• [SLOW TEST:48.646 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Update Demo
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should do a rolling update of a replication controller  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 20:32:08.635: INFO: >>> kubeConfig: /tmp/kubeconfig-166913721
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-map-817ad6b0-f73a-11e8-8d0a-02420af40402
STEP: Creating a pod to test consume configMaps
Dec  3 20:32:08.738: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-817b6f87-f73a-11e8-8d0a-02420af40402" in namespace "e2e-tests-projected-9mvc9" to be "success or failure"
Dec  3 20:32:08.755: INFO: Pod "pod-projected-configmaps-817b6f87-f73a-11e8-8d0a-02420af40402": Phase="Pending", Reason="", readiness=false. Elapsed: 16.874455ms
Dec  3 20:32:10.758: INFO: Pod "pod-projected-configmaps-817b6f87-f73a-11e8-8d0a-02420af40402": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.019874493s
STEP: Saw pod success
Dec  3 20:32:10.758: INFO: Pod "pod-projected-configmaps-817b6f87-f73a-11e8-8d0a-02420af40402" satisfied condition "success or failure"
Dec  3 20:32:10.761: INFO: Trying to get logs from node hungry-keller-3o9a pod pod-projected-configmaps-817b6f87-f73a-11e8-8d0a-02420af40402 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Dec  3 20:32:10.788: INFO: Waiting for pod pod-projected-configmaps-817b6f87-f73a-11e8-8d0a-02420af40402 to disappear
Dec  3 20:32:10.793: INFO: Pod pod-projected-configmaps-817b6f87-f73a-11e8-8d0a-02420af40402 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 20:32:10.793: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-9mvc9" for this suite.
Dec  3 20:32:16.807: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 20:32:16.869: INFO: namespace: e2e-tests-projected-9mvc9, resource: bindings, ignored listing per whitelist
Dec  3 20:32:16.900: INFO: namespace e2e-tests-projected-9mvc9 deletion completed in 6.103173695s

• [SLOW TEST:8.265 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Projected 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 20:32:16.900: INFO: >>> kubeConfig: /tmp/kubeconfig-166913721
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name s-test-opt-del-86658da4-f73a-11e8-8d0a-02420af40402
STEP: Creating secret with name s-test-opt-upd-86658df6-f73a-11e8-8d0a-02420af40402
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-86658da4-f73a-11e8-8d0a-02420af40402
STEP: Updating secret s-test-opt-upd-86658df6-f73a-11e8-8d0a-02420af40402
STEP: Creating secret with name s-test-opt-create-86658e19-f73a-11e8-8d0a-02420af40402
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 20:32:25.100: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-mmffv" for this suite.
Dec  3 20:32:47.115: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 20:32:47.164: INFO: namespace: e2e-tests-projected-mmffv, resource: bindings, ignored listing per whitelist
Dec  3 20:32:47.217: INFO: namespace e2e-tests-projected-mmffv deletion completed in 22.11356193s

• [SLOW TEST:30.317 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 20:32:47.217: INFO: >>> kubeConfig: /tmp/kubeconfig-166913721
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
Dec  3 20:32:47.283: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 20:32:50.414: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-init-container-xbpz7" for this suite.
Dec  3 20:32:56.428: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 20:32:56.515: INFO: namespace: e2e-tests-init-container-xbpz7, resource: bindings, ignored listing per whitelist
Dec  3 20:32:56.520: INFO: namespace e2e-tests-init-container-xbpz7 deletion completed in 6.102095161s

• [SLOW TEST:9.302 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Projected 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 20:32:56.521: INFO: >>> kubeConfig: /tmp/kubeconfig-166913721
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Dec  3 20:32:56.745: INFO: Waiting up to 5m0s for pod "downwardapi-volume-9e18baa5-f73a-11e8-8d0a-02420af40402" in namespace "e2e-tests-projected-gkmb2" to be "success or failure"
Dec  3 20:32:56.757: INFO: Pod "downwardapi-volume-9e18baa5-f73a-11e8-8d0a-02420af40402": Phase="Pending", Reason="", readiness=false. Elapsed: 11.844738ms
Dec  3 20:32:58.760: INFO: Pod "downwardapi-volume-9e18baa5-f73a-11e8-8d0a-02420af40402": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015607277s
Dec  3 20:33:00.764: INFO: Pod "downwardapi-volume-9e18baa5-f73a-11e8-8d0a-02420af40402": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.019274s
STEP: Saw pod success
Dec  3 20:33:00.764: INFO: Pod "downwardapi-volume-9e18baa5-f73a-11e8-8d0a-02420af40402" satisfied condition "success or failure"
Dec  3 20:33:00.767: INFO: Trying to get logs from node hungry-keller-3o9a pod downwardapi-volume-9e18baa5-f73a-11e8-8d0a-02420af40402 container client-container: <nil>
STEP: delete the pod
Dec  3 20:33:00.785: INFO: Waiting for pod downwardapi-volume-9e18baa5-f73a-11e8-8d0a-02420af40402 to disappear
Dec  3 20:33:00.788: INFO: Pod downwardapi-volume-9e18baa5-f73a-11e8-8d0a-02420af40402 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 20:33:00.788: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-gkmb2" for this suite.
Dec  3 20:33:06.803: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 20:33:06.851: INFO: namespace: e2e-tests-projected-gkmb2, resource: bindings, ignored listing per whitelist
Dec  3 20:33:06.895: INFO: namespace e2e-tests-projected-gkmb2 deletion completed in 6.103394855s

• [SLOW TEST:10.374 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with downward pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 20:33:06.895: INFO: >>> kubeConfig: /tmp/kubeconfig-166913721
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with downward pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-downwardapi-jgsz
STEP: Creating a pod to test atomic-volume-subpath
Dec  3 20:33:06.985: INFO: Waiting up to 5m0s for pod "pod-subpath-test-downwardapi-jgsz" in namespace "e2e-tests-subpath-62rb5" to be "success or failure"
Dec  3 20:33:07.003: INFO: Pod "pod-subpath-test-downwardapi-jgsz": Phase="Pending", Reason="", readiness=false. Elapsed: 17.997118ms
Dec  3 20:33:09.007: INFO: Pod "pod-subpath-test-downwardapi-jgsz": Phase="Pending", Reason="", readiness=false. Elapsed: 2.022739543s
Dec  3 20:33:11.011: INFO: Pod "pod-subpath-test-downwardapi-jgsz": Phase="Running", Reason="", readiness=false. Elapsed: 4.026855093s
Dec  3 20:33:13.015: INFO: Pod "pod-subpath-test-downwardapi-jgsz": Phase="Running", Reason="", readiness=false. Elapsed: 6.030496617s
Dec  3 20:33:15.019: INFO: Pod "pod-subpath-test-downwardapi-jgsz": Phase="Running", Reason="", readiness=false. Elapsed: 8.03447551s
Dec  3 20:33:17.023: INFO: Pod "pod-subpath-test-downwardapi-jgsz": Phase="Running", Reason="", readiness=false. Elapsed: 10.03879268s
Dec  3 20:33:19.027: INFO: Pod "pod-subpath-test-downwardapi-jgsz": Phase="Running", Reason="", readiness=false. Elapsed: 12.042726415s
Dec  3 20:33:21.031: INFO: Pod "pod-subpath-test-downwardapi-jgsz": Phase="Running", Reason="", readiness=false. Elapsed: 14.04668464s
Dec  3 20:33:23.035: INFO: Pod "pod-subpath-test-downwardapi-jgsz": Phase="Running", Reason="", readiness=false. Elapsed: 16.050142966s
Dec  3 20:33:25.039: INFO: Pod "pod-subpath-test-downwardapi-jgsz": Phase="Running", Reason="", readiness=false. Elapsed: 18.054232994s
Dec  3 20:33:27.043: INFO: Pod "pod-subpath-test-downwardapi-jgsz": Phase="Running", Reason="", readiness=false. Elapsed: 20.058324281s
Dec  3 20:33:29.047: INFO: Pod "pod-subpath-test-downwardapi-jgsz": Phase="Running", Reason="", readiness=false. Elapsed: 22.062275406s
Dec  3 20:33:31.051: INFO: Pod "pod-subpath-test-downwardapi-jgsz": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.066593669s
STEP: Saw pod success
Dec  3 20:33:31.051: INFO: Pod "pod-subpath-test-downwardapi-jgsz" satisfied condition "success or failure"
Dec  3 20:33:31.058: INFO: Trying to get logs from node hungry-keller-3o9e pod pod-subpath-test-downwardapi-jgsz container test-container-subpath-downwardapi-jgsz: <nil>
STEP: delete the pod
Dec  3 20:33:31.092: INFO: Waiting for pod pod-subpath-test-downwardapi-jgsz to disappear
Dec  3 20:33:31.097: INFO: Pod pod-subpath-test-downwardapi-jgsz no longer exists
STEP: Deleting pod pod-subpath-test-downwardapi-jgsz
Dec  3 20:33:31.097: INFO: Deleting pod "pod-subpath-test-downwardapi-jgsz" in namespace "e2e-tests-subpath-62rb5"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 20:33:31.100: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-62rb5" for this suite.
Dec  3 20:33:37.114: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 20:33:37.138: INFO: namespace: e2e-tests-subpath-62rb5, resource: bindings, ignored listing per whitelist
Dec  3 20:33:37.227: INFO: namespace e2e-tests-subpath-62rb5 deletion completed in 6.122307071s

• [SLOW TEST:30.332 seconds]
[sig-storage] Subpath
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with downward pod [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 20:33:37.227: INFO: >>> kubeConfig: /tmp/kubeconfig-166913721
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the rc1
STEP: create the rc2
STEP: set half of pods created by rc simpletest-rc-to-be-deleted to have rc simpletest-rc-to-stay as owner as well
STEP: delete the rc simpletest-rc-to-be-deleted
STEP: wait for the rc to be deleted
STEP: Gathering metrics
W1203 20:33:47.500407      19 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Dec  3 20:33:47.500: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 20:33:47.500: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-gv8p5" for this suite.
Dec  3 20:33:55.515: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 20:33:55.558: INFO: namespace: e2e-tests-gc-gv8p5, resource: bindings, ignored listing per whitelist
Dec  3 20:33:55.600: INFO: namespace e2e-tests-gc-gv8p5 deletion completed in 8.096562882s

• [SLOW TEST:18.373 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] Downward API volume 
  should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 20:33:55.601: INFO: >>> kubeConfig: /tmp/kubeconfig-166913721
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Dec  3 20:33:55.693: INFO: Waiting up to 5m0s for pod "downwardapi-volume-c13b7c58-f73a-11e8-8d0a-02420af40402" in namespace "e2e-tests-downward-api-wtppz" to be "success or failure"
Dec  3 20:33:55.703: INFO: Pod "downwardapi-volume-c13b7c58-f73a-11e8-8d0a-02420af40402": Phase="Pending", Reason="", readiness=false. Elapsed: 9.676437ms
Dec  3 20:33:57.707: INFO: Pod "downwardapi-volume-c13b7c58-f73a-11e8-8d0a-02420af40402": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01393909s
Dec  3 20:33:59.711: INFO: Pod "downwardapi-volume-c13b7c58-f73a-11e8-8d0a-02420af40402": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.017485901s
STEP: Saw pod success
Dec  3 20:33:59.711: INFO: Pod "downwardapi-volume-c13b7c58-f73a-11e8-8d0a-02420af40402" satisfied condition "success or failure"
Dec  3 20:33:59.713: INFO: Trying to get logs from node hungry-keller-3o9a pod downwardapi-volume-c13b7c58-f73a-11e8-8d0a-02420af40402 container client-container: <nil>
STEP: delete the pod
Dec  3 20:33:59.732: INFO: Waiting for pod downwardapi-volume-c13b7c58-f73a-11e8-8d0a-02420af40402 to disappear
Dec  3 20:33:59.734: INFO: Pod downwardapi-volume-c13b7c58-f73a-11e8-8d0a-02420af40402 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 20:33:59.734: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-wtppz" for this suite.
Dec  3 20:34:05.751: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 20:34:05.814: INFO: namespace: e2e-tests-downward-api-wtppz, resource: bindings, ignored listing per whitelist
Dec  3 20:34:05.847: INFO: namespace e2e-tests-downward-api-wtppz deletion completed in 6.10925996s

• [SLOW TEST:10.246 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 20:34:05.847: INFO: >>> kubeConfig: /tmp/kubeconfig-166913721
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-4r8pg
[It] Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Looking for a node to schedule stateful set and pod
STEP: Creating pod with conflicting port in namespace e2e-tests-statefulset-4r8pg
STEP: Creating statefulset with conflicting port in namespace e2e-tests-statefulset-4r8pg
STEP: Waiting until pod test-pod will start running in namespace e2e-tests-statefulset-4r8pg
STEP: Waiting until stateful pod ss-0 will be recreated and deleted at least once in namespace e2e-tests-statefulset-4r8pg
Dec  3 20:34:11.979: INFO: Observed stateful pod in namespace: e2e-tests-statefulset-4r8pg, name: ss-0, uid: cab3d68a-f73a-11e8-8af3-a28d93e01224, status phase: Pending. Waiting for statefulset controller to delete.
Dec  3 20:34:12.152: INFO: Observed stateful pod in namespace: e2e-tests-statefulset-4r8pg, name: ss-0, uid: cab3d68a-f73a-11e8-8af3-a28d93e01224, status phase: Failed. Waiting for statefulset controller to delete.
Dec  3 20:34:12.157: INFO: Observed stateful pod in namespace: e2e-tests-statefulset-4r8pg, name: ss-0, uid: cab3d68a-f73a-11e8-8af3-a28d93e01224, status phase: Failed. Waiting for statefulset controller to delete.
Dec  3 20:34:12.165: INFO: Observed delete event for stateful pod ss-0 in namespace e2e-tests-statefulset-4r8pg
STEP: Removing pod with conflicting port in namespace e2e-tests-statefulset-4r8pg
STEP: Waiting when stateful pod ss-0 will be recreated in namespace e2e-tests-statefulset-4r8pg and will be in running state
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Dec  3 20:34:16.211: INFO: Deleting all statefulset in ns e2e-tests-statefulset-4r8pg
Dec  3 20:34:16.214: INFO: Scaling statefulset ss to 0
Dec  3 20:34:26.241: INFO: Waiting for statefulset status.replicas updated to 0
Dec  3 20:34:26.244: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 20:34:26.261: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-4r8pg" for this suite.
Dec  3 20:34:32.275: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 20:34:32.315: INFO: namespace: e2e-tests-statefulset-4r8pg, resource: bindings, ignored listing per whitelist
Dec  3 20:34:32.392: INFO: namespace e2e-tests-statefulset-4r8pg deletion completed in 6.126101053s

• [SLOW TEST:26.545 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    Should recreate evicted statefulset [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-network] Service endpoints latency 
  should not be very high  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 20:34:32.392: INFO: >>> kubeConfig: /tmp/kubeconfig-166913721
STEP: Building a namespace api object, basename svc-latency
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be very high  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating replication controller svc-latency-rc in namespace e2e-tests-svc-latency-98tfc
I1203 20:34:32.473995      19 runners.go:180] Created replication controller with name: svc-latency-rc, namespace: e2e-tests-svc-latency-98tfc, replica count: 1
I1203 20:34:33.524529      19 runners.go:180] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1203 20:34:34.524809      19 runners.go:180] svc-latency-rc Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Dec  3 20:34:34.642: INFO: Created: latency-svc-rhg2f
Dec  3 20:34:34.648: INFO: Got endpoints: latency-svc-rhg2f [23.60671ms]
Dec  3 20:34:34.680: INFO: Created: latency-svc-rwzwr
Dec  3 20:34:34.691: INFO: Got endpoints: latency-svc-rwzwr [42.160214ms]
Dec  3 20:34:34.693: INFO: Created: latency-svc-52sl5
Dec  3 20:34:34.909: INFO: Got endpoints: latency-svc-52sl5 [259.11037ms]
Dec  3 20:34:34.926: INFO: Created: latency-svc-ndb89
Dec  3 20:34:34.935: INFO: Got endpoints: latency-svc-ndb89 [284.980953ms]
Dec  3 20:34:34.941: INFO: Created: latency-svc-zl5gc
Dec  3 20:34:34.962: INFO: Got endpoints: latency-svc-zl5gc [313.366599ms]
Dec  3 20:34:34.963: INFO: Created: latency-svc-mxm8m
Dec  3 20:34:34.975: INFO: Created: latency-svc-b5n9d
Dec  3 20:34:34.984: INFO: Got endpoints: latency-svc-b5n9d [334.992584ms]
Dec  3 20:34:34.985: INFO: Got endpoints: latency-svc-mxm8m [335.205855ms]
Dec  3 20:34:34.993: INFO: Created: latency-svc-d6829
Dec  3 20:34:35.001: INFO: Got endpoints: latency-svc-d6829 [351.121494ms]
Dec  3 20:34:35.009: INFO: Created: latency-svc-5s2ww
Dec  3 20:34:35.018: INFO: Created: latency-svc-5ngj6
Dec  3 20:34:35.025: INFO: Got endpoints: latency-svc-5s2ww [375.237851ms]
Dec  3 20:34:35.041: INFO: Got endpoints: latency-svc-5ngj6 [391.744921ms]
Dec  3 20:34:35.042: INFO: Created: latency-svc-kfrhc
Dec  3 20:34:35.048: INFO: Got endpoints: latency-svc-kfrhc [47.201658ms]
Dec  3 20:34:35.054: INFO: Created: latency-svc-ng49g
Dec  3 20:34:35.064: INFO: Got endpoints: latency-svc-ng49g [414.007766ms]
Dec  3 20:34:35.071: INFO: Created: latency-svc-psbbh
Dec  3 20:34:35.079: INFO: Created: latency-svc-8q9rz
Dec  3 20:34:35.092: INFO: Got endpoints: latency-svc-8q9rz [442.457258ms]
Dec  3 20:34:35.092: INFO: Got endpoints: latency-svc-psbbh [442.467923ms]
Dec  3 20:34:35.103: INFO: Created: latency-svc-njdp6
Dec  3 20:34:35.114: INFO: Created: latency-svc-mdbx8
Dec  3 20:34:35.119: INFO: Got endpoints: latency-svc-njdp6 [469.218756ms]
Dec  3 20:34:35.129: INFO: Created: latency-svc-5dspq
Dec  3 20:34:35.140: INFO: Created: latency-svc-pv5kn
Dec  3 20:34:35.144: INFO: Got endpoints: latency-svc-5dspq [494.430422ms]
Dec  3 20:34:35.145: INFO: Got endpoints: latency-svc-mdbx8 [494.887605ms]
Dec  3 20:34:35.156: INFO: Got endpoints: latency-svc-pv5kn [465.324706ms]
Dec  3 20:34:35.162: INFO: Created: latency-svc-jwgfp
Dec  3 20:34:35.169: INFO: Got endpoints: latency-svc-jwgfp [259.996445ms]
Dec  3 20:34:35.178: INFO: Created: latency-svc-twv9f
Dec  3 20:34:35.186: INFO: Got endpoints: latency-svc-twv9f [251.142778ms]
Dec  3 20:34:35.194: INFO: Created: latency-svc-mxqwl
Dec  3 20:34:35.201: INFO: Got endpoints: latency-svc-mxqwl [238.909012ms]
Dec  3 20:34:35.210: INFO: Created: latency-svc-n4sk2
Dec  3 20:34:35.214: INFO: Got endpoints: latency-svc-n4sk2 [229.343644ms]
Dec  3 20:34:35.225: INFO: Created: latency-svc-nv2cz
Dec  3 20:34:35.232: INFO: Got endpoints: latency-svc-nv2cz [247.518904ms]
Dec  3 20:34:35.239: INFO: Created: latency-svc-vt5z4
Dec  3 20:34:35.246: INFO: Got endpoints: latency-svc-vt5z4 [220.723441ms]
Dec  3 20:34:35.256: INFO: Created: latency-svc-ds2qs
Dec  3 20:34:35.263: INFO: Created: latency-svc-qnqlc
Dec  3 20:34:35.270: INFO: Got endpoints: latency-svc-qnqlc [222.27765ms]
Dec  3 20:34:35.281: INFO: Got endpoints: latency-svc-ds2qs [239.437194ms]
Dec  3 20:34:35.283: INFO: Created: latency-svc-25tqb
Dec  3 20:34:35.297: INFO: Got endpoints: latency-svc-25tqb [233.10627ms]
Dec  3 20:34:35.303: INFO: Created: latency-svc-bhws8
Dec  3 20:34:35.314: INFO: Got endpoints: latency-svc-bhws8 [221.906374ms]
Dec  3 20:34:35.323: INFO: Created: latency-svc-vhlcq
Dec  3 20:34:35.336: INFO: Got endpoints: latency-svc-vhlcq [243.642104ms]
Dec  3 20:34:35.347: INFO: Created: latency-svc-bn9bt
Dec  3 20:34:35.354: INFO: Got endpoints: latency-svc-bn9bt [234.827996ms]
Dec  3 20:34:35.370: INFO: Created: latency-svc-kqc6w
Dec  3 20:34:35.385: INFO: Created: latency-svc-jrjmm
Dec  3 20:34:35.385: INFO: Got endpoints: latency-svc-kqc6w [240.772533ms]
Dec  3 20:34:35.397: INFO: Created: latency-svc-7sdwd
Dec  3 20:34:35.404: INFO: Got endpoints: latency-svc-7sdwd [247.876336ms]
Dec  3 20:34:35.404: INFO: Got endpoints: latency-svc-jrjmm [259.822797ms]
Dec  3 20:34:35.416: INFO: Created: latency-svc-fz56h
Dec  3 20:34:35.424: INFO: Created: latency-svc-75zrw
Dec  3 20:34:35.429: INFO: Got endpoints: latency-svc-fz56h [259.632029ms]
Dec  3 20:34:35.439: INFO: Created: latency-svc-xlwsm
Dec  3 20:34:35.448: INFO: Got endpoints: latency-svc-xlwsm [246.910532ms]
Dec  3 20:34:35.448: INFO: Got endpoints: latency-svc-75zrw [262.434073ms]
Dec  3 20:34:35.456: INFO: Created: latency-svc-8n52q
Dec  3 20:34:35.465: INFO: Got endpoints: latency-svc-8n52q [251.001412ms]
Dec  3 20:34:35.469: INFO: Created: latency-svc-f7267
Dec  3 20:34:35.477: INFO: Got endpoints: latency-svc-f7267 [244.662924ms]
Dec  3 20:34:35.483: INFO: Created: latency-svc-d8wpr
Dec  3 20:34:35.491: INFO: Got endpoints: latency-svc-d8wpr [245.264912ms]
Dec  3 20:34:35.503: INFO: Created: latency-svc-chchw
Dec  3 20:34:35.520: INFO: Created: latency-svc-xwzxh
Dec  3 20:34:35.524: INFO: Created: latency-svc-kzcn6
Dec  3 20:34:35.525: INFO: Got endpoints: latency-svc-chchw [254.879762ms]
Dec  3 20:34:35.532: INFO: Got endpoints: latency-svc-xwzxh [251.071221ms]
Dec  3 20:34:35.540: INFO: Created: latency-svc-crknd
Dec  3 20:34:35.555: INFO: Created: latency-svc-6sf4n
Dec  3 20:34:35.555: INFO: Got endpoints: latency-svc-kzcn6 [257.903008ms]
Dec  3 20:34:35.555: INFO: Got endpoints: latency-svc-crknd [240.266262ms]
Dec  3 20:34:35.567: INFO: Created: latency-svc-9grw5
Dec  3 20:34:35.570: INFO: Got endpoints: latency-svc-6sf4n [233.7689ms]
Dec  3 20:34:35.581: INFO: Created: latency-svc-4wpnh
Dec  3 20:34:35.581: INFO: Got endpoints: latency-svc-9grw5 [227.439014ms]
Dec  3 20:34:35.595: INFO: Got endpoints: latency-svc-4wpnh [209.265127ms]
Dec  3 20:34:35.605: INFO: Created: latency-svc-lr4lp
Dec  3 20:34:35.615: INFO: Created: latency-svc-ktm6h
Dec  3 20:34:35.620: INFO: Created: latency-svc-8s4mx
Dec  3 20:34:35.632: INFO: Created: latency-svc-84mxp
Dec  3 20:34:35.636: INFO: Got endpoints: latency-svc-lr4lp [231.13836ms]
Dec  3 20:34:35.642: INFO: Created: latency-svc-pbtkp
Dec  3 20:34:35.656: INFO: Created: latency-svc-klqh9
Dec  3 20:34:35.669: INFO: Created: latency-svc-9l8zx
Dec  3 20:34:35.677: INFO: Created: latency-svc-5q24b
Dec  3 20:34:35.686: INFO: Got endpoints: latency-svc-ktm6h [281.760805ms]
Dec  3 20:34:35.691: INFO: Created: latency-svc-qw94f
Dec  3 20:34:35.699: INFO: Created: latency-svc-78qdd
Dec  3 20:34:35.709: INFO: Created: latency-svc-85rd4
Dec  3 20:34:35.715: INFO: Created: latency-svc-fqgs7
Dec  3 20:34:35.724: INFO: Created: latency-svc-ls8kv
Dec  3 20:34:35.732: INFO: Got endpoints: latency-svc-8s4mx [303.696864ms]
Dec  3 20:34:35.738: INFO: Created: latency-svc-gtgrm
Dec  3 20:34:35.745: INFO: Created: latency-svc-j7vwv
Dec  3 20:34:35.756: INFO: Created: latency-svc-527br
Dec  3 20:34:35.766: INFO: Created: latency-svc-dxbkz
Dec  3 20:34:35.777: INFO: Created: latency-svc-ksh5m
Dec  3 20:34:35.784: INFO: Got endpoints: latency-svc-84mxp [335.585324ms]
Dec  3 20:34:35.799: INFO: Created: latency-svc-f96pm
Dec  3 20:34:35.830: INFO: Got endpoints: latency-svc-pbtkp [381.107422ms]
Dec  3 20:34:35.843: INFO: Created: latency-svc-v9cw2
Dec  3 20:34:35.880: INFO: Got endpoints: latency-svc-klqh9 [415.543685ms]
Dec  3 20:34:35.892: INFO: Created: latency-svc-vfjtz
Dec  3 20:34:35.929: INFO: Got endpoints: latency-svc-9l8zx [451.997836ms]
Dec  3 20:34:35.942: INFO: Created: latency-svc-czvwg
Dec  3 20:34:35.980: INFO: Got endpoints: latency-svc-5q24b [489.496363ms]
Dec  3 20:34:35.994: INFO: Created: latency-svc-77xfl
Dec  3 20:34:36.029: INFO: Got endpoints: latency-svc-qw94f [503.664997ms]
Dec  3 20:34:36.042: INFO: Created: latency-svc-2tr78
Dec  3 20:34:36.079: INFO: Got endpoints: latency-svc-78qdd [546.911069ms]
Dec  3 20:34:36.101: INFO: Created: latency-svc-vvddv
Dec  3 20:34:36.129: INFO: Got endpoints: latency-svc-85rd4 [573.677718ms]
Dec  3 20:34:36.141: INFO: Created: latency-svc-9lx54
Dec  3 20:34:36.179: INFO: Got endpoints: latency-svc-fqgs7 [622.059712ms]
Dec  3 20:34:36.193: INFO: Created: latency-svc-bwjl5
Dec  3 20:34:36.229: INFO: Got endpoints: latency-svc-ls8kv [659.426432ms]
Dec  3 20:34:36.245: INFO: Created: latency-svc-jssx9
Dec  3 20:34:36.279: INFO: Got endpoints: latency-svc-gtgrm [698.100927ms]
Dec  3 20:34:36.295: INFO: Created: latency-svc-fbpnk
Dec  3 20:34:36.330: INFO: Got endpoints: latency-svc-j7vwv [735.285141ms]
Dec  3 20:34:36.347: INFO: Created: latency-svc-tpgtc
Dec  3 20:34:36.380: INFO: Got endpoints: latency-svc-527br [743.964044ms]
Dec  3 20:34:36.393: INFO: Created: latency-svc-h7sbt
Dec  3 20:34:36.433: INFO: Got endpoints: latency-svc-dxbkz [746.490302ms]
Dec  3 20:34:36.447: INFO: Created: latency-svc-b2sjg
Dec  3 20:34:36.479: INFO: Got endpoints: latency-svc-ksh5m [745.809858ms]
Dec  3 20:34:36.490: INFO: Created: latency-svc-v77pg
Dec  3 20:34:36.529: INFO: Got endpoints: latency-svc-f96pm [745.174377ms]
Dec  3 20:34:36.548: INFO: Created: latency-svc-gk5rj
Dec  3 20:34:36.579: INFO: Got endpoints: latency-svc-v9cw2 [749.671194ms]
Dec  3 20:34:36.593: INFO: Created: latency-svc-8cxpp
Dec  3 20:34:36.629: INFO: Got endpoints: latency-svc-vfjtz [748.811214ms]
Dec  3 20:34:36.726: INFO: Got endpoints: latency-svc-czvwg [797.406433ms]
Dec  3 20:34:36.729: INFO: Created: latency-svc-z2f9r
Dec  3 20:34:36.739: INFO: Got endpoints: latency-svc-77xfl [758.374313ms]
Dec  3 20:34:36.752: INFO: Created: latency-svc-p7bl7
Dec  3 20:34:36.757: INFO: Created: latency-svc-t2xss
Dec  3 20:34:36.779: INFO: Got endpoints: latency-svc-2tr78 [750.15314ms]
Dec  3 20:34:36.793: INFO: Created: latency-svc-fdk55
Dec  3 20:34:36.841: INFO: Got endpoints: latency-svc-vvddv [761.940054ms]
Dec  3 20:34:36.854: INFO: Created: latency-svc-clxd4
Dec  3 20:34:36.879: INFO: Got endpoints: latency-svc-9lx54 [750.642313ms]
Dec  3 20:34:36.892: INFO: Created: latency-svc-bfscb
Dec  3 20:34:36.942: INFO: Got endpoints: latency-svc-bwjl5 [763.006202ms]
Dec  3 20:34:36.981: INFO: Created: latency-svc-fw9sv
Dec  3 20:34:36.984: INFO: Got endpoints: latency-svc-jssx9 [754.534581ms]
Dec  3 20:34:36.996: INFO: Created: latency-svc-qxb9d
Dec  3 20:34:37.029: INFO: Got endpoints: latency-svc-fbpnk [749.98621ms]
Dec  3 20:34:37.043: INFO: Created: latency-svc-xzrz9
Dec  3 20:34:37.081: INFO: Got endpoints: latency-svc-tpgtc [750.536984ms]
Dec  3 20:34:37.093: INFO: Created: latency-svc-79gb2
Dec  3 20:34:37.130: INFO: Got endpoints: latency-svc-h7sbt [749.883788ms]
Dec  3 20:34:37.141: INFO: Created: latency-svc-gtvws
Dec  3 20:34:37.179: INFO: Got endpoints: latency-svc-b2sjg [746.058554ms]
Dec  3 20:34:37.193: INFO: Created: latency-svc-p2b8g
Dec  3 20:34:37.228: INFO: Got endpoints: latency-svc-v77pg [749.425986ms]
Dec  3 20:34:37.243: INFO: Created: latency-svc-9qm4r
Dec  3 20:34:37.279: INFO: Got endpoints: latency-svc-gk5rj [749.881965ms]
Dec  3 20:34:37.296: INFO: Created: latency-svc-5dv9j
Dec  3 20:34:37.329: INFO: Got endpoints: latency-svc-8cxpp [749.257884ms]
Dec  3 20:34:37.342: INFO: Created: latency-svc-7kjqn
Dec  3 20:34:37.380: INFO: Got endpoints: latency-svc-z2f9r [750.756072ms]
Dec  3 20:34:37.403: INFO: Created: latency-svc-j7jvl
Dec  3 20:34:37.429: INFO: Got endpoints: latency-svc-p7bl7 [702.507006ms]
Dec  3 20:34:37.442: INFO: Created: latency-svc-nxlcb
Dec  3 20:34:37.479: INFO: Got endpoints: latency-svc-t2xss [739.828641ms]
Dec  3 20:34:37.494: INFO: Created: latency-svc-s6srx
Dec  3 20:34:37.530: INFO: Got endpoints: latency-svc-fdk55 [750.569045ms]
Dec  3 20:34:37.541: INFO: Created: latency-svc-qp864
Dec  3 20:34:37.581: INFO: Got endpoints: latency-svc-clxd4 [739.591898ms]
Dec  3 20:34:37.593: INFO: Created: latency-svc-8xczv
Dec  3 20:34:37.629: INFO: Got endpoints: latency-svc-bfscb [749.235398ms]
Dec  3 20:34:37.650: INFO: Created: latency-svc-jrtzf
Dec  3 20:34:37.680: INFO: Got endpoints: latency-svc-fw9sv [737.280541ms]
Dec  3 20:34:37.733: INFO: Created: latency-svc-ml4jq
Dec  3 20:34:37.737: INFO: Got endpoints: latency-svc-qxb9d [752.074403ms]
Dec  3 20:34:37.749: INFO: Created: latency-svc-xwd55
Dec  3 20:34:37.781: INFO: Got endpoints: latency-svc-xzrz9 [751.985538ms]
Dec  3 20:34:37.794: INFO: Created: latency-svc-tw5tx
Dec  3 20:34:37.855: INFO: Got endpoints: latency-svc-79gb2 [774.252516ms]
Dec  3 20:34:37.867: INFO: Created: latency-svc-gjgbq
Dec  3 20:34:37.879: INFO: Got endpoints: latency-svc-gtvws [749.48059ms]
Dec  3 20:34:37.896: INFO: Created: latency-svc-8jljv
Dec  3 20:34:37.928: INFO: Got endpoints: latency-svc-p2b8g [748.717097ms]
Dec  3 20:34:37.942: INFO: Created: latency-svc-bcssq
Dec  3 20:34:37.980: INFO: Got endpoints: latency-svc-9qm4r [751.590018ms]
Dec  3 20:34:37.993: INFO: Created: latency-svc-vhrld
Dec  3 20:34:38.030: INFO: Got endpoints: latency-svc-5dv9j [750.348358ms]
Dec  3 20:34:38.054: INFO: Created: latency-svc-qbrhz
Dec  3 20:34:38.089: INFO: Got endpoints: latency-svc-7kjqn [760.635832ms]
Dec  3 20:34:38.103: INFO: Created: latency-svc-fj4nh
Dec  3 20:34:38.131: INFO: Got endpoints: latency-svc-j7jvl [751.017465ms]
Dec  3 20:34:38.149: INFO: Created: latency-svc-c4shq
Dec  3 20:34:38.183: INFO: Got endpoints: latency-svc-nxlcb [753.874919ms]
Dec  3 20:34:38.207: INFO: Created: latency-svc-gtp2j
Dec  3 20:34:38.231: INFO: Got endpoints: latency-svc-s6srx [751.888863ms]
Dec  3 20:34:38.242: INFO: Created: latency-svc-2p8zt
Dec  3 20:34:38.279: INFO: Got endpoints: latency-svc-qp864 [749.06581ms]
Dec  3 20:34:38.296: INFO: Created: latency-svc-prpbz
Dec  3 20:34:38.330: INFO: Got endpoints: latency-svc-8xczv [748.941108ms]
Dec  3 20:34:38.344: INFO: Created: latency-svc-rtcll
Dec  3 20:34:38.379: INFO: Got endpoints: latency-svc-jrtzf [749.463829ms]
Dec  3 20:34:38.393: INFO: Created: latency-svc-7zbnf
Dec  3 20:34:38.429: INFO: Got endpoints: latency-svc-ml4jq [749.014055ms]
Dec  3 20:34:38.443: INFO: Created: latency-svc-brlw9
Dec  3 20:34:38.481: INFO: Got endpoints: latency-svc-xwd55 [744.419201ms]
Dec  3 20:34:38.494: INFO: Created: latency-svc-qnsb7
Dec  3 20:34:38.530: INFO: Got endpoints: latency-svc-tw5tx [748.039447ms]
Dec  3 20:34:38.544: INFO: Created: latency-svc-fbfvd
Dec  3 20:34:38.579: INFO: Got endpoints: latency-svc-gjgbq [723.649162ms]
Dec  3 20:34:38.591: INFO: Created: latency-svc-94rlr
Dec  3 20:34:38.633: INFO: Got endpoints: latency-svc-8jljv [753.84541ms]
Dec  3 20:34:38.644: INFO: Created: latency-svc-9nm2h
Dec  3 20:34:38.681: INFO: Got endpoints: latency-svc-bcssq [752.224981ms]
Dec  3 20:34:38.695: INFO: Created: latency-svc-lx4sr
Dec  3 20:34:38.730: INFO: Got endpoints: latency-svc-vhrld [750.452874ms]
Dec  3 20:34:38.749: INFO: Created: latency-svc-s22rx
Dec  3 20:34:38.780: INFO: Got endpoints: latency-svc-qbrhz [749.447966ms]
Dec  3 20:34:38.816: INFO: Created: latency-svc-2mvfp
Dec  3 20:34:38.829: INFO: Got endpoints: latency-svc-fj4nh [739.995675ms]
Dec  3 20:34:39.061: INFO: Created: latency-svc-kbplh
Dec  3 20:34:39.067: INFO: Got endpoints: latency-svc-gtp2j [883.882484ms]
Dec  3 20:34:39.067: INFO: Got endpoints: latency-svc-prpbz [787.777168ms]
Dec  3 20:34:39.067: INFO: Got endpoints: latency-svc-2p8zt [835.902096ms]
Dec  3 20:34:39.067: INFO: Got endpoints: latency-svc-c4shq [936.106861ms]
Dec  3 20:34:39.092: INFO: Got endpoints: latency-svc-rtcll [761.984143ms]
Dec  3 20:34:39.107: INFO: Created: latency-svc-2kdls
Dec  3 20:34:39.113: INFO: Created: latency-svc-jhnrc
Dec  3 20:34:39.126: INFO: Created: latency-svc-xcwwr
Dec  3 20:34:39.135: INFO: Got endpoints: latency-svc-7zbnf [755.953626ms]
Dec  3 20:34:39.139: INFO: Created: latency-svc-6dhh6
Dec  3 20:34:39.153: INFO: Created: latency-svc-g5xkw
Dec  3 20:34:39.171: INFO: Created: latency-svc-mxlrb
Dec  3 20:34:39.179: INFO: Got endpoints: latency-svc-brlw9 [749.954085ms]
Dec  3 20:34:39.191: INFO: Created: latency-svc-42ssd
Dec  3 20:34:39.230: INFO: Got endpoints: latency-svc-qnsb7 [748.637345ms]
Dec  3 20:34:39.243: INFO: Created: latency-svc-xm66g
Dec  3 20:34:39.467: INFO: Got endpoints: latency-svc-lx4sr [786.509124ms]
Dec  3 20:34:39.468: INFO: Got endpoints: latency-svc-94rlr [888.282843ms]
Dec  3 20:34:39.468: INFO: Got endpoints: latency-svc-fbfvd [938.181745ms]
Dec  3 20:34:39.468: INFO: Got endpoints: latency-svc-9nm2h [834.295016ms]
Dec  3 20:34:39.486: INFO: Created: latency-svc-lfbpm
Dec  3 20:34:39.489: INFO: Got endpoints: latency-svc-s22rx [758.936803ms]
Dec  3 20:34:39.496: INFO: Created: latency-svc-8flq4
Dec  3 20:34:39.509: INFO: Created: latency-svc-c4rtd
Dec  3 20:34:39.521: INFO: Created: latency-svc-9rr9f
Dec  3 20:34:39.527: INFO: Created: latency-svc-4qcr5
Dec  3 20:34:39.532: INFO: Got endpoints: latency-svc-2mvfp [752.141918ms]
Dec  3 20:34:39.556: INFO: Created: latency-svc-m4hwp
Dec  3 20:34:39.601: INFO: Got endpoints: latency-svc-kbplh [772.089878ms]
Dec  3 20:34:39.635: INFO: Created: latency-svc-tp2vc
Dec  3 20:34:39.636: INFO: Got endpoints: latency-svc-2kdls [569.523489ms]
Dec  3 20:34:39.656: INFO: Created: latency-svc-4whv6
Dec  3 20:34:39.680: INFO: Got endpoints: latency-svc-jhnrc [613.049607ms]
Dec  3 20:34:39.691: INFO: Created: latency-svc-ht257
Dec  3 20:34:39.730: INFO: Got endpoints: latency-svc-xcwwr [662.7134ms]
Dec  3 20:34:39.743: INFO: Created: latency-svc-8gndm
Dec  3 20:34:39.780: INFO: Got endpoints: latency-svc-6dhh6 [713.292052ms]
Dec  3 20:34:39.795: INFO: Created: latency-svc-fhxd7
Dec  3 20:34:39.829: INFO: Got endpoints: latency-svc-g5xkw [737.334203ms]
Dec  3 20:34:39.844: INFO: Created: latency-svc-w87nd
Dec  3 20:34:39.879: INFO: Got endpoints: latency-svc-mxlrb [744.131904ms]
Dec  3 20:34:39.893: INFO: Created: latency-svc-srdb9
Dec  3 20:34:39.929: INFO: Got endpoints: latency-svc-42ssd [750.056782ms]
Dec  3 20:34:39.948: INFO: Created: latency-svc-mmbxz
Dec  3 20:34:39.979: INFO: Got endpoints: latency-svc-xm66g [749.203504ms]
Dec  3 20:34:39.994: INFO: Created: latency-svc-8tf82
Dec  3 20:34:40.035: INFO: Got endpoints: latency-svc-lfbpm [566.993862ms]
Dec  3 20:34:40.046: INFO: Created: latency-svc-fknz9
Dec  3 20:34:40.080: INFO: Got endpoints: latency-svc-8flq4 [611.153862ms]
Dec  3 20:34:40.092: INFO: Created: latency-svc-h95gr
Dec  3 20:34:40.129: INFO: Got endpoints: latency-svc-c4rtd [661.381335ms]
Dec  3 20:34:40.147: INFO: Created: latency-svc-mzsnd
Dec  3 20:34:40.179: INFO: Got endpoints: latency-svc-9rr9f [711.609267ms]
Dec  3 20:34:40.237: INFO: Created: latency-svc-fdmml
Dec  3 20:34:40.239: INFO: Got endpoints: latency-svc-4qcr5 [750.13984ms]
Dec  3 20:34:40.354: INFO: Got endpoints: latency-svc-tp2vc [752.608903ms]
Dec  3 20:34:40.355: INFO: Got endpoints: latency-svc-m4hwp [822.237777ms]
Dec  3 20:34:40.368: INFO: Created: latency-svc-756gd
Dec  3 20:34:40.381: INFO: Created: latency-svc-pqkkb
Dec  3 20:34:40.388: INFO: Got endpoints: latency-svc-4whv6 [751.699348ms]
Dec  3 20:34:40.392: INFO: Created: latency-svc-zp8cc
Dec  3 20:34:40.403: INFO: Created: latency-svc-jpzx9
Dec  3 20:34:40.430: INFO: Got endpoints: latency-svc-ht257 [749.301742ms]
Dec  3 20:34:40.443: INFO: Created: latency-svc-nbhm7
Dec  3 20:34:40.479: INFO: Got endpoints: latency-svc-8gndm [749.603148ms]
Dec  3 20:34:40.491: INFO: Created: latency-svc-xqvxq
Dec  3 20:34:40.529: INFO: Got endpoints: latency-svc-fhxd7 [748.970359ms]
Dec  3 20:34:40.542: INFO: Created: latency-svc-sd4bb
Dec  3 20:34:40.607: INFO: Got endpoints: latency-svc-w87nd [777.119561ms]
Dec  3 20:34:40.618: INFO: Created: latency-svc-ppr2v
Dec  3 20:34:40.629: INFO: Got endpoints: latency-svc-srdb9 [749.937943ms]
Dec  3 20:34:40.645: INFO: Created: latency-svc-5pkp6
Dec  3 20:34:40.680: INFO: Got endpoints: latency-svc-mmbxz [750.318553ms]
Dec  3 20:34:40.693: INFO: Created: latency-svc-hvrpz
Dec  3 20:34:40.730: INFO: Got endpoints: latency-svc-8tf82 [747.312321ms]
Dec  3 20:34:40.742: INFO: Created: latency-svc-tk5k4
Dec  3 20:34:40.781: INFO: Got endpoints: latency-svc-fknz9 [745.90541ms]
Dec  3 20:34:40.793: INFO: Created: latency-svc-m9z96
Dec  3 20:34:40.829: INFO: Got endpoints: latency-svc-h95gr [749.17773ms]
Dec  3 20:34:40.842: INFO: Created: latency-svc-xz746
Dec  3 20:34:40.879: INFO: Got endpoints: latency-svc-mzsnd [750.573446ms]
Dec  3 20:34:40.892: INFO: Created: latency-svc-kzwcj
Dec  3 20:34:40.935: INFO: Got endpoints: latency-svc-fdmml [755.454313ms]
Dec  3 20:34:40.950: INFO: Created: latency-svc-47vgh
Dec  3 20:34:40.979: INFO: Got endpoints: latency-svc-756gd [739.472597ms]
Dec  3 20:34:41.008: INFO: Created: latency-svc-7ggxw
Dec  3 20:34:41.029: INFO: Got endpoints: latency-svc-pqkkb [674.632224ms]
Dec  3 20:34:41.053: INFO: Created: latency-svc-fb29t
Dec  3 20:34:41.079: INFO: Got endpoints: latency-svc-zp8cc [724.154156ms]
Dec  3 20:34:41.098: INFO: Created: latency-svc-rm8f2
Dec  3 20:34:41.131: INFO: Got endpoints: latency-svc-jpzx9 [742.394646ms]
Dec  3 20:34:41.142: INFO: Created: latency-svc-gvpdw
Dec  3 20:34:41.179: INFO: Got endpoints: latency-svc-nbhm7 [749.242539ms]
Dec  3 20:34:41.192: INFO: Created: latency-svc-zxd7l
Dec  3 20:34:41.229: INFO: Got endpoints: latency-svc-xqvxq [749.822109ms]
Dec  3 20:34:41.244: INFO: Created: latency-svc-hwrtf
Dec  3 20:34:41.294: INFO: Got endpoints: latency-svc-sd4bb [764.609788ms]
Dec  3 20:34:41.309: INFO: Created: latency-svc-s2bfn
Dec  3 20:34:41.331: INFO: Got endpoints: latency-svc-ppr2v [724.098842ms]
Dec  3 20:34:41.344: INFO: Created: latency-svc-9dbrl
Dec  3 20:34:41.380: INFO: Got endpoints: latency-svc-5pkp6 [750.260599ms]
Dec  3 20:34:41.392: INFO: Created: latency-svc-wtmpt
Dec  3 20:34:41.430: INFO: Got endpoints: latency-svc-hvrpz [749.944095ms]
Dec  3 20:34:41.442: INFO: Created: latency-svc-k2t6k
Dec  3 20:34:41.479: INFO: Got endpoints: latency-svc-tk5k4 [749.13508ms]
Dec  3 20:34:41.495: INFO: Created: latency-svc-b4cpp
Dec  3 20:34:41.529: INFO: Got endpoints: latency-svc-m9z96 [748.131138ms]
Dec  3 20:34:41.553: INFO: Created: latency-svc-tndb2
Dec  3 20:34:41.579: INFO: Got endpoints: latency-svc-xz746 [749.867987ms]
Dec  3 20:34:41.592: INFO: Created: latency-svc-svndh
Dec  3 20:34:41.629: INFO: Got endpoints: latency-svc-kzwcj [749.286205ms]
Dec  3 20:34:41.643: INFO: Created: latency-svc-xh968
Dec  3 20:34:41.682: INFO: Got endpoints: latency-svc-47vgh [746.117666ms]
Dec  3 20:34:41.731: INFO: Created: latency-svc-l7xx6
Dec  3 20:34:41.733: INFO: Got endpoints: latency-svc-7ggxw [754.252373ms]
Dec  3 20:34:41.774: INFO: Created: latency-svc-76p6b
Dec  3 20:34:41.782: INFO: Got endpoints: latency-svc-fb29t [752.639986ms]
Dec  3 20:34:41.807: INFO: Created: latency-svc-rvtrw
Dec  3 20:34:41.833: INFO: Got endpoints: latency-svc-rm8f2 [754.115873ms]
Dec  3 20:34:41.899: INFO: Got endpoints: latency-svc-gvpdw [767.940789ms]
Dec  3 20:34:41.913: INFO: Created: latency-svc-j2ch8
Dec  3 20:34:41.923: INFO: Created: latency-svc-ph4md
Dec  3 20:34:41.929: INFO: Got endpoints: latency-svc-zxd7l [749.544336ms]
Dec  3 20:34:41.940: INFO: Created: latency-svc-r8c2c
Dec  3 20:34:41.980: INFO: Got endpoints: latency-svc-hwrtf [750.235907ms]
Dec  3 20:34:42.000: INFO: Created: latency-svc-s4wz5
Dec  3 20:34:42.029: INFO: Got endpoints: latency-svc-s2bfn [734.973535ms]
Dec  3 20:34:42.044: INFO: Created: latency-svc-klszf
Dec  3 20:34:42.080: INFO: Got endpoints: latency-svc-9dbrl [749.098513ms]
Dec  3 20:34:42.092: INFO: Created: latency-svc-hlxj4
Dec  3 20:34:42.129: INFO: Got endpoints: latency-svc-wtmpt [749.396651ms]
Dec  3 20:34:42.142: INFO: Created: latency-svc-6k8cz
Dec  3 20:34:42.178: INFO: Got endpoints: latency-svc-k2t6k [748.278866ms]
Dec  3 20:34:42.193: INFO: Created: latency-svc-lvsdl
Dec  3 20:34:42.246: INFO: Got endpoints: latency-svc-b4cpp [766.729694ms]
Dec  3 20:34:42.263: INFO: Created: latency-svc-cxn9j
Dec  3 20:34:42.279: INFO: Got endpoints: latency-svc-tndb2 [749.650113ms]
Dec  3 20:34:42.292: INFO: Created: latency-svc-mp4kq
Dec  3 20:34:42.378: INFO: Got endpoints: latency-svc-svndh [799.482931ms]
Dec  3 20:34:42.431: INFO: Got endpoints: latency-svc-l7xx6 [749.428656ms]
Dec  3 20:34:42.431: INFO: Got endpoints: latency-svc-xh968 [802.567859ms]
Dec  3 20:34:42.467: INFO: Created: latency-svc-wjsmd
Dec  3 20:34:42.478: INFO: Created: latency-svc-mjkp6
Dec  3 20:34:42.488: INFO: Got endpoints: latency-svc-76p6b [754.271392ms]
Dec  3 20:34:42.491: INFO: Created: latency-svc-77cgv
Dec  3 20:34:42.504: INFO: Created: latency-svc-g8cmb
Dec  3 20:34:42.531: INFO: Got endpoints: latency-svc-rvtrw [749.822367ms]
Dec  3 20:34:42.549: INFO: Created: latency-svc-fq8sq
Dec  3 20:34:42.579: INFO: Got endpoints: latency-svc-j2ch8 [745.7256ms]
Dec  3 20:34:42.662: INFO: Created: latency-svc-cn7qj
Dec  3 20:34:42.683: INFO: Got endpoints: latency-svc-ph4md [783.782133ms]
Dec  3 20:34:42.687: INFO: Got endpoints: latency-svc-r8c2c [757.756541ms]
Dec  3 20:34:42.731: INFO: Got endpoints: latency-svc-s4wz5 [751.488325ms]
Dec  3 20:34:42.785: INFO: Got endpoints: latency-svc-klszf [755.587717ms]
Dec  3 20:34:42.850: INFO: Got endpoints: latency-svc-hlxj4 [769.593097ms]
Dec  3 20:34:42.912: INFO: Got endpoints: latency-svc-6k8cz [783.000912ms]
Dec  3 20:34:42.934: INFO: Got endpoints: latency-svc-lvsdl [754.995047ms]
Dec  3 20:34:42.989: INFO: Got endpoints: latency-svc-cxn9j [743.112847ms]
Dec  3 20:34:43.032: INFO: Got endpoints: latency-svc-mp4kq [753.380984ms]
Dec  3 20:34:43.088: INFO: Got endpoints: latency-svc-wjsmd [709.035633ms]
Dec  3 20:34:43.129: INFO: Got endpoints: latency-svc-mjkp6 [697.596806ms]
Dec  3 20:34:43.179: INFO: Got endpoints: latency-svc-77cgv [747.136114ms]
Dec  3 20:34:43.229: INFO: Got endpoints: latency-svc-g8cmb [741.235926ms]
Dec  3 20:34:43.279: INFO: Got endpoints: latency-svc-fq8sq [747.637765ms]
Dec  3 20:34:43.330: INFO: Got endpoints: latency-svc-cn7qj [751.007361ms]
Dec  3 20:34:43.331: INFO: Latencies: [42.160214ms 47.201658ms 209.265127ms 220.723441ms 221.906374ms 222.27765ms 227.439014ms 229.343644ms 231.13836ms 233.10627ms 233.7689ms 234.827996ms 238.909012ms 239.437194ms 240.266262ms 240.772533ms 243.642104ms 244.662924ms 245.264912ms 246.910532ms 247.518904ms 247.876336ms 251.001412ms 251.071221ms 251.142778ms 254.879762ms 257.903008ms 259.11037ms 259.632029ms 259.822797ms 259.996445ms 262.434073ms 281.760805ms 284.980953ms 303.696864ms 313.366599ms 334.992584ms 335.205855ms 335.585324ms 351.121494ms 375.237851ms 381.107422ms 391.744921ms 414.007766ms 415.543685ms 442.457258ms 442.467923ms 451.997836ms 465.324706ms 469.218756ms 489.496363ms 494.430422ms 494.887605ms 503.664997ms 546.911069ms 566.993862ms 569.523489ms 573.677718ms 611.153862ms 613.049607ms 622.059712ms 659.426432ms 661.381335ms 662.7134ms 674.632224ms 697.596806ms 698.100927ms 702.507006ms 709.035633ms 711.609267ms 713.292052ms 723.649162ms 724.098842ms 724.154156ms 734.973535ms 735.285141ms 737.280541ms 737.334203ms 739.472597ms 739.591898ms 739.828641ms 739.995675ms 741.235926ms 742.394646ms 743.112847ms 743.964044ms 744.131904ms 744.419201ms 745.174377ms 745.7256ms 745.809858ms 745.90541ms 746.058554ms 746.117666ms 746.490302ms 747.136114ms 747.312321ms 747.637765ms 748.039447ms 748.131138ms 748.278866ms 748.637345ms 748.717097ms 748.811214ms 748.941108ms 748.970359ms 749.014055ms 749.06581ms 749.098513ms 749.13508ms 749.17773ms 749.203504ms 749.235398ms 749.242539ms 749.257884ms 749.286205ms 749.301742ms 749.396651ms 749.425986ms 749.428656ms 749.447966ms 749.463829ms 749.48059ms 749.544336ms 749.603148ms 749.650113ms 749.671194ms 749.822109ms 749.822367ms 749.867987ms 749.881965ms 749.883788ms 749.937943ms 749.944095ms 749.954085ms 749.98621ms 750.056782ms 750.13984ms 750.15314ms 750.235907ms 750.260599ms 750.318553ms 750.348358ms 750.452874ms 750.536984ms 750.569045ms 750.573446ms 750.642313ms 750.756072ms 751.007361ms 751.017465ms 751.488325ms 751.590018ms 751.699348ms 751.888863ms 751.985538ms 752.074403ms 752.141918ms 752.224981ms 752.608903ms 752.639986ms 753.380984ms 753.84541ms 753.874919ms 754.115873ms 754.252373ms 754.271392ms 754.534581ms 754.995047ms 755.454313ms 755.587717ms 755.953626ms 757.756541ms 758.374313ms 758.936803ms 760.635832ms 761.940054ms 761.984143ms 763.006202ms 764.609788ms 766.729694ms 767.940789ms 769.593097ms 772.089878ms 774.252516ms 777.119561ms 783.000912ms 783.782133ms 786.509124ms 787.777168ms 797.406433ms 799.482931ms 802.567859ms 822.237777ms 834.295016ms 835.902096ms 883.882484ms 888.282843ms 936.106861ms 938.181745ms]
Dec  3 20:34:43.331: INFO: 50 %ile: 748.278866ms
Dec  3 20:34:43.331: INFO: 90 %ile: 766.729694ms
Dec  3 20:34:43.332: INFO: 99 %ile: 936.106861ms
Dec  3 20:34:43.332: INFO: Total sample count: 200
[AfterEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 20:34:43.332: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-svc-latency-98tfc" for this suite.
Dec  3 20:34:55.348: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 20:34:55.396: INFO: namespace: e2e-tests-svc-latency-98tfc, resource: bindings, ignored listing per whitelist
Dec  3 20:34:55.459: INFO: namespace e2e-tests-svc-latency-98tfc deletion completed in 12.123399552s

• [SLOW TEST:23.067 seconds]
[sig-network] Service endpoints latency
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should not be very high  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-api-machinery] Downward API 
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 20:34:55.460: INFO: >>> kubeConfig: /tmp/kubeconfig-166913721
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Dec  3 20:34:55.571: INFO: Waiting up to 5m0s for pod "downward-api-e4e89e0f-f73a-11e8-8d0a-02420af40402" in namespace "e2e-tests-downward-api-sbhw7" to be "success or failure"
Dec  3 20:34:55.592: INFO: Pod "downward-api-e4e89e0f-f73a-11e8-8d0a-02420af40402": Phase="Pending", Reason="", readiness=false. Elapsed: 21.599224ms
Dec  3 20:34:57.596: INFO: Pod "downward-api-e4e89e0f-f73a-11e8-8d0a-02420af40402": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.025658479s
STEP: Saw pod success
Dec  3 20:34:57.596: INFO: Pod "downward-api-e4e89e0f-f73a-11e8-8d0a-02420af40402" satisfied condition "success or failure"
Dec  3 20:34:57.599: INFO: Trying to get logs from node hungry-keller-3o9a pod downward-api-e4e89e0f-f73a-11e8-8d0a-02420af40402 container dapi-container: <nil>
STEP: delete the pod
Dec  3 20:34:57.621: INFO: Waiting for pod downward-api-e4e89e0f-f73a-11e8-8d0a-02420af40402 to disappear
Dec  3 20:34:57.623: INFO: Pod downward-api-e4e89e0f-f73a-11e8-8d0a-02420af40402 no longer exists
[AfterEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 20:34:57.624: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-sbhw7" for this suite.
Dec  3 20:35:03.642: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 20:35:03.684: INFO: namespace: e2e-tests-downward-api-sbhw7, resource: bindings, ignored listing per whitelist
Dec  3 20:35:03.737: INFO: namespace e2e-tests-downward-api-sbhw7 deletion completed in 6.109875608s

• [SLOW TEST:8.277 seconds]
[sig-api-machinery] Downward API
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 20:35:03.737: INFO: >>> kubeConfig: /tmp/kubeconfig-166913721
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:98
[It] should run and stop simple daemon [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Dec  3 20:35:03.861: INFO: Number of nodes with available pods: 0
Dec  3 20:35:03.861: INFO: Node hungry-keller-3o96 is running more than one daemon pod
Dec  3 20:35:04.869: INFO: Number of nodes with available pods: 0
Dec  3 20:35:04.869: INFO: Node hungry-keller-3o96 is running more than one daemon pod
Dec  3 20:35:05.872: INFO: Number of nodes with available pods: 1
Dec  3 20:35:05.872: INFO: Node hungry-keller-3o96 is running more than one daemon pod
Dec  3 20:35:06.868: INFO: Number of nodes with available pods: 3
Dec  3 20:35:06.868: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Stop a daemon pod, check that the daemon pod is revived.
Dec  3 20:35:06.888: INFO: Number of nodes with available pods: 2
Dec  3 20:35:06.888: INFO: Node hungry-keller-3o9a is running more than one daemon pod
Dec  3 20:35:07.896: INFO: Number of nodes with available pods: 2
Dec  3 20:35:07.896: INFO: Node hungry-keller-3o9a is running more than one daemon pod
Dec  3 20:35:08.895: INFO: Number of nodes with available pods: 2
Dec  3 20:35:08.895: INFO: Node hungry-keller-3o9a is running more than one daemon pod
Dec  3 20:35:09.895: INFO: Number of nodes with available pods: 2
Dec  3 20:35:09.895: INFO: Node hungry-keller-3o9a is running more than one daemon pod
Dec  3 20:35:10.896: INFO: Number of nodes with available pods: 2
Dec  3 20:35:10.896: INFO: Node hungry-keller-3o9a is running more than one daemon pod
Dec  3 20:35:11.895: INFO: Number of nodes with available pods: 2
Dec  3 20:35:11.895: INFO: Node hungry-keller-3o9a is running more than one daemon pod
Dec  3 20:35:12.895: INFO: Number of nodes with available pods: 2
Dec  3 20:35:12.895: INFO: Node hungry-keller-3o9a is running more than one daemon pod
Dec  3 20:35:13.896: INFO: Number of nodes with available pods: 2
Dec  3 20:35:13.896: INFO: Node hungry-keller-3o9a is running more than one daemon pod
Dec  3 20:35:14.895: INFO: Number of nodes with available pods: 2
Dec  3 20:35:14.895: INFO: Node hungry-keller-3o9a is running more than one daemon pod
Dec  3 20:35:15.895: INFO: Number of nodes with available pods: 2
Dec  3 20:35:15.895: INFO: Node hungry-keller-3o9a is running more than one daemon pod
Dec  3 20:35:16.895: INFO: Number of nodes with available pods: 2
Dec  3 20:35:16.895: INFO: Node hungry-keller-3o9a is running more than one daemon pod
Dec  3 20:35:17.896: INFO: Number of nodes with available pods: 2
Dec  3 20:35:17.897: INFO: Node hungry-keller-3o9a is running more than one daemon pod
Dec  3 20:35:18.895: INFO: Number of nodes with available pods: 2
Dec  3 20:35:18.895: INFO: Node hungry-keller-3o9a is running more than one daemon pod
Dec  3 20:35:19.897: INFO: Number of nodes with available pods: 2
Dec  3 20:35:19.897: INFO: Node hungry-keller-3o9a is running more than one daemon pod
Dec  3 20:35:20.895: INFO: Number of nodes with available pods: 2
Dec  3 20:35:20.895: INFO: Node hungry-keller-3o9a is running more than one daemon pod
Dec  3 20:35:21.896: INFO: Number of nodes with available pods: 2
Dec  3 20:35:21.896: INFO: Node hungry-keller-3o9a is running more than one daemon pod
Dec  3 20:35:22.895: INFO: Number of nodes with available pods: 2
Dec  3 20:35:22.895: INFO: Node hungry-keller-3o9a is running more than one daemon pod
Dec  3 20:35:23.895: INFO: Number of nodes with available pods: 2
Dec  3 20:35:23.895: INFO: Node hungry-keller-3o9a is running more than one daemon pod
Dec  3 20:35:24.895: INFO: Number of nodes with available pods: 2
Dec  3 20:35:24.895: INFO: Node hungry-keller-3o9a is running more than one daemon pod
Dec  3 20:35:25.895: INFO: Number of nodes with available pods: 2
Dec  3 20:35:25.895: INFO: Node hungry-keller-3o9a is running more than one daemon pod
Dec  3 20:35:26.895: INFO: Number of nodes with available pods: 2
Dec  3 20:35:26.895: INFO: Node hungry-keller-3o9a is running more than one daemon pod
Dec  3 20:35:27.895: INFO: Number of nodes with available pods: 2
Dec  3 20:35:27.895: INFO: Node hungry-keller-3o9a is running more than one daemon pod
Dec  3 20:35:28.895: INFO: Number of nodes with available pods: 2
Dec  3 20:35:28.895: INFO: Node hungry-keller-3o9a is running more than one daemon pod
Dec  3 20:35:29.895: INFO: Number of nodes with available pods: 2
Dec  3 20:35:29.895: INFO: Node hungry-keller-3o9a is running more than one daemon pod
Dec  3 20:35:30.895: INFO: Number of nodes with available pods: 2
Dec  3 20:35:30.895: INFO: Node hungry-keller-3o9a is running more than one daemon pod
Dec  3 20:35:31.895: INFO: Number of nodes with available pods: 2
Dec  3 20:35:31.895: INFO: Node hungry-keller-3o9a is running more than one daemon pod
Dec  3 20:35:32.895: INFO: Number of nodes with available pods: 2
Dec  3 20:35:32.895: INFO: Node hungry-keller-3o9a is running more than one daemon pod
Dec  3 20:35:33.896: INFO: Number of nodes with available pods: 2
Dec  3 20:35:33.896: INFO: Node hungry-keller-3o9a is running more than one daemon pod
Dec  3 20:35:34.895: INFO: Number of nodes with available pods: 2
Dec  3 20:35:34.895: INFO: Node hungry-keller-3o9a is running more than one daemon pod
Dec  3 20:35:35.894: INFO: Number of nodes with available pods: 2
Dec  3 20:35:35.894: INFO: Node hungry-keller-3o9a is running more than one daemon pod
Dec  3 20:35:36.897: INFO: Number of nodes with available pods: 2
Dec  3 20:35:36.897: INFO: Node hungry-keller-3o9a is running more than one daemon pod
Dec  3 20:35:37.907: INFO: Number of nodes with available pods: 2
Dec  3 20:35:37.907: INFO: Node hungry-keller-3o9a is running more than one daemon pod
Dec  3 20:35:38.897: INFO: Number of nodes with available pods: 2
Dec  3 20:35:38.897: INFO: Node hungry-keller-3o9a is running more than one daemon pod
Dec  3 20:35:39.895: INFO: Number of nodes with available pods: 2
Dec  3 20:35:39.895: INFO: Node hungry-keller-3o9a is running more than one daemon pod
Dec  3 20:35:40.896: INFO: Number of nodes with available pods: 2
Dec  3 20:35:40.896: INFO: Node hungry-keller-3o9a is running more than one daemon pod
Dec  3 20:35:41.895: INFO: Number of nodes with available pods: 2
Dec  3 20:35:41.895: INFO: Node hungry-keller-3o9a is running more than one daemon pod
Dec  3 20:35:42.895: INFO: Number of nodes with available pods: 2
Dec  3 20:35:42.895: INFO: Node hungry-keller-3o9a is running more than one daemon pod
Dec  3 20:35:43.895: INFO: Number of nodes with available pods: 3
Dec  3 20:35:43.895: INFO: Number of running nodes: 3, number of available pods: 3
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:64
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting {extensions DaemonSet} daemon-set in namespace e2e-tests-daemonsets-grl6w, will wait for the garbage collector to delete the pods
Dec  3 20:35:43.959: INFO: Deleting {extensions DaemonSet} daemon-set took: 9.492013ms
Dec  3 20:35:44.060: INFO: Terminating {extensions DaemonSet} daemon-set pods took: 100.29599ms
Dec  3 20:36:24.763: INFO: Number of nodes with available pods: 0
Dec  3 20:36:24.763: INFO: Number of running nodes: 0, number of available pods: 0
Dec  3 20:36:24.766: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-grl6w/daemonsets","resourceVersion":"13848"},"items":null}

Dec  3 20:36:24.768: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-grl6w/pods","resourceVersion":"13848"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 20:36:24.778: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-grl6w" for this suite.
Dec  3 20:36:30.791: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 20:36:30.820: INFO: namespace: e2e-tests-daemonsets-grl6w, resource: bindings, ignored listing per whitelist
Dec  3 20:36:30.874: INFO: namespace e2e-tests-daemonsets-grl6w deletion completed in 6.092561802s

• [SLOW TEST:87.136 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] EmptyDir volumes 
  volume on default medium should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 20:36:30.874: INFO: >>> kubeConfig: /tmp/kubeconfig-166913721
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on default medium should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir volume type on node default medium
Dec  3 20:36:30.948: INFO: Waiting up to 5m0s for pod "pod-1dc59e6d-f73b-11e8-8d0a-02420af40402" in namespace "e2e-tests-emptydir-ttv58" to be "success or failure"
Dec  3 20:36:30.959: INFO: Pod "pod-1dc59e6d-f73b-11e8-8d0a-02420af40402": Phase="Pending", Reason="", readiness=false. Elapsed: 10.265222ms
Dec  3 20:36:32.963: INFO: Pod "pod-1dc59e6d-f73b-11e8-8d0a-02420af40402": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015213892s
Dec  3 20:36:34.967: INFO: Pod "pod-1dc59e6d-f73b-11e8-8d0a-02420af40402": Phase="Running", Reason="", readiness=true. Elapsed: 4.018786338s
Dec  3 20:36:36.972: INFO: Pod "pod-1dc59e6d-f73b-11e8-8d0a-02420af40402": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.02352488s
STEP: Saw pod success
Dec  3 20:36:36.972: INFO: Pod "pod-1dc59e6d-f73b-11e8-8d0a-02420af40402" satisfied condition "success or failure"
Dec  3 20:36:36.975: INFO: Trying to get logs from node hungry-keller-3o9a pod pod-1dc59e6d-f73b-11e8-8d0a-02420af40402 container test-container: <nil>
STEP: delete the pod
Dec  3 20:36:36.999: INFO: Waiting for pod pod-1dc59e6d-f73b-11e8-8d0a-02420af40402 to disappear
Dec  3 20:36:37.006: INFO: Pod pod-1dc59e6d-f73b-11e8-8d0a-02420af40402 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 20:36:37.006: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-ttv58" for this suite.
Dec  3 20:36:43.021: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 20:36:43.050: INFO: namespace: e2e-tests-emptydir-ttv58, resource: bindings, ignored listing per whitelist
Dec  3 20:36:43.112: INFO: namespace e2e-tests-emptydir-ttv58 deletion completed in 6.101587797s

• [SLOW TEST:12.238 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  volume on default medium should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 20:36:43.112: INFO: >>> kubeConfig: /tmp/kubeconfig-166913721
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-2519b7ea-f73b-11e8-8d0a-02420af40402
STEP: Creating a pod to test consume secrets
Dec  3 20:36:43.247: INFO: Waiting up to 5m0s for pod "pod-secrets-251a4249-f73b-11e8-8d0a-02420af40402" in namespace "e2e-tests-secrets-g99hc" to be "success or failure"
Dec  3 20:36:43.263: INFO: Pod "pod-secrets-251a4249-f73b-11e8-8d0a-02420af40402": Phase="Pending", Reason="", readiness=false. Elapsed: 15.74282ms
Dec  3 20:36:45.267: INFO: Pod "pod-secrets-251a4249-f73b-11e8-8d0a-02420af40402": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.019602672s
STEP: Saw pod success
Dec  3 20:36:45.267: INFO: Pod "pod-secrets-251a4249-f73b-11e8-8d0a-02420af40402" satisfied condition "success or failure"
Dec  3 20:36:45.269: INFO: Trying to get logs from node hungry-keller-3o9a pod pod-secrets-251a4249-f73b-11e8-8d0a-02420af40402 container secret-volume-test: <nil>
STEP: delete the pod
Dec  3 20:36:45.292: INFO: Waiting for pod pod-secrets-251a4249-f73b-11e8-8d0a-02420af40402 to disappear
Dec  3 20:36:45.295: INFO: Pod pod-secrets-251a4249-f73b-11e8-8d0a-02420af40402 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 20:36:45.296: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-g99hc" for this suite.
Dec  3 20:36:51.309: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 20:36:51.385: INFO: namespace: e2e-tests-secrets-g99hc, resource: bindings, ignored listing per whitelist
Dec  3 20:36:51.401: INFO: namespace e2e-tests-secrets-g99hc deletion completed in 6.102580937s

• [SLOW TEST:8.289 seconds]
[sig-storage] Secrets
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 20:36:51.403: INFO: >>> kubeConfig: /tmp/kubeconfig-166913721
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test substitution in container's command
Dec  3 20:36:51.479: INFO: Waiting up to 5m0s for pod "var-expansion-2a024df9-f73b-11e8-8d0a-02420af40402" in namespace "e2e-tests-var-expansion-hj57k" to be "success or failure"
Dec  3 20:36:51.489: INFO: Pod "var-expansion-2a024df9-f73b-11e8-8d0a-02420af40402": Phase="Pending", Reason="", readiness=false. Elapsed: 9.764526ms
Dec  3 20:36:53.493: INFO: Pod "var-expansion-2a024df9-f73b-11e8-8d0a-02420af40402": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013578054s
Dec  3 20:36:55.498: INFO: Pod "var-expansion-2a024df9-f73b-11e8-8d0a-02420af40402": Phase="Pending", Reason="", readiness=false. Elapsed: 4.018661364s
Dec  3 20:36:57.501: INFO: Pod "var-expansion-2a024df9-f73b-11e8-8d0a-02420af40402": Phase="Pending", Reason="", readiness=false. Elapsed: 6.022246366s
Dec  3 20:36:59.505: INFO: Pod "var-expansion-2a024df9-f73b-11e8-8d0a-02420af40402": Phase="Pending", Reason="", readiness=false. Elapsed: 8.026242886s
Dec  3 20:37:01.509: INFO: Pod "var-expansion-2a024df9-f73b-11e8-8d0a-02420af40402": Phase="Succeeded", Reason="", readiness=false. Elapsed: 10.030100981s
STEP: Saw pod success
Dec  3 20:37:01.509: INFO: Pod "var-expansion-2a024df9-f73b-11e8-8d0a-02420af40402" satisfied condition "success or failure"
Dec  3 20:37:01.512: INFO: Trying to get logs from node hungry-keller-3o9a pod var-expansion-2a024df9-f73b-11e8-8d0a-02420af40402 container dapi-container: <nil>
STEP: delete the pod
Dec  3 20:37:01.642: INFO: Waiting for pod var-expansion-2a024df9-f73b-11e8-8d0a-02420af40402 to disappear
Dec  3 20:37:01.645: INFO: Pod var-expansion-2a024df9-f73b-11e8-8d0a-02420af40402 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 20:37:01.645: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-var-expansion-hj57k" for this suite.
Dec  3 20:37:07.662: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 20:37:07.713: INFO: namespace: e2e-tests-var-expansion-hj57k, resource: bindings, ignored listing per whitelist
Dec  3 20:37:07.745: INFO: namespace e2e-tests-var-expansion-hj57k deletion completed in 6.093935332s

• [SLOW TEST:16.342 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[k8s.io] Pods 
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 20:37:07.745: INFO: >>> kubeConfig: /tmp/kubeconfig-166913721
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Dec  3 20:37:09.878: INFO: Waiting up to 5m0s for pod "client-envvars-34f87442-f73b-11e8-8d0a-02420af40402" in namespace "e2e-tests-pods-f8k85" to be "success or failure"
Dec  3 20:37:09.903: INFO: Pod "client-envvars-34f87442-f73b-11e8-8d0a-02420af40402": Phase="Pending", Reason="", readiness=false. Elapsed: 25.631723ms
Dec  3 20:37:11.908: INFO: Pod "client-envvars-34f87442-f73b-11e8-8d0a-02420af40402": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.029853702s
STEP: Saw pod success
Dec  3 20:37:11.908: INFO: Pod "client-envvars-34f87442-f73b-11e8-8d0a-02420af40402" satisfied condition "success or failure"
Dec  3 20:37:11.913: INFO: Trying to get logs from node hungry-keller-3o9e pod client-envvars-34f87442-f73b-11e8-8d0a-02420af40402 container env3cont: <nil>
STEP: delete the pod
Dec  3 20:37:11.943: INFO: Waiting for pod client-envvars-34f87442-f73b-11e8-8d0a-02420af40402 to disappear
Dec  3 20:37:11.953: INFO: Pod client-envvars-34f87442-f73b-11e8-8d0a-02420af40402 no longer exists
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 20:37:11.953: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-f8k85" for this suite.
Dec  3 20:37:58.006: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 20:37:58.053: INFO: namespace: e2e-tests-pods-f8k85, resource: bindings, ignored listing per whitelist
Dec  3 20:37:58.091: INFO: namespace e2e-tests-pods-f8k85 deletion completed in 46.134818365s

• [SLOW TEST:50.346 seconds]
[k8s.io] Pods
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 20:37:58.093: INFO: >>> kubeConfig: /tmp/kubeconfig-166913721
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Dec  3 20:37:58.228: INFO: Waiting up to 5m0s for pod "downwardapi-volume-51cb4265-f73b-11e8-8d0a-02420af40402" in namespace "e2e-tests-projected-7q4s9" to be "success or failure"
Dec  3 20:37:58.237: INFO: Pod "downwardapi-volume-51cb4265-f73b-11e8-8d0a-02420af40402": Phase="Pending", Reason="", readiness=false. Elapsed: 9.621875ms
Dec  3 20:38:00.241: INFO: Pod "downwardapi-volume-51cb4265-f73b-11e8-8d0a-02420af40402": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.013413096s
STEP: Saw pod success
Dec  3 20:38:00.241: INFO: Pod "downwardapi-volume-51cb4265-f73b-11e8-8d0a-02420af40402" satisfied condition "success or failure"
Dec  3 20:38:00.244: INFO: Trying to get logs from node hungry-keller-3o9a pod downwardapi-volume-51cb4265-f73b-11e8-8d0a-02420af40402 container client-container: <nil>
STEP: delete the pod
Dec  3 20:38:00.753: INFO: Waiting for pod downwardapi-volume-51cb4265-f73b-11e8-8d0a-02420af40402 to disappear
Dec  3 20:38:00.756: INFO: Pod downwardapi-volume-51cb4265-f73b-11e8-8d0a-02420af40402 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 20:38:00.756: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-7q4s9" for this suite.
Dec  3 20:38:06.876: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 20:38:06.952: INFO: namespace: e2e-tests-projected-7q4s9, resource: bindings, ignored listing per whitelist
Dec  3 20:38:06.960: INFO: namespace e2e-tests-projected-7q4s9 deletion completed in 6.201259996s

• [SLOW TEST:8.867 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 20:38:06.960: INFO: >>> kubeConfig: /tmp/kubeconfig-166913721
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-w4kjd
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Dec  3 20:38:07.019: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Dec  3 20:38:29.135: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.244.4.4:8080/dial?request=hostName&protocol=http&host=10.244.72.3&port=8080&tries=1'] Namespace:e2e-tests-pod-network-test-w4kjd PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec  3 20:38:29.135: INFO: >>> kubeConfig: /tmp/kubeconfig-166913721
Dec  3 20:38:29.327: INFO: Waiting for endpoints: map[]
Dec  3 20:38:29.332: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.244.4.4:8080/dial?request=hostName&protocol=http&host=10.244.4.3&port=8080&tries=1'] Namespace:e2e-tests-pod-network-test-w4kjd PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec  3 20:38:29.332: INFO: >>> kubeConfig: /tmp/kubeconfig-166913721
Dec  3 20:38:29.575: INFO: Waiting for endpoints: map[]
Dec  3 20:38:29.579: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.244.4.4:8080/dial?request=hostName&protocol=http&host=10.244.1.4&port=8080&tries=1'] Namespace:e2e-tests-pod-network-test-w4kjd PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec  3 20:38:29.579: INFO: >>> kubeConfig: /tmp/kubeconfig-166913721
Dec  3 20:38:29.831: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 20:38:29.831: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-w4kjd" for this suite.
Dec  3 20:38:51.858: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 20:38:51.896: INFO: namespace: e2e-tests-pod-network-test-w4kjd, resource: bindings, ignored listing per whitelist
Dec  3 20:38:51.950: INFO: namespace e2e-tests-pod-network-test-w4kjd deletion completed in 22.114418422s

• [SLOW TEST:44.990 seconds]
[sig-network] Networking
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: http [NodeConformance] [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Secrets 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 20:38:51.950: INFO: >>> kubeConfig: /tmp/kubeconfig-166913721
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name s-test-opt-del-71dc79ce-f73b-11e8-8d0a-02420af40402
STEP: Creating secret with name s-test-opt-upd-71dc7a2c-f73b-11e8-8d0a-02420af40402
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-71dc79ce-f73b-11e8-8d0a-02420af40402
STEP: Updating secret s-test-opt-upd-71dc7a2c-f73b-11e8-8d0a-02420af40402
STEP: Creating secret with name s-test-opt-create-71dc7a4d-f73b-11e8-8d0a-02420af40402
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 20:40:08.578: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-jqh94" for this suite.
Dec  3 20:40:30.593: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 20:40:30.664: INFO: namespace: e2e-tests-secrets-jqh94, resource: bindings, ignored listing per whitelist
Dec  3 20:40:30.674: INFO: namespace e2e-tests-secrets-jqh94 deletion completed in 22.092783063s

• [SLOW TEST:98.724 seconds]
[sig-storage] Secrets
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 20:40:30.674: INFO: >>> kubeConfig: /tmp/kubeconfig-166913721
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Dec  3 20:40:30.804: INFO: Waiting up to 5m0s for pod "downwardapi-volume-acbc7c81-f73b-11e8-8d0a-02420af40402" in namespace "e2e-tests-downward-api-8ckgd" to be "success or failure"
Dec  3 20:40:30.812: INFO: Pod "downwardapi-volume-acbc7c81-f73b-11e8-8d0a-02420af40402": Phase="Pending", Reason="", readiness=false. Elapsed: 8.3307ms
Dec  3 20:40:32.816: INFO: Pod "downwardapi-volume-acbc7c81-f73b-11e8-8d0a-02420af40402": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012163213s
Dec  3 20:40:34.819: INFO: Pod "downwardapi-volume-acbc7c81-f73b-11e8-8d0a-02420af40402": Phase="Pending", Reason="", readiness=false. Elapsed: 4.015592083s
Dec  3 20:40:36.823: INFO: Pod "downwardapi-volume-acbc7c81-f73b-11e8-8d0a-02420af40402": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.018993594s
STEP: Saw pod success
Dec  3 20:40:36.823: INFO: Pod "downwardapi-volume-acbc7c81-f73b-11e8-8d0a-02420af40402" satisfied condition "success or failure"
Dec  3 20:40:36.825: INFO: Trying to get logs from node hungry-keller-3o9a pod downwardapi-volume-acbc7c81-f73b-11e8-8d0a-02420af40402 container client-container: <nil>
STEP: delete the pod
Dec  3 20:40:36.855: INFO: Waiting for pod downwardapi-volume-acbc7c81-f73b-11e8-8d0a-02420af40402 to disappear
Dec  3 20:40:36.868: INFO: Pod downwardapi-volume-acbc7c81-f73b-11e8-8d0a-02420af40402 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 20:40:36.868: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-8ckgd" for this suite.
Dec  3 20:40:42.882: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 20:40:42.900: INFO: namespace: e2e-tests-downward-api-8ckgd, resource: bindings, ignored listing per whitelist
Dec  3 20:40:42.971: INFO: namespace e2e-tests-downward-api-8ckgd deletion completed in 6.099334807s

• [SLOW TEST:12.297 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 20:40:42.973: INFO: >>> kubeConfig: /tmp/kubeconfig-166913721
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-b4089631-f73b-11e8-8d0a-02420af40402
STEP: Creating a pod to test consume secrets
Dec  3 20:40:43.049: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-b4092b4c-f73b-11e8-8d0a-02420af40402" in namespace "e2e-tests-projected-jkjq6" to be "success or failure"
Dec  3 20:40:43.057: INFO: Pod "pod-projected-secrets-b4092b4c-f73b-11e8-8d0a-02420af40402": Phase="Pending", Reason="", readiness=false. Elapsed: 7.35788ms
Dec  3 20:40:45.060: INFO: Pod "pod-projected-secrets-b4092b4c-f73b-11e8-8d0a-02420af40402": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010791608s
Dec  3 20:40:47.064: INFO: Pod "pod-projected-secrets-b4092b4c-f73b-11e8-8d0a-02420af40402": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014413159s
STEP: Saw pod success
Dec  3 20:40:47.064: INFO: Pod "pod-projected-secrets-b4092b4c-f73b-11e8-8d0a-02420af40402" satisfied condition "success or failure"
Dec  3 20:40:47.066: INFO: Trying to get logs from node hungry-keller-3o9a pod pod-projected-secrets-b4092b4c-f73b-11e8-8d0a-02420af40402 container projected-secret-volume-test: <nil>
STEP: delete the pod
Dec  3 20:40:47.092: INFO: Waiting for pod pod-projected-secrets-b4092b4c-f73b-11e8-8d0a-02420af40402 to disappear
Dec  3 20:40:47.096: INFO: Pod pod-projected-secrets-b4092b4c-f73b-11e8-8d0a-02420af40402 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 20:40:47.096: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-jkjq6" for this suite.
Dec  3 20:40:53.110: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 20:40:53.193: INFO: namespace: e2e-tests-projected-jkjq6, resource: bindings, ignored listing per whitelist
Dec  3 20:40:53.197: INFO: namespace e2e-tests-projected-jkjq6 deletion completed in 6.097674658s

• [SLOW TEST:10.225 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-api-machinery] ConfigMap 
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 20:40:53.198: INFO: >>> kubeConfig: /tmp/kubeconfig-166913721
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap e2e-tests-configmap-dntc5/configmap-test-ba22b26a-f73b-11e8-8d0a-02420af40402
STEP: Creating a pod to test consume configMaps
Dec  3 20:40:53.291: INFO: Waiting up to 5m0s for pod "pod-configmaps-ba233943-f73b-11e8-8d0a-02420af40402" in namespace "e2e-tests-configmap-dntc5" to be "success or failure"
Dec  3 20:40:53.304: INFO: Pod "pod-configmaps-ba233943-f73b-11e8-8d0a-02420af40402": Phase="Pending", Reason="", readiness=false. Elapsed: 12.868706ms
Dec  3 20:40:55.308: INFO: Pod "pod-configmaps-ba233943-f73b-11e8-8d0a-02420af40402": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01673949s
Dec  3 20:40:57.313: INFO: Pod "pod-configmaps-ba233943-f73b-11e8-8d0a-02420af40402": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.02180199s
STEP: Saw pod success
Dec  3 20:40:57.313: INFO: Pod "pod-configmaps-ba233943-f73b-11e8-8d0a-02420af40402" satisfied condition "success or failure"
Dec  3 20:40:57.316: INFO: Trying to get logs from node hungry-keller-3o9a pod pod-configmaps-ba233943-f73b-11e8-8d0a-02420af40402 container env-test: <nil>
STEP: delete the pod
Dec  3 20:40:57.338: INFO: Waiting for pod pod-configmaps-ba233943-f73b-11e8-8d0a-02420af40402 to disappear
Dec  3 20:40:57.341: INFO: Pod pod-configmaps-ba233943-f73b-11e8-8d0a-02420af40402 no longer exists
[AfterEach] [sig-api-machinery] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 20:40:57.341: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-dntc5" for this suite.
Dec  3 20:41:03.354: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 20:41:03.425: INFO: namespace: e2e-tests-configmap-dntc5, resource: bindings, ignored listing per whitelist
Dec  3 20:41:03.447: INFO: namespace e2e-tests-configmap-dntc5 deletion completed in 6.103129411s

• [SLOW TEST:10.249 seconds]
[sig-api-machinery] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:30
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 20:41:03.447: INFO: >>> kubeConfig: /tmp/kubeconfig-166913721
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-gfpth
[It] should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a new StatefulSet
Dec  3 20:41:03.553: INFO: Found 0 stateful pods, waiting for 3
Dec  3 20:41:13.557: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Dec  3 20:41:13.557: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Dec  3 20:41:13.557: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
Dec  3 20:41:13.565: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-166913721 exec --namespace=e2e-tests-statefulset-gfpth ss2-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Dec  3 20:41:13.823: INFO: stderr: ""
Dec  3 20:41:13.823: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Dec  3 20:41:13.823: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss2-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

STEP: Updating StatefulSet template: update image from docker.io/library/nginx:1.14-alpine to docker.io/library/nginx:1.15-alpine
Dec  3 20:41:23.856: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Updating Pods in reverse ordinal order
Dec  3 20:41:23.874: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-166913721 exec --namespace=e2e-tests-statefulset-gfpth ss2-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec  3 20:41:24.147: INFO: stderr: ""
Dec  3 20:41:24.147: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Dec  3 20:41:24.147: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss2-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Dec  3 20:41:44.168: INFO: Waiting for StatefulSet e2e-tests-statefulset-gfpth/ss2 to complete update
STEP: Rolling back to a previous revision
Dec  3 20:41:54.175: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-166913721 exec --namespace=e2e-tests-statefulset-gfpth ss2-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Dec  3 20:41:54.517: INFO: stderr: ""
Dec  3 20:41:54.517: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Dec  3 20:41:54.517: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss2-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Dec  3 20:42:04.550: INFO: Updating stateful set ss2
STEP: Rolling back update in reverse ordinal order
Dec  3 20:42:04.592: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-166913721 exec --namespace=e2e-tests-statefulset-gfpth ss2-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec  3 20:42:04.898: INFO: stderr: ""
Dec  3 20:42:04.898: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Dec  3 20:42:04.898: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss2-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Dec  3 20:42:04.953: INFO: Waiting for StatefulSet e2e-tests-statefulset-gfpth/ss2 to complete update
Dec  3 20:42:04.953: INFO: Waiting for Pod e2e-tests-statefulset-gfpth/ss2-0 to have revision ss2-787997d666 update revision ss2-c79899b9
Dec  3 20:42:04.953: INFO: Waiting for Pod e2e-tests-statefulset-gfpth/ss2-1 to have revision ss2-787997d666 update revision ss2-c79899b9
Dec  3 20:42:04.953: INFO: Waiting for Pod e2e-tests-statefulset-gfpth/ss2-2 to have revision ss2-787997d666 update revision ss2-c79899b9
Dec  3 20:42:14.963: INFO: Waiting for StatefulSet e2e-tests-statefulset-gfpth/ss2 to complete update
Dec  3 20:42:14.963: INFO: Waiting for Pod e2e-tests-statefulset-gfpth/ss2-0 to have revision ss2-787997d666 update revision ss2-c79899b9
Dec  3 20:42:24.960: INFO: Waiting for StatefulSet e2e-tests-statefulset-gfpth/ss2 to complete update
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Dec  3 20:42:34.960: INFO: Deleting all statefulset in ns e2e-tests-statefulset-gfpth
Dec  3 20:42:34.963: INFO: Scaling statefulset ss2 to 0
Dec  3 20:42:54.987: INFO: Waiting for statefulset status.replicas updated to 0
Dec  3 20:42:54.990: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 20:42:55.016: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-gfpth" for this suite.
Dec  3 20:43:01.032: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 20:43:01.054: INFO: namespace: e2e-tests-statefulset-gfpth, resource: bindings, ignored listing per whitelist
Dec  3 20:43:01.125: INFO: namespace e2e-tests-statefulset-gfpth deletion completed in 6.105066022s

• [SLOW TEST:117.679 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should perform rolling updates and roll backs of template modifications [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 20:43:01.126: INFO: >>> kubeConfig: /tmp/kubeconfig-166913721
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-06614445-f73c-11e8-8d0a-02420af40402
STEP: Creating a pod to test consume configMaps
Dec  3 20:43:01.204: INFO: Waiting up to 5m0s for pod "pod-configmaps-0661d684-f73c-11e8-8d0a-02420af40402" in namespace "e2e-tests-configmap-rbpgq" to be "success or failure"
Dec  3 20:43:01.211: INFO: Pod "pod-configmaps-0661d684-f73c-11e8-8d0a-02420af40402": Phase="Pending", Reason="", readiness=false. Elapsed: 7.439827ms
Dec  3 20:43:03.216: INFO: Pod "pod-configmaps-0661d684-f73c-11e8-8d0a-02420af40402": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011805219s
Dec  3 20:43:05.220: INFO: Pod "pod-configmaps-0661d684-f73c-11e8-8d0a-02420af40402": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.01594542s
STEP: Saw pod success
Dec  3 20:43:05.220: INFO: Pod "pod-configmaps-0661d684-f73c-11e8-8d0a-02420af40402" satisfied condition "success or failure"
Dec  3 20:43:05.222: INFO: Trying to get logs from node hungry-keller-3o9a pod pod-configmaps-0661d684-f73c-11e8-8d0a-02420af40402 container configmap-volume-test: <nil>
STEP: delete the pod
Dec  3 20:43:05.243: INFO: Waiting for pod pod-configmaps-0661d684-f73c-11e8-8d0a-02420af40402 to disappear
Dec  3 20:43:05.248: INFO: Pod pod-configmaps-0661d684-f73c-11e8-8d0a-02420af40402 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 20:43:05.248: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-rbpgq" for this suite.
Dec  3 20:43:11.262: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 20:43:11.348: INFO: namespace: e2e-tests-configmap-rbpgq, resource: bindings, ignored listing per whitelist
Dec  3 20:43:11.353: INFO: namespace e2e-tests-configmap-rbpgq deletion completed in 6.10121767s

• [SLOW TEST:10.227 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-apps] Deployment 
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 20:43:11.353: INFO: >>> kubeConfig: /tmp/kubeconfig-166913721
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Dec  3 20:43:11.423: INFO: Creating deployment "nginx-deployment"
Dec  3 20:43:11.432: INFO: Waiting for observed generation 1
Dec  3 20:43:13.466: INFO: Waiting for all required pods to come up
Dec  3 20:43:13.474: INFO: Pod name nginx: Found 10 pods out of 10
STEP: ensuring each pod is running
Dec  3 20:43:15.499: INFO: Waiting for deployment "nginx-deployment" to complete
Dec  3 20:43:15.506: INFO: Updating deployment "nginx-deployment" with a non-existent image
Dec  3 20:43:15.516: INFO: Updating deployment nginx-deployment
Dec  3 20:43:15.516: INFO: Waiting for observed generation 2
Dec  3 20:43:17.719: INFO: Waiting for the first rollout's replicaset to have .status.availableReplicas = 8
Dec  3 20:43:17.722: INFO: Waiting for the first rollout's replicaset to have .spec.replicas = 8
Dec  3 20:43:17.724: INFO: Waiting for the first rollout's replicaset of deployment "nginx-deployment" to have desired number of replicas
Dec  3 20:43:17.732: INFO: Verifying that the second rollout's replicaset has .status.availableReplicas = 0
Dec  3 20:43:17.733: INFO: Waiting for the second rollout's replicaset to have .spec.replicas = 5
Dec  3 20:43:17.735: INFO: Waiting for the second rollout's replicaset of deployment "nginx-deployment" to have desired number of replicas
Dec  3 20:43:17.740: INFO: Verifying that deployment "nginx-deployment" has minimum required number of available replicas
Dec  3 20:43:17.740: INFO: Scaling up the deployment "nginx-deployment" from 10 to 30
Dec  3 20:43:17.748: INFO: Updating deployment nginx-deployment
Dec  3 20:43:17.748: INFO: Waiting for the replicasets of deployment "nginx-deployment" to have desired number of replicas
Dec  3 20:43:17.797: INFO: Verifying that first rollout's replicaset has .spec.replicas = 20
Dec  3 20:43:20.161: INFO: Verifying that second rollout's replicaset has .spec.replicas = 13
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Dec  3 20:43:20.468: INFO: Deployment "nginx-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment,GenerateName:,Namespace:e2e-tests-deployment-wxrn4,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-wxrn4/deployments/nginx-deployment,UID:0c7b2472-f73c-11e8-8af3-a28d93e01224,ResourceVersion:15473,Generation:3,CreationTimestamp:2018-12-03 20:43:11 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*30,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:2,MaxSurge:3,},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:3,Replicas:33,UpdatedReplicas:13,AvailableReplicas:8,UnavailableReplicas:25,Conditions:[{Available False 2018-12-03 20:43:17 +0000 UTC 2018-12-03 20:43:17 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.} {Progressing True 2018-12-03 20:43:18 +0000 UTC 2018-12-03 20:43:11 +0000 UTC ReplicaSetUpdated ReplicaSet "nginx-deployment-7dc8f79789" is progressing.}],ReadyReplicas:8,CollisionCount:nil,},}

Dec  3 20:43:20.496: INFO: New ReplicaSet "nginx-deployment-7dc8f79789" of Deployment "nginx-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789,GenerateName:,Namespace:e2e-tests-deployment-wxrn4,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-wxrn4/replicasets/nginx-deployment-7dc8f79789,UID:0eeb9add-f73c-11e8-8af3-a28d93e01224,ResourceVersion:15466,Generation:3,CreationTimestamp:2018-12-03 20:43:15 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 30,deployment.kubernetes.io/max-replicas: 33,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment nginx-deployment 0c7b2472-f73c-11e8-8af3-a28d93e01224 0xc420fec207 0xc420fec208}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*13,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:13,FullyLabeledReplicas:13,ObservedGeneration:3,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Dec  3 20:43:20.496: INFO: All old ReplicaSets of Deployment "nginx-deployment":
Dec  3 20:43:20.496: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b,GenerateName:,Namespace:e2e-tests-deployment-wxrn4,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-wxrn4/replicasets/nginx-deployment-7f9675fb8b,UID:0c7c6c97-f73c-11e8-8af3-a28d93e01224,ResourceVersion:15465,Generation:3,CreationTimestamp:2018-12-03 20:43:11 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 30,deployment.kubernetes.io/max-replicas: 33,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment nginx-deployment 0c7b2472-f73c-11e8-8af3-a28d93e01224 0xc420fec2c7 0xc420fec2c8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*20,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:20,FullyLabeledReplicas:20,ObservedGeneration:3,ReadyReplicas:8,AvailableReplicas:8,Conditions:[],},}
Dec  3 20:43:20.510: INFO: Pod "nginx-deployment-7dc8f79789-2pmd7" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-2pmd7,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-wxrn4,SelfLink:/api/v1/namespaces/e2e-tests-deployment-wxrn4/pods/nginx-deployment-7dc8f79789-2pmd7,UID:0f0aac6c-f73c-11e8-8af3-a28d93e01224,ResourceVersion:15394,Generation:0,CreationTimestamp:2018-12-03 20:43:15 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 0eeb9add-f73c-11e8-8af3-a28d93e01224 0xc42193cfb7 0xc42193cfb8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-gbfqg {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-gbfqg,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-gbfqg true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:hungry-keller-3o96,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc42193d020} {node.kubernetes.io/unreachable Exists  NoExecute 0xc42193d040}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-03 20:43:15 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-03 20:43:15 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-03 20:43:15 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-03 20:43:15 +0000 UTC  }],Message:,Reason:,HostIP:10.136.127.223,PodIP:10.244.1.7,StartTime:2018-12-03 20:43:15 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = Error response from daemon: manifest for nginx:404 not found,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec  3 20:43:20.510: INFO: Pod "nginx-deployment-7dc8f79789-7m2ds" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-7m2ds,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-wxrn4,SelfLink:/api/v1/namespaces/e2e-tests-deployment-wxrn4/pods/nginx-deployment-7dc8f79789-7m2ds,UID:105b022d-f73c-11e8-8af3-a28d93e01224,ResourceVersion:15511,Generation:0,CreationTimestamp:2018-12-03 20:43:17 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 0eeb9add-f73c-11e8-8af3-a28d93e01224 0xc42193d1d0 0xc42193d1d1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-gbfqg {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-gbfqg,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-gbfqg true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:hungry-keller-3o9e,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc42193d2b0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc42193d2d0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-03 20:43:18 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-03 20:43:18 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-03 20:43:18 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-03 20:43:18 +0000 UTC  }],Message:,Reason:,HostIP:10.136.45.151,PodIP:,StartTime:2018-12-03 20:43:18 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec  3 20:43:20.510: INFO: Pod "nginx-deployment-7dc8f79789-92drb" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-92drb,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-wxrn4,SelfLink:/api/v1/namespaces/e2e-tests-deployment-wxrn4/pods/nginx-deployment-7dc8f79789-92drb,UID:10538ae5-f73c-11e8-8af3-a28d93e01224,ResourceVersion:15541,Generation:0,CreationTimestamp:2018-12-03 20:43:17 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 0eeb9add-f73c-11e8-8af3-a28d93e01224 0xc42193d400 0xc42193d401}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-gbfqg {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-gbfqg,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-gbfqg true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:hungry-keller-3o9e,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc42193d470} {node.kubernetes.io/unreachable Exists  NoExecute 0xc42193d490}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-03 20:43:18 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-03 20:43:18 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-03 20:43:18 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-03 20:43:17 +0000 UTC  }],Message:,Reason:,HostIP:10.136.45.151,PodIP:10.244.4.11,StartTime:2018-12-03 20:43:18 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = Error response from daemon: manifest for nginx:404 not found,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec  3 20:43:20.510: INFO: Pod "nginx-deployment-7dc8f79789-98bkh" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-98bkh,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-wxrn4,SelfLink:/api/v1/namespaces/e2e-tests-deployment-wxrn4/pods/nginx-deployment-7dc8f79789-98bkh,UID:0f19938e-f73c-11e8-8af3-a28d93e01224,ResourceVersion:15476,Generation:0,CreationTimestamp:2018-12-03 20:43:15 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 0eeb9add-f73c-11e8-8af3-a28d93e01224 0xc42193d690 0xc42193d691}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-gbfqg {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-gbfqg,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-gbfqg true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:hungry-keller-3o9e,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc42193d760} {node.kubernetes.io/unreachable Exists  NoExecute 0xc42193d780}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-03 20:43:15 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-03 20:43:15 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-03 20:43:15 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-03 20:43:15 +0000 UTC  }],Message:,Reason:,HostIP:10.136.45.151,PodIP:10.244.4.7,StartTime:2018-12-03 20:43:15 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = Error response from daemon: manifest for nginx:404 not found,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec  3 20:43:20.511: INFO: Pod "nginx-deployment-7dc8f79789-bq2xb" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-bq2xb,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-wxrn4,SelfLink:/api/v1/namespaces/e2e-tests-deployment-wxrn4/pods/nginx-deployment-7dc8f79789-bq2xb,UID:0f16a5fd-f73c-11e8-8af3-a28d93e01224,ResourceVersion:15387,Generation:0,CreationTimestamp:2018-12-03 20:43:15 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 0eeb9add-f73c-11e8-8af3-a28d93e01224 0xc42193d8a0 0xc42193d8a1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-gbfqg {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-gbfqg,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-gbfqg true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:hungry-keller-3o9a,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc42193d910} {node.kubernetes.io/unreachable Exists  NoExecute 0xc42193dad0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-03 20:43:16 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-03 20:43:16 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-03 20:43:16 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-03 20:43:15 +0000 UTC  }],Message:,Reason:,HostIP:10.136.91.235,PodIP:,StartTime:2018-12-03 20:43:16 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec  3 20:43:20.511: INFO: Pod "nginx-deployment-7dc8f79789-gwj74" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-gwj74,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-wxrn4,SelfLink:/api/v1/namespaces/e2e-tests-deployment-wxrn4/pods/nginx-deployment-7dc8f79789-gwj74,UID:105b3733-f73c-11e8-8af3-a28d93e01224,ResourceVersion:15497,Generation:0,CreationTimestamp:2018-12-03 20:43:17 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 0eeb9add-f73c-11e8-8af3-a28d93e01224 0xc42193dba0 0xc42193dba1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-gbfqg {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-gbfqg,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-gbfqg true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:hungry-keller-3o9e,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc42193dcb0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc42193dd00}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-03 20:43:18 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-03 20:43:18 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-03 20:43:18 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-03 20:43:18 +0000 UTC  }],Message:,Reason:,HostIP:10.136.45.151,PodIP:,StartTime:2018-12-03 20:43:18 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec  3 20:43:20.511: INFO: Pod "nginx-deployment-7dc8f79789-hbrsw" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-hbrsw,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-wxrn4,SelfLink:/api/v1/namespaces/e2e-tests-deployment-wxrn4/pods/nginx-deployment-7dc8f79789-hbrsw,UID:104c14a2-f73c-11e8-8af3-a28d93e01224,ResourceVersion:15528,Generation:0,CreationTimestamp:2018-12-03 20:43:17 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 0eeb9add-f73c-11e8-8af3-a28d93e01224 0xc42193dec0 0xc42193dec1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-gbfqg {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-gbfqg,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-gbfqg true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:hungry-keller-3o96,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc420d68030} {node.kubernetes.io/unreachable Exists  NoExecute 0xc420d68050}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-03 20:43:17 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-03 20:43:17 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-03 20:43:17 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-03 20:43:17 +0000 UTC  }],Message:,Reason:,HostIP:10.136.127.223,PodIP:10.244.1.8,StartTime:2018-12-03 20:43:17 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = Error response from daemon: manifest for nginx:404 not found,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec  3 20:43:20.511: INFO: Pod "nginx-deployment-7dc8f79789-jqvrr" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-jqvrr,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-wxrn4,SelfLink:/api/v1/namespaces/e2e-tests-deployment-wxrn4/pods/nginx-deployment-7dc8f79789-jqvrr,UID:105ae3da-f73c-11e8-8af3-a28d93e01224,ResourceVersion:15460,Generation:0,CreationTimestamp:2018-12-03 20:43:17 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 0eeb9add-f73c-11e8-8af3-a28d93e01224 0xc420d681b0 0xc420d681b1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-gbfqg {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-gbfqg,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-gbfqg true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:hungry-keller-3o9a,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc420d68220} {node.kubernetes.io/unreachable Exists  NoExecute 0xc420d68240}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-03 20:43:18 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec  3 20:43:20.511: INFO: Pod "nginx-deployment-7dc8f79789-jvvnp" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-jvvnp,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-wxrn4,SelfLink:/api/v1/namespaces/e2e-tests-deployment-wxrn4/pods/nginx-deployment-7dc8f79789-jvvnp,UID:1057b51b-f73c-11e8-8af3-a28d93e01224,ResourceVersion:15470,Generation:0,CreationTimestamp:2018-12-03 20:43:17 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 0eeb9add-f73c-11e8-8af3-a28d93e01224 0xc420d682b0 0xc420d682b1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-gbfqg {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-gbfqg,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-gbfqg true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:hungry-keller-3o96,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc420d68390} {node.kubernetes.io/unreachable Exists  NoExecute 0xc420d683b0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-03 20:43:18 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-03 20:43:18 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-03 20:43:18 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-03 20:43:18 +0000 UTC  }],Message:,Reason:,HostIP:10.136.127.223,PodIP:,StartTime:2018-12-03 20:43:18 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec  3 20:43:20.512: INFO: Pod "nginx-deployment-7dc8f79789-jx8xl" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-jx8xl,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-wxrn4,SelfLink:/api/v1/namespaces/e2e-tests-deployment-wxrn4/pods/nginx-deployment-7dc8f79789-jx8xl,UID:0f0a5eef-f73c-11e8-8af3-a28d93e01224,ResourceVersion:15384,Generation:0,CreationTimestamp:2018-12-03 20:43:15 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 0eeb9add-f73c-11e8-8af3-a28d93e01224 0xc420d68530 0xc420d68531}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-gbfqg {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-gbfqg,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-gbfqg true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:hungry-keller-3o9a,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc420d68630} {node.kubernetes.io/unreachable Exists  NoExecute 0xc420d686d0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-03 20:43:16 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-03 20:43:16 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-03 20:43:16 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-03 20:43:15 +0000 UTC  }],Message:,Reason:,HostIP:10.136.91.235,PodIP:,StartTime:2018-12-03 20:43:16 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec  3 20:43:20.512: INFO: Pod "nginx-deployment-7dc8f79789-m8zh5" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-m8zh5,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-wxrn4,SelfLink:/api/v1/namespaces/e2e-tests-deployment-wxrn4/pods/nginx-deployment-7dc8f79789-m8zh5,UID:1052ec15-f73c-11e8-8af3-a28d93e01224,ResourceVersion:15552,Generation:0,CreationTimestamp:2018-12-03 20:43:17 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 0eeb9add-f73c-11e8-8af3-a28d93e01224 0xc420d68790 0xc420d68791}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-gbfqg {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-gbfqg,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-gbfqg true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:hungry-keller-3o9a,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc420d68900} {node.kubernetes.io/unreachable Exists  NoExecute 0xc420d68920}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-03 20:43:20 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-03 20:43:20 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-03 20:43:20 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-03 20:43:17 +0000 UTC  }],Message:,Reason:,HostIP:10.136.91.235,PodIP:,StartTime:2018-12-03 20:43:20 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec  3 20:43:20.512: INFO: Pod "nginx-deployment-7dc8f79789-tfmpx" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-tfmpx,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-wxrn4,SelfLink:/api/v1/namespaces/e2e-tests-deployment-wxrn4/pods/nginx-deployment-7dc8f79789-tfmpx,UID:106d35f7-f73c-11e8-8af3-a28d93e01224,ResourceVersion:15523,Generation:0,CreationTimestamp:2018-12-03 20:43:18 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 0eeb9add-f73c-11e8-8af3-a28d93e01224 0xc420d68a50 0xc420d68a51}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-gbfqg {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-gbfqg,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-gbfqg true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:hungry-keller-3o96,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc420d68bb0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc420d68be0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-03 20:43:18 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-03 20:43:18 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-03 20:43:18 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-03 20:43:18 +0000 UTC  }],Message:,Reason:,HostIP:10.136.127.223,PodIP:10.244.1.10,StartTime:2018-12-03 20:43:18 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = Error response from daemon: manifest for nginx:404 not found,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec  3 20:43:20.512: INFO: Pod "nginx-deployment-7dc8f79789-wldvj" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-wldvj,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-wxrn4,SelfLink:/api/v1/namespaces/e2e-tests-deployment-wxrn4/pods/nginx-deployment-7dc8f79789-wldvj,UID:0eecf318-f73c-11e8-8af3-a28d93e01224,ResourceVersion:15468,Generation:0,CreationTimestamp:2018-12-03 20:43:15 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 0eeb9add-f73c-11e8-8af3-a28d93e01224 0xc420d68ea0 0xc420d68ea1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-gbfqg {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-gbfqg,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-gbfqg true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:hungry-keller-3o9e,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc420d68f10} {node.kubernetes.io/unreachable Exists  NoExecute 0xc420d68f30}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-03 20:43:15 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-03 20:43:15 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-03 20:43:15 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-03 20:43:15 +0000 UTC  }],Message:,Reason:,HostIP:10.136.45.151,PodIP:10.244.4.6,StartTime:2018-12-03 20:43:15 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = Error response from daemon: manifest for nginx:404 not found,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec  3 20:43:20.512: INFO: Pod "nginx-deployment-7f9675fb8b-55pfk" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-55pfk,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-wxrn4,SelfLink:/api/v1/namespaces/e2e-tests-deployment-wxrn4/pods/nginx-deployment-7f9675fb8b-55pfk,UID:0c9273ff-f73c-11e8-8af3-a28d93e01224,ResourceVersion:15312,Generation:0,CreationTimestamp:2018-12-03 20:43:11 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 0c7c6c97-f73c-11e8-8af3-a28d93e01224 0xc420d69130 0xc420d69131}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-gbfqg {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-gbfqg,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-gbfqg true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:hungry-keller-3o96,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc420d69350} {node.kubernetes.io/unreachable Exists  NoExecute 0xc420d69370}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-03 20:43:11 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-12-03 20:43:13 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2018-12-03 20:43:13 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-03 20:43:11 +0000 UTC  }],Message:,Reason:,HostIP:10.136.127.223,PodIP:10.244.1.6,StartTime:2018-12-03 20:43:11 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2018-12-03 20:43:12 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:3c1380fd5f6f0e4c468a922ed6331831e60cea9db317b8ac4a8ad36335e53bbd docker://bc0c4ed34a68c0be56531e9e99b1be71ff3155e90de54669b70e2aabd83771f8}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec  3 20:43:20.513: INFO: Pod "nginx-deployment-7f9675fb8b-5kxtw" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-5kxtw,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-wxrn4,SelfLink:/api/v1/namespaces/e2e-tests-deployment-wxrn4/pods/nginx-deployment-7f9675fb8b-5kxtw,UID:1043ab57-f73c-11e8-8af3-a28d93e01224,ResourceVersion:15519,Generation:0,CreationTimestamp:2018-12-03 20:43:17 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 0c7c6c97-f73c-11e8-8af3-a28d93e01224 0xc420d69520 0xc420d69521}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-gbfqg {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-gbfqg,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-gbfqg true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:hungry-keller-3o9a,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc420d696b0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc420d696d0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-03 20:43:19 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-03 20:43:19 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-03 20:43:19 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-03 20:43:17 +0000 UTC  }],Message:,Reason:,HostIP:10.136.91.235,PodIP:,StartTime:2018-12-03 20:43:19 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec  3 20:43:20.513: INFO: Pod "nginx-deployment-7f9675fb8b-6hxjp" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-6hxjp,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-wxrn4,SelfLink:/api/v1/namespaces/e2e-tests-deployment-wxrn4/pods/nginx-deployment-7f9675fb8b-6hxjp,UID:1047572d-f73c-11e8-8af3-a28d93e01224,ResourceVersion:15450,Generation:0,CreationTimestamp:2018-12-03 20:43:17 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 0c7c6c97-f73c-11e8-8af3-a28d93e01224 0xc420d69837 0xc420d69838}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-gbfqg {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-gbfqg,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-gbfqg true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:hungry-keller-3o9e,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc420d69aa0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc420d69ad0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-03 20:43:17 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-03 20:43:17 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-03 20:43:17 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-03 20:43:17 +0000 UTC  }],Message:,Reason:,HostIP:10.136.45.151,PodIP:,StartTime:2018-12-03 20:43:17 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec  3 20:43:20.513: INFO: Pod "nginx-deployment-7f9675fb8b-6lq4m" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-6lq4m,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-wxrn4,SelfLink:/api/v1/namespaces/e2e-tests-deployment-wxrn4/pods/nginx-deployment-7f9675fb8b-6lq4m,UID:0c8adf08-f73c-11e8-8af3-a28d93e01224,ResourceVersion:15307,Generation:0,CreationTimestamp:2018-12-03 20:43:11 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 0c7c6c97-f73c-11e8-8af3-a28d93e01224 0xc420d69cf7 0xc420d69cf8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-gbfqg {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-gbfqg,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-gbfqg true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:hungry-keller-3o9e,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc420d69fb0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc420d69fe0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-03 20:43:11 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-12-03 20:43:13 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2018-12-03 20:43:13 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-03 20:43:11 +0000 UTC  }],Message:,Reason:,HostIP:10.136.45.151,PodIP:10.244.4.4,StartTime:2018-12-03 20:43:11 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2018-12-03 20:43:12 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:3c1380fd5f6f0e4c468a922ed6331831e60cea9db317b8ac4a8ad36335e53bbd docker://9975b8c8cb96ad28eb33ce3574a220c0a2bd2b14202aadb69434956d556c66a8}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec  3 20:43:20.513: INFO: Pod "nginx-deployment-7f9675fb8b-dgbgr" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-dgbgr,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-wxrn4,SelfLink:/api/v1/namespaces/e2e-tests-deployment-wxrn4/pods/nginx-deployment-7f9675fb8b-dgbgr,UID:0c922e0c-f73c-11e8-8af3-a28d93e01224,ResourceVersion:15321,Generation:0,CreationTimestamp:2018-12-03 20:43:11 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 0c7c6c97-f73c-11e8-8af3-a28d93e01224 0xc420d82480 0xc420d82481}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-gbfqg {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-gbfqg,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-gbfqg true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:hungry-keller-3o9a,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc420d82590} {node.kubernetes.io/unreachable Exists  NoExecute 0xc420d825b0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-03 20:43:11 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-12-03 20:43:14 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2018-12-03 20:43:14 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-03 20:43:11 +0000 UTC  }],Message:,Reason:,HostIP:10.136.91.235,PodIP:10.244.72.6,StartTime:2018-12-03 20:43:11 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2018-12-03 20:43:13 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:3c1380fd5f6f0e4c468a922ed6331831e60cea9db317b8ac4a8ad36335e53bbd docker://feedce8cc82819af17b7f8d4f1dc1f11e5fbd488f24d1ce320fca5eb7629b127}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec  3 20:43:20.513: INFO: Pod "nginx-deployment-7f9675fb8b-f7679" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-f7679,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-wxrn4,SelfLink:/api/v1/namespaces/e2e-tests-deployment-wxrn4/pods/nginx-deployment-7f9675fb8b-f7679,UID:0c846c0b-f73c-11e8-8af3-a28d93e01224,ResourceVersion:15279,Generation:0,CreationTimestamp:2018-12-03 20:43:11 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 0c7c6c97-f73c-11e8-8af3-a28d93e01224 0xc420d827c0 0xc420d827c1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-gbfqg {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-gbfqg,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-gbfqg true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:hungry-keller-3o96,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc420d82900} {node.kubernetes.io/unreachable Exists  NoExecute 0xc420d82920}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-03 20:43:11 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-12-03 20:43:12 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2018-12-03 20:43:12 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-03 20:43:11 +0000 UTC  }],Message:,Reason:,HostIP:10.136.127.223,PodIP:10.244.1.4,StartTime:2018-12-03 20:43:11 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2018-12-03 20:43:12 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:3c1380fd5f6f0e4c468a922ed6331831e60cea9db317b8ac4a8ad36335e53bbd docker://630f0ca0d6d13ea7672feba41de999702948701c534a1cf8e9907504b2a75ead}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec  3 20:43:20.514: INFO: Pod "nginx-deployment-7f9675fb8b-gjxpz" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-gjxpz,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-wxrn4,SelfLink:/api/v1/namespaces/e2e-tests-deployment-wxrn4/pods/nginx-deployment-7f9675fb8b-gjxpz,UID:1059bf34-f73c-11e8-8af3-a28d93e01224,ResourceVersion:15457,Generation:0,CreationTimestamp:2018-12-03 20:43:17 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 0c7c6c97-f73c-11e8-8af3-a28d93e01224 0xc420d82af0 0xc420d82af1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-gbfqg {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-gbfqg,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-gbfqg true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:hungry-keller-3o9a,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc420d82b90} {node.kubernetes.io/unreachable Exists  NoExecute 0xc420d82c70}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-03 20:43:18 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec  3 20:43:20.514: INFO: Pod "nginx-deployment-7f9675fb8b-hjmgd" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-hjmgd,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-wxrn4,SelfLink:/api/v1/namespaces/e2e-tests-deployment-wxrn4/pods/nginx-deployment-7f9675fb8b-hjmgd,UID:104182ab-f73c-11e8-8af3-a28d93e01224,ResourceVersion:15503,Generation:0,CreationTimestamp:2018-12-03 20:43:17 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 0c7c6c97-f73c-11e8-8af3-a28d93e01224 0xc420d82d10 0xc420d82d11}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-gbfqg {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-gbfqg,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-gbfqg true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:hungry-keller-3o9a,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc420d82ef0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc420d82f10}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-03 20:43:18 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-03 20:43:18 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-03 20:43:18 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-03 20:43:17 +0000 UTC  }],Message:,Reason:,HostIP:10.136.91.235,PodIP:,StartTime:2018-12-03 20:43:18 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec  3 20:43:20.514: INFO: Pod "nginx-deployment-7f9675fb8b-hn4b2" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-hn4b2,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-wxrn4,SelfLink:/api/v1/namespaces/e2e-tests-deployment-wxrn4/pods/nginx-deployment-7f9675fb8b-hn4b2,UID:0c938047-f73c-11e8-8af3-a28d93e01224,ResourceVersion:15318,Generation:0,CreationTimestamp:2018-12-03 20:43:11 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 0c7c6c97-f73c-11e8-8af3-a28d93e01224 0xc420d83087 0xc420d83088}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-gbfqg {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-gbfqg,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-gbfqg true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:hungry-keller-3o9a,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc420d833c0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc420d833f0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-03 20:43:11 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-12-03 20:43:14 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2018-12-03 20:43:14 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-03 20:43:11 +0000 UTC  }],Message:,Reason:,HostIP:10.136.91.235,PodIP:10.244.72.3,StartTime:2018-12-03 20:43:11 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2018-12-03 20:43:13 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:3c1380fd5f6f0e4c468a922ed6331831e60cea9db317b8ac4a8ad36335e53bbd docker://080c3fb47e85ae763fe5bfc30b86088c3466227b79a72a31801d27961ce02e6e}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec  3 20:43:20.514: INFO: Pod "nginx-deployment-7f9675fb8b-kns4g" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-kns4g,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-wxrn4,SelfLink:/api/v1/namespaces/e2e-tests-deployment-wxrn4/pods/nginx-deployment-7f9675fb8b-kns4g,UID:1052843a-f73c-11e8-8af3-a28d93e01224,ResourceVersion:15434,Generation:0,CreationTimestamp:2018-12-03 20:43:17 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 0c7c6c97-f73c-11e8-8af3-a28d93e01224 0xc420d83850 0xc420d83851}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-gbfqg {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-gbfqg,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-gbfqg true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:hungry-keller-3o9a,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc420d83920} {node.kubernetes.io/unreachable Exists  NoExecute 0xc420d83960}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-03 20:43:17 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec  3 20:43:20.514: INFO: Pod "nginx-deployment-7f9675fb8b-mrhdc" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-mrhdc,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-wxrn4,SelfLink:/api/v1/namespaces/e2e-tests-deployment-wxrn4/pods/nginx-deployment-7f9675fb8b-mrhdc,UID:1059d33e-f73c-11e8-8af3-a28d93e01224,ResourceVersion:15458,Generation:0,CreationTimestamp:2018-12-03 20:43:17 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 0c7c6c97-f73c-11e8-8af3-a28d93e01224 0xc420d83a20 0xc420d83a21}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-gbfqg {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-gbfqg,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-gbfqg true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:hungry-keller-3o9a,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc420d83ab0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc420d83ad0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-03 20:43:18 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec  3 20:43:20.514: INFO: Pod "nginx-deployment-7f9675fb8b-nfxk5" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-nfxk5,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-wxrn4,SelfLink:/api/v1/namespaces/e2e-tests-deployment-wxrn4/pods/nginx-deployment-7f9675fb8b-nfxk5,UID:0c8b8b20-f73c-11e8-8af3-a28d93e01224,ResourceVersion:15315,Generation:0,CreationTimestamp:2018-12-03 20:43:11 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 0c7c6c97-f73c-11e8-8af3-a28d93e01224 0xc4217fe080 0xc4217fe081}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-gbfqg {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-gbfqg,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-gbfqg true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:hungry-keller-3o96,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc4217fe0f0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc4217fe110}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-03 20:43:11 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-12-03 20:43:13 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2018-12-03 20:43:13 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-03 20:43:11 +0000 UTC  }],Message:,Reason:,HostIP:10.136.127.223,PodIP:10.244.1.5,StartTime:2018-12-03 20:43:11 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2018-12-03 20:43:13 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:3c1380fd5f6f0e4c468a922ed6331831e60cea9db317b8ac4a8ad36335e53bbd docker://231c5dab86a1df61a5b95e99fbf0388b392f7699c75649481f0b305276760b5d}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec  3 20:43:20.515: INFO: Pod "nginx-deployment-7f9675fb8b-rsxdd" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-rsxdd,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-wxrn4,SelfLink:/api/v1/namespaces/e2e-tests-deployment-wxrn4/pods/nginx-deployment-7f9675fb8b-rsxdd,UID:1042c176-f73c-11e8-8af3-a28d93e01224,ResourceVersion:15431,Generation:0,CreationTimestamp:2018-12-03 20:43:17 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 0c7c6c97-f73c-11e8-8af3-a28d93e01224 0xc4217fe300 0xc4217fe301}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-gbfqg {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-gbfqg,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-gbfqg true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:hungry-keller-3o9e,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc4217fe360} {node.kubernetes.io/unreachable Exists  NoExecute 0xc4217fe380}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-03 20:43:17 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-03 20:43:17 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-03 20:43:17 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-03 20:43:17 +0000 UTC  }],Message:,Reason:,HostIP:10.136.45.151,PodIP:,StartTime:2018-12-03 20:43:17 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec  3 20:43:20.515: INFO: Pod "nginx-deployment-7f9675fb8b-rx88k" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-rx88k,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-wxrn4,SelfLink:/api/v1/namespaces/e2e-tests-deployment-wxrn4/pods/nginx-deployment-7f9675fb8b-rx88k,UID:1058e07b-f73c-11e8-8af3-a28d93e01224,ResourceVersion:15479,Generation:0,CreationTimestamp:2018-12-03 20:43:17 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 0c7c6c97-f73c-11e8-8af3-a28d93e01224 0xc4217fe557 0xc4217fe558}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-gbfqg {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-gbfqg,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-gbfqg true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:hungry-keller-3o96,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc4217fe610} {node.kubernetes.io/unreachable Exists  NoExecute 0xc4217fe640}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-03 20:43:18 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-03 20:43:18 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-03 20:43:18 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-03 20:43:18 +0000 UTC  }],Message:,Reason:,HostIP:10.136.127.223,PodIP:,StartTime:2018-12-03 20:43:18 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec  3 20:43:20.515: INFO: Pod "nginx-deployment-7f9675fb8b-sbtkz" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-sbtkz,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-wxrn4,SelfLink:/api/v1/namespaces/e2e-tests-deployment-wxrn4/pods/nginx-deployment-7f9675fb8b-sbtkz,UID:104c036e-f73c-11e8-8af3-a28d93e01224,ResourceVersion:15549,Generation:0,CreationTimestamp:2018-12-03 20:43:17 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 0c7c6c97-f73c-11e8-8af3-a28d93e01224 0xc4217fe977 0xc4217fe978}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-gbfqg {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-gbfqg,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-gbfqg true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:hungry-keller-3o9a,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc4217fec80} {node.kubernetes.io/unreachable Exists  NoExecute 0xc4217fecb0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-03 20:43:19 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-03 20:43:19 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-03 20:43:19 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-03 20:43:17 +0000 UTC  }],Message:,Reason:,HostIP:10.136.91.235,PodIP:,StartTime:2018-12-03 20:43:19 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec  3 20:43:20.515: INFO: Pod "nginx-deployment-7f9675fb8b-sn45c" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-sn45c,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-wxrn4,SelfLink:/api/v1/namespaces/e2e-tests-deployment-wxrn4/pods/nginx-deployment-7f9675fb8b-sn45c,UID:104a216d-f73c-11e8-8af3-a28d93e01224,ResourceVersion:15484,Generation:0,CreationTimestamp:2018-12-03 20:43:17 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 0c7c6c97-f73c-11e8-8af3-a28d93e01224 0xc4217fedb7 0xc4217fedb8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-gbfqg {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-gbfqg,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-gbfqg true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:hungry-keller-3o9e,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc4217ff120} {node.kubernetes.io/unreachable Exists  NoExecute 0xc4217ff150}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-03 20:43:17 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-03 20:43:17 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-03 20:43:17 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-03 20:43:17 +0000 UTC  }],Message:,Reason:,HostIP:10.136.45.151,PodIP:,StartTime:2018-12-03 20:43:17 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec  3 20:43:20.515: INFO: Pod "nginx-deployment-7f9675fb8b-vl82j" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-vl82j,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-wxrn4,SelfLink:/api/v1/namespaces/e2e-tests-deployment-wxrn4/pods/nginx-deployment-7f9675fb8b-vl82j,UID:104aab3d-f73c-11e8-8af3-a28d93e01224,ResourceVersion:15543,Generation:0,CreationTimestamp:2018-12-03 20:43:17 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 0c7c6c97-f73c-11e8-8af3-a28d93e01224 0xc4217ff4d7 0xc4217ff4d8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-gbfqg {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-gbfqg,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-gbfqg true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:hungry-keller-3o9a,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc4217ff6d0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc4217ff6f0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-03 20:43:19 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-03 20:43:19 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-03 20:43:19 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-03 20:43:17 +0000 UTC  }],Message:,Reason:,HostIP:10.136.91.235,PodIP:,StartTime:2018-12-03 20:43:19 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec  3 20:43:20.516: INFO: Pod "nginx-deployment-7f9675fb8b-xxr5h" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-xxr5h,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-wxrn4,SelfLink:/api/v1/namespaces/e2e-tests-deployment-wxrn4/pods/nginx-deployment-7f9675fb8b-xxr5h,UID:1059e48a-f73c-11e8-8af3-a28d93e01224,ResourceVersion:15483,Generation:0,CreationTimestamp:2018-12-03 20:43:17 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 0c7c6c97-f73c-11e8-8af3-a28d93e01224 0xc4217ff887 0xc4217ff888}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-gbfqg {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-gbfqg,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-gbfqg true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:hungry-keller-3o96,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc4217ffa70} {node.kubernetes.io/unreachable Exists  NoExecute 0xc4217ffa90}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-03 20:43:18 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-03 20:43:18 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-03 20:43:18 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-03 20:43:18 +0000 UTC  }],Message:,Reason:,HostIP:10.136.127.223,PodIP:,StartTime:2018-12-03 20:43:18 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec  3 20:43:20.516: INFO: Pod "nginx-deployment-7f9675fb8b-zds2v" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-zds2v,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-wxrn4,SelfLink:/api/v1/namespaces/e2e-tests-deployment-wxrn4/pods/nginx-deployment-7f9675fb8b-zds2v,UID:0c8b9dfe-f73c-11e8-8af3-a28d93e01224,ResourceVersion:15304,Generation:0,CreationTimestamp:2018-12-03 20:43:11 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 0c7c6c97-f73c-11e8-8af3-a28d93e01224 0xc4217ffbe7 0xc4217ffbe8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-gbfqg {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-gbfqg,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-gbfqg true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:hungry-keller-3o9e,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc4217ffcc0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc4217ffce0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-03 20:43:11 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-12-03 20:43:13 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2018-12-03 20:43:13 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-03 20:43:11 +0000 UTC  }],Message:,Reason:,HostIP:10.136.45.151,PodIP:10.244.4.5,StartTime:2018-12-03 20:43:11 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2018-12-03 20:43:12 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:3c1380fd5f6f0e4c468a922ed6331831e60cea9db317b8ac4a8ad36335e53bbd docker://7e1dfa93aa983a20d21c5087fcea4e25a124a55b0565be769349ce52b227403c}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec  3 20:43:20.516: INFO: Pod "nginx-deployment-7f9675fb8b-zw85h" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-zw85h,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-wxrn4,SelfLink:/api/v1/namespaces/e2e-tests-deployment-wxrn4/pods/nginx-deployment-7f9675fb8b-zw85h,UID:0c836a15-f73c-11e8-8af3-a28d93e01224,ResourceVersion:15300,Generation:0,CreationTimestamp:2018-12-03 20:43:11 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 0c7c6c97-f73c-11e8-8af3-a28d93e01224 0xc4217ffef0 0xc4217ffef1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-gbfqg {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-gbfqg,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-gbfqg true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:hungry-keller-3o9e,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc4217fff60} {node.kubernetes.io/unreachable Exists  NoExecute 0xc4217fff80}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-03 20:43:11 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-12-03 20:43:13 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2018-12-03 20:43:13 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-03 20:43:11 +0000 UTC  }],Message:,Reason:,HostIP:10.136.45.151,PodIP:10.244.4.3,StartTime:2018-12-03 20:43:11 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2018-12-03 20:43:12 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:3c1380fd5f6f0e4c468a922ed6331831e60cea9db317b8ac4a8ad36335e53bbd docker://ee6da038d29df23ca4452e9a37bf71597b589a783cb70690b5acbcbbb8a6a310}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 20:43:20.516: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-wxrn4" for this suite.
Dec  3 20:43:28.550: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 20:43:28.595: INFO: namespace: e2e-tests-deployment-wxrn4, resource: bindings, ignored listing per whitelist
Dec  3 20:43:28.661: INFO: namespace e2e-tests-deployment-wxrn4 deletion completed in 8.132585181s

• [SLOW TEST:17.309 seconds]
[sig-apps] Deployment
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 20:43:28.662: INFO: >>> kubeConfig: /tmp/kubeconfig-166913721
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-map-16ccc858-f73c-11e8-8d0a-02420af40402
STEP: Creating a pod to test consume configMaps
Dec  3 20:43:28.756: INFO: Waiting up to 5m0s for pod "pod-configmaps-16cde82a-f73c-11e8-8d0a-02420af40402" in namespace "e2e-tests-configmap-m64zn" to be "success or failure"
Dec  3 20:43:28.763: INFO: Pod "pod-configmaps-16cde82a-f73c-11e8-8d0a-02420af40402": Phase="Pending", Reason="", readiness=false. Elapsed: 7.134023ms
Dec  3 20:43:30.767: INFO: Pod "pod-configmaps-16cde82a-f73c-11e8-8d0a-02420af40402": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010847525s
STEP: Saw pod success
Dec  3 20:43:30.767: INFO: Pod "pod-configmaps-16cde82a-f73c-11e8-8d0a-02420af40402" satisfied condition "success or failure"
Dec  3 20:43:30.769: INFO: Trying to get logs from node hungry-keller-3o9a pod pod-configmaps-16cde82a-f73c-11e8-8d0a-02420af40402 container configmap-volume-test: <nil>
STEP: delete the pod
Dec  3 20:43:30.792: INFO: Waiting for pod pod-configmaps-16cde82a-f73c-11e8-8d0a-02420af40402 to disappear
Dec  3 20:43:30.797: INFO: Pod pod-configmaps-16cde82a-f73c-11e8-8d0a-02420af40402 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 20:43:30.797: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-m64zn" for this suite.
Dec  3 20:43:36.812: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 20:43:36.914: INFO: namespace: e2e-tests-configmap-m64zn, resource: bindings, ignored listing per whitelist
Dec  3 20:43:36.974: INFO: namespace e2e-tests-configmap-m64zn deletion completed in 6.174280259s

• [SLOW TEST:8.312 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 20:43:36.974: INFO: >>> kubeConfig: /tmp/kubeconfig-166913721
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test override all
Dec  3 20:43:37.051: INFO: Waiting up to 5m0s for pod "client-containers-1bbfac8e-f73c-11e8-8d0a-02420af40402" in namespace "e2e-tests-containers-86rxr" to be "success or failure"
Dec  3 20:43:37.060: INFO: Pod "client-containers-1bbfac8e-f73c-11e8-8d0a-02420af40402": Phase="Pending", Reason="", readiness=false. Elapsed: 9.013974ms
Dec  3 20:43:39.063: INFO: Pod "client-containers-1bbfac8e-f73c-11e8-8d0a-02420af40402": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012383829s
Dec  3 20:43:41.067: INFO: Pod "client-containers-1bbfac8e-f73c-11e8-8d0a-02420af40402": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.016381117s
STEP: Saw pod success
Dec  3 20:43:41.067: INFO: Pod "client-containers-1bbfac8e-f73c-11e8-8d0a-02420af40402" satisfied condition "success or failure"
Dec  3 20:43:41.070: INFO: Trying to get logs from node hungry-keller-3o9a pod client-containers-1bbfac8e-f73c-11e8-8d0a-02420af40402 container test-container: <nil>
STEP: delete the pod
Dec  3 20:43:41.090: INFO: Waiting for pod client-containers-1bbfac8e-f73c-11e8-8d0a-02420af40402 to disappear
Dec  3 20:43:41.094: INFO: Pod client-containers-1bbfac8e-f73c-11e8-8d0a-02420af40402 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 20:43:41.094: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-86rxr" for this suite.
Dec  3 20:43:47.109: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 20:43:47.170: INFO: namespace: e2e-tests-containers-86rxr, resource: bindings, ignored listing per whitelist
Dec  3 20:43:47.196: INFO: namespace e2e-tests-containers-86rxr deletion completed in 6.098045031s

• [SLOW TEST:10.222 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 20:43:47.198: INFO: >>> kubeConfig: /tmp/kubeconfig-166913721
STEP: Building a namespace api object, basename namespaces
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a test namespace
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a pod in the namespace
STEP: Waiting for the pod to have running status
STEP: Creating an uninitialized pod in the namespace
Dec  3 20:43:49.677: INFO: error from create uninitialized namespace: <nil>
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Verifying there are no pods in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 20:44:13.727: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-namespaces-5tz72" for this suite.
Dec  3 20:44:19.739: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 20:44:19.755: INFO: namespace: e2e-tests-namespaces-5tz72, resource: bindings, ignored listing per whitelist
Dec  3 20:44:19.829: INFO: namespace e2e-tests-namespaces-5tz72 deletion completed in 6.099789854s
STEP: Destroying namespace "e2e-tests-nsdeletetest-qw8v4" for this suite.
Dec  3 20:44:19.832: INFO: Namespace e2e-tests-nsdeletetest-qw8v4 was already deleted
STEP: Destroying namespace "e2e-tests-nsdeletetest-hxqdw" for this suite.
Dec  3 20:44:25.842: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 20:44:25.912: INFO: namespace: e2e-tests-nsdeletetest-hxqdw, resource: bindings, ignored listing per whitelist
Dec  3 20:44:25.932: INFO: namespace e2e-tests-nsdeletetest-hxqdw deletion completed in 6.099229789s

• [SLOW TEST:38.734 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with secret pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 20:44:25.932: INFO: >>> kubeConfig: /tmp/kubeconfig-166913721
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with secret pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-secret-4vp5
STEP: Creating a pod to test atomic-volume-subpath
Dec  3 20:44:26.015: INFO: Waiting up to 5m0s for pod "pod-subpath-test-secret-4vp5" in namespace "e2e-tests-subpath-d8zll" to be "success or failure"
Dec  3 20:44:26.024: INFO: Pod "pod-subpath-test-secret-4vp5": Phase="Pending", Reason="", readiness=false. Elapsed: 9.187542ms
Dec  3 20:44:28.028: INFO: Pod "pod-subpath-test-secret-4vp5": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013338321s
Dec  3 20:44:30.032: INFO: Pod "pod-subpath-test-secret-4vp5": Phase="Running", Reason="", readiness=false. Elapsed: 4.017073273s
Dec  3 20:44:32.036: INFO: Pod "pod-subpath-test-secret-4vp5": Phase="Running", Reason="", readiness=false. Elapsed: 6.020921567s
Dec  3 20:44:34.039: INFO: Pod "pod-subpath-test-secret-4vp5": Phase="Running", Reason="", readiness=false. Elapsed: 8.024349293s
Dec  3 20:44:36.043: INFO: Pod "pod-subpath-test-secret-4vp5": Phase="Running", Reason="", readiness=false. Elapsed: 10.027751425s
Dec  3 20:44:38.047: INFO: Pod "pod-subpath-test-secret-4vp5": Phase="Running", Reason="", readiness=false. Elapsed: 12.031677455s
Dec  3 20:44:40.051: INFO: Pod "pod-subpath-test-secret-4vp5": Phase="Running", Reason="", readiness=false. Elapsed: 14.036075908s
Dec  3 20:44:42.055: INFO: Pod "pod-subpath-test-secret-4vp5": Phase="Running", Reason="", readiness=false. Elapsed: 16.040192937s
Dec  3 20:44:44.059: INFO: Pod "pod-subpath-test-secret-4vp5": Phase="Running", Reason="", readiness=false. Elapsed: 18.044176396s
Dec  3 20:44:46.063: INFO: Pod "pod-subpath-test-secret-4vp5": Phase="Running", Reason="", readiness=false. Elapsed: 20.048025704s
Dec  3 20:44:48.066: INFO: Pod "pod-subpath-test-secret-4vp5": Phase="Running", Reason="", readiness=false. Elapsed: 22.051526393s
Dec  3 20:44:50.070: INFO: Pod "pod-subpath-test-secret-4vp5": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.055267274s
STEP: Saw pod success
Dec  3 20:44:50.070: INFO: Pod "pod-subpath-test-secret-4vp5" satisfied condition "success or failure"
Dec  3 20:44:50.073: INFO: Trying to get logs from node hungry-keller-3o9a pod pod-subpath-test-secret-4vp5 container test-container-subpath-secret-4vp5: <nil>
STEP: delete the pod
Dec  3 20:44:50.095: INFO: Waiting for pod pod-subpath-test-secret-4vp5 to disappear
Dec  3 20:44:50.099: INFO: Pod pod-subpath-test-secret-4vp5 no longer exists
STEP: Deleting pod pod-subpath-test-secret-4vp5
Dec  3 20:44:50.099: INFO: Deleting pod "pod-subpath-test-secret-4vp5" in namespace "e2e-tests-subpath-d8zll"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 20:44:50.101: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-d8zll" for this suite.
Dec  3 20:44:56.115: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 20:44:56.150: INFO: namespace: e2e-tests-subpath-d8zll, resource: bindings, ignored listing per whitelist
Dec  3 20:44:56.200: INFO: namespace e2e-tests-subpath-d8zll deletion completed in 6.09480324s

• [SLOW TEST:30.268 seconds]
[sig-storage] Subpath
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with secret pod [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 20:44:56.200: INFO: >>> kubeConfig: /tmp/kubeconfig-166913721
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a watch on configmaps
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: closing the watch once it receives two notifications
Dec  3 20:44:56.290: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-kwljk,SelfLink:/api/v1/namespaces/e2e-tests-watch-kwljk/configmaps/e2e-watch-test-watch-closed,UID:4afb2fdf-f73c-11e8-8af3-a28d93e01224,ResourceVersion:16121,Generation:0,CreationTimestamp:2018-12-03 20:44:56 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Dec  3 20:44:56.290: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-kwljk,SelfLink:/api/v1/namespaces/e2e-tests-watch-kwljk/configmaps/e2e-watch-test-watch-closed,UID:4afb2fdf-f73c-11e8-8af3-a28d93e01224,ResourceVersion:16122,Generation:0,CreationTimestamp:2018-12-03 20:44:56 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time, while the watch is closed
STEP: creating a new watch on configmaps from the last resource version observed by the first watch
STEP: deleting the configmap
STEP: Expecting to observe notifications for all changes to the configmap since the first watch closed
Dec  3 20:44:56.302: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-kwljk,SelfLink:/api/v1/namespaces/e2e-tests-watch-kwljk/configmaps/e2e-watch-test-watch-closed,UID:4afb2fdf-f73c-11e8-8af3-a28d93e01224,ResourceVersion:16123,Generation:0,CreationTimestamp:2018-12-03 20:44:56 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Dec  3 20:44:56.302: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-kwljk,SelfLink:/api/v1/namespaces/e2e-tests-watch-kwljk/configmaps/e2e-watch-test-watch-closed,UID:4afb2fdf-f73c-11e8-8af3-a28d93e01224,ResourceVersion:16124,Generation:0,CreationTimestamp:2018-12-03 20:44:56 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 20:44:56.302: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-kwljk" for this suite.
Dec  3 20:45:02.316: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 20:45:02.403: INFO: namespace: e2e-tests-watch-kwljk, resource: bindings, ignored listing per whitelist
Dec  3 20:45:02.409: INFO: namespace e2e-tests-watch-kwljk deletion completed in 6.103733518s

• [SLOW TEST:6.210 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 20:45:02.410: INFO: >>> kubeConfig: /tmp/kubeconfig-166913721
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-map-4eab4c66-f73c-11e8-8d0a-02420af40402
STEP: Creating a pod to test consume configMaps
Dec  3 20:45:02.487: INFO: Waiting up to 5m0s for pod "pod-configmaps-4eabdda3-f73c-11e8-8d0a-02420af40402" in namespace "e2e-tests-configmap-dsdnd" to be "success or failure"
Dec  3 20:45:02.500: INFO: Pod "pod-configmaps-4eabdda3-f73c-11e8-8d0a-02420af40402": Phase="Pending", Reason="", readiness=false. Elapsed: 13.604478ms
Dec  3 20:45:04.504: INFO: Pod "pod-configmaps-4eabdda3-f73c-11e8-8d0a-02420af40402": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01739036s
Dec  3 20:45:06.510: INFO: Pod "pod-configmaps-4eabdda3-f73c-11e8-8d0a-02420af40402": Phase="Pending", Reason="", readiness=false. Elapsed: 4.022881237s
Dec  3 20:45:08.514: INFO: Pod "pod-configmaps-4eabdda3-f73c-11e8-8d0a-02420af40402": Phase="Pending", Reason="", readiness=false. Elapsed: 6.026952234s
Dec  3 20:45:10.517: INFO: Pod "pod-configmaps-4eabdda3-f73c-11e8-8d0a-02420af40402": Phase="Pending", Reason="", readiness=false. Elapsed: 8.030247184s
Dec  3 20:45:12.520: INFO: Pod "pod-configmaps-4eabdda3-f73c-11e8-8d0a-02420af40402": Phase="Pending", Reason="", readiness=false. Elapsed: 10.033655615s
Dec  3 20:45:14.524: INFO: Pod "pod-configmaps-4eabdda3-f73c-11e8-8d0a-02420af40402": Phase="Pending", Reason="", readiness=false. Elapsed: 12.036938259s
Dec  3 20:45:16.527: INFO: Pod "pod-configmaps-4eabdda3-f73c-11e8-8d0a-02420af40402": Phase="Pending", Reason="", readiness=false. Elapsed: 14.040504842s
Dec  3 20:45:18.531: INFO: Pod "pod-configmaps-4eabdda3-f73c-11e8-8d0a-02420af40402": Phase="Succeeded", Reason="", readiness=false. Elapsed: 16.044554167s
STEP: Saw pod success
Dec  3 20:45:18.531: INFO: Pod "pod-configmaps-4eabdda3-f73c-11e8-8d0a-02420af40402" satisfied condition "success or failure"
Dec  3 20:45:18.534: INFO: Trying to get logs from node hungry-keller-3o9a pod pod-configmaps-4eabdda3-f73c-11e8-8d0a-02420af40402 container configmap-volume-test: <nil>
STEP: delete the pod
Dec  3 20:45:18.561: INFO: Waiting for pod pod-configmaps-4eabdda3-f73c-11e8-8d0a-02420af40402 to disappear
Dec  3 20:45:18.566: INFO: Pod pod-configmaps-4eabdda3-f73c-11e8-8d0a-02420af40402 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 20:45:18.566: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-dsdnd" for this suite.
Dec  3 20:45:24.585: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 20:45:24.613: INFO: namespace: e2e-tests-configmap-dsdnd, resource: bindings, ignored listing per whitelist
Dec  3 20:45:24.676: INFO: namespace e2e-tests-configmap-dsdnd deletion completed in 6.102283791s

• [SLOW TEST:22.266 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should support rollover [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 20:45:24.676: INFO: >>> kubeConfig: /tmp/kubeconfig-166913721
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should support rollover [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Dec  3 20:45:24.750: INFO: Pod name rollover-pod: Found 0 pods out of 1
Dec  3 20:45:29.754: INFO: Pod name rollover-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Dec  3 20:45:29.754: INFO: Waiting for pods owned by replica set "test-rollover-controller" to become ready
Dec  3 20:45:31.757: INFO: Creating deployment "test-rollover-deployment"
Dec  3 20:45:31.774: INFO: Make sure deployment "test-rollover-deployment" performs scaling operations
Dec  3 20:45:33.796: INFO: Check revision of new replica set for deployment "test-rollover-deployment"
Dec  3 20:45:33.802: INFO: Ensure that both replica sets have 1 created replica
Dec  3 20:45:33.808: INFO: Rollover old replica sets for deployment "test-rollover-deployment" with new image update
Dec  3 20:45:33.818: INFO: Updating deployment test-rollover-deployment
Dec  3 20:45:33.818: INFO: Wait deployment "test-rollover-deployment" to be observed by the deployment controller
Dec  3 20:45:35.838: INFO: Wait for revision update of deployment "test-rollover-deployment" to 2
Dec  3 20:45:35.843: INFO: Make sure deployment "test-rollover-deployment" is complete
Dec  3 20:45:35.849: INFO: all replica sets need to contain the pod-template-hash label
Dec  3 20:45:35.849: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63679466731, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63679466731, loc:(*time.Location)(0x6c43b60)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63679466735, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63679466731, loc:(*time.Location)(0x6c43b60)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-5b76ff8c4\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec  3 20:45:37.856: INFO: all replica sets need to contain the pod-template-hash label
Dec  3 20:45:37.856: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63679466731, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63679466731, loc:(*time.Location)(0x6c43b60)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63679466735, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63679466731, loc:(*time.Location)(0x6c43b60)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-5b76ff8c4\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec  3 20:45:39.855: INFO: all replica sets need to contain the pod-template-hash label
Dec  3 20:45:39.855: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63679466731, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63679466731, loc:(*time.Location)(0x6c43b60)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63679466735, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63679466731, loc:(*time.Location)(0x6c43b60)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-5b76ff8c4\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec  3 20:45:41.863: INFO: all replica sets need to contain the pod-template-hash label
Dec  3 20:45:41.863: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63679466731, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63679466731, loc:(*time.Location)(0x6c43b60)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63679466735, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63679466731, loc:(*time.Location)(0x6c43b60)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-5b76ff8c4\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec  3 20:45:43.856: INFO: all replica sets need to contain the pod-template-hash label
Dec  3 20:45:43.856: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63679466731, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63679466731, loc:(*time.Location)(0x6c43b60)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63679466735, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63679466731, loc:(*time.Location)(0x6c43b60)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-5b76ff8c4\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec  3 20:45:45.856: INFO: 
Dec  3 20:45:45.856: INFO: Ensure that both old replica sets have no replicas
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Dec  3 20:45:45.863: INFO: Deployment "test-rollover-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment,GenerateName:,Namespace:e2e-tests-deployment-cqbw6,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-cqbw6/deployments/test-rollover-deployment,UID:602065df-f73c-11e8-8af3-a28d93e01224,ResourceVersion:16301,Generation:2,CreationTimestamp:2018-12-03 20:45:31 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:0,MaxSurge:1,},},MinReadySeconds:10,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[{Available True 2018-12-03 20:45:31 +0000 UTC 2018-12-03 20:45:31 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2018-12-03 20:45:45 +0000 UTC 2018-12-03 20:45:31 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-rollover-deployment-5b76ff8c4" has successfully progressed.}],ReadyReplicas:1,CollisionCount:nil,},}

Dec  3 20:45:45.866: INFO: New ReplicaSet "test-rollover-deployment-5b76ff8c4" of Deployment "test-rollover-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-5b76ff8c4,GenerateName:,Namespace:e2e-tests-deployment-cqbw6,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-cqbw6/replicasets/test-rollover-deployment-5b76ff8c4,UID:615abbc3-f73c-11e8-8af3-a28d93e01224,ResourceVersion:16292,Generation:2,CreationTimestamp:2018-12-03 20:45:33 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 5b76ff8c4,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment 602065df-f73c-11e8-8af3-a28d93e01224 0xc421f6c727 0xc421f6c728}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 5b76ff8c4,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 5b76ff8c4,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:2,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Dec  3 20:45:45.866: INFO: All old ReplicaSets of Deployment "test-rollover-deployment":
Dec  3 20:45:45.866: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-controller,GenerateName:,Namespace:e2e-tests-deployment-cqbw6,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-cqbw6/replicasets/test-rollover-controller,UID:5bf163e2-f73c-11e8-8af3-a28d93e01224,ResourceVersion:16300,Generation:2,CreationTimestamp:2018-12-03 20:45:24 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod: nginx,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment 602065df-f73c-11e8-8af3-a28d93e01224 0xc421f6c65e 0xc421f6c65f}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Dec  3 20:45:45.866: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-6975f4fb87,GenerateName:,Namespace:e2e-tests-deployment-cqbw6,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-cqbw6/replicasets/test-rollover-deployment-6975f4fb87,UID:60233aa1-f73c-11e8-8af3-a28d93e01224,ResourceVersion:16269,Generation:2,CreationTimestamp:2018-12-03 20:45:31 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6975f4fb87,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment 602065df-f73c-11e8-8af3-a28d93e01224 0xc421f6c7f7 0xc421f6c7f8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 6975f4fb87,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6975f4fb87,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis-slave gcr.io/google_samples/gb-redisslave:nonexistent [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Dec  3 20:45:45.869: INFO: Pod "test-rollover-deployment-5b76ff8c4-8lv5g" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-5b76ff8c4-8lv5g,GenerateName:test-rollover-deployment-5b76ff8c4-,Namespace:e2e-tests-deployment-cqbw6,SelfLink:/api/v1/namespaces/e2e-tests-deployment-cqbw6/pods/test-rollover-deployment-5b76ff8c4-8lv5g,UID:6160f19b-f73c-11e8-8af3-a28d93e01224,ResourceVersion:16275,Generation:0,CreationTimestamp:2018-12-03 20:45:33 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 5b76ff8c4,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet test-rollover-deployment-5b76ff8c4 615abbc3-f73c-11e8-8af3-a28d93e01224 0xc421f6d370 0xc421f6d371}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-pcrjq {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-pcrjq,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-pcrjq true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:hungry-keller-3o9a,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc421f6d3d0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421f6d3f0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-03 20:45:33 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-12-03 20:45:35 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2018-12-03 20:45:35 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-03 20:45:33 +0000 UTC  }],Message:,Reason:,HostIP:10.136.91.235,PodIP:10.244.72.4,StartTime:2018-12-03 20:45:33 +0000 UTC,ContainerStatuses:[{redis {nil ContainerStateRunning{StartedAt:2018-12-03 20:45:34 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/redis:1.0 docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830 docker://45ea9dbc6d99bb3c82b1c081fd6e44af3c553b94137ae98797032989b0632bd1}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 20:45:45.869: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-cqbw6" for this suite.
Dec  3 20:45:51.882: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 20:45:51.973: INFO: namespace: e2e-tests-deployment-cqbw6, resource: bindings, ignored listing per whitelist
Dec  3 20:45:51.996: INFO: namespace e2e-tests-deployment-cqbw6 deletion completed in 6.12371424s

• [SLOW TEST:27.320 seconds]
[sig-apps] Deployment
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  deployment should support rollover [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] Secrets 
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 20:45:51.996: INFO: >>> kubeConfig: /tmp/kubeconfig-166913721
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-6c39ea35-f73c-11e8-8d0a-02420af40402
STEP: Creating a pod to test consume secrets
Dec  3 20:45:52.109: INFO: Waiting up to 5m0s for pod "pod-secrets-6c3fdea1-f73c-11e8-8d0a-02420af40402" in namespace "e2e-tests-secrets-bbfp9" to be "success or failure"
Dec  3 20:45:52.123: INFO: Pod "pod-secrets-6c3fdea1-f73c-11e8-8d0a-02420af40402": Phase="Pending", Reason="", readiness=false. Elapsed: 14.018458ms
Dec  3 20:45:54.127: INFO: Pod "pod-secrets-6c3fdea1-f73c-11e8-8d0a-02420af40402": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.01790057s
STEP: Saw pod success
Dec  3 20:45:54.127: INFO: Pod "pod-secrets-6c3fdea1-f73c-11e8-8d0a-02420af40402" satisfied condition "success or failure"
Dec  3 20:45:54.131: INFO: Trying to get logs from node hungry-keller-3o9a pod pod-secrets-6c3fdea1-f73c-11e8-8d0a-02420af40402 container secret-volume-test: <nil>
STEP: delete the pod
Dec  3 20:45:54.148: INFO: Waiting for pod pod-secrets-6c3fdea1-f73c-11e8-8d0a-02420af40402 to disappear
Dec  3 20:45:54.151: INFO: Pod pod-secrets-6c3fdea1-f73c-11e8-8d0a-02420af40402 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 20:45:54.151: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-bbfp9" for this suite.
Dec  3 20:46:00.166: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 20:46:00.240: INFO: namespace: e2e-tests-secrets-bbfp9, resource: bindings, ignored listing per whitelist
Dec  3 20:46:00.252: INFO: namespace e2e-tests-secrets-bbfp9 deletion completed in 6.097781894s
STEP: Destroying namespace "e2e-tests-secret-namespace-m7vxk" for this suite.
Dec  3 20:46:06.261: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 20:46:06.325: INFO: namespace: e2e-tests-secret-namespace-m7vxk, resource: bindings, ignored listing per whitelist
Dec  3 20:46:06.349: INFO: namespace e2e-tests-secret-namespace-m7vxk deletion completed in 6.096901366s

• [SLOW TEST:14.352 seconds]
[sig-storage] Secrets
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 20:46:06.350: INFO: >>> kubeConfig: /tmp/kubeconfig-166913721
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Dec  3 20:46:06.427: INFO: Pod name cleanup-pod: Found 0 pods out of 1
Dec  3 20:46:11.432: INFO: Pod name cleanup-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Dec  3 20:46:11.432: INFO: Creating deployment test-cleanup-deployment
STEP: Waiting for deployment test-cleanup-deployment history to be cleaned up
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Dec  3 20:46:15.497: INFO: Deployment "test-cleanup-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-deployment,GenerateName:,Namespace:e2e-tests-deployment-4bknm,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-4bknm/deployments/test-cleanup-deployment,UID:77c705bc-f73c-11e8-8af3-a28d93e01224,ResourceVersion:16459,Generation:1,CreationTimestamp:2018-12-03 20:46:11 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,},Annotations:map[string]string{deployment.kubernetes.io/revision: 1,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*0,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[{Available True 2018-12-03 20:46:11 +0000 UTC 2018-12-03 20:46:11 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2018-12-03 20:46:14 +0000 UTC 2018-12-03 20:46:11 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-cleanup-deployment-755f6b95cc" has successfully progressed.}],ReadyReplicas:1,CollisionCount:nil,},}

Dec  3 20:46:15.501: INFO: New ReplicaSet "test-cleanup-deployment-755f6b95cc" of Deployment "test-cleanup-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-deployment-755f6b95cc,GenerateName:,Namespace:e2e-tests-deployment-4bknm,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-4bknm/replicasets/test-cleanup-deployment-755f6b95cc,UID:77c9b428-f73c-11e8-8af3-a28d93e01224,ResourceVersion:16450,Generation:1,CreationTimestamp:2018-12-03 20:46:11 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod-template-hash: 755f6b95cc,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-cleanup-deployment 77c705bc-f73c-11e8-8af3-a28d93e01224 0xc42295b747 0xc42295b748}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,pod-template-hash: 755f6b95cc,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod-template-hash: 755f6b95cc,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Dec  3 20:46:15.504: INFO: Pod "test-cleanup-deployment-755f6b95cc-6d2s8" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-deployment-755f6b95cc-6d2s8,GenerateName:test-cleanup-deployment-755f6b95cc-,Namespace:e2e-tests-deployment-4bknm,SelfLink:/api/v1/namespaces/e2e-tests-deployment-4bknm/pods/test-cleanup-deployment-755f6b95cc-6d2s8,UID:77cb5daa-f73c-11e8-8af3-a28d93e01224,ResourceVersion:16449,Generation:0,CreationTimestamp:2018-12-03 20:46:11 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod-template-hash: 755f6b95cc,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet test-cleanup-deployment-755f6b95cc 77c9b428-f73c-11e8-8af3-a28d93e01224 0xc422792177 0xc422792178}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-lkvv2 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-lkvv2,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-lkvv2 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:hungry-keller-3o9e,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc4227922b0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc4227922d0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-03 20:46:11 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-12-03 20:46:14 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2018-12-03 20:46:14 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-03 20:46:11 +0000 UTC  }],Message:,Reason:,HostIP:10.136.45.151,PodIP:10.244.4.3,StartTime:2018-12-03 20:46:11 +0000 UTC,ContainerStatuses:[{redis {nil ContainerStateRunning{StartedAt:2018-12-03 20:46:13 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/redis:1.0 docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830 docker://c9b83aa493a29c1c6c02289a42d1591d42446202940a5b9a68c8a4f51d039785}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 20:46:15.504: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-4bknm" for this suite.
Dec  3 20:46:21.530: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 20:46:21.600: INFO: namespace: e2e-tests-deployment-4bknm, resource: bindings, ignored listing per whitelist
Dec  3 20:46:21.623: INFO: namespace e2e-tests-deployment-4bknm deletion completed in 6.115432869s

• [SLOW TEST:15.274 seconds]
[sig-apps] Deployment
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 20:46:21.624: INFO: >>> kubeConfig: /tmp/kubeconfig-166913721
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-exec in namespace e2e-tests-container-probe-zt5cc
Dec  3 20:46:23.763: INFO: Started pod liveness-exec in namespace e2e-tests-container-probe-zt5cc
STEP: checking the pod's current state and verifying that restartCount is present
Dec  3 20:46:23.765: INFO: Initial restart count of pod liveness-exec is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 20:50:24.522: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-zt5cc" for this suite.
Dec  3 20:50:30.546: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 20:50:30.576: INFO: namespace: e2e-tests-container-probe-zt5cc, resource: bindings, ignored listing per whitelist
Dec  3 20:50:30.629: INFO: namespace e2e-tests-container-probe-zt5cc deletion completed in 6.103502249s

• [SLOW TEST:249.005 seconds]
[k8s.io] Probing container
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-network] Services 
  should provide secure master service  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 20:50:30.629: INFO: >>> kubeConfig: /tmp/kubeconfig-166913721
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:83
[It] should provide secure master service  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 20:50:30.700: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-services-stw9s" for this suite.
Dec  3 20:50:36.714: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 20:50:36.806: INFO: namespace: e2e-tests-services-stw9s, resource: bindings, ignored listing per whitelist
Dec  3 20:50:36.832: INFO: namespace e2e-tests-services-stw9s deletion completed in 6.128832085s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:88

• [SLOW TEST:6.203 seconds]
[sig-network] Services
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide secure master service  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should scale a replication controller  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 20:50:36.833: INFO: >>> kubeConfig: /tmp/kubeconfig-166913721
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:293
[It] should scale a replication controller  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a replication controller
Dec  3 20:50:36.899: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-166913721 create -f - --namespace=e2e-tests-kubectl-s8wq9'
Dec  3 20:50:37.327: INFO: stderr: ""
Dec  3 20:50:37.327: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Dec  3 20:50:37.327: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-166913721 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-s8wq9'
Dec  3 20:50:37.446: INFO: stderr: ""
Dec  3 20:50:37.446: INFO: stdout: "update-demo-nautilus-ltkvz update-demo-nautilus-nfwh8 "
Dec  3 20:50:37.446: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-166913721 get pods update-demo-nautilus-ltkvz -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-s8wq9'
Dec  3 20:50:37.545: INFO: stderr: ""
Dec  3 20:50:37.545: INFO: stdout: ""
Dec  3 20:50:37.545: INFO: update-demo-nautilus-ltkvz is created but not running
Dec  3 20:50:42.545: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-166913721 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-s8wq9'
Dec  3 20:50:42.665: INFO: stderr: ""
Dec  3 20:50:42.665: INFO: stdout: "update-demo-nautilus-ltkvz update-demo-nautilus-nfwh8 "
Dec  3 20:50:42.665: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-166913721 get pods update-demo-nautilus-ltkvz -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-s8wq9'
Dec  3 20:50:42.802: INFO: stderr: ""
Dec  3 20:50:42.802: INFO: stdout: "true"
Dec  3 20:50:42.802: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-166913721 get pods update-demo-nautilus-ltkvz -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-s8wq9'
Dec  3 20:50:42.900: INFO: stderr: ""
Dec  3 20:50:42.900: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Dec  3 20:50:42.900: INFO: validating pod update-demo-nautilus-ltkvz
Dec  3 20:50:42.909: INFO: got data: {
  "image": "nautilus.jpg"
}

Dec  3 20:50:42.909: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Dec  3 20:50:42.909: INFO: update-demo-nautilus-ltkvz is verified up and running
Dec  3 20:50:42.909: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-166913721 get pods update-demo-nautilus-nfwh8 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-s8wq9'
Dec  3 20:50:43.004: INFO: stderr: ""
Dec  3 20:50:43.004: INFO: stdout: ""
Dec  3 20:50:43.004: INFO: update-demo-nautilus-nfwh8 is created but not running
Dec  3 20:50:48.005: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-166913721 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-s8wq9'
Dec  3 20:50:48.148: INFO: stderr: ""
Dec  3 20:50:48.148: INFO: stdout: "update-demo-nautilus-ltkvz update-demo-nautilus-nfwh8 "
Dec  3 20:50:48.148: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-166913721 get pods update-demo-nautilus-ltkvz -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-s8wq9'
Dec  3 20:50:48.255: INFO: stderr: ""
Dec  3 20:50:48.255: INFO: stdout: "true"
Dec  3 20:50:48.255: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-166913721 get pods update-demo-nautilus-ltkvz -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-s8wq9'
Dec  3 20:50:48.681: INFO: stderr: ""
Dec  3 20:50:48.681: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Dec  3 20:50:48.681: INFO: validating pod update-demo-nautilus-ltkvz
Dec  3 20:50:48.693: INFO: got data: {
  "image": "nautilus.jpg"
}

Dec  3 20:50:48.693: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Dec  3 20:50:48.693: INFO: update-demo-nautilus-ltkvz is verified up and running
Dec  3 20:50:48.693: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-166913721 get pods update-demo-nautilus-nfwh8 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-s8wq9'
Dec  3 20:50:49.140: INFO: stderr: ""
Dec  3 20:50:49.140: INFO: stdout: "true"
Dec  3 20:50:49.140: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-166913721 get pods update-demo-nautilus-nfwh8 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-s8wq9'
Dec  3 20:50:49.241: INFO: stderr: ""
Dec  3 20:50:49.241: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Dec  3 20:50:49.241: INFO: validating pod update-demo-nautilus-nfwh8
Dec  3 20:50:49.250: INFO: got data: {
  "image": "nautilus.jpg"
}

Dec  3 20:50:49.250: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Dec  3 20:50:49.250: INFO: update-demo-nautilus-nfwh8 is verified up and running
STEP: scaling down the replication controller
Dec  3 20:50:49.251: INFO: scanned /root for discovery docs: <nil>
Dec  3 20:50:49.251: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-166913721 scale rc update-demo-nautilus --replicas=1 --timeout=5m --namespace=e2e-tests-kubectl-s8wq9'
Dec  3 20:50:50.401: INFO: stderr: ""
Dec  3 20:50:50.401: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Dec  3 20:50:50.401: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-166913721 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-s8wq9'
Dec  3 20:50:50.535: INFO: stderr: ""
Dec  3 20:50:50.535: INFO: stdout: "update-demo-nautilus-ltkvz update-demo-nautilus-nfwh8 "
STEP: Replicas for name=update-demo: expected=1 actual=2
Dec  3 20:50:55.535: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-166913721 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-s8wq9'
Dec  3 20:50:55.639: INFO: stderr: ""
Dec  3 20:50:55.639: INFO: stdout: "update-demo-nautilus-ltkvz "
Dec  3 20:50:55.639: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-166913721 get pods update-demo-nautilus-ltkvz -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-s8wq9'
Dec  3 20:50:55.749: INFO: stderr: ""
Dec  3 20:50:55.749: INFO: stdout: "true"
Dec  3 20:50:55.749: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-166913721 get pods update-demo-nautilus-ltkvz -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-s8wq9'
Dec  3 20:50:55.854: INFO: stderr: ""
Dec  3 20:50:55.854: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Dec  3 20:50:55.854: INFO: validating pod update-demo-nautilus-ltkvz
Dec  3 20:50:55.858: INFO: got data: {
  "image": "nautilus.jpg"
}

Dec  3 20:50:55.858: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Dec  3 20:50:55.859: INFO: update-demo-nautilus-ltkvz is verified up and running
STEP: scaling up the replication controller
Dec  3 20:50:55.860: INFO: scanned /root for discovery docs: <nil>
Dec  3 20:50:55.860: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-166913721 scale rc update-demo-nautilus --replicas=2 --timeout=5m --namespace=e2e-tests-kubectl-s8wq9'
Dec  3 20:50:56.986: INFO: stderr: ""
Dec  3 20:50:56.986: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Dec  3 20:50:56.986: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-166913721 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-s8wq9'
Dec  3 20:50:57.102: INFO: stderr: ""
Dec  3 20:50:57.102: INFO: stdout: "update-demo-nautilus-ltkvz update-demo-nautilus-r9hhh "
Dec  3 20:50:57.102: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-166913721 get pods update-demo-nautilus-ltkvz -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-s8wq9'
Dec  3 20:50:57.207: INFO: stderr: ""
Dec  3 20:50:57.207: INFO: stdout: "true"
Dec  3 20:50:57.207: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-166913721 get pods update-demo-nautilus-ltkvz -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-s8wq9'
Dec  3 20:50:57.316: INFO: stderr: ""
Dec  3 20:50:57.316: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Dec  3 20:50:57.316: INFO: validating pod update-demo-nautilus-ltkvz
Dec  3 20:50:57.320: INFO: got data: {
  "image": "nautilus.jpg"
}

Dec  3 20:50:57.320: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Dec  3 20:50:57.320: INFO: update-demo-nautilus-ltkvz is verified up and running
Dec  3 20:50:57.321: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-166913721 get pods update-demo-nautilus-r9hhh -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-s8wq9'
Dec  3 20:50:57.445: INFO: stderr: ""
Dec  3 20:50:57.445: INFO: stdout: "true"
Dec  3 20:50:57.445: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-166913721 get pods update-demo-nautilus-r9hhh -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-s8wq9'
Dec  3 20:50:57.580: INFO: stderr: ""
Dec  3 20:50:57.580: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Dec  3 20:50:57.580: INFO: validating pod update-demo-nautilus-r9hhh
Dec  3 20:50:57.585: INFO: got data: {
  "image": "nautilus.jpg"
}

Dec  3 20:50:57.585: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Dec  3 20:50:57.586: INFO: update-demo-nautilus-r9hhh is verified up and running
STEP: using delete to clean up resources
Dec  3 20:50:57.586: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-166913721 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-s8wq9'
Dec  3 20:50:57.719: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Dec  3 20:50:57.719: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Dec  3 20:50:57.719: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-166913721 get rc,svc -l name=update-demo --no-headers --namespace=e2e-tests-kubectl-s8wq9'
Dec  3 20:50:57.868: INFO: stderr: "No resources found.\n"
Dec  3 20:50:57.868: INFO: stdout: ""
Dec  3 20:50:57.868: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-166913721 get pods -l name=update-demo --namespace=e2e-tests-kubectl-s8wq9 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Dec  3 20:50:58.000: INFO: stderr: ""
Dec  3 20:50:58.000: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 20:50:58.000: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-s8wq9" for this suite.
Dec  3 20:51:04.016: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 20:51:04.058: INFO: namespace: e2e-tests-kubectl-s8wq9, resource: bindings, ignored listing per whitelist
Dec  3 20:51:04.103: INFO: namespace e2e-tests-kubectl-s8wq9 deletion completed in 6.098678181s

• [SLOW TEST:27.270 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Update Demo
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should scale a replication controller  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 20:51:04.104: INFO: >>> kubeConfig: /tmp/kubeconfig-166913721
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-map-2641d2e7-f73d-11e8-8d0a-02420af40402
STEP: Creating a pod to test consume secrets
Dec  3 20:51:04.181: INFO: Waiting up to 5m0s for pod "pod-secrets-26426355-f73d-11e8-8d0a-02420af40402" in namespace "e2e-tests-secrets-t7jf8" to be "success or failure"
Dec  3 20:51:04.194: INFO: Pod "pod-secrets-26426355-f73d-11e8-8d0a-02420af40402": Phase="Pending", Reason="", readiness=false. Elapsed: 12.355614ms
Dec  3 20:51:06.197: INFO: Pod "pod-secrets-26426355-f73d-11e8-8d0a-02420af40402": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.015846612s
STEP: Saw pod success
Dec  3 20:51:06.197: INFO: Pod "pod-secrets-26426355-f73d-11e8-8d0a-02420af40402" satisfied condition "success or failure"
Dec  3 20:51:06.200: INFO: Trying to get logs from node hungry-keller-3o9a pod pod-secrets-26426355-f73d-11e8-8d0a-02420af40402 container secret-volume-test: <nil>
STEP: delete the pod
Dec  3 20:51:06.222: INFO: Waiting for pod pod-secrets-26426355-f73d-11e8-8d0a-02420af40402 to disappear
Dec  3 20:51:06.226: INFO: Pod pod-secrets-26426355-f73d-11e8-8d0a-02420af40402 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 20:51:06.226: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-t7jf8" for this suite.
Dec  3 20:51:12.241: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 20:51:12.268: INFO: namespace: e2e-tests-secrets-t7jf8, resource: bindings, ignored listing per whitelist
Dec  3 20:51:12.324: INFO: namespace e2e-tests-secrets-t7jf8 deletion completed in 6.095163578s

• [SLOW TEST:8.221 seconds]
[sig-storage] Secrets
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-network] DNS 
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 20:51:12.325: INFO: >>> kubeConfig: /tmp/kubeconfig-166913721
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(dig +notcp +noall +answer +search kubernetes.default A)" && echo OK > /results/wheezy_udp@kubernetes.default;test -n "$$(dig +tcp +noall +answer +search kubernetes.default A)" && echo OK > /results/wheezy_tcp@kubernetes.default;test -n "$$(dig +notcp +noall +answer +search kubernetes.default.svc A)" && echo OK > /results/wheezy_udp@kubernetes.default.svc;test -n "$$(dig +tcp +noall +answer +search kubernetes.default.svc A)" && echo OK > /results/wheezy_tcp@kubernetes.default.svc;test -n "$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && echo OK > /results/wheezy_udp@kubernetes.default.svc.cluster.local;test -n "$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && echo OK > /results/wheezy_tcp@kubernetes.default.svc.cluster.local;test -n "$$(getent hosts dns-querier-1.dns-test-service.e2e-tests-dns-tvzb9.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-1.dns-test-service.e2e-tests-dns-tvzb9.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/wheezy_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-tvzb9.pod.cluster.local"}');test -n "$$(dig +notcp +noall +answer +search $${podARec} A)" && echo OK > /results/wheezy_udp@PodARecord;test -n "$$(dig +tcp +noall +answer +search $${podARec} A)" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(dig +notcp +noall +answer +search kubernetes.default A)" && echo OK > /results/jessie_udp@kubernetes.default;test -n "$$(dig +tcp +noall +answer +search kubernetes.default A)" && echo OK > /results/jessie_tcp@kubernetes.default;test -n "$$(dig +notcp +noall +answer +search kubernetes.default.svc A)" && echo OK > /results/jessie_udp@kubernetes.default.svc;test -n "$$(dig +tcp +noall +answer +search kubernetes.default.svc A)" && echo OK > /results/jessie_tcp@kubernetes.default.svc;test -n "$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && echo OK > /results/jessie_udp@kubernetes.default.svc.cluster.local;test -n "$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && echo OK > /results/jessie_tcp@kubernetes.default.svc.cluster.local;test -n "$$(getent hosts dns-querier-1.dns-test-service.e2e-tests-dns-tvzb9.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-1.dns-test-service.e2e-tests-dns-tvzb9.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/jessie_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-tvzb9.pod.cluster.local"}');test -n "$$(dig +notcp +noall +answer +search $${podARec} A)" && echo OK > /results/jessie_udp@PodARecord;test -n "$$(dig +tcp +noall +answer +search $${podARec} A)" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Dec  3 20:51:32.491: INFO: DNS probes using e2e-tests-dns-tvzb9/dns-test-2b28e5da-f73d-11e8-8d0a-02420af40402 succeeded

STEP: deleting the pod
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 20:51:32.510: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-dns-tvzb9" for this suite.
Dec  3 20:51:38.526: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 20:51:38.576: INFO: namespace: e2e-tests-dns-tvzb9, resource: bindings, ignored listing per whitelist
Dec  3 20:51:38.612: INFO: namespace e2e-tests-dns-tvzb9 deletion completed in 6.096452226s

• [SLOW TEST:26.287 seconds]
[sig-network] DNS
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-api-machinery] Downward API 
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 20:51:38.614: INFO: >>> kubeConfig: /tmp/kubeconfig-166913721
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Dec  3 20:51:38.688: INFO: Waiting up to 5m0s for pod "downward-api-3ad39972-f73d-11e8-8d0a-02420af40402" in namespace "e2e-tests-downward-api-mzs9t" to be "success or failure"
Dec  3 20:51:38.696: INFO: Pod "downward-api-3ad39972-f73d-11e8-8d0a-02420af40402": Phase="Pending", Reason="", readiness=false. Elapsed: 8.823784ms
Dec  3 20:51:40.700: INFO: Pod "downward-api-3ad39972-f73d-11e8-8d0a-02420af40402": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012695011s
Dec  3 20:51:42.704: INFO: Pod "downward-api-3ad39972-f73d-11e8-8d0a-02420af40402": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.016411208s
STEP: Saw pod success
Dec  3 20:51:42.704: INFO: Pod "downward-api-3ad39972-f73d-11e8-8d0a-02420af40402" satisfied condition "success or failure"
Dec  3 20:51:42.706: INFO: Trying to get logs from node hungry-keller-3o9a pod downward-api-3ad39972-f73d-11e8-8d0a-02420af40402 container dapi-container: <nil>
STEP: delete the pod
Dec  3 20:51:42.743: INFO: Waiting for pod downward-api-3ad39972-f73d-11e8-8d0a-02420af40402 to disappear
Dec  3 20:51:42.747: INFO: Pod downward-api-3ad39972-f73d-11e8-8d0a-02420af40402 no longer exists
[AfterEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 20:51:42.747: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-mzs9t" for this suite.
Dec  3 20:51:48.759: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 20:51:48.824: INFO: namespace: e2e-tests-downward-api-mzs9t, resource: bindings, ignored listing per whitelist
Dec  3 20:51:48.847: INFO: namespace e2e-tests-downward-api-mzs9t deletion completed in 6.096505561s

• [SLOW TEST:10.233 seconds]
[sig-api-machinery] Downward API
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 20:51:48.848: INFO: >>> kubeConfig: /tmp/kubeconfig-166913721
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating the pod
Dec  3 20:51:51.513: INFO: Successfully updated pod "labelsupdate40f56e35-f73d-11e8-8d0a-02420af40402"
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 20:51:55.545: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-sjl89" for this suite.
Dec  3 20:52:17.559: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 20:52:17.597: INFO: namespace: e2e-tests-projected-sjl89, resource: bindings, ignored listing per whitelist
Dec  3 20:52:17.656: INFO: namespace e2e-tests-projected-sjl89 deletion completed in 22.107393912s

• [SLOW TEST:28.808 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 20:52:17.656: INFO: >>> kubeConfig: /tmp/kubeconfig-166913721
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Dec  3 20:52:17.736: INFO: Waiting up to 5m0s for pod "downwardapi-volume-5219cdff-f73d-11e8-8d0a-02420af40402" in namespace "e2e-tests-downward-api-l2blz" to be "success or failure"
Dec  3 20:52:17.745: INFO: Pod "downwardapi-volume-5219cdff-f73d-11e8-8d0a-02420af40402": Phase="Pending", Reason="", readiness=false. Elapsed: 9.115772ms
Dec  3 20:52:19.760: INFO: Pod "downwardapi-volume-5219cdff-f73d-11e8-8d0a-02420af40402": Phase="Pending", Reason="", readiness=false. Elapsed: 2.023772217s
Dec  3 20:52:21.764: INFO: Pod "downwardapi-volume-5219cdff-f73d-11e8-8d0a-02420af40402": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.027171595s
STEP: Saw pod success
Dec  3 20:52:21.764: INFO: Pod "downwardapi-volume-5219cdff-f73d-11e8-8d0a-02420af40402" satisfied condition "success or failure"
Dec  3 20:52:21.766: INFO: Trying to get logs from node hungry-keller-3o9a pod downwardapi-volume-5219cdff-f73d-11e8-8d0a-02420af40402 container client-container: <nil>
STEP: delete the pod
Dec  3 20:52:21.788: INFO: Waiting for pod downwardapi-volume-5219cdff-f73d-11e8-8d0a-02420af40402 to disappear
Dec  3 20:52:21.793: INFO: Pod downwardapi-volume-5219cdff-f73d-11e8-8d0a-02420af40402 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 20:52:21.793: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-l2blz" for this suite.
Dec  3 20:52:27.807: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 20:52:27.898: INFO: namespace: e2e-tests-downward-api-l2blz, resource: bindings, ignored listing per whitelist
Dec  3 20:52:27.910: INFO: namespace e2e-tests-downward-api-l2blz deletion completed in 6.113863543s

• [SLOW TEST:10.254 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[k8s.io] [sig-node] Events 
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 20:52:27.911: INFO: >>> kubeConfig: /tmp/kubeconfig-166913721
STEP: Building a namespace api object, basename events
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: retrieving the pod
Dec  3 20:52:30.009: INFO: &Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:send-events-5835fba6-f73d-11e8-8d0a-02420af40402,GenerateName:,Namespace:e2e-tests-events-br2ql,SelfLink:/api/v1/namespaces/e2e-tests-events-br2ql/pods/send-events-5835fba6-f73d-11e8-8d0a-02420af40402,UID:5837d7e6-f73d-11e8-8af3-a28d93e01224,ResourceVersion:17277,Generation:0,CreationTimestamp:2018-12-03 20:52:27 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: foo,time: 979873604,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-d9r4d {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-d9r4d,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{p gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1 [] []  [{ 0 80 TCP }] [] [] {map[] map[]} [{default-token-d9r4d true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*30,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:hungry-keller-3o9a,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc421c8dfd0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421c8dff0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-03 20:52:28 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-12-03 20:52:29 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2018-12-03 20:52:29 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-03 20:52:27 +0000 UTC  }],Message:,Reason:,HostIP:10.136.91.235,PodIP:10.244.72.3,StartTime:2018-12-03 20:52:28 +0000 UTC,ContainerStatuses:[{p {nil ContainerStateRunning{StartedAt:2018-12-03 20:52:29 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1 docker-pullable://gcr.io/kubernetes-e2e-test-images/serve-hostname@sha256:bab70473a6d8ef65a22625dc9a1b0f0452e811530fdbe77e4408523460177ff1 docker://ca501e422e60952212046c5b4676e4256cca131a985e49786628992efc89d107}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}

STEP: checking for scheduler event about the pod
Dec  3 20:52:32.013: INFO: Saw scheduler event for our pod.
STEP: checking for kubelet event about the pod
Dec  3 20:52:34.017: INFO: Saw kubelet event for our pod.
STEP: deleting the pod
[AfterEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 20:52:34.022: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-events-br2ql" for this suite.
Dec  3 20:53:20.042: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 20:53:20.122: INFO: namespace: e2e-tests-events-br2ql, resource: bindings, ignored listing per whitelist
Dec  3 20:53:20.129: INFO: namespace e2e-tests-events-br2ql deletion completed in 46.101207525s

• [SLOW TEST:52.218 seconds]
[k8s.io] [sig-node] Events
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 20:53:20.129: INFO: >>> kubeConfig: /tmp/kubeconfig-166913721
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0644 on tmpfs
Dec  3 20:53:20.216: INFO: Waiting up to 5m0s for pod "pod-7755399f-f73d-11e8-8d0a-02420af40402" in namespace "e2e-tests-emptydir-ttjjc" to be "success or failure"
Dec  3 20:53:20.225: INFO: Pod "pod-7755399f-f73d-11e8-8d0a-02420af40402": Phase="Pending", Reason="", readiness=false. Elapsed: 8.843739ms
Dec  3 20:53:22.229: INFO: Pod "pod-7755399f-f73d-11e8-8d0a-02420af40402": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012625848s
Dec  3 20:53:24.232: INFO: Pod "pod-7755399f-f73d-11e8-8d0a-02420af40402": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.016167503s
STEP: Saw pod success
Dec  3 20:53:24.232: INFO: Pod "pod-7755399f-f73d-11e8-8d0a-02420af40402" satisfied condition "success or failure"
Dec  3 20:53:24.235: INFO: Trying to get logs from node hungry-keller-3o9a pod pod-7755399f-f73d-11e8-8d0a-02420af40402 container test-container: <nil>
STEP: delete the pod
Dec  3 20:53:24.255: INFO: Waiting for pod pod-7755399f-f73d-11e8-8d0a-02420af40402 to disappear
Dec  3 20:53:24.258: INFO: Pod pod-7755399f-f73d-11e8-8d0a-02420af40402 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 20:53:24.259: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-ttjjc" for this suite.
Dec  3 20:53:30.272: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 20:53:30.355: INFO: namespace: e2e-tests-emptydir-ttjjc, resource: bindings, ignored listing per whitelist
Dec  3 20:53:30.363: INFO: namespace e2e-tests-emptydir-ttjjc deletion completed in 6.101155317s

• [SLOW TEST:10.234 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 20:53:30.363: INFO: >>> kubeConfig: /tmp/kubeconfig-166913721
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for all rs to be garbage collected
STEP: expected 0 rs, got 1 rs
STEP: expected 0 pods, got 2 pods
STEP: Gathering metrics
W1203 20:53:31.332174      19 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Dec  3 20:53:31.332: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 20:53:31.332: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-tq9zl" for this suite.
Dec  3 20:53:37.350: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 20:53:37.400: INFO: namespace: e2e-tests-gc-tq9zl, resource: bindings, ignored listing per whitelist
Dec  3 20:53:37.440: INFO: namespace e2e-tests-gc-tq9zl deletion completed in 6.102765975s

• [SLOW TEST:7.076 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 20:53:37.440: INFO: >>> kubeConfig: /tmp/kubeconfig-166913721
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0666 on tmpfs
Dec  3 20:53:37.645: INFO: Waiting up to 5m0s for pod "pod-81bb0eba-f73d-11e8-8d0a-02420af40402" in namespace "e2e-tests-emptydir-gkj4f" to be "success or failure"
Dec  3 20:53:37.653: INFO: Pod "pod-81bb0eba-f73d-11e8-8d0a-02420af40402": Phase="Pending", Reason="", readiness=false. Elapsed: 8.650191ms
Dec  3 20:53:39.657: INFO: Pod "pod-81bb0eba-f73d-11e8-8d0a-02420af40402": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012512773s
Dec  3 20:53:41.661: INFO: Pod "pod-81bb0eba-f73d-11e8-8d0a-02420af40402": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.016286386s
STEP: Saw pod success
Dec  3 20:53:41.661: INFO: Pod "pod-81bb0eba-f73d-11e8-8d0a-02420af40402" satisfied condition "success or failure"
Dec  3 20:53:41.664: INFO: Trying to get logs from node hungry-keller-3o9a pod pod-81bb0eba-f73d-11e8-8d0a-02420af40402 container test-container: <nil>
STEP: delete the pod
Dec  3 20:53:41.687: INFO: Waiting for pod pod-81bb0eba-f73d-11e8-8d0a-02420af40402 to disappear
Dec  3 20:53:41.691: INFO: Pod pod-81bb0eba-f73d-11e8-8d0a-02420af40402 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 20:53:41.691: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-gkj4f" for this suite.
Dec  3 20:53:47.706: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 20:53:47.788: INFO: namespace: e2e-tests-emptydir-gkj4f, resource: bindings, ignored listing per whitelist
Dec  3 20:53:47.799: INFO: namespace e2e-tests-emptydir-gkj4f deletion completed in 6.104588983s

• [SLOW TEST:10.359 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources Simple CustomResourceDefinition 
  creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 20:53:47.800: INFO: >>> kubeConfig: /tmp/kubeconfig-166913721
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Waiting for a default service account to be provisioned in namespace
[It] creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Dec  3 20:53:47.893: INFO: >>> kubeConfig: /tmp/kubeconfig-166913721
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 20:53:48.984: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-custom-resource-definition-pwqr8" for this suite.
Dec  3 20:53:54.998: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 20:53:55.045: INFO: namespace: e2e-tests-custom-resource-definition-pwqr8, resource: bindings, ignored listing per whitelist
Dec  3 20:53:55.096: INFO: namespace e2e-tests-custom-resource-definition-pwqr8 deletion completed in 6.108496499s

• [SLOW TEST:7.297 seconds]
[sig-api-machinery] CustomResourceDefinition resources
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  Simple CustomResourceDefinition
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/custom_resource_definition.go:35
    creating/deleting custom resource definition objects works  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Proxy server 
  should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 20:53:55.097: INFO: >>> kubeConfig: /tmp/kubeconfig-166913721
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: starting the proxy server
Dec  3 20:53:55.161: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-166913721 proxy -p 0 --disable-filter'
STEP: curling proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 20:53:55.249: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-js6sc" for this suite.
Dec  3 20:54:01.264: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 20:54:01.302: INFO: namespace: e2e-tests-kubectl-js6sc, resource: bindings, ignored listing per whitelist
Dec  3 20:54:01.365: INFO: namespace e2e-tests-kubectl-js6sc deletion completed in 6.112204561s

• [SLOW TEST:6.268 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Proxy server
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should support proxy with --port 0  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 20:54:01.365: INFO: >>> kubeConfig: /tmp/kubeconfig-166913721
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Dec  3 20:54:01.491: INFO: Waiting up to 5m0s for pod "downwardapi-volume-8ff19d12-f73d-11e8-8d0a-02420af40402" in namespace "e2e-tests-downward-api-bb72r" to be "success or failure"
Dec  3 20:54:01.498: INFO: Pod "downwardapi-volume-8ff19d12-f73d-11e8-8d0a-02420af40402": Phase="Pending", Reason="", readiness=false. Elapsed: 7.478213ms
Dec  3 20:54:03.502: INFO: Pod "downwardapi-volume-8ff19d12-f73d-11e8-8d0a-02420af40402": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010894543s
STEP: Saw pod success
Dec  3 20:54:03.502: INFO: Pod "downwardapi-volume-8ff19d12-f73d-11e8-8d0a-02420af40402" satisfied condition "success or failure"
Dec  3 20:54:03.504: INFO: Trying to get logs from node hungry-keller-3o9a pod downwardapi-volume-8ff19d12-f73d-11e8-8d0a-02420af40402 container client-container: <nil>
STEP: delete the pod
Dec  3 20:54:03.529: INFO: Waiting for pod downwardapi-volume-8ff19d12-f73d-11e8-8d0a-02420af40402 to disappear
Dec  3 20:54:03.533: INFO: Pod downwardapi-volume-8ff19d12-f73d-11e8-8d0a-02420af40402 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 20:54:03.533: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-bb72r" for this suite.
Dec  3 20:54:09.562: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 20:54:09.605: INFO: namespace: e2e-tests-downward-api-bb72r, resource: bindings, ignored listing per whitelist
Dec  3 20:54:09.651: INFO: namespace e2e-tests-downward-api-bb72r deletion completed in 6.112546049s

• [SLOW TEST:8.286 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 20:54:09.651: INFO: >>> kubeConfig: /tmp/kubeconfig-166913721
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-94db328e-f73d-11e8-8d0a-02420af40402
STEP: Creating a pod to test consume secrets
Dec  3 20:54:09.736: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-94dbb4e8-f73d-11e8-8d0a-02420af40402" in namespace "e2e-tests-projected-g98qh" to be "success or failure"
Dec  3 20:54:09.741: INFO: Pod "pod-projected-secrets-94dbb4e8-f73d-11e8-8d0a-02420af40402": Phase="Pending", Reason="", readiness=false. Elapsed: 5.410678ms
Dec  3 20:54:11.745: INFO: Pod "pod-projected-secrets-94dbb4e8-f73d-11e8-8d0a-02420af40402": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009361235s
STEP: Saw pod success
Dec  3 20:54:11.745: INFO: Pod "pod-projected-secrets-94dbb4e8-f73d-11e8-8d0a-02420af40402" satisfied condition "success or failure"
Dec  3 20:54:11.748: INFO: Trying to get logs from node hungry-keller-3o9a pod pod-projected-secrets-94dbb4e8-f73d-11e8-8d0a-02420af40402 container projected-secret-volume-test: <nil>
STEP: delete the pod
Dec  3 20:54:11.768: INFO: Waiting for pod pod-projected-secrets-94dbb4e8-f73d-11e8-8d0a-02420af40402 to disappear
Dec  3 20:54:11.773: INFO: Pod pod-projected-secrets-94dbb4e8-f73d-11e8-8d0a-02420af40402 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 20:54:11.774: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-g98qh" for this suite.
Dec  3 20:54:17.789: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 20:54:17.873: INFO: namespace: e2e-tests-projected-g98qh, resource: bindings, ignored listing per whitelist
Dec  3 20:54:17.886: INFO: namespace e2e-tests-projected-g98qh deletion completed in 6.109438601s

• [SLOW TEST:8.235 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 20:54:17.887: INFO: >>> kubeConfig: /tmp/kubeconfig-166913721
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-99c3be42-f73d-11e8-8d0a-02420af40402
STEP: Creating a pod to test consume configMaps
Dec  3 20:54:17.978: INFO: Waiting up to 5m0s for pod "pod-configmaps-99c4fb14-f73d-11e8-8d0a-02420af40402" in namespace "e2e-tests-configmap-4m5wv" to be "success or failure"
Dec  3 20:54:17.985: INFO: Pod "pod-configmaps-99c4fb14-f73d-11e8-8d0a-02420af40402": Phase="Pending", Reason="", readiness=false. Elapsed: 5.93144ms
Dec  3 20:54:19.989: INFO: Pod "pod-configmaps-99c4fb14-f73d-11e8-8d0a-02420af40402": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009795176s
STEP: Saw pod success
Dec  3 20:54:19.989: INFO: Pod "pod-configmaps-99c4fb14-f73d-11e8-8d0a-02420af40402" satisfied condition "success or failure"
Dec  3 20:54:19.991: INFO: Trying to get logs from node hungry-keller-3o9a pod pod-configmaps-99c4fb14-f73d-11e8-8d0a-02420af40402 container configmap-volume-test: <nil>
STEP: delete the pod
Dec  3 20:54:20.011: INFO: Waiting for pod pod-configmaps-99c4fb14-f73d-11e8-8d0a-02420af40402 to disappear
Dec  3 20:54:20.014: INFO: Pod pod-configmaps-99c4fb14-f73d-11e8-8d0a-02420af40402 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 20:54:20.014: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-4m5wv" for this suite.
Dec  3 20:54:26.032: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 20:54:26.065: INFO: namespace: e2e-tests-configmap-4m5wv, resource: bindings, ignored listing per whitelist
Dec  3 20:54:26.121: INFO: namespace e2e-tests-configmap-4m5wv deletion completed in 6.099066877s

• [SLOW TEST:8.235 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Downward API volume 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 20:54:26.121: INFO: >>> kubeConfig: /tmp/kubeconfig-166913721
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating the pod
Dec  3 20:54:32.738: INFO: Successfully updated pod "annotationupdate9eaaabcd-f73d-11e8-8d0a-02420af40402"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 20:54:36.768: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-x6x6j" for this suite.
Dec  3 20:54:58.782: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 20:54:58.838: INFO: namespace: e2e-tests-downward-api-x6x6j, resource: bindings, ignored listing per whitelist
Dec  3 20:54:58.874: INFO: namespace e2e-tests-downward-api-x6x6j deletion completed in 22.101274152s

• [SLOW TEST:32.752 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Projected 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 20:54:58.874: INFO: >>> kubeConfig: /tmp/kubeconfig-166913721
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name cm-test-opt-del-b230b23c-f73d-11e8-8d0a-02420af40402
STEP: Creating configMap with name cm-test-opt-upd-b230b279-f73d-11e8-8d0a-02420af40402
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-b230b23c-f73d-11e8-8d0a-02420af40402
STEP: Updating configmap cm-test-opt-upd-b230b279-f73d-11e8-8d0a-02420af40402
STEP: Creating configMap with name cm-test-opt-create-b230b290-f73d-11e8-8d0a-02420af40402
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 20:55:07.075: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-k9jfp" for this suite.
Dec  3 20:55:29.092: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 20:55:29.180: INFO: namespace: e2e-tests-projected-k9jfp, resource: bindings, ignored listing per whitelist
Dec  3 20:55:29.182: INFO: namespace e2e-tests-projected-k9jfp deletion completed in 22.101792693s

• [SLOW TEST:30.307 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 20:55:29.187: INFO: >>> kubeConfig: /tmp/kubeconfig-166913721
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0777 on tmpfs
Dec  3 20:55:29.263: INFO: Waiting up to 5m0s for pod "pod-c442ad2a-f73d-11e8-8d0a-02420af40402" in namespace "e2e-tests-emptydir-z9j6h" to be "success or failure"
Dec  3 20:55:29.275: INFO: Pod "pod-c442ad2a-f73d-11e8-8d0a-02420af40402": Phase="Pending", Reason="", readiness=false. Elapsed: 11.778409ms
Dec  3 20:55:31.279: INFO: Pod "pod-c442ad2a-f73d-11e8-8d0a-02420af40402": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.015656397s
STEP: Saw pod success
Dec  3 20:55:31.279: INFO: Pod "pod-c442ad2a-f73d-11e8-8d0a-02420af40402" satisfied condition "success or failure"
Dec  3 20:55:31.281: INFO: Trying to get logs from node hungry-keller-3o9a pod pod-c442ad2a-f73d-11e8-8d0a-02420af40402 container test-container: <nil>
STEP: delete the pod
Dec  3 20:55:31.520: INFO: Waiting for pod pod-c442ad2a-f73d-11e8-8d0a-02420af40402 to disappear
Dec  3 20:55:31.524: INFO: Pod pod-c442ad2a-f73d-11e8-8d0a-02420af40402 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 20:55:31.524: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-z9j6h" for this suite.
Dec  3 20:55:37.535: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 20:55:37.574: INFO: namespace: e2e-tests-emptydir-z9j6h, resource: bindings, ignored listing per whitelist
Dec  3 20:55:37.636: INFO: namespace e2e-tests-emptydir-z9j6h deletion completed in 6.109132571s

• [SLOW TEST:8.450 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 20:55:37.636: INFO: >>> kubeConfig: /tmp/kubeconfig-166913721
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating replication controller my-hostname-basic-c94e1e37-f73d-11e8-8d0a-02420af40402
Dec  3 20:55:37.729: INFO: Pod name my-hostname-basic-c94e1e37-f73d-11e8-8d0a-02420af40402: Found 0 pods out of 1
Dec  3 20:55:42.733: INFO: Pod name my-hostname-basic-c94e1e37-f73d-11e8-8d0a-02420af40402: Found 1 pods out of 1
Dec  3 20:55:42.733: INFO: Ensuring all pods for ReplicationController "my-hostname-basic-c94e1e37-f73d-11e8-8d0a-02420af40402" are running
Dec  3 20:55:42.736: INFO: Pod "my-hostname-basic-c94e1e37-f73d-11e8-8d0a-02420af40402-ndsc7" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2018-12-03 20:55:37 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2018-12-03 20:55:39 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2018-12-03 20:55:39 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2018-12-03 20:55:37 +0000 UTC Reason: Message:}])
Dec  3 20:55:42.736: INFO: Trying to dial the pod
Dec  3 20:55:47.754: INFO: Controller my-hostname-basic-c94e1e37-f73d-11e8-8d0a-02420af40402: Got expected result from replica 1 [my-hostname-basic-c94e1e37-f73d-11e8-8d0a-02420af40402-ndsc7]: "my-hostname-basic-c94e1e37-f73d-11e8-8d0a-02420af40402-ndsc7", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 20:55:47.754: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-replication-controller-bwtb9" for this suite.
Dec  3 20:55:53.767: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 20:55:53.829: INFO: namespace: e2e-tests-replication-controller-bwtb9, resource: bindings, ignored listing per whitelist
Dec  3 20:55:53.861: INFO: namespace e2e-tests-replication-controller-bwtb9 deletion completed in 6.104022524s

• [SLOW TEST:16.225 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected 
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 20:55:53.862: INFO: >>> kubeConfig: /tmp/kubeconfig-166913721
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-projected-all-test-volume-d2f7156b-f73d-11e8-8d0a-02420af40402
STEP: Creating secret with name secret-projected-all-test-volume-d2f71555-f73d-11e8-8d0a-02420af40402
STEP: Creating a pod to test Check all projections for projected volume plugin
Dec  3 20:55:53.948: INFO: Waiting up to 5m0s for pod "projected-volume-d2f71529-f73d-11e8-8d0a-02420af40402" in namespace "e2e-tests-projected-9rd98" to be "success or failure"
Dec  3 20:55:53.962: INFO: Pod "projected-volume-d2f71529-f73d-11e8-8d0a-02420af40402": Phase="Pending", Reason="", readiness=false. Elapsed: 13.499218ms
Dec  3 20:55:55.965: INFO: Pod "projected-volume-d2f71529-f73d-11e8-8d0a-02420af40402": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.0168709s
STEP: Saw pod success
Dec  3 20:55:55.965: INFO: Pod "projected-volume-d2f71529-f73d-11e8-8d0a-02420af40402" satisfied condition "success or failure"
Dec  3 20:55:55.967: INFO: Trying to get logs from node hungry-keller-3o9a pod projected-volume-d2f71529-f73d-11e8-8d0a-02420af40402 container projected-all-volume-test: <nil>
STEP: delete the pod
Dec  3 20:55:55.991: INFO: Waiting for pod projected-volume-d2f71529-f73d-11e8-8d0a-02420af40402 to disappear
Dec  3 20:55:55.995: INFO: Pod projected-volume-d2f71529-f73d-11e8-8d0a-02420af40402 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 20:55:55.995: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-9rd98" for this suite.
Dec  3 20:56:02.016: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 20:56:02.091: INFO: namespace: e2e-tests-projected-9rd98, resource: bindings, ignored listing per whitelist
Dec  3 20:56:02.113: INFO: namespace e2e-tests-projected-9rd98 deletion completed in 6.11454121s

• [SLOW TEST:8.252 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 20:56:02.113: INFO: >>> kubeConfig: /tmp/kubeconfig-166913721
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test override arguments
Dec  3 20:56:02.188: INFO: Waiting up to 5m0s for pod "client-containers-d7e2901d-f73d-11e8-8d0a-02420af40402" in namespace "e2e-tests-containers-2tnzc" to be "success or failure"
Dec  3 20:56:02.201: INFO: Pod "client-containers-d7e2901d-f73d-11e8-8d0a-02420af40402": Phase="Pending", Reason="", readiness=false. Elapsed: 12.770634ms
Dec  3 20:56:04.205: INFO: Pod "client-containers-d7e2901d-f73d-11e8-8d0a-02420af40402": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.016697281s
STEP: Saw pod success
Dec  3 20:56:04.205: INFO: Pod "client-containers-d7e2901d-f73d-11e8-8d0a-02420af40402" satisfied condition "success or failure"
Dec  3 20:56:04.207: INFO: Trying to get logs from node hungry-keller-3o9a pod client-containers-d7e2901d-f73d-11e8-8d0a-02420af40402 container test-container: <nil>
STEP: delete the pod
Dec  3 20:56:04.228: INFO: Waiting for pod client-containers-d7e2901d-f73d-11e8-8d0a-02420af40402 to disappear
Dec  3 20:56:04.230: INFO: Pod client-containers-d7e2901d-f73d-11e8-8d0a-02420af40402 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 20:56:04.230: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-2tnzc" for this suite.
Dec  3 20:56:10.245: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 20:56:10.279: INFO: namespace: e2e-tests-containers-2tnzc, resource: bindings, ignored listing per whitelist
Dec  3 20:56:10.341: INFO: namespace e2e-tests-containers-2tnzc deletion completed in 6.106308273s

• [SLOW TEST:8.228 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 20:56:10.341: INFO: >>> kubeConfig: /tmp/kubeconfig-166913721
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a watch on configmaps with a certain label
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: changing the label value of the configmap
STEP: Expecting to observe a delete notification for the watched object
Dec  3 20:56:10.500: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-5blzr,SelfLink:/api/v1/namespaces/e2e-tests-watch-5blzr/configmaps/e2e-watch-test-label-changed,UID:dcd52d48-f73d-11e8-8af3-a28d93e01224,ResourceVersion:17984,Generation:0,CreationTimestamp:2018-12-03 20:56:10 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Dec  3 20:56:10.500: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-5blzr,SelfLink:/api/v1/namespaces/e2e-tests-watch-5blzr/configmaps/e2e-watch-test-label-changed,UID:dcd52d48-f73d-11e8-8af3-a28d93e01224,ResourceVersion:17985,Generation:0,CreationTimestamp:2018-12-03 20:56:10 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Dec  3 20:56:10.501: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-5blzr,SelfLink:/api/v1/namespaces/e2e-tests-watch-5blzr/configmaps/e2e-watch-test-label-changed,UID:dcd52d48-f73d-11e8-8af3-a28d93e01224,ResourceVersion:17986,Generation:0,CreationTimestamp:2018-12-03 20:56:10 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time
STEP: Expecting not to observe a notification because the object no longer meets the selector's requirements
STEP: changing the label value of the configmap back
STEP: modifying the configmap a third time
STEP: deleting the configmap
STEP: Expecting to observe an add notification for the watched object when the label value was restored
Dec  3 20:56:20.529: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-5blzr,SelfLink:/api/v1/namespaces/e2e-tests-watch-5blzr/configmaps/e2e-watch-test-label-changed,UID:dcd52d48-f73d-11e8-8af3-a28d93e01224,ResourceVersion:18002,Generation:0,CreationTimestamp:2018-12-03 20:56:10 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Dec  3 20:56:20.529: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-5blzr,SelfLink:/api/v1/namespaces/e2e-tests-watch-5blzr/configmaps/e2e-watch-test-label-changed,UID:dcd52d48-f73d-11e8-8af3-a28d93e01224,ResourceVersion:18003,Generation:0,CreationTimestamp:2018-12-03 20:56:10 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
Dec  3 20:56:20.529: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-5blzr,SelfLink:/api/v1/namespaces/e2e-tests-watch-5blzr/configmaps/e2e-watch-test-label-changed,UID:dcd52d48-f73d-11e8-8af3-a28d93e01224,ResourceVersion:18004,Generation:0,CreationTimestamp:2018-12-03 20:56:10 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 20:56:20.529: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-5blzr" for this suite.
Dec  3 20:56:26.544: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 20:56:26.628: INFO: namespace: e2e-tests-watch-5blzr, resource: bindings, ignored listing per whitelist
Dec  3 20:56:26.635: INFO: namespace e2e-tests-watch-5blzr deletion completed in 6.102186557s

• [SLOW TEST:16.294 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 20:56:26.636: INFO: >>> kubeConfig: /tmp/kubeconfig-166913721
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0777 on node default medium
Dec  3 20:56:26.713: INFO: Waiting up to 5m0s for pod "pod-e68056c4-f73d-11e8-8d0a-02420af40402" in namespace "e2e-tests-emptydir-w4ld7" to be "success or failure"
Dec  3 20:56:26.724: INFO: Pod "pod-e68056c4-f73d-11e8-8d0a-02420af40402": Phase="Pending", Reason="", readiness=false. Elapsed: 10.429053ms
Dec  3 20:56:28.727: INFO: Pod "pod-e68056c4-f73d-11e8-8d0a-02420af40402": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014343347s
Dec  3 20:56:30.731: INFO: Pod "pod-e68056c4-f73d-11e8-8d0a-02420af40402": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.018035261s
STEP: Saw pod success
Dec  3 20:56:30.731: INFO: Pod "pod-e68056c4-f73d-11e8-8d0a-02420af40402" satisfied condition "success or failure"
Dec  3 20:56:30.733: INFO: Trying to get logs from node hungry-keller-3o9a pod pod-e68056c4-f73d-11e8-8d0a-02420af40402 container test-container: <nil>
STEP: delete the pod
Dec  3 20:56:30.756: INFO: Waiting for pod pod-e68056c4-f73d-11e8-8d0a-02420af40402 to disappear
Dec  3 20:56:30.761: INFO: Pod pod-e68056c4-f73d-11e8-8d0a-02420af40402 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 20:56:30.761: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-w4ld7" for this suite.
Dec  3 20:56:36.773: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 20:56:36.831: INFO: namespace: e2e-tests-emptydir-w4ld7, resource: bindings, ignored listing per whitelist
Dec  3 20:56:36.867: INFO: namespace e2e-tests-emptydir-w4ld7 deletion completed in 6.103052709s

• [SLOW TEST:10.231 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 20:56:36.868: INFO: >>> kubeConfig: /tmp/kubeconfig-166913721
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
Dec  3 20:56:36.935: INFO: PodSpec: initContainers in spec.initContainers
Dec  3 20:57:27.067: INFO: init container has failed twice: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-init-ec99a76d-f73d-11e8-8d0a-02420af40402", GenerateName:"", Namespace:"e2e-tests-init-container-vflpv", SelfLink:"/api/v1/namespaces/e2e-tests-init-container-vflpv/pods/pod-init-ec99a76d-f73d-11e8-8d0a-02420af40402", UID:"ec9b0346-f73d-11e8-8af3-a28d93e01224", ResourceVersion:"18156", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63679467396, loc:(*time.Location)(0x6c43b60)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"time":"935877215", "name":"foo"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Initializers:(*v1.Initializers)(nil), Finalizers:[]string(nil), ClusterName:""}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"default-token-mp5h9", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(0xc42146be40), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil)}}}, InitContainers:[]v1.Container{v1.Container{Name:"init1", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/false"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-mp5h9", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}, v1.Container{Name:"init2", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/true"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-mp5h9", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, Containers:[]v1.Container{v1.Container{Name:"run1", Image:"k8s.gcr.io/pause:3.1", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}, Requests:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-mp5h9", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc4218709e8), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"hungry-keller-3o9a", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc421238180), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc421870bc0)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc421870be0)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc421870be8), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil)}, Status:v1.PodStatus{Phase:"Pending", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63679467399, loc:(*time.Location)(0x6c43b60)}}, Reason:"ContainersNotInitialized", Message:"containers with incomplete status: [init1 init2]"}, v1.PodCondition{Type:"Ready", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63679467399, loc:(*time.Location)(0x6c43b60)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"ContainersReady", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63679467399, loc:(*time.Location)(0x6c43b60)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63679467396, loc:(*time.Location)(0x6c43b60)}}, Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"10.136.91.235", PodIP:"10.244.72.3", StartTime:(*v1.Time)(0xc421993440), InitContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"init1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc4212eae00)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc4212eae70)}, Ready:false, RestartCount:3, Image:"busybox:1.29", ImageID:"docker-pullable://busybox@sha256:2a03a6059f21e150ae84b0973863609494aad70f0a80eaeb64bddd8d92465812", ContainerID:"docker://39bbf82102d5ca78d90b792faa61496123624566dc2bae6753f27f4185aebc3c"}, v1.ContainerStatus{Name:"init2", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc421993480), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"docker.io/library/busybox:1.29", ImageID:"", ContainerID:""}}, ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"run1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc421993460), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"k8s.gcr.io/pause:3.1", ImageID:"", ContainerID:""}}, QOSClass:"Guaranteed"}}
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 20:57:27.068: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-init-container-vflpv" for this suite.
Dec  3 20:57:49.091: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 20:57:49.123: INFO: namespace: e2e-tests-init-container-vflpv, resource: bindings, ignored listing per whitelist
Dec  3 20:57:49.186: INFO: namespace e2e-tests-init-container-vflpv deletion completed in 22.114994096s

• [SLOW TEST:72.319 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-api-machinery] Secrets 
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 20:57:49.187: INFO: >>> kubeConfig: /tmp/kubeconfig-166913721
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-17b46f96-f73e-11e8-8d0a-02420af40402
STEP: Creating a pod to test consume secrets
Dec  3 20:57:49.263: INFO: Waiting up to 5m0s for pod "pod-secrets-17b506c3-f73e-11e8-8d0a-02420af40402" in namespace "e2e-tests-secrets-8qcl7" to be "success or failure"
Dec  3 20:57:49.273: INFO: Pod "pod-secrets-17b506c3-f73e-11e8-8d0a-02420af40402": Phase="Pending", Reason="", readiness=false. Elapsed: 9.943381ms
Dec  3 20:57:51.277: INFO: Pod "pod-secrets-17b506c3-f73e-11e8-8d0a-02420af40402": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013429658s
Dec  3 20:57:53.281: INFO: Pod "pod-secrets-17b506c3-f73e-11e8-8d0a-02420af40402": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.017293041s
STEP: Saw pod success
Dec  3 20:57:53.281: INFO: Pod "pod-secrets-17b506c3-f73e-11e8-8d0a-02420af40402" satisfied condition "success or failure"
Dec  3 20:57:53.284: INFO: Trying to get logs from node hungry-keller-3o9a pod pod-secrets-17b506c3-f73e-11e8-8d0a-02420af40402 container secret-env-test: <nil>
STEP: delete the pod
Dec  3 20:57:53.309: INFO: Waiting for pod pod-secrets-17b506c3-f73e-11e8-8d0a-02420af40402 to disappear
Dec  3 20:57:53.313: INFO: Pod pod-secrets-17b506c3-f73e-11e8-8d0a-02420af40402 no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 20:57:53.314: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-8qcl7" for this suite.
Dec  3 20:57:59.336: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 20:57:59.424: INFO: namespace: e2e-tests-secrets-8qcl7, resource: bindings, ignored listing per whitelist
Dec  3 20:57:59.431: INFO: namespace e2e-tests-secrets-8qcl7 deletion completed in 6.11360015s

• [SLOW TEST:10.244 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:31
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 20:57:59.432: INFO: >>> kubeConfig: /tmp/kubeconfig-166913721
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0777 on tmpfs
Dec  3 20:57:59.505: INFO: Waiting up to 5m0s for pod "pod-1dcfa07d-f73e-11e8-8d0a-02420af40402" in namespace "e2e-tests-emptydir-b79qn" to be "success or failure"
Dec  3 20:57:59.517: INFO: Pod "pod-1dcfa07d-f73e-11e8-8d0a-02420af40402": Phase="Pending", Reason="", readiness=false. Elapsed: 12.533785ms
Dec  3 20:58:01.545: INFO: Pod "pod-1dcfa07d-f73e-11e8-8d0a-02420af40402": Phase="Pending", Reason="", readiness=false. Elapsed: 2.040146624s
Dec  3 20:58:03.548: INFO: Pod "pod-1dcfa07d-f73e-11e8-8d0a-02420af40402": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.043523754s
STEP: Saw pod success
Dec  3 20:58:03.548: INFO: Pod "pod-1dcfa07d-f73e-11e8-8d0a-02420af40402" satisfied condition "success or failure"
Dec  3 20:58:03.551: INFO: Trying to get logs from node hungry-keller-3o9a pod pod-1dcfa07d-f73e-11e8-8d0a-02420af40402 container test-container: <nil>
STEP: delete the pod
Dec  3 20:58:03.574: INFO: Waiting for pod pod-1dcfa07d-f73e-11e8-8d0a-02420af40402 to disappear
Dec  3 20:58:03.578: INFO: Pod pod-1dcfa07d-f73e-11e8-8d0a-02420af40402 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 20:58:03.578: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-b79qn" for this suite.
Dec  3 20:58:09.590: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 20:58:09.618: INFO: namespace: e2e-tests-emptydir-b79qn, resource: bindings, ignored listing per whitelist
Dec  3 20:58:09.679: INFO: namespace e2e-tests-emptydir-b79qn deletion completed in 6.097776998s

• [SLOW TEST:10.247 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-api-machinery] ConfigMap 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 20:58:09.679: INFO: >>> kubeConfig: /tmp/kubeconfig-166913721
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap e2e-tests-configmap-g5b9c/configmap-test-23ebc747-f73e-11e8-8d0a-02420af40402
STEP: Creating a pod to test consume configMaps
Dec  3 20:58:09.759: INFO: Waiting up to 5m0s for pod "pod-configmaps-23ec525c-f73e-11e8-8d0a-02420af40402" in namespace "e2e-tests-configmap-g5b9c" to be "success or failure"
Dec  3 20:58:09.772: INFO: Pod "pod-configmaps-23ec525c-f73e-11e8-8d0a-02420af40402": Phase="Pending", Reason="", readiness=false. Elapsed: 13.060537ms
Dec  3 20:58:11.776: INFO: Pod "pod-configmaps-23ec525c-f73e-11e8-8d0a-02420af40402": Phase="Pending", Reason="", readiness=false. Elapsed: 2.016538149s
Dec  3 20:58:13.781: INFO: Pod "pod-configmaps-23ec525c-f73e-11e8-8d0a-02420af40402": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.022009028s
STEP: Saw pod success
Dec  3 20:58:13.781: INFO: Pod "pod-configmaps-23ec525c-f73e-11e8-8d0a-02420af40402" satisfied condition "success or failure"
Dec  3 20:58:13.784: INFO: Trying to get logs from node hungry-keller-3o9a pod pod-configmaps-23ec525c-f73e-11e8-8d0a-02420af40402 container env-test: <nil>
STEP: delete the pod
Dec  3 20:58:13.805: INFO: Waiting for pod pod-configmaps-23ec525c-f73e-11e8-8d0a-02420af40402 to disappear
Dec  3 20:58:13.808: INFO: Pod pod-configmaps-23ec525c-f73e-11e8-8d0a-02420af40402 no longer exists
[AfterEach] [sig-api-machinery] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 20:58:13.808: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-g5b9c" for this suite.
Dec  3 20:58:19.823: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 20:58:19.896: INFO: namespace: e2e-tests-configmap-g5b9c, resource: bindings, ignored listing per whitelist
Dec  3 20:58:19.913: INFO: namespace e2e-tests-configmap-g5b9c deletion completed in 6.100195274s

• [SLOW TEST:10.234 seconds]
[sig-api-machinery] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:30
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] KubeletManagedEtcHosts 
  should test kubelet managed /etc/hosts file [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 20:58:19.916: INFO: >>> kubeConfig: /tmp/kubeconfig-166913721
STEP: Building a namespace api object, basename e2e-kubelet-etc-hosts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should test kubelet managed /etc/hosts file [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Setting up the test
STEP: Creating hostNetwork=false pod
STEP: Creating hostNetwork=true pod
STEP: Running the test
STEP: Verifying /etc/hosts of container is kubelet-managed for pod with hostNetwork=false
Dec  3 20:58:28.082: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-td4mq PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec  3 20:58:28.082: INFO: >>> kubeConfig: /tmp/kubeconfig-166913721
Dec  3 20:58:28.285: INFO: Exec stderr: ""
Dec  3 20:58:28.285: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-td4mq PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec  3 20:58:28.285: INFO: >>> kubeConfig: /tmp/kubeconfig-166913721
Dec  3 20:58:28.486: INFO: Exec stderr: ""
Dec  3 20:58:28.486: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-td4mq PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec  3 20:58:28.486: INFO: >>> kubeConfig: /tmp/kubeconfig-166913721
Dec  3 20:58:28.649: INFO: Exec stderr: ""
Dec  3 20:58:28.649: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-td4mq PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec  3 20:58:28.649: INFO: >>> kubeConfig: /tmp/kubeconfig-166913721
Dec  3 20:58:28.845: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts of container is not kubelet-managed since container specifies /etc/hosts mount
Dec  3 20:58:28.845: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-td4mq PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec  3 20:58:28.845: INFO: >>> kubeConfig: /tmp/kubeconfig-166913721
Dec  3 20:58:28.991: INFO: Exec stderr: ""
Dec  3 20:58:28.991: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-td4mq PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec  3 20:58:28.991: INFO: >>> kubeConfig: /tmp/kubeconfig-166913721
Dec  3 20:58:29.188: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts content of container is not kubelet-managed for pod with hostNetwork=true
Dec  3 20:58:29.188: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-td4mq PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec  3 20:58:29.188: INFO: >>> kubeConfig: /tmp/kubeconfig-166913721
Dec  3 20:58:29.390: INFO: Exec stderr: ""
Dec  3 20:58:29.390: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-td4mq PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec  3 20:58:29.390: INFO: >>> kubeConfig: /tmp/kubeconfig-166913721
Dec  3 20:58:29.637: INFO: Exec stderr: ""
Dec  3 20:58:29.637: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-td4mq PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec  3 20:58:29.637: INFO: >>> kubeConfig: /tmp/kubeconfig-166913721
Dec  3 20:58:29.851: INFO: Exec stderr: ""
Dec  3 20:58:29.851: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-td4mq PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec  3 20:58:29.851: INFO: >>> kubeConfig: /tmp/kubeconfig-166913721
Dec  3 20:58:30.073: INFO: Exec stderr: ""
[AfterEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 20:58:30.074: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-e2e-kubelet-etc-hosts-td4mq" for this suite.
Dec  3 20:59:12.089: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 20:59:12.121: INFO: namespace: e2e-tests-e2e-kubelet-etc-hosts-td4mq, resource: bindings, ignored listing per whitelist
Dec  3 20:59:12.178: INFO: namespace e2e-tests-e2e-kubelet-etc-hosts-td4mq deletion completed in 42.100025385s

• [SLOW TEST:52.262 seconds]
[k8s.io] KubeletManagedEtcHosts
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should test kubelet managed /etc/hosts file [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[k8s.io] [sig-node] PreStop 
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 20:59:12.178: INFO: >>> kubeConfig: /tmp/kubeconfig-166913721
STEP: Building a namespace api object, basename prestop
STEP: Waiting for a default service account to be provisioned in namespace
[It] should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating server pod server in namespace e2e-tests-prestop-fgx45
STEP: Waiting for pods to come up.
STEP: Creating tester pod tester in namespace e2e-tests-prestop-fgx45
STEP: Deleting pre-stop pod
Dec  3 20:59:23.310: INFO: Saw: {
	"Hostname": "server",
	"Sent": null,
	"Received": {
		"prestop": 1
	},
	"Errors": null,
	"Log": [
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up."
	],
	"StillContactingPeers": true
}
STEP: Deleting the server pod
[AfterEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 20:59:23.315: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-prestop-fgx45" for this suite.
Dec  3 21:00:01.335: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 21:00:01.408: INFO: namespace: e2e-tests-prestop-fgx45, resource: bindings, ignored listing per whitelist
Dec  3 21:00:01.438: INFO: namespace e2e-tests-prestop-fgx45 deletion completed in 38.114548327s

• [SLOW TEST:49.260 seconds]
[k8s.io] [sig-node] PreStop
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Projected 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 21:00:01.439: INFO: >>> kubeConfig: /tmp/kubeconfig-166913721
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Dec  3 21:00:01.522: INFO: Waiting up to 5m0s for pod "downwardapi-volume-6689f5f4-f73e-11e8-8d0a-02420af40402" in namespace "e2e-tests-projected-kj66m" to be "success or failure"
Dec  3 21:00:01.532: INFO: Pod "downwardapi-volume-6689f5f4-f73e-11e8-8d0a-02420af40402": Phase="Pending", Reason="", readiness=false. Elapsed: 9.86889ms
Dec  3 21:00:03.535: INFO: Pod "downwardapi-volume-6689f5f4-f73e-11e8-8d0a-02420af40402": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013392314s
Dec  3 21:00:05.540: INFO: Pod "downwardapi-volume-6689f5f4-f73e-11e8-8d0a-02420af40402": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.017587029s
STEP: Saw pod success
Dec  3 21:00:05.540: INFO: Pod "downwardapi-volume-6689f5f4-f73e-11e8-8d0a-02420af40402" satisfied condition "success or failure"
Dec  3 21:00:05.542: INFO: Trying to get logs from node hungry-keller-3o9a pod downwardapi-volume-6689f5f4-f73e-11e8-8d0a-02420af40402 container client-container: <nil>
STEP: delete the pod
Dec  3 21:00:05.565: INFO: Waiting for pod downwardapi-volume-6689f5f4-f73e-11e8-8d0a-02420af40402 to disappear
Dec  3 21:00:05.569: INFO: Pod downwardapi-volume-6689f5f4-f73e-11e8-8d0a-02420af40402 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 21:00:05.569: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-kj66m" for this suite.
Dec  3 21:00:11.583: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 21:00:11.655: INFO: namespace: e2e-tests-projected-kj66m, resource: bindings, ignored listing per whitelist
Dec  3 21:00:11.671: INFO: namespace e2e-tests-projected-kj66m deletion completed in 6.097977398s

• [SLOW TEST:10.232 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] HostPath 
  should give a volume the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 21:00:11.671: INFO: >>> kubeConfig: /tmp/kubeconfig-166913721
STEP: Building a namespace api object, basename hostpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:37
[It] should give a volume the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test hostPath mode
Dec  3 21:00:11.801: INFO: Waiting up to 5m0s for pod "pod-host-path-test" in namespace "e2e-tests-hostpath-wpgw2" to be "success or failure"
Dec  3 21:00:11.826: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 25.473682ms
Dec  3 21:00:13.830: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 2.029609174s
Dec  3 21:00:15.834: INFO: Pod "pod-host-path-test": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.033109032s
STEP: Saw pod success
Dec  3 21:00:15.834: INFO: Pod "pod-host-path-test" satisfied condition "success or failure"
Dec  3 21:00:15.837: INFO: Trying to get logs from node hungry-keller-3o9e pod pod-host-path-test container test-container-1: <nil>
STEP: delete the pod
Dec  3 21:00:15.857: INFO: Waiting for pod pod-host-path-test to disappear
Dec  3 21:00:15.860: INFO: Pod pod-host-path-test no longer exists
[AfterEach] [sig-storage] HostPath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 21:00:15.860: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-hostpath-wpgw2" for this suite.
Dec  3 21:00:21.874: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 21:00:21.903: INFO: namespace: e2e-tests-hostpath-wpgw2, resource: bindings, ignored listing per whitelist
Dec  3 21:00:21.960: INFO: namespace e2e-tests-hostpath-wpgw2 deletion completed in 6.096024359s

• [SLOW TEST:10.288 seconds]
[sig-storage] HostPath
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:34
  should give a volume the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-apps] Deployment 
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 21:00:21.961: INFO: >>> kubeConfig: /tmp/kubeconfig-166913721
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Dec  3 21:00:22.023: INFO: Creating replica set "test-rolling-update-controller" (going to be adopted)
Dec  3 21:00:22.033: INFO: Pod name sample-pod: Found 0 pods out of 1
Dec  3 21:00:27.037: INFO: Pod name sample-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Dec  3 21:00:27.037: INFO: Creating deployment "test-rolling-update-deployment"
Dec  3 21:00:27.044: INFO: Ensuring deployment "test-rolling-update-deployment" gets the next revision from the one the adopted replica set "test-rolling-update-controller" has
Dec  3 21:00:27.073: INFO: deployment "test-rolling-update-deployment" doesn't have the required revision set
Dec  3 21:00:29.079: INFO: Ensuring status for deployment "test-rolling-update-deployment" is the expected
Dec  3 21:00:29.082: INFO: Ensuring deployment "test-rolling-update-deployment" has one old replica set (the one it adopted)
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Dec  3 21:00:29.089: INFO: Deployment "test-rolling-update-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment,GenerateName:,Namespace:e2e-tests-deployment-jlmwx,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-jlmwx/deployments/test-rolling-update-deployment,UID:75c1b4fe-f73e-11e8-8af3-a28d93e01224,ResourceVersion:18719,Generation:1,CreationTimestamp:2018-12-03 21:00:27 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,},Annotations:map[string]string{deployment.kubernetes.io/revision: 3546343826724305833,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[{Available True 2018-12-03 21:00:27 +0000 UTC 2018-12-03 21:00:27 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2018-12-03 21:00:29 +0000 UTC 2018-12-03 21:00:27 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-rolling-update-deployment-65b7695dcf" has successfully progressed.}],ReadyReplicas:1,CollisionCount:nil,},}

Dec  3 21:00:29.092: INFO: New ReplicaSet "test-rolling-update-deployment-65b7695dcf" of Deployment "test-rolling-update-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment-65b7695dcf,GenerateName:,Namespace:e2e-tests-deployment-jlmwx,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-jlmwx/replicasets/test-rolling-update-deployment-65b7695dcf,UID:75c546c4-f73e-11e8-8af3-a28d93e01224,ResourceVersion:18710,Generation:1,CreationTimestamp:2018-12-03 21:00:27 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 65b7695dcf,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 3546343826724305833,},OwnerReferences:[{apps/v1 Deployment test-rolling-update-deployment 75c1b4fe-f73e-11e8-8af3-a28d93e01224 0xc421f6df67 0xc421f6df68}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod-template-hash: 65b7695dcf,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 65b7695dcf,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Dec  3 21:00:29.092: INFO: All old ReplicaSets of Deployment "test-rolling-update-deployment":
Dec  3 21:00:29.092: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-controller,GenerateName:,Namespace:e2e-tests-deployment-jlmwx,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-jlmwx/replicasets/test-rolling-update-controller,UID:72c4b598-f73e-11e8-8af3-a28d93e01224,ResourceVersion:18718,Generation:2,CreationTimestamp:2018-12-03 21:00:22 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod: nginx,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 3546343826724305832,},OwnerReferences:[{apps/v1 Deployment test-rolling-update-deployment 75c1b4fe-f73e-11e8-8af3-a28d93e01224 0xc421f6de9e 0xc421f6de9f}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Dec  3 21:00:29.095: INFO: Pod "test-rolling-update-deployment-65b7695dcf-ws4v9" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment-65b7695dcf-ws4v9,GenerateName:test-rolling-update-deployment-65b7695dcf-,Namespace:e2e-tests-deployment-jlmwx,SelfLink:/api/v1/namespaces/e2e-tests-deployment-jlmwx/pods/test-rolling-update-deployment-65b7695dcf-ws4v9,UID:75c6ab91-f73e-11e8-8af3-a28d93e01224,ResourceVersion:18709,Generation:0,CreationTimestamp:2018-12-03 21:00:27 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 65b7695dcf,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet test-rolling-update-deployment-65b7695dcf 75c546c4-f73e-11e8-8af3-a28d93e01224 0xc420d821f7 0xc420d821f8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-z7rn2 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-z7rn2,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-z7rn2 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:hungry-keller-3o9e,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc420d82390} {node.kubernetes.io/unreachable Exists  NoExecute 0xc420d825d0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-03 21:00:27 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-12-03 21:00:28 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2018-12-03 21:00:28 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-03 21:00:27 +0000 UTC  }],Message:,Reason:,HostIP:10.136.45.151,PodIP:10.244.4.3,StartTime:2018-12-03 21:00:27 +0000 UTC,ContainerStatuses:[{redis {nil ContainerStateRunning{StartedAt:2018-12-03 21:00:28 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/redis:1.0 docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830 docker://4fac095ddb79fc011cef147256755a62bd48e9780d82ab19a0d38f49ef05a950}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 21:00:29.095: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-jlmwx" for this suite.
Dec  3 21:00:35.110: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 21:00:35.198: INFO: namespace: e2e-tests-deployment-jlmwx, resource: bindings, ignored listing per whitelist
Dec  3 21:00:35.219: INFO: namespace e2e-tests-deployment-jlmwx deletion completed in 6.120957919s

• [SLOW TEST:13.259 seconds]
[sig-apps] Deployment
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 21:00:35.220: INFO: >>> kubeConfig: /tmp/kubeconfig-166913721
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-7aab6478-f73e-11e8-8d0a-02420af40402
STEP: Creating a pod to test consume secrets
Dec  3 21:00:35.298: INFO: Waiting up to 5m0s for pod "pod-secrets-7aabe4c7-f73e-11e8-8d0a-02420af40402" in namespace "e2e-tests-secrets-vjmp2" to be "success or failure"
Dec  3 21:00:35.344: INFO: Pod "pod-secrets-7aabe4c7-f73e-11e8-8d0a-02420af40402": Phase="Pending", Reason="", readiness=false. Elapsed: 45.404928ms
Dec  3 21:00:37.347: INFO: Pod "pod-secrets-7aabe4c7-f73e-11e8-8d0a-02420af40402": Phase="Pending", Reason="", readiness=false. Elapsed: 2.049055845s
Dec  3 21:00:39.351: INFO: Pod "pod-secrets-7aabe4c7-f73e-11e8-8d0a-02420af40402": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.053031199s
STEP: Saw pod success
Dec  3 21:00:39.351: INFO: Pod "pod-secrets-7aabe4c7-f73e-11e8-8d0a-02420af40402" satisfied condition "success or failure"
Dec  3 21:00:39.354: INFO: Trying to get logs from node hungry-keller-3o9a pod pod-secrets-7aabe4c7-f73e-11e8-8d0a-02420af40402 container secret-volume-test: <nil>
STEP: delete the pod
Dec  3 21:00:39.374: INFO: Waiting for pod pod-secrets-7aabe4c7-f73e-11e8-8d0a-02420af40402 to disappear
Dec  3 21:00:39.378: INFO: Pod pod-secrets-7aabe4c7-f73e-11e8-8d0a-02420af40402 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 21:00:39.378: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-vjmp2" for this suite.
Dec  3 21:00:45.393: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 21:00:45.454: INFO: namespace: e2e-tests-secrets-vjmp2, resource: bindings, ignored listing per whitelist
Dec  3 21:00:45.495: INFO: namespace e2e-tests-secrets-vjmp2 deletion completed in 6.113377997s

• [SLOW TEST:10.275 seconds]
[sig-storage] Secrets
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl replace 
  should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 21:00:45.496: INFO: >>> kubeConfig: /tmp/kubeconfig-166913721
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Kubectl replace
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1511
[It] should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Dec  3 21:00:45.569: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-166913721 run e2e-test-nginx-pod --generator=run-pod/v1 --image=docker.io/library/nginx:1.14-alpine --labels=run=e2e-test-nginx-pod --namespace=e2e-tests-kubectl-k7vjq'
Dec  3 21:00:45.869: INFO: stderr: ""
Dec  3 21:00:45.869: INFO: stdout: "pod/e2e-test-nginx-pod created\n"
STEP: verifying the pod e2e-test-nginx-pod is running
STEP: verifying the pod e2e-test-nginx-pod was created
Dec  3 21:00:50.919: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-166913721 get pod e2e-test-nginx-pod --namespace=e2e-tests-kubectl-k7vjq -o json'
Dec  3 21:00:51.019: INFO: stderr: ""
Dec  3 21:00:51.019: INFO: stdout: "{\n    \"apiVersion\": \"v1\",\n    \"kind\": \"Pod\",\n    \"metadata\": {\n        \"creationTimestamp\": \"2018-12-03T21:00:45Z\",\n        \"labels\": {\n            \"run\": \"e2e-test-nginx-pod\"\n        },\n        \"name\": \"e2e-test-nginx-pod\",\n        \"namespace\": \"e2e-tests-kubectl-k7vjq\",\n        \"resourceVersion\": \"18809\",\n        \"selfLink\": \"/api/v1/namespaces/e2e-tests-kubectl-k7vjq/pods/e2e-test-nginx-pod\",\n        \"uid\": \"80f8d2e3-f73e-11e8-8af3-a28d93e01224\"\n    },\n    \"spec\": {\n        \"containers\": [\n            {\n                \"image\": \"docker.io/library/nginx:1.14-alpine\",\n                \"imagePullPolicy\": \"IfNotPresent\",\n                \"name\": \"e2e-test-nginx-pod\",\n                \"resources\": {},\n                \"terminationMessagePath\": \"/dev/termination-log\",\n                \"terminationMessagePolicy\": \"File\",\n                \"volumeMounts\": [\n                    {\n                        \"mountPath\": \"/var/run/secrets/kubernetes.io/serviceaccount\",\n                        \"name\": \"default-token-j9qsb\",\n                        \"readOnly\": true\n                    }\n                ]\n            }\n        ],\n        \"dnsPolicy\": \"ClusterFirst\",\n        \"nodeName\": \"hungry-keller-3o9a\",\n        \"priority\": 0,\n        \"restartPolicy\": \"Always\",\n        \"schedulerName\": \"default-scheduler\",\n        \"securityContext\": {},\n        \"serviceAccount\": \"default\",\n        \"serviceAccountName\": \"default\",\n        \"terminationGracePeriodSeconds\": 30,\n        \"tolerations\": [\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/not-ready\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            },\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/unreachable\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            }\n        ],\n        \"volumes\": [\n            {\n                \"name\": \"default-token-j9qsb\",\n                \"secret\": {\n                    \"defaultMode\": 420,\n                    \"secretName\": \"default-token-j9qsb\"\n                }\n            }\n        ]\n    },\n    \"status\": {\n        \"conditions\": [\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2018-12-03T21:00:45Z\",\n                \"status\": \"True\",\n                \"type\": \"Initialized\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2018-12-03T21:00:48Z\",\n                \"status\": \"True\",\n                \"type\": \"Ready\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2018-12-03T21:00:48Z\",\n                \"status\": \"True\",\n                \"type\": \"ContainersReady\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2018-12-03T21:00:45Z\",\n                \"status\": \"True\",\n                \"type\": \"PodScheduled\"\n            }\n        ],\n        \"containerStatuses\": [\n            {\n                \"containerID\": \"docker://c4fcf50a686022796353797711240c6bb74d7fc0fea1c00c62efea15eab01168\",\n                \"image\": \"nginx:1.14-alpine\",\n                \"imageID\": \"docker-pullable://nginx@sha256:3c1380fd5f6f0e4c468a922ed6331831e60cea9db317b8ac4a8ad36335e53bbd\",\n                \"lastState\": {},\n                \"name\": \"e2e-test-nginx-pod\",\n                \"ready\": true,\n                \"restartCount\": 0,\n                \"state\": {\n                    \"running\": {\n                        \"startedAt\": \"2018-12-03T21:00:47Z\"\n                    }\n                }\n            }\n        ],\n        \"hostIP\": \"10.136.91.235\",\n        \"phase\": \"Running\",\n        \"podIP\": \"10.244.72.3\",\n        \"qosClass\": \"BestEffort\",\n        \"startTime\": \"2018-12-03T21:00:45Z\"\n    }\n}\n"
STEP: replace the image in the pod
Dec  3 21:00:51.019: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-166913721 replace -f - --namespace=e2e-tests-kubectl-k7vjq'
Dec  3 21:00:51.243: INFO: stderr: ""
Dec  3 21:00:51.243: INFO: stdout: "pod/e2e-test-nginx-pod replaced\n"
STEP: verifying the pod e2e-test-nginx-pod has the right image docker.io/library/busybox:1.29
[AfterEach] [k8s.io] Kubectl replace
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1516
Dec  3 21:00:51.258: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-166913721 delete pods e2e-test-nginx-pod --namespace=e2e-tests-kubectl-k7vjq'
Dec  3 21:01:04.715: INFO: stderr: ""
Dec  3 21:01:04.715: INFO: stdout: "pod \"e2e-test-nginx-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 21:01:04.715: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-k7vjq" for this suite.
Dec  3 21:01:10.729: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 21:01:10.760: INFO: namespace: e2e-tests-kubectl-k7vjq, resource: bindings, ignored listing per whitelist
Dec  3 21:01:10.848: INFO: namespace e2e-tests-kubectl-k7vjq deletion completed in 6.129134344s

• [SLOW TEST:25.353 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl replace
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should update a single-container pod's image  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[k8s.io] Pods 
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 21:01:10.849: INFO: >>> kubeConfig: /tmp/kubeconfig-166913721
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating pod
Dec  3 21:01:20.944: INFO: Pod pod-hostip-8fe8d11b-f73e-11e8-8d0a-02420af40402 has hostIP: 10.136.91.235
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 21:01:20.945: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-6q5br" for this suite.
Dec  3 21:01:42.959: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 21:01:43.046: INFO: namespace: e2e-tests-pods-6q5br, resource: bindings, ignored listing per whitelist
Dec  3 21:01:43.048: INFO: namespace e2e-tests-pods-6q5br deletion completed in 22.099474494s

• [SLOW TEST:32.199 seconds]
[k8s.io] Pods
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl logs 
  should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 21:01:43.048: INFO: >>> kubeConfig: /tmp/kubeconfig-166913721
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Kubectl logs
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1083
STEP: creating an rc
Dec  3 21:01:43.111: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-166913721 create -f - --namespace=e2e-tests-kubectl-7vkx6'
Dec  3 21:01:43.312: INFO: stderr: ""
Dec  3 21:01:43.312: INFO: stdout: "replicationcontroller/redis-master created\n"
[It] should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Waiting for Redis master to start.
Dec  3 21:01:44.317: INFO: Selector matched 1 pods for map[app:redis]
Dec  3 21:01:44.317: INFO: Found 0 / 1
Dec  3 21:01:45.355: INFO: Selector matched 1 pods for map[app:redis]
Dec  3 21:01:45.355: INFO: Found 1 / 1
Dec  3 21:01:45.355: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Dec  3 21:01:45.358: INFO: Selector matched 1 pods for map[app:redis]
Dec  3 21:01:45.358: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
STEP: checking for a matching strings
Dec  3 21:01:45.358: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-166913721 logs redis-master-lpgmm redis-master --namespace=e2e-tests-kubectl-7vkx6'
Dec  3 21:01:45.510: INFO: stderr: ""
Dec  3 21:01:45.510: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 03 Dec 21:01:44.506 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 03 Dec 21:01:44.506 # Server started, Redis version 3.2.12\n1:M 03 Dec 21:01:44.506 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 03 Dec 21:01:44.506 * The server is now ready to accept connections on port 6379\n"
STEP: limiting log lines
Dec  3 21:01:45.510: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-166913721 log redis-master-lpgmm redis-master --namespace=e2e-tests-kubectl-7vkx6 --tail=1'
Dec  3 21:01:45.651: INFO: stderr: ""
Dec  3 21:01:45.651: INFO: stdout: "1:M 03 Dec 21:01:44.506 * The server is now ready to accept connections on port 6379\n"
STEP: limiting log bytes
Dec  3 21:01:45.651: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-166913721 log redis-master-lpgmm redis-master --namespace=e2e-tests-kubectl-7vkx6 --limit-bytes=1'
Dec  3 21:01:45.790: INFO: stderr: ""
Dec  3 21:01:45.790: INFO: stdout: " "
STEP: exposing timestamps
Dec  3 21:01:45.790: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-166913721 log redis-master-lpgmm redis-master --namespace=e2e-tests-kubectl-7vkx6 --tail=1 --timestamps'
Dec  3 21:01:45.905: INFO: stderr: ""
Dec  3 21:01:45.905: INFO: stdout: "2018-12-03T21:01:44.507232485Z 1:M 03 Dec 21:01:44.506 * The server is now ready to accept connections on port 6379\n"
STEP: restricting to a time range
Dec  3 21:01:48.405: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-166913721 log redis-master-lpgmm redis-master --namespace=e2e-tests-kubectl-7vkx6 --since=1s'
Dec  3 21:01:48.549: INFO: stderr: ""
Dec  3 21:01:48.549: INFO: stdout: ""
Dec  3 21:01:48.549: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-166913721 log redis-master-lpgmm redis-master --namespace=e2e-tests-kubectl-7vkx6 --since=24h'
Dec  3 21:01:48.692: INFO: stderr: ""
Dec  3 21:01:48.692: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 03 Dec 21:01:44.506 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 03 Dec 21:01:44.506 # Server started, Redis version 3.2.12\n1:M 03 Dec 21:01:44.506 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 03 Dec 21:01:44.506 * The server is now ready to accept connections on port 6379\n"
[AfterEach] [k8s.io] Kubectl logs
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1088
STEP: using delete to clean up resources
Dec  3 21:01:48.692: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-166913721 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-7vkx6'
Dec  3 21:01:48.819: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Dec  3 21:01:48.819: INFO: stdout: "replicationcontroller \"redis-master\" force deleted\n"
Dec  3 21:01:48.819: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-166913721 get rc,svc -l name=nginx --no-headers --namespace=e2e-tests-kubectl-7vkx6'
Dec  3 21:01:48.948: INFO: stderr: "No resources found.\n"
Dec  3 21:01:48.948: INFO: stdout: ""
Dec  3 21:01:48.948: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-166913721 get pods -l name=nginx --namespace=e2e-tests-kubectl-7vkx6 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Dec  3 21:01:49.068: INFO: stderr: ""
Dec  3 21:01:49.068: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 21:01:49.068: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-7vkx6" for this suite.
Dec  3 21:02:11.081: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 21:02:11.162: INFO: namespace: e2e-tests-kubectl-7vkx6, resource: bindings, ignored listing per whitelist
Dec  3 21:02:11.169: INFO: namespace e2e-tests-kubectl-7vkx6 deletion completed in 22.097878379s

• [SLOW TEST:28.122 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl logs
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should be able to retrieve and filter logs  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod with mountPath of existing file [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 21:02:11.170: INFO: >>> kubeConfig: /tmp/kubeconfig-166913721
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with configmap pod with mountPath of existing file [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-configmap-w2bc
STEP: Creating a pod to test atomic-volume-subpath
Dec  3 21:02:11.542: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-w2bc" in namespace "e2e-tests-subpath-vc59x" to be "success or failure"
Dec  3 21:02:11.558: INFO: Pod "pod-subpath-test-configmap-w2bc": Phase="Pending", Reason="", readiness=false. Elapsed: 15.564148ms
Dec  3 21:02:13.561: INFO: Pod "pod-subpath-test-configmap-w2bc": Phase="Pending", Reason="", readiness=false. Elapsed: 2.019208867s
Dec  3 21:02:15.566: INFO: Pod "pod-subpath-test-configmap-w2bc": Phase="Running", Reason="", readiness=false. Elapsed: 4.024242878s
Dec  3 21:02:17.570: INFO: Pod "pod-subpath-test-configmap-w2bc": Phase="Running", Reason="", readiness=false. Elapsed: 6.027651713s
Dec  3 21:02:19.574: INFO: Pod "pod-subpath-test-configmap-w2bc": Phase="Running", Reason="", readiness=false. Elapsed: 8.031502794s
Dec  3 21:02:21.579: INFO: Pod "pod-subpath-test-configmap-w2bc": Phase="Running", Reason="", readiness=false. Elapsed: 10.036651596s
Dec  3 21:02:23.582: INFO: Pod "pod-subpath-test-configmap-w2bc": Phase="Running", Reason="", readiness=false. Elapsed: 12.039879134s
Dec  3 21:02:25.586: INFO: Pod "pod-subpath-test-configmap-w2bc": Phase="Running", Reason="", readiness=false. Elapsed: 14.043357347s
Dec  3 21:02:27.589: INFO: Pod "pod-subpath-test-configmap-w2bc": Phase="Running", Reason="", readiness=false. Elapsed: 16.047320817s
Dec  3 21:02:29.593: INFO: Pod "pod-subpath-test-configmap-w2bc": Phase="Running", Reason="", readiness=false. Elapsed: 18.051028115s
Dec  3 21:02:31.597: INFO: Pod "pod-subpath-test-configmap-w2bc": Phase="Running", Reason="", readiness=false. Elapsed: 20.054366641s
Dec  3 21:02:33.600: INFO: Pod "pod-subpath-test-configmap-w2bc": Phase="Running", Reason="", readiness=false. Elapsed: 22.058065835s
Dec  3 21:02:35.604: INFO: Pod "pod-subpath-test-configmap-w2bc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.061986581s
STEP: Saw pod success
Dec  3 21:02:35.604: INFO: Pod "pod-subpath-test-configmap-w2bc" satisfied condition "success or failure"
Dec  3 21:02:35.607: INFO: Trying to get logs from node hungry-keller-3o9a pod pod-subpath-test-configmap-w2bc container test-container-subpath-configmap-w2bc: <nil>
STEP: delete the pod
Dec  3 21:02:35.628: INFO: Waiting for pod pod-subpath-test-configmap-w2bc to disappear
Dec  3 21:02:35.631: INFO: Pod pod-subpath-test-configmap-w2bc no longer exists
STEP: Deleting pod pod-subpath-test-configmap-w2bc
Dec  3 21:02:35.631: INFO: Deleting pod "pod-subpath-test-configmap-w2bc" in namespace "e2e-tests-subpath-vc59x"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 21:02:35.633: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-vc59x" for this suite.
Dec  3 21:02:41.650: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 21:02:41.728: INFO: namespace: e2e-tests-subpath-vc59x, resource: bindings, ignored listing per whitelist
Dec  3 21:02:41.735: INFO: namespace e2e-tests-subpath-vc59x deletion completed in 6.097680449s

• [SLOW TEST:30.565 seconds]
[sig-storage] Subpath
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with configmap pod with mountPath of existing file [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 21:02:41.736: INFO: >>> kubeConfig: /tmp/kubeconfig-166913721
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-map-c622d491-f73e-11e8-8d0a-02420af40402
STEP: Creating a pod to test consume configMaps
Dec  3 21:02:41.911: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-c623604e-f73e-11e8-8d0a-02420af40402" in namespace "e2e-tests-projected-sdwgk" to be "success or failure"
Dec  3 21:02:41.923: INFO: Pod "pod-projected-configmaps-c623604e-f73e-11e8-8d0a-02420af40402": Phase="Pending", Reason="", readiness=false. Elapsed: 10.964097ms
Dec  3 21:02:43.926: INFO: Pod "pod-projected-configmaps-c623604e-f73e-11e8-8d0a-02420af40402": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.014772585s
STEP: Saw pod success
Dec  3 21:02:43.926: INFO: Pod "pod-projected-configmaps-c623604e-f73e-11e8-8d0a-02420af40402" satisfied condition "success or failure"
Dec  3 21:02:43.929: INFO: Trying to get logs from node hungry-keller-3o9a pod pod-projected-configmaps-c623604e-f73e-11e8-8d0a-02420af40402 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Dec  3 21:02:43.951: INFO: Waiting for pod pod-projected-configmaps-c623604e-f73e-11e8-8d0a-02420af40402 to disappear
Dec  3 21:02:43.955: INFO: Pod pod-projected-configmaps-c623604e-f73e-11e8-8d0a-02420af40402 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 21:02:43.955: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-sdwgk" for this suite.
Dec  3 21:02:49.968: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 21:02:49.998: INFO: namespace: e2e-tests-projected-sdwgk, resource: bindings, ignored listing per whitelist
Dec  3 21:02:50.068: INFO: namespace e2e-tests-projected-sdwgk deletion completed in 6.109417196s

• [SLOW TEST:8.333 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-network] DNS 
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 21:02:50.069: INFO: >>> kubeConfig: /tmp/kubeconfig-166913721
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for services  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(dig +notcp +noall +answer +search dns-test-service A)" && echo OK > /results/wheezy_udp@dns-test-service;test -n "$$(dig +tcp +noall +answer +search dns-test-service A)" && echo OK > /results/wheezy_tcp@dns-test-service;test -n "$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-tz22p A)" && echo OK > /results/wheezy_udp@dns-test-service.e2e-tests-dns-tz22p;test -n "$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-tz22p A)" && echo OK > /results/wheezy_tcp@dns-test-service.e2e-tests-dns-tz22p;test -n "$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-tz22p.svc A)" && echo OK > /results/wheezy_udp@dns-test-service.e2e-tests-dns-tz22p.svc;test -n "$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-tz22p.svc A)" && echo OK > /results/wheezy_tcp@dns-test-service.e2e-tests-dns-tz22p.svc;test -n "$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-tz22p.svc SRV)" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.e2e-tests-dns-tz22p.svc;test -n "$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-tz22p.svc SRV)" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.e2e-tests-dns-tz22p.svc;test -n "$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-tz22p.svc SRV)" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.e2e-tests-dns-tz22p.svc;test -n "$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-tz22p.svc SRV)" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.e2e-tests-dns-tz22p.svc;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-tz22p.pod.cluster.local"}');test -n "$$(dig +notcp +noall +answer +search $${podARec} A)" && echo OK > /results/wheezy_udp@PodARecord;test -n "$$(dig +tcp +noall +answer +search $${podARec} A)" && echo OK > /results/wheezy_tcp@PodARecord;test -n "$$(dig +notcp +noall +answer +search 171.128.245.10.in-addr.arpa. PTR)" && echo OK > /results/10.245.128.171_udp@PTR;test -n "$$(dig +tcp +noall +answer +search 171.128.245.10.in-addr.arpa. PTR)" && echo OK > /results/10.245.128.171_tcp@PTR;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(dig +notcp +noall +answer +search dns-test-service A)" && echo OK > /results/jessie_udp@dns-test-service;test -n "$$(dig +tcp +noall +answer +search dns-test-service A)" && echo OK > /results/jessie_tcp@dns-test-service;test -n "$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-tz22p A)" && echo OK > /results/jessie_udp@dns-test-service.e2e-tests-dns-tz22p;test -n "$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-tz22p A)" && echo OK > /results/jessie_tcp@dns-test-service.e2e-tests-dns-tz22p;test -n "$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-tz22p.svc A)" && echo OK > /results/jessie_udp@dns-test-service.e2e-tests-dns-tz22p.svc;test -n "$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-tz22p.svc A)" && echo OK > /results/jessie_tcp@dns-test-service.e2e-tests-dns-tz22p.svc;test -n "$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-tz22p.svc SRV)" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-tz22p.svc;test -n "$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-tz22p.svc SRV)" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-tz22p.svc;test -n "$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-tz22p.svc SRV)" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.e2e-tests-dns-tz22p.svc;test -n "$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-tz22p.svc SRV)" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.e2e-tests-dns-tz22p.svc;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-tz22p.pod.cluster.local"}');test -n "$$(dig +notcp +noall +answer +search $${podARec} A)" && echo OK > /results/jessie_udp@PodARecord;test -n "$$(dig +tcp +noall +answer +search $${podARec} A)" && echo OK > /results/jessie_tcp@PodARecord;test -n "$$(dig +notcp +noall +answer +search 171.128.245.10.in-addr.arpa. PTR)" && echo OK > /results/10.245.128.171_udp@PTR;test -n "$$(dig +tcp +noall +answer +search 171.128.245.10.in-addr.arpa. PTR)" && echo OK > /results/10.245.128.171_tcp@PTR;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Dec  3 21:03:10.313: INFO: DNS probes using e2e-tests-dns-tz22p/dns-test-cb0fb2fb-f73e-11e8-8d0a-02420af40402 succeeded

STEP: deleting the pod
STEP: deleting the test service
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 21:03:10.619: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-dns-tz22p" for this suite.
Dec  3 21:03:16.639: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 21:03:16.693: INFO: namespace: e2e-tests-dns-tz22p, resource: bindings, ignored listing per whitelist
Dec  3 21:03:16.727: INFO: namespace e2e-tests-dns-tz22p deletion completed in 6.099736723s

• [SLOW TEST:26.659 seconds]
[sig-network] DNS
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 21:03:16.730: INFO: >>> kubeConfig: /tmp/kubeconfig-166913721
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:98
[It] should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Dec  3 21:03:16.861: INFO: Number of nodes with available pods: 0
Dec  3 21:03:16.862: INFO: Node hungry-keller-3o96 is running more than one daemon pod
Dec  3 21:03:17.869: INFO: Number of nodes with available pods: 0
Dec  3 21:03:17.870: INFO: Node hungry-keller-3o96 is running more than one daemon pod
Dec  3 21:03:18.880: INFO: Number of nodes with available pods: 0
Dec  3 21:03:18.880: INFO: Node hungry-keller-3o96 is running more than one daemon pod
Dec  3 21:03:19.868: INFO: Number of nodes with available pods: 3
Dec  3 21:03:19.868: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Set a daemon pod's phase to 'Failed', check that the daemon pod is revived.
Dec  3 21:03:19.892: INFO: Number of nodes with available pods: 2
Dec  3 21:03:19.892: INFO: Node hungry-keller-3o9a is running more than one daemon pod
Dec  3 21:03:20.917: INFO: Number of nodes with available pods: 2
Dec  3 21:03:20.917: INFO: Node hungry-keller-3o9a is running more than one daemon pod
Dec  3 21:03:21.900: INFO: Number of nodes with available pods: 2
Dec  3 21:03:21.900: INFO: Node hungry-keller-3o9a is running more than one daemon pod
Dec  3 21:03:22.899: INFO: Number of nodes with available pods: 3
Dec  3 21:03:22.900: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Wait for the failed daemon pod to be completely deleted.
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:64
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting {extensions DaemonSet} daemon-set in namespace e2e-tests-daemonsets-nslxj, will wait for the garbage collector to delete the pods
Dec  3 21:03:22.967: INFO: Deleting {extensions DaemonSet} daemon-set took: 9.495557ms
Dec  3 21:03:23.168: INFO: Terminating {extensions DaemonSet} daemon-set pods took: 200.277764ms
Dec  3 21:04:04.772: INFO: Number of nodes with available pods: 0
Dec  3 21:04:04.772: INFO: Number of running nodes: 0, number of available pods: 0
Dec  3 21:04:04.774: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-nslxj/daemonsets","resourceVersion":"19361"},"items":null}

Dec  3 21:04:04.776: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-nslxj/pods","resourceVersion":"19361"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 21:04:04.786: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-nslxj" for this suite.
Dec  3 21:04:10.799: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 21:04:10.861: INFO: namespace: e2e-tests-daemonsets-nslxj, resource: bindings, ignored listing per whitelist
Dec  3 21:04:10.891: INFO: namespace e2e-tests-daemonsets-nslxj deletion completed in 6.101797914s

• [SLOW TEST:54.161 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 21:04:10.891: INFO: >>> kubeConfig: /tmp/kubeconfig-166913721
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-fb3a0f86-f73e-11e8-8d0a-02420af40402
STEP: Creating a pod to test consume configMaps
Dec  3 21:04:10.982: INFO: Waiting up to 5m0s for pod "pod-configmaps-fb3a9c68-f73e-11e8-8d0a-02420af40402" in namespace "e2e-tests-configmap-t56g9" to be "success or failure"
Dec  3 21:04:10.989: INFO: Pod "pod-configmaps-fb3a9c68-f73e-11e8-8d0a-02420af40402": Phase="Pending", Reason="", readiness=false. Elapsed: 6.882712ms
Dec  3 21:04:12.993: INFO: Pod "pod-configmaps-fb3a9c68-f73e-11e8-8d0a-02420af40402": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01037856s
Dec  3 21:04:14.996: INFO: Pod "pod-configmaps-fb3a9c68-f73e-11e8-8d0a-02420af40402": Phase="Pending", Reason="", readiness=false. Elapsed: 4.014094253s
Dec  3 21:04:17.052: INFO: Pod "pod-configmaps-fb3a9c68-f73e-11e8-8d0a-02420af40402": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.07012967s
STEP: Saw pod success
Dec  3 21:04:17.052: INFO: Pod "pod-configmaps-fb3a9c68-f73e-11e8-8d0a-02420af40402" satisfied condition "success or failure"
Dec  3 21:04:17.055: INFO: Trying to get logs from node hungry-keller-3o9a pod pod-configmaps-fb3a9c68-f73e-11e8-8d0a-02420af40402 container configmap-volume-test: <nil>
STEP: delete the pod
Dec  3 21:04:17.105: INFO: Waiting for pod pod-configmaps-fb3a9c68-f73e-11e8-8d0a-02420af40402 to disappear
Dec  3 21:04:17.155: INFO: Pod pod-configmaps-fb3a9c68-f73e-11e8-8d0a-02420af40402 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 21:04:17.155: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-t56g9" for this suite.
Dec  3 21:04:23.185: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 21:04:23.212: INFO: namespace: e2e-tests-configmap-t56g9, resource: bindings, ignored listing per whitelist
Dec  3 21:04:23.274: INFO: namespace e2e-tests-configmap-t56g9 deletion completed in 6.115592105s

• [SLOW TEST:12.383 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 21:04:23.275: INFO: >>> kubeConfig: /tmp/kubeconfig-166913721
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: modifying the configmap a second time
STEP: deleting the configmap
STEP: creating a watch on configmaps from the resource version returned by the first update
STEP: Expecting to observe notifications for all changes to the configmap after the first update
Dec  3 21:04:23.373: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-resource-version,GenerateName:,Namespace:e2e-tests-watch-v4h5l,SelfLink:/api/v1/namespaces/e2e-tests-watch-v4h5l/configmaps/e2e-watch-test-resource-version,UID:029bace7-f73f-11e8-8af3-a28d93e01224,ResourceVersion:19449,Generation:0,CreationTimestamp:2018-12-03 21:04:23 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: from-resource-version,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Dec  3 21:04:23.373: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-resource-version,GenerateName:,Namespace:e2e-tests-watch-v4h5l,SelfLink:/api/v1/namespaces/e2e-tests-watch-v4h5l/configmaps/e2e-watch-test-resource-version,UID:029bace7-f73f-11e8-8af3-a28d93e01224,ResourceVersion:19450,Generation:0,CreationTimestamp:2018-12-03 21:04:23 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: from-resource-version,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 21:04:23.373: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-v4h5l" for this suite.
Dec  3 21:04:29.387: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 21:04:29.466: INFO: namespace: e2e-tests-watch-v4h5l, resource: bindings, ignored listing per whitelist
Dec  3 21:04:29.480: INFO: namespace e2e-tests-watch-v4h5l deletion completed in 6.103237159s

• [SLOW TEST:6.205 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run pod 
  should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 21:04:29.481: INFO: >>> kubeConfig: /tmp/kubeconfig-166913721
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Kubectl run pod
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1475
[It] should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Dec  3 21:04:29.611: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-166913721 run e2e-test-nginx-pod --restart=Never --generator=run-pod/v1 --image=docker.io/library/nginx:1.14-alpine --namespace=e2e-tests-kubectl-wxq2g'
Dec  3 21:04:29.722: INFO: stderr: ""
Dec  3 21:04:29.722: INFO: stdout: "pod/e2e-test-nginx-pod created\n"
STEP: verifying the pod e2e-test-nginx-pod was created
[AfterEach] [k8s.io] Kubectl run pod
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1480
Dec  3 21:04:29.725: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-166913721 delete pods e2e-test-nginx-pod --namespace=e2e-tests-kubectl-wxq2g'
Dec  3 21:04:34.713: INFO: stderr: ""
Dec  3 21:04:34.713: INFO: stdout: "pod \"e2e-test-nginx-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 21:04:34.713: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-wxq2g" for this suite.
Dec  3 21:04:40.727: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 21:04:40.779: INFO: namespace: e2e-tests-kubectl-wxq2g, resource: bindings, ignored listing per whitelist
Dec  3 21:04:40.808: INFO: namespace e2e-tests-kubectl-wxq2g deletion completed in 6.090585237s

• [SLOW TEST:11.327 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run pod
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create a pod from an image when restart is Never  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 21:04:40.808: INFO: >>> kubeConfig: /tmp/kubeconfig-166913721
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-0d0c1f6f-f73f-11e8-8d0a-02420af40402
STEP: Creating a pod to test consume configMaps
Dec  3 21:04:40.879: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-0d0c9e8b-f73f-11e8-8d0a-02420af40402" in namespace "e2e-tests-projected-qkmd6" to be "success or failure"
Dec  3 21:04:40.892: INFO: Pod "pod-projected-configmaps-0d0c9e8b-f73f-11e8-8d0a-02420af40402": Phase="Pending", Reason="", readiness=false. Elapsed: 12.891036ms
Dec  3 21:04:42.896: INFO: Pod "pod-projected-configmaps-0d0c9e8b-f73f-11e8-8d0a-02420af40402": Phase="Pending", Reason="", readiness=false. Elapsed: 2.016787046s
Dec  3 21:04:44.899: INFO: Pod "pod-projected-configmaps-0d0c9e8b-f73f-11e8-8d0a-02420af40402": Phase="Pending", Reason="", readiness=false. Elapsed: 4.020461543s
Dec  3 21:04:46.903: INFO: Pod "pod-projected-configmaps-0d0c9e8b-f73f-11e8-8d0a-02420af40402": Phase="Pending", Reason="", readiness=false. Elapsed: 6.024249371s
Dec  3 21:04:48.907: INFO: Pod "pod-projected-configmaps-0d0c9e8b-f73f-11e8-8d0a-02420af40402": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.028312244s
STEP: Saw pod success
Dec  3 21:04:48.907: INFO: Pod "pod-projected-configmaps-0d0c9e8b-f73f-11e8-8d0a-02420af40402" satisfied condition "success or failure"
Dec  3 21:04:48.910: INFO: Trying to get logs from node hungry-keller-3o9a pod pod-projected-configmaps-0d0c9e8b-f73f-11e8-8d0a-02420af40402 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Dec  3 21:04:48.931: INFO: Waiting for pod pod-projected-configmaps-0d0c9e8b-f73f-11e8-8d0a-02420af40402 to disappear
Dec  3 21:04:48.935: INFO: Pod pod-projected-configmaps-0d0c9e8b-f73f-11e8-8d0a-02420af40402 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 21:04:48.935: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-qkmd6" for this suite.
Dec  3 21:04:54.956: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 21:04:54.988: INFO: namespace: e2e-tests-projected-qkmd6, resource: bindings, ignored listing per whitelist
Dec  3 21:04:55.039: INFO: namespace e2e-tests-projected-qkmd6 deletion completed in 6.100317749s

• [SLOW TEST:14.231 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl describe 
  should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 21:04:55.039: INFO: >>> kubeConfig: /tmp/kubeconfig-166913721
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Dec  3 21:04:55.106: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-166913721 version --client'
Dec  3 21:04:55.191: INFO: stderr: ""
Dec  3 21:04:55.191: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"12\", GitVersion:\"v1.12.1\", GitCommit:\"4ed3216f3ec431b140b1d899130a69fc671678f4\", GitTreeState:\"clean\", BuildDate:\"2018-10-05T16:46:06Z\", GoVersion:\"go1.10.4\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
Dec  3 21:04:55.193: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-166913721 create -f - --namespace=e2e-tests-kubectl-svrgb'
Dec  3 21:04:55.382: INFO: stderr: ""
Dec  3 21:04:55.382: INFO: stdout: "replicationcontroller/redis-master created\n"
Dec  3 21:04:55.382: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-166913721 create -f - --namespace=e2e-tests-kubectl-svrgb'
Dec  3 21:04:55.600: INFO: stderr: ""
Dec  3 21:04:55.600: INFO: stdout: "service/redis-master created\n"
STEP: Waiting for Redis master to start.
Dec  3 21:04:56.604: INFO: Selector matched 1 pods for map[app:redis]
Dec  3 21:04:56.604: INFO: Found 0 / 1
Dec  3 21:04:57.604: INFO: Selector matched 1 pods for map[app:redis]
Dec  3 21:04:57.604: INFO: Found 1 / 1
Dec  3 21:04:57.604: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Dec  3 21:04:57.607: INFO: Selector matched 1 pods for map[app:redis]
Dec  3 21:04:57.607: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Dec  3 21:04:57.607: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-166913721 describe pod redis-master-xg249 --namespace=e2e-tests-kubectl-svrgb'
Dec  3 21:04:57.742: INFO: stderr: ""
Dec  3 21:04:57.742: INFO: stdout: "Name:               redis-master-xg249\nNamespace:          e2e-tests-kubectl-svrgb\nPriority:           0\nPriorityClassName:  <none>\nNode:               hungry-keller-3o9a/10.136.91.235\nStart Time:         Mon, 03 Dec 2018 21:04:55 +0000\nLabels:             app=redis\n                    role=master\nAnnotations:        <none>\nStatus:             Running\nIP:                 10.244.72.3\nControlled By:      ReplicationController/redis-master\nContainers:\n  redis-master:\n    Container ID:   docker://1acaf3549324c68901005c7a7ac59b1e0e73a29ae491d7fbd44dd60bed767b95\n    Image:          gcr.io/kubernetes-e2e-test-images/redis:1.0\n    Image ID:       docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830\n    Port:           6379/TCP\n    Host Port:      0/TCP\n    State:          Running\n      Started:      Mon, 03 Dec 2018 21:04:56 +0000\n    Ready:          True\n    Restart Count:  0\n    Environment:    <none>\n    Mounts:\n      /var/run/secrets/kubernetes.io/serviceaccount from default-token-mfjww (ro)\nConditions:\n  Type              Status\n  Initialized       True \n  Ready             True \n  ContainersReady   True \n  PodScheduled      True \nVolumes:\n  default-token-mfjww:\n    Type:        Secret (a volume populated by a Secret)\n    SecretName:  default-token-mfjww\n    Optional:    false\nQoS Class:       BestEffort\nNode-Selectors:  <none>\nTolerations:     node.kubernetes.io/not-ready:NoExecute for 300s\n                 node.kubernetes.io/unreachable:NoExecute for 300s\nEvents:\n  Type    Reason     Age   From                         Message\n  ----    ------     ----  ----                         -------\n  Normal  Scheduled  2s    default-scheduler            Successfully assigned e2e-tests-kubectl-svrgb/redis-master-xg249 to hungry-keller-3o9a\n  Normal  Pulled     1s    kubelet, hungry-keller-3o9a  Container image \"gcr.io/kubernetes-e2e-test-images/redis:1.0\" already present on machine\n  Normal  Created    1s    kubelet, hungry-keller-3o9a  Created container\n  Normal  Started    1s    kubelet, hungry-keller-3o9a  Started container\n"
Dec  3 21:04:57.742: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-166913721 describe rc redis-master --namespace=e2e-tests-kubectl-svrgb'
Dec  3 21:04:57.886: INFO: stderr: ""
Dec  3 21:04:57.886: INFO: stdout: "Name:         redis-master\nNamespace:    e2e-tests-kubectl-svrgb\nSelector:     app=redis,role=master\nLabels:       app=redis\n              role=master\nAnnotations:  <none>\nReplicas:     1 current / 1 desired\nPods Status:  1 Running / 0 Waiting / 0 Succeeded / 0 Failed\nPod Template:\n  Labels:  app=redis\n           role=master\n  Containers:\n   redis-master:\n    Image:        gcr.io/kubernetes-e2e-test-images/redis:1.0\n    Port:         6379/TCP\n    Host Port:    0/TCP\n    Environment:  <none>\n    Mounts:       <none>\n  Volumes:        <none>\nEvents:\n  Type    Reason            Age   From                    Message\n  ----    ------            ----  ----                    -------\n  Normal  SuccessfulCreate  2s    replication-controller  Created pod: redis-master-xg249\n"
Dec  3 21:04:57.886: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-166913721 describe service redis-master --namespace=e2e-tests-kubectl-svrgb'
Dec  3 21:04:58.021: INFO: stderr: ""
Dec  3 21:04:58.021: INFO: stdout: "Name:              redis-master\nNamespace:         e2e-tests-kubectl-svrgb\nLabels:            app=redis\n                   role=master\nAnnotations:       <none>\nSelector:          app=redis,role=master\nType:              ClusterIP\nIP:                10.245.185.139\nPort:              <unset>  6379/TCP\nTargetPort:        redis-server/TCP\nEndpoints:         10.244.72.3:6379\nSession Affinity:  None\nEvents:            <none>\n"
Dec  3 21:04:58.025: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-166913721 describe node hungry-keller-3o96'
Dec  3 21:04:58.163: INFO: stderr: ""
Dec  3 21:04:58.163: INFO: stdout: "Name:               hungry-keller-3o96\nRoles:              <none>\nLabels:             beta.kubernetes.io/arch=amd64\n                    beta.kubernetes.io/instance-type=s-4vcpu-8gb\n                    beta.kubernetes.io/os=linux\n                    failure-domain.beta.kubernetes.io/region=nyc1\n                    kubernetes.io/hostname=hungry-keller-3o96\n                    region=nyc1\nAnnotations:        csi.volume.kubernetes.io/nodeid: {\"dobs.csi.digitalocean.com\":\"121609761\"}\n                    node.alpha.kubernetes.io/ttl: 0\n                    volumes.kubernetes.io/controller-managed-attach-detach: true\nCreationTimestamp:  Mon, 03 Dec 2018 19:18:24 +0000\nTaints:             <none>\nUnschedulable:      false\nConditions:\n  Type             Status  LastHeartbeatTime                 LastTransitionTime                Reason                       Message\n  ----             ------  -----------------                 ------------------                ------                       -------\n  OutOfDisk        False   Mon, 03 Dec 2018 21:04:51 +0000   Mon, 03 Dec 2018 19:18:24 +0000   KubeletHasSufficientDisk     kubelet has sufficient disk space available\n  MemoryPressure   False   Mon, 03 Dec 2018 21:04:51 +0000   Mon, 03 Dec 2018 19:18:24 +0000   KubeletHasSufficientMemory   kubelet has sufficient memory available\n  DiskPressure     False   Mon, 03 Dec 2018 21:04:51 +0000   Mon, 03 Dec 2018 19:18:24 +0000   KubeletHasNoDiskPressure     kubelet has no disk pressure\n  PIDPressure      False   Mon, 03 Dec 2018 21:04:51 +0000   Mon, 03 Dec 2018 19:18:24 +0000   KubeletHasSufficientPID      kubelet has sufficient PID available\n  Ready            True    Mon, 03 Dec 2018 21:04:51 +0000   Mon, 03 Dec 2018 19:18:24 +0000   KubeletReady                 kubelet is posting ready status\nAddresses:\n  Hostname:    hungry-keller-3o96\n  InternalIP:  10.136.127.223\n  ExternalIP:  206.81.9.129\nCapacity:\n attachable-volumes-csi-dobs.csi.digitalocean.com:  7\n cpu:                                               4\n ephemeral-storage:                                 165105408Ki\n hugepages-1Gi:                                     0\n hugepages-2Mi:                                     0\n memory:                                            8179332Ki\n pods:                                              110\nAllocatable:\n attachable-volumes-csi-dobs.csi.digitalocean.com:  7\n cpu:                                               4\n ephemeral-storage:                                 152161143761\n hugepages-1Gi:                                     0\n hugepages-2Mi:                                     0\n memory:                                            8076932Ki\n pods:                                              110\nSystem Info:\n Machine ID:                 4a96cdf3f93543ee81e7544f17930d4e\n System UUID:                4A96CDF3-F935-43EE-81E7-544F17930D4E\n Boot ID:                    51078b21-0026-499d-9530-cfd9db35e88a\n Kernel Version:             4.9.0-8-amd64\n OS Image:                   Debian GNU/Linux 9 (stretch)\n Operating System:           linux\n Architecture:               amd64\n Container Runtime Version:  docker://18.9.0\n Kubelet Version:            v1.12.3\n Kube-Proxy Version:         v1.12.3\nPodCIDR:                     10.244.0.0/24\nProviderID:                  digitalocean://121609761\nNon-terminated Pods:         (5 in total)\n  Namespace                  Name                                                       CPU Requests  CPU Limits  Memory Requests  Memory Limits\n  ---------                  ----                                                       ------------  ----------  ---------------  -------------\n  heptio-sonobuoy            sonobuoy-systemd-logs-daemon-set-15edf0f0fb534ac8-s4x2r    0 (0%)        0 (0%)      0 (0%)           0 (0%)\n  kube-system                csi-do-controller-0                                        0 (0%)        0 (0%)      0 (0%)           0 (0%)\n  kube-system                csi-do-node-rt2f8                                          0 (0%)        0 (0%)      0 (0%)           0 (0%)\n  kube-system                kube-dns-55cf9576c4-wx9kt                                  260m (6%)     0 (0%)      110Mi (1%)       170Mi (2%)\n  kube-system                kube-proxy-hungry-keller-3o96                              0 (0%)        0 (0%)      0 (0%)           0 (0%)\nAllocated resources:\n  (Total limits may be over 100 percent, i.e., overcommitted.)\n  Resource                                          Requests    Limits\n  --------                                          --------    ------\n  cpu                                               260m (6%)   0 (0%)\n  memory                                            110Mi (1%)  170Mi (2%)\n  attachable-volumes-csi-dobs.csi.digitalocean.com  0           0\nEvents:                                             <none>\n"
Dec  3 21:04:58.163: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-166913721 describe namespace e2e-tests-kubectl-svrgb'
Dec  3 21:04:58.280: INFO: stderr: ""
Dec  3 21:04:58.280: INFO: stdout: "Name:         e2e-tests-kubectl-svrgb\nLabels:       e2e-framework=kubectl\n              e2e-run=161a3e08-f733-11e8-8d0a-02420af40402\nAnnotations:  <none>\nStatus:       Active\n\nNo resource quota.\n\nNo resource limits.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 21:04:58.280: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-svrgb" for this suite.
Dec  3 21:05:20.294: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 21:05:20.340: INFO: namespace: e2e-tests-kubectl-svrgb, resource: bindings, ignored listing per whitelist
Dec  3 21:05:20.397: INFO: namespace e2e-tests-kubectl-svrgb deletion completed in 22.113207908s

• [SLOW TEST:25.358 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl describe
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should check if kubectl describe prints relevant information for rc and pods  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run job 
  should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 21:05:20.397: INFO: >>> kubeConfig: /tmp/kubeconfig-166913721
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Kubectl run job
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1402
[It] should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Dec  3 21:05:20.467: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-166913721 run e2e-test-nginx-job --restart=OnFailure --generator=job/v1 --image=docker.io/library/nginx:1.14-alpine --namespace=e2e-tests-kubectl-gvm4f'
Dec  3 21:05:20.608: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl create instead.\n"
Dec  3 21:05:20.608: INFO: stdout: "job.batch/e2e-test-nginx-job created\n"
STEP: verifying the job e2e-test-nginx-job was created
[AfterEach] [k8s.io] Kubectl run job
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1407
Dec  3 21:05:20.628: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-166913721 delete jobs e2e-test-nginx-job --namespace=e2e-tests-kubectl-gvm4f'
Dec  3 21:05:20.747: INFO: stderr: ""
Dec  3 21:05:20.747: INFO: stdout: "job.batch \"e2e-test-nginx-job\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 21:05:20.747: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-gvm4f" for this suite.
Dec  3 21:05:26.770: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 21:05:26.812: INFO: namespace: e2e-tests-kubectl-gvm4f, resource: bindings, ignored listing per whitelist
Dec  3 21:05:26.858: INFO: namespace e2e-tests-kubectl-gvm4f deletion completed in 6.103706483s

• [SLOW TEST:6.461 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run job
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create a job from an image when restart is OnFailure  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 21:05:26.858: INFO: >>> kubeConfig: /tmp/kubeconfig-166913721
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:78
Dec  3 21:05:26.977: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Dec  3 21:05:26.983: INFO: Waiting for terminating namespaces to be deleted...
Dec  3 21:05:26.985: INFO: 
Logging pods the kubelet thinks is on node hungry-keller-3o96 before test
Dec  3 21:05:26.993: INFO: csi-do-controller-0 from kube-system started at 2018-12-03 19:18:27 +0000 UTC (4 container statuses recorded)
Dec  3 21:05:26.993: INFO: 	Container csi-attacher ready: true, restart count 0
Dec  3 21:05:26.993: INFO: 	Container csi-do-plugin ready: true, restart count 0
Dec  3 21:05:26.993: INFO: 	Container csi-provisioner ready: true, restart count 0
Dec  3 21:05:26.993: INFO: 	Container csi-snapshotter ready: true, restart count 2
Dec  3 21:05:26.993: INFO: sonobuoy-systemd-logs-daemon-set-15edf0f0fb534ac8-s4x2r from heptio-sonobuoy started at 2018-12-03 19:38:50 +0000 UTC (2 container statuses recorded)
Dec  3 21:05:26.993: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 1
Dec  3 21:05:26.993: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Dec  3 21:05:26.993: INFO: kube-dns-55cf9576c4-wx9kt from kube-system started at 2018-12-03 19:18:27 +0000 UTC (3 container statuses recorded)
Dec  3 21:05:26.993: INFO: 	Container dnsmasq ready: true, restart count 0
Dec  3 21:05:26.993: INFO: 	Container kubedns ready: true, restart count 0
Dec  3 21:05:26.993: INFO: 	Container sidecar ready: true, restart count 0
Dec  3 21:05:26.993: INFO: kube-proxy-hungry-keller-3o96 from kube-system started at <nil> (0 container statuses recorded)
Dec  3 21:05:26.993: INFO: csi-do-node-rt2f8 from kube-system started at 2018-12-03 19:18:39 +0000 UTC (2 container statuses recorded)
Dec  3 21:05:26.993: INFO: 	Container csi-do-plugin ready: true, restart count 0
Dec  3 21:05:26.993: INFO: 	Container driver-registrar ready: true, restart count 2
Dec  3 21:05:26.993: INFO: 
Logging pods the kubelet thinks is on node hungry-keller-3o9a before test
Dec  3 21:05:27.000: INFO: sonobuoy from heptio-sonobuoy started at 2018-12-03 19:38:46 +0000 UTC (1 container statuses recorded)
Dec  3 21:05:27.001: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Dec  3 21:05:27.001: INFO: sonobuoy-systemd-logs-daemon-set-15edf0f0fb534ac8-g5n59 from heptio-sonobuoy started at 2018-12-03 19:38:50 +0000 UTC (2 container statuses recorded)
Dec  3 21:05:27.001: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 1
Dec  3 21:05:27.001: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Dec  3 21:05:27.001: INFO: kube-proxy-hungry-keller-3o9a from kube-system started at <nil> (0 container statuses recorded)
Dec  3 21:05:27.001: INFO: csi-do-node-8zhsm from kube-system started at 2018-12-03 19:18:33 +0000 UTC (2 container statuses recorded)
Dec  3 21:05:27.001: INFO: 	Container csi-do-plugin ready: true, restart count 0
Dec  3 21:05:27.001: INFO: 	Container driver-registrar ready: true, restart count 0
Dec  3 21:05:27.001: INFO: 
Logging pods the kubelet thinks is on node hungry-keller-3o9e before test
Dec  3 21:05:27.018: INFO: sonobuoy-systemd-logs-daemon-set-15edf0f0fb534ac8-nncfq from heptio-sonobuoy started at 2018-12-03 19:38:50 +0000 UTC (2 container statuses recorded)
Dec  3 21:05:27.018: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 1
Dec  3 21:05:27.018: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Dec  3 21:05:27.018: INFO: csi-do-node-2vwn4 from kube-system started at 2018-12-03 19:18:41 +0000 UTC (2 container statuses recorded)
Dec  3 21:05:27.018: INFO: 	Container csi-do-plugin ready: true, restart count 0
Dec  3 21:05:27.018: INFO: 	Container driver-registrar ready: true, restart count 0
Dec  3 21:05:27.018: INFO: sonobuoy-e2e-job-ef309e1fd8f04e08 from heptio-sonobuoy started at 2018-12-03 19:38:49 +0000 UTC (2 container statuses recorded)
Dec  3 21:05:27.018: INFO: 	Container e2e ready: true, restart count 0
Dec  3 21:05:27.018: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Dec  3 21:05:27.018: INFO: kube-proxy-hungry-keller-3o9e from kube-system started at <nil> (0 container statuses recorded)
[It] validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Trying to schedule Pod with nonempty NodeSelector.
STEP: Considering event: 
Type = [Warning], Name = [restricted-pod.156cee9c3a7b68ce], Reason = [FailedScheduling], Message = [0/3 nodes are available: 3 node(s) didn't match node selector.]
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 21:05:28.042: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-sched-pred-zmfsx" for this suite.
Dec  3 21:05:34.059: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 21:05:34.150: INFO: namespace: e2e-tests-sched-pred-zmfsx, resource: bindings, ignored listing per whitelist
Dec  3 21:05:34.177: INFO: namespace e2e-tests-sched-pred-zmfsx deletion completed in 6.131211736s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:69

• [SLOW TEST:7.319 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl patch 
  should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 21:05:34.177: INFO: >>> kubeConfig: /tmp/kubeconfig-166913721
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating Redis RC
Dec  3 21:05:34.313: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-166913721 create -f - --namespace=e2e-tests-kubectl-lfccf'
Dec  3 21:05:34.523: INFO: stderr: ""
Dec  3 21:05:34.523: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
Dec  3 21:05:35.527: INFO: Selector matched 1 pods for map[app:redis]
Dec  3 21:05:35.527: INFO: Found 0 / 1
Dec  3 21:05:36.527: INFO: Selector matched 1 pods for map[app:redis]
Dec  3 21:05:36.527: INFO: Found 0 / 1
Dec  3 21:05:37.527: INFO: Selector matched 1 pods for map[app:redis]
Dec  3 21:05:37.527: INFO: Found 1 / 1
Dec  3 21:05:37.527: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
STEP: patching all pods
Dec  3 21:05:37.529: INFO: Selector matched 1 pods for map[app:redis]
Dec  3 21:05:37.529: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Dec  3 21:05:37.529: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-166913721 patch pod redis-master-pfldw --namespace=e2e-tests-kubectl-lfccf -p {"metadata":{"annotations":{"x":"y"}}}'
Dec  3 21:05:37.714: INFO: stderr: ""
Dec  3 21:05:37.714: INFO: stdout: "pod/redis-master-pfldw patched\n"
STEP: checking annotations
Dec  3 21:05:37.717: INFO: Selector matched 1 pods for map[app:redis]
Dec  3 21:05:37.717: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 21:05:37.717: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-lfccf" for this suite.
Dec  3 21:05:59.734: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 21:05:59.799: INFO: namespace: e2e-tests-kubectl-lfccf, resource: bindings, ignored listing per whitelist
Dec  3 21:05:59.824: INFO: namespace e2e-tests-kubectl-lfccf deletion completed in 22.102773052s

• [SLOW TEST:25.647 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl patch
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should add annotations for pods in rc  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-api-machinery] Downward API 
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 21:05:59.825: INFO: >>> kubeConfig: /tmp/kubeconfig-166913721
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Dec  3 21:05:59.898: INFO: Waiting up to 5m0s for pod "downward-api-3c25dead-f73f-11e8-8d0a-02420af40402" in namespace "e2e-tests-downward-api-nsghw" to be "success or failure"
Dec  3 21:05:59.909: INFO: Pod "downward-api-3c25dead-f73f-11e8-8d0a-02420af40402": Phase="Pending", Reason="", readiness=false. Elapsed: 11.038597ms
Dec  3 21:06:01.913: INFO: Pod "downward-api-3c25dead-f73f-11e8-8d0a-02420af40402": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.014984286s
STEP: Saw pod success
Dec  3 21:06:01.914: INFO: Pod "downward-api-3c25dead-f73f-11e8-8d0a-02420af40402" satisfied condition "success or failure"
Dec  3 21:06:01.916: INFO: Trying to get logs from node hungry-keller-3o9e pod downward-api-3c25dead-f73f-11e8-8d0a-02420af40402 container dapi-container: <nil>
STEP: delete the pod
Dec  3 21:06:01.937: INFO: Waiting for pod downward-api-3c25dead-f73f-11e8-8d0a-02420af40402 to disappear
Dec  3 21:06:01.941: INFO: Pod downward-api-3c25dead-f73f-11e8-8d0a-02420af40402 no longer exists
[AfterEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 21:06:01.941: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-nsghw" for this suite.
Dec  3 21:06:07.955: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 21:06:07.992: INFO: namespace: e2e-tests-downward-api-nsghw, resource: bindings, ignored listing per whitelist
Dec  3 21:06:08.047: INFO: namespace e2e-tests-downward-api-nsghw deletion completed in 6.101704369s

• [SLOW TEST:8.222 seconds]
[sig-api-machinery] Downward API
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 21:06:08.047: INFO: >>> kubeConfig: /tmp/kubeconfig-166913721
STEP: Building a namespace api object, basename namespaces
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a test namespace
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a service in the namespace
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Verifying there is no service in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 21:06:14.614: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-namespaces-mxkjv" for this suite.
Dec  3 21:06:20.757: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 21:06:20.798: INFO: namespace: e2e-tests-namespaces-mxkjv, resource: bindings, ignored listing per whitelist
Dec  3 21:06:20.850: INFO: namespace e2e-tests-namespaces-mxkjv deletion completed in 6.231183775s
STEP: Destroying namespace "e2e-tests-nsdeletetest-w9j88" for this suite.
Dec  3 21:06:20.853: INFO: Namespace e2e-tests-nsdeletetest-w9j88 was already deleted
STEP: Destroying namespace "e2e-tests-nsdeletetest-b9bpf" for this suite.
Dec  3 21:06:26.864: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 21:06:26.932: INFO: namespace: e2e-tests-nsdeletetest-b9bpf, resource: bindings, ignored listing per whitelist
Dec  3 21:06:26.950: INFO: namespace e2e-tests-nsdeletetest-b9bpf deletion completed in 6.097733419s

• [SLOW TEST:18.904 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec  3 21:06:26.951: INFO: >>> kubeConfig: /tmp/kubeconfig-166913721
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Dec  3 21:06:31.080: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Dec  3 21:06:31.083: INFO: Pod pod-with-poststart-http-hook still exists
Dec  3 21:06:33.083: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Dec  3 21:06:33.087: INFO: Pod pod-with-poststart-http-hook still exists
Dec  3 21:06:35.083: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Dec  3 21:06:35.087: INFO: Pod pod-with-poststart-http-hook still exists
Dec  3 21:06:37.083: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Dec  3 21:06:37.088: INFO: Pod pod-with-poststart-http-hook still exists
Dec  3 21:06:39.083: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Dec  3 21:06:39.087: INFO: Pod pod-with-poststart-http-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec  3 21:06:39.087: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-lifecycle-hook-9pgvh" for this suite.
Dec  3 21:07:01.102: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 21:07:01.123: INFO: namespace: e2e-tests-container-lifecycle-hook-9pgvh, resource: bindings, ignored listing per whitelist
Dec  3 21:07:01.192: INFO: namespace e2e-tests-container-lifecycle-hook-9pgvh deletion completed in 22.101915521s

• [SLOW TEST:34.241 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when create a pod with lifecycle hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute poststart http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSDec  3 21:07:01.192: INFO: Running AfterSuite actions on all node
Dec  3 21:07:01.193: INFO: Running AfterSuite actions on node 1
Dec  3 21:07:01.193: INFO: Skipping dumping logs from cluster

Ran 187 of 1814 Specs in 5277.887 seconds
SUCCESS! -- 187 Passed | 0 Failed | 0 Pending | 1627 Skipped PASS

Ginkgo ran 1 suite in 1h27m59.273080318s
Test Suite Passed
