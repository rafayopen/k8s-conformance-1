Dec 10 13:43:16.707: INFO: Overriding default scale value of zero to 1
Dec 10 13:43:16.708: INFO: Overriding default milliseconds value of zero to 5000
I1210 13:43:17.151586      15 test_context.go:385] Using a temporary kubeconfig file from in-cluster config : /tmp/kubeconfig-578738756
I1210 13:43:17.151886      15 e2e.go:304] Starting e2e run "8c1b051f-fc81-11e8-a36b-7e9ed3de7210" on Ginkgo node 1
Running Suite: Kubernetes e2e suite
===================================
Random Seed: 1544449396 - Will randomize all specs
Will run 188 of 1814 specs

Dec 10 13:43:17.296: INFO: >>> kubeConfig: /tmp/kubeconfig-578738756
Dec 10 13:43:17.298: INFO: Waiting up to 30m0s for all (but 0) nodes to be schedulable
Dec 10 13:43:17.314: INFO: Waiting up to 10m0s for all pods (need at least 0) in namespace 'kube-system' to be running and ready
Dec 10 13:43:17.348: INFO: 27 / 27 pods in namespace 'kube-system' are running and ready (0 seconds elapsed)
Dec 10 13:43:17.348: INFO: expected 6 pod replicas in namespace 'kube-system', 6 are Running and Ready.
Dec 10 13:43:17.348: INFO: Waiting up to 5m0s for all daemonsets in namespace 'kube-system' to start
Dec 10 13:43:17.357: INFO: 5 / 5 pods ready in namespace 'kube-system' in daemonset 'calico-node' (0 seconds elapsed)
Dec 10 13:43:17.357: INFO: 5 / 5 pods ready in namespace 'kube-system' in daemonset 'kube-proxy' (0 seconds elapsed)
Dec 10 13:43:17.357: INFO: e2e test version: v1.12.1
Dec 10 13:43:17.358: INFO: kube-apiserver version: v1.12.3
SSSSSSSS
------------------------------
[sig-api-machinery] Downward API 
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 10 13:43:17.359: INFO: >>> kubeConfig: /tmp/kubeconfig-578738756
STEP: Building a namespace api object, basename downward-api
Dec 10 13:43:17.430: INFO: No PodSecurityPolicies found; assuming PodSecurityPolicy is disabled.
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Dec 10 13:43:17.444: INFO: Waiting up to 5m0s for pod "downward-api-8c9463f3-fc81-11e8-a36b-7e9ed3de7210" in namespace "e2e-tests-downward-api-xlcnw" to be "success or failure"
Dec 10 13:43:17.449: INFO: Pod "downward-api-8c9463f3-fc81-11e8-a36b-7e9ed3de7210": Phase="Pending", Reason="", readiness=false. Elapsed: 4.503202ms
Dec 10 13:43:19.454: INFO: Pod "downward-api-8c9463f3-fc81-11e8-a36b-7e9ed3de7210": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009978617s
Dec 10 13:43:21.459: INFO: Pod "downward-api-8c9463f3-fc81-11e8-a36b-7e9ed3de7210": Phase="Pending", Reason="", readiness=false. Elapsed: 4.014588444s
Dec 10 13:43:23.464: INFO: Pod "downward-api-8c9463f3-fc81-11e8-a36b-7e9ed3de7210": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.019506209s
STEP: Saw pod success
Dec 10 13:43:23.464: INFO: Pod "downward-api-8c9463f3-fc81-11e8-a36b-7e9ed3de7210" satisfied condition "success or failure"
Dec 10 13:43:23.468: INFO: Trying to get logs from node conformance-cluster1-k8s-node-2 pod downward-api-8c9463f3-fc81-11e8-a36b-7e9ed3de7210 container dapi-container: <nil>
STEP: delete the pod
Dec 10 13:43:23.509: INFO: Waiting for pod downward-api-8c9463f3-fc81-11e8-a36b-7e9ed3de7210 to disappear
Dec 10 13:43:23.512: INFO: Pod downward-api-8c9463f3-fc81-11e8-a36b-7e9ed3de7210 no longer exists
[AfterEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 10 13:43:23.512: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-xlcnw" for this suite.
Dec 10 13:43:29.531: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 13:43:29.554: INFO: namespace: e2e-tests-downward-api-xlcnw, resource: bindings, ignored listing per whitelist
Dec 10 13:43:29.647: INFO: namespace e2e-tests-downward-api-xlcnw deletion completed in 6.130614889s

• [SLOW TEST:12.289 seconds]
[sig-api-machinery] Downward API
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 10 13:43:29.648: INFO: >>> kubeConfig: /tmp/kubeconfig-578738756
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-93e756da-fc81-11e8-a36b-7e9ed3de7210
STEP: Creating a pod to test consume secrets
Dec 10 13:43:29.774: INFO: Waiting up to 5m0s for pod "pod-secrets-93ee63c6-fc81-11e8-a36b-7e9ed3de7210" in namespace "e2e-tests-secrets-qrv7z" to be "success or failure"
Dec 10 13:43:29.780: INFO: Pod "pod-secrets-93ee63c6-fc81-11e8-a36b-7e9ed3de7210": Phase="Pending", Reason="", readiness=false. Elapsed: 5.993711ms
Dec 10 13:43:37.868: INFO: Pod "pod-secrets-93ee63c6-fc81-11e8-a36b-7e9ed3de7210": Phase="Pending", Reason="", readiness=false. Elapsed: 8.094448428s
Dec 10 13:43:49.744: INFO: Pod "pod-secrets-93ee63c6-fc81-11e8-a36b-7e9ed3de7210": Phase="Pending", Reason="", readiness=false. Elapsed: 19.9703796s
Dec 10 13:43:51.750: INFO: Pod "pod-secrets-93ee63c6-fc81-11e8-a36b-7e9ed3de7210": Phase="Succeeded", Reason="", readiness=false. Elapsed: 21.976331724s
STEP: Saw pod success
Dec 10 13:43:51.750: INFO: Pod "pod-secrets-93ee63c6-fc81-11e8-a36b-7e9ed3de7210" satisfied condition "success or failure"
Dec 10 13:43:51.756: INFO: Trying to get logs from node conformance-cluster1-k8s-node-2 pod pod-secrets-93ee63c6-fc81-11e8-a36b-7e9ed3de7210 container secret-volume-test: <nil>
STEP: delete the pod
Dec 10 13:43:51.805: INFO: Waiting for pod pod-secrets-93ee63c6-fc81-11e8-a36b-7e9ed3de7210 to disappear
Dec 10 13:43:51.812: INFO: Pod pod-secrets-93ee63c6-fc81-11e8-a36b-7e9ed3de7210 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 10 13:43:51.812: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-qrv7z" for this suite.
Dec 10 13:43:57.844: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 13:43:57.893: INFO: namespace: e2e-tests-secrets-qrv7z, resource: bindings, ignored listing per whitelist
Dec 10 13:43:57.950: INFO: namespace e2e-tests-secrets-qrv7z deletion completed in 6.13175097s
STEP: Destroying namespace "e2e-tests-secret-namespace-2rkmp" for this suite.
Dec 10 13:44:03.966: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 13:44:04.049: INFO: namespace: e2e-tests-secret-namespace-2rkmp, resource: bindings, ignored listing per whitelist
Dec 10 13:44:04.076: INFO: namespace e2e-tests-secret-namespace-2rkmp deletion completed in 6.125946853s

• [SLOW TEST:34.428 seconds]
[sig-storage] Secrets
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Projected 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 10 13:44:04.077: INFO: >>> kubeConfig: /tmp/kubeconfig-578738756
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-a86b7c72-fc81-11e8-a36b-7e9ed3de7210
STEP: Creating a pod to test consume configMaps
Dec 10 13:44:04.155: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-a86c8616-fc81-11e8-a36b-7e9ed3de7210" in namespace "e2e-tests-projected-2glfr" to be "success or failure"
Dec 10 13:44:04.158: INFO: Pod "pod-projected-configmaps-a86c8616-fc81-11e8-a36b-7e9ed3de7210": Phase="Pending", Reason="", readiness=false. Elapsed: 3.043462ms
Dec 10 13:44:06.162: INFO: Pod "pod-projected-configmaps-a86c8616-fc81-11e8-a36b-7e9ed3de7210": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00716749s
Dec 10 13:44:08.167: INFO: Pod "pod-projected-configmaps-a86c8616-fc81-11e8-a36b-7e9ed3de7210": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012003257s
STEP: Saw pod success
Dec 10 13:44:08.167: INFO: Pod "pod-projected-configmaps-a86c8616-fc81-11e8-a36b-7e9ed3de7210" satisfied condition "success or failure"
Dec 10 13:44:08.171: INFO: Trying to get logs from node conformance-cluster1-k8s-node-2 pod pod-projected-configmaps-a86c8616-fc81-11e8-a36b-7e9ed3de7210 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Dec 10 13:44:08.199: INFO: Waiting for pod pod-projected-configmaps-a86c8616-fc81-11e8-a36b-7e9ed3de7210 to disappear
Dec 10 13:44:08.203: INFO: Pod pod-projected-configmaps-a86c8616-fc81-11e8-a36b-7e9ed3de7210 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 10 13:44:08.204: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-2glfr" for this suite.
Dec 10 13:44:14.223: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 13:44:14.339: INFO: namespace: e2e-tests-projected-2glfr, resource: bindings, ignored listing per whitelist
Dec 10 13:44:14.339: INFO: namespace e2e-tests-projected-2glfr deletion completed in 6.130802969s

• [SLOW TEST:10.263 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 10 13:44:14.340: INFO: >>> kubeConfig: /tmp/kubeconfig-578738756
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-62vng
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Dec 10 13:44:14.407: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Dec 10 13:44:44.496: INFO: ExecWithOptions {Command:[/bin/sh -c echo 'hostName' | timeout -t 2 nc -w 1 -u 10.233.64.131 8081 | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-62vng PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 10 13:44:44.496: INFO: >>> kubeConfig: /tmp/kubeconfig-578738756
Dec 10 13:44:45.604: INFO: Found all expected endpoints: [netserver-0]
Dec 10 13:44:45.608: INFO: ExecWithOptions {Command:[/bin/sh -c echo 'hostName' | timeout -t 2 nc -w 1 -u 10.233.122.199 8081 | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-62vng PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 10 13:44:45.608: INFO: >>> kubeConfig: /tmp/kubeconfig-578738756
Dec 10 13:44:46.721: INFO: Found all expected endpoints: [netserver-1]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 10 13:44:46.721: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-62vng" for this suite.
Dec 10 13:45:08.742: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 13:45:08.767: INFO: namespace: e2e-tests-pod-network-test-62vng, resource: bindings, ignored listing per whitelist
Dec 10 13:45:08.852: INFO: namespace e2e-tests-pod-network-test-62vng deletion completed in 22.125293718s

• [SLOW TEST:54.512 seconds]
[sig-network] Networking
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: udp [NodeConformance] [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 10 13:45:08.853: INFO: >>> kubeConfig: /tmp/kubeconfig-578738756
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Dec 10 13:45:08.932: INFO: Waiting up to 5m0s for pod "downwardapi-volume-cf086210-fc81-11e8-a36b-7e9ed3de7210" in namespace "e2e-tests-downward-api-z7hlq" to be "success or failure"
Dec 10 13:45:08.942: INFO: Pod "downwardapi-volume-cf086210-fc81-11e8-a36b-7e9ed3de7210": Phase="Pending", Reason="", readiness=false. Elapsed: 9.934237ms
Dec 10 13:45:10.946: INFO: Pod "downwardapi-volume-cf086210-fc81-11e8-a36b-7e9ed3de7210": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014632021s
Dec 10 13:45:12.951: INFO: Pod "downwardapi-volume-cf086210-fc81-11e8-a36b-7e9ed3de7210": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.019243815s
STEP: Saw pod success
Dec 10 13:45:12.951: INFO: Pod "downwardapi-volume-cf086210-fc81-11e8-a36b-7e9ed3de7210" satisfied condition "success or failure"
Dec 10 13:45:12.954: INFO: Trying to get logs from node conformance-cluster1-k8s-node-1 pod downwardapi-volume-cf086210-fc81-11e8-a36b-7e9ed3de7210 container client-container: <nil>
STEP: delete the pod
Dec 10 13:45:12.988: INFO: Waiting for pod downwardapi-volume-cf086210-fc81-11e8-a36b-7e9ed3de7210 to disappear
Dec 10 13:45:12.991: INFO: Pod downwardapi-volume-cf086210-fc81-11e8-a36b-7e9ed3de7210 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 10 13:45:12.991: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-z7hlq" for this suite.
Dec 10 13:45:19.017: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 13:45:19.031: INFO: namespace: e2e-tests-downward-api-z7hlq, resource: bindings, ignored listing per whitelist
Dec 10 13:45:19.127: INFO: namespace e2e-tests-downward-api-z7hlq deletion completed in 6.13152894s

• [SLOW TEST:10.274 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 10 13:45:19.128: INFO: >>> kubeConfig: /tmp/kubeconfig-578738756
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the rc1
STEP: create the rc2
STEP: set half of pods created by rc simpletest-rc-to-be-deleted to have rc simpletest-rc-to-stay as owner as well
STEP: delete the rc simpletest-rc-to-be-deleted
STEP: wait for the rc to be deleted
STEP: Gathering metrics
W1210 13:45:29.285688      15 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Dec 10 13:45:29.285: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 10 13:45:29.285: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-c2lfc" for this suite.
Dec 10 13:45:35.308: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 13:45:35.422: INFO: namespace: e2e-tests-gc-c2lfc, resource: bindings, ignored listing per whitelist
Dec 10 13:45:35.473: INFO: namespace e2e-tests-gc-c2lfc deletion completed in 6.182382296s

• [SLOW TEST:16.345 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-api-machinery] Secrets 
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 10 13:45:35.473: INFO: >>> kubeConfig: /tmp/kubeconfig-578738756
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-dee7d418-fc81-11e8-a36b-7e9ed3de7210
STEP: Creating a pod to test consume secrets
Dec 10 13:45:35.568: INFO: Waiting up to 5m0s for pod "pod-secrets-dee90304-fc81-11e8-a36b-7e9ed3de7210" in namespace "e2e-tests-secrets-c58v2" to be "success or failure"
Dec 10 13:45:35.572: INFO: Pod "pod-secrets-dee90304-fc81-11e8-a36b-7e9ed3de7210": Phase="Pending", Reason="", readiness=false. Elapsed: 3.673269ms
Dec 10 13:45:37.576: INFO: Pod "pod-secrets-dee90304-fc81-11e8-a36b-7e9ed3de7210": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008336914s
Dec 10 13:45:39.585: INFO: Pod "pod-secrets-dee90304-fc81-11e8-a36b-7e9ed3de7210": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.017319221s
STEP: Saw pod success
Dec 10 13:45:39.585: INFO: Pod "pod-secrets-dee90304-fc81-11e8-a36b-7e9ed3de7210" satisfied condition "success or failure"
Dec 10 13:45:39.589: INFO: Trying to get logs from node conformance-cluster1-k8s-node-2 pod pod-secrets-dee90304-fc81-11e8-a36b-7e9ed3de7210 container secret-env-test: <nil>
STEP: delete the pod
Dec 10 13:45:39.611: INFO: Waiting for pod pod-secrets-dee90304-fc81-11e8-a36b-7e9ed3de7210 to disappear
Dec 10 13:45:39.614: INFO: Pod pod-secrets-dee90304-fc81-11e8-a36b-7e9ed3de7210 no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 10 13:45:39.614: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-c58v2" for this suite.
Dec 10 13:45:45.634: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 13:45:45.648: INFO: namespace: e2e-tests-secrets-c58v2, resource: bindings, ignored listing per whitelist
Dec 10 13:45:45.745: INFO: namespace e2e-tests-secrets-c58v2 deletion completed in 6.126089796s

• [SLOW TEST:10.272 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:31
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 10 13:45:45.745: INFO: >>> kubeConfig: /tmp/kubeconfig-578738756
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-e5049368-fc81-11e8-a36b-7e9ed3de7210
STEP: Creating a pod to test consume configMaps
Dec 10 13:45:45.821: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-e5059c42-fc81-11e8-a36b-7e9ed3de7210" in namespace "e2e-tests-projected-jscq9" to be "success or failure"
Dec 10 13:45:45.825: INFO: Pod "pod-projected-configmaps-e5059c42-fc81-11e8-a36b-7e9ed3de7210": Phase="Pending", Reason="", readiness=false. Elapsed: 4.055462ms
Dec 10 13:45:47.831: INFO: Pod "pod-projected-configmaps-e5059c42-fc81-11e8-a36b-7e9ed3de7210": Phase="Running", Reason="", readiness=true. Elapsed: 2.009562667s
Dec 10 13:45:49.841: INFO: Pod "pod-projected-configmaps-e5059c42-fc81-11e8-a36b-7e9ed3de7210": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.019282402s
STEP: Saw pod success
Dec 10 13:45:49.841: INFO: Pod "pod-projected-configmaps-e5059c42-fc81-11e8-a36b-7e9ed3de7210" satisfied condition "success or failure"
Dec 10 13:45:49.844: INFO: Trying to get logs from node conformance-cluster1-k8s-node-2 pod pod-projected-configmaps-e5059c42-fc81-11e8-a36b-7e9ed3de7210 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Dec 10 13:45:49.870: INFO: Waiting for pod pod-projected-configmaps-e5059c42-fc81-11e8-a36b-7e9ed3de7210 to disappear
Dec 10 13:45:49.875: INFO: Pod pod-projected-configmaps-e5059c42-fc81-11e8-a36b-7e9ed3de7210 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 10 13:45:49.875: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-jscq9" for this suite.
Dec 10 13:45:55.894: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 13:45:55.981: INFO: namespace: e2e-tests-projected-jscq9, resource: bindings, ignored listing per whitelist
Dec 10 13:45:56.010: INFO: namespace e2e-tests-projected-jscq9 deletion completed in 6.13083666s

• [SLOW TEST:10.265 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 10 13:45:56.010: INFO: >>> kubeConfig: /tmp/kubeconfig-578738756
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:98
[It] should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Dec 10 13:45:56.088: INFO: Creating simple daemon set daemon-set
STEP: Check that daemon pods launch on every node of the cluster.
Dec 10 13:45:56.101: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:45:56.101: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:45:56.101: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:45:56.105: INFO: Number of nodes with available pods: 0
Dec 10 13:45:56.105: INFO: Node conformance-cluster1-k8s-node-1 is running more than one daemon pod
Dec 10 13:45:57.110: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:45:57.110: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:45:57.110: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:45:57.113: INFO: Number of nodes with available pods: 0
Dec 10 13:45:57.113: INFO: Node conformance-cluster1-k8s-node-1 is running more than one daemon pod
Dec 10 13:45:58.109: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:45:58.110: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:45:58.110: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:45:58.113: INFO: Number of nodes with available pods: 0
Dec 10 13:45:58.113: INFO: Node conformance-cluster1-k8s-node-1 is running more than one daemon pod
Dec 10 13:45:59.110: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:45:59.110: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:45:59.110: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:45:59.114: INFO: Number of nodes with available pods: 0
Dec 10 13:45:59.114: INFO: Node conformance-cluster1-k8s-node-1 is running more than one daemon pod
Dec 10 13:46:00.118: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:46:00.118: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:46:00.118: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:46:00.123: INFO: Number of nodes with available pods: 1
Dec 10 13:46:00.123: INFO: Node conformance-cluster1-k8s-node-1 is running more than one daemon pod
Dec 10 13:46:01.110: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:46:01.110: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:46:01.110: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:46:01.113: INFO: Number of nodes with available pods: 2
Dec 10 13:46:01.114: INFO: Number of running nodes: 2, number of available pods: 2
STEP: Update daemon pods image.
STEP: Check that daemon pods images are updated.
Dec 10 13:46:01.141: INFO: Wrong image for pod: daemon-set-58th2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 10 13:46:01.141: INFO: Wrong image for pod: daemon-set-5s5zw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 10 13:46:01.146: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:46:01.146: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:46:01.146: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:46:02.150: INFO: Wrong image for pod: daemon-set-58th2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 10 13:46:02.150: INFO: Wrong image for pod: daemon-set-5s5zw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 10 13:46:02.154: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:46:02.154: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:46:02.154: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:46:03.151: INFO: Wrong image for pod: daemon-set-58th2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 10 13:46:03.151: INFO: Wrong image for pod: daemon-set-5s5zw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 10 13:46:03.155: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:46:03.155: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:46:03.155: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:46:04.150: INFO: Wrong image for pod: daemon-set-58th2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 10 13:46:04.151: INFO: Wrong image for pod: daemon-set-5s5zw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 10 13:46:04.155: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:46:04.155: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:46:04.155: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:46:05.150: INFO: Wrong image for pod: daemon-set-58th2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 10 13:46:05.150: INFO: Wrong image for pod: daemon-set-5s5zw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 10 13:46:05.155: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:46:05.155: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:46:05.155: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:46:06.150: INFO: Wrong image for pod: daemon-set-58th2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 10 13:46:06.150: INFO: Wrong image for pod: daemon-set-5s5zw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 10 13:46:06.154: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:46:06.154: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:46:06.155: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:46:07.151: INFO: Wrong image for pod: daemon-set-58th2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 10 13:46:07.151: INFO: Wrong image for pod: daemon-set-5s5zw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 10 13:46:07.155: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:46:07.155: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:46:07.155: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:46:08.151: INFO: Wrong image for pod: daemon-set-58th2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 10 13:46:08.151: INFO: Wrong image for pod: daemon-set-5s5zw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 10 13:46:08.155: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:46:08.155: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:46:08.155: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:46:09.150: INFO: Wrong image for pod: daemon-set-58th2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 10 13:46:09.151: INFO: Wrong image for pod: daemon-set-5s5zw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 10 13:46:09.155: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:46:09.155: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:46:09.155: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:46:10.158: INFO: Wrong image for pod: daemon-set-58th2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 10 13:46:10.158: INFO: Wrong image for pod: daemon-set-5s5zw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 10 13:46:10.163: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:46:10.163: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:46:10.163: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:46:11.150: INFO: Wrong image for pod: daemon-set-58th2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 10 13:46:11.150: INFO: Wrong image for pod: daemon-set-5s5zw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 10 13:46:11.155: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:46:11.155: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:46:11.155: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:46:12.151: INFO: Wrong image for pod: daemon-set-58th2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 10 13:46:12.151: INFO: Wrong image for pod: daemon-set-5s5zw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 10 13:46:12.155: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:46:12.155: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:46:12.155: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:46:13.150: INFO: Wrong image for pod: daemon-set-58th2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 10 13:46:13.150: INFO: Wrong image for pod: daemon-set-5s5zw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 10 13:46:13.154: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:46:13.154: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:46:13.154: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:46:14.151: INFO: Wrong image for pod: daemon-set-58th2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 10 13:46:14.151: INFO: Wrong image for pod: daemon-set-5s5zw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 10 13:46:14.155: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:46:14.155: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:46:14.155: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:46:15.151: INFO: Wrong image for pod: daemon-set-58th2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 10 13:46:15.151: INFO: Wrong image for pod: daemon-set-5s5zw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 10 13:46:15.155: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:46:15.155: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:46:15.155: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:46:16.151: INFO: Wrong image for pod: daemon-set-58th2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 10 13:46:16.151: INFO: Wrong image for pod: daemon-set-5s5zw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 10 13:46:16.157: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:46:16.157: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:46:16.157: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:46:17.150: INFO: Wrong image for pod: daemon-set-58th2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 10 13:46:17.151: INFO: Wrong image for pod: daemon-set-5s5zw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 10 13:46:17.155: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:46:17.155: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:46:17.155: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:46:18.150: INFO: Wrong image for pod: daemon-set-58th2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 10 13:46:18.151: INFO: Wrong image for pod: daemon-set-5s5zw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 10 13:46:18.155: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:46:18.155: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:46:18.155: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:46:19.151: INFO: Wrong image for pod: daemon-set-58th2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 10 13:46:19.151: INFO: Wrong image for pod: daemon-set-5s5zw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 10 13:46:19.156: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:46:19.156: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:46:19.156: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:46:20.151: INFO: Wrong image for pod: daemon-set-58th2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 10 13:46:20.151: INFO: Wrong image for pod: daemon-set-5s5zw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 10 13:46:20.155: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:46:20.155: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:46:20.155: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:46:21.156: INFO: Wrong image for pod: daemon-set-58th2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 10 13:46:21.156: INFO: Wrong image for pod: daemon-set-5s5zw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 10 13:46:21.160: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:46:21.161: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:46:21.161: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:46:22.150: INFO: Wrong image for pod: daemon-set-58th2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 10 13:46:22.150: INFO: Wrong image for pod: daemon-set-5s5zw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 10 13:46:22.155: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:46:22.155: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:46:22.155: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:46:23.150: INFO: Wrong image for pod: daemon-set-58th2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 10 13:46:23.150: INFO: Wrong image for pod: daemon-set-5s5zw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 10 13:46:23.155: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:46:23.155: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:46:23.155: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:46:24.151: INFO: Wrong image for pod: daemon-set-58th2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 10 13:46:24.151: INFO: Wrong image for pod: daemon-set-5s5zw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 10 13:46:24.155: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:46:24.155: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:46:24.155: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:46:25.151: INFO: Wrong image for pod: daemon-set-58th2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 10 13:46:25.151: INFO: Wrong image for pod: daemon-set-5s5zw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 10 13:46:25.155: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:46:25.155: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:46:25.155: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:46:26.150: INFO: Wrong image for pod: daemon-set-58th2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 10 13:46:26.151: INFO: Wrong image for pod: daemon-set-5s5zw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 10 13:46:26.155: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:46:26.155: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:46:26.155: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:46:27.151: INFO: Wrong image for pod: daemon-set-58th2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 10 13:46:27.151: INFO: Wrong image for pod: daemon-set-5s5zw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 10 13:46:27.155: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:46:27.155: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:46:27.155: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:46:28.151: INFO: Wrong image for pod: daemon-set-58th2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 10 13:46:28.151: INFO: Wrong image for pod: daemon-set-5s5zw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 10 13:46:28.156: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:46:28.156: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:46:28.156: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:46:29.151: INFO: Wrong image for pod: daemon-set-58th2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 10 13:46:29.151: INFO: Wrong image for pod: daemon-set-5s5zw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 10 13:46:29.156: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:46:29.156: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:46:29.156: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:46:30.152: INFO: Wrong image for pod: daemon-set-58th2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 10 13:46:30.152: INFO: Wrong image for pod: daemon-set-5s5zw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 10 13:46:30.156: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:46:30.156: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:46:30.156: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:46:31.151: INFO: Wrong image for pod: daemon-set-58th2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 10 13:46:31.151: INFO: Wrong image for pod: daemon-set-5s5zw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 10 13:46:31.156: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:46:31.156: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:46:31.156: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:46:32.156: INFO: Wrong image for pod: daemon-set-58th2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 10 13:46:32.156: INFO: Wrong image for pod: daemon-set-5s5zw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 10 13:46:32.161: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:46:32.161: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:46:32.161: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:46:33.150: INFO: Wrong image for pod: daemon-set-58th2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 10 13:46:33.150: INFO: Wrong image for pod: daemon-set-5s5zw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 10 13:46:33.155: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:46:33.155: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:46:33.155: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:46:34.150: INFO: Wrong image for pod: daemon-set-58th2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 10 13:46:34.150: INFO: Wrong image for pod: daemon-set-5s5zw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 10 13:46:34.150: INFO: Pod daemon-set-5s5zw is not available
Dec 10 13:46:34.155: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:46:34.155: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:46:34.155: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:46:35.151: INFO: Wrong image for pod: daemon-set-58th2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 10 13:46:35.151: INFO: Wrong image for pod: daemon-set-5s5zw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 10 13:46:35.151: INFO: Pod daemon-set-5s5zw is not available
Dec 10 13:46:35.156: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:46:35.156: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:46:35.156: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:46:36.150: INFO: Wrong image for pod: daemon-set-58th2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 10 13:46:36.151: INFO: Wrong image for pod: daemon-set-5s5zw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 10 13:46:36.151: INFO: Pod daemon-set-5s5zw is not available
Dec 10 13:46:36.155: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:46:36.155: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:46:36.155: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:46:37.150: INFO: Wrong image for pod: daemon-set-58th2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 10 13:46:37.151: INFO: Wrong image for pod: daemon-set-5s5zw. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 10 13:46:37.151: INFO: Pod daemon-set-5s5zw is not available
Dec 10 13:46:37.155: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:46:37.155: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:46:37.155: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:46:38.150: INFO: Wrong image for pod: daemon-set-58th2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 10 13:46:38.151: INFO: Pod daemon-set-cbmnj is not available
Dec 10 13:46:38.155: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:46:38.155: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:46:38.155: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:46:39.151: INFO: Wrong image for pod: daemon-set-58th2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 10 13:46:39.151: INFO: Pod daemon-set-cbmnj is not available
Dec 10 13:46:39.155: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:46:39.155: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:46:39.155: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:46:40.151: INFO: Wrong image for pod: daemon-set-58th2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 10 13:46:40.151: INFO: Pod daemon-set-cbmnj is not available
Dec 10 13:46:40.155: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:46:40.155: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:46:40.155: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:46:41.151: INFO: Wrong image for pod: daemon-set-58th2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 10 13:46:41.151: INFO: Pod daemon-set-cbmnj is not available
Dec 10 13:46:41.155: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:46:41.155: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:46:41.155: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:46:42.151: INFO: Wrong image for pod: daemon-set-58th2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 10 13:46:42.151: INFO: Pod daemon-set-cbmnj is not available
Dec 10 13:46:42.155: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:46:42.155: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:46:42.155: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:46:43.156: INFO: Wrong image for pod: daemon-set-58th2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 10 13:46:43.162: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:46:43.162: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:46:43.162: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:46:44.151: INFO: Wrong image for pod: daemon-set-58th2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 10 13:46:44.156: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:46:44.156: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:46:44.156: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:46:45.151: INFO: Wrong image for pod: daemon-set-58th2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 10 13:46:45.155: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:46:45.155: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:46:45.155: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:46:46.150: INFO: Wrong image for pod: daemon-set-58th2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 10 13:46:46.155: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:46:46.155: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:46:46.155: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:46:47.150: INFO: Wrong image for pod: daemon-set-58th2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 10 13:46:47.155: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:46:47.155: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:46:47.155: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:46:48.150: INFO: Wrong image for pod: daemon-set-58th2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 10 13:46:48.154: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:46:48.154: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:46:48.154: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:46:49.150: INFO: Wrong image for pod: daemon-set-58th2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 10 13:46:49.155: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:46:49.155: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:46:49.155: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:46:50.151: INFO: Wrong image for pod: daemon-set-58th2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 10 13:46:50.156: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:46:50.156: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:46:50.156: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:46:51.150: INFO: Wrong image for pod: daemon-set-58th2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 10 13:46:51.155: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:46:51.155: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:46:51.155: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:46:52.151: INFO: Wrong image for pod: daemon-set-58th2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 10 13:46:52.155: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:46:52.155: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:46:52.155: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:46:53.151: INFO: Wrong image for pod: daemon-set-58th2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 10 13:46:53.157: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:46:53.157: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:46:53.157: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:46:54.156: INFO: Wrong image for pod: daemon-set-58th2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 10 13:46:54.161: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:46:54.161: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:46:54.161: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:46:55.150: INFO: Wrong image for pod: daemon-set-58th2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 10 13:46:55.155: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:46:55.155: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:46:55.155: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:46:56.151: INFO: Wrong image for pod: daemon-set-58th2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 10 13:46:56.155: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:46:56.155: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:46:56.155: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:46:57.151: INFO: Wrong image for pod: daemon-set-58th2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 10 13:46:57.155: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:46:57.155: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:46:57.155: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:46:58.150: INFO: Wrong image for pod: daemon-set-58th2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 10 13:46:58.155: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:46:58.155: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:46:58.155: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:46:59.151: INFO: Wrong image for pod: daemon-set-58th2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 10 13:46:59.155: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:46:59.155: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:46:59.155: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:47:00.150: INFO: Wrong image for pod: daemon-set-58th2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 10 13:47:00.155: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:47:00.155: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:47:00.155: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:47:01.151: INFO: Wrong image for pod: daemon-set-58th2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 10 13:47:01.155: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:47:01.155: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:47:01.155: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:47:02.151: INFO: Wrong image for pod: daemon-set-58th2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 10 13:47:02.155: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:47:02.155: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:47:02.155: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:47:03.150: INFO: Wrong image for pod: daemon-set-58th2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 10 13:47:03.154: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:47:03.155: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:47:03.155: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:47:04.151: INFO: Wrong image for pod: daemon-set-58th2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 10 13:47:04.155: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:47:04.155: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:47:04.156: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:47:05.156: INFO: Wrong image for pod: daemon-set-58th2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 10 13:47:05.160: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:47:05.160: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:47:05.160: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:47:06.151: INFO: Wrong image for pod: daemon-set-58th2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 10 13:47:06.155: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:47:06.155: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:47:06.155: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:47:07.151: INFO: Wrong image for pod: daemon-set-58th2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 10 13:47:07.155: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:47:07.155: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:47:07.156: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:47:08.150: INFO: Wrong image for pod: daemon-set-58th2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 10 13:47:08.154: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:47:08.154: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:47:08.154: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:47:09.151: INFO: Wrong image for pod: daemon-set-58th2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 10 13:47:09.156: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:47:09.156: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:47:09.156: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:47:10.150: INFO: Wrong image for pod: daemon-set-58th2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 10 13:47:10.155: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:47:10.155: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:47:10.155: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:47:11.150: INFO: Wrong image for pod: daemon-set-58th2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 10 13:47:11.155: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:47:11.155: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:47:11.155: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:47:12.150: INFO: Wrong image for pod: daemon-set-58th2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 10 13:47:12.155: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:47:12.155: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:47:12.155: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:47:13.150: INFO: Wrong image for pod: daemon-set-58th2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 10 13:47:13.155: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:47:13.155: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:47:13.155: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:47:14.151: INFO: Wrong image for pod: daemon-set-58th2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 10 13:47:14.151: INFO: Pod daemon-set-58th2 is not available
Dec 10 13:47:14.155: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:47:14.155: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:47:14.155: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:47:15.150: INFO: Pod daemon-set-h82wz is not available
Dec 10 13:47:15.155: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:47:15.155: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:47:15.155: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
STEP: Check that daemon pods are still running on every node of the cluster.
Dec 10 13:47:15.164: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:47:15.164: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:47:15.164: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:47:15.167: INFO: Number of nodes with available pods: 1
Dec 10 13:47:15.167: INFO: Node conformance-cluster1-k8s-node-2 is running more than one daemon pod
Dec 10 13:47:16.172: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:47:16.172: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:47:16.172: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:47:16.176: INFO: Number of nodes with available pods: 1
Dec 10 13:47:16.176: INFO: Node conformance-cluster1-k8s-node-2 is running more than one daemon pod
Dec 10 13:47:17.172: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:47:17.172: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:47:17.172: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:47:17.176: INFO: Number of nodes with available pods: 1
Dec 10 13:47:17.176: INFO: Node conformance-cluster1-k8s-node-2 is running more than one daemon pod
Dec 10 13:47:18.172: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:47:18.172: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:47:18.172: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:47:18.176: INFO: Number of nodes with available pods: 1
Dec 10 13:47:18.176: INFO: Node conformance-cluster1-k8s-node-2 is running more than one daemon pod
Dec 10 13:47:19.172: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:47:19.172: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:47:19.172: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:47:19.177: INFO: Number of nodes with available pods: 2
Dec 10 13:47:19.177: INFO: Number of running nodes: 2, number of available pods: 2
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:64
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting {extensions DaemonSet} daemon-set in namespace e2e-tests-daemonsets-k5wxq, will wait for the garbage collector to delete the pods
Dec 10 13:47:19.262: INFO: Deleting {extensions DaemonSet} daemon-set took: 10.901973ms
Dec 10 13:47:19.362: INFO: Terminating {extensions DaemonSet} daemon-set pods took: 100.217741ms
Dec 10 13:47:28.275: INFO: Number of nodes with available pods: 0
Dec 10 13:47:28.275: INFO: Number of running nodes: 0, number of available pods: 0
Dec 10 13:47:28.280: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-k5wxq/daemonsets","resourceVersion":"3986"},"items":null}

Dec 10 13:47:28.284: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-k5wxq/pods","resourceVersion":"3986"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 10 13:47:28.294: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-k5wxq" for this suite.
Dec 10 13:47:34.321: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 13:47:34.384: INFO: namespace: e2e-tests-daemonsets-k5wxq, resource: bindings, ignored listing per whitelist
Dec 10 13:47:34.424: INFO: namespace e2e-tests-daemonsets-k5wxq deletion completed in 6.125969115s

• [SLOW TEST:98.414 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 10 13:47:34.424: INFO: >>> kubeConfig: /tmp/kubeconfig-578738756
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name s-test-opt-del-25cd2786-fc82-11e8-a36b-7e9ed3de7210
STEP: Creating secret with name s-test-opt-upd-25cd27e9-fc82-11e8-a36b-7e9ed3de7210
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-25cd2786-fc82-11e8-a36b-7e9ed3de7210
STEP: Updating secret s-test-opt-upd-25cd27e9-fc82-11e8-a36b-7e9ed3de7210
STEP: Creating secret with name s-test-opt-create-25cd2807-fc82-11e8-a36b-7e9ed3de7210
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 10 13:47:38.623: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-zgt87" for this suite.
Dec 10 13:48:00.647: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 13:48:00.677: INFO: namespace: e2e-tests-projected-zgt87, resource: bindings, ignored listing per whitelist
Dec 10 13:48:00.752: INFO: namespace e2e-tests-projected-zgt87 deletion completed in 22.124507486s

• [SLOW TEST:26.328 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 10 13:48:00.753: INFO: >>> kubeConfig: /tmp/kubeconfig-578738756
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-http in namespace e2e-tests-container-probe-sf49r
Dec 10 13:48:02.835: INFO: Started pod liveness-http in namespace e2e-tests-container-probe-sf49r
STEP: checking the pod's current state and verifying that restartCount is present
Dec 10 13:48:02.839: INFO: Initial restart count of pod liveness-http is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 10 13:52:03.523: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-sf49r" for this suite.
Dec 10 13:52:09.542: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 13:52:09.626: INFO: namespace: e2e-tests-container-probe-sf49r, resource: bindings, ignored listing per whitelist
Dec 10 13:52:09.653: INFO: namespace e2e-tests-container-probe-sf49r deletion completed in 6.125343716s

• [SLOW TEST:248.900 seconds]
[k8s.io] Probing container
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-api-machinery] Watchers 
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 10 13:52:09.654: INFO: >>> kubeConfig: /tmp/kubeconfig-578738756
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a watch on configmaps with label A
STEP: creating a watch on configmaps with label B
STEP: creating a watch on configmaps with label A or B
STEP: creating a configmap with label A and ensuring the correct watchers observe the notification
Dec 10 13:52:09.723: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-m2jrc,SelfLink:/api/v1/namespaces/e2e-tests-watch-m2jrc/configmaps/e2e-watch-test-configmap-a,UID:c9d8b935-fc82-11e8-8690-fa163e74bd5a,ResourceVersion:4618,Generation:0,CreationTimestamp:2018-12-10 13:52:09 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Dec 10 13:52:09.723: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-m2jrc,SelfLink:/api/v1/namespaces/e2e-tests-watch-m2jrc/configmaps/e2e-watch-test-configmap-a,UID:c9d8b935-fc82-11e8-8690-fa163e74bd5a,ResourceVersion:4618,Generation:0,CreationTimestamp:2018-12-10 13:52:09 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: modifying configmap A and ensuring the correct watchers observe the notification
Dec 10 13:52:19.737: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-m2jrc,SelfLink:/api/v1/namespaces/e2e-tests-watch-m2jrc/configmaps/e2e-watch-test-configmap-a,UID:c9d8b935-fc82-11e8-8690-fa163e74bd5a,ResourceVersion:4638,Generation:0,CreationTimestamp:2018-12-10 13:52:09 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Dec 10 13:52:19.737: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-m2jrc,SelfLink:/api/v1/namespaces/e2e-tests-watch-m2jrc/configmaps/e2e-watch-test-configmap-a,UID:c9d8b935-fc82-11e8-8690-fa163e74bd5a,ResourceVersion:4638,Generation:0,CreationTimestamp:2018-12-10 13:52:09 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying configmap A again and ensuring the correct watchers observe the notification
Dec 10 13:52:29.750: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-m2jrc,SelfLink:/api/v1/namespaces/e2e-tests-watch-m2jrc/configmaps/e2e-watch-test-configmap-a,UID:c9d8b935-fc82-11e8-8690-fa163e74bd5a,ResourceVersion:4658,Generation:0,CreationTimestamp:2018-12-10 13:52:09 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Dec 10 13:52:29.751: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-m2jrc,SelfLink:/api/v1/namespaces/e2e-tests-watch-m2jrc/configmaps/e2e-watch-test-configmap-a,UID:c9d8b935-fc82-11e8-8690-fa163e74bd5a,ResourceVersion:4658,Generation:0,CreationTimestamp:2018-12-10 13:52:09 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: deleting configmap A and ensuring the correct watchers observe the notification
Dec 10 13:52:39.766: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-m2jrc,SelfLink:/api/v1/namespaces/e2e-tests-watch-m2jrc/configmaps/e2e-watch-test-configmap-a,UID:c9d8b935-fc82-11e8-8690-fa163e74bd5a,ResourceVersion:4677,Generation:0,CreationTimestamp:2018-12-10 13:52:09 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Dec 10 13:52:39.766: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-m2jrc,SelfLink:/api/v1/namespaces/e2e-tests-watch-m2jrc/configmaps/e2e-watch-test-configmap-a,UID:c9d8b935-fc82-11e8-8690-fa163e74bd5a,ResourceVersion:4677,Generation:0,CreationTimestamp:2018-12-10 13:52:09 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: creating a configmap with label B and ensuring the correct watchers observe the notification
Dec 10 13:52:49.779: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-m2jrc,SelfLink:/api/v1/namespaces/e2e-tests-watch-m2jrc/configmaps/e2e-watch-test-configmap-b,UID:e1b8ca2c-fc82-11e8-8690-fa163e74bd5a,ResourceVersion:4696,Generation:0,CreationTimestamp:2018-12-10 13:52:49 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Dec 10 13:52:49.779: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-m2jrc,SelfLink:/api/v1/namespaces/e2e-tests-watch-m2jrc/configmaps/e2e-watch-test-configmap-b,UID:e1b8ca2c-fc82-11e8-8690-fa163e74bd5a,ResourceVersion:4696,Generation:0,CreationTimestamp:2018-12-10 13:52:49 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: deleting configmap B and ensuring the correct watchers observe the notification
Dec 10 13:52:59.794: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-m2jrc,SelfLink:/api/v1/namespaces/e2e-tests-watch-m2jrc/configmaps/e2e-watch-test-configmap-b,UID:e1b8ca2c-fc82-11e8-8690-fa163e74bd5a,ResourceVersion:4715,Generation:0,CreationTimestamp:2018-12-10 13:52:49 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Dec 10 13:52:59.794: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-m2jrc,SelfLink:/api/v1/namespaces/e2e-tests-watch-m2jrc/configmaps/e2e-watch-test-configmap-b,UID:e1b8ca2c-fc82-11e8-8690-fa163e74bd5a,ResourceVersion:4715,Generation:0,CreationTimestamp:2018-12-10 13:52:49 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 10 13:53:09.794: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-m2jrc" for this suite.
Dec 10 13:53:15.820: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 13:53:15.849: INFO: namespace: e2e-tests-watch-m2jrc, resource: bindings, ignored listing per whitelist
Dec 10 13:53:15.924: INFO: namespace e2e-tests-watch-m2jrc deletion completed in 6.120476801s

• [SLOW TEST:66.271 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 10 13:53:15.925: INFO: >>> kubeConfig: /tmp/kubeconfig-578738756
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0777 on tmpfs
Dec 10 13:53:16.000: INFO: Waiting up to 5m0s for pod "pod-f158f9c2-fc82-11e8-a36b-7e9ed3de7210" in namespace "e2e-tests-emptydir-bm4qm" to be "success or failure"
Dec 10 13:53:16.006: INFO: Pod "pod-f158f9c2-fc82-11e8-a36b-7e9ed3de7210": Phase="Pending", Reason="", readiness=false. Elapsed: 6.05863ms
Dec 10 13:53:18.011: INFO: Pod "pod-f158f9c2-fc82-11e8-a36b-7e9ed3de7210": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.011140015s
STEP: Saw pod success
Dec 10 13:53:18.011: INFO: Pod "pod-f158f9c2-fc82-11e8-a36b-7e9ed3de7210" satisfied condition "success or failure"
Dec 10 13:53:18.015: INFO: Trying to get logs from node conformance-cluster1-k8s-node-2 pod pod-f158f9c2-fc82-11e8-a36b-7e9ed3de7210 container test-container: <nil>
STEP: delete the pod
Dec 10 13:53:18.042: INFO: Waiting for pod pod-f158f9c2-fc82-11e8-a36b-7e9ed3de7210 to disappear
Dec 10 13:53:18.045: INFO: Pod pod-f158f9c2-fc82-11e8-a36b-7e9ed3de7210 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 10 13:53:18.045: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-bm4qm" for this suite.
Dec 10 13:53:24.064: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 13:53:24.160: INFO: namespace: e2e-tests-emptydir-bm4qm, resource: bindings, ignored listing per whitelist
Dec 10 13:53:24.169: INFO: namespace e2e-tests-emptydir-bm4qm deletion completed in 6.119188342s

• [SLOW TEST:8.243 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 10 13:53:24.169: INFO: >>> kubeConfig: /tmp/kubeconfig-578738756
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:98
[It] should run and stop simple daemon [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Dec 10 13:53:24.251: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:53:24.251: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:53:24.251: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:53:24.256: INFO: Number of nodes with available pods: 0
Dec 10 13:53:24.256: INFO: Node conformance-cluster1-k8s-node-1 is running more than one daemon pod
Dec 10 13:53:25.262: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:53:25.262: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:53:25.262: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:53:25.267: INFO: Number of nodes with available pods: 0
Dec 10 13:53:25.267: INFO: Node conformance-cluster1-k8s-node-1 is running more than one daemon pod
Dec 10 13:53:26.262: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:53:26.262: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:53:26.262: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:53:26.266: INFO: Number of nodes with available pods: 2
Dec 10 13:53:26.266: INFO: Number of running nodes: 2, number of available pods: 2
STEP: Stop a daemon pod, check that the daemon pod is revived.
Dec 10 13:53:26.289: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:53:26.289: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:53:26.290: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:53:26.292: INFO: Number of nodes with available pods: 1
Dec 10 13:53:26.293: INFO: Node conformance-cluster1-k8s-node-2 is running more than one daemon pod
Dec 10 13:53:27.299: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:53:27.299: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:53:27.299: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:53:27.303: INFO: Number of nodes with available pods: 1
Dec 10 13:53:27.303: INFO: Node conformance-cluster1-k8s-node-2 is running more than one daemon pod
Dec 10 13:53:28.298: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:53:28.298: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:53:28.298: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:53:28.302: INFO: Number of nodes with available pods: 1
Dec 10 13:53:28.302: INFO: Node conformance-cluster1-k8s-node-2 is running more than one daemon pod
Dec 10 13:53:29.299: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:53:29.299: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:53:29.299: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:53:29.302: INFO: Number of nodes with available pods: 1
Dec 10 13:53:29.302: INFO: Node conformance-cluster1-k8s-node-2 is running more than one daemon pod
Dec 10 13:53:30.303: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:53:30.303: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:53:30.303: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:53:30.307: INFO: Number of nodes with available pods: 1
Dec 10 13:53:30.307: INFO: Node conformance-cluster1-k8s-node-2 is running more than one daemon pod
Dec 10 13:53:31.298: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:53:31.298: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:53:31.299: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:53:31.302: INFO: Number of nodes with available pods: 1
Dec 10 13:53:31.303: INFO: Node conformance-cluster1-k8s-node-2 is running more than one daemon pod
Dec 10 13:53:32.299: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:53:32.299: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:53:32.299: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:53:32.303: INFO: Number of nodes with available pods: 1
Dec 10 13:53:32.303: INFO: Node conformance-cluster1-k8s-node-2 is running more than one daemon pod
Dec 10 13:53:33.299: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:53:33.299: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:53:33.299: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:53:33.302: INFO: Number of nodes with available pods: 1
Dec 10 13:53:33.302: INFO: Node conformance-cluster1-k8s-node-2 is running more than one daemon pod
Dec 10 13:53:34.297: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:53:34.297: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:53:34.297: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:53:34.301: INFO: Number of nodes with available pods: 1
Dec 10 13:53:34.301: INFO: Node conformance-cluster1-k8s-node-2 is running more than one daemon pod
Dec 10 13:53:35.298: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:53:35.298: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:53:35.298: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:53:35.301: INFO: Number of nodes with available pods: 1
Dec 10 13:53:35.301: INFO: Node conformance-cluster1-k8s-node-2 is running more than one daemon pod
Dec 10 13:53:36.298: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:53:36.298: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:53:36.298: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:53:36.302: INFO: Number of nodes with available pods: 1
Dec 10 13:53:36.302: INFO: Node conformance-cluster1-k8s-node-2 is running more than one daemon pod
Dec 10 13:53:37.298: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:53:37.298: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:53:37.298: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:53:37.302: INFO: Number of nodes with available pods: 1
Dec 10 13:53:37.302: INFO: Node conformance-cluster1-k8s-node-2 is running more than one daemon pod
Dec 10 13:53:38.298: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:53:38.298: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:53:38.298: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:53:38.301: INFO: Number of nodes with available pods: 1
Dec 10 13:53:38.301: INFO: Node conformance-cluster1-k8s-node-2 is running more than one daemon pod
Dec 10 13:53:39.297: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:53:39.297: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:53:39.298: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:53:39.301: INFO: Number of nodes with available pods: 1
Dec 10 13:53:39.301: INFO: Node conformance-cluster1-k8s-node-2 is running more than one daemon pod
Dec 10 13:53:40.298: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:53:40.298: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:53:40.298: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:53:40.301: INFO: Number of nodes with available pods: 1
Dec 10 13:53:40.301: INFO: Node conformance-cluster1-k8s-node-2 is running more than one daemon pod
Dec 10 13:53:41.303: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:53:41.303: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:53:41.303: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:53:41.306: INFO: Number of nodes with available pods: 1
Dec 10 13:53:41.306: INFO: Node conformance-cluster1-k8s-node-2 is running more than one daemon pod
Dec 10 13:53:42.298: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:53:42.298: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:53:42.298: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:53:42.301: INFO: Number of nodes with available pods: 1
Dec 10 13:53:42.301: INFO: Node conformance-cluster1-k8s-node-2 is running more than one daemon pod
Dec 10 13:53:43.297: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:53:43.297: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:53:43.297: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:53:43.301: INFO: Number of nodes with available pods: 1
Dec 10 13:53:43.301: INFO: Node conformance-cluster1-k8s-node-2 is running more than one daemon pod
Dec 10 13:53:44.298: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:53:44.298: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:53:44.298: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:53:44.302: INFO: Number of nodes with available pods: 1
Dec 10 13:53:44.302: INFO: Node conformance-cluster1-k8s-node-2 is running more than one daemon pod
Dec 10 13:53:45.298: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:53:45.298: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:53:45.298: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:53:45.302: INFO: Number of nodes with available pods: 1
Dec 10 13:53:45.302: INFO: Node conformance-cluster1-k8s-node-2 is running more than one daemon pod
Dec 10 13:53:46.298: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:53:46.298: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:53:46.298: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:53:46.302: INFO: Number of nodes with available pods: 1
Dec 10 13:53:46.302: INFO: Node conformance-cluster1-k8s-node-2 is running more than one daemon pod
Dec 10 13:53:47.298: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:53:47.298: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:53:47.298: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:53:47.302: INFO: Number of nodes with available pods: 1
Dec 10 13:53:47.302: INFO: Node conformance-cluster1-k8s-node-2 is running more than one daemon pod
Dec 10 13:53:48.297: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:53:48.298: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:53:48.298: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:53:48.302: INFO: Number of nodes with available pods: 1
Dec 10 13:53:48.302: INFO: Node conformance-cluster1-k8s-node-2 is running more than one daemon pod
Dec 10 13:53:49.298: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:53:49.298: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:53:49.298: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:53:49.302: INFO: Number of nodes with available pods: 1
Dec 10 13:53:49.302: INFO: Node conformance-cluster1-k8s-node-2 is running more than one daemon pod
Dec 10 13:53:50.297: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:53:50.297: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:53:50.298: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:53:50.301: INFO: Number of nodes with available pods: 1
Dec 10 13:53:50.301: INFO: Node conformance-cluster1-k8s-node-2 is running more than one daemon pod
Dec 10 13:53:51.298: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:53:51.298: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:53:51.298: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:53:51.302: INFO: Number of nodes with available pods: 1
Dec 10 13:53:51.302: INFO: Node conformance-cluster1-k8s-node-2 is running more than one daemon pod
Dec 10 13:53:52.303: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:53:52.303: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:53:52.303: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:53:52.307: INFO: Number of nodes with available pods: 1
Dec 10 13:53:52.307: INFO: Node conformance-cluster1-k8s-node-2 is running more than one daemon pod
Dec 10 13:53:53.298: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:53:53.298: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:53:53.298: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:53:53.302: INFO: Number of nodes with available pods: 1
Dec 10 13:53:53.302: INFO: Node conformance-cluster1-k8s-node-2 is running more than one daemon pod
Dec 10 13:53:54.298: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:53:54.298: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:53:54.298: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:53:54.302: INFO: Number of nodes with available pods: 1
Dec 10 13:53:54.302: INFO: Node conformance-cluster1-k8s-node-2 is running more than one daemon pod
Dec 10 13:53:55.298: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:53:55.298: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:53:55.298: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:53:55.302: INFO: Number of nodes with available pods: 1
Dec 10 13:53:55.302: INFO: Node conformance-cluster1-k8s-node-2 is running more than one daemon pod
Dec 10 13:53:56.298: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:53:56.298: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:53:56.298: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:53:56.302: INFO: Number of nodes with available pods: 1
Dec 10 13:53:56.302: INFO: Node conformance-cluster1-k8s-node-2 is running more than one daemon pod
Dec 10 13:53:57.298: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:53:57.298: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:53:57.298: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:53:57.301: INFO: Number of nodes with available pods: 1
Dec 10 13:53:57.301: INFO: Node conformance-cluster1-k8s-node-2 is running more than one daemon pod
Dec 10 13:53:58.298: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:53:58.298: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:53:58.298: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:53:58.302: INFO: Number of nodes with available pods: 1
Dec 10 13:53:58.302: INFO: Node conformance-cluster1-k8s-node-2 is running more than one daemon pod
Dec 10 13:53:59.297: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:53:59.297: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:53:59.297: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:53:59.301: INFO: Number of nodes with available pods: 1
Dec 10 13:53:59.301: INFO: Node conformance-cluster1-k8s-node-2 is running more than one daemon pod
Dec 10 13:54:00.301: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:54:00.301: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:54:00.301: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:54:00.305: INFO: Number of nodes with available pods: 1
Dec 10 13:54:00.305: INFO: Node conformance-cluster1-k8s-node-2 is running more than one daemon pod
Dec 10 13:54:01.298: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:54:01.298: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:54:01.298: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:54:01.302: INFO: Number of nodes with available pods: 1
Dec 10 13:54:01.302: INFO: Node conformance-cluster1-k8s-node-2 is running more than one daemon pod
Dec 10 13:54:02.297: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:54:02.297: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:54:02.297: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:54:02.300: INFO: Number of nodes with available pods: 1
Dec 10 13:54:02.300: INFO: Node conformance-cluster1-k8s-node-2 is running more than one daemon pod
Dec 10 13:54:03.302: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:54:03.302: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:54:03.302: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 13:54:03.306: INFO: Number of nodes with available pods: 2
Dec 10 13:54:03.306: INFO: Number of running nodes: 2, number of available pods: 2
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:64
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting {extensions DaemonSet} daemon-set in namespace e2e-tests-daemonsets-gmfmw, will wait for the garbage collector to delete the pods
Dec 10 13:54:03.372: INFO: Deleting {extensions DaemonSet} daemon-set took: 10.235929ms
Dec 10 13:54:03.473: INFO: Terminating {extensions DaemonSet} daemon-set pods took: 100.179842ms
Dec 10 13:54:38.286: INFO: Number of nodes with available pods: 0
Dec 10 13:54:38.286: INFO: Number of running nodes: 0, number of available pods: 0
Dec 10 13:54:38.290: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-gmfmw/daemonsets","resourceVersion":"5003"},"items":null}

Dec 10 13:54:38.294: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-gmfmw/pods","resourceVersion":"5003"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 10 13:54:38.304: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-gmfmw" for this suite.
Dec 10 13:54:44.322: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 13:54:44.347: INFO: namespace: e2e-tests-daemonsets-gmfmw, resource: bindings, ignored listing per whitelist
Dec 10 13:54:44.434: INFO: namespace e2e-tests-daemonsets-gmfmw deletion completed in 6.126621981s

• [SLOW TEST:80.265 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 10 13:54:44.435: INFO: >>> kubeConfig: /tmp/kubeconfig-578738756
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test substitution in container's args
Dec 10 13:54:44.511: INFO: Waiting up to 5m0s for pod "var-expansion-261abd3c-fc83-11e8-a36b-7e9ed3de7210" in namespace "e2e-tests-var-expansion-q6kxk" to be "success or failure"
Dec 10 13:54:44.519: INFO: Pod "var-expansion-261abd3c-fc83-11e8-a36b-7e9ed3de7210": Phase="Pending", Reason="", readiness=false. Elapsed: 8.006348ms
Dec 10 13:54:46.524: INFO: Pod "var-expansion-261abd3c-fc83-11e8-a36b-7e9ed3de7210": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.012737937s
STEP: Saw pod success
Dec 10 13:54:46.524: INFO: Pod "var-expansion-261abd3c-fc83-11e8-a36b-7e9ed3de7210" satisfied condition "success or failure"
Dec 10 13:54:46.528: INFO: Trying to get logs from node conformance-cluster1-k8s-node-2 pod var-expansion-261abd3c-fc83-11e8-a36b-7e9ed3de7210 container dapi-container: <nil>
STEP: delete the pod
Dec 10 13:54:46.563: INFO: Waiting for pod var-expansion-261abd3c-fc83-11e8-a36b-7e9ed3de7210 to disappear
Dec 10 13:54:46.566: INFO: Pod var-expansion-261abd3c-fc83-11e8-a36b-7e9ed3de7210 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 10 13:54:46.566: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-var-expansion-q6kxk" for this suite.
Dec 10 13:54:52.586: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 13:54:52.676: INFO: namespace: e2e-tests-var-expansion-q6kxk, resource: bindings, ignored listing per whitelist
Dec 10 13:54:52.694: INFO: namespace e2e-tests-var-expansion-q6kxk deletion completed in 6.123426072s

• [SLOW TEST:8.259 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 10 13:54:52.694: INFO: >>> kubeConfig: /tmp/kubeconfig-578738756
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
Dec 10 13:54:52.748: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 10 13:54:55.484: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-init-container-4c5kj" for this suite.
Dec 10 13:55:01.503: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 13:55:01.553: INFO: namespace: e2e-tests-init-container-4c5kj, resource: bindings, ignored listing per whitelist
Dec 10 13:55:01.610: INFO: namespace e2e-tests-init-container-4c5kj deletion completed in 6.121997023s

• [SLOW TEST:8.916 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-apps] Deployment 
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 10 13:55:01.612: INFO: >>> kubeConfig: /tmp/kubeconfig-578738756
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Dec 10 13:55:01.675: INFO: Creating deployment "nginx-deployment"
Dec 10 13:55:01.683: INFO: Waiting for observed generation 1
Dec 10 13:55:03.694: INFO: Waiting for all required pods to come up
Dec 10 13:55:03.700: INFO: Pod name nginx: Found 10 pods out of 10
STEP: ensuring each pod is running
Dec 10 13:55:05.722: INFO: Waiting for deployment "nginx-deployment" to complete
Dec 10 13:55:05.728: INFO: Updating deployment "nginx-deployment" with a non-existent image
Dec 10 13:55:05.739: INFO: Updating deployment nginx-deployment
Dec 10 13:55:05.739: INFO: Waiting for observed generation 2
Dec 10 13:55:07.747: INFO: Waiting for the first rollout's replicaset to have .status.availableReplicas = 8
Dec 10 13:55:07.754: INFO: Waiting for the first rollout's replicaset to have .spec.replicas = 8
Dec 10 13:55:07.764: INFO: Waiting for the first rollout's replicaset of deployment "nginx-deployment" to have desired number of replicas
Dec 10 13:55:07.775: INFO: Verifying that the second rollout's replicaset has .status.availableReplicas = 0
Dec 10 13:55:07.775: INFO: Waiting for the second rollout's replicaset to have .spec.replicas = 5
Dec 10 13:55:07.779: INFO: Waiting for the second rollout's replicaset of deployment "nginx-deployment" to have desired number of replicas
Dec 10 13:55:07.786: INFO: Verifying that deployment "nginx-deployment" has minimum required number of available replicas
Dec 10 13:55:07.786: INFO: Scaling up the deployment "nginx-deployment" from 10 to 30
Dec 10 13:55:07.797: INFO: Updating deployment nginx-deployment
Dec 10 13:55:07.797: INFO: Waiting for the replicasets of deployment "nginx-deployment" to have desired number of replicas
Dec 10 13:55:07.809: INFO: Verifying that first rollout's replicaset has .spec.replicas = 20
Dec 10 13:55:09.842: INFO: Verifying that second rollout's replicaset has .spec.replicas = 13
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Dec 10 13:55:09.850: INFO: Deployment "nginx-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment,GenerateName:,Namespace:e2e-tests-deployment-4vvtv,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-4vvtv/deployments/nginx-deployment,UID:3057999b-fc83-11e8-8690-fa163e74bd5a,ResourceVersion:5452,Generation:3,CreationTimestamp:2018-12-10 13:55:01 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*30,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:2,MaxSurge:3,},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:3,Replicas:33,UpdatedReplicas:13,AvailableReplicas:8,UnavailableReplicas:25,Conditions:[{Available False 2018-12-10 13:55:07 +0000 UTC 2018-12-10 13:55:07 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.} {Progressing True 2018-12-10 13:55:07 +0000 UTC 2018-12-10 13:55:01 +0000 UTC ReplicaSetUpdated ReplicaSet "nginx-deployment-7dc8f79789" is progressing.}],ReadyReplicas:8,CollisionCount:nil,},}

Dec 10 13:55:09.854: INFO: New ReplicaSet "nginx-deployment-7dc8f79789" of Deployment "nginx-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789,GenerateName:,Namespace:e2e-tests-deployment-4vvtv,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-4vvtv/replicasets/nginx-deployment-7dc8f79789,UID:32c30cac-fc83-11e8-808b-fa163e6bf550,ResourceVersion:5450,Generation:3,CreationTimestamp:2018-12-10 13:55:05 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 30,deployment.kubernetes.io/max-replicas: 33,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment nginx-deployment 3057999b-fc83-11e8-8690-fa163e74bd5a 0xc421da3a87 0xc421da3a88}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*13,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:13,FullyLabeledReplicas:13,ObservedGeneration:3,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Dec 10 13:55:09.854: INFO: All old ReplicaSets of Deployment "nginx-deployment":
Dec 10 13:55:09.854: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b,GenerateName:,Namespace:e2e-tests-deployment-4vvtv,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-4vvtv/replicasets/nginx-deployment-7f9675fb8b,UID:30595545-fc83-11e8-808b-fa163e6bf550,ResourceVersion:5439,Generation:3,CreationTimestamp:2018-12-10 13:55:01 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 30,deployment.kubernetes.io/max-replicas: 33,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment nginx-deployment 3057999b-fc83-11e8-8690-fa163e74bd5a 0xc421da3b47 0xc421da3b48}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*20,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:20,FullyLabeledReplicas:20,ObservedGeneration:3,ReadyReplicas:8,AvailableReplicas:8,Conditions:[],},}
Dec 10 13:55:09.860: INFO: Pod "nginx-deployment-7dc8f79789-2rpdd" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-2rpdd,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-4vvtv,SelfLink:/api/v1/namespaces/e2e-tests-deployment-4vvtv/pods/nginx-deployment-7dc8f79789-2rpdd,UID:3405798f-fc83-11e8-808b-fa163e6bf550,ResourceVersion:5500,Generation:0,CreationTimestamp:2018-12-10 13:55:07 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 32c30cac-fc83-11e8-808b-fa163e6bf550 0xc422ab83e0 0xc422ab83e1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-9h59q {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-9h59q,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-9h59q true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:conformance-cluster1-k8s-node-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc422ab8450} {node.kubernetes.io/unreachable Exists  NoExecute 0xc422ab8470}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-10 13:55:07 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-10 13:55:07 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-10 13:55:07 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-10 13:55:07 +0000 UTC  }],Message:,Reason:,HostIP:10.0.0.6,PodIP:,StartTime:2018-12-10 13:55:07 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec 10 13:55:09.860: INFO: Pod "nginx-deployment-7dc8f79789-9hfgx" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-9hfgx,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-4vvtv,SelfLink:/api/v1/namespaces/e2e-tests-deployment-4vvtv/pods/nginx-deployment-7dc8f79789-9hfgx,UID:32cdc28b-fc83-11e8-808b-fa163e6bf550,ResourceVersion:5349,Generation:0,CreationTimestamp:2018-12-10 13:55:05 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 32c30cac-fc83-11e8-808b-fa163e6bf550 0xc422ab8530 0xc422ab8531}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-9h59q {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-9h59q,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-9h59q true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:conformance-cluster1-k8s-node-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc422ab85a0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc422ab85c0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-10 13:55:05 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-10 13:55:05 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-10 13:55:05 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-10 13:55:05 +0000 UTC  }],Message:,Reason:,HostIP:10.0.0.6,PodIP:,StartTime:2018-12-10 13:55:05 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec 10 13:55:09.860: INFO: Pod "nginx-deployment-7dc8f79789-9m9qv" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-9m9qv,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-4vvtv,SelfLink:/api/v1/namespaces/e2e-tests-deployment-4vvtv/pods/nginx-deployment-7dc8f79789-9m9qv,UID:3405869b-fc83-11e8-808b-fa163e6bf550,ResourceVersion:5433,Generation:0,CreationTimestamp:2018-12-10 13:55:07 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 32c30cac-fc83-11e8-808b-fa163e6bf550 0xc422ab8680 0xc422ab8681}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-9h59q {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-9h59q,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-9h59q true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:conformance-cluster1-k8s-node-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc422ab86f0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc422ab8710}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-10 13:55:07 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec 10 13:55:09.860: INFO: Pod "nginx-deployment-7dc8f79789-dqtjz" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-dqtjz,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-4vvtv,SelfLink:/api/v1/namespaces/e2e-tests-deployment-4vvtv/pods/nginx-deployment-7dc8f79789-dqtjz,UID:32cf30b6-fc83-11e8-808b-fa163e6bf550,ResourceVersion:5350,Generation:0,CreationTimestamp:2018-12-10 13:55:05 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 32c30cac-fc83-11e8-808b-fa163e6bf550 0xc422ab8780 0xc422ab8781}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-9h59q {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-9h59q,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-9h59q true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:conformance-cluster1-k8s-node-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc422ab87f0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc422ab8810}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-10 13:55:05 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-10 13:55:05 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-10 13:55:05 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-10 13:55:05 +0000 UTC  }],Message:,Reason:,HostIP:10.0.0.6,PodIP:,StartTime:2018-12-10 13:55:05 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec 10 13:55:09.860: INFO: Pod "nginx-deployment-7dc8f79789-fl5n4" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-fl5n4,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-4vvtv,SelfLink:/api/v1/namespaces/e2e-tests-deployment-4vvtv/pods/nginx-deployment-7dc8f79789-fl5n4,UID:32c53faa-fc83-11e8-808b-fa163e6bf550,ResourceVersion:5347,Generation:0,CreationTimestamp:2018-12-10 13:55:05 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 32c30cac-fc83-11e8-808b-fa163e6bf550 0xc422ab88d0 0xc422ab88d1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-9h59q {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-9h59q,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-9h59q true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:conformance-cluster1-k8s-node-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc422ab8940} {node.kubernetes.io/unreachable Exists  NoExecute 0xc422ab8960}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-10 13:55:05 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-10 13:55:05 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-10 13:55:05 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-10 13:55:05 +0000 UTC  }],Message:,Reason:,HostIP:10.0.0.10,PodIP:,StartTime:2018-12-10 13:55:05 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec 10 13:55:09.861: INFO: Pod "nginx-deployment-7dc8f79789-g6kcs" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-g6kcs,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-4vvtv,SelfLink:/api/v1/namespaces/e2e-tests-deployment-4vvtv/pods/nginx-deployment-7dc8f79789-g6kcs,UID:32c5281f-fc83-11e8-808b-fa163e6bf550,ResourceVersion:5348,Generation:0,CreationTimestamp:2018-12-10 13:55:05 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 32c30cac-fc83-11e8-808b-fa163e6bf550 0xc422ab8a20 0xc422ab8a21}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-9h59q {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-9h59q,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-9h59q true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:conformance-cluster1-k8s-node-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc422ab8a90} {node.kubernetes.io/unreachable Exists  NoExecute 0xc422ab8ab0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-10 13:55:05 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-10 13:55:05 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-10 13:55:05 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-10 13:55:05 +0000 UTC  }],Message:,Reason:,HostIP:10.0.0.6,PodIP:,StartTime:2018-12-10 13:55:05 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec 10 13:55:09.861: INFO: Pod "nginx-deployment-7dc8f79789-gftx9" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-gftx9,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-4vvtv,SelfLink:/api/v1/namespaces/e2e-tests-deployment-4vvtv/pods/nginx-deployment-7dc8f79789-gftx9,UID:3405852e-fc83-11e8-808b-fa163e6bf550,ResourceVersion:5494,Generation:0,CreationTimestamp:2018-12-10 13:55:07 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 32c30cac-fc83-11e8-808b-fa163e6bf550 0xc422ab8b70 0xc422ab8b71}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-9h59q {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-9h59q,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-9h59q true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:conformance-cluster1-k8s-node-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc422ab8be0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc422ab8c00}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-10 13:55:07 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-10 13:55:07 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-10 13:55:07 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-10 13:55:07 +0000 UTC  }],Message:,Reason:,HostIP:10.0.0.6,PodIP:,StartTime:2018-12-10 13:55:07 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec 10 13:55:09.861: INFO: Pod "nginx-deployment-7dc8f79789-kwd5h" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-kwd5h,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-4vvtv,SelfLink:/api/v1/namespaces/e2e-tests-deployment-4vvtv/pods/nginx-deployment-7dc8f79789-kwd5h,UID:33ffe786-fc83-11e8-808b-fa163e6bf550,ResourceVersion:5428,Generation:0,CreationTimestamp:2018-12-10 13:55:07 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 32c30cac-fc83-11e8-808b-fa163e6bf550 0xc422ab8cc0 0xc422ab8cc1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-9h59q {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-9h59q,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-9h59q true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:conformance-cluster1-k8s-node-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc422ab8d30} {node.kubernetes.io/unreachable Exists  NoExecute 0xc422ab8d50}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-10 13:55:07 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-10 13:55:07 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-10 13:55:07 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-10 13:55:07 +0000 UTC  }],Message:,Reason:,HostIP:10.0.0.10,PodIP:,StartTime:2018-12-10 13:55:07 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec 10 13:55:09.861: INFO: Pod "nginx-deployment-7dc8f79789-kxph5" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-kxph5,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-4vvtv,SelfLink:/api/v1/namespaces/e2e-tests-deployment-4vvtv/pods/nginx-deployment-7dc8f79789-kxph5,UID:34093503-fc83-11e8-808b-fa163e6bf550,ResourceVersion:5437,Generation:0,CreationTimestamp:2018-12-10 13:55:07 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 32c30cac-fc83-11e8-808b-fa163e6bf550 0xc422ab8e10 0xc422ab8e11}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-9h59q {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-9h59q,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-9h59q true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:conformance-cluster1-k8s-node-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc422ab8e80} {node.kubernetes.io/unreachable Exists  NoExecute 0xc422ab8ea0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-10 13:55:07 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec 10 13:55:09.861: INFO: Pod "nginx-deployment-7dc8f79789-qqg45" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-qqg45,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-4vvtv,SelfLink:/api/v1/namespaces/e2e-tests-deployment-4vvtv/pods/nginx-deployment-7dc8f79789-qqg45,UID:34054658-fc83-11e8-808b-fa163e6bf550,ResourceVersion:5467,Generation:0,CreationTimestamp:2018-12-10 13:55:07 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 32c30cac-fc83-11e8-808b-fa163e6bf550 0xc422ab8f10 0xc422ab8f11}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-9h59q {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-9h59q,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-9h59q true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:conformance-cluster1-k8s-node-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc422ab8f80} {node.kubernetes.io/unreachable Exists  NoExecute 0xc422ab8fa0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-10 13:55:07 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-10 13:55:07 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-10 13:55:07 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-10 13:55:07 +0000 UTC  }],Message:,Reason:,HostIP:10.0.0.10,PodIP:,StartTime:2018-12-10 13:55:07 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec 10 13:55:09.861: INFO: Pod "nginx-deployment-7dc8f79789-xgppv" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-xgppv,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-4vvtv,SelfLink:/api/v1/namespaces/e2e-tests-deployment-4vvtv/pods/nginx-deployment-7dc8f79789-xgppv,UID:32c40ddf-fc83-11e8-808b-fa163e6bf550,ResourceVersion:5320,Generation:0,CreationTimestamp:2018-12-10 13:55:05 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 32c30cac-fc83-11e8-808b-fa163e6bf550 0xc422ab9060 0xc422ab9061}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-9h59q {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-9h59q,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-9h59q true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:conformance-cluster1-k8s-node-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc422ab90d0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc422ab90f0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-10 13:55:05 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-10 13:55:05 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-10 13:55:05 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-10 13:55:05 +0000 UTC  }],Message:,Reason:,HostIP:10.0.0.10,PodIP:,StartTime:2018-12-10 13:55:05 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec 10 13:55:09.861: INFO: Pod "nginx-deployment-7dc8f79789-z7pld" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-z7pld,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-4vvtv,SelfLink:/api/v1/namespaces/e2e-tests-deployment-4vvtv/pods/nginx-deployment-7dc8f79789-z7pld,UID:3402442f-fc83-11e8-808b-fa163e6bf550,ResourceVersion:5492,Generation:0,CreationTimestamp:2018-12-10 13:55:07 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 32c30cac-fc83-11e8-808b-fa163e6bf550 0xc422ab91b0 0xc422ab91b1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-9h59q {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-9h59q,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-9h59q true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:conformance-cluster1-k8s-node-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc422ab9220} {node.kubernetes.io/unreachable Exists  NoExecute 0xc422ab9240}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-10 13:55:07 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-10 13:55:07 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-10 13:55:07 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-10 13:55:07 +0000 UTC  }],Message:,Reason:,HostIP:10.0.0.10,PodIP:,StartTime:2018-12-10 13:55:07 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec 10 13:55:09.861: INFO: Pod "nginx-deployment-7dc8f79789-zwd56" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-zwd56,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-4vvtv,SelfLink:/api/v1/namespaces/e2e-tests-deployment-4vvtv/pods/nginx-deployment-7dc8f79789-zwd56,UID:3402089d-fc83-11e8-808b-fa163e6bf550,ResourceVersion:5464,Generation:0,CreationTimestamp:2018-12-10 13:55:07 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 32c30cac-fc83-11e8-808b-fa163e6bf550 0xc422ab9300 0xc422ab9301}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-9h59q {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-9h59q,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-9h59q true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:conformance-cluster1-k8s-node-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc422ab9370} {node.kubernetes.io/unreachable Exists  NoExecute 0xc422ab9390}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-10 13:55:07 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-10 13:55:07 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-10 13:55:07 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-10 13:55:07 +0000 UTC  }],Message:,Reason:,HostIP:10.0.0.10,PodIP:,StartTime:2018-12-10 13:55:07 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec 10 13:55:09.862: INFO: Pod "nginx-deployment-7f9675fb8b-5998z" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-5998z,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-4vvtv,SelfLink:/api/v1/namespaces/e2e-tests-deployment-4vvtv/pods/nginx-deployment-7f9675fb8b-5998z,UID:34023a88-fc83-11e8-808b-fa163e6bf550,ResourceVersion:5466,Generation:0,CreationTimestamp:2018-12-10 13:55:07 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 30595545-fc83-11e8-808b-fa163e6bf550 0xc422ab9450 0xc422ab9451}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-9h59q {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-9h59q,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-9h59q true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:conformance-cluster1-k8s-node-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc422ab94b0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc422ab94d0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-10 13:55:07 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-10 13:55:07 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-10 13:55:07 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-10 13:55:07 +0000 UTC  }],Message:,Reason:,HostIP:10.0.0.6,PodIP:,StartTime:2018-12-10 13:55:07 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec 10 13:55:09.862: INFO: Pod "nginx-deployment-7f9675fb8b-6lddc" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-6lddc,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-4vvtv,SelfLink:/api/v1/namespaces/e2e-tests-deployment-4vvtv/pods/nginx-deployment-7f9675fb8b-6lddc,UID:3062432b-fc83-11e8-808b-fa163e6bf550,ResourceVersion:5292,Generation:0,CreationTimestamp:2018-12-10 13:55:01 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 30595545-fc83-11e8-808b-fa163e6bf550 0xc422ab9580 0xc422ab9581}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-9h59q {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-9h59q,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-9h59q true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:conformance-cluster1-k8s-node-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc422ab95e0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc422ab9600}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-10 13:55:01 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-12-10 13:55:05 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2018-12-10 13:55:05 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-10 13:55:01 +0000 UTC  }],Message:,Reason:,HostIP:10.0.0.10,PodIP:10.233.122.219,StartTime:2018-12-10 13:55:01 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2018-12-10 13:55:04 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:2abeba7cab34eb197ff7363486a2aa590027388eafd8e740efae7aae1bed28b6 docker://c383583ac38e28c7bf1bd28124c95b94ce0a5f8db60c449114d8f1ac6b9946d2}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec 10 13:55:09.862: INFO: Pod "nginx-deployment-7f9675fb8b-6ppkx" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-6ppkx,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-4vvtv,SelfLink:/api/v1/namespaces/e2e-tests-deployment-4vvtv/pods/nginx-deployment-7f9675fb8b-6ppkx,UID:34023af1-fc83-11e8-808b-fa163e6bf550,ResourceVersion:5479,Generation:0,CreationTimestamp:2018-12-10 13:55:07 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 30595545-fc83-11e8-808b-fa163e6bf550 0xc422ab96c0 0xc422ab96c1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-9h59q {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-9h59q,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-9h59q true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:conformance-cluster1-k8s-node-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc422ab9720} {node.kubernetes.io/unreachable Exists  NoExecute 0xc422ab9740}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-10 13:55:07 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-10 13:55:07 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-10 13:55:07 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-10 13:55:07 +0000 UTC  }],Message:,Reason:,HostIP:10.0.0.10,PodIP:,StartTime:2018-12-10 13:55:07 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec 10 13:55:09.862: INFO: Pod "nginx-deployment-7f9675fb8b-79pjh" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-79pjh,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-4vvtv,SelfLink:/api/v1/namespaces/e2e-tests-deployment-4vvtv/pods/nginx-deployment-7f9675fb8b-79pjh,UID:34059164-fc83-11e8-808b-fa163e6bf550,ResourceVersion:5499,Generation:0,CreationTimestamp:2018-12-10 13:55:07 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 30595545-fc83-11e8-808b-fa163e6bf550 0xc422ab97f0 0xc422ab97f1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-9h59q {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-9h59q,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-9h59q true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:conformance-cluster1-k8s-node-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc422ab9850} {node.kubernetes.io/unreachable Exists  NoExecute 0xc422ab9870}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-10 13:55:07 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-10 13:55:07 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-10 13:55:07 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-10 13:55:07 +0000 UTC  }],Message:,Reason:,HostIP:10.0.0.10,PodIP:,StartTime:2018-12-10 13:55:07 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec 10 13:55:09.862: INFO: Pod "nginx-deployment-7f9675fb8b-99xhs" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-99xhs,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-4vvtv,SelfLink:/api/v1/namespaces/e2e-tests-deployment-4vvtv/pods/nginx-deployment-7f9675fb8b-99xhs,UID:305f839d-fc83-11e8-808b-fa163e6bf550,ResourceVersion:5285,Generation:0,CreationTimestamp:2018-12-10 13:55:01 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 30595545-fc83-11e8-808b-fa163e6bf550 0xc422ab9920 0xc422ab9921}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-9h59q {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-9h59q,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-9h59q true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:conformance-cluster1-k8s-node-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc422ab9980} {node.kubernetes.io/unreachable Exists  NoExecute 0xc422ab99a0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-10 13:55:01 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-12-10 13:55:05 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2018-12-10 13:55:05 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-10 13:55:01 +0000 UTC  }],Message:,Reason:,HostIP:10.0.0.6,PodIP:10.233.64.144,StartTime:2018-12-10 13:55:01 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2018-12-10 13:55:04 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:2abeba7cab34eb197ff7363486a2aa590027388eafd8e740efae7aae1bed28b6 docker://d8916ad157f53c0c3d5cdf75793931de3e2dbc379d20547655582cb38d6978a7}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec 10 13:55:09.862: INFO: Pod "nginx-deployment-7f9675fb8b-clvkf" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-clvkf,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-4vvtv,SelfLink:/api/v1/namespaces/e2e-tests-deployment-4vvtv/pods/nginx-deployment-7f9675fb8b-clvkf,UID:305fa917-fc83-11e8-808b-fa163e6bf550,ResourceVersion:5295,Generation:0,CreationTimestamp:2018-12-10 13:55:01 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 30595545-fc83-11e8-808b-fa163e6bf550 0xc422ab9a60 0xc422ab9a61}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-9h59q {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-9h59q,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-9h59q true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:conformance-cluster1-k8s-node-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc422ab9ac0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc422ab9ae0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-10 13:55:01 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-12-10 13:55:05 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2018-12-10 13:55:05 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-10 13:55:01 +0000 UTC  }],Message:,Reason:,HostIP:10.0.0.10,PodIP:10.233.122.220,StartTime:2018-12-10 13:55:01 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2018-12-10 13:55:04 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:2abeba7cab34eb197ff7363486a2aa590027388eafd8e740efae7aae1bed28b6 docker://a2be442646c2b321d468b2c67d68cb6d0a170e58c2ff8cbe87f667f2ce481756}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec 10 13:55:09.862: INFO: Pod "nginx-deployment-7f9675fb8b-dr27m" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-dr27m,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-4vvtv,SelfLink:/api/v1/namespaces/e2e-tests-deployment-4vvtv/pods/nginx-deployment-7f9675fb8b-dr27m,UID:34056476-fc83-11e8-808b-fa163e6bf550,ResourceVersion:5497,Generation:0,CreationTimestamp:2018-12-10 13:55:07 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 30595545-fc83-11e8-808b-fa163e6bf550 0xc422ab9ba0 0xc422ab9ba1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-9h59q {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-9h59q,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-9h59q true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:conformance-cluster1-k8s-node-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc422ab9c00} {node.kubernetes.io/unreachable Exists  NoExecute 0xc422ab9c20}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-10 13:55:07 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-10 13:55:07 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-10 13:55:07 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-10 13:55:07 +0000 UTC  }],Message:,Reason:,HostIP:10.0.0.10,PodIP:,StartTime:2018-12-10 13:55:07 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec 10 13:55:09.862: INFO: Pod "nginx-deployment-7f9675fb8b-f9q2s" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-f9q2s,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-4vvtv,SelfLink:/api/v1/namespaces/e2e-tests-deployment-4vvtv/pods/nginx-deployment-7f9675fb8b-f9q2s,UID:305fea8b-fc83-11e8-808b-fa163e6bf550,ResourceVersion:5283,Generation:0,CreationTimestamp:2018-12-10 13:55:01 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 30595545-fc83-11e8-808b-fa163e6bf550 0xc422ab9cd0 0xc422ab9cd1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-9h59q {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-9h59q,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-9h59q true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:conformance-cluster1-k8s-node-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc422ab9d30} {node.kubernetes.io/unreachable Exists  NoExecute 0xc422ab9d50}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-10 13:55:01 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-12-10 13:55:05 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2018-12-10 13:55:05 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-10 13:55:01 +0000 UTC  }],Message:,Reason:,HostIP:10.0.0.6,PodIP:10.233.64.142,StartTime:2018-12-10 13:55:01 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2018-12-10 13:55:04 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:2abeba7cab34eb197ff7363486a2aa590027388eafd8e740efae7aae1bed28b6 docker://0f987e265c4d471332459d032480f539fe65bb8b65bd93a6a864bd30d79863cb}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec 10 13:55:09.862: INFO: Pod "nginx-deployment-7f9675fb8b-ftdw8" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-ftdw8,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-4vvtv,SelfLink:/api/v1/namespaces/e2e-tests-deployment-4vvtv/pods/nginx-deployment-7f9675fb8b-ftdw8,UID:34057b12-fc83-11e8-808b-fa163e6bf550,ResourceVersion:5498,Generation:0,CreationTimestamp:2018-12-10 13:55:07 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 30595545-fc83-11e8-808b-fa163e6bf550 0xc422ab9e10 0xc422ab9e11}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-9h59q {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-9h59q,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-9h59q true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:conformance-cluster1-k8s-node-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc422ab9e70} {node.kubernetes.io/unreachable Exists  NoExecute 0xc422ab9e90}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-10 13:55:07 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-10 13:55:07 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-10 13:55:07 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-10 13:55:07 +0000 UTC  }],Message:,Reason:,HostIP:10.0.0.6,PodIP:,StartTime:2018-12-10 13:55:07 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec 10 13:55:09.863: INFO: Pod "nginx-deployment-7f9675fb8b-hfjtr" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-hfjtr,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-4vvtv,SelfLink:/api/v1/namespaces/e2e-tests-deployment-4vvtv/pods/nginx-deployment-7f9675fb8b-hfjtr,UID:305db216-fc83-11e8-808b-fa163e6bf550,ResourceVersion:5257,Generation:0,CreationTimestamp:2018-12-10 13:55:01 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 30595545-fc83-11e8-808b-fa163e6bf550 0xc422ab9f40 0xc422ab9f41}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-9h59q {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-9h59q,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-9h59q true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:conformance-cluster1-k8s-node-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc422ab9fa0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc422ab9fc0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-10 13:55:01 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-12-10 13:55:04 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2018-12-10 13:55:04 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-10 13:55:01 +0000 UTC  }],Message:,Reason:,HostIP:10.0.0.6,PodIP:10.233.64.141,StartTime:2018-12-10 13:55:01 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2018-12-10 13:55:03 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:2abeba7cab34eb197ff7363486a2aa590027388eafd8e740efae7aae1bed28b6 docker://cde9bfde13ab895acba8865f1f18d5625477565c4f6da915bddaf93462dc19c8}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec 10 13:55:09.863: INFO: Pod "nginx-deployment-7f9675fb8b-hmrdz" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-hmrdz,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-4vvtv,SelfLink:/api/v1/namespaces/e2e-tests-deployment-4vvtv/pods/nginx-deployment-7f9675fb8b-hmrdz,UID:33ffa8f0-fc83-11e8-808b-fa163e6bf550,ResourceVersion:5459,Generation:0,CreationTimestamp:2018-12-10 13:55:07 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 30595545-fc83-11e8-808b-fa163e6bf550 0xc42136e080 0xc42136e081}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-9h59q {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-9h59q,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-9h59q true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:conformance-cluster1-k8s-node-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc42136e0e0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc42136e100}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-10 13:55:07 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-10 13:55:07 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-10 13:55:07 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-10 13:55:07 +0000 UTC  }],Message:,Reason:,HostIP:10.0.0.10,PodIP:,StartTime:2018-12-10 13:55:07 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec 10 13:55:09.863: INFO: Pod "nginx-deployment-7f9675fb8b-j9xss" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-j9xss,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-4vvtv,SelfLink:/api/v1/namespaces/e2e-tests-deployment-4vvtv/pods/nginx-deployment-7f9675fb8b-j9xss,UID:33ff7a20-fc83-11e8-808b-fa163e6bf550,ResourceVersion:5424,Generation:0,CreationTimestamp:2018-12-10 13:55:07 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 30595545-fc83-11e8-808b-fa163e6bf550 0xc42136e1b0 0xc42136e1b1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-9h59q {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-9h59q,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-9h59q true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:conformance-cluster1-k8s-node-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc42136e210} {node.kubernetes.io/unreachable Exists  NoExecute 0xc42136e230}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-10 13:55:07 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-10 13:55:07 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-10 13:55:07 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-10 13:55:07 +0000 UTC  }],Message:,Reason:,HostIP:10.0.0.6,PodIP:,StartTime:2018-12-10 13:55:07 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec 10 13:55:09.863: INFO: Pod "nginx-deployment-7f9675fb8b-jldwn" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-jldwn,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-4vvtv,SelfLink:/api/v1/namespaces/e2e-tests-deployment-4vvtv/pods/nginx-deployment-7f9675fb8b-jldwn,UID:33fe2f2c-fc83-11e8-808b-fa163e6bf550,ResourceVersion:5414,Generation:0,CreationTimestamp:2018-12-10 13:55:07 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 30595545-fc83-11e8-808b-fa163e6bf550 0xc42136e2e0 0xc42136e2e1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-9h59q {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-9h59q,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-9h59q true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:conformance-cluster1-k8s-node-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc42136e340} {node.kubernetes.io/unreachable Exists  NoExecute 0xc42136e360}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-10 13:55:07 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-10 13:55:07 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-10 13:55:07 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-10 13:55:07 +0000 UTC  }],Message:,Reason:,HostIP:10.0.0.6,PodIP:,StartTime:2018-12-10 13:55:07 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec 10 13:55:09.863: INFO: Pod "nginx-deployment-7f9675fb8b-kpfrd" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-kpfrd,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-4vvtv,SelfLink:/api/v1/namespaces/e2e-tests-deployment-4vvtv/pods/nginx-deployment-7f9675fb8b-kpfrd,UID:305db42a-fc83-11e8-808b-fa163e6bf550,ResourceVersion:5289,Generation:0,CreationTimestamp:2018-12-10 13:55:01 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 30595545-fc83-11e8-808b-fa163e6bf550 0xc42136e410 0xc42136e411}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-9h59q {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-9h59q,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-9h59q true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:conformance-cluster1-k8s-node-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc42136e470} {node.kubernetes.io/unreachable Exists  NoExecute 0xc42136e490}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-10 13:55:01 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-12-10 13:55:05 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2018-12-10 13:55:05 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-10 13:55:01 +0000 UTC  }],Message:,Reason:,HostIP:10.0.0.10,PodIP:10.233.122.221,StartTime:2018-12-10 13:55:01 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2018-12-10 13:55:04 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:2abeba7cab34eb197ff7363486a2aa590027388eafd8e740efae7aae1bed28b6 docker://ced2bafbe84c23a5f280474102b319990f9fcc49b4818d46997cd7d2567f1ae0}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec 10 13:55:09.863: INFO: Pod "nginx-deployment-7f9675fb8b-mwvvp" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-mwvvp,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-4vvtv,SelfLink:/api/v1/namespaces/e2e-tests-deployment-4vvtv/pods/nginx-deployment-7f9675fb8b-mwvvp,UID:34056ccd-fc83-11e8-808b-fa163e6bf550,ResourceVersion:5481,Generation:0,CreationTimestamp:2018-12-10 13:55:07 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 30595545-fc83-11e8-808b-fa163e6bf550 0xc42136e550 0xc42136e551}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-9h59q {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-9h59q,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-9h59q true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:conformance-cluster1-k8s-node-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc42136e5b0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc42136e5d0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-10 13:55:07 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-10 13:55:07 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-10 13:55:07 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-10 13:55:07 +0000 UTC  }],Message:,Reason:,HostIP:10.0.0.6,PodIP:,StartTime:2018-12-10 13:55:07 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec 10 13:55:09.863: INFO: Pod "nginx-deployment-7f9675fb8b-pgrbp" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-pgrbp,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-4vvtv,SelfLink:/api/v1/namespaces/e2e-tests-deployment-4vvtv/pods/nginx-deployment-7f9675fb8b-pgrbp,UID:305ca430-fc83-11e8-808b-fa163e6bf550,ResourceVersion:5298,Generation:0,CreationTimestamp:2018-12-10 13:55:01 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 30595545-fc83-11e8-808b-fa163e6bf550 0xc42136e680 0xc42136e681}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-9h59q {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-9h59q,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-9h59q true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:conformance-cluster1-k8s-node-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc42136e6e0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc42136e700}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-10 13:55:01 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-12-10 13:55:05 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2018-12-10 13:55:05 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-10 13:55:01 +0000 UTC  }],Message:,Reason:,HostIP:10.0.0.10,PodIP:10.233.122.218,StartTime:2018-12-10 13:55:01 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2018-12-10 13:55:04 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:2abeba7cab34eb197ff7363486a2aa590027388eafd8e740efae7aae1bed28b6 docker://805a1755945ec6d6ba4bfbb4b3b82e48eb25a9041f7418b74904a1b58f9e9c64}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec 10 13:55:09.864: INFO: Pod "nginx-deployment-7f9675fb8b-rsb25" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-rsb25,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-4vvtv,SelfLink:/api/v1/namespaces/e2e-tests-deployment-4vvtv/pods/nginx-deployment-7f9675fb8b-rsb25,UID:30622412-fc83-11e8-808b-fa163e6bf550,ResourceVersion:5273,Generation:0,CreationTimestamp:2018-12-10 13:55:01 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 30595545-fc83-11e8-808b-fa163e6bf550 0xc42136e7c0 0xc42136e7c1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-9h59q {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-9h59q,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-9h59q true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:conformance-cluster1-k8s-node-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc42136e820} {node.kubernetes.io/unreachable Exists  NoExecute 0xc42136e840}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-10 13:55:01 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-12-10 13:55:04 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2018-12-10 13:55:04 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-10 13:55:01 +0000 UTC  }],Message:,Reason:,HostIP:10.0.0.10,PodIP:10.233.122.217,StartTime:2018-12-10 13:55:01 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2018-12-10 13:55:03 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:2abeba7cab34eb197ff7363486a2aa590027388eafd8e740efae7aae1bed28b6 docker://92e2b529c0cc6153e070f34e100cf1dd2dd4ac8dee2a386830e0d02ccd2b6fce}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec 10 13:55:09.864: INFO: Pod "nginx-deployment-7f9675fb8b-sddhr" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-sddhr,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-4vvtv,SelfLink:/api/v1/namespaces/e2e-tests-deployment-4vvtv/pods/nginx-deployment-7f9675fb8b-sddhr,UID:34055ee5-fc83-11e8-808b-fa163e6bf550,ResourceVersion:5468,Generation:0,CreationTimestamp:2018-12-10 13:55:07 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 30595545-fc83-11e8-808b-fa163e6bf550 0xc42136e900 0xc42136e901}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-9h59q {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-9h59q,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-9h59q true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:conformance-cluster1-k8s-node-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc42136e960} {node.kubernetes.io/unreachable Exists  NoExecute 0xc42136e980}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-10 13:55:07 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-10 13:55:07 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-10 13:55:07 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-10 13:55:07 +0000 UTC  }],Message:,Reason:,HostIP:10.0.0.10,PodIP:,StartTime:2018-12-10 13:55:07 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec 10 13:55:09.864: INFO: Pod "nginx-deployment-7f9675fb8b-ttgzd" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-ttgzd,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-4vvtv,SelfLink:/api/v1/namespaces/e2e-tests-deployment-4vvtv/pods/nginx-deployment-7f9675fb8b-ttgzd,UID:34022b59-fc83-11e8-808b-fa163e6bf550,ResourceVersion:5455,Generation:0,CreationTimestamp:2018-12-10 13:55:07 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 30595545-fc83-11e8-808b-fa163e6bf550 0xc42136ea30 0xc42136ea31}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-9h59q {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-9h59q,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-9h59q true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:conformance-cluster1-k8s-node-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc42136ea90} {node.kubernetes.io/unreachable Exists  NoExecute 0xc42136eab0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-10 13:55:07 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-10 13:55:07 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-10 13:55:07 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-10 13:55:07 +0000 UTC  }],Message:,Reason:,HostIP:10.0.0.6,PodIP:,StartTime:2018-12-10 13:55:07 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec 10 13:55:09.864: INFO: Pod "nginx-deployment-7f9675fb8b-zsnzd" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-zsnzd,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-4vvtv,SelfLink:/api/v1/namespaces/e2e-tests-deployment-4vvtv/pods/nginx-deployment-7f9675fb8b-zsnzd,UID:34024d49-fc83-11e8-808b-fa163e6bf550,ResourceVersion:5461,Generation:0,CreationTimestamp:2018-12-10 13:55:07 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 30595545-fc83-11e8-808b-fa163e6bf550 0xc42136eb60 0xc42136eb61}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-9h59q {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-9h59q,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-9h59q true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:conformance-cluster1-k8s-node-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc42136ebc0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc42136ebe0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-10 13:55:07 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-10 13:55:07 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-10 13:55:07 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-10 13:55:07 +0000 UTC  }],Message:,Reason:,HostIP:10.0.0.6,PodIP:,StartTime:2018-12-10 13:55:07 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 10 13:55:09.864: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-4vvtv" for this suite.
Dec 10 13:55:17.896: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 13:55:17.952: INFO: namespace: e2e-tests-deployment-4vvtv, resource: bindings, ignored listing per whitelist
Dec 10 13:55:18.047: INFO: namespace e2e-tests-deployment-4vvtv deletion completed in 8.177338431s

• [SLOW TEST:16.435 seconds]
[sig-apps] Deployment
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] ConfigMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 10 13:55:18.047: INFO: >>> kubeConfig: /tmp/kubeconfig-578738756
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name cm-test-opt-del-3a29df1f-fc83-11e8-a36b-7e9ed3de7210
STEP: Creating configMap with name cm-test-opt-upd-3a29df5a-fc83-11e8-a36b-7e9ed3de7210
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-3a29df1f-fc83-11e8-a36b-7e9ed3de7210
STEP: Updating configmap cm-test-opt-upd-3a29df5a-fc83-11e8-a36b-7e9ed3de7210
STEP: Creating configMap with name cm-test-opt-create-3a29df6f-fc83-11e8-a36b-7e9ed3de7210
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 10 13:56:30.717: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-kwcpg" for this suite.
Dec 10 13:56:52.739: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 13:56:52.835: INFO: namespace: e2e-tests-configmap-kwcpg, resource: bindings, ignored listing per whitelist
Dec 10 13:56:52.838: INFO: namespace e2e-tests-configmap-kwcpg deletion completed in 22.116799835s

• [SLOW TEST:94.791 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 10 13:56:52.839: INFO: >>> kubeConfig: /tmp/kubeconfig-578738756
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-map-72a32fef-fc83-11e8-a36b-7e9ed3de7210
STEP: Creating a pod to test consume configMaps
Dec 10 13:56:52.916: INFO: Waiting up to 5m0s for pod "pod-configmaps-72a43a58-fc83-11e8-a36b-7e9ed3de7210" in namespace "e2e-tests-configmap-t62l7" to be "success or failure"
Dec 10 13:56:52.924: INFO: Pod "pod-configmaps-72a43a58-fc83-11e8-a36b-7e9ed3de7210": Phase="Pending", Reason="", readiness=false. Elapsed: 8.118894ms
Dec 10 13:56:54.928: INFO: Pod "pod-configmaps-72a43a58-fc83-11e8-a36b-7e9ed3de7210": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.012623173s
STEP: Saw pod success
Dec 10 13:56:54.928: INFO: Pod "pod-configmaps-72a43a58-fc83-11e8-a36b-7e9ed3de7210" satisfied condition "success or failure"
Dec 10 13:56:54.932: INFO: Trying to get logs from node conformance-cluster1-k8s-node-2 pod pod-configmaps-72a43a58-fc83-11e8-a36b-7e9ed3de7210 container configmap-volume-test: <nil>
STEP: delete the pod
Dec 10 13:56:54.957: INFO: Waiting for pod pod-configmaps-72a43a58-fc83-11e8-a36b-7e9ed3de7210 to disappear
Dec 10 13:56:54.960: INFO: Pod pod-configmaps-72a43a58-fc83-11e8-a36b-7e9ed3de7210 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 10 13:56:54.960: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-t62l7" for this suite.
Dec 10 13:57:00.980: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 13:57:01.070: INFO: namespace: e2e-tests-configmap-t62l7, resource: bindings, ignored listing per whitelist
Dec 10 13:57:01.094: INFO: namespace e2e-tests-configmap-t62l7 deletion completed in 6.128281642s

• [SLOW TEST:8.256 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Proxy server 
  should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 10 13:57:01.097: INFO: >>> kubeConfig: /tmp/kubeconfig-578738756
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: starting the proxy server
Dec 10 13:57:01.157: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-578738756 proxy -p 0 --disable-filter'
STEP: curling proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 10 13:57:01.267: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-2qbz7" for this suite.
Dec 10 13:57:07.288: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 13:57:07.353: INFO: namespace: e2e-tests-kubectl-2qbz7, resource: bindings, ignored listing per whitelist
Dec 10 13:57:07.407: INFO: namespace e2e-tests-kubectl-2qbz7 deletion completed in 6.135706984s

• [SLOW TEST:6.310 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Proxy server
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should support proxy with --port 0  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl label 
  should update the label on a resource  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 10 13:57:07.408: INFO: >>> kubeConfig: /tmp/kubeconfig-578738756
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Kubectl label
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1042
STEP: creating the pod
Dec 10 13:57:07.469: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-578738756 create -f - --namespace=e2e-tests-kubectl-wqdk8'
Dec 10 13:57:07.728: INFO: stderr: ""
Dec 10 13:57:07.728: INFO: stdout: "pod/pause created\n"
Dec 10 13:57:07.728: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [pause]
Dec 10 13:57:07.728: INFO: Waiting up to 5m0s for pod "pause" in namespace "e2e-tests-kubectl-wqdk8" to be "running and ready"
Dec 10 13:57:07.733: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 4.437866ms
Dec 10 13:57:09.737: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008607758s
Dec 10 13:57:11.742: INFO: Pod "pause": Phase="Running", Reason="", readiness=true. Elapsed: 4.013194861s
Dec 10 13:57:11.742: INFO: Pod "pause" satisfied condition "running and ready"
Dec 10 13:57:11.742: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [pause]
[It] should update the label on a resource  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: adding the label testing-label with value testing-label-value to a pod
Dec 10 13:57:11.742: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-578738756 label pods pause testing-label=testing-label-value --namespace=e2e-tests-kubectl-wqdk8'
Dec 10 13:57:11.859: INFO: stderr: ""
Dec 10 13:57:11.859: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod has the label testing-label with the value testing-label-value
Dec 10 13:57:11.859: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-578738756 get pod pause -L testing-label --namespace=e2e-tests-kubectl-wqdk8'
Dec 10 13:57:11.952: INFO: stderr: ""
Dec 10 13:57:11.952: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          4s    testing-label-value\n"
STEP: removing the label testing-label of a pod
Dec 10 13:57:11.953: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-578738756 label pods pause testing-label- --namespace=e2e-tests-kubectl-wqdk8'
Dec 10 13:57:12.047: INFO: stderr: ""
Dec 10 13:57:12.048: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod doesn't have the label testing-label
Dec 10 13:57:12.048: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-578738756 get pod pause -L testing-label --namespace=e2e-tests-kubectl-wqdk8'
Dec 10 13:57:12.131: INFO: stderr: ""
Dec 10 13:57:12.131: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          5s    \n"
[AfterEach] [k8s.io] Kubectl label
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1048
STEP: using delete to clean up resources
Dec 10 13:57:12.131: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-578738756 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-wqdk8'
Dec 10 13:57:12.221: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Dec 10 13:57:12.222: INFO: stdout: "pod \"pause\" force deleted\n"
Dec 10 13:57:12.222: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-578738756 get rc,svc -l name=pause --no-headers --namespace=e2e-tests-kubectl-wqdk8'
Dec 10 13:57:12.321: INFO: stderr: "No resources found.\n"
Dec 10 13:57:12.321: INFO: stdout: ""
Dec 10 13:57:12.322: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-578738756 get pods -l name=pause --namespace=e2e-tests-kubectl-wqdk8 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Dec 10 13:57:12.412: INFO: stderr: ""
Dec 10 13:57:12.412: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 10 13:57:12.412: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-wqdk8" for this suite.
Dec 10 13:57:18.438: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 13:57:18.480: INFO: namespace: e2e-tests-kubectl-wqdk8, resource: bindings, ignored listing per whitelist
Dec 10 13:57:18.548: INFO: namespace e2e-tests-kubectl-wqdk8 deletion completed in 6.129295222s

• [SLOW TEST:11.141 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl label
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should update the label on a resource  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 10 13:57:18.551: INFO: >>> kubeConfig: /tmp/kubeconfig-578738756
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
Dec 10 13:57:18.619: INFO: PodSpec: initContainers in spec.initContainers
Dec 10 13:58:01.421: INFO: init container has failed twice: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-init-81f76724-fc83-11e8-a36b-7e9ed3de7210", GenerateName:"", Namespace:"e2e-tests-init-container-wbmvn", SelfLink:"/api/v1/namespaces/e2e-tests-init-container-wbmvn/pods/pod-init-81f76724-fc83-11e8-a36b-7e9ed3de7210", UID:"81f7f85e-fc83-11e8-8690-fa163e74bd5a", ResourceVersion:"6400", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63680047038, loc:(*time.Location)(0x6c43b60)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"619018091"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Initializers:(*v1.Initializers)(nil), Finalizers:[]string(nil), ClusterName:""}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"default-token-9jwzc", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(0xc422782a40), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil)}}}, InitContainers:[]v1.Container{v1.Container{Name:"init1", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/false"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-9jwzc", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}, v1.Container{Name:"init2", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/true"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-9jwzc", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, Containers:[]v1.Container{v1.Container{Name:"run1", Image:"k8s.gcr.io/pause:3.1", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}, Requests:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-9jwzc", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc4214aaa58), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"conformance-cluster1-k8s-node-2", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc421c1a540), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc4214aaad0)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc4214aaaf0)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc4214aaaf8), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil)}, Status:v1.PodStatus{Phase:"Pending", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63680047038, loc:(*time.Location)(0x6c43b60)}}, Reason:"ContainersNotInitialized", Message:"containers with incomplete status: [init1 init2]"}, v1.PodCondition{Type:"Ready", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63680047038, loc:(*time.Location)(0x6c43b60)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"ContainersReady", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63680047038, loc:(*time.Location)(0x6c43b60)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63680047038, loc:(*time.Location)(0x6c43b60)}}, Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"10.0.0.10", PodIP:"10.233.122.240", StartTime:(*v1.Time)(0xc420f521a0), InitContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"init1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc421237ce0)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc421237d50)}, Ready:false, RestartCount:3, Image:"busybox:1.29", ImageID:"docker-pullable://busybox@sha256:2a03a6059f21e150ae84b0973863609494aad70f0a80eaeb64bddd8d92465812", ContainerID:"docker://9ea6ef50354ffe7303c5157607a0487fcc08ea2fa2ec66ad5319fcafc1c28817"}, v1.ContainerStatus{Name:"init2", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc420f521e0), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"docker.io/library/busybox:1.29", ImageID:"", ContainerID:""}}, ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"run1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc420f521c0), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"k8s.gcr.io/pause:3.1", ImageID:"", ContainerID:""}}, QOSClass:"Guaranteed"}}
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 10 13:58:01.421: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-init-container-wbmvn" for this suite.
Dec 10 13:58:23.450: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 13:58:23.507: INFO: namespace: e2e-tests-init-container-wbmvn, resource: bindings, ignored listing per whitelist
Dec 10 13:58:23.558: INFO: namespace e2e-tests-init-container-wbmvn deletion completed in 22.127206892s

• [SLOW TEST:65.007 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] HostPath 
  should give a volume the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 10 13:58:23.558: INFO: >>> kubeConfig: /tmp/kubeconfig-578738756
STEP: Building a namespace api object, basename hostpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:37
[It] should give a volume the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test hostPath mode
Dec 10 13:58:23.639: INFO: Waiting up to 5m0s for pod "pod-host-path-test" in namespace "e2e-tests-hostpath-s6fk4" to be "success or failure"
Dec 10 13:58:23.647: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 8.349469ms
Dec 10 13:58:25.651: INFO: Pod "pod-host-path-test": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.012668502s
STEP: Saw pod success
Dec 10 13:58:25.651: INFO: Pod "pod-host-path-test" satisfied condition "success or failure"
Dec 10 13:58:25.656: INFO: Trying to get logs from node conformance-cluster1-k8s-node-2 pod pod-host-path-test container test-container-1: <nil>
STEP: delete the pod
Dec 10 13:58:25.680: INFO: Waiting for pod pod-host-path-test to disappear
Dec 10 13:58:25.683: INFO: Pod pod-host-path-test no longer exists
[AfterEach] [sig-storage] HostPath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 10 13:58:25.683: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-hostpath-s6fk4" for this suite.
Dec 10 13:58:31.702: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 13:58:31.744: INFO: namespace: e2e-tests-hostpath-s6fk4, resource: bindings, ignored listing per whitelist
Dec 10 13:58:31.811: INFO: namespace e2e-tests-hostpath-s6fk4 deletion completed in 6.124030505s

• [SLOW TEST:8.254 seconds]
[sig-storage] HostPath
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:34
  should give a volume the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 10 13:58:31.812: INFO: >>> kubeConfig: /tmp/kubeconfig-578738756
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-map-ad9fd31f-fc83-11e8-a36b-7e9ed3de7210
STEP: Creating a pod to test consume configMaps
Dec 10 13:58:31.881: INFO: Waiting up to 5m0s for pod "pod-configmaps-ada0e57b-fc83-11e8-a36b-7e9ed3de7210" in namespace "e2e-tests-configmap-wbqmj" to be "success or failure"
Dec 10 13:58:31.885: INFO: Pod "pod-configmaps-ada0e57b-fc83-11e8-a36b-7e9ed3de7210": Phase="Pending", Reason="", readiness=false. Elapsed: 4.32504ms
Dec 10 13:58:33.901: INFO: Pod "pod-configmaps-ada0e57b-fc83-11e8-a36b-7e9ed3de7210": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.019991748s
STEP: Saw pod success
Dec 10 13:58:33.901: INFO: Pod "pod-configmaps-ada0e57b-fc83-11e8-a36b-7e9ed3de7210" satisfied condition "success or failure"
Dec 10 13:58:33.904: INFO: Trying to get logs from node conformance-cluster1-k8s-node-2 pod pod-configmaps-ada0e57b-fc83-11e8-a36b-7e9ed3de7210 container configmap-volume-test: <nil>
STEP: delete the pod
Dec 10 13:58:33.934: INFO: Waiting for pod pod-configmaps-ada0e57b-fc83-11e8-a36b-7e9ed3de7210 to disappear
Dec 10 13:58:33.939: INFO: Pod pod-configmaps-ada0e57b-fc83-11e8-a36b-7e9ed3de7210 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 10 13:58:33.939: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-wbqmj" for this suite.
Dec 10 13:58:39.959: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 13:58:40.010: INFO: namespace: e2e-tests-configmap-wbqmj, resource: bindings, ignored listing per whitelist
Dec 10 13:58:40.067: INFO: namespace e2e-tests-configmap-wbqmj deletion completed in 6.124009371s

• [SLOW TEST:8.256 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 10 13:58:40.068: INFO: >>> kubeConfig: /tmp/kubeconfig-578738756
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-b28da90e-fc83-11e8-a36b-7e9ed3de7210
STEP: Creating a pod to test consume configMaps
Dec 10 13:58:40.152: INFO: Waiting up to 5m0s for pod "pod-configmaps-b28efc43-fc83-11e8-a36b-7e9ed3de7210" in namespace "e2e-tests-configmap-ztd7h" to be "success or failure"
Dec 10 13:58:40.156: INFO: Pod "pod-configmaps-b28efc43-fc83-11e8-a36b-7e9ed3de7210": Phase="Pending", Reason="", readiness=false. Elapsed: 3.68424ms
Dec 10 13:58:42.160: INFO: Pod "pod-configmaps-b28efc43-fc83-11e8-a36b-7e9ed3de7210": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008067945s
STEP: Saw pod success
Dec 10 13:58:42.160: INFO: Pod "pod-configmaps-b28efc43-fc83-11e8-a36b-7e9ed3de7210" satisfied condition "success or failure"
Dec 10 13:58:42.164: INFO: Trying to get logs from node conformance-cluster1-k8s-node-2 pod pod-configmaps-b28efc43-fc83-11e8-a36b-7e9ed3de7210 container configmap-volume-test: <nil>
STEP: delete the pod
Dec 10 13:58:42.188: INFO: Waiting for pod pod-configmaps-b28efc43-fc83-11e8-a36b-7e9ed3de7210 to disappear
Dec 10 13:58:42.192: INFO: Pod pod-configmaps-b28efc43-fc83-11e8-a36b-7e9ed3de7210 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 10 13:58:42.192: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-ztd7h" for this suite.
Dec 10 13:58:48.211: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 13:58:48.256: INFO: namespace: e2e-tests-configmap-ztd7h, resource: bindings, ignored listing per whitelist
Dec 10 13:58:48.316: INFO: namespace e2e-tests-configmap-ztd7h deletion completed in 6.120019038s

• [SLOW TEST:8.248 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 10 13:58:48.316: INFO: >>> kubeConfig: /tmp/kubeconfig-578738756
STEP: Building a namespace api object, basename namespaces
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a test namespace
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a service in the namespace
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Verifying there is no service in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 10 13:58:54.470: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-namespaces-qb6ln" for this suite.
Dec 10 13:59:00.490: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 13:59:00.592: INFO: namespace: e2e-tests-namespaces-qb6ln, resource: bindings, ignored listing per whitelist
Dec 10 13:59:00.599: INFO: namespace e2e-tests-namespaces-qb6ln deletion completed in 6.124058369s
STEP: Destroying namespace "e2e-tests-nsdeletetest-j54d2" for this suite.
Dec 10 13:59:00.602: INFO: Namespace e2e-tests-nsdeletetest-j54d2 was already deleted
STEP: Destroying namespace "e2e-tests-nsdeletetest-9rts2" for this suite.
Dec 10 13:59:06.617: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 13:59:06.714: INFO: namespace: e2e-tests-nsdeletetest-9rts2, resource: bindings, ignored listing per whitelist
Dec 10 13:59:06.720: INFO: namespace e2e-tests-nsdeletetest-9rts2 deletion completed in 6.117756857s

• [SLOW TEST:18.405 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 10 13:59:06.720: INFO: >>> kubeConfig: /tmp/kubeconfig-578738756
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-4rrqf
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Dec 10 13:59:06.794: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Dec 10 13:59:28.879: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.233.122.245:8080/dial?request=hostName&protocol=http&host=10.233.64.159&port=8080&tries=1'] Namespace:e2e-tests-pod-network-test-4rrqf PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 10 13:59:28.879: INFO: >>> kubeConfig: /tmp/kubeconfig-578738756
Dec 10 13:59:28.991: INFO: Waiting for endpoints: map[]
Dec 10 13:59:28.995: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.233.122.245:8080/dial?request=hostName&protocol=http&host=10.233.122.244&port=8080&tries=1'] Namespace:e2e-tests-pod-network-test-4rrqf PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 10 13:59:28.995: INFO: >>> kubeConfig: /tmp/kubeconfig-578738756
Dec 10 13:59:29.099: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 10 13:59:29.100: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-4rrqf" for this suite.
Dec 10 13:59:51.120: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 13:59:51.154: INFO: namespace: e2e-tests-pod-network-test-4rrqf, resource: bindings, ignored listing per whitelist
Dec 10 13:59:51.221: INFO: namespace e2e-tests-pod-network-test-4rrqf deletion completed in 22.116103362s

• [SLOW TEST:44.501 seconds]
[sig-network] Networking
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: http [NodeConformance] [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 10 13:59:51.221: INFO: >>> kubeConfig: /tmp/kubeconfig-578738756
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-wgg4v
[It] should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a new StatefulSet
Dec 10 13:59:51.316: INFO: Found 0 stateful pods, waiting for 3
Dec 10 14:00:01.329: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Dec 10 14:00:01.329: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Dec 10 14:00:01.329: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
Dec 10 14:00:01.339: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-578738756 exec --namespace=e2e-tests-statefulset-wgg4v ss2-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Dec 10 14:00:01.543: INFO: stderr: ""
Dec 10 14:00:01.543: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Dec 10 14:00:01.543: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss2-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

STEP: Updating StatefulSet template: update image from docker.io/library/nginx:1.14-alpine to docker.io/library/nginx:1.15-alpine
Dec 10 14:00:11.584: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Updating Pods in reverse ordinal order
Dec 10 14:00:21.611: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-578738756 exec --namespace=e2e-tests-statefulset-wgg4v ss2-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec 10 14:00:21.798: INFO: stderr: ""
Dec 10 14:00:21.798: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Dec 10 14:00:21.798: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss2-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Dec 10 14:00:31.826: INFO: Waiting for StatefulSet e2e-tests-statefulset-wgg4v/ss2 to complete update
Dec 10 14:00:31.826: INFO: Waiting for Pod e2e-tests-statefulset-wgg4v/ss2-0 to have revision ss2-c79899b9 update revision ss2-787997d666
Dec 10 14:00:31.826: INFO: Waiting for Pod e2e-tests-statefulset-wgg4v/ss2-1 to have revision ss2-c79899b9 update revision ss2-787997d666
Dec 10 14:00:41.840: INFO: Waiting for StatefulSet e2e-tests-statefulset-wgg4v/ss2 to complete update
Dec 10 14:00:41.840: INFO: Waiting for Pod e2e-tests-statefulset-wgg4v/ss2-0 to have revision ss2-c79899b9 update revision ss2-787997d666
STEP: Rolling back to a previous revision
Dec 10 14:00:51.835: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-578738756 exec --namespace=e2e-tests-statefulset-wgg4v ss2-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Dec 10 14:00:52.057: INFO: stderr: ""
Dec 10 14:00:52.057: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Dec 10 14:00:52.057: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss2-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Dec 10 14:01:02.107: INFO: Updating stateful set ss2
STEP: Rolling back update in reverse ordinal order
Dec 10 14:01:12.137: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-578738756 exec --namespace=e2e-tests-statefulset-wgg4v ss2-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec 10 14:01:12.331: INFO: stderr: ""
Dec 10 14:01:12.331: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Dec 10 14:01:12.331: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss2-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Dec 10 14:01:32.359: INFO: Waiting for StatefulSet e2e-tests-statefulset-wgg4v/ss2 to complete update
Dec 10 14:01:32.359: INFO: Waiting for Pod e2e-tests-statefulset-wgg4v/ss2-0 to have revision ss2-787997d666 update revision ss2-c79899b9
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Dec 10 14:01:42.373: INFO: Deleting all statefulset in ns e2e-tests-statefulset-wgg4v
Dec 10 14:01:42.376: INFO: Scaling statefulset ss2 to 0
Dec 10 14:02:02.394: INFO: Waiting for statefulset status.replicas updated to 0
Dec 10 14:02:02.399: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 10 14:02:02.423: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-wgg4v" for this suite.
Dec 10 14:02:08.447: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 14:02:08.465: INFO: namespace: e2e-tests-statefulset-wgg4v, resource: bindings, ignored listing per whitelist
Dec 10 14:02:08.558: INFO: namespace e2e-tests-statefulset-wgg4v deletion completed in 6.125774185s

• [SLOW TEST:137.337 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should perform rolling updates and roll backs of template modifications [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 10 14:02:08.559: INFO: >>> kubeConfig: /tmp/kubeconfig-578738756
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:78
Dec 10 14:02:08.637: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Dec 10 14:02:08.645: INFO: Waiting for terminating namespaces to be deleted...
Dec 10 14:02:08.648: INFO: 
Logging pods the kubelet thinks is on node conformance-cluster1-k8s-node-1 before test
Dec 10 14:02:08.655: INFO: calico-node-wng6k from kube-system started at 2018-12-10 13:31:47 +0000 UTC (1 container statuses recorded)
Dec 10 14:02:08.655: INFO: 	Container calico-node ready: true, restart count 0
Dec 10 14:02:08.655: INFO: kube-proxy-pxl26 from kube-system started at 2018-12-10 13:32:28 +0000 UTC (1 container statuses recorded)
Dec 10 14:02:08.655: INFO: 	Container kube-proxy ready: true, restart count 0
Dec 10 14:02:08.655: INFO: sonobuoy from heptio-sonobuoy started at 2018-12-10 13:42:48 +0000 UTC (1 container statuses recorded)
Dec 10 14:02:08.655: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Dec 10 14:02:08.655: INFO: sonobuoy-e2e-job-98e31667bd8c4837 from heptio-sonobuoy started at 2018-12-10 13:42:53 +0000 UTC (2 container statuses recorded)
Dec 10 14:02:08.655: INFO: 	Container e2e ready: true, restart count 0
Dec 10 14:02:08.655: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Dec 10 14:02:08.655: INFO: nginx-proxy-conformance-cluster1-k8s-node-1 from kube-system started at <nil> (0 container statuses recorded)
Dec 10 14:02:08.655: INFO: sonobuoy-systemd-logs-daemon-set-fb293fe0c33e403d-krfqj from heptio-sonobuoy started at 2018-12-10 13:42:53 +0000 UTC (2 container statuses recorded)
Dec 10 14:02:08.655: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 0
Dec 10 14:02:08.655: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Dec 10 14:02:08.655: INFO: 
Logging pods the kubelet thinks is on node conformance-cluster1-k8s-node-2 before test
Dec 10 14:02:08.663: INFO: dns-autoscaler-66b95c57d9-thm4m from kube-system started at 2018-12-10 13:33:31 +0000 UTC (1 container statuses recorded)
Dec 10 14:02:08.663: INFO: 	Container autoscaler ready: true, restart count 0
Dec 10 14:02:08.663: INFO: nginx-proxy-conformance-cluster1-k8s-node-2 from kube-system started at <nil> (0 container statuses recorded)
Dec 10 14:02:08.663: INFO: kube-proxy-fzw6d from kube-system started at 2018-12-10 13:31:48 +0000 UTC (1 container statuses recorded)
Dec 10 14:02:08.663: INFO: 	Container kube-proxy ready: true, restart count 0
Dec 10 14:02:08.663: INFO: calico-node-kspwz from kube-system started at 2018-12-10 13:31:47 +0000 UTC (1 container statuses recorded)
Dec 10 14:02:08.663: INFO: 	Container calico-node ready: true, restart count 0
Dec 10 14:02:08.663: INFO: calico-kube-controllers-7fbf568fdb-q84ks from kube-system started at 2018-12-10 13:31:59 +0000 UTC (1 container statuses recorded)
Dec 10 14:02:08.663: INFO: 	Container calico-kube-controllers ready: true, restart count 0
Dec 10 14:02:08.663: INFO: kubernetes-dashboard-68697c45d9-2tpxx from kube-system started at 2018-12-10 13:33:37 +0000 UTC (1 container statuses recorded)
Dec 10 14:02:08.663: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
Dec 10 14:02:08.663: INFO: sonobuoy-systemd-logs-daemon-set-fb293fe0c33e403d-4kjtv from heptio-sonobuoy started at 2018-12-10 13:42:53 +0000 UTC (2 container statuses recorded)
Dec 10 14:02:08.663: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 0
Dec 10 14:02:08.663: INFO: 	Container sonobuoy-worker ready: true, restart count 0
[It] validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Trying to schedule Pod with nonempty NodeSelector.
STEP: Considering event: 
Type = [Warning], Name = [restricted-pod.156efd92afaa9c29], Reason = [FailedScheduling], Message = [0/5 nodes are available: 5 node(s) didn't match node selector.]
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 10 14:02:09.694: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-sched-pred-znktw" for this suite.
Dec 10 14:02:15.714: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 14:02:15.751: INFO: namespace: e2e-tests-sched-pred-znktw, resource: bindings, ignored listing per whitelist
Dec 10 14:02:15.820: INFO: namespace e2e-tests-sched-pred-znktw deletion completed in 6.121172339s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:69

• [SLOW TEST:7.261 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl patch 
  should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 10 14:02:15.820: INFO: >>> kubeConfig: /tmp/kubeconfig-578738756
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating Redis RC
Dec 10 14:02:15.877: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-578738756 create -f - --namespace=e2e-tests-kubectl-rwn7h'
Dec 10 14:02:16.034: INFO: stderr: ""
Dec 10 14:02:16.034: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
Dec 10 14:02:17.038: INFO: Selector matched 1 pods for map[app:redis]
Dec 10 14:02:17.038: INFO: Found 0 / 1
Dec 10 14:02:18.039: INFO: Selector matched 1 pods for map[app:redis]
Dec 10 14:02:18.039: INFO: Found 1 / 1
Dec 10 14:02:18.039: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
STEP: patching all pods
Dec 10 14:02:18.043: INFO: Selector matched 1 pods for map[app:redis]
Dec 10 14:02:18.043: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Dec 10 14:02:18.043: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-578738756 patch pod redis-master-ppv88 --namespace=e2e-tests-kubectl-rwn7h -p {"metadata":{"annotations":{"x":"y"}}}'
Dec 10 14:02:18.149: INFO: stderr: ""
Dec 10 14:02:18.149: INFO: stdout: "pod/redis-master-ppv88 patched\n"
STEP: checking annotations
Dec 10 14:02:18.154: INFO: Selector matched 1 pods for map[app:redis]
Dec 10 14:02:18.154: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 10 14:02:18.154: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-rwn7h" for this suite.
Dec 10 14:02:40.173: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 14:02:40.210: INFO: namespace: e2e-tests-kubectl-rwn7h, resource: bindings, ignored listing per whitelist
Dec 10 14:02:40.285: INFO: namespace e2e-tests-kubectl-rwn7h deletion completed in 22.12724974s

• [SLOW TEST:24.466 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl patch
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should add annotations for pods in rc  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] ConfigMap 
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 10 14:02:40.286: INFO: >>> kubeConfig: /tmp/kubeconfig-578738756
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-upd-41bd9454-fc84-11e8-a36b-7e9ed3de7210
STEP: Creating the pod
STEP: Waiting for pod with text data
STEP: Waiting for pod with binary data
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 10 14:02:44.427: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-nfl44" for this suite.
Dec 10 14:03:06.448: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 14:03:06.457: INFO: namespace: e2e-tests-configmap-nfl44, resource: bindings, ignored listing per whitelist
Dec 10 14:03:06.553: INFO: namespace e2e-tests-configmap-nfl44 deletion completed in 22.121354101s

• [SLOW TEST:26.267 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 10 14:03:06.553: INFO: >>> kubeConfig: /tmp/kubeconfig-578738756
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0666 on tmpfs
Dec 10 14:03:06.626: INFO: Waiting up to 5m0s for pod "pod-51638bca-fc84-11e8-a36b-7e9ed3de7210" in namespace "e2e-tests-emptydir-zjmrb" to be "success or failure"
Dec 10 14:03:06.633: INFO: Pod "pod-51638bca-fc84-11e8-a36b-7e9ed3de7210": Phase="Pending", Reason="", readiness=false. Elapsed: 6.837072ms
Dec 10 14:03:08.644: INFO: Pod "pod-51638bca-fc84-11e8-a36b-7e9ed3de7210": Phase="Pending", Reason="", readiness=false. Elapsed: 2.017982959s
Dec 10 14:03:10.648: INFO: Pod "pod-51638bca-fc84-11e8-a36b-7e9ed3de7210": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.022065133s
STEP: Saw pod success
Dec 10 14:03:10.648: INFO: Pod "pod-51638bca-fc84-11e8-a36b-7e9ed3de7210" satisfied condition "success or failure"
Dec 10 14:03:10.652: INFO: Trying to get logs from node conformance-cluster1-k8s-node-2 pod pod-51638bca-fc84-11e8-a36b-7e9ed3de7210 container test-container: <nil>
STEP: delete the pod
Dec 10 14:03:10.677: INFO: Waiting for pod pod-51638bca-fc84-11e8-a36b-7e9ed3de7210 to disappear
Dec 10 14:03:10.680: INFO: Pod pod-51638bca-fc84-11e8-a36b-7e9ed3de7210 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 10 14:03:10.680: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-zjmrb" for this suite.
Dec 10 14:03:16.703: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 14:03:16.733: INFO: namespace: e2e-tests-emptydir-zjmrb, resource: bindings, ignored listing per whitelist
Dec 10 14:03:16.814: INFO: namespace e2e-tests-emptydir-zjmrb deletion completed in 6.125013809s

• [SLOW TEST:10.261 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 10 14:03:16.815: INFO: >>> kubeConfig: /tmp/kubeconfig-578738756
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:78
Dec 10 14:03:16.881: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Dec 10 14:03:16.889: INFO: Waiting for terminating namespaces to be deleted...
Dec 10 14:03:16.892: INFO: 
Logging pods the kubelet thinks is on node conformance-cluster1-k8s-node-1 before test
Dec 10 14:03:16.897: INFO: sonobuoy from heptio-sonobuoy started at 2018-12-10 13:42:48 +0000 UTC (1 container statuses recorded)
Dec 10 14:03:16.897: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Dec 10 14:03:16.897: INFO: sonobuoy-e2e-job-98e31667bd8c4837 from heptio-sonobuoy started at 2018-12-10 13:42:53 +0000 UTC (2 container statuses recorded)
Dec 10 14:03:16.897: INFO: 	Container e2e ready: true, restart count 0
Dec 10 14:03:16.897: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Dec 10 14:03:16.897: INFO: kube-proxy-pxl26 from kube-system started at 2018-12-10 13:32:28 +0000 UTC (1 container statuses recorded)
Dec 10 14:03:16.898: INFO: 	Container kube-proxy ready: true, restart count 0
Dec 10 14:03:16.898: INFO: sonobuoy-systemd-logs-daemon-set-fb293fe0c33e403d-krfqj from heptio-sonobuoy started at 2018-12-10 13:42:53 +0000 UTC (2 container statuses recorded)
Dec 10 14:03:16.898: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 0
Dec 10 14:03:16.898: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Dec 10 14:03:16.898: INFO: nginx-proxy-conformance-cluster1-k8s-node-1 from kube-system started at <nil> (0 container statuses recorded)
Dec 10 14:03:16.898: INFO: calico-node-wng6k from kube-system started at 2018-12-10 13:31:47 +0000 UTC (1 container statuses recorded)
Dec 10 14:03:16.898: INFO: 	Container calico-node ready: true, restart count 0
Dec 10 14:03:16.898: INFO: 
Logging pods the kubelet thinks is on node conformance-cluster1-k8s-node-2 before test
Dec 10 14:03:16.905: INFO: dns-autoscaler-66b95c57d9-thm4m from kube-system started at 2018-12-10 13:33:31 +0000 UTC (1 container statuses recorded)
Dec 10 14:03:16.905: INFO: 	Container autoscaler ready: true, restart count 0
Dec 10 14:03:16.905: INFO: calico-node-kspwz from kube-system started at 2018-12-10 13:31:47 +0000 UTC (1 container statuses recorded)
Dec 10 14:03:16.905: INFO: 	Container calico-node ready: true, restart count 0
Dec 10 14:03:16.905: INFO: calico-kube-controllers-7fbf568fdb-q84ks from kube-system started at 2018-12-10 13:31:59 +0000 UTC (1 container statuses recorded)
Dec 10 14:03:16.905: INFO: 	Container calico-kube-controllers ready: true, restart count 0
Dec 10 14:03:16.905: INFO: kubernetes-dashboard-68697c45d9-2tpxx from kube-system started at 2018-12-10 13:33:37 +0000 UTC (1 container statuses recorded)
Dec 10 14:03:16.905: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
Dec 10 14:03:16.905: INFO: sonobuoy-systemd-logs-daemon-set-fb293fe0c33e403d-4kjtv from heptio-sonobuoy started at 2018-12-10 13:42:53 +0000 UTC (2 container statuses recorded)
Dec 10 14:03:16.905: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 0
Dec 10 14:03:16.905: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Dec 10 14:03:16.905: INFO: nginx-proxy-conformance-cluster1-k8s-node-2 from kube-system started at <nil> (0 container statuses recorded)
Dec 10 14:03:16.905: INFO: kube-proxy-fzw6d from kube-system started at 2018-12-10 13:31:48 +0000 UTC (1 container statuses recorded)
Dec 10 14:03:16.905: INFO: 	Container kube-proxy ready: true, restart count 0
[It] validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Trying to launch a pod without a label to get a node which can launch it.
STEP: Explicitly delete pod here to free the resource it takes.
STEP: Trying to apply a random label on the found node.
STEP: verifying the node has the label kubernetes.io/e2e-58be433a-fc84-11e8-a36b-7e9ed3de7210 42
STEP: Trying to relaunch the pod, now with labels.
STEP: removing the label kubernetes.io/e2e-58be433a-fc84-11e8-a36b-7e9ed3de7210 off the node conformance-cluster1-k8s-node-2
STEP: verifying the node doesn't have the label kubernetes.io/e2e-58be433a-fc84-11e8-a36b-7e9ed3de7210
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 10 14:03:20.997: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-sched-pred-rfvq7" for this suite.
Dec 10 14:03:39.016: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 14:03:39.095: INFO: namespace: e2e-tests-sched-pred-rfvq7, resource: bindings, ignored listing per whitelist
Dec 10 14:03:39.161: INFO: namespace e2e-tests-sched-pred-rfvq7 deletion completed in 18.160250155s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:69

• [SLOW TEST:22.346 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 10 14:03:39.162: INFO: >>> kubeConfig: /tmp/kubeconfig-578738756
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
Dec 10 14:03:39.230: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 10 14:03:43.111: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-init-container-kpzfg" for this suite.
Dec 10 14:03:49.138: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 14:03:49.184: INFO: namespace: e2e-tests-init-container-kpzfg, resource: bindings, ignored listing per whitelist
Dec 10 14:03:49.255: INFO: namespace e2e-tests-init-container-kpzfg deletion completed in 6.139614707s

• [SLOW TEST:10.094 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-api-machinery] ConfigMap 
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 10 14:03:49.256: INFO: >>> kubeConfig: /tmp/kubeconfig-578738756
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap e2e-tests-configmap-mdnhv/configmap-test-6ad8af4a-fc84-11e8-a36b-7e9ed3de7210
STEP: Creating a pod to test consume configMaps
Dec 10 14:03:49.342: INFO: Waiting up to 5m0s for pod "pod-configmaps-6ad9f40d-fc84-11e8-a36b-7e9ed3de7210" in namespace "e2e-tests-configmap-mdnhv" to be "success or failure"
Dec 10 14:03:49.349: INFO: Pod "pod-configmaps-6ad9f40d-fc84-11e8-a36b-7e9ed3de7210": Phase="Pending", Reason="", readiness=false. Elapsed: 6.300727ms
Dec 10 14:03:51.353: INFO: Pod "pod-configmaps-6ad9f40d-fc84-11e8-a36b-7e9ed3de7210": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010446359s
STEP: Saw pod success
Dec 10 14:03:51.353: INFO: Pod "pod-configmaps-6ad9f40d-fc84-11e8-a36b-7e9ed3de7210" satisfied condition "success or failure"
Dec 10 14:03:51.357: INFO: Trying to get logs from node conformance-cluster1-k8s-node-2 pod pod-configmaps-6ad9f40d-fc84-11e8-a36b-7e9ed3de7210 container env-test: <nil>
STEP: delete the pod
Dec 10 14:03:51.384: INFO: Waiting for pod pod-configmaps-6ad9f40d-fc84-11e8-a36b-7e9ed3de7210 to disappear
Dec 10 14:03:51.387: INFO: Pod pod-configmaps-6ad9f40d-fc84-11e8-a36b-7e9ed3de7210 no longer exists
[AfterEach] [sig-api-machinery] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 10 14:03:51.387: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-mdnhv" for this suite.
Dec 10 14:03:57.408: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 14:03:57.450: INFO: namespace: e2e-tests-configmap-mdnhv, resource: bindings, ignored listing per whitelist
Dec 10 14:03:57.516: INFO: namespace e2e-tests-configmap-mdnhv deletion completed in 6.124500593s

• [SLOW TEST:8.261 seconds]
[sig-api-machinery] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:30
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ConfigMap 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 10 14:03:57.518: INFO: >>> kubeConfig: /tmp/kubeconfig-578738756
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap e2e-tests-configmap-l2fzq/configmap-test-6fc2e42d-fc84-11e8-a36b-7e9ed3de7210
STEP: Creating a pod to test consume configMaps
Dec 10 14:03:57.588: INFO: Waiting up to 5m0s for pod "pod-configmaps-6fc4012c-fc84-11e8-a36b-7e9ed3de7210" in namespace "e2e-tests-configmap-l2fzq" to be "success or failure"
Dec 10 14:03:57.593: INFO: Pod "pod-configmaps-6fc4012c-fc84-11e8-a36b-7e9ed3de7210": Phase="Pending", Reason="", readiness=false. Elapsed: 4.770687ms
Dec 10 14:03:59.604: INFO: Pod "pod-configmaps-6fc4012c-fc84-11e8-a36b-7e9ed3de7210": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.015351275s
STEP: Saw pod success
Dec 10 14:03:59.604: INFO: Pod "pod-configmaps-6fc4012c-fc84-11e8-a36b-7e9ed3de7210" satisfied condition "success or failure"
Dec 10 14:03:59.608: INFO: Trying to get logs from node conformance-cluster1-k8s-node-2 pod pod-configmaps-6fc4012c-fc84-11e8-a36b-7e9ed3de7210 container env-test: <nil>
STEP: delete the pod
Dec 10 14:03:59.633: INFO: Waiting for pod pod-configmaps-6fc4012c-fc84-11e8-a36b-7e9ed3de7210 to disappear
Dec 10 14:03:59.637: INFO: Pod pod-configmaps-6fc4012c-fc84-11e8-a36b-7e9ed3de7210 no longer exists
[AfterEach] [sig-api-machinery] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 10 14:03:59.637: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-l2fzq" for this suite.
Dec 10 14:04:05.655: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 14:04:05.757: INFO: namespace: e2e-tests-configmap-l2fzq, resource: bindings, ignored listing per whitelist
Dec 10 14:04:05.761: INFO: namespace e2e-tests-configmap-l2fzq deletion completed in 6.120087661s

• [SLOW TEST:8.243 seconds]
[sig-api-machinery] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:30
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 10 14:04:05.761: INFO: >>> kubeConfig: /tmp/kubeconfig-578738756
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Dec 10 14:04:09.888: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Dec 10 14:04:09.892: INFO: Pod pod-with-prestop-http-hook still exists
Dec 10 14:04:11.892: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Dec 10 14:04:11.897: INFO: Pod pod-with-prestop-http-hook still exists
Dec 10 14:04:13.892: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Dec 10 14:04:13.897: INFO: Pod pod-with-prestop-http-hook still exists
Dec 10 14:04:15.892: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Dec 10 14:04:15.900: INFO: Pod pod-with-prestop-http-hook still exists
Dec 10 14:04:17.892: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Dec 10 14:04:17.897: INFO: Pod pod-with-prestop-http-hook still exists
Dec 10 14:04:19.892: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Dec 10 14:04:19.902: INFO: Pod pod-with-prestop-http-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 10 14:04:19.914: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-lifecycle-hook-84jvc" for this suite.
Dec 10 14:04:41.937: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 14:04:41.957: INFO: namespace: e2e-tests-container-lifecycle-hook-84jvc, resource: bindings, ignored listing per whitelist
Dec 10 14:04:42.055: INFO: namespace e2e-tests-container-lifecycle-hook-84jvc deletion completed in 22.136764804s

• [SLOW TEST:36.294 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when create a pod with lifecycle hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute prestop http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 10 14:04:42.055: INFO: >>> kubeConfig: /tmp/kubeconfig-578738756
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Dec 10 14:04:42.135: INFO: Waiting up to 5m0s for pod "downwardapi-volume-8a508c23-fc84-11e8-a36b-7e9ed3de7210" in namespace "e2e-tests-downward-api-k9cfb" to be "success or failure"
Dec 10 14:04:42.138: INFO: Pod "downwardapi-volume-8a508c23-fc84-11e8-a36b-7e9ed3de7210": Phase="Pending", Reason="", readiness=false. Elapsed: 3.547159ms
Dec 10 14:04:44.142: INFO: Pod "downwardapi-volume-8a508c23-fc84-11e8-a36b-7e9ed3de7210": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007738867s
STEP: Saw pod success
Dec 10 14:04:44.142: INFO: Pod "downwardapi-volume-8a508c23-fc84-11e8-a36b-7e9ed3de7210" satisfied condition "success or failure"
Dec 10 14:04:44.146: INFO: Trying to get logs from node conformance-cluster1-k8s-node-2 pod downwardapi-volume-8a508c23-fc84-11e8-a36b-7e9ed3de7210 container client-container: <nil>
STEP: delete the pod
Dec 10 14:04:44.174: INFO: Waiting for pod downwardapi-volume-8a508c23-fc84-11e8-a36b-7e9ed3de7210 to disappear
Dec 10 14:04:44.178: INFO: Pod downwardapi-volume-8a508c23-fc84-11e8-a36b-7e9ed3de7210 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 10 14:04:44.178: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-k9cfb" for this suite.
Dec 10 14:04:50.200: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 14:04:50.275: INFO: namespace: e2e-tests-downward-api-k9cfb, resource: bindings, ignored listing per whitelist
Dec 10 14:04:50.310: INFO: namespace e2e-tests-downward-api-k9cfb deletion completed in 6.126701285s

• [SLOW TEST:8.255 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 10 14:04:50.311: INFO: >>> kubeConfig: /tmp/kubeconfig-578738756
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-8f3aff45-fc84-11e8-a36b-7e9ed3de7210
STEP: Creating a pod to test consume configMaps
Dec 10 14:04:50.393: INFO: Waiting up to 5m0s for pod "pod-configmaps-8f3c1995-fc84-11e8-a36b-7e9ed3de7210" in namespace "e2e-tests-configmap-hkb59" to be "success or failure"
Dec 10 14:04:50.398: INFO: Pod "pod-configmaps-8f3c1995-fc84-11e8-a36b-7e9ed3de7210": Phase="Pending", Reason="", readiness=false. Elapsed: 4.882729ms
Dec 10 14:04:52.411: INFO: Pod "pod-configmaps-8f3c1995-fc84-11e8-a36b-7e9ed3de7210": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.018521089s
STEP: Saw pod success
Dec 10 14:04:52.411: INFO: Pod "pod-configmaps-8f3c1995-fc84-11e8-a36b-7e9ed3de7210" satisfied condition "success or failure"
Dec 10 14:04:52.415: INFO: Trying to get logs from node conformance-cluster1-k8s-node-2 pod pod-configmaps-8f3c1995-fc84-11e8-a36b-7e9ed3de7210 container configmap-volume-test: <nil>
STEP: delete the pod
Dec 10 14:04:52.440: INFO: Waiting for pod pod-configmaps-8f3c1995-fc84-11e8-a36b-7e9ed3de7210 to disappear
Dec 10 14:04:52.443: INFO: Pod pod-configmaps-8f3c1995-fc84-11e8-a36b-7e9ed3de7210 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 10 14:04:52.443: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-hkb59" for this suite.
Dec 10 14:04:58.462: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 14:04:58.545: INFO: namespace: e2e-tests-configmap-hkb59, resource: bindings, ignored listing per whitelist
Dec 10 14:04:58.576: INFO: namespace e2e-tests-configmap-hkb59 deletion completed in 6.128792797s

• [SLOW TEST:8.265 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-apps] Deployment 
  deployment should support rollover [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 10 14:04:58.577: INFO: >>> kubeConfig: /tmp/kubeconfig-578738756
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should support rollover [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Dec 10 14:04:58.652: INFO: Pod name rollover-pod: Found 0 pods out of 1
Dec 10 14:05:03.662: INFO: Pod name rollover-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Dec 10 14:05:03.662: INFO: Waiting for pods owned by replica set "test-rollover-controller" to become ready
Dec 10 14:05:05.666: INFO: Creating deployment "test-rollover-deployment"
Dec 10 14:05:05.675: INFO: Make sure deployment "test-rollover-deployment" performs scaling operations
Dec 10 14:05:07.682: INFO: Check revision of new replica set for deployment "test-rollover-deployment"
Dec 10 14:05:07.689: INFO: Ensure that both replica sets have 1 created replica
Dec 10 14:05:07.696: INFO: Rollover old replica sets for deployment "test-rollover-deployment" with new image update
Dec 10 14:05:07.704: INFO: Updating deployment test-rollover-deployment
Dec 10 14:05:07.705: INFO: Wait deployment "test-rollover-deployment" to be observed by the deployment controller
Dec 10 14:05:09.715: INFO: Wait for revision update of deployment "test-rollover-deployment" to 2
Dec 10 14:05:09.722: INFO: Make sure deployment "test-rollover-deployment" is complete
Dec 10 14:05:09.731: INFO: all replica sets need to contain the pod-template-hash label
Dec 10 14:05:09.731: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63680047505, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63680047505, loc:(*time.Location)(0x6c43b60)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63680047509, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63680047505, loc:(*time.Location)(0x6c43b60)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-5b76ff8c4\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec 10 14:05:11.739: INFO: all replica sets need to contain the pod-template-hash label
Dec 10 14:05:11.739: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63680047505, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63680047505, loc:(*time.Location)(0x6c43b60)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63680047509, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63680047505, loc:(*time.Location)(0x6c43b60)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-5b76ff8c4\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec 10 14:05:13.744: INFO: all replica sets need to contain the pod-template-hash label
Dec 10 14:05:13.744: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63680047505, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63680047505, loc:(*time.Location)(0x6c43b60)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63680047509, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63680047505, loc:(*time.Location)(0x6c43b60)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-5b76ff8c4\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec 10 14:05:15.740: INFO: all replica sets need to contain the pod-template-hash label
Dec 10 14:05:15.740: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63680047505, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63680047505, loc:(*time.Location)(0x6c43b60)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63680047509, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63680047505, loc:(*time.Location)(0x6c43b60)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-5b76ff8c4\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec 10 14:05:17.739: INFO: all replica sets need to contain the pod-template-hash label
Dec 10 14:05:17.739: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63680047505, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63680047505, loc:(*time.Location)(0x6c43b60)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63680047509, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63680047505, loc:(*time.Location)(0x6c43b60)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-5b76ff8c4\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec 10 14:05:19.739: INFO: 
Dec 10 14:05:19.739: INFO: Ensure that both old replica sets have no replicas
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Dec 10 14:05:19.749: INFO: Deployment "test-rollover-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment,GenerateName:,Namespace:e2e-tests-deployment-jlwpb,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-jlwpb/deployments/test-rollover-deployment,UID:98595522-fc84-11e8-8690-fa163e74bd5a,ResourceVersion:8374,Generation:2,CreationTimestamp:2018-12-10 14:05:05 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:0,MaxSurge:1,},},MinReadySeconds:10,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[{Available True 2018-12-10 14:05:05 +0000 UTC 2018-12-10 14:05:05 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2018-12-10 14:05:19 +0000 UTC 2018-12-10 14:05:05 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-rollover-deployment-5b76ff8c4" has successfully progressed.}],ReadyReplicas:1,CollisionCount:nil,},}

Dec 10 14:05:19.752: INFO: New ReplicaSet "test-rollover-deployment-5b76ff8c4" of Deployment "test-rollover-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-5b76ff8c4,GenerateName:,Namespace:e2e-tests-deployment-jlwpb,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-jlwpb/replicasets/test-rollover-deployment-5b76ff8c4,UID:998ff735-fc84-11e8-808b-fa163e6bf550,ResourceVersion:8365,Generation:2,CreationTimestamp:2018-12-10 14:05:07 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 5b76ff8c4,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment 98595522-fc84-11e8-8690-fa163e74bd5a 0xc420e730b7 0xc420e730b8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 5b76ff8c4,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 5b76ff8c4,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:2,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Dec 10 14:05:19.752: INFO: All old ReplicaSets of Deployment "test-rollover-deployment":
Dec 10 14:05:19.753: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-controller,GenerateName:,Namespace:e2e-tests-deployment-jlwpb,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-jlwpb/replicasets/test-rollover-controller,UID:94292776-fc84-11e8-8690-fa163e74bd5a,ResourceVersion:8373,Generation:2,CreationTimestamp:2018-12-10 14:04:58 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod: nginx,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment 98595522-fc84-11e8-8690-fa163e74bd5a 0xc420e72fe7 0xc420e72fe8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Dec 10 14:05:19.753: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-6975f4fb87,GenerateName:,Namespace:e2e-tests-deployment-jlwpb,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-jlwpb/replicasets/test-rollover-deployment-6975f4fb87,UID:985c8b66-fc84-11e8-808b-fa163e6bf550,ResourceVersion:8328,Generation:2,CreationTimestamp:2018-12-10 14:05:05 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6975f4fb87,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment 98595522-fc84-11e8-8690-fa163e74bd5a 0xc420e73167 0xc420e73168}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 6975f4fb87,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6975f4fb87,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis-slave gcr.io/google_samples/gb-redisslave:nonexistent [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Dec 10 14:05:19.760: INFO: Pod "test-rollover-deployment-5b76ff8c4-h55rs" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-5b76ff8c4-h55rs,GenerateName:test-rollover-deployment-5b76ff8c4-,Namespace:e2e-tests-deployment-jlwpb,SelfLink:/api/v1/namespaces/e2e-tests-deployment-jlwpb/pods/test-rollover-deployment-5b76ff8c4-h55rs,UID:9995daaf-fc84-11e8-808b-fa163e6bf550,ResourceVersion:8344,Generation:0,CreationTimestamp:2018-12-10 14:05:07 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 5b76ff8c4,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet test-rollover-deployment-5b76ff8c4 998ff735-fc84-11e8-808b-fa163e6bf550 0xc4215a3140 0xc4215a3141}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-bvk2g {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-bvk2g,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-bvk2g true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:conformance-cluster1-k8s-node-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc4215a31a0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc4215a31c0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-10 14:05:07 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-12-10 14:05:09 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2018-12-10 14:05:09 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-10 14:05:07 +0000 UTC  }],Message:,Reason:,HostIP:10.0.0.6,PodIP:10.233.64.163,StartTime:2018-12-10 14:05:07 +0000 UTC,ContainerStatuses:[{redis {nil ContainerStateRunning{StartedAt:2018-12-10 14:05:08 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/redis:1.0 docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830 docker://df7befaf23274ec071c69a274cf2f30f37020c45bd66aac16b934b7778dab32b}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 10 14:05:19.761: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-jlwpb" for this suite.
Dec 10 14:05:25.781: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 14:05:25.824: INFO: namespace: e2e-tests-deployment-jlwpb, resource: bindings, ignored listing per whitelist
Dec 10 14:05:25.888: INFO: namespace e2e-tests-deployment-jlwpb deletion completed in 6.123582642s

• [SLOW TEST:27.311 seconds]
[sig-apps] Deployment
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  deployment should support rollover [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 10 14:05:25.888: INFO: >>> kubeConfig: /tmp/kubeconfig-578738756
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-map-a471d13e-fc84-11e8-a36b-7e9ed3de7210
STEP: Creating a pod to test consume configMaps
Dec 10 14:05:25.975: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-a472e36c-fc84-11e8-a36b-7e9ed3de7210" in namespace "e2e-tests-projected-dmd76" to be "success or failure"
Dec 10 14:05:25.982: INFO: Pod "pod-projected-configmaps-a472e36c-fc84-11e8-a36b-7e9ed3de7210": Phase="Pending", Reason="", readiness=false. Elapsed: 6.615086ms
Dec 10 14:05:27.986: INFO: Pod "pod-projected-configmaps-a472e36c-fc84-11e8-a36b-7e9ed3de7210": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010685497s
STEP: Saw pod success
Dec 10 14:05:27.986: INFO: Pod "pod-projected-configmaps-a472e36c-fc84-11e8-a36b-7e9ed3de7210" satisfied condition "success or failure"
Dec 10 14:05:27.990: INFO: Trying to get logs from node conformance-cluster1-k8s-node-2 pod pod-projected-configmaps-a472e36c-fc84-11e8-a36b-7e9ed3de7210 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Dec 10 14:05:28.016: INFO: Waiting for pod pod-projected-configmaps-a472e36c-fc84-11e8-a36b-7e9ed3de7210 to disappear
Dec 10 14:05:28.019: INFO: Pod pod-projected-configmaps-a472e36c-fc84-11e8-a36b-7e9ed3de7210 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 10 14:05:28.019: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-dmd76" for this suite.
Dec 10 14:05:34.046: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 14:05:34.140: INFO: namespace: e2e-tests-projected-dmd76, resource: bindings, ignored listing per whitelist
Dec 10 14:05:34.158: INFO: namespace e2e-tests-projected-dmd76 deletion completed in 6.133496747s

• [SLOW TEST:8.270 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-network] DNS 
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 10 14:05:34.158: INFO: >>> kubeConfig: /tmp/kubeconfig-578738756
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for services  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(dig +notcp +noall +answer +search dns-test-service A)" && echo OK > /results/wheezy_udp@dns-test-service;test -n "$$(dig +tcp +noall +answer +search dns-test-service A)" && echo OK > /results/wheezy_tcp@dns-test-service;test -n "$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-brh5l A)" && echo OK > /results/wheezy_udp@dns-test-service.e2e-tests-dns-brh5l;test -n "$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-brh5l A)" && echo OK > /results/wheezy_tcp@dns-test-service.e2e-tests-dns-brh5l;test -n "$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-brh5l.svc A)" && echo OK > /results/wheezy_udp@dns-test-service.e2e-tests-dns-brh5l.svc;test -n "$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-brh5l.svc A)" && echo OK > /results/wheezy_tcp@dns-test-service.e2e-tests-dns-brh5l.svc;test -n "$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-brh5l.svc SRV)" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.e2e-tests-dns-brh5l.svc;test -n "$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-brh5l.svc SRV)" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.e2e-tests-dns-brh5l.svc;test -n "$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-brh5l.svc SRV)" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.e2e-tests-dns-brh5l.svc;test -n "$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-brh5l.svc SRV)" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.e2e-tests-dns-brh5l.svc;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-brh5l.pod.cluster.local"}');test -n "$$(dig +notcp +noall +answer +search $${podARec} A)" && echo OK > /results/wheezy_udp@PodARecord;test -n "$$(dig +tcp +noall +answer +search $${podARec} A)" && echo OK > /results/wheezy_tcp@PodARecord;test -n "$$(dig +notcp +noall +answer +search 75.57.233.10.in-addr.arpa. PTR)" && echo OK > /results/10.233.57.75_udp@PTR;test -n "$$(dig +tcp +noall +answer +search 75.57.233.10.in-addr.arpa. PTR)" && echo OK > /results/10.233.57.75_tcp@PTR;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(dig +notcp +noall +answer +search dns-test-service A)" && echo OK > /results/jessie_udp@dns-test-service;test -n "$$(dig +tcp +noall +answer +search dns-test-service A)" && echo OK > /results/jessie_tcp@dns-test-service;test -n "$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-brh5l A)" && echo OK > /results/jessie_udp@dns-test-service.e2e-tests-dns-brh5l;test -n "$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-brh5l A)" && echo OK > /results/jessie_tcp@dns-test-service.e2e-tests-dns-brh5l;test -n "$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-brh5l.svc A)" && echo OK > /results/jessie_udp@dns-test-service.e2e-tests-dns-brh5l.svc;test -n "$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-brh5l.svc A)" && echo OK > /results/jessie_tcp@dns-test-service.e2e-tests-dns-brh5l.svc;test -n "$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-brh5l.svc SRV)" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-brh5l.svc;test -n "$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-brh5l.svc SRV)" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-brh5l.svc;test -n "$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-brh5l.svc SRV)" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.e2e-tests-dns-brh5l.svc;test -n "$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-brh5l.svc SRV)" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.e2e-tests-dns-brh5l.svc;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-brh5l.pod.cluster.local"}');test -n "$$(dig +notcp +noall +answer +search $${podARec} A)" && echo OK > /results/jessie_udp@PodARecord;test -n "$$(dig +tcp +noall +answer +search $${podARec} A)" && echo OK > /results/jessie_tcp@PodARecord;test -n "$$(dig +notcp +noall +answer +search 75.57.233.10.in-addr.arpa. PTR)" && echo OK > /results/10.233.57.75_udp@PTR;test -n "$$(dig +tcp +noall +answer +search 75.57.233.10.in-addr.arpa. PTR)" && echo OK > /results/10.233.57.75_tcp@PTR;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Dec 10 14:06:04.280: INFO: Unable to read wheezy_udp@dns-test-service from pod e2e-tests-dns-brh5l/dns-test-a961a3f9-fc84-11e8-a36b-7e9ed3de7210: the server could not find the requested resource (get pods dns-test-a961a3f9-fc84-11e8-a36b-7e9ed3de7210)
Dec 10 14:06:04.285: INFO: Unable to read wheezy_tcp@dns-test-service from pod e2e-tests-dns-brh5l/dns-test-a961a3f9-fc84-11e8-a36b-7e9ed3de7210: the server could not find the requested resource (get pods dns-test-a961a3f9-fc84-11e8-a36b-7e9ed3de7210)
Dec 10 14:06:04.295: INFO: Unable to read wheezy_tcp@dns-test-service.e2e-tests-dns-brh5l from pod e2e-tests-dns-brh5l/dns-test-a961a3f9-fc84-11e8-a36b-7e9ed3de7210: the server could not find the requested resource (get pods dns-test-a961a3f9-fc84-11e8-a36b-7e9ed3de7210)
Dec 10 14:06:04.303: INFO: Unable to read wheezy_tcp@dns-test-service.e2e-tests-dns-brh5l.svc from pod e2e-tests-dns-brh5l/dns-test-a961a3f9-fc84-11e8-a36b-7e9ed3de7210: the server could not find the requested resource (get pods dns-test-a961a3f9-fc84-11e8-a36b-7e9ed3de7210)
Dec 10 14:06:04.308: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.e2e-tests-dns-brh5l.svc from pod e2e-tests-dns-brh5l/dns-test-a961a3f9-fc84-11e8-a36b-7e9ed3de7210: the server could not find the requested resource (get pods dns-test-a961a3f9-fc84-11e8-a36b-7e9ed3de7210)
Dec 10 14:06:04.313: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.e2e-tests-dns-brh5l.svc from pod e2e-tests-dns-brh5l/dns-test-a961a3f9-fc84-11e8-a36b-7e9ed3de7210: the server could not find the requested resource (get pods dns-test-a961a3f9-fc84-11e8-a36b-7e9ed3de7210)
Dec 10 14:06:04.341: INFO: Unable to read jessie_udp@dns-test-service from pod e2e-tests-dns-brh5l/dns-test-a961a3f9-fc84-11e8-a36b-7e9ed3de7210: the server could not find the requested resource (get pods dns-test-a961a3f9-fc84-11e8-a36b-7e9ed3de7210)
Dec 10 14:06:04.345: INFO: Unable to read jessie_tcp@dns-test-service from pod e2e-tests-dns-brh5l/dns-test-a961a3f9-fc84-11e8-a36b-7e9ed3de7210: the server could not find the requested resource (get pods dns-test-a961a3f9-fc84-11e8-a36b-7e9ed3de7210)
Dec 10 14:06:04.348: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-brh5l from pod e2e-tests-dns-brh5l/dns-test-a961a3f9-fc84-11e8-a36b-7e9ed3de7210: the server could not find the requested resource (get pods dns-test-a961a3f9-fc84-11e8-a36b-7e9ed3de7210)
Dec 10 14:06:04.352: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-brh5l from pod e2e-tests-dns-brh5l/dns-test-a961a3f9-fc84-11e8-a36b-7e9ed3de7210: the server could not find the requested resource (get pods dns-test-a961a3f9-fc84-11e8-a36b-7e9ed3de7210)
Dec 10 14:06:04.357: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-brh5l.svc from pod e2e-tests-dns-brh5l/dns-test-a961a3f9-fc84-11e8-a36b-7e9ed3de7210: the server could not find the requested resource (get pods dns-test-a961a3f9-fc84-11e8-a36b-7e9ed3de7210)
Dec 10 14:06:04.361: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-brh5l.svc from pod e2e-tests-dns-brh5l/dns-test-a961a3f9-fc84-11e8-a36b-7e9ed3de7210: the server could not find the requested resource (get pods dns-test-a961a3f9-fc84-11e8-a36b-7e9ed3de7210)
Dec 10 14:06:04.366: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-brh5l.svc from pod e2e-tests-dns-brh5l/dns-test-a961a3f9-fc84-11e8-a36b-7e9ed3de7210: the server could not find the requested resource (get pods dns-test-a961a3f9-fc84-11e8-a36b-7e9ed3de7210)
Dec 10 14:06:04.370: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-brh5l.svc from pod e2e-tests-dns-brh5l/dns-test-a961a3f9-fc84-11e8-a36b-7e9ed3de7210: the server could not find the requested resource (get pods dns-test-a961a3f9-fc84-11e8-a36b-7e9ed3de7210)
Dec 10 14:06:04.395: INFO: Lookups using e2e-tests-dns-brh5l/dns-test-a961a3f9-fc84-11e8-a36b-7e9ed3de7210 failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_tcp@dns-test-service.e2e-tests-dns-brh5l wheezy_tcp@dns-test-service.e2e-tests-dns-brh5l.svc wheezy_udp@_http._tcp.dns-test-service.e2e-tests-dns-brh5l.svc wheezy_tcp@_http._tcp.dns-test-service.e2e-tests-dns-brh5l.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.e2e-tests-dns-brh5l jessie_tcp@dns-test-service.e2e-tests-dns-brh5l jessie_udp@dns-test-service.e2e-tests-dns-brh5l.svc jessie_tcp@dns-test-service.e2e-tests-dns-brh5l.svc jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-brh5l.svc jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-brh5l.svc]

Dec 10 14:06:14.394: INFO: DNS probes using e2e-tests-dns-brh5l/dns-test-a961a3f9-fc84-11e8-a36b-7e9ed3de7210 succeeded

STEP: deleting the pod
STEP: deleting the test service
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 10 14:06:14.459: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-dns-brh5l" for this suite.
Dec 10 14:06:20.480: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 14:06:20.495: INFO: namespace: e2e-tests-dns-brh5l, resource: bindings, ignored listing per whitelist
Dec 10 14:06:20.595: INFO: namespace e2e-tests-dns-brh5l deletion completed in 6.130908698s

• [SLOW TEST:46.437 seconds]
[sig-network] DNS
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[k8s.io] Probing container 
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 10 14:06:20.596: INFO: >>> kubeConfig: /tmp/kubeconfig-578738756
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Dec 10 14:06:38.683: INFO: Container started at 2018-12-10 14:06:21 +0000 UTC, pod became ready at 2018-12-10 14:06:38 +0000 UTC
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 10 14:06:38.684: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-l26pw" for this suite.
Dec 10 14:07:00.703: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 14:07:00.768: INFO: namespace: e2e-tests-container-probe-l26pw, resource: bindings, ignored listing per whitelist
Dec 10 14:07:00.807: INFO: namespace e2e-tests-container-probe-l26pw deletion completed in 22.118589961s

• [SLOW TEST:40.211 seconds]
[k8s.io] Probing container
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl version 
  should check is all data is printed  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 10 14:07:00.807: INFO: >>> kubeConfig: /tmp/kubeconfig-578738756
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should check is all data is printed  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Dec 10 14:07:00.875: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-578738756 version'
Dec 10 14:07:00.944: INFO: stderr: ""
Dec 10 14:07:00.944: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"12\", GitVersion:\"v1.12.1\", GitCommit:\"4ed3216f3ec431b140b1d899130a69fc671678f4\", GitTreeState:\"clean\", BuildDate:\"2018-10-05T16:46:06Z\", GoVersion:\"go1.10.4\", Compiler:\"gc\", Platform:\"linux/amd64\"}\nServer Version: version.Info{Major:\"1\", Minor:\"12\", GitVersion:\"v1.12.3\", GitCommit:\"435f92c719f279a3a67808c80521ea17d5715c66\", GitTreeState:\"clean\", BuildDate:\"2018-11-26T12:46:57Z\", GoVersion:\"go1.10.4\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 10 14:07:00.944: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-8qf5m" for this suite.
Dec 10 14:07:06.964: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 14:07:07.069: INFO: namespace: e2e-tests-kubectl-8qf5m, resource: bindings, ignored listing per whitelist
Dec 10 14:07:07.072: INFO: namespace e2e-tests-kubectl-8qf5m deletion completed in 6.123349176s

• [SLOW TEST:6.265 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl version
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should check is all data is printed  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 10 14:07:07.073: INFO: >>> kubeConfig: /tmp/kubeconfig-578738756
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Dec 10 14:07:07.149: INFO: Waiting up to 5m0s for pod "downwardapi-volume-e0bf654b-fc84-11e8-a36b-7e9ed3de7210" in namespace "e2e-tests-downward-api-44lh7" to be "success or failure"
Dec 10 14:07:07.161: INFO: Pod "downwardapi-volume-e0bf654b-fc84-11e8-a36b-7e9ed3de7210": Phase="Pending", Reason="", readiness=false. Elapsed: 11.728072ms
Dec 10 14:07:09.171: INFO: Pod "downwardapi-volume-e0bf654b-fc84-11e8-a36b-7e9ed3de7210": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.022233071s
STEP: Saw pod success
Dec 10 14:07:09.171: INFO: Pod "downwardapi-volume-e0bf654b-fc84-11e8-a36b-7e9ed3de7210" satisfied condition "success or failure"
Dec 10 14:07:09.177: INFO: Trying to get logs from node conformance-cluster1-k8s-node-1 pod downwardapi-volume-e0bf654b-fc84-11e8-a36b-7e9ed3de7210 container client-container: <nil>
STEP: delete the pod
Dec 10 14:07:09.207: INFO: Waiting for pod downwardapi-volume-e0bf654b-fc84-11e8-a36b-7e9ed3de7210 to disappear
Dec 10 14:07:09.211: INFO: Pod downwardapi-volume-e0bf654b-fc84-11e8-a36b-7e9ed3de7210 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 10 14:07:09.211: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-44lh7" for this suite.
Dec 10 14:07:15.231: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 14:07:15.331: INFO: namespace: e2e-tests-downward-api-44lh7, resource: bindings, ignored listing per whitelist
Dec 10 14:07:15.337: INFO: namespace e2e-tests-downward-api-44lh7 deletion completed in 6.121136612s

• [SLOW TEST:8.264 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-cli] Kubectl client [k8s.io] Guestbook application 
  should create and stop a working application  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 10 14:07:15.337: INFO: >>> kubeConfig: /tmp/kubeconfig-578738756
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should create and stop a working application  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating all guestbook components
Dec 10 14:07:15.416: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-slave
  labels:
    app: redis
    role: slave
    tier: backend
spec:
  ports:
  - port: 6379
  selector:
    app: redis
    role: slave
    tier: backend

Dec 10 14:07:15.416: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-578738756 create -f - --namespace=e2e-tests-kubectl-26z27'
Dec 10 14:07:15.696: INFO: stderr: ""
Dec 10 14:07:15.696: INFO: stdout: "service/redis-slave created\n"
Dec 10 14:07:15.696: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-master
  labels:
    app: redis
    role: master
    tier: backend
spec:
  ports:
  - port: 6379
    targetPort: 6379
  selector:
    app: redis
    role: master
    tier: backend

Dec 10 14:07:15.696: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-578738756 create -f - --namespace=e2e-tests-kubectl-26z27'
Dec 10 14:07:15.882: INFO: stderr: ""
Dec 10 14:07:15.882: INFO: stdout: "service/redis-master created\n"
Dec 10 14:07:15.882: INFO: apiVersion: v1
kind: Service
metadata:
  name: frontend
  labels:
    app: guestbook
    tier: frontend
spec:
  # if your cluster supports it, uncomment the following to automatically create
  # an external load-balanced IP for the frontend service.
  # type: LoadBalancer
  ports:
  - port: 80
  selector:
    app: guestbook
    tier: frontend

Dec 10 14:07:15.882: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-578738756 create -f - --namespace=e2e-tests-kubectl-26z27'
Dec 10 14:07:16.080: INFO: stderr: ""
Dec 10 14:07:16.080: INFO: stdout: "service/frontend created\n"
Dec 10 14:07:16.080: INFO: apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: frontend
spec:
  replicas: 3
  template:
    metadata:
      labels:
        app: guestbook
        tier: frontend
    spec:
      containers:
      - name: php-redis
        image: gcr.io/google-samples/gb-frontend:v6
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access environment variables to find service host
          # info, comment out the 'value: dns' line above, and uncomment the
          # line below:
          # value: env
        ports:
        - containerPort: 80

Dec 10 14:07:16.080: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-578738756 create -f - --namespace=e2e-tests-kubectl-26z27'
Dec 10 14:07:16.274: INFO: stderr: ""
Dec 10 14:07:16.274: INFO: stdout: "deployment.extensions/frontend created\n"
Dec 10 14:07:16.274: INFO: apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: redis-master
spec:
  replicas: 1
  template:
    metadata:
      labels:
        app: redis
        role: master
        tier: backend
    spec:
      containers:
      - name: master
        image: gcr.io/kubernetes-e2e-test-images/redis:1.0
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        ports:
        - containerPort: 6379

Dec 10 14:07:16.274: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-578738756 create -f - --namespace=e2e-tests-kubectl-26z27'
Dec 10 14:07:16.465: INFO: stderr: ""
Dec 10 14:07:16.465: INFO: stdout: "deployment.extensions/redis-master created\n"
Dec 10 14:07:16.466: INFO: apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: redis-slave
spec:
  replicas: 2
  template:
    metadata:
      labels:
        app: redis
        role: slave
        tier: backend
    spec:
      containers:
      - name: slave
        image: gcr.io/google-samples/gb-redisslave:v3
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access an environment variable to find the master
          # service's host, comment out the 'value: dns' line above, and
          # uncomment the line below:
          # value: env
        ports:
        - containerPort: 6379

Dec 10 14:07:16.466: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-578738756 create -f - --namespace=e2e-tests-kubectl-26z27'
Dec 10 14:07:16.693: INFO: stderr: ""
Dec 10 14:07:16.693: INFO: stdout: "deployment.extensions/redis-slave created\n"
STEP: validating guestbook app
Dec 10 14:07:16.693: INFO: Waiting for all frontend pods to be Running.
Dec 10 14:07:36.744: INFO: Waiting for frontend to serve content.
Dec 10 14:07:41.307: INFO: Trying to add a new entry to the guestbook.
Dec 10 14:07:41.323: INFO: Verifying that added entry can be retrieved.
STEP: using delete to clean up resources
Dec 10 14:07:41.339: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-578738756 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-26z27'
Dec 10 14:07:41.471: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Dec 10 14:07:41.471: INFO: stdout: "service \"redis-slave\" force deleted\n"
STEP: using delete to clean up resources
Dec 10 14:07:41.471: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-578738756 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-26z27'
Dec 10 14:07:41.599: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Dec 10 14:07:41.599: INFO: stdout: "service \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
Dec 10 14:07:41.599: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-578738756 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-26z27'
Dec 10 14:07:41.748: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Dec 10 14:07:41.748: INFO: stdout: "service \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Dec 10 14:07:41.748: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-578738756 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-26z27'
Dec 10 14:07:41.901: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Dec 10 14:07:41.901: INFO: stdout: "deployment.extensions \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Dec 10 14:07:41.902: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-578738756 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-26z27'
Dec 10 14:07:42.040: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Dec 10 14:07:42.040: INFO: stdout: "deployment.extensions \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
Dec 10 14:07:42.040: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-578738756 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-26z27'
Dec 10 14:07:42.265: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Dec 10 14:07:42.265: INFO: stdout: "deployment.extensions \"redis-slave\" force deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 10 14:07:42.265: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-26z27" for this suite.
Dec 10 14:08:22.303: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 14:08:22.385: INFO: namespace: e2e-tests-kubectl-26z27, resource: bindings, ignored listing per whitelist
Dec 10 14:08:22.436: INFO: namespace e2e-tests-kubectl-26z27 deletion completed in 40.16397954s

• [SLOW TEST:67.099 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Guestbook application
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create and stop a working application  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] Projected 
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 10 14:08:22.436: INFO: >>> kubeConfig: /tmp/kubeconfig-578738756
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-projected-all-test-volume-0dab775a-fc85-11e8-a36b-7e9ed3de7210
STEP: Creating secret with name secret-projected-all-test-volume-0dab774a-fc85-11e8-a36b-7e9ed3de7210
STEP: Creating a pod to test Check all projections for projected volume plugin
Dec 10 14:08:22.519: INFO: Waiting up to 5m0s for pod "projected-volume-0dab7717-fc85-11e8-a36b-7e9ed3de7210" in namespace "e2e-tests-projected-pmmfz" to be "success or failure"
Dec 10 14:08:22.525: INFO: Pod "projected-volume-0dab7717-fc85-11e8-a36b-7e9ed3de7210": Phase="Pending", Reason="", readiness=false. Elapsed: 6.252656ms
Dec 10 14:08:24.530: INFO: Pod "projected-volume-0dab7717-fc85-11e8-a36b-7e9ed3de7210": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.011033551s
STEP: Saw pod success
Dec 10 14:08:24.530: INFO: Pod "projected-volume-0dab7717-fc85-11e8-a36b-7e9ed3de7210" satisfied condition "success or failure"
Dec 10 14:08:24.534: INFO: Trying to get logs from node conformance-cluster1-k8s-node-2 pod projected-volume-0dab7717-fc85-11e8-a36b-7e9ed3de7210 container projected-all-volume-test: <nil>
STEP: delete the pod
Dec 10 14:08:24.560: INFO: Waiting for pod projected-volume-0dab7717-fc85-11e8-a36b-7e9ed3de7210 to disappear
Dec 10 14:08:24.564: INFO: Pod projected-volume-0dab7717-fc85-11e8-a36b-7e9ed3de7210 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 10 14:08:24.564: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-pmmfz" for this suite.
Dec 10 14:08:30.583: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 14:08:30.618: INFO: namespace: e2e-tests-projected-pmmfz, resource: bindings, ignored listing per whitelist
Dec 10 14:08:30.687: INFO: namespace e2e-tests-projected-pmmfz deletion completed in 6.118417386s

• [SLOW TEST:8.251 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] Downward API volume 
  should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 10 14:08:30.687: INFO: >>> kubeConfig: /tmp/kubeconfig-578738756
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Dec 10 14:08:30.765: INFO: Waiting up to 5m0s for pod "downwardapi-volume-12969149-fc85-11e8-a36b-7e9ed3de7210" in namespace "e2e-tests-downward-api-qqcmn" to be "success or failure"
Dec 10 14:08:30.772: INFO: Pod "downwardapi-volume-12969149-fc85-11e8-a36b-7e9ed3de7210": Phase="Pending", Reason="", readiness=false. Elapsed: 6.817646ms
Dec 10 14:08:32.782: INFO: Pod "downwardapi-volume-12969149-fc85-11e8-a36b-7e9ed3de7210": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.017605437s
STEP: Saw pod success
Dec 10 14:08:32.782: INFO: Pod "downwardapi-volume-12969149-fc85-11e8-a36b-7e9ed3de7210" satisfied condition "success or failure"
Dec 10 14:08:32.786: INFO: Trying to get logs from node conformance-cluster1-k8s-node-2 pod downwardapi-volume-12969149-fc85-11e8-a36b-7e9ed3de7210 container client-container: <nil>
STEP: delete the pod
Dec 10 14:08:32.811: INFO: Waiting for pod downwardapi-volume-12969149-fc85-11e8-a36b-7e9ed3de7210 to disappear
Dec 10 14:08:32.814: INFO: Pod downwardapi-volume-12969149-fc85-11e8-a36b-7e9ed3de7210 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 10 14:08:32.815: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-qqcmn" for this suite.
Dec 10 14:08:38.835: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 14:08:38.930: INFO: namespace: e2e-tests-downward-api-qqcmn, resource: bindings, ignored listing per whitelist
Dec 10 14:08:38.948: INFO: namespace e2e-tests-downward-api-qqcmn deletion completed in 6.128869458s

• [SLOW TEST:8.261 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 10 14:08:38.948: INFO: >>> kubeConfig: /tmp/kubeconfig-578738756
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-1783c88f-fc85-11e8-a36b-7e9ed3de7210
STEP: Creating a pod to test consume secrets
Dec 10 14:08:39.035: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-17851f59-fc85-11e8-a36b-7e9ed3de7210" in namespace "e2e-tests-projected-2prrg" to be "success or failure"
Dec 10 14:08:39.040: INFO: Pod "pod-projected-secrets-17851f59-fc85-11e8-a36b-7e9ed3de7210": Phase="Pending", Reason="", readiness=false. Elapsed: 4.935685ms
Dec 10 14:08:41.044: INFO: Pod "pod-projected-secrets-17851f59-fc85-11e8-a36b-7e9ed3de7210": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009274581s
STEP: Saw pod success
Dec 10 14:08:41.045: INFO: Pod "pod-projected-secrets-17851f59-fc85-11e8-a36b-7e9ed3de7210" satisfied condition "success or failure"
Dec 10 14:08:41.048: INFO: Trying to get logs from node conformance-cluster1-k8s-node-2 pod pod-projected-secrets-17851f59-fc85-11e8-a36b-7e9ed3de7210 container projected-secret-volume-test: <nil>
STEP: delete the pod
Dec 10 14:08:41.073: INFO: Waiting for pod pod-projected-secrets-17851f59-fc85-11e8-a36b-7e9ed3de7210 to disappear
Dec 10 14:08:41.076: INFO: Pod pod-projected-secrets-17851f59-fc85-11e8-a36b-7e9ed3de7210 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 10 14:08:41.076: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-2prrg" for this suite.
Dec 10 14:08:47.095: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 14:08:47.189: INFO: namespace: e2e-tests-projected-2prrg, resource: bindings, ignored listing per whitelist
Dec 10 14:08:47.204: INFO: namespace e2e-tests-projected-2prrg deletion completed in 6.123221928s

• [SLOW TEST:8.255 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 10 14:08:47.204: INFO: >>> kubeConfig: /tmp/kubeconfig-578738756
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test override arguments
Dec 10 14:08:47.275: INFO: Waiting up to 5m0s for pod "client-containers-1c6e70d5-fc85-11e8-a36b-7e9ed3de7210" in namespace "e2e-tests-containers-bkpfb" to be "success or failure"
Dec 10 14:08:47.278: INFO: Pod "client-containers-1c6e70d5-fc85-11e8-a36b-7e9ed3de7210": Phase="Pending", Reason="", readiness=false. Elapsed: 3.380389ms
Dec 10 14:08:49.282: INFO: Pod "client-containers-1c6e70d5-fc85-11e8-a36b-7e9ed3de7210": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007809838s
Dec 10 14:08:51.287: INFO: Pod "client-containers-1c6e70d5-fc85-11e8-a36b-7e9ed3de7210": Phase="Pending", Reason="", readiness=false. Elapsed: 4.01202599s
Dec 10 14:08:53.296: INFO: Pod "client-containers-1c6e70d5-fc85-11e8-a36b-7e9ed3de7210": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.021374764s
STEP: Saw pod success
Dec 10 14:08:53.296: INFO: Pod "client-containers-1c6e70d5-fc85-11e8-a36b-7e9ed3de7210" satisfied condition "success or failure"
Dec 10 14:08:53.299: INFO: Trying to get logs from node conformance-cluster1-k8s-node-2 pod client-containers-1c6e70d5-fc85-11e8-a36b-7e9ed3de7210 container test-container: <nil>
STEP: delete the pod
Dec 10 14:08:53.324: INFO: Waiting for pod client-containers-1c6e70d5-fc85-11e8-a36b-7e9ed3de7210 to disappear
Dec 10 14:08:53.327: INFO: Pod client-containers-1c6e70d5-fc85-11e8-a36b-7e9ed3de7210 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 10 14:08:53.327: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-bkpfb" for this suite.
Dec 10 14:08:59.345: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 14:08:59.352: INFO: namespace: e2e-tests-containers-bkpfb, resource: bindings, ignored listing per whitelist
Dec 10 14:08:59.455: INFO: namespace e2e-tests-containers-bkpfb deletion completed in 6.123710483s

• [SLOW TEST:12.252 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 10 14:08:59.457: INFO: >>> kubeConfig: /tmp/kubeconfig-578738756
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0644 on node default medium
Dec 10 14:08:59.532: INFO: Waiting up to 5m0s for pod "pod-23bcd711-fc85-11e8-a36b-7e9ed3de7210" in namespace "e2e-tests-emptydir-lxmch" to be "success or failure"
Dec 10 14:08:59.536: INFO: Pod "pod-23bcd711-fc85-11e8-a36b-7e9ed3de7210": Phase="Pending", Reason="", readiness=false. Elapsed: 3.386137ms
Dec 10 14:09:01.540: INFO: Pod "pod-23bcd711-fc85-11e8-a36b-7e9ed3de7210": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007864565s
STEP: Saw pod success
Dec 10 14:09:01.540: INFO: Pod "pod-23bcd711-fc85-11e8-a36b-7e9ed3de7210" satisfied condition "success or failure"
Dec 10 14:09:01.544: INFO: Trying to get logs from node conformance-cluster1-k8s-node-2 pod pod-23bcd711-fc85-11e8-a36b-7e9ed3de7210 container test-container: <nil>
STEP: delete the pod
Dec 10 14:09:01.569: INFO: Waiting for pod pod-23bcd711-fc85-11e8-a36b-7e9ed3de7210 to disappear
Dec 10 14:09:01.573: INFO: Pod pod-23bcd711-fc85-11e8-a36b-7e9ed3de7210 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 10 14:09:01.573: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-lxmch" for this suite.
Dec 10 14:09:07.592: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 14:09:07.680: INFO: namespace: e2e-tests-emptydir-lxmch, resource: bindings, ignored listing per whitelist
Dec 10 14:09:07.701: INFO: namespace e2e-tests-emptydir-lxmch deletion completed in 6.124275281s

• [SLOW TEST:8.245 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should provide secure master service  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 10 14:09:07.702: INFO: >>> kubeConfig: /tmp/kubeconfig-578738756
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:83
[It] should provide secure master service  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 10 14:09:07.763: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-services-kwwsn" for this suite.
Dec 10 14:09:13.788: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 14:09:13.828: INFO: namespace: e2e-tests-services-kwwsn, resource: bindings, ignored listing per whitelist
Dec 10 14:09:13.901: INFO: namespace e2e-tests-services-kwwsn deletion completed in 6.133623043s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:88

• [SLOW TEST:6.199 seconds]
[sig-network] Services
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide secure master service  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 10 14:09:13.903: INFO: >>> kubeConfig: /tmp/kubeconfig-578738756
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-http in namespace e2e-tests-container-probe-h6pwt
Dec 10 14:09:19.999: INFO: Started pod liveness-http in namespace e2e-tests-container-probe-h6pwt
STEP: checking the pod's current state and verifying that restartCount is present
Dec 10 14:09:20.002: INFO: Initial restart count of pod liveness-http is 0
Dec 10 14:09:38.056: INFO: Restart count of pod e2e-tests-container-probe-h6pwt/liveness-http is now 1 (18.054121341s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 10 14:09:38.076: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-h6pwt" for this suite.
Dec 10 14:09:44.102: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 14:09:44.201: INFO: namespace: e2e-tests-container-probe-h6pwt, resource: bindings, ignored listing per whitelist
Dec 10 14:09:44.210: INFO: namespace e2e-tests-container-probe-h6pwt deletion completed in 6.130106781s

• [SLOW TEST:30.308 seconds]
[k8s.io] Probing container
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 10 14:09:44.211: INFO: >>> kubeConfig: /tmp/kubeconfig-578738756
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-3e6ac9ed-fc85-11e8-a36b-7e9ed3de7210
STEP: Creating a pod to test consume configMaps
Dec 10 14:09:44.299: INFO: Waiting up to 5m0s for pod "pod-configmaps-3e6bd012-fc85-11e8-a36b-7e9ed3de7210" in namespace "e2e-tests-configmap-8w2q9" to be "success or failure"
Dec 10 14:09:44.308: INFO: Pod "pod-configmaps-3e6bd012-fc85-11e8-a36b-7e9ed3de7210": Phase="Pending", Reason="", readiness=false. Elapsed: 9.919581ms
Dec 10 14:09:46.314: INFO: Pod "pod-configmaps-3e6bd012-fc85-11e8-a36b-7e9ed3de7210": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.015296396s
STEP: Saw pod success
Dec 10 14:09:46.314: INFO: Pod "pod-configmaps-3e6bd012-fc85-11e8-a36b-7e9ed3de7210" satisfied condition "success or failure"
Dec 10 14:09:46.317: INFO: Trying to get logs from node conformance-cluster1-k8s-node-2 pod pod-configmaps-3e6bd012-fc85-11e8-a36b-7e9ed3de7210 container configmap-volume-test: <nil>
STEP: delete the pod
Dec 10 14:09:46.348: INFO: Waiting for pod pod-configmaps-3e6bd012-fc85-11e8-a36b-7e9ed3de7210 to disappear
Dec 10 14:09:46.351: INFO: Pod pod-configmaps-3e6bd012-fc85-11e8-a36b-7e9ed3de7210 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 10 14:09:46.351: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-8w2q9" for this suite.
Dec 10 14:09:52.368: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 14:09:52.460: INFO: namespace: e2e-tests-configmap-8w2q9, resource: bindings, ignored listing per whitelist
Dec 10 14:09:52.479: INFO: namespace e2e-tests-configmap-8w2q9 deletion completed in 6.124488235s

• [SLOW TEST:8.269 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run --rm job 
  should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 10 14:09:52.479: INFO: >>> kubeConfig: /tmp/kubeconfig-578738756
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: executing a command with run --rm and attach with stdin
Dec 10 14:09:52.539: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-578738756 --namespace=e2e-tests-kubectl-qxh4c run e2e-test-rm-busybox-job --image=docker.io/library/busybox:1.29 --rm=true --generator=job/v1 --restart=OnFailure --attach=true --stdin -- sh -c cat && echo 'stdin closed''
Dec 10 14:09:54.970: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl create instead.\nIf you don't see a command prompt, try pressing enter.\n"
Dec 10 14:09:54.970: INFO: stdout: "abcd1234stdin closed\njob.batch \"e2e-test-rm-busybox-job\" deleted\n"
STEP: verifying the job e2e-test-rm-busybox-job was deleted
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 10 14:09:56.984: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-qxh4c" for this suite.
Dec 10 14:10:03.002: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 14:10:03.042: INFO: namespace: e2e-tests-kubectl-qxh4c, resource: bindings, ignored listing per whitelist
Dec 10 14:10:03.112: INFO: namespace e2e-tests-kubectl-qxh4c deletion completed in 6.124637024s

• [SLOW TEST:10.633 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run --rm job
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create a job from an image, then delete the job  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-storage] Projected 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 10 14:10:03.114: INFO: >>> kubeConfig: /tmp/kubeconfig-578738756
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating the pod
Dec 10 14:10:05.746: INFO: Successfully updated pod "annotationupdate49b03f89-fc85-11e8-a36b-7e9ed3de7210"
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 10 14:10:07.772: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-2lt94" for this suite.
Dec 10 14:10:29.797: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 14:10:29.856: INFO: namespace: e2e-tests-projected-2lt94, resource: bindings, ignored listing per whitelist
Dec 10 14:10:29.900: INFO: namespace e2e-tests-projected-2lt94 deletion completed in 22.123623099s

• [SLOW TEST:26.786 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-api-machinery] Downward API 
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 10 14:10:29.900: INFO: >>> kubeConfig: /tmp/kubeconfig-578738756
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Dec 10 14:10:29.980: INFO: Waiting up to 5m0s for pod "downward-api-59a5c6e8-fc85-11e8-a36b-7e9ed3de7210" in namespace "e2e-tests-downward-api-q6ql7" to be "success or failure"
Dec 10 14:10:29.983: INFO: Pod "downward-api-59a5c6e8-fc85-11e8-a36b-7e9ed3de7210": Phase="Pending", Reason="", readiness=false. Elapsed: 3.257878ms
Dec 10 14:10:31.987: INFO: Pod "downward-api-59a5c6e8-fc85-11e8-a36b-7e9ed3de7210": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007822681s
Dec 10 14:10:33.993: INFO: Pod "downward-api-59a5c6e8-fc85-11e8-a36b-7e9ed3de7210": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013661955s
STEP: Saw pod success
Dec 10 14:10:33.993: INFO: Pod "downward-api-59a5c6e8-fc85-11e8-a36b-7e9ed3de7210" satisfied condition "success or failure"
Dec 10 14:10:33.997: INFO: Trying to get logs from node conformance-cluster1-k8s-node-1 pod downward-api-59a5c6e8-fc85-11e8-a36b-7e9ed3de7210 container dapi-container: <nil>
STEP: delete the pod
Dec 10 14:10:34.029: INFO: Waiting for pod downward-api-59a5c6e8-fc85-11e8-a36b-7e9ed3de7210 to disappear
Dec 10 14:10:34.033: INFO: Pod downward-api-59a5c6e8-fc85-11e8-a36b-7e9ed3de7210 no longer exists
[AfterEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 10 14:10:34.033: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-q6ql7" for this suite.
Dec 10 14:10:40.057: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 14:10:40.105: INFO: namespace: e2e-tests-downward-api-q6ql7, resource: bindings, ignored listing per whitelist
Dec 10 14:10:40.168: INFO: namespace e2e-tests-downward-api-q6ql7 deletion completed in 6.130848622s

• [SLOW TEST:10.267 seconds]
[sig-api-machinery] Downward API
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-apps] ReplicaSet 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 10 14:10:40.168: INFO: >>> kubeConfig: /tmp/kubeconfig-578738756
STEP: Building a namespace api object, basename replicaset
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Dec 10 14:10:40.238: INFO: Creating ReplicaSet my-hostname-basic-5fc4d927-fc85-11e8-a36b-7e9ed3de7210
Dec 10 14:10:40.252: INFO: Pod name my-hostname-basic-5fc4d927-fc85-11e8-a36b-7e9ed3de7210: Found 0 pods out of 1
Dec 10 14:10:45.258: INFO: Pod name my-hostname-basic-5fc4d927-fc85-11e8-a36b-7e9ed3de7210: Found 1 pods out of 1
Dec 10 14:10:45.258: INFO: Ensuring a pod for ReplicaSet "my-hostname-basic-5fc4d927-fc85-11e8-a36b-7e9ed3de7210" is running
Dec 10 14:10:45.262: INFO: Pod "my-hostname-basic-5fc4d927-fc85-11e8-a36b-7e9ed3de7210-m4qqt" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2018-12-10 14:10:40 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2018-12-10 14:10:42 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2018-12-10 14:10:42 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2018-12-10 14:10:40 +0000 UTC Reason: Message:}])
Dec 10 14:10:45.262: INFO: Trying to dial the pod
Dec 10 14:10:50.282: INFO: Controller my-hostname-basic-5fc4d927-fc85-11e8-a36b-7e9ed3de7210: Got expected result from replica 1 [my-hostname-basic-5fc4d927-fc85-11e8-a36b-7e9ed3de7210-m4qqt]: "my-hostname-basic-5fc4d927-fc85-11e8-a36b-7e9ed3de7210-m4qqt", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 10 14:10:50.282: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-replicaset-frfrj" for this suite.
Dec 10 14:10:56.299: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 14:10:56.308: INFO: namespace: e2e-tests-replicaset-frfrj, resource: bindings, ignored listing per whitelist
Dec 10 14:10:56.413: INFO: namespace e2e-tests-replicaset-frfrj deletion completed in 6.127412322s

• [SLOW TEST:16.246 seconds]
[sig-apps] ReplicaSet
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl expose 
  should create services for rc  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 10 14:10:56.416: INFO: >>> kubeConfig: /tmp/kubeconfig-578738756
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should create services for rc  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating Redis RC
Dec 10 14:10:56.480: INFO: namespace e2e-tests-kubectl-22prn
Dec 10 14:10:56.480: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-578738756 create -f - --namespace=e2e-tests-kubectl-22prn'
Dec 10 14:10:56.683: INFO: stderr: ""
Dec 10 14:10:56.683: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
Dec 10 14:10:57.688: INFO: Selector matched 1 pods for map[app:redis]
Dec 10 14:10:57.688: INFO: Found 0 / 1
Dec 10 14:10:58.688: INFO: Selector matched 1 pods for map[app:redis]
Dec 10 14:10:58.688: INFO: Found 1 / 1
Dec 10 14:10:58.688: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Dec 10 14:10:58.692: INFO: Selector matched 1 pods for map[app:redis]
Dec 10 14:10:58.692: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Dec 10 14:10:58.692: INFO: wait on redis-master startup in e2e-tests-kubectl-22prn 
Dec 10 14:10:58.692: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-578738756 logs redis-master-fnpp6 redis-master --namespace=e2e-tests-kubectl-22prn'
Dec 10 14:10:58.806: INFO: stderr: ""
Dec 10 14:10:58.806: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 10 Dec 14:10:57.873 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 10 Dec 14:10:57.873 # Server started, Redis version 3.2.12\n1:M 10 Dec 14:10:57.873 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 10 Dec 14:10:57.873 * The server is now ready to accept connections on port 6379\n"
STEP: exposing RC
Dec 10 14:10:58.806: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-578738756 expose rc redis-master --name=rm2 --port=1234 --target-port=6379 --namespace=e2e-tests-kubectl-22prn'
Dec 10 14:10:58.937: INFO: stderr: ""
Dec 10 14:10:58.937: INFO: stdout: "service/rm2 exposed\n"
Dec 10 14:10:58.941: INFO: Service rm2 in namespace e2e-tests-kubectl-22prn found.
STEP: exposing service
Dec 10 14:11:00.957: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-578738756 expose service rm2 --name=rm3 --port=2345 --target-port=6379 --namespace=e2e-tests-kubectl-22prn'
Dec 10 14:11:01.062: INFO: stderr: ""
Dec 10 14:11:01.062: INFO: stdout: "service/rm3 exposed\n"
Dec 10 14:11:01.067: INFO: Service rm3 in namespace e2e-tests-kubectl-22prn found.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 10 14:11:03.075: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-22prn" for this suite.
Dec 10 14:11:25.094: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 14:11:25.173: INFO: namespace: e2e-tests-kubectl-22prn, resource: bindings, ignored listing per whitelist
Dec 10 14:11:25.212: INFO: namespace e2e-tests-kubectl-22prn deletion completed in 22.133729118s

• [SLOW TEST:28.797 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl expose
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create services for rc  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-auth] ServiceAccounts 
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 10 14:11:25.214: INFO: >>> kubeConfig: /tmp/kubeconfig-578738756
STEP: Building a namespace api object, basename svcaccounts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should mount an API token into pods  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: getting the auto-created API token
STEP: Creating a pod to test consume service account token
Dec 10 14:11:25.797: INFO: Waiting up to 5m0s for pod "pod-service-account-7aea633f-fc85-11e8-a36b-7e9ed3de7210-75828" in namespace "e2e-tests-svcaccounts-p7fml" to be "success or failure"
Dec 10 14:11:25.803: INFO: Pod "pod-service-account-7aea633f-fc85-11e8-a36b-7e9ed3de7210-75828": Phase="Pending", Reason="", readiness=false. Elapsed: 6.249922ms
Dec 10 14:11:27.808: INFO: Pod "pod-service-account-7aea633f-fc85-11e8-a36b-7e9ed3de7210-75828": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.01110997s
STEP: Saw pod success
Dec 10 14:11:27.808: INFO: Pod "pod-service-account-7aea633f-fc85-11e8-a36b-7e9ed3de7210-75828" satisfied condition "success or failure"
Dec 10 14:11:27.813: INFO: Trying to get logs from node conformance-cluster1-k8s-node-2 pod pod-service-account-7aea633f-fc85-11e8-a36b-7e9ed3de7210-75828 container token-test: <nil>
STEP: delete the pod
Dec 10 14:11:27.841: INFO: Waiting for pod pod-service-account-7aea633f-fc85-11e8-a36b-7e9ed3de7210-75828 to disappear
Dec 10 14:11:27.844: INFO: Pod pod-service-account-7aea633f-fc85-11e8-a36b-7e9ed3de7210-75828 no longer exists
STEP: Creating a pod to test consume service account root CA
Dec 10 14:11:27.852: INFO: Waiting up to 5m0s for pod "pod-service-account-7aea633f-fc85-11e8-a36b-7e9ed3de7210-cnpfj" in namespace "e2e-tests-svcaccounts-p7fml" to be "success or failure"
Dec 10 14:11:27.858: INFO: Pod "pod-service-account-7aea633f-fc85-11e8-a36b-7e9ed3de7210-cnpfj": Phase="Pending", Reason="", readiness=false. Elapsed: 6.016878ms
Dec 10 14:11:29.863: INFO: Pod "pod-service-account-7aea633f-fc85-11e8-a36b-7e9ed3de7210-cnpfj": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010933926s
STEP: Saw pod success
Dec 10 14:11:29.863: INFO: Pod "pod-service-account-7aea633f-fc85-11e8-a36b-7e9ed3de7210-cnpfj" satisfied condition "success or failure"
Dec 10 14:11:29.870: INFO: Trying to get logs from node conformance-cluster1-k8s-node-2 pod pod-service-account-7aea633f-fc85-11e8-a36b-7e9ed3de7210-cnpfj container root-ca-test: <nil>
STEP: delete the pod
Dec 10 14:11:29.903: INFO: Waiting for pod pod-service-account-7aea633f-fc85-11e8-a36b-7e9ed3de7210-cnpfj to disappear
Dec 10 14:11:29.907: INFO: Pod pod-service-account-7aea633f-fc85-11e8-a36b-7e9ed3de7210-cnpfj no longer exists
STEP: Creating a pod to test consume service account namespace
Dec 10 14:11:29.915: INFO: Waiting up to 5m0s for pod "pod-service-account-7aea633f-fc85-11e8-a36b-7e9ed3de7210-shtx4" in namespace "e2e-tests-svcaccounts-p7fml" to be "success or failure"
Dec 10 14:11:29.924: INFO: Pod "pod-service-account-7aea633f-fc85-11e8-a36b-7e9ed3de7210-shtx4": Phase="Pending", Reason="", readiness=false. Elapsed: 8.647051ms
Dec 10 14:11:31.928: INFO: Pod "pod-service-account-7aea633f-fc85-11e8-a36b-7e9ed3de7210-shtx4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.013200033s
STEP: Saw pod success
Dec 10 14:11:31.928: INFO: Pod "pod-service-account-7aea633f-fc85-11e8-a36b-7e9ed3de7210-shtx4" satisfied condition "success or failure"
Dec 10 14:11:31.932: INFO: Trying to get logs from node conformance-cluster1-k8s-node-2 pod pod-service-account-7aea633f-fc85-11e8-a36b-7e9ed3de7210-shtx4 container namespace-test: <nil>
STEP: delete the pod
Dec 10 14:11:31.956: INFO: Waiting for pod pod-service-account-7aea633f-fc85-11e8-a36b-7e9ed3de7210-shtx4 to disappear
Dec 10 14:11:31.960: INFO: Pod pod-service-account-7aea633f-fc85-11e8-a36b-7e9ed3de7210-shtx4 no longer exists
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 10 14:11:31.960: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-svcaccounts-p7fml" for this suite.
Dec 10 14:11:37.979: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 14:11:38.050: INFO: namespace: e2e-tests-svcaccounts-p7fml, resource: bindings, ignored listing per whitelist
Dec 10 14:11:38.089: INFO: namespace e2e-tests-svcaccounts-p7fml deletion completed in 6.123853498s

• [SLOW TEST:12.875 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:22
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] version v1
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 10 14:11:38.089: INFO: >>> kubeConfig: /tmp/kubeconfig-578738756
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: starting an echo server on multiple ports
STEP: creating replication controller proxy-service-hx9wb in namespace e2e-tests-proxy-gdbqh
I1210 14:11:38.176577      15 runners.go:180] Created replication controller with name: proxy-service-hx9wb, namespace: e2e-tests-proxy-gdbqh, replica count: 1
I1210 14:11:39.227820      15 runners.go:180] proxy-service-hx9wb Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1210 14:11:40.227992      15 runners.go:180] proxy-service-hx9wb Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1210 14:11:41.228156      15 runners.go:180] proxy-service-hx9wb Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1210 14:11:42.228297      15 runners.go:180] proxy-service-hx9wb Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1210 14:11:43.228481      15 runners.go:180] proxy-service-hx9wb Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Dec 10 14:11:43.232: INFO: setup took 5.076959923s, starting test cases
STEP: running 16 cases, 20 attempts per case, 320 total attempts
Dec 10 14:11:43.242: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-gdbqh/pods/proxy-service-hx9wb-f7qd4:162/proxy/: bar (200; 9.424817ms)
Dec 10 14:11:43.246: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-gdbqh/pods/http:proxy-service-hx9wb-f7qd4:162/proxy/: bar (200; 13.689836ms)
Dec 10 14:11:43.247: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-gdbqh/pods/proxy-service-hx9wb-f7qd4:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-gdbqh/pods/proxy-service-hx9wb-f7qd4:1080/proxy/rewri... (200; 13.891748ms)
Dec 10 14:11:43.247: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-gdbqh/pods/proxy-service-hx9wb-f7qd4/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-gdbqh/pods/proxy-service-hx9wb-f7qd4/proxy/rewriteme"... (200; 14.845205ms)
Dec 10 14:11:43.247: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-gdbqh/pods/http:proxy-service-hx9wb-f7qd4:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-gdbqh/pods/http:proxy-service-hx9wb-f7qd4:1080/proxy/... (200; 14.463021ms)
Dec 10 14:11:43.247: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-gdbqh/pods/http:proxy-service-hx9wb-f7qd4:160/proxy/: foo (200; 14.614387ms)
Dec 10 14:11:43.247: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-gdbqh/pods/proxy-service-hx9wb-f7qd4:160/proxy/: foo (200; 14.484696ms)
Dec 10 14:11:43.249: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-gdbqh/services/http:proxy-service-hx9wb:portname1/proxy/: foo (200; 16.422751ms)
Dec 10 14:11:43.249: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-gdbqh/services/proxy-service-hx9wb:portname1/proxy/: foo (200; 16.630786ms)
Dec 10 14:11:43.250: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-gdbqh/pods/https:proxy-service-hx9wb-f7qd4:462/proxy/: tls qux (200; 17.309439ms)
Dec 10 14:11:43.251: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-gdbqh/pods/https:proxy-service-hx9wb-f7qd4:460/proxy/: tls baz (200; 18.875122ms)
Dec 10 14:11:43.251: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-gdbqh/services/https:proxy-service-hx9wb:tlsportname2/proxy/: tls qux (200; 18.522859ms)
Dec 10 14:11:43.252: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-gdbqh/services/http:proxy-service-hx9wb:portname2/proxy/: bar (200; 18.824379ms)
Dec 10 14:11:43.252: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-gdbqh/services/proxy-service-hx9wb:portname2/proxy/: bar (200; 19.076777ms)
Dec 10 14:11:43.252: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-gdbqh/services/https:proxy-service-hx9wb:tlsportname1/proxy/: tls baz (200; 19.133861ms)
Dec 10 14:11:43.253: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-gdbqh/pods/https:proxy-service-hx9wb-f7qd4:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-gdbqh/pods/https:proxy-service-hx9wb-f7qd4:443/proxy/... (200; 20.474362ms)
Dec 10 14:11:43.259: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-gdbqh/pods/https:proxy-service-hx9wb-f7qd4:462/proxy/: tls qux (200; 5.824541ms)
Dec 10 14:11:43.263: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-gdbqh/pods/proxy-service-hx9wb-f7qd4:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-gdbqh/pods/proxy-service-hx9wb-f7qd4:1080/proxy/rewri... (200; 9.162756ms)
Dec 10 14:11:43.264: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-gdbqh/pods/proxy-service-hx9wb-f7qd4/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-gdbqh/pods/proxy-service-hx9wb-f7qd4/proxy/rewriteme"... (200; 9.758843ms)
Dec 10 14:11:43.264: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-gdbqh/pods/http:proxy-service-hx9wb-f7qd4:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-gdbqh/pods/http:proxy-service-hx9wb-f7qd4:1080/proxy/... (200; 9.331944ms)
Dec 10 14:11:43.264: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-gdbqh/pods/https:proxy-service-hx9wb-f7qd4:460/proxy/: tls baz (200; 10.006604ms)
Dec 10 14:11:43.264: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-gdbqh/pods/http:proxy-service-hx9wb-f7qd4:162/proxy/: bar (200; 10.142521ms)
Dec 10 14:11:43.265: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-gdbqh/pods/http:proxy-service-hx9wb-f7qd4:160/proxy/: foo (200; 10.794867ms)
Dec 10 14:11:43.265: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-gdbqh/pods/https:proxy-service-hx9wb-f7qd4:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-gdbqh/pods/https:proxy-service-hx9wb-f7qd4:443/proxy/... (200; 11.318027ms)
Dec 10 14:11:43.267: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-gdbqh/services/https:proxy-service-hx9wb:tlsportname2/proxy/: tls qux (200; 12.67421ms)
Dec 10 14:11:43.267: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-gdbqh/pods/proxy-service-hx9wb-f7qd4:160/proxy/: foo (200; 11.996453ms)
Dec 10 14:11:43.268: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-gdbqh/services/proxy-service-hx9wb:portname2/proxy/: bar (200; 13.649932ms)
Dec 10 14:11:43.268: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-gdbqh/pods/proxy-service-hx9wb-f7qd4:162/proxy/: bar (200; 14.88538ms)
Dec 10 14:11:43.270: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-gdbqh/services/proxy-service-hx9wb:portname1/proxy/: foo (200; 15.792215ms)
Dec 10 14:11:43.270: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-gdbqh/services/https:proxy-service-hx9wb:tlsportname1/proxy/: tls baz (200; 16.07552ms)
Dec 10 14:11:43.271: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-gdbqh/services/http:proxy-service-hx9wb:portname1/proxy/: foo (200; 15.658263ms)
Dec 10 14:11:43.273: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-gdbqh/services/http:proxy-service-hx9wb:portname2/proxy/: bar (200; 17.836123ms)
Dec 10 14:11:43.277: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-gdbqh/pods/proxy-service-hx9wb-f7qd4:162/proxy/: bar (200; 4.834919ms)
Dec 10 14:11:43.280: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-gdbqh/pods/http:proxy-service-hx9wb-f7qd4:162/proxy/: bar (200; 7.225494ms)
Dec 10 14:11:43.280: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-gdbqh/pods/https:proxy-service-hx9wb-f7qd4:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-gdbqh/pods/https:proxy-service-hx9wb-f7qd4:443/proxy/... (200; 7.530228ms)
Dec 10 14:11:43.282: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-gdbqh/pods/http:proxy-service-hx9wb-f7qd4:160/proxy/: foo (200; 8.792907ms)
Dec 10 14:11:43.283: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-gdbqh/pods/http:proxy-service-hx9wb-f7qd4:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-gdbqh/pods/http:proxy-service-hx9wb-f7qd4:1080/proxy/... (200; 9.595939ms)
Dec 10 14:11:43.283: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-gdbqh/pods/https:proxy-service-hx9wb-f7qd4:462/proxy/: tls qux (200; 9.606669ms)
Dec 10 14:11:43.283: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-gdbqh/pods/https:proxy-service-hx9wb-f7qd4:460/proxy/: tls baz (200; 9.66478ms)
Dec 10 14:11:43.283: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-gdbqh/pods/proxy-service-hx9wb-f7qd4:160/proxy/: foo (200; 9.878438ms)
Dec 10 14:11:43.283: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-gdbqh/pods/proxy-service-hx9wb-f7qd4/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-gdbqh/pods/proxy-service-hx9wb-f7qd4/proxy/rewriteme"... (200; 10.10396ms)
Dec 10 14:11:43.284: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-gdbqh/pods/proxy-service-hx9wb-f7qd4:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-gdbqh/pods/proxy-service-hx9wb-f7qd4:1080/proxy/rewri... (200; 11.847513ms)
Dec 10 14:11:43.285: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-gdbqh/services/https:proxy-service-hx9wb:tlsportname2/proxy/: tls qux (200; 11.87003ms)
Dec 10 14:11:43.285: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-gdbqh/services/proxy-service-hx9wb:portname2/proxy/: bar (200; 12.424207ms)
Dec 10 14:11:43.288: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-gdbqh/services/http:proxy-service-hx9wb:portname2/proxy/: bar (200; 15.625113ms)
Dec 10 14:11:43.288: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-gdbqh/services/https:proxy-service-hx9wb:tlsportname1/proxy/: tls baz (200; 15.677644ms)
Dec 10 14:11:43.293: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-gdbqh/services/http:proxy-service-hx9wb:portname1/proxy/: foo (200; 19.706137ms)
Dec 10 14:11:43.295: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-gdbqh/services/proxy-service-hx9wb:portname1/proxy/: foo (200; 21.86519ms)
Dec 10 14:11:43.308: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-gdbqh/pods/proxy-service-hx9wb-f7qd4:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-gdbqh/pods/proxy-service-hx9wb-f7qd4:1080/proxy/rewri... (200; 12.50327ms)
Dec 10 14:11:43.308: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-gdbqh/pods/https:proxy-service-hx9wb-f7qd4:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-gdbqh/pods/https:proxy-service-hx9wb-f7qd4:443/proxy/... (200; 12.570641ms)
Dec 10 14:11:43.309: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-gdbqh/pods/proxy-service-hx9wb-f7qd4:162/proxy/: bar (200; 13.958396ms)
Dec 10 14:11:43.309: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-gdbqh/pods/proxy-service-hx9wb-f7qd4:160/proxy/: foo (200; 14.01846ms)
Dec 10 14:11:43.309: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-gdbqh/pods/http:proxy-service-hx9wb-f7qd4:162/proxy/: bar (200; 14.037291ms)
Dec 10 14:11:43.310: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-gdbqh/pods/https:proxy-service-hx9wb-f7qd4:460/proxy/: tls baz (200; 14.483176ms)
Dec 10 14:11:43.310: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-gdbqh/pods/https:proxy-service-hx9wb-f7qd4:462/proxy/: tls qux (200; 14.410253ms)
Dec 10 14:11:43.310: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-gdbqh/pods/http:proxy-service-hx9wb-f7qd4:160/proxy/: foo (200; 14.481392ms)
Dec 10 14:11:43.310: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-gdbqh/pods/proxy-service-hx9wb-f7qd4/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-gdbqh/pods/proxy-service-hx9wb-f7qd4/proxy/rewriteme"... (200; 14.587464ms)
Dec 10 14:11:43.310: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-gdbqh/pods/http:proxy-service-hx9wb-f7qd4:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-gdbqh/pods/http:proxy-service-hx9wb-f7qd4:1080/proxy/... (200; 15.099972ms)
Dec 10 14:11:43.311: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-gdbqh/services/http:proxy-service-hx9wb:portname1/proxy/: foo (200; 15.796595ms)
Dec 10 14:11:43.312: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-gdbqh/services/https:proxy-service-hx9wb:tlsportname2/proxy/: tls qux (200; 17.215829ms)
Dec 10 14:11:43.312: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-gdbqh/services/http:proxy-service-hx9wb:portname2/proxy/: bar (200; 17.037929ms)
Dec 10 14:11:43.312: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-gdbqh/services/proxy-service-hx9wb:portname1/proxy/: foo (200; 17.214507ms)
Dec 10 14:11:43.312: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-gdbqh/services/proxy-service-hx9wb:portname2/proxy/: bar (200; 17.096703ms)
Dec 10 14:11:43.314: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-gdbqh/services/https:proxy-service-hx9wb:tlsportname1/proxy/: tls baz (200; 19.250935ms)
Dec 10 14:11:43.325: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-gdbqh/pods/https:proxy-service-hx9wb-f7qd4:460/proxy/: tls baz (200; 10.419559ms)
Dec 10 14:11:43.326: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-gdbqh/pods/https:proxy-service-hx9wb-f7qd4:462/proxy/: tls qux (200; 10.933623ms)
Dec 10 14:11:43.327: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-gdbqh/pods/proxy-service-hx9wb-f7qd4:162/proxy/: bar (200; 12.12656ms)
Dec 10 14:11:43.328: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-gdbqh/services/http:proxy-service-hx9wb:portname1/proxy/: foo (200; 13.91537ms)
Dec 10 14:11:43.329: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-gdbqh/pods/proxy-service-hx9wb-f7qd4:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-gdbqh/pods/proxy-service-hx9wb-f7qd4:1080/proxy/rewri... (200; 14.316647ms)
Dec 10 14:11:43.329: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-gdbqh/pods/https:proxy-service-hx9wb-f7qd4:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-gdbqh/pods/https:proxy-service-hx9wb-f7qd4:443/proxy/... (200; 14.286964ms)
Dec 10 14:11:43.329: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-gdbqh/pods/http:proxy-service-hx9wb-f7qd4:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-gdbqh/pods/http:proxy-service-hx9wb-f7qd4:1080/proxy/... (200; 14.774091ms)
Dec 10 14:11:43.329: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-gdbqh/pods/http:proxy-service-hx9wb-f7qd4:160/proxy/: foo (200; 14.302554ms)
Dec 10 14:11:43.329: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-gdbqh/pods/http:proxy-service-hx9wb-f7qd4:162/proxy/: bar (200; 14.459941ms)
Dec 10 14:11:43.330: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-gdbqh/pods/proxy-service-hx9wb-f7qd4:160/proxy/: foo (200; 15.560066ms)
Dec 10 14:11:43.330: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-gdbqh/pods/proxy-service-hx9wb-f7qd4/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-gdbqh/pods/proxy-service-hx9wb-f7qd4/proxy/rewriteme"... (200; 15.780803ms)
Dec 10 14:11:43.334: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-gdbqh/services/proxy-service-hx9wb:portname1/proxy/: foo (200; 18.764597ms)
Dec 10 14:11:43.336: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-gdbqh/services/https:proxy-service-hx9wb:tlsportname1/proxy/: tls baz (200; 20.664149ms)
Dec 10 14:11:43.336: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-gdbqh/services/https:proxy-service-hx9wb:tlsportname2/proxy/: tls qux (200; 21.143163ms)
Dec 10 14:11:43.336: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-gdbqh/services/http:proxy-service-hx9wb:portname2/proxy/: bar (200; 20.819015ms)
Dec 10 14:11:43.336: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-gdbqh/services/proxy-service-hx9wb:portname2/proxy/: bar (200; 20.874187ms)
Dec 10 14:11:43.343: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-gdbqh/pods/http:proxy-service-hx9wb-f7qd4:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-gdbqh/pods/http:proxy-service-hx9wb-f7qd4:1080/proxy/... (200; 7.111343ms)
Dec 10 14:11:43.345: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-gdbqh/services/http:proxy-service-hx9wb:portname1/proxy/: foo (200; 8.956558ms)
Dec 10 14:11:43.345: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-gdbqh/pods/https:proxy-service-hx9wb-f7qd4:460/proxy/: tls baz (200; 8.530771ms)
Dec 10 14:11:43.346: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-gdbqh/pods/proxy-service-hx9wb-f7qd4:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-gdbqh/pods/proxy-service-hx9wb-f7qd4:1080/proxy/rewri... (200; 9.150579ms)
Dec 10 14:11:43.346: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-gdbqh/pods/http:proxy-service-hx9wb-f7qd4:160/proxy/: foo (200; 8.720953ms)
Dec 10 14:11:43.346: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-gdbqh/pods/proxy-service-hx9wb-f7qd4:162/proxy/: bar (200; 9.625007ms)
Dec 10 14:11:43.346: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-gdbqh/pods/https:proxy-service-hx9wb-f7qd4:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-gdbqh/pods/https:proxy-service-hx9wb-f7qd4:443/proxy/... (200; 9.608957ms)
Dec 10 14:11:43.346: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-gdbqh/pods/proxy-service-hx9wb-f7qd4/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-gdbqh/pods/proxy-service-hx9wb-f7qd4/proxy/rewriteme"... (200; 9.357171ms)
Dec 10 14:11:43.347: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-gdbqh/pods/https:proxy-service-hx9wb-f7qd4:462/proxy/: tls qux (200; 10.654921ms)
Dec 10 14:11:43.347: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-gdbqh/pods/proxy-service-hx9wb-f7qd4:160/proxy/: foo (200; 10.41369ms)
Dec 10 14:11:43.347: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-gdbqh/pods/http:proxy-service-hx9wb-f7qd4:162/proxy/: bar (200; 10.809834ms)
Dec 10 14:11:43.349: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-gdbqh/services/http:proxy-service-hx9wb:portname2/proxy/: bar (200; 12.791604ms)
Dec 10 14:11:43.352: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-gdbqh/services/https:proxy-service-hx9wb:tlsportname2/proxy/: tls qux (200; 14.904327ms)
Dec 10 14:11:43.352: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-gdbqh/services/proxy-service-hx9wb:portname1/proxy/: foo (200; 14.980807ms)
Dec 10 14:11:43.352: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-gdbqh/services/https:proxy-service-hx9wb:tlsportname1/proxy/: tls baz (200; 14.731928ms)
Dec 10 14:11:43.352: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-gdbqh/services/proxy-service-hx9wb:portname2/proxy/: bar (200; 15.104255ms)
Dec 10 14:11:43.363: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-gdbqh/pods/https:proxy-service-hx9wb-f7qd4:462/proxy/: tls qux (200; 9.421266ms)
Dec 10 14:11:43.363: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-gdbqh/pods/http:proxy-service-hx9wb-f7qd4:162/proxy/: bar (200; 10.18412ms)
Dec 10 14:11:43.363: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-gdbqh/pods/https:proxy-service-hx9wb-f7qd4:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-gdbqh/pods/https:proxy-service-hx9wb-f7qd4:443/proxy/... (200; 10.691532ms)
Dec 10 14:11:43.364: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-gdbqh/pods/proxy-service-hx9wb-f7qd4:160/proxy/: foo (200; 11.067023ms)
Dec 10 14:11:43.364: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-gdbqh/pods/proxy-service-hx9wb-f7qd4:162/proxy/: bar (200; 11.237578ms)
Dec 10 14:11:43.364: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-gdbqh/pods/proxy-service-hx9wb-f7qd4/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-gdbqh/pods/proxy-service-hx9wb-f7qd4/proxy/rewriteme"... (200; 10.32005ms)
Dec 10 14:11:43.364: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-gdbqh/pods/proxy-service-hx9wb-f7qd4:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-gdbqh/pods/proxy-service-hx9wb-f7qd4:1080/proxy/rewri... (200; 11.087497ms)
Dec 10 14:11:43.364: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-gdbqh/pods/https:proxy-service-hx9wb-f7qd4:460/proxy/: tls baz (200; 11.868589ms)
Dec 10 14:11:43.364: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-gdbqh/pods/http:proxy-service-hx9wb-f7qd4:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-gdbqh/pods/http:proxy-service-hx9wb-f7qd4:1080/proxy/... (200; 11.751383ms)
Dec 10 14:11:43.364: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-gdbqh/pods/http:proxy-service-hx9wb-f7qd4:160/proxy/: foo (200; 10.725658ms)
Dec 10 14:11:43.365: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-gdbqh/services/http:proxy-service-hx9wb:portname2/proxy/: bar (200; 12.054879ms)
Dec 10 14:11:43.367: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-gdbqh/services/https:proxy-service-hx9wb:tlsportname2/proxy/: tls qux (200; 14.342666ms)
Dec 10 14:11:43.368: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-gdbqh/services/http:proxy-service-hx9wb:portname1/proxy/: foo (200; 15.245913ms)
Dec 10 14:11:43.368: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-gdbqh/services/proxy-service-hx9wb:portname1/proxy/: foo (200; 15.755091ms)
Dec 10 14:11:43.368: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-gdbqh/services/https:proxy-service-hx9wb:tlsportname1/proxy/: tls baz (200; 14.91096ms)
Dec 10 14:11:43.368: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-gdbqh/services/proxy-service-hx9wb:portname2/proxy/: bar (200; 14.848114ms)
Dec 10 14:11:43.374: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-gdbqh/pods/https:proxy-service-hx9wb-f7qd4:462/proxy/: tls qux (200; 5.647254ms)
Dec 10 14:11:43.377: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-gdbqh/pods/proxy-service-hx9wb-f7qd4:162/proxy/: bar (200; 8.441982ms)
Dec 10 14:11:43.377: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-gdbqh/pods/http:proxy-service-hx9wb-f7qd4:160/proxy/: foo (200; 8.529966ms)
Dec 10 14:11:43.378: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-gdbqh/pods/proxy-service-hx9wb-f7qd4:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-gdbqh/pods/proxy-service-hx9wb-f7qd4:1080/proxy/rewri... (200; 8.542938ms)
Dec 10 14:11:43.378: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-gdbqh/pods/http:proxy-service-hx9wb-f7qd4:162/proxy/: bar (200; 9.337439ms)
Dec 10 14:11:43.378: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-gdbqh/pods/https:proxy-service-hx9wb-f7qd4:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-gdbqh/pods/https:proxy-service-hx9wb-f7qd4:443/proxy/... (200; 9.885401ms)
Dec 10 14:11:43.378: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-gdbqh/pods/proxy-service-hx9wb-f7qd4/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-gdbqh/pods/proxy-service-hx9wb-f7qd4/proxy/rewriteme"... (200; 9.456669ms)
Dec 10 14:11:43.378: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-gdbqh/pods/https:proxy-service-hx9wb-f7qd4:460/proxy/: tls baz (200; 9.845696ms)
Dec 10 14:11:43.378: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-gdbqh/pods/proxy-service-hx9wb-f7qd4:160/proxy/: foo (200; 9.283253ms)
Dec 10 14:11:43.378: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-gdbqh/pods/http:proxy-service-hx9wb-f7qd4:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-gdbqh/pods/http:proxy-service-hx9wb-f7qd4:1080/proxy/... (200; 9.306354ms)
Dec 10 14:11:43.381: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-gdbqh/services/proxy-service-hx9wb:portname2/proxy/: bar (200; 11.844124ms)
Dec 10 14:11:43.384: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-gdbqh/services/https:proxy-service-hx9wb:tlsportname2/proxy/: tls qux (200; 15.993604ms)
Dec 10 14:11:43.385: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-gdbqh/services/proxy-service-hx9wb:portname1/proxy/: foo (200; 15.872087ms)
Dec 10 14:11:43.385: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-gdbqh/services/http:proxy-service-hx9wb:portname1/proxy/: foo (200; 15.759848ms)
Dec 10 14:11:43.385: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-gdbqh/services/https:proxy-service-hx9wb:tlsportname1/proxy/: tls baz (200; 16.419162ms)
Dec 10 14:11:43.385: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-gdbqh/services/http:proxy-service-hx9wb:portname2/proxy/: bar (200; 16.551428ms)
Dec 10 14:11:43.395: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-gdbqh/pods/https:proxy-service-hx9wb-f7qd4:460/proxy/: tls baz (200; 10.133201ms)
Dec 10 14:11:43.400: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-gdbqh/pods/https:proxy-service-hx9wb-f7qd4:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-gdbqh/pods/https:proxy-service-hx9wb-f7qd4:443/proxy/... (200; 14.536311ms)
Dec 10 14:11:43.401: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-gdbqh/pods/http:proxy-service-hx9wb-f7qd4:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-gdbqh/pods/http:proxy-service-hx9wb-f7qd4:1080/proxy/... (200; 15.074072ms)
Dec 10 14:11:43.401: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-gdbqh/pods/proxy-service-hx9wb-f7qd4:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-gdbqh/pods/proxy-service-hx9wb-f7qd4:1080/proxy/rewri... (200; 15.036465ms)
Dec 10 14:11:43.401: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-gdbqh/pods/proxy-service-hx9wb-f7qd4:162/proxy/: bar (200; 15.258529ms)
Dec 10 14:11:43.401: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-gdbqh/pods/http:proxy-service-hx9wb-f7qd4:162/proxy/: bar (200; 15.006189ms)
Dec 10 14:11:43.401: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-gdbqh/pods/proxy-service-hx9wb-f7qd4:160/proxy/: foo (200; 15.495126ms)
Dec 10 14:11:43.402: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-gdbqh/pods/proxy-service-hx9wb-f7qd4/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-gdbqh/pods/proxy-service-hx9wb-f7qd4/proxy/rewriteme"... (200; 16.502871ms)
Dec 10 14:11:43.402: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-gdbqh/pods/https:proxy-service-hx9wb-f7qd4:462/proxy/: tls qux (200; 16.567469ms)
Dec 10 14:11:43.402: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-gdbqh/pods/http:proxy-service-hx9wb-f7qd4:160/proxy/: foo (200; 16.672748ms)
Dec 10 14:11:43.404: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-gdbqh/services/proxy-service-hx9wb:portname1/proxy/: foo (200; 18.776366ms)
Dec 10 14:11:43.406: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-gdbqh/services/http:proxy-service-hx9wb:portname1/proxy/: foo (200; 20.066537ms)
Dec 10 14:11:43.408: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-gdbqh/services/https:proxy-service-hx9wb:tlsportname2/proxy/: tls qux (200; 22.011159ms)
Dec 10 14:11:43.408: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-gdbqh/services/proxy-service-hx9wb:portname2/proxy/: bar (200; 22.548749ms)
Dec 10 14:11:43.408: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-gdbqh/services/http:proxy-service-hx9wb:portname2/proxy/: bar (200; 22.622461ms)
Dec 10 14:11:43.408: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-gdbqh/services/https:proxy-service-hx9wb:tlsportname1/proxy/: tls baz (200; 23.025065ms)
Dec 10 14:11:43.418: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-gdbqh/pods/proxy-service-hx9wb-f7qd4:160/proxy/: foo (200; 9.660657ms)
Dec 10 14:11:43.422: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-gdbqh/pods/http:proxy-service-hx9wb-f7qd4:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-gdbqh/pods/http:proxy-service-hx9wb-f7qd4:1080/proxy/... (200; 12.902688ms)
Dec 10 14:11:43.422: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-gdbqh/pods/https:proxy-service-hx9wb-f7qd4:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-gdbqh/pods/https:proxy-service-hx9wb-f7qd4:443/proxy/... (200; 12.950738ms)
Dec 10 14:11:43.422: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-gdbqh/pods/proxy-service-hx9wb-f7qd4:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-gdbqh/pods/proxy-service-hx9wb-f7qd4:1080/proxy/rewri... (200; 13.066305ms)
Dec 10 14:11:43.422: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-gdbqh/pods/proxy-service-hx9wb-f7qd4:162/proxy/: bar (200; 13.304625ms)
Dec 10 14:11:43.425: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-gdbqh/pods/proxy-service-hx9wb-f7qd4/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-gdbqh/pods/proxy-service-hx9wb-f7qd4/proxy/rewriteme"... (200; 16.590468ms)
Dec 10 14:11:43.425: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-gdbqh/pods/https:proxy-service-hx9wb-f7qd4:462/proxy/: tls qux (200; 16.637361ms)
Dec 10 14:11:43.425: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-gdbqh/pods/http:proxy-service-hx9wb-f7qd4:160/proxy/: foo (200; 16.524201ms)
Dec 10 14:11:43.425: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-gdbqh/pods/https:proxy-service-hx9wb-f7qd4:460/proxy/: tls baz (200; 16.670326ms)
Dec 10 14:11:43.425: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-gdbqh/pods/http:proxy-service-hx9wb-f7qd4:162/proxy/: bar (200; 17.087981ms)
Dec 10 14:11:43.427: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-gdbqh/services/proxy-service-hx9wb:portname2/proxy/: bar (200; 18.874984ms)
Dec 10 14:11:43.430: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-gdbqh/services/http:proxy-service-hx9wb:portname2/proxy/: bar (200; 21.280977ms)
Dec 10 14:11:43.430: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-gdbqh/services/proxy-service-hx9wb:portname1/proxy/: foo (200; 21.189332ms)
Dec 10 14:11:43.430: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-gdbqh/services/https:proxy-service-hx9wb:tlsportname2/proxy/: tls qux (200; 21.361021ms)
Dec 10 14:11:43.430: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-gdbqh/services/http:proxy-service-hx9wb:portname1/proxy/: foo (200; 21.770526ms)
Dec 10 14:11:43.431: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-gdbqh/services/https:proxy-service-hx9wb:tlsportname1/proxy/: tls baz (200; 23.061056ms)
Dec 10 14:11:43.456: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-gdbqh/pods/http:proxy-service-hx9wb-f7qd4:160/proxy/: foo (200; 24.065914ms)
Dec 10 14:11:43.456: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-gdbqh/pods/proxy-service-hx9wb-f7qd4:162/proxy/: bar (200; 23.954346ms)
Dec 10 14:11:43.456: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-gdbqh/pods/proxy-service-hx9wb-f7qd4:160/proxy/: foo (200; 24.268826ms)
Dec 10 14:11:43.456: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-gdbqh/pods/proxy-service-hx9wb-f7qd4:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-gdbqh/pods/proxy-service-hx9wb-f7qd4:1080/proxy/rewri... (200; 23.608824ms)
Dec 10 14:11:43.460: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-gdbqh/pods/proxy-service-hx9wb-f7qd4/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-gdbqh/pods/proxy-service-hx9wb-f7qd4/proxy/rewriteme"... (200; 28.267741ms)
Dec 10 14:11:43.460: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-gdbqh/pods/http:proxy-service-hx9wb-f7qd4:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-gdbqh/pods/http:proxy-service-hx9wb-f7qd4:1080/proxy/... (200; 28.606852ms)
Dec 10 14:11:43.461: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-gdbqh/pods/https:proxy-service-hx9wb-f7qd4:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-gdbqh/pods/https:proxy-service-hx9wb-f7qd4:443/proxy/... (200; 28.836205ms)
Dec 10 14:11:43.461: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-gdbqh/pods/http:proxy-service-hx9wb-f7qd4:162/proxy/: bar (200; 28.931957ms)
Dec 10 14:11:43.461: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-gdbqh/pods/https:proxy-service-hx9wb-f7qd4:462/proxy/: tls qux (200; 29.148299ms)
Dec 10 14:11:43.461: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-gdbqh/pods/https:proxy-service-hx9wb-f7qd4:460/proxy/: tls baz (200; 29.129981ms)
Dec 10 14:11:43.463: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-gdbqh/services/proxy-service-hx9wb:portname1/proxy/: foo (200; 31.149444ms)
Dec 10 14:11:43.464: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-gdbqh/services/http:proxy-service-hx9wb:portname2/proxy/: bar (200; 32.275025ms)
Dec 10 14:11:43.464: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-gdbqh/services/https:proxy-service-hx9wb:tlsportname1/proxy/: tls baz (200; 32.417375ms)
Dec 10 14:11:43.465: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-gdbqh/services/proxy-service-hx9wb:portname2/proxy/: bar (200; 33.026894ms)
Dec 10 14:11:43.465: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-gdbqh/services/http:proxy-service-hx9wb:portname1/proxy/: foo (200; 33.286377ms)
Dec 10 14:11:43.466: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-gdbqh/services/https:proxy-service-hx9wb:tlsportname2/proxy/: tls qux (200; 34.400137ms)
Dec 10 14:11:43.477: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-gdbqh/pods/proxy-service-hx9wb-f7qd4:162/proxy/: bar (200; 11.002168ms)
Dec 10 14:11:43.483: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-gdbqh/pods/https:proxy-service-hx9wb-f7qd4:462/proxy/: tls qux (200; 16.282539ms)
Dec 10 14:11:43.483: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-gdbqh/pods/proxy-service-hx9wb-f7qd4/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-gdbqh/pods/proxy-service-hx9wb-f7qd4/proxy/rewriteme"... (200; 16.608859ms)
Dec 10 14:11:43.483: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-gdbqh/pods/http:proxy-service-hx9wb-f7qd4:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-gdbqh/pods/http:proxy-service-hx9wb-f7qd4:1080/proxy/... (200; 16.622832ms)
Dec 10 14:11:43.484: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-gdbqh/pods/http:proxy-service-hx9wb-f7qd4:160/proxy/: foo (200; 17.127198ms)
Dec 10 14:11:43.484: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-gdbqh/pods/proxy-service-hx9wb-f7qd4:160/proxy/: foo (200; 17.14744ms)
Dec 10 14:11:43.484: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-gdbqh/pods/http:proxy-service-hx9wb-f7qd4:162/proxy/: bar (200; 17.37015ms)
Dec 10 14:11:43.484: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-gdbqh/pods/https:proxy-service-hx9wb-f7qd4:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-gdbqh/pods/https:proxy-service-hx9wb-f7qd4:443/proxy/... (200; 17.426708ms)
Dec 10 14:11:43.484: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-gdbqh/pods/https:proxy-service-hx9wb-f7qd4:460/proxy/: tls baz (200; 17.378652ms)
Dec 10 14:11:43.484: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-gdbqh/pods/proxy-service-hx9wb-f7qd4:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-gdbqh/pods/proxy-service-hx9wb-f7qd4:1080/proxy/rewri... (200; 17.423725ms)
Dec 10 14:11:43.484: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-gdbqh/services/proxy-service-hx9wb:portname1/proxy/: foo (200; 17.833964ms)
Dec 10 14:11:43.486: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-gdbqh/services/https:proxy-service-hx9wb:tlsportname2/proxy/: tls qux (200; 19.418521ms)
Dec 10 14:11:43.488: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-gdbqh/services/proxy-service-hx9wb:portname2/proxy/: bar (200; 21.026699ms)
Dec 10 14:11:43.488: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-gdbqh/services/http:proxy-service-hx9wb:portname1/proxy/: foo (200; 21.164756ms)
Dec 10 14:11:43.489: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-gdbqh/services/http:proxy-service-hx9wb:portname2/proxy/: bar (200; 22.513756ms)
Dec 10 14:11:43.489: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-gdbqh/services/https:proxy-service-hx9wb:tlsportname1/proxy/: tls baz (200; 22.648029ms)
Dec 10 14:11:43.501: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-gdbqh/pods/http:proxy-service-hx9wb-f7qd4:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-gdbqh/pods/http:proxy-service-hx9wb-f7qd4:1080/proxy/... (200; 10.844216ms)
Dec 10 14:11:43.501: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-gdbqh/pods/https:proxy-service-hx9wb-f7qd4:460/proxy/: tls baz (200; 11.534668ms)
Dec 10 14:11:43.502: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-gdbqh/pods/proxy-service-hx9wb-f7qd4:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-gdbqh/pods/proxy-service-hx9wb-f7qd4:1080/proxy/rewri... (200; 12.096707ms)
Dec 10 14:11:43.502: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-gdbqh/pods/http:proxy-service-hx9wb-f7qd4:160/proxy/: foo (200; 12.163518ms)
Dec 10 14:11:43.502: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-gdbqh/pods/https:proxy-service-hx9wb-f7qd4:462/proxy/: tls qux (200; 12.191855ms)
Dec 10 14:11:43.503: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-gdbqh/pods/https:proxy-service-hx9wb-f7qd4:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-gdbqh/pods/https:proxy-service-hx9wb-f7qd4:443/proxy/... (200; 13.325255ms)
Dec 10 14:11:43.503: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-gdbqh/services/http:proxy-service-hx9wb:portname2/proxy/: bar (200; 13.169653ms)
Dec 10 14:11:43.503: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-gdbqh/pods/proxy-service-hx9wb-f7qd4/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-gdbqh/pods/proxy-service-hx9wb-f7qd4/proxy/rewriteme"... (200; 14.005189ms)
Dec 10 14:11:43.504: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-gdbqh/services/http:proxy-service-hx9wb:portname1/proxy/: foo (200; 13.931031ms)
Dec 10 14:11:43.504: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-gdbqh/pods/proxy-service-hx9wb-f7qd4:160/proxy/: foo (200; 14.232358ms)
Dec 10 14:11:43.504: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-gdbqh/services/https:proxy-service-hx9wb:tlsportname2/proxy/: tls qux (200; 14.103743ms)
Dec 10 14:11:43.504: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-gdbqh/pods/proxy-service-hx9wb-f7qd4:162/proxy/: bar (200; 14.218799ms)
Dec 10 14:11:43.504: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-gdbqh/services/proxy-service-hx9wb:portname2/proxy/: bar (200; 13.96371ms)
Dec 10 14:11:43.504: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-gdbqh/services/https:proxy-service-hx9wb:tlsportname1/proxy/: tls baz (200; 14.361284ms)
Dec 10 14:11:43.504: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-gdbqh/services/proxy-service-hx9wb:portname1/proxy/: foo (200; 14.599427ms)
Dec 10 14:11:43.505: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-gdbqh/pods/http:proxy-service-hx9wb-f7qd4:162/proxy/: bar (200; 15.122145ms)
Dec 10 14:11:43.519: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-gdbqh/pods/proxy-service-hx9wb-f7qd4/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-gdbqh/pods/proxy-service-hx9wb-f7qd4/proxy/rewriteme"... (200; 13.303847ms)
Dec 10 14:11:43.519: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-gdbqh/pods/proxy-service-hx9wb-f7qd4:160/proxy/: foo (200; 13.168279ms)
Dec 10 14:11:43.519: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-gdbqh/pods/http:proxy-service-hx9wb-f7qd4:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-gdbqh/pods/http:proxy-service-hx9wb-f7qd4:1080/proxy/... (200; 13.481046ms)
Dec 10 14:11:43.519: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-gdbqh/pods/proxy-service-hx9wb-f7qd4:162/proxy/: bar (200; 14.621462ms)
Dec 10 14:11:43.520: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-gdbqh/pods/https:proxy-service-hx9wb-f7qd4:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-gdbqh/pods/https:proxy-service-hx9wb-f7qd4:443/proxy/... (200; 14.616778ms)
Dec 10 14:11:43.520: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-gdbqh/pods/http:proxy-service-hx9wb-f7qd4:162/proxy/: bar (200; 14.589434ms)
Dec 10 14:11:43.520: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-gdbqh/pods/https:proxy-service-hx9wb-f7qd4:460/proxy/: tls baz (200; 14.564849ms)
Dec 10 14:11:43.520: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-gdbqh/pods/https:proxy-service-hx9wb-f7qd4:462/proxy/: tls qux (200; 14.073935ms)
Dec 10 14:11:43.520: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-gdbqh/pods/http:proxy-service-hx9wb-f7qd4:160/proxy/: foo (200; 14.14274ms)
Dec 10 14:11:43.520: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-gdbqh/pods/proxy-service-hx9wb-f7qd4:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-gdbqh/pods/proxy-service-hx9wb-f7qd4:1080/proxy/rewri... (200; 15.020355ms)
Dec 10 14:11:43.521: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-gdbqh/services/https:proxy-service-hx9wb:tlsportname2/proxy/: tls qux (200; 15.995458ms)
Dec 10 14:11:43.523: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-gdbqh/services/proxy-service-hx9wb:portname1/proxy/: foo (200; 17.766408ms)
Dec 10 14:11:43.526: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-gdbqh/services/http:proxy-service-hx9wb:portname2/proxy/: bar (200; 20.409802ms)
Dec 10 14:11:43.527: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-gdbqh/services/proxy-service-hx9wb:portname2/proxy/: bar (200; 21.023311ms)
Dec 10 14:11:43.527: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-gdbqh/services/http:proxy-service-hx9wb:portname1/proxy/: foo (200; 20.762302ms)
Dec 10 14:11:43.529: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-gdbqh/services/https:proxy-service-hx9wb:tlsportname1/proxy/: tls baz (200; 22.910953ms)
Dec 10 14:11:43.542: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-gdbqh/pods/proxy-service-hx9wb-f7qd4:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-gdbqh/pods/proxy-service-hx9wb-f7qd4:1080/proxy/rewri... (200; 13.701205ms)
Dec 10 14:11:43.543: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-gdbqh/pods/http:proxy-service-hx9wb-f7qd4:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-gdbqh/pods/http:proxy-service-hx9wb-f7qd4:1080/proxy/... (200; 13.683734ms)
Dec 10 14:11:43.543: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-gdbqh/pods/http:proxy-service-hx9wb-f7qd4:160/proxy/: foo (200; 14.307369ms)
Dec 10 14:11:43.543: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-gdbqh/pods/proxy-service-hx9wb-f7qd4:162/proxy/: bar (200; 14.646558ms)
Dec 10 14:11:43.544: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-gdbqh/pods/http:proxy-service-hx9wb-f7qd4:162/proxy/: bar (200; 14.790959ms)
Dec 10 14:11:43.544: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-gdbqh/pods/https:proxy-service-hx9wb-f7qd4:460/proxy/: tls baz (200; 14.905621ms)
Dec 10 14:11:43.544: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-gdbqh/pods/https:proxy-service-hx9wb-f7qd4:462/proxy/: tls qux (200; 14.92929ms)
Dec 10 14:11:43.544: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-gdbqh/pods/https:proxy-service-hx9wb-f7qd4:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-gdbqh/pods/https:proxy-service-hx9wb-f7qd4:443/proxy/... (200; 15.3208ms)
Dec 10 14:11:43.544: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-gdbqh/pods/proxy-service-hx9wb-f7qd4/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-gdbqh/pods/proxy-service-hx9wb-f7qd4/proxy/rewriteme"... (200; 15.248275ms)
Dec 10 14:11:43.544: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-gdbqh/pods/proxy-service-hx9wb-f7qd4:160/proxy/: foo (200; 15.287777ms)
Dec 10 14:11:43.546: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-gdbqh/services/proxy-service-hx9wb:portname2/proxy/: bar (200; 17.362738ms)
Dec 10 14:11:43.546: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-gdbqh/services/http:proxy-service-hx9wb:portname2/proxy/: bar (200; 17.132403ms)
Dec 10 14:11:43.548: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-gdbqh/services/https:proxy-service-hx9wb:tlsportname1/proxy/: tls baz (200; 18.940307ms)
Dec 10 14:11:43.548: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-gdbqh/services/https:proxy-service-hx9wb:tlsportname2/proxy/: tls qux (200; 19.602323ms)
Dec 10 14:11:43.549: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-gdbqh/services/proxy-service-hx9wb:portname1/proxy/: foo (200; 19.669949ms)
Dec 10 14:11:43.549: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-gdbqh/services/http:proxy-service-hx9wb:portname1/proxy/: foo (200; 20.067431ms)
Dec 10 14:11:43.562: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-gdbqh/pods/proxy-service-hx9wb-f7qd4:160/proxy/: foo (200; 12.946351ms)
Dec 10 14:11:43.563: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-gdbqh/pods/https:proxy-service-hx9wb-f7qd4:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-gdbqh/pods/https:proxy-service-hx9wb-f7qd4:443/proxy/... (200; 13.590341ms)
Dec 10 14:11:43.563: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-gdbqh/pods/proxy-service-hx9wb-f7qd4/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-gdbqh/pods/proxy-service-hx9wb-f7qd4/proxy/rewriteme"... (200; 14.153528ms)
Dec 10 14:11:43.564: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-gdbqh/pods/http:proxy-service-hx9wb-f7qd4:162/proxy/: bar (200; 14.15583ms)
Dec 10 14:11:43.564: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-gdbqh/pods/https:proxy-service-hx9wb-f7qd4:460/proxy/: tls baz (200; 14.85962ms)
Dec 10 14:11:43.564: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-gdbqh/pods/proxy-service-hx9wb-f7qd4:162/proxy/: bar (200; 14.741625ms)
Dec 10 14:11:43.564: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-gdbqh/pods/http:proxy-service-hx9wb-f7qd4:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-gdbqh/pods/http:proxy-service-hx9wb-f7qd4:1080/proxy/... (200; 14.811424ms)
Dec 10 14:11:43.564: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-gdbqh/pods/http:proxy-service-hx9wb-f7qd4:160/proxy/: foo (200; 14.965878ms)
Dec 10 14:11:43.564: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-gdbqh/pods/proxy-service-hx9wb-f7qd4:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-gdbqh/pods/proxy-service-hx9wb-f7qd4:1080/proxy/rewri... (200; 14.991759ms)
Dec 10 14:11:43.565: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-gdbqh/pods/https:proxy-service-hx9wb-f7qd4:462/proxy/: tls qux (200; 15.237703ms)
Dec 10 14:11:43.565: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-gdbqh/services/http:proxy-service-hx9wb:portname1/proxy/: foo (200; 15.54818ms)
Dec 10 14:11:43.567: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-gdbqh/services/https:proxy-service-hx9wb:tlsportname2/proxy/: tls qux (200; 17.989019ms)
Dec 10 14:11:43.569: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-gdbqh/services/https:proxy-service-hx9wb:tlsportname1/proxy/: tls baz (200; 20.123761ms)
Dec 10 14:11:43.570: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-gdbqh/services/proxy-service-hx9wb:portname1/proxy/: foo (200; 20.453685ms)
Dec 10 14:11:43.570: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-gdbqh/services/proxy-service-hx9wb:portname2/proxy/: bar (200; 20.674757ms)
Dec 10 14:11:43.570: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-gdbqh/services/http:proxy-service-hx9wb:portname2/proxy/: bar (200; 20.890478ms)
Dec 10 14:11:43.578: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-gdbqh/pods/https:proxy-service-hx9wb-f7qd4:460/proxy/: tls baz (200; 7.829119ms)
Dec 10 14:11:43.578: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-gdbqh/pods/http:proxy-service-hx9wb-f7qd4:162/proxy/: bar (200; 7.711276ms)
Dec 10 14:11:43.580: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-gdbqh/pods/proxy-service-hx9wb-f7qd4/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-gdbqh/pods/proxy-service-hx9wb-f7qd4/proxy/rewriteme"... (200; 9.804892ms)
Dec 10 14:11:43.580: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-gdbqh/services/https:proxy-service-hx9wb:tlsportname2/proxy/: tls qux (200; 10.178278ms)
Dec 10 14:11:43.581: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-gdbqh/pods/http:proxy-service-hx9wb-f7qd4:160/proxy/: foo (200; 10.116289ms)
Dec 10 14:11:43.581: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-gdbqh/pods/https:proxy-service-hx9wb-f7qd4:462/proxy/: tls qux (200; 10.072797ms)
Dec 10 14:11:43.581: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-gdbqh/services/http:proxy-service-hx9wb:portname2/proxy/: bar (200; 10.971296ms)
Dec 10 14:11:43.582: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-gdbqh/pods/https:proxy-service-hx9wb-f7qd4:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-gdbqh/pods/https:proxy-service-hx9wb-f7qd4:443/proxy/... (200; 11.591597ms)
Dec 10 14:11:43.583: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-gdbqh/services/https:proxy-service-hx9wb:tlsportname1/proxy/: tls baz (200; 12.184022ms)
Dec 10 14:11:43.584: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-gdbqh/pods/proxy-service-hx9wb-f7qd4:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-gdbqh/pods/proxy-service-hx9wb-f7qd4:1080/proxy/rewri... (200; 12.736312ms)
Dec 10 14:11:43.584: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-gdbqh/pods/proxy-service-hx9wb-f7qd4:160/proxy/: foo (200; 13.556313ms)
Dec 10 14:11:43.585: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-gdbqh/pods/proxy-service-hx9wb-f7qd4:162/proxy/: bar (200; 14.473218ms)
Dec 10 14:11:43.586: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-gdbqh/services/proxy-service-hx9wb:portname2/proxy/: bar (200; 15.410982ms)
Dec 10 14:11:43.586: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-gdbqh/pods/http:proxy-service-hx9wb-f7qd4:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-gdbqh/pods/http:proxy-service-hx9wb-f7qd4:1080/proxy/... (200; 15.494394ms)
Dec 10 14:11:43.586: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-gdbqh/services/proxy-service-hx9wb:portname1/proxy/: foo (200; 15.740713ms)
Dec 10 14:11:43.591: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-gdbqh/services/http:proxy-service-hx9wb:portname1/proxy/: foo (200; 19.703739ms)
Dec 10 14:11:43.598: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-gdbqh/pods/https:proxy-service-hx9wb-f7qd4:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-gdbqh/pods/https:proxy-service-hx9wb-f7qd4:443/proxy/... (200; 7.149554ms)
Dec 10 14:11:43.602: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-gdbqh/pods/http:proxy-service-hx9wb-f7qd4:162/proxy/: bar (200; 10.977918ms)
Dec 10 14:11:43.602: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-gdbqh/pods/http:proxy-service-hx9wb-f7qd4:160/proxy/: foo (200; 10.551179ms)
Dec 10 14:11:43.602: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-gdbqh/pods/http:proxy-service-hx9wb-f7qd4:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-gdbqh/pods/http:proxy-service-hx9wb-f7qd4:1080/proxy/... (200; 10.594873ms)
Dec 10 14:11:43.602: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-gdbqh/pods/proxy-service-hx9wb-f7qd4:162/proxy/: bar (200; 10.453489ms)
Dec 10 14:11:43.602: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-gdbqh/pods/proxy-service-hx9wb-f7qd4:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-gdbqh/pods/proxy-service-hx9wb-f7qd4:1080/proxy/rewri... (200; 10.414606ms)
Dec 10 14:11:43.603: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-gdbqh/pods/https:proxy-service-hx9wb-f7qd4:462/proxy/: tls qux (200; 11.619763ms)
Dec 10 14:11:43.603: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-gdbqh/pods/https:proxy-service-hx9wb-f7qd4:460/proxy/: tls baz (200; 11.725829ms)
Dec 10 14:11:43.603: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-gdbqh/pods/proxy-service-hx9wb-f7qd4:160/proxy/: foo (200; 10.984871ms)
Dec 10 14:11:43.603: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-gdbqh/pods/proxy-service-hx9wb-f7qd4/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-gdbqh/pods/proxy-service-hx9wb-f7qd4/proxy/rewriteme"... (200; 11.380689ms)
Dec 10 14:11:43.604: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-gdbqh/services/proxy-service-hx9wb:portname2/proxy/: bar (200; 12.398699ms)
Dec 10 14:11:43.605: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-gdbqh/services/proxy-service-hx9wb:portname1/proxy/: foo (200; 13.80162ms)
Dec 10 14:11:43.605: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-gdbqh/services/https:proxy-service-hx9wb:tlsportname2/proxy/: tls qux (200; 14.183908ms)
Dec 10 14:11:43.605: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-gdbqh/services/http:proxy-service-hx9wb:portname1/proxy/: foo (200; 13.372797ms)
Dec 10 14:11:43.605: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-gdbqh/services/http:proxy-service-hx9wb:portname2/proxy/: bar (200; 13.946216ms)
Dec 10 14:11:43.605: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-gdbqh/services/https:proxy-service-hx9wb:tlsportname1/proxy/: tls baz (200; 13.874038ms)
Dec 10 14:11:43.616: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-gdbqh/pods/proxy-service-hx9wb-f7qd4:162/proxy/: bar (200; 10.134613ms)
Dec 10 14:11:43.616: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-gdbqh/pods/https:proxy-service-hx9wb-f7qd4:460/proxy/: tls baz (200; 10.413455ms)
Dec 10 14:11:43.617: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-gdbqh/pods/proxy-service-hx9wb-f7qd4/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-gdbqh/pods/proxy-service-hx9wb-f7qd4/proxy/rewriteme"... (200; 11.259845ms)
Dec 10 14:11:43.617: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-gdbqh/pods/proxy-service-hx9wb-f7qd4:160/proxy/: foo (200; 11.38602ms)
Dec 10 14:11:43.617: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-gdbqh/pods/proxy-service-hx9wb-f7qd4:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-gdbqh/pods/proxy-service-hx9wb-f7qd4:1080/proxy/rewri... (200; 11.388302ms)
Dec 10 14:11:43.617: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-gdbqh/pods/https:proxy-service-hx9wb-f7qd4:462/proxy/: tls qux (200; 11.679722ms)
Dec 10 14:11:43.618: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-gdbqh/pods/http:proxy-service-hx9wb-f7qd4:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-gdbqh/pods/http:proxy-service-hx9wb-f7qd4:1080/proxy/... (200; 11.594546ms)
Dec 10 14:11:43.618: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-gdbqh/pods/https:proxy-service-hx9wb-f7qd4:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-gdbqh/pods/https:proxy-service-hx9wb-f7qd4:443/proxy/... (200; 12.704875ms)
Dec 10 14:11:43.618: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-gdbqh/pods/http:proxy-service-hx9wb-f7qd4:162/proxy/: bar (200; 12.598835ms)
Dec 10 14:11:43.618: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-gdbqh/pods/http:proxy-service-hx9wb-f7qd4:160/proxy/: foo (200; 12.60197ms)
Dec 10 14:11:43.618: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-gdbqh/services/proxy-service-hx9wb:portname1/proxy/: foo (200; 12.966021ms)
Dec 10 14:11:43.619: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-gdbqh/services/https:proxy-service-hx9wb:tlsportname1/proxy/: tls baz (200; 13.701669ms)
Dec 10 14:11:43.620: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-gdbqh/services/proxy-service-hx9wb:portname2/proxy/: bar (200; 13.726276ms)
Dec 10 14:11:43.620: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-gdbqh/services/http:proxy-service-hx9wb:portname2/proxy/: bar (200; 13.809909ms)
Dec 10 14:11:43.620: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-gdbqh/services/https:proxy-service-hx9wb:tlsportname2/proxy/: tls qux (200; 14.111564ms)
Dec 10 14:11:43.620: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-gdbqh/services/http:proxy-service-hx9wb:portname1/proxy/: foo (200; 13.911641ms)
Dec 10 14:11:43.632: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-gdbqh/pods/proxy-service-hx9wb-f7qd4:162/proxy/: bar (200; 12.147021ms)
Dec 10 14:11:43.633: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-gdbqh/pods/proxy-service-hx9wb-f7qd4/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-gdbqh/pods/proxy-service-hx9wb-f7qd4/proxy/rewriteme"... (200; 12.405247ms)
Dec 10 14:11:43.633: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-gdbqh/pods/https:proxy-service-hx9wb-f7qd4:462/proxy/: tls qux (200; 12.405606ms)
Dec 10 14:11:43.633: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-gdbqh/pods/http:proxy-service-hx9wb-f7qd4:162/proxy/: bar (200; 12.781103ms)
Dec 10 14:11:43.633: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-gdbqh/pods/proxy-service-hx9wb-f7qd4:160/proxy/: foo (200; 13.239673ms)
Dec 10 14:11:43.633: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-gdbqh/pods/http:proxy-service-hx9wb-f7qd4:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-gdbqh/pods/http:proxy-service-hx9wb-f7qd4:1080/proxy/... (200; 12.944617ms)
Dec 10 14:11:43.634: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-gdbqh/pods/https:proxy-service-hx9wb-f7qd4:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-gdbqh/pods/https:proxy-service-hx9wb-f7qd4:443/proxy/... (200; 13.465885ms)
Dec 10 14:11:43.634: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-gdbqh/pods/http:proxy-service-hx9wb-f7qd4:160/proxy/: foo (200; 13.620937ms)
Dec 10 14:11:43.634: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-gdbqh/pods/https:proxy-service-hx9wb-f7qd4:460/proxy/: tls baz (200; 13.707263ms)
Dec 10 14:11:43.634: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-gdbqh/pods/proxy-service-hx9wb-f7qd4:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-gdbqh/pods/proxy-service-hx9wb-f7qd4:1080/proxy/rewri... (200; 13.935225ms)
Dec 10 14:11:43.635: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-gdbqh/services/proxy-service-hx9wb:portname2/proxy/: bar (200; 14.511769ms)
Dec 10 14:11:43.635: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-gdbqh/services/https:proxy-service-hx9wb:tlsportname1/proxy/: tls baz (200; 15.018464ms)
Dec 10 14:11:43.636: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-gdbqh/services/http:proxy-service-hx9wb:portname2/proxy/: bar (200; 15.626489ms)
Dec 10 14:11:43.636: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-gdbqh/services/proxy-service-hx9wb:portname1/proxy/: foo (200; 15.730954ms)
Dec 10 14:11:43.636: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-gdbqh/services/https:proxy-service-hx9wb:tlsportname2/proxy/: tls qux (200; 16.071753ms)
Dec 10 14:11:43.636: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-gdbqh/services/http:proxy-service-hx9wb:portname1/proxy/: foo (200; 15.824369ms)
STEP: deleting { ReplicationController} proxy-service-hx9wb in namespace e2e-tests-proxy-gdbqh, will wait for the garbage collector to delete the pods
Dec 10 14:11:43.701: INFO: Deleting { ReplicationController} proxy-service-hx9wb took: 10.762688ms
Dec 10 14:11:43.801: INFO: Terminating { ReplicationController} proxy-service-hx9wb pods took: 100.198631ms
[AfterEach] version v1
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 10 14:11:47.101: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-proxy-gdbqh" for this suite.
Dec 10 14:11:53.126: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 14:11:53.167: INFO: namespace: e2e-tests-proxy-gdbqh, resource: bindings, ignored listing per whitelist
Dec 10 14:11:53.237: INFO: namespace e2e-tests-proxy-gdbqh deletion completed in 6.126145675s

• [SLOW TEST:15.149 seconds]
[sig-network] Proxy
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy through a service and a pod  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 10 14:11:53.238: INFO: >>> kubeConfig: /tmp/kubeconfig-578738756
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the rs
STEP: Gathering metrics
W1210 14:12:23.856470      15 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Dec 10 14:12:23.856: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 10 14:12:23.856: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-62w2l" for this suite.
Dec 10 14:12:29.874: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 14:12:29.941: INFO: namespace: e2e-tests-gc-62w2l, resource: bindings, ignored listing per whitelist
Dec 10 14:12:29.981: INFO: namespace e2e-tests-gc-62w2l deletion completed in 6.12053403s

• [SLOW TEST:36.743 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 10 14:12:29.981: INFO: >>> kubeConfig: /tmp/kubeconfig-578738756
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Dec 10 14:12:38.106: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Dec 10 14:12:38.109: INFO: Pod pod-with-prestop-exec-hook still exists
Dec 10 14:12:40.110: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Dec 10 14:12:40.114: INFO: Pod pod-with-prestop-exec-hook still exists
Dec 10 14:12:42.110: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Dec 10 14:12:42.114: INFO: Pod pod-with-prestop-exec-hook still exists
Dec 10 14:12:44.110: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Dec 10 14:12:44.120: INFO: Pod pod-with-prestop-exec-hook still exists
Dec 10 14:12:46.110: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Dec 10 14:12:46.114: INFO: Pod pod-with-prestop-exec-hook still exists
Dec 10 14:12:48.110: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Dec 10 14:12:48.114: INFO: Pod pod-with-prestop-exec-hook still exists
Dec 10 14:12:50.110: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Dec 10 14:12:50.114: INFO: Pod pod-with-prestop-exec-hook still exists
Dec 10 14:12:52.110: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Dec 10 14:12:52.114: INFO: Pod pod-with-prestop-exec-hook still exists
Dec 10 14:12:54.110: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Dec 10 14:12:54.115: INFO: Pod pod-with-prestop-exec-hook still exists
Dec 10 14:12:56.110: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Dec 10 14:12:56.120: INFO: Pod pod-with-prestop-exec-hook still exists
Dec 10 14:12:58.110: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Dec 10 14:12:58.114: INFO: Pod pod-with-prestop-exec-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 10 14:12:58.126: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-lifecycle-hook-kjcwp" for this suite.
Dec 10 14:13:20.146: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 14:13:20.235: INFO: namespace: e2e-tests-container-lifecycle-hook-kjcwp, resource: bindings, ignored listing per whitelist
Dec 10 14:13:20.253: INFO: namespace e2e-tests-container-lifecycle-hook-kjcwp deletion completed in 22.122368496s

• [SLOW TEST:50.273 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when create a pod with lifecycle hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute prestop exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run rc 
  should create an rc from an image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 10 14:13:20.253: INFO: >>> kubeConfig: /tmp/kubeconfig-578738756
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Kubectl run rc
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1246
[It] should create an rc from an image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Dec 10 14:13:20.330: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-578738756 run e2e-test-nginx-rc --image=docker.io/library/nginx:1.14-alpine --generator=run/v1 --namespace=e2e-tests-kubectl-7ndzr'
Dec 10 14:13:20.428: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl create instead.\n"
Dec 10 14:13:20.428: INFO: stdout: "replicationcontroller/e2e-test-nginx-rc created\n"
STEP: verifying the rc e2e-test-nginx-rc was created
STEP: verifying the pod controlled by rc e2e-test-nginx-rc was created
STEP: confirm that you can get logs from an rc
Dec 10 14:13:20.437: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [e2e-test-nginx-rc-h2h7r]
Dec 10 14:13:20.437: INFO: Waiting up to 5m0s for pod "e2e-test-nginx-rc-h2h7r" in namespace "e2e-tests-kubectl-7ndzr" to be "running and ready"
Dec 10 14:13:20.444: INFO: Pod "e2e-test-nginx-rc-h2h7r": Phase="Pending", Reason="", readiness=false. Elapsed: 7.125248ms
Dec 10 14:13:22.449: INFO: Pod "e2e-test-nginx-rc-h2h7r": Phase="Running", Reason="", readiness=true. Elapsed: 2.011977215s
Dec 10 14:13:22.449: INFO: Pod "e2e-test-nginx-rc-h2h7r" satisfied condition "running and ready"
Dec 10 14:13:22.449: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [e2e-test-nginx-rc-h2h7r]
Dec 10 14:13:22.449: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-578738756 logs rc/e2e-test-nginx-rc --namespace=e2e-tests-kubectl-7ndzr'
Dec 10 14:13:22.567: INFO: stderr: ""
Dec 10 14:13:22.567: INFO: stdout: ""
[AfterEach] [k8s.io] Kubectl run rc
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1251
Dec 10 14:13:22.567: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-578738756 delete rc e2e-test-nginx-rc --namespace=e2e-tests-kubectl-7ndzr'
Dec 10 14:13:22.677: INFO: stderr: ""
Dec 10 14:13:22.678: INFO: stdout: "replicationcontroller \"e2e-test-nginx-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 10 14:13:22.678: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-7ndzr" for this suite.
Dec 10 14:13:44.699: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 14:13:44.778: INFO: namespace: e2e-tests-kubectl-7ndzr, resource: bindings, ignored listing per whitelist
Dec 10 14:13:44.805: INFO: namespace e2e-tests-kubectl-7ndzr deletion completed in 22.119784921s

• [SLOW TEST:24.552 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run rc
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create an rc from an image  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-network] Services 
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 10 14:13:44.807: INFO: >>> kubeConfig: /tmp/kubeconfig-578738756
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:83
[It] should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating service multi-endpoint-test in namespace e2e-tests-services-t8g9h
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-t8g9h to expose endpoints map[]
Dec 10 14:13:44.894: INFO: Get endpoints failed (3.142187ms elapsed, ignoring for 5s): endpoints "multi-endpoint-test" not found
Dec 10 14:13:45.898: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-t8g9h exposes endpoints map[] (1.007535828s elapsed)
STEP: Creating pod pod1 in namespace e2e-tests-services-t8g9h
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-t8g9h to expose endpoints map[pod1:[100]]
Dec 10 14:13:47.934: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-t8g9h exposes endpoints map[pod1:[100]] (2.027160506s elapsed)
STEP: Creating pod pod2 in namespace e2e-tests-services-t8g9h
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-t8g9h to expose endpoints map[pod1:[100] pod2:[101]]
Dec 10 14:13:52.023: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-t8g9h exposes endpoints map[pod1:[100] pod2:[101]] (4.081570149s elapsed)
STEP: Deleting pod pod1 in namespace e2e-tests-services-t8g9h
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-t8g9h to expose endpoints map[pod2:[101]]
Dec 10 14:13:52.041: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-t8g9h exposes endpoints map[pod2:[101]] (10.891996ms elapsed)
STEP: Deleting pod pod2 in namespace e2e-tests-services-t8g9h
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-t8g9h to expose endpoints map[]
Dec 10 14:13:52.054: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-t8g9h exposes endpoints map[] (4.44645ms elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 10 14:13:52.081: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-services-t8g9h" for this suite.
Dec 10 14:14:14.106: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 14:14:14.197: INFO: namespace: e2e-tests-services-t8g9h, resource: bindings, ignored listing per whitelist
Dec 10 14:14:14.215: INFO: namespace e2e-tests-services-t8g9h deletion completed in 22.129905262s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:88

• [SLOW TEST:29.408 seconds]
[sig-network] Services
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-storage] ConfigMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 10 14:14:14.215: INFO: >>> kubeConfig: /tmp/kubeconfig-578738756
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-upd-df59e10d-fc85-11e8-a36b-7e9ed3de7210
STEP: Creating the pod
STEP: Updating configmap configmap-test-upd-df59e10d-fc85-11e8-a36b-7e9ed3de7210
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 10 14:14:18.357: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-2zmxd" for this suite.
Dec 10 14:14:40.375: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 14:14:40.403: INFO: namespace: e2e-tests-configmap-2zmxd, resource: bindings, ignored listing per whitelist
Dec 10 14:14:40.479: INFO: namespace e2e-tests-configmap-2zmxd deletion completed in 22.117774825s

• [SLOW TEST:26.264 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 10 14:14:40.480: INFO: >>> kubeConfig: /tmp/kubeconfig-578738756
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:78
Dec 10 14:14:40.542: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Dec 10 14:14:40.549: INFO: Waiting for terminating namespaces to be deleted...
Dec 10 14:14:40.552: INFO: 
Logging pods the kubelet thinks is on node conformance-cluster1-k8s-node-1 before test
Dec 10 14:14:40.558: INFO: calico-node-wng6k from kube-system started at 2018-12-10 13:31:47 +0000 UTC (1 container statuses recorded)
Dec 10 14:14:40.558: INFO: 	Container calico-node ready: true, restart count 0
Dec 10 14:14:40.558: INFO: sonobuoy from heptio-sonobuoy started at 2018-12-10 13:42:48 +0000 UTC (1 container statuses recorded)
Dec 10 14:14:40.558: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Dec 10 14:14:40.558: INFO: sonobuoy-e2e-job-98e31667bd8c4837 from heptio-sonobuoy started at 2018-12-10 13:42:53 +0000 UTC (2 container statuses recorded)
Dec 10 14:14:40.558: INFO: 	Container e2e ready: true, restart count 0
Dec 10 14:14:40.558: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Dec 10 14:14:40.558: INFO: kube-proxy-pxl26 from kube-system started at 2018-12-10 13:32:28 +0000 UTC (1 container statuses recorded)
Dec 10 14:14:40.558: INFO: 	Container kube-proxy ready: true, restart count 0
Dec 10 14:14:40.558: INFO: sonobuoy-systemd-logs-daemon-set-fb293fe0c33e403d-krfqj from heptio-sonobuoy started at 2018-12-10 13:42:53 +0000 UTC (2 container statuses recorded)
Dec 10 14:14:40.558: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 0
Dec 10 14:14:40.558: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Dec 10 14:14:40.558: INFO: nginx-proxy-conformance-cluster1-k8s-node-1 from kube-system started at <nil> (0 container statuses recorded)
Dec 10 14:14:40.558: INFO: 
Logging pods the kubelet thinks is on node conformance-cluster1-k8s-node-2 before test
Dec 10 14:14:40.567: INFO: dns-autoscaler-66b95c57d9-thm4m from kube-system started at 2018-12-10 13:33:31 +0000 UTC (1 container statuses recorded)
Dec 10 14:14:40.567: INFO: 	Container autoscaler ready: true, restart count 0
Dec 10 14:14:40.567: INFO: calico-node-kspwz from kube-system started at 2018-12-10 13:31:47 +0000 UTC (1 container statuses recorded)
Dec 10 14:14:40.567: INFO: 	Container calico-node ready: true, restart count 0
Dec 10 14:14:40.567: INFO: calico-kube-controllers-7fbf568fdb-q84ks from kube-system started at 2018-12-10 13:31:59 +0000 UTC (1 container statuses recorded)
Dec 10 14:14:40.567: INFO: 	Container calico-kube-controllers ready: true, restart count 0
Dec 10 14:14:40.567: INFO: kubernetes-dashboard-68697c45d9-2tpxx from kube-system started at 2018-12-10 13:33:37 +0000 UTC (1 container statuses recorded)
Dec 10 14:14:40.567: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
Dec 10 14:14:40.567: INFO: sonobuoy-systemd-logs-daemon-set-fb293fe0c33e403d-4kjtv from heptio-sonobuoy started at 2018-12-10 13:42:53 +0000 UTC (2 container statuses recorded)
Dec 10 14:14:40.567: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 0
Dec 10 14:14:40.567: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Dec 10 14:14:40.567: INFO: nginx-proxy-conformance-cluster1-k8s-node-2 from kube-system started at <nil> (0 container statuses recorded)
Dec 10 14:14:40.567: INFO: kube-proxy-fzw6d from kube-system started at 2018-12-10 13:31:48 +0000 UTC (1 container statuses recorded)
Dec 10 14:14:40.567: INFO: 	Container kube-proxy ready: true, restart count 0
[It] validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: verifying the node has the label node conformance-cluster1-k8s-node-1
STEP: verifying the node has the label node conformance-cluster1-k8s-node-2
Dec 10 14:14:40.605: INFO: Pod sonobuoy requesting resource cpu=0m on Node conformance-cluster1-k8s-node-1
Dec 10 14:14:40.605: INFO: Pod sonobuoy-e2e-job-98e31667bd8c4837 requesting resource cpu=0m on Node conformance-cluster1-k8s-node-1
Dec 10 14:14:40.605: INFO: Pod sonobuoy-systemd-logs-daemon-set-fb293fe0c33e403d-4kjtv requesting resource cpu=0m on Node conformance-cluster1-k8s-node-2
Dec 10 14:14:40.605: INFO: Pod sonobuoy-systemd-logs-daemon-set-fb293fe0c33e403d-krfqj requesting resource cpu=0m on Node conformance-cluster1-k8s-node-1
Dec 10 14:14:40.605: INFO: Pod calico-kube-controllers-7fbf568fdb-q84ks requesting resource cpu=30m on Node conformance-cluster1-k8s-node-2
Dec 10 14:14:40.605: INFO: Pod calico-node-kspwz requesting resource cpu=150m on Node conformance-cluster1-k8s-node-2
Dec 10 14:14:40.605: INFO: Pod calico-node-wng6k requesting resource cpu=150m on Node conformance-cluster1-k8s-node-1
Dec 10 14:14:40.605: INFO: Pod dns-autoscaler-66b95c57d9-thm4m requesting resource cpu=20m on Node conformance-cluster1-k8s-node-2
Dec 10 14:14:40.605: INFO: Pod kube-proxy-fzw6d requesting resource cpu=0m on Node conformance-cluster1-k8s-node-2
Dec 10 14:14:40.605: INFO: Pod kube-proxy-pxl26 requesting resource cpu=0m on Node conformance-cluster1-k8s-node-1
Dec 10 14:14:40.605: INFO: Pod kubernetes-dashboard-68697c45d9-2tpxx requesting resource cpu=50m on Node conformance-cluster1-k8s-node-2
Dec 10 14:14:40.606: INFO: Pod nginx-proxy-conformance-cluster1-k8s-node-1 requesting resource cpu=25m on Node conformance-cluster1-k8s-node-1
Dec 10 14:14:40.606: INFO: Pod nginx-proxy-conformance-cluster1-k8s-node-2 requesting resource cpu=25m on Node conformance-cluster1-k8s-node-2
STEP: Starting Pods to consume most of the cluster CPU.
STEP: Creating another pod that requires unavailable amount of CPU.
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-ef0a0609-fc85-11e8-a36b-7e9ed3de7210.156efe41c296d751], Reason = [Scheduled], Message = [Successfully assigned e2e-tests-sched-pred-gdbp6/filler-pod-ef0a0609-fc85-11e8-a36b-7e9ed3de7210 to conformance-cluster1-k8s-node-1]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-ef0a0609-fc85-11e8-a36b-7e9ed3de7210.156efe41f920c736], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-ef0a0609-fc85-11e8-a36b-7e9ed3de7210.156efe41fb62b2a9], Reason = [Created], Message = [Created container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-ef0a0609-fc85-11e8-a36b-7e9ed3de7210.156efe42062602d2], Reason = [Started], Message = [Started container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-ef0bdb0b-fc85-11e8-a36b-7e9ed3de7210.156efe41c32d81a1], Reason = [Scheduled], Message = [Successfully assigned e2e-tests-sched-pred-gdbp6/filler-pod-ef0bdb0b-fc85-11e8-a36b-7e9ed3de7210 to conformance-cluster1-k8s-node-2]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-ef0bdb0b-fc85-11e8-a36b-7e9ed3de7210.156efe41fcdb7ff5], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-ef0bdb0b-fc85-11e8-a36b-7e9ed3de7210.156efe41ff509ff1], Reason = [Created], Message = [Created container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-ef0bdb0b-fc85-11e8-a36b-7e9ed3de7210.156efe420c972976], Reason = [Started], Message = [Started container]
STEP: Considering event: 
Type = [Warning], Name = [additional-pod.156efe423b26386d], Reason = [FailedScheduling], Message = [0/5 nodes are available: 2 Insufficient cpu, 3 node(s) had taints that the pod didn't tolerate.]
STEP: removing the label node off the node conformance-cluster1-k8s-node-1
STEP: verifying the node doesn't have the label node
STEP: removing the label node off the node conformance-cluster1-k8s-node-2
STEP: verifying the node doesn't have the label node
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 10 14:14:43.690: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-sched-pred-gdbp6" for this suite.
Dec 10 14:14:49.716: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 14:14:49.749: INFO: namespace: e2e-tests-sched-pred-gdbp6, resource: bindings, ignored listing per whitelist
Dec 10 14:14:49.826: INFO: namespace e2e-tests-sched-pred-gdbp6 deletion completed in 6.12921338s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:69

• [SLOW TEST:9.346 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 10 14:14:49.826: INFO: >>> kubeConfig: /tmp/kubeconfig-578738756
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0644 on node default medium
Dec 10 14:14:49.891: INFO: Waiting up to 5m0s for pod "pod-f4910f87-fc85-11e8-a36b-7e9ed3de7210" in namespace "e2e-tests-emptydir-qvtrj" to be "success or failure"
Dec 10 14:14:49.897: INFO: Pod "pod-f4910f87-fc85-11e8-a36b-7e9ed3de7210": Phase="Pending", Reason="", readiness=false. Elapsed: 6.217317ms
Dec 10 14:14:51.903: INFO: Pod "pod-f4910f87-fc85-11e8-a36b-7e9ed3de7210": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011325197s
Dec 10 14:14:53.907: INFO: Pod "pod-f4910f87-fc85-11e8-a36b-7e9ed3de7210": Phase="Pending", Reason="", readiness=false. Elapsed: 4.015603617s
Dec 10 14:14:55.911: INFO: Pod "pod-f4910f87-fc85-11e8-a36b-7e9ed3de7210": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.020195905s
STEP: Saw pod success
Dec 10 14:14:55.911: INFO: Pod "pod-f4910f87-fc85-11e8-a36b-7e9ed3de7210" satisfied condition "success or failure"
Dec 10 14:14:55.915: INFO: Trying to get logs from node conformance-cluster1-k8s-node-2 pod pod-f4910f87-fc85-11e8-a36b-7e9ed3de7210 container test-container: <nil>
STEP: delete the pod
Dec 10 14:14:55.939: INFO: Waiting for pod pod-f4910f87-fc85-11e8-a36b-7e9ed3de7210 to disappear
Dec 10 14:14:55.942: INFO: Pod pod-f4910f87-fc85-11e8-a36b-7e9ed3de7210 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 10 14:14:55.942: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-qvtrj" for this suite.
Dec 10 14:15:01.961: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 14:15:02.053: INFO: namespace: e2e-tests-emptydir-qvtrj, resource: bindings, ignored listing per whitelist
Dec 10 14:15:02.078: INFO: namespace e2e-tests-emptydir-qvtrj deletion completed in 6.131858488s

• [SLOW TEST:12.252 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 10 14:15:02.079: INFO: >>> kubeConfig: /tmp/kubeconfig-578738756
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Dec 10 14:15:02.152: INFO: Waiting up to 5m0s for pod "downwardapi-volume-fbe016c1-fc85-11e8-a36b-7e9ed3de7210" in namespace "e2e-tests-projected-w2bhl" to be "success or failure"
Dec 10 14:15:02.158: INFO: Pod "downwardapi-volume-fbe016c1-fc85-11e8-a36b-7e9ed3de7210": Phase="Pending", Reason="", readiness=false. Elapsed: 6.550754ms
Dec 10 14:15:04.163: INFO: Pod "downwardapi-volume-fbe016c1-fc85-11e8-a36b-7e9ed3de7210": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.011312388s
STEP: Saw pod success
Dec 10 14:15:04.163: INFO: Pod "downwardapi-volume-fbe016c1-fc85-11e8-a36b-7e9ed3de7210" satisfied condition "success or failure"
Dec 10 14:15:04.167: INFO: Trying to get logs from node conformance-cluster1-k8s-node-2 pod downwardapi-volume-fbe016c1-fc85-11e8-a36b-7e9ed3de7210 container client-container: <nil>
STEP: delete the pod
Dec 10 14:15:04.194: INFO: Waiting for pod downwardapi-volume-fbe016c1-fc85-11e8-a36b-7e9ed3de7210 to disappear
Dec 10 14:15:04.198: INFO: Pod downwardapi-volume-fbe016c1-fc85-11e8-a36b-7e9ed3de7210 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 10 14:15:04.198: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-w2bhl" for this suite.
Dec 10 14:15:10.218: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 14:15:10.323: INFO: namespace: e2e-tests-projected-w2bhl, resource: bindings, ignored listing per whitelist
Dec 10 14:15:10.335: INFO: namespace e2e-tests-projected-w2bhl deletion completed in 6.132705392s

• [SLOW TEST:8.256 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl describe 
  should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 10 14:15:10.335: INFO: >>> kubeConfig: /tmp/kubeconfig-578738756
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Dec 10 14:15:10.394: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-578738756 version --client'
Dec 10 14:15:10.457: INFO: stderr: ""
Dec 10 14:15:10.457: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"12\", GitVersion:\"v1.12.1\", GitCommit:\"4ed3216f3ec431b140b1d899130a69fc671678f4\", GitTreeState:\"clean\", BuildDate:\"2018-10-05T16:46:06Z\", GoVersion:\"go1.10.4\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
Dec 10 14:15:10.458: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-578738756 create -f - --namespace=e2e-tests-kubectl-db7gv'
Dec 10 14:15:10.617: INFO: stderr: ""
Dec 10 14:15:10.617: INFO: stdout: "replicationcontroller/redis-master created\n"
Dec 10 14:15:10.617: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-578738756 create -f - --namespace=e2e-tests-kubectl-db7gv'
Dec 10 14:15:10.816: INFO: stderr: ""
Dec 10 14:15:10.816: INFO: stdout: "service/redis-master created\n"
STEP: Waiting for Redis master to start.
Dec 10 14:15:11.820: INFO: Selector matched 1 pods for map[app:redis]
Dec 10 14:15:11.820: INFO: Found 0 / 1
Dec 10 14:15:12.820: INFO: Selector matched 1 pods for map[app:redis]
Dec 10 14:15:12.820: INFO: Found 1 / 1
Dec 10 14:15:12.820: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Dec 10 14:15:12.824: INFO: Selector matched 1 pods for map[app:redis]
Dec 10 14:15:12.824: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Dec 10 14:15:12.824: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-578738756 describe pod redis-master-b2c5g --namespace=e2e-tests-kubectl-db7gv'
Dec 10 14:15:12.925: INFO: stderr: ""
Dec 10 14:15:12.925: INFO: stdout: "Name:               redis-master-b2c5g\nNamespace:          e2e-tests-kubectl-db7gv\nPriority:           0\nPriorityClassName:  <none>\nNode:               conformance-cluster1-k8s-node-2/10.0.0.10\nStart Time:         Mon, 10 Dec 2018 14:15:10 +0000\nLabels:             app=redis\n                    role=master\nAnnotations:        <none>\nStatus:             Running\nIP:                 10.233.122.237\nControlled By:      ReplicationController/redis-master\nContainers:\n  redis-master:\n    Container ID:   docker://f8bb1ef3fe2c6ff4a255cf940e6abe1d4137af813a7ab66613fbc3ffd11d8d2a\n    Image:          gcr.io/kubernetes-e2e-test-images/redis:1.0\n    Image ID:       docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830\n    Port:           6379/TCP\n    Host Port:      0/TCP\n    State:          Running\n      Started:      Mon, 10 Dec 2018 14:15:11 +0000\n    Ready:          True\n    Restart Count:  0\n    Environment:    <none>\n    Mounts:\n      /var/run/secrets/kubernetes.io/serviceaccount from default-token-fpmxs (ro)\nConditions:\n  Type              Status\n  Initialized       True \n  Ready             True \n  ContainersReady   True \n  PodScheduled      True \nVolumes:\n  default-token-fpmxs:\n    Type:        Secret (a volume populated by a Secret)\n    SecretName:  default-token-fpmxs\n    Optional:    false\nQoS Class:       BestEffort\nNode-Selectors:  <none>\nTolerations:     node.kubernetes.io/not-ready:NoExecute for 300s\n                 node.kubernetes.io/unreachable:NoExecute for 300s\nEvents:\n  Type    Reason     Age   From                                      Message\n  ----    ------     ----  ----                                      -------\n  Normal  Scheduled  2s    default-scheduler                         Successfully assigned e2e-tests-kubectl-db7gv/redis-master-b2c5g to conformance-cluster1-k8s-node-2\n  Normal  Pulled     1s    kubelet, conformance-cluster1-k8s-node-2  Container image \"gcr.io/kubernetes-e2e-test-images/redis:1.0\" already present on machine\n  Normal  Created    1s    kubelet, conformance-cluster1-k8s-node-2  Created container\n  Normal  Started    1s    kubelet, conformance-cluster1-k8s-node-2  Started container\n"
Dec 10 14:15:12.926: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-578738756 describe rc redis-master --namespace=e2e-tests-kubectl-db7gv'
Dec 10 14:15:13.053: INFO: stderr: ""
Dec 10 14:15:13.053: INFO: stdout: "Name:         redis-master\nNamespace:    e2e-tests-kubectl-db7gv\nSelector:     app=redis,role=master\nLabels:       app=redis\n              role=master\nAnnotations:  <none>\nReplicas:     1 current / 1 desired\nPods Status:  1 Running / 0 Waiting / 0 Succeeded / 0 Failed\nPod Template:\n  Labels:  app=redis\n           role=master\n  Containers:\n   redis-master:\n    Image:        gcr.io/kubernetes-e2e-test-images/redis:1.0\n    Port:         6379/TCP\n    Host Port:    0/TCP\n    Environment:  <none>\n    Mounts:       <none>\n  Volumes:        <none>\nEvents:\n  Type    Reason            Age   From                    Message\n  ----    ------            ----  ----                    -------\n  Normal  SuccessfulCreate  3s    replication-controller  Created pod: redis-master-b2c5g\n"
Dec 10 14:15:13.053: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-578738756 describe service redis-master --namespace=e2e-tests-kubectl-db7gv'
Dec 10 14:15:13.165: INFO: stderr: ""
Dec 10 14:15:13.165: INFO: stdout: "Name:              redis-master\nNamespace:         e2e-tests-kubectl-db7gv\nLabels:            app=redis\n                   role=master\nAnnotations:       <none>\nSelector:          app=redis,role=master\nType:              ClusterIP\nIP:                10.233.40.119\nPort:              <unset>  6379/TCP\nTargetPort:        redis-server/TCP\nEndpoints:         10.233.122.237:6379\nSession Affinity:  None\nEvents:            <none>\n"
Dec 10 14:15:13.169: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-578738756 describe node conformance-cluster1-k8s-master-1'
Dec 10 14:15:13.293: INFO: stderr: ""
Dec 10 14:15:13.293: INFO: stdout: "Name:               conformance-cluster1-k8s-master-1\nRoles:              master\nLabels:             beta.kubernetes.io/arch=amd64\n                    beta.kubernetes.io/instance-type=3f73fc93-ec61-4808-88df-2580d94c1a9b\n                    beta.kubernetes.io/os=linux\n                    failure-domain.beta.kubernetes.io/region=se-sto\n                    failure-domain.beta.kubernetes.io/zone=sto1\n                    kubernetes.io/hostname=conformance-cluster1-k8s-master-1\n                    node-role.kubernetes.io/master=\nAnnotations:        kubeadm.alpha.kubernetes.io/cri-socket: /var/run/dockershim.sock\n                    node.alpha.kubernetes.io/ttl: 0\n                    volumes.kubernetes.io/controller-managed-attach-detach: true\nCreationTimestamp:  Mon, 10 Dec 2018 13:29:15 +0000\nTaints:             node-role.kubernetes.io/master:NoSchedule\nUnschedulable:      false\nConditions:\n  Type             Status  LastHeartbeatTime                 LastTransitionTime                Reason                       Message\n  ----             ------  -----------------                 ------------------                ------                       -------\n  OutOfDisk        False   Mon, 10 Dec 2018 14:15:12 +0000   Mon, 10 Dec 2018 13:29:10 +0000   KubeletHasSufficientDisk     kubelet has sufficient disk space available\n  MemoryPressure   False   Mon, 10 Dec 2018 14:15:12 +0000   Mon, 10 Dec 2018 13:29:10 +0000   KubeletHasSufficientMemory   kubelet has sufficient memory available\n  DiskPressure     False   Mon, 10 Dec 2018 14:15:12 +0000   Mon, 10 Dec 2018 13:29:10 +0000   KubeletHasNoDiskPressure     kubelet has no disk pressure\n  PIDPressure      False   Mon, 10 Dec 2018 14:15:12 +0000   Mon, 10 Dec 2018 13:29:10 +0000   KubeletHasSufficientPID      kubelet has sufficient PID available\n  Ready            True    Mon, 10 Dec 2018 14:15:12 +0000   Mon, 10 Dec 2018 13:30:45 +0000   KubeletReady                 kubelet is posting ready status. AppArmor enabled\nAddresses:\n  InternalIP:  10.0.0.4\n  ExternalIP:  212.237.149.116\n  Hostname:    conformance-cluster1-k8s-master-1\nCapacity:\n cpu:                2\n ephemeral-storage:  40593708Ki\n hugepages-1Gi:      0\n hugepages-2Mi:      0\n memory:             8175040Ki\n pods:               110\nAllocatable:\n cpu:                1800m\n ephemeral-storage:  37411161231\n hugepages-1Gi:      0\n hugepages-2Mi:      0\n memory:             7572640Ki\n pods:               110\nSystem Info:\n Machine ID:                 f8a8875256e847baabe8267db10e91f1\n System UUID:                F8A88752-56E8-47BA-ABE8-267DB10E91F1\n Boot ID:                    857eb34e-17c4-44aa-9293-5bbeb5c38132\n Kernel Version:             4.4.0-135-generic\n OS Image:                   Ubuntu 16.04.5 LTS\n Operating System:           linux\n Architecture:               amd64\n Container Runtime Version:  docker://18.6.1\n Kubelet Version:            v1.12.3\n Kube-Proxy Version:         v1.12.3\nPodCIDR:                     10.233.66.0/24\nProviderID:                  openstack:///f8a88752-56e8-47ba-abe8-267db10e91f1\nNon-terminated Pods:         (8 in total)\n  Namespace                  Name                                                         CPU Requests  CPU Limits  Memory Requests  Memory Limits\n  ---------                  ----                                                         ------------  ----------  ---------------  -------------\n  heptio-sonobuoy            sonobuoy-systemd-logs-daemon-set-fb293fe0c33e403d-hfpkn      0 (0%)        0 (0%)      0 (0%)           0 (0%)\n  kube-system                calico-node-2btqv                                            150m (8%)     300m (16%)  64M (0%)         500M (6%)\n  kube-system                coredns-788d98cc7b-2brz2                                     100m (5%)     0 (0%)      70Mi (0%)        170Mi (2%)\n  kube-system                kube-apiserver-conformance-cluster1-k8s-master-1             250m (13%)    0 (0%)      0 (0%)           0 (0%)\n  kube-system                kube-controller-manager-conformance-cluster1-k8s-master-1    200m (11%)    0 (0%)      0 (0%)           0 (0%)\n  kube-system                kube-proxy-6hp56                                             0 (0%)        0 (0%)      0 (0%)           0 (0%)\n  kube-system                kube-scheduler-conformance-cluster1-k8s-master-1             100m (5%)     0 (0%)      0 (0%)           0 (0%)\n  kube-system                metrics-server-694898c9bc-fdctc                              5m (0%)       100m (5%)   50Mi (0%)        300Mi (4%)\nAllocated resources:\n  (Total limits may be over 100 percent, i.e., overcommitted.)\n  Resource  Requests        Limits\n  --------  --------        ------\n  cpu       805m (44%)      400m (22%)\n  memory    189829120 (2%)  992830720 (12%)\nEvents:\n  Type    Reason                   Age                From                                           Message\n  ----    ------                   ----               ----                                           -------\n  Normal  Starting                 46m                kubelet, conformance-cluster1-k8s-master-1     Starting kubelet.\n  Normal  NodeAllocatableEnforced  46m                kubelet, conformance-cluster1-k8s-master-1     Updated Node Allocatable limit across pods\n  Normal  NodeHasSufficientPID     46m (x5 over 46m)  kubelet, conformance-cluster1-k8s-master-1     Node conformance-cluster1-k8s-master-1 status is now: NodeHasSufficientPID\n  Normal  NodeHasSufficientDisk    46m (x6 over 46m)  kubelet, conformance-cluster1-k8s-master-1     Node conformance-cluster1-k8s-master-1 status is now: NodeHasSufficientDisk\n  Normal  NodeHasSufficientMemory  46m (x6 over 46m)  kubelet, conformance-cluster1-k8s-master-1     Node conformance-cluster1-k8s-master-1 status is now: NodeHasSufficientMemory\n  Normal  NodeHasNoDiskPressure    46m (x6 over 46m)  kubelet, conformance-cluster1-k8s-master-1     Node conformance-cluster1-k8s-master-1 status is now: NodeHasNoDiskPressure\n  Normal  Starting                 45m                kubelet, conformance-cluster1-k8s-master-1     Starting kubelet.\n  Normal  NodeAllocatableEnforced  45m                kubelet, conformance-cluster1-k8s-master-1     Updated Node Allocatable limit across pods\n  Normal  NodeHasSufficientDisk    45m                kubelet, conformance-cluster1-k8s-master-1     Node conformance-cluster1-k8s-master-1 status is now: NodeHasSufficientDisk\n  Normal  NodeHasSufficientMemory  45m                kubelet, conformance-cluster1-k8s-master-1     Node conformance-cluster1-k8s-master-1 status is now: NodeHasSufficientMemory\n  Normal  NodeHasNoDiskPressure    45m                kubelet, conformance-cluster1-k8s-master-1     Node conformance-cluster1-k8s-master-1 status is now: NodeHasNoDiskPressure\n  Normal  NodeHasSufficientPID     45m                kubelet, conformance-cluster1-k8s-master-1     Node conformance-cluster1-k8s-master-1 status is now: NodeHasSufficientPID\n  Normal  Starting                 45m                kube-proxy, conformance-cluster1-k8s-master-1  Starting kube-proxy.\n  Normal  NodeReady                44m                kubelet, conformance-cluster1-k8s-master-1     Node conformance-cluster1-k8s-master-1 status is now: NodeReady\n  Normal  Starting                 43m                kube-proxy, conformance-cluster1-k8s-master-1  Starting kube-proxy.\n"
Dec 10 14:15:13.293: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-578738756 describe namespace e2e-tests-kubectl-db7gv'
Dec 10 14:15:13.390: INFO: stderr: ""
Dec 10 14:15:13.390: INFO: stdout: "Name:         e2e-tests-kubectl-db7gv\nLabels:       e2e-framework=kubectl\n              e2e-run=8c1b051f-fc81-11e8-a36b-7e9ed3de7210\nAnnotations:  <none>\nStatus:       Active\n\nNo resource quota.\n\nNo resource limits.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 10 14:15:13.390: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-db7gv" for this suite.
Dec 10 14:15:35.410: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 14:15:35.465: INFO: namespace: e2e-tests-kubectl-db7gv, resource: bindings, ignored listing per whitelist
Dec 10 14:15:35.511: INFO: namespace e2e-tests-kubectl-db7gv deletion completed in 22.115750499s

• [SLOW TEST:25.176 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl describe
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should check if kubectl describe prints relevant information for rc and pods  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 10 14:15:35.512: INFO: >>> kubeConfig: /tmp/kubeconfig-578738756
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-map-0fcea6c5-fc86-11e8-a36b-7e9ed3de7210
STEP: Creating a pod to test consume configMaps
Dec 10 14:15:35.601: INFO: Waiting up to 5m0s for pod "pod-configmaps-0fcfc437-fc86-11e8-a36b-7e9ed3de7210" in namespace "e2e-tests-configmap-zjsp4" to be "success or failure"
Dec 10 14:15:35.606: INFO: Pod "pod-configmaps-0fcfc437-fc86-11e8-a36b-7e9ed3de7210": Phase="Pending", Reason="", readiness=false. Elapsed: 5.240891ms
Dec 10 14:15:37.611: INFO: Pod "pod-configmaps-0fcfc437-fc86-11e8-a36b-7e9ed3de7210": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009487563s
STEP: Saw pod success
Dec 10 14:15:37.611: INFO: Pod "pod-configmaps-0fcfc437-fc86-11e8-a36b-7e9ed3de7210" satisfied condition "success or failure"
Dec 10 14:15:37.614: INFO: Trying to get logs from node conformance-cluster1-k8s-node-2 pod pod-configmaps-0fcfc437-fc86-11e8-a36b-7e9ed3de7210 container configmap-volume-test: <nil>
STEP: delete the pod
Dec 10 14:15:37.640: INFO: Waiting for pod pod-configmaps-0fcfc437-fc86-11e8-a36b-7e9ed3de7210 to disappear
Dec 10 14:15:37.644: INFO: Pod pod-configmaps-0fcfc437-fc86-11e8-a36b-7e9ed3de7210 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 10 14:15:37.644: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-zjsp4" for this suite.
Dec 10 14:15:43.663: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 14:15:43.773: INFO: namespace: e2e-tests-configmap-zjsp4, resource: bindings, ignored listing per whitelist
Dec 10 14:15:43.774: INFO: namespace e2e-tests-configmap-zjsp4 deletion completed in 6.125307666s

• [SLOW TEST:8.262 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 10 14:15:43.775: INFO: >>> kubeConfig: /tmp/kubeconfig-578738756
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-vcbpx
[It] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Initializing watcher for selector baz=blah,foo=bar
STEP: Creating stateful set ss in namespace e2e-tests-statefulset-vcbpx
STEP: Waiting until all stateful set ss replicas will be running in namespace e2e-tests-statefulset-vcbpx
Dec 10 14:15:43.852: INFO: Found 0 stateful pods, waiting for 1
Dec 10 14:15:53.863: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will halt with unhealthy stateful pod
Dec 10 14:15:53.866: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-578738756 exec --namespace=e2e-tests-statefulset-vcbpx ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Dec 10 14:15:54.066: INFO: stderr: ""
Dec 10 14:15:54.066: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Dec 10 14:15:54.066: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Dec 10 14:15:54.071: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Dec 10 14:16:04.081: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Dec 10 14:16:04.081: INFO: Waiting for statefulset status.replicas updated to 0
Dec 10 14:16:04.099: INFO: Verifying statefulset ss doesn't scale past 1 for another 9.999999656s
Dec 10 14:16:05.104: INFO: Verifying statefulset ss doesn't scale past 1 for another 8.995310005s
Dec 10 14:16:06.108: INFO: Verifying statefulset ss doesn't scale past 1 for another 7.990791041s
Dec 10 14:16:07.113: INFO: Verifying statefulset ss doesn't scale past 1 for another 6.98636106s
Dec 10 14:16:08.118: INFO: Verifying statefulset ss doesn't scale past 1 for another 5.981388024s
Dec 10 14:16:09.122: INFO: Verifying statefulset ss doesn't scale past 1 for another 4.976721498s
Dec 10 14:16:10.126: INFO: Verifying statefulset ss doesn't scale past 1 for another 3.972609433s
Dec 10 14:16:11.131: INFO: Verifying statefulset ss doesn't scale past 1 for another 2.9682658s
Dec 10 14:16:12.136: INFO: Verifying statefulset ss doesn't scale past 1 for another 1.963573811s
Dec 10 14:16:13.140: INFO: Verifying statefulset ss doesn't scale past 1 for another 958.693098ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace e2e-tests-statefulset-vcbpx
Dec 10 14:16:14.151: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-578738756 exec --namespace=e2e-tests-statefulset-vcbpx ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec 10 14:16:14.358: INFO: stderr: ""
Dec 10 14:16:14.358: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Dec 10 14:16:14.358: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Dec 10 14:16:14.363: INFO: Found 1 stateful pods, waiting for 3
Dec 10 14:16:24.374: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Dec 10 14:16:24.374: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Dec 10 14:16:24.374: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Verifying that stateful set ss was scaled up in order
STEP: Scale down will halt with unhealthy stateful pod
Dec 10 14:16:24.380: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-578738756 exec --namespace=e2e-tests-statefulset-vcbpx ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Dec 10 14:16:24.569: INFO: stderr: ""
Dec 10 14:16:24.569: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Dec 10 14:16:24.569: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Dec 10 14:16:24.570: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-578738756 exec --namespace=e2e-tests-statefulset-vcbpx ss-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Dec 10 14:16:24.766: INFO: stderr: ""
Dec 10 14:16:24.766: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Dec 10 14:16:24.766: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Dec 10 14:16:24.767: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-578738756 exec --namespace=e2e-tests-statefulset-vcbpx ss-2 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Dec 10 14:16:24.975: INFO: stderr: ""
Dec 10 14:16:24.975: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Dec 10 14:16:24.975: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-2: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Dec 10 14:16:24.975: INFO: Waiting for statefulset status.replicas updated to 0
Dec 10 14:16:24.980: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 2
Dec 10 14:16:34.993: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Dec 10 14:16:34.993: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Dec 10 14:16:34.993: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Dec 10 14:16:35.007: INFO: Verifying statefulset ss doesn't scale past 3 for another 9.999999651s
Dec 10 14:16:36.012: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.99406906s
Dec 10 14:16:37.016: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.989564594s
Dec 10 14:16:38.021: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.985172457s
Dec 10 14:16:39.026: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.980599324s
Dec 10 14:16:40.030: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.975766675s
Dec 10 14:16:41.034: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.971197402s
Dec 10 14:16:42.039: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.966955871s
Dec 10 14:16:43.046: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.962310026s
Dec 10 14:16:44.051: INFO: Verifying statefulset ss doesn't scale past 3 for another 955.799234ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacee2e-tests-statefulset-vcbpx
Dec 10 14:16:45.061: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-578738756 exec --namespace=e2e-tests-statefulset-vcbpx ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec 10 14:16:45.261: INFO: stderr: ""
Dec 10 14:16:45.261: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Dec 10 14:16:45.261: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Dec 10 14:16:45.261: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-578738756 exec --namespace=e2e-tests-statefulset-vcbpx ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec 10 14:16:45.452: INFO: stderr: ""
Dec 10 14:16:45.452: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Dec 10 14:16:45.452: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Dec 10 14:16:45.452: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-578738756 exec --namespace=e2e-tests-statefulset-vcbpx ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec 10 14:16:45.671: INFO: stderr: ""
Dec 10 14:16:45.671: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Dec 10 14:16:45.671: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-2: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Dec 10 14:16:45.671: INFO: Scaling statefulset ss to 0
STEP: Verifying that stateful set ss was scaled down in reverse order
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Dec 10 14:17:15.694: INFO: Deleting all statefulset in ns e2e-tests-statefulset-vcbpx
Dec 10 14:17:15.698: INFO: Scaling statefulset ss to 0
Dec 10 14:17:15.709: INFO: Waiting for statefulset status.replicas updated to 0
Dec 10 14:17:15.712: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 10 14:17:15.731: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-vcbpx" for this suite.
Dec 10 14:17:21.753: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 14:17:21.841: INFO: namespace: e2e-tests-statefulset-vcbpx, resource: bindings, ignored listing per whitelist
Dec 10 14:17:21.873: INFO: namespace e2e-tests-statefulset-vcbpx deletion completed in 6.137922222s

• [SLOW TEST:98.098 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 10 14:17:21.874: INFO: >>> kubeConfig: /tmp/kubeconfig-578738756
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0644 on tmpfs
Dec 10 14:17:21.945: INFO: Waiting up to 5m0s for pod "pod-4f32cd29-fc86-11e8-a36b-7e9ed3de7210" in namespace "e2e-tests-emptydir-n5fvq" to be "success or failure"
Dec 10 14:17:21.950: INFO: Pod "pod-4f32cd29-fc86-11e8-a36b-7e9ed3de7210": Phase="Pending", Reason="", readiness=false. Elapsed: 5.149815ms
Dec 10 14:17:23.955: INFO: Pod "pod-4f32cd29-fc86-11e8-a36b-7e9ed3de7210": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009922558s
STEP: Saw pod success
Dec 10 14:17:23.955: INFO: Pod "pod-4f32cd29-fc86-11e8-a36b-7e9ed3de7210" satisfied condition "success or failure"
Dec 10 14:17:23.959: INFO: Trying to get logs from node conformance-cluster1-k8s-node-2 pod pod-4f32cd29-fc86-11e8-a36b-7e9ed3de7210 container test-container: <nil>
STEP: delete the pod
Dec 10 14:17:23.983: INFO: Waiting for pod pod-4f32cd29-fc86-11e8-a36b-7e9ed3de7210 to disappear
Dec 10 14:17:23.986: INFO: Pod pod-4f32cd29-fc86-11e8-a36b-7e9ed3de7210 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 10 14:17:23.986: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-n5fvq" for this suite.
Dec 10 14:17:30.007: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 14:17:30.061: INFO: namespace: e2e-tests-emptydir-n5fvq, resource: bindings, ignored listing per whitelist
Dec 10 14:17:30.122: INFO: namespace e2e-tests-emptydir-n5fvq deletion completed in 6.131857612s

• [SLOW TEST:8.248 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-api-machinery] Downward API 
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 10 14:17:30.122: INFO: >>> kubeConfig: /tmp/kubeconfig-578738756
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Dec 10 14:17:30.189: INFO: Waiting up to 5m0s for pod "downward-api-541c8e0e-fc86-11e8-a36b-7e9ed3de7210" in namespace "e2e-tests-downward-api-wcrtp" to be "success or failure"
Dec 10 14:17:30.193: INFO: Pod "downward-api-541c8e0e-fc86-11e8-a36b-7e9ed3de7210": Phase="Pending", Reason="", readiness=false. Elapsed: 4.696319ms
Dec 10 14:17:32.198: INFO: Pod "downward-api-541c8e0e-fc86-11e8-a36b-7e9ed3de7210": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009233603s
STEP: Saw pod success
Dec 10 14:17:32.198: INFO: Pod "downward-api-541c8e0e-fc86-11e8-a36b-7e9ed3de7210" satisfied condition "success or failure"
Dec 10 14:17:32.202: INFO: Trying to get logs from node conformance-cluster1-k8s-node-2 pod downward-api-541c8e0e-fc86-11e8-a36b-7e9ed3de7210 container dapi-container: <nil>
STEP: delete the pod
Dec 10 14:17:32.228: INFO: Waiting for pod downward-api-541c8e0e-fc86-11e8-a36b-7e9ed3de7210 to disappear
Dec 10 14:17:32.231: INFO: Pod downward-api-541c8e0e-fc86-11e8-a36b-7e9ed3de7210 no longer exists
[AfterEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 10 14:17:32.231: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-wcrtp" for this suite.
Dec 10 14:17:38.250: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 14:17:38.306: INFO: namespace: e2e-tests-downward-api-wcrtp, resource: bindings, ignored listing per whitelist
Dec 10 14:17:38.357: INFO: namespace e2e-tests-downward-api-wcrtp deletion completed in 6.121311425s

• [SLOW TEST:8.235 seconds]
[sig-api-machinery] Downward API
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 10 14:17:38.358: INFO: >>> kubeConfig: /tmp/kubeconfig-578738756
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: Gathering metrics
W1210 14:17:44.460364      15 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Dec 10 14:17:44.461: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 10 14:17:44.461: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-kklrs" for this suite.
Dec 10 14:17:50.488: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 14:17:50.552: INFO: namespace: e2e-tests-gc-kklrs, resource: bindings, ignored listing per whitelist
Dec 10 14:17:50.596: INFO: namespace e2e-tests-gc-kklrs deletion completed in 6.127563036s

• [SLOW TEST:12.238 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 10 14:17:50.597: INFO: >>> kubeConfig: /tmp/kubeconfig-578738756
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:98
[It] should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Dec 10 14:17:50.667: INFO: Requires at least 2 nodes (not -1)
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:64
Dec 10 14:17:50.676: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-2lcch/daemonsets","resourceVersion":"11874"},"items":null}

Dec 10 14:17:50.681: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-2lcch/pods","resourceVersion":"11874"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 10 14:17:50.692: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-2lcch" for this suite.
Dec 10 14:17:56.718: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 14:17:56.811: INFO: namespace: e2e-tests-daemonsets-2lcch, resource: bindings, ignored listing per whitelist
Dec 10 14:17:56.827: INFO: namespace e2e-tests-daemonsets-2lcch deletion completed in 6.130979157s

S [SKIPPING] [6.231 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should rollback without unnecessary restarts [Conformance] [It]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699

  Dec 10 14:17:50.667: Requires at least 2 nodes (not -1)

  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/util.go:292
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 10 14:17:56.828: INFO: >>> kubeConfig: /tmp/kubeconfig-578738756
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:293
[It] should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the initial replication controller
Dec 10 14:17:56.897: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-578738756 create -f - --namespace=e2e-tests-kubectl-k4875'
Dec 10 14:17:57.145: INFO: stderr: ""
Dec 10 14:17:57.145: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Dec 10 14:17:57.145: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-578738756 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-k4875'
Dec 10 14:17:57.243: INFO: stderr: ""
Dec 10 14:17:57.243: INFO: stdout: "update-demo-nautilus-bp5f5 update-demo-nautilus-dr9rh "
Dec 10 14:17:57.243: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-578738756 get pods update-demo-nautilus-bp5f5 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-k4875'
Dec 10 14:17:57.334: INFO: stderr: ""
Dec 10 14:17:57.334: INFO: stdout: ""
Dec 10 14:17:57.334: INFO: update-demo-nautilus-bp5f5 is created but not running
Dec 10 14:18:02.334: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-578738756 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-k4875'
Dec 10 14:18:02.417: INFO: stderr: ""
Dec 10 14:18:02.417: INFO: stdout: "update-demo-nautilus-bp5f5 update-demo-nautilus-dr9rh "
Dec 10 14:18:02.418: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-578738756 get pods update-demo-nautilus-bp5f5 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-k4875'
Dec 10 14:18:02.516: INFO: stderr: ""
Dec 10 14:18:02.516: INFO: stdout: "true"
Dec 10 14:18:02.516: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-578738756 get pods update-demo-nautilus-bp5f5 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-k4875'
Dec 10 14:18:02.596: INFO: stderr: ""
Dec 10 14:18:02.596: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Dec 10 14:18:02.596: INFO: validating pod update-demo-nautilus-bp5f5
Dec 10 14:18:02.603: INFO: got data: {
  "image": "nautilus.jpg"
}

Dec 10 14:18:02.603: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Dec 10 14:18:02.603: INFO: update-demo-nautilus-bp5f5 is verified up and running
Dec 10 14:18:02.603: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-578738756 get pods update-demo-nautilus-dr9rh -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-k4875'
Dec 10 14:18:02.683: INFO: stderr: ""
Dec 10 14:18:02.683: INFO: stdout: "true"
Dec 10 14:18:02.683: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-578738756 get pods update-demo-nautilus-dr9rh -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-k4875'
Dec 10 14:18:02.765: INFO: stderr: ""
Dec 10 14:18:02.765: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Dec 10 14:18:02.765: INFO: validating pod update-demo-nautilus-dr9rh
Dec 10 14:18:02.770: INFO: got data: {
  "image": "nautilus.jpg"
}

Dec 10 14:18:02.770: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Dec 10 14:18:02.770: INFO: update-demo-nautilus-dr9rh is verified up and running
STEP: rolling-update to new replication controller
Dec 10 14:18:02.772: INFO: scanned /root for discovery docs: <nil>
Dec 10 14:18:02.772: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-578738756 rolling-update update-demo-nautilus --update-period=1s -f - --namespace=e2e-tests-kubectl-k4875'
Dec 10 14:18:27.273: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Dec 10 14:18:27.273: INFO: stdout: "Created update-demo-kitten\nScaling up update-demo-kitten from 0 to 2, scaling down update-demo-nautilus from 2 to 0 (keep 2 pods available, don't exceed 3 pods)\nScaling update-demo-kitten up to 1\nScaling update-demo-nautilus down to 1\nScaling update-demo-kitten up to 2\nScaling update-demo-nautilus down to 0\nUpdate succeeded. Deleting old controller: update-demo-nautilus\nRenaming update-demo-kitten to update-demo-nautilus\nreplicationcontroller/update-demo-nautilus rolling updated\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Dec 10 14:18:27.273: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-578738756 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-k4875'
Dec 10 14:18:27.366: INFO: stderr: ""
Dec 10 14:18:27.366: INFO: stdout: "update-demo-kitten-4cvtz update-demo-kitten-zwfg9 update-demo-nautilus-bp5f5 "
STEP: Replicas for name=update-demo: expected=2 actual=3
Dec 10 14:18:32.366: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-578738756 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-k4875'
Dec 10 14:18:32.449: INFO: stderr: ""
Dec 10 14:18:32.449: INFO: stdout: "update-demo-kitten-4cvtz update-demo-kitten-zwfg9 "
Dec 10 14:18:32.449: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-578738756 get pods update-demo-kitten-4cvtz -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-k4875'
Dec 10 14:18:32.545: INFO: stderr: ""
Dec 10 14:18:32.545: INFO: stdout: "true"
Dec 10 14:18:32.545: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-578738756 get pods update-demo-kitten-4cvtz -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-k4875'
Dec 10 14:18:32.626: INFO: stderr: ""
Dec 10 14:18:32.626: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
Dec 10 14:18:32.626: INFO: validating pod update-demo-kitten-4cvtz
Dec 10 14:18:32.633: INFO: got data: {
  "image": "kitten.jpg"
}

Dec 10 14:18:32.633: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Dec 10 14:18:32.633: INFO: update-demo-kitten-4cvtz is verified up and running
Dec 10 14:18:32.633: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-578738756 get pods update-demo-kitten-zwfg9 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-k4875'
Dec 10 14:18:32.713: INFO: stderr: ""
Dec 10 14:18:32.713: INFO: stdout: "true"
Dec 10 14:18:32.713: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-578738756 get pods update-demo-kitten-zwfg9 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-k4875'
Dec 10 14:18:32.794: INFO: stderr: ""
Dec 10 14:18:32.794: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
Dec 10 14:18:32.794: INFO: validating pod update-demo-kitten-zwfg9
Dec 10 14:18:32.799: INFO: got data: {
  "image": "kitten.jpg"
}

Dec 10 14:18:32.799: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Dec 10 14:18:32.799: INFO: update-demo-kitten-zwfg9 is verified up and running
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 10 14:18:32.799: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-k4875" for this suite.
Dec 10 14:18:54.822: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 14:18:54.901: INFO: namespace: e2e-tests-kubectl-k4875, resource: bindings, ignored listing per whitelist
Dec 10 14:18:54.944: INFO: namespace e2e-tests-kubectl-k4875 deletion completed in 22.139230437s

• [SLOW TEST:58.116 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Update Demo
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should do a rolling update of a replication controller  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 10 14:18:54.944: INFO: >>> kubeConfig: /tmp/kubeconfig-578738756
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-86accb67-fc86-11e8-a36b-7e9ed3de7210
STEP: Creating a pod to test consume configMaps
Dec 10 14:18:55.024: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-86ade897-fc86-11e8-a36b-7e9ed3de7210" in namespace "e2e-tests-projected-8ccjk" to be "success or failure"
Dec 10 14:18:55.031: INFO: Pod "pod-projected-configmaps-86ade897-fc86-11e8-a36b-7e9ed3de7210": Phase="Pending", Reason="", readiness=false. Elapsed: 6.809203ms
Dec 10 14:18:57.035: INFO: Pod "pod-projected-configmaps-86ade897-fc86-11e8-a36b-7e9ed3de7210": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011468095s
Dec 10 14:18:59.039: INFO: Pod "pod-projected-configmaps-86ade897-fc86-11e8-a36b-7e9ed3de7210": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.015655401s
STEP: Saw pod success
Dec 10 14:18:59.039: INFO: Pod "pod-projected-configmaps-86ade897-fc86-11e8-a36b-7e9ed3de7210" satisfied condition "success or failure"
Dec 10 14:18:59.043: INFO: Trying to get logs from node conformance-cluster1-k8s-node-2 pod pod-projected-configmaps-86ade897-fc86-11e8-a36b-7e9ed3de7210 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Dec 10 14:18:59.069: INFO: Waiting for pod pod-projected-configmaps-86ade897-fc86-11e8-a36b-7e9ed3de7210 to disappear
Dec 10 14:18:59.072: INFO: Pod pod-projected-configmaps-86ade897-fc86-11e8-a36b-7e9ed3de7210 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 10 14:18:59.072: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-8ccjk" for this suite.
Dec 10 14:19:05.091: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 14:19:05.183: INFO: namespace: e2e-tests-projected-8ccjk, resource: bindings, ignored listing per whitelist
Dec 10 14:19:05.198: INFO: namespace e2e-tests-projected-8ccjk deletion completed in 6.121476235s

• [SLOW TEST:10.254 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 10 14:19:05.198: INFO: >>> kubeConfig: /tmp/kubeconfig-578738756
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0777 on tmpfs
Dec 10 14:19:05.272: INFO: Waiting up to 5m0s for pod "pod-8cc90614-fc86-11e8-a36b-7e9ed3de7210" in namespace "e2e-tests-emptydir-5rd7b" to be "success or failure"
Dec 10 14:19:05.278: INFO: Pod "pod-8cc90614-fc86-11e8-a36b-7e9ed3de7210": Phase="Pending", Reason="", readiness=false. Elapsed: 5.673499ms
Dec 10 14:19:07.282: INFO: Pod "pod-8cc90614-fc86-11e8-a36b-7e9ed3de7210": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010306276s
Dec 10 14:19:09.287: INFO: Pod "pod-8cc90614-fc86-11e8-a36b-7e9ed3de7210": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014976957s
STEP: Saw pod success
Dec 10 14:19:09.287: INFO: Pod "pod-8cc90614-fc86-11e8-a36b-7e9ed3de7210" satisfied condition "success or failure"
Dec 10 14:19:09.290: INFO: Trying to get logs from node conformance-cluster1-k8s-node-2 pod pod-8cc90614-fc86-11e8-a36b-7e9ed3de7210 container test-container: <nil>
STEP: delete the pod
Dec 10 14:19:09.317: INFO: Waiting for pod pod-8cc90614-fc86-11e8-a36b-7e9ed3de7210 to disappear
Dec 10 14:19:09.320: INFO: Pod pod-8cc90614-fc86-11e8-a36b-7e9ed3de7210 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 10 14:19:09.320: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-5rd7b" for this suite.
Dec 10 14:19:15.337: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 14:19:15.405: INFO: namespace: e2e-tests-emptydir-5rd7b, resource: bindings, ignored listing per whitelist
Dec 10 14:19:15.448: INFO: namespace e2e-tests-emptydir-5rd7b deletion completed in 6.123916193s

• [SLOW TEST:10.249 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 10 14:19:15.448: INFO: >>> kubeConfig: /tmp/kubeconfig-578738756
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-exec in namespace e2e-tests-container-probe-pn8xr
Dec 10 14:19:17.547: INFO: Started pod liveness-exec in namespace e2e-tests-container-probe-pn8xr
STEP: checking the pod's current state and verifying that restartCount is present
Dec 10 14:19:17.550: INFO: Initial restart count of pod liveness-exec is 0
Dec 10 14:20:05.684: INFO: Restart count of pod e2e-tests-container-probe-pn8xr/liveness-exec is now 1 (48.133179453s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 10 14:20:05.699: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-pn8xr" for this suite.
Dec 10 14:20:11.726: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 14:20:11.798: INFO: namespace: e2e-tests-container-probe-pn8xr, resource: bindings, ignored listing per whitelist
Dec 10 14:20:11.846: INFO: namespace e2e-tests-container-probe-pn8xr deletion completed in 6.142499322s

• [SLOW TEST:56.398 seconds]
[k8s.io] Probing container
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 10 14:20:11.850: INFO: >>> kubeConfig: /tmp/kubeconfig-578738756
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: setting up watch
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: verifying pod creation was observed
Dec 10 14:20:13.942: INFO: running pod: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-submit-remove-b4835ec9-fc86-11e8-a36b-7e9ed3de7210", GenerateName:"", Namespace:"e2e-tests-pods-xg9k8", SelfLink:"/api/v1/namespaces/e2e-tests-pods-xg9k8/pods/pod-submit-remove-b4835ec9-fc86-11e8-a36b-7e9ed3de7210", UID:"b4847cb7-fc86-11e8-8690-fa163e74bd5a", ResourceVersion:"12442", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63680048411, loc:(*time.Location)(0x6c43b60)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"912574788"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Initializers:(*v1.Initializers)(nil), Finalizers:[]string(nil), ClusterName:""}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"default-token-79mdb", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(0xc420789800), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil)}}}, InitContainers:[]v1.Container(nil), Containers:[]v1.Container{v1.Container{Name:"nginx", Image:"docker.io/library/nginx:1.14-alpine", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-79mdb", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc421909c88), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"conformance-cluster1-k8s-node-2", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc421111740), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc421909cc0)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc421909ce0)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc421909ce8), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil)}, Status:v1.PodStatus{Phase:"Running", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63680048411, loc:(*time.Location)(0x6c43b60)}}, Reason:"", Message:""}, v1.PodCondition{Type:"Ready", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63680048413, loc:(*time.Location)(0x6c43b60)}}, Reason:"", Message:""}, v1.PodCondition{Type:"ContainersReady", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63680048413, loc:(*time.Location)(0x6c43b60)}}, Reason:"", Message:""}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63680048411, loc:(*time.Location)(0x6c43b60)}}, Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"10.0.0.10", PodIP:"10.233.122.255", StartTime:(*v1.Time)(0xc421333320), InitContainerStatuses:[]v1.ContainerStatus(nil), ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"nginx", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(0xc421333340), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:true, RestartCount:0, Image:"nginx:1.14-alpine", ImageID:"docker-pullable://nginx@sha256:2abeba7cab34eb197ff7363486a2aa590027388eafd8e740efae7aae1bed28b6", ContainerID:"docker://058f85700b5fc1b7b0730d0349845ea4f6a3f1fa86c1849e4b33354613efb96c"}}, QOSClass:"BestEffort"}}
STEP: deleting the pod gracefully
STEP: verifying the kubelet observed the termination notice
STEP: verifying pod deletion was observed
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 10 14:20:28.182: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-xg9k8" for this suite.
Dec 10 14:20:34.201: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 14:20:34.292: INFO: namespace: e2e-tests-pods-xg9k8, resource: bindings, ignored listing per whitelist
Dec 10 14:20:34.309: INFO: namespace e2e-tests-pods-xg9k8 deletion completed in 6.123044303s

• [SLOW TEST:22.460 seconds]
[k8s.io] Pods
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 10 14:20:34.309: INFO: >>> kubeConfig: /tmp/kubeconfig-578738756
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0777 on node default medium
Dec 10 14:20:34.385: INFO: Waiting up to 5m0s for pod "pod-c1e6a66a-fc86-11e8-a36b-7e9ed3de7210" in namespace "e2e-tests-emptydir-vdrsg" to be "success or failure"
Dec 10 14:20:34.390: INFO: Pod "pod-c1e6a66a-fc86-11e8-a36b-7e9ed3de7210": Phase="Pending", Reason="", readiness=false. Elapsed: 5.132117ms
Dec 10 14:20:36.394: INFO: Pod "pod-c1e6a66a-fc86-11e8-a36b-7e9ed3de7210": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009168746s
STEP: Saw pod success
Dec 10 14:20:36.394: INFO: Pod "pod-c1e6a66a-fc86-11e8-a36b-7e9ed3de7210" satisfied condition "success or failure"
Dec 10 14:20:36.398: INFO: Trying to get logs from node conformance-cluster1-k8s-node-2 pod pod-c1e6a66a-fc86-11e8-a36b-7e9ed3de7210 container test-container: <nil>
STEP: delete the pod
Dec 10 14:20:36.422: INFO: Waiting for pod pod-c1e6a66a-fc86-11e8-a36b-7e9ed3de7210 to disappear
Dec 10 14:20:36.426: INFO: Pod pod-c1e6a66a-fc86-11e8-a36b-7e9ed3de7210 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 10 14:20:36.426: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-vdrsg" for this suite.
Dec 10 14:20:42.445: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 14:20:42.458: INFO: namespace: e2e-tests-emptydir-vdrsg, resource: bindings, ignored listing per whitelist
Dec 10 14:20:42.563: INFO: namespace e2e-tests-emptydir-vdrsg deletion completed in 6.132647466s

• [SLOW TEST:8.253 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 10 14:20:42.563: INFO: >>> kubeConfig: /tmp/kubeconfig-578738756
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 10 14:21:42.637: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-x9xb8" for this suite.
Dec 10 14:22:04.658: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 14:22:04.766: INFO: namespace: e2e-tests-container-probe-x9xb8, resource: bindings, ignored listing per whitelist
Dec 10 14:22:04.771: INFO: namespace e2e-tests-container-probe-x9xb8 deletion completed in 22.129806108s

• [SLOW TEST:82.209 seconds]
[k8s.io] Probing container
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-apps] Deployment 
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 10 14:22:04.772: INFO: >>> kubeConfig: /tmp/kubeconfig-578738756
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Dec 10 14:22:04.845: INFO: Creating deployment "test-recreate-deployment"
Dec 10 14:22:04.853: INFO: Waiting deployment "test-recreate-deployment" to be updated to revision 1
Dec 10 14:22:04.859: INFO: new replicaset for deployment "test-recreate-deployment" is yet to be created
Dec 10 14:22:06.867: INFO: Waiting deployment "test-recreate-deployment" to complete
Dec 10 14:22:06.871: INFO: Triggering a new rollout for deployment "test-recreate-deployment"
Dec 10 14:22:06.880: INFO: Updating deployment test-recreate-deployment
Dec 10 14:22:06.880: INFO: Watching deployment "test-recreate-deployment" to verify that new pods will not run with olds pods
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Dec 10 14:22:06.965: INFO: Deployment "test-recreate-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment,GenerateName:,Namespace:e2e-tests-deployment-fqr7f,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-fqr7f/deployments/test-recreate-deployment,UID:f7d3a6b5-fc86-11e8-8690-fa163e74bd5a,ResourceVersion:12785,Generation:2,CreationTimestamp:2018-12-10 14:22:04 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},Strategy:DeploymentStrategy{Type:Recreate,RollingUpdate:nil,},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:0,UnavailableReplicas:1,Conditions:[{Available False 2018-12-10 14:22:06 +0000 UTC 2018-12-10 14:22:06 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.} {Progressing True 2018-12-10 14:22:06 +0000 UTC 2018-12-10 14:22:04 +0000 UTC ReplicaSetUpdated ReplicaSet "test-recreate-deployment-7cf749666b" is progressing.}],ReadyReplicas:0,CollisionCount:nil,},}

Dec 10 14:22:06.968: INFO: New ReplicaSet "test-recreate-deployment-7cf749666b" of Deployment "test-recreate-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-7cf749666b,GenerateName:,Namespace:e2e-tests-deployment-fqr7f,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-fqr7f/replicasets/test-recreate-deployment-7cf749666b,UID:f90fe15f-fc86-11e8-808b-fa163e6bf550,ResourceVersion:12783,Generation:1,CreationTimestamp:2018-12-10 14:22:06 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 7cf749666b,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 1,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment test-recreate-deployment f7d3a6b5-fc86-11e8-8690-fa163e74bd5a 0xc421b18487 0xc421b18488}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 7cf749666b,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 7cf749666b,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Dec 10 14:22:06.969: INFO: All old ReplicaSets of Deployment "test-recreate-deployment":
Dec 10 14:22:06.969: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-79f694ff59,GenerateName:,Namespace:e2e-tests-deployment-fqr7f,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-fqr7f/replicasets/test-recreate-deployment-79f694ff59,UID:f7d5c2a2-fc86-11e8-808b-fa163e6bf550,ResourceVersion:12773,Generation:2,CreationTimestamp:2018-12-10 14:22:04 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 79f694ff59,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 1,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-recreate-deployment f7d3a6b5-fc86-11e8-8690-fa163e74bd5a 0xc421b183c7 0xc421b183c8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 79f694ff59,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 79f694ff59,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Dec 10 14:22:06.972: INFO: Pod "test-recreate-deployment-7cf749666b-782fh" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-7cf749666b-782fh,GenerateName:test-recreate-deployment-7cf749666b-,Namespace:e2e-tests-deployment-fqr7f,SelfLink:/api/v1/namespaces/e2e-tests-deployment-fqr7f/pods/test-recreate-deployment-7cf749666b-782fh,UID:f910a393-fc86-11e8-808b-fa163e6bf550,ResourceVersion:12784,Generation:0,CreationTimestamp:2018-12-10 14:22:06 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 7cf749666b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet test-recreate-deployment-7cf749666b f90fe15f-fc86-11e8-808b-fa163e6bf550 0xc421fbbfe7 0xc421fbbfe8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-bnrbp {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-bnrbp,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-bnrbp true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:conformance-cluster1-k8s-node-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc421c1c160} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421c1c180}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-10 14:22:06 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-10 14:22:06 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-10 14:22:06 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-10 14:22:06 +0000 UTC  }],Message:,Reason:,HostIP:10.0.0.10,PodIP:,StartTime:2018-12-10 14:22:06 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 10 14:22:06.972: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-fqr7f" for this suite.
Dec 10 14:22:12.995: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 14:22:13.076: INFO: namespace: e2e-tests-deployment-fqr7f, resource: bindings, ignored listing per whitelist
Dec 10 14:22:13.098: INFO: namespace e2e-tests-deployment-fqr7f deletion completed in 6.122122s

• [SLOW TEST:8.326 seconds]
[sig-apps] Deployment
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 10 14:22:13.099: INFO: >>> kubeConfig: /tmp/kubeconfig-578738756
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Dec 10 14:22:13.171: INFO: Waiting up to 5m0s for pod "downwardapi-volume-fcc7e468-fc86-11e8-a36b-7e9ed3de7210" in namespace "e2e-tests-projected-nlp7p" to be "success or failure"
Dec 10 14:22:13.176: INFO: Pod "downwardapi-volume-fcc7e468-fc86-11e8-a36b-7e9ed3de7210": Phase="Pending", Reason="", readiness=false. Elapsed: 5.411246ms
Dec 10 14:22:15.180: INFO: Pod "downwardapi-volume-fcc7e468-fc86-11e8-a36b-7e9ed3de7210": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009533178s
STEP: Saw pod success
Dec 10 14:22:15.181: INFO: Pod "downwardapi-volume-fcc7e468-fc86-11e8-a36b-7e9ed3de7210" satisfied condition "success or failure"
Dec 10 14:22:15.184: INFO: Trying to get logs from node conformance-cluster1-k8s-node-2 pod downwardapi-volume-fcc7e468-fc86-11e8-a36b-7e9ed3de7210 container client-container: <nil>
STEP: delete the pod
Dec 10 14:22:15.208: INFO: Waiting for pod downwardapi-volume-fcc7e468-fc86-11e8-a36b-7e9ed3de7210 to disappear
Dec 10 14:22:15.212: INFO: Pod downwardapi-volume-fcc7e468-fc86-11e8-a36b-7e9ed3de7210 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 10 14:22:15.212: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-nlp7p" for this suite.
Dec 10 14:22:21.232: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 14:22:21.317: INFO: namespace: e2e-tests-projected-nlp7p, resource: bindings, ignored listing per whitelist
Dec 10 14:22:21.340: INFO: namespace e2e-tests-projected-nlp7p deletion completed in 6.123954759s

• [SLOW TEST:8.241 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 10 14:22:21.340: INFO: >>> kubeConfig: /tmp/kubeconfig-578738756
STEP: Building a namespace api object, basename namespaces
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a test namespace
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a pod in the namespace
STEP: Waiting for the pod to have running status
STEP: Creating an uninitialized pod in the namespace
Dec 10 14:22:23.474: INFO: error from create uninitialized namespace: <nil>
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Verifying there are no pods in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 10 14:22:47.533: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-namespaces-7k8bl" for this suite.
Dec 10 14:22:53.553: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 14:22:53.608: INFO: namespace: e2e-tests-namespaces-7k8bl, resource: bindings, ignored listing per whitelist
Dec 10 14:22:53.657: INFO: namespace e2e-tests-namespaces-7k8bl deletion completed in 6.11967082s
STEP: Destroying namespace "e2e-tests-nsdeletetest-mwqvr" for this suite.
Dec 10 14:22:53.660: INFO: Namespace e2e-tests-nsdeletetest-mwqvr was already deleted
STEP: Destroying namespace "e2e-tests-nsdeletetest-crp6d" for this suite.
Dec 10 14:22:59.676: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 14:22:59.745: INFO: namespace: e2e-tests-nsdeletetest-crp6d, resource: bindings, ignored listing per whitelist
Dec 10 14:22:59.787: INFO: namespace e2e-tests-nsdeletetest-crp6d deletion completed in 6.126949955s

• [SLOW TEST:38.447 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 10 14:22:59.788: INFO: >>> kubeConfig: /tmp/kubeconfig-578738756
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0666 on tmpfs
Dec 10 14:22:59.870: INFO: Waiting up to 5m0s for pod "pod-189d8bef-fc87-11e8-a36b-7e9ed3de7210" in namespace "e2e-tests-emptydir-cxlpf" to be "success or failure"
Dec 10 14:22:59.877: INFO: Pod "pod-189d8bef-fc87-11e8-a36b-7e9ed3de7210": Phase="Pending", Reason="", readiness=false. Elapsed: 6.2669ms
Dec 10 14:23:01.882: INFO: Pod "pod-189d8bef-fc87-11e8-a36b-7e9ed3de7210": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.011129606s
STEP: Saw pod success
Dec 10 14:23:01.882: INFO: Pod "pod-189d8bef-fc87-11e8-a36b-7e9ed3de7210" satisfied condition "success or failure"
Dec 10 14:23:01.886: INFO: Trying to get logs from node conformance-cluster1-k8s-node-2 pod pod-189d8bef-fc87-11e8-a36b-7e9ed3de7210 container test-container: <nil>
STEP: delete the pod
Dec 10 14:23:01.912: INFO: Waiting for pod pod-189d8bef-fc87-11e8-a36b-7e9ed3de7210 to disappear
Dec 10 14:23:01.916: INFO: Pod pod-189d8bef-fc87-11e8-a36b-7e9ed3de7210 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 10 14:23:01.916: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-cxlpf" for this suite.
Dec 10 14:23:07.933: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 14:23:07.958: INFO: namespace: e2e-tests-emptydir-cxlpf, resource: bindings, ignored listing per whitelist
Dec 10 14:23:08.055: INFO: namespace e2e-tests-emptydir-cxlpf deletion completed in 6.134949714s

• [SLOW TEST:8.267 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 10 14:23:08.055: INFO: >>> kubeConfig: /tmp/kubeconfig-578738756
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-map-1d8909d6-fc87-11e8-a36b-7e9ed3de7210
STEP: Creating a pod to test consume secrets
Dec 10 14:23:08.125: INFO: Waiting up to 5m0s for pod "pod-secrets-1d8a1377-fc87-11e8-a36b-7e9ed3de7210" in namespace "e2e-tests-secrets-twghw" to be "success or failure"
Dec 10 14:23:08.132: INFO: Pod "pod-secrets-1d8a1377-fc87-11e8-a36b-7e9ed3de7210": Phase="Pending", Reason="", readiness=false. Elapsed: 6.325397ms
Dec 10 14:23:10.136: INFO: Pod "pod-secrets-1d8a1377-fc87-11e8-a36b-7e9ed3de7210": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.01108984s
STEP: Saw pod success
Dec 10 14:23:10.136: INFO: Pod "pod-secrets-1d8a1377-fc87-11e8-a36b-7e9ed3de7210" satisfied condition "success or failure"
Dec 10 14:23:10.140: INFO: Trying to get logs from node conformance-cluster1-k8s-node-2 pod pod-secrets-1d8a1377-fc87-11e8-a36b-7e9ed3de7210 container secret-volume-test: <nil>
STEP: delete the pod
Dec 10 14:23:10.165: INFO: Waiting for pod pod-secrets-1d8a1377-fc87-11e8-a36b-7e9ed3de7210 to disappear
Dec 10 14:23:10.168: INFO: Pod pod-secrets-1d8a1377-fc87-11e8-a36b-7e9ed3de7210 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 10 14:23:10.168: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-twghw" for this suite.
Dec 10 14:23:16.192: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 14:23:16.292: INFO: namespace: e2e-tests-secrets-twghw, resource: bindings, ignored listing per whitelist
Dec 10 14:23:16.302: INFO: namespace e2e-tests-secrets-twghw deletion completed in 6.129896307s

• [SLOW TEST:8.247 seconds]
[sig-storage] Secrets
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 10 14:23:16.302: INFO: >>> kubeConfig: /tmp/kubeconfig-578738756
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Dec 10 14:23:16.387: INFO: Pod name cleanup-pod: Found 0 pods out of 1
Dec 10 14:23:21.392: INFO: Pod name cleanup-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Dec 10 14:23:21.392: INFO: Creating deployment test-cleanup-deployment
STEP: Waiting for deployment test-cleanup-deployment history to be cleaned up
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Dec 10 14:23:21.412: INFO: Deployment "test-cleanup-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-deployment,GenerateName:,Namespace:e2e-tests-deployment-228cv,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-228cv/deployments/test-cleanup-deployment,UID:25746aa8-fc87-11e8-8690-fa163e74bd5a,ResourceVersion:13148,Generation:1,CreationTimestamp:2018-12-10 14:23:21 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*0,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:0,Replicas:0,UpdatedReplicas:0,AvailableReplicas:0,UnavailableReplicas:0,Conditions:[],ReadyReplicas:0,CollisionCount:nil,},}

Dec 10 14:23:21.419: INFO: New ReplicaSet of Deployment "test-cleanup-deployment" is nil.
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 10 14:23:21.424: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-228cv" for this suite.
Dec 10 14:23:27.457: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 14:23:27.526: INFO: namespace: e2e-tests-deployment-228cv, resource: bindings, ignored listing per whitelist
Dec 10 14:23:27.563: INFO: namespace e2e-tests-deployment-228cv deletion completed in 6.134541188s

• [SLOW TEST:11.261 seconds]
[sig-apps] Deployment
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with secret pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 10 14:23:27.564: INFO: >>> kubeConfig: /tmp/kubeconfig-578738756
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with secret pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-secret-mdjw
STEP: Creating a pod to test atomic-volume-subpath
Dec 10 14:23:27.653: INFO: Waiting up to 5m0s for pod "pod-subpath-test-secret-mdjw" in namespace "e2e-tests-subpath-s2vxb" to be "success or failure"
Dec 10 14:23:27.661: INFO: Pod "pod-subpath-test-secret-mdjw": Phase="Pending", Reason="", readiness=false. Elapsed: 7.314425ms
Dec 10 14:23:29.666: INFO: Pod "pod-subpath-test-secret-mdjw": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01234132s
Dec 10 14:23:31.670: INFO: Pod "pod-subpath-test-secret-mdjw": Phase="Running", Reason="", readiness=false. Elapsed: 4.017194396s
Dec 10 14:23:33.675: INFO: Pod "pod-subpath-test-secret-mdjw": Phase="Running", Reason="", readiness=false. Elapsed: 6.021605068s
Dec 10 14:23:35.679: INFO: Pod "pod-subpath-test-secret-mdjw": Phase="Running", Reason="", readiness=false. Elapsed: 8.026260257s
Dec 10 14:23:37.689: INFO: Pod "pod-subpath-test-secret-mdjw": Phase="Running", Reason="", readiness=false. Elapsed: 10.036036646s
Dec 10 14:23:39.694: INFO: Pod "pod-subpath-test-secret-mdjw": Phase="Running", Reason="", readiness=false. Elapsed: 12.040619922s
Dec 10 14:23:41.698: INFO: Pod "pod-subpath-test-secret-mdjw": Phase="Running", Reason="", readiness=false. Elapsed: 14.045185668s
Dec 10 14:23:43.703: INFO: Pod "pod-subpath-test-secret-mdjw": Phase="Running", Reason="", readiness=false. Elapsed: 16.049666316s
Dec 10 14:23:45.707: INFO: Pod "pod-subpath-test-secret-mdjw": Phase="Running", Reason="", readiness=false. Elapsed: 18.053605724s
Dec 10 14:23:47.717: INFO: Pod "pod-subpath-test-secret-mdjw": Phase="Running", Reason="", readiness=false. Elapsed: 20.063500728s
Dec 10 14:23:49.721: INFO: Pod "pod-subpath-test-secret-mdjw": Phase="Running", Reason="", readiness=false. Elapsed: 22.067641134s
Dec 10 14:23:51.726: INFO: Pod "pod-subpath-test-secret-mdjw": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.072726906s
STEP: Saw pod success
Dec 10 14:23:51.726: INFO: Pod "pod-subpath-test-secret-mdjw" satisfied condition "success or failure"
Dec 10 14:23:51.730: INFO: Trying to get logs from node conformance-cluster1-k8s-node-2 pod pod-subpath-test-secret-mdjw container test-container-subpath-secret-mdjw: <nil>
STEP: delete the pod
Dec 10 14:23:51.757: INFO: Waiting for pod pod-subpath-test-secret-mdjw to disappear
Dec 10 14:23:51.760: INFO: Pod pod-subpath-test-secret-mdjw no longer exists
STEP: Deleting pod pod-subpath-test-secret-mdjw
Dec 10 14:23:51.761: INFO: Deleting pod "pod-subpath-test-secret-mdjw" in namespace "e2e-tests-subpath-s2vxb"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 10 14:23:51.764: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-s2vxb" for this suite.
Dec 10 14:23:57.787: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 14:23:57.883: INFO: namespace: e2e-tests-subpath-s2vxb, resource: bindings, ignored listing per whitelist
Dec 10 14:23:57.893: INFO: namespace e2e-tests-subpath-s2vxb deletion completed in 6.125274225s

• [SLOW TEST:30.329 seconds]
[sig-storage] Subpath
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with secret pod [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 10 14:23:57.893: INFO: >>> kubeConfig: /tmp/kubeconfig-578738756
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test substitution in container's command
Dec 10 14:23:57.965: INFO: Waiting up to 5m0s for pod "var-expansion-3b3ebb9a-fc87-11e8-a36b-7e9ed3de7210" in namespace "e2e-tests-var-expansion-5cp79" to be "success or failure"
Dec 10 14:23:57.972: INFO: Pod "var-expansion-3b3ebb9a-fc87-11e8-a36b-7e9ed3de7210": Phase="Pending", Reason="", readiness=false. Elapsed: 6.839992ms
Dec 10 14:23:59.976: INFO: Pod "var-expansion-3b3ebb9a-fc87-11e8-a36b-7e9ed3de7210": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.01112069s
STEP: Saw pod success
Dec 10 14:23:59.976: INFO: Pod "var-expansion-3b3ebb9a-fc87-11e8-a36b-7e9ed3de7210" satisfied condition "success or failure"
Dec 10 14:23:59.980: INFO: Trying to get logs from node conformance-cluster1-k8s-node-2 pod var-expansion-3b3ebb9a-fc87-11e8-a36b-7e9ed3de7210 container dapi-container: <nil>
STEP: delete the pod
Dec 10 14:24:00.004: INFO: Waiting for pod var-expansion-3b3ebb9a-fc87-11e8-a36b-7e9ed3de7210 to disappear
Dec 10 14:24:00.007: INFO: Pod var-expansion-3b3ebb9a-fc87-11e8-a36b-7e9ed3de7210 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 10 14:24:00.007: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-var-expansion-5cp79" for this suite.
Dec 10 14:24:06.024: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 14:24:06.120: INFO: namespace: e2e-tests-var-expansion-5cp79, resource: bindings, ignored listing per whitelist
Dec 10 14:24:06.130: INFO: namespace e2e-tests-var-expansion-5cp79 deletion completed in 6.119452519s

• [SLOW TEST:8.237 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 10 14:24:06.131: INFO: >>> kubeConfig: /tmp/kubeconfig-578738756
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Dec 10 14:24:10.260: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Dec 10 14:24:10.264: INFO: Pod pod-with-poststart-exec-hook still exists
Dec 10 14:24:12.264: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Dec 10 14:24:12.268: INFO: Pod pod-with-poststart-exec-hook still exists
Dec 10 14:24:14.264: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Dec 10 14:24:14.269: INFO: Pod pod-with-poststart-exec-hook still exists
Dec 10 14:24:16.264: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Dec 10 14:24:16.268: INFO: Pod pod-with-poststart-exec-hook still exists
Dec 10 14:24:18.264: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Dec 10 14:24:18.279: INFO: Pod pod-with-poststart-exec-hook still exists
Dec 10 14:24:20.264: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Dec 10 14:24:20.269: INFO: Pod pod-with-poststart-exec-hook still exists
Dec 10 14:24:22.264: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Dec 10 14:24:22.268: INFO: Pod pod-with-poststart-exec-hook still exists
Dec 10 14:24:24.264: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Dec 10 14:24:24.269: INFO: Pod pod-with-poststart-exec-hook still exists
Dec 10 14:24:26.264: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Dec 10 14:24:26.268: INFO: Pod pod-with-poststart-exec-hook still exists
Dec 10 14:24:28.264: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Dec 10 14:24:28.269: INFO: Pod pod-with-poststart-exec-hook still exists
Dec 10 14:24:30.264: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Dec 10 14:24:30.274: INFO: Pod pod-with-poststart-exec-hook still exists
Dec 10 14:24:32.264: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Dec 10 14:24:32.269: INFO: Pod pod-with-poststart-exec-hook still exists
Dec 10 14:24:34.264: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Dec 10 14:24:34.269: INFO: Pod pod-with-poststart-exec-hook still exists
Dec 10 14:24:36.264: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Dec 10 14:24:36.269: INFO: Pod pod-with-poststart-exec-hook still exists
Dec 10 14:24:38.264: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Dec 10 14:24:38.268: INFO: Pod pod-with-poststart-exec-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 10 14:24:38.269: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-lifecycle-hook-mgg86" for this suite.
Dec 10 14:24:54.289: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 14:24:54.310: INFO: namespace: e2e-tests-container-lifecycle-hook-mgg86, resource: bindings, ignored listing per whitelist
Dec 10 14:24:54.402: INFO: namespace e2e-tests-container-lifecycle-hook-mgg86 deletion completed in 16.128995641s

• [SLOW TEST:48.272 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when create a pod with lifecycle hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute poststart exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected 
  should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 10 14:24:54.403: INFO: >>> kubeConfig: /tmp/kubeconfig-578738756
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Dec 10 14:24:54.480: INFO: Waiting up to 5m0s for pod "downwardapi-volume-5cee30e6-fc87-11e8-a36b-7e9ed3de7210" in namespace "e2e-tests-projected-tdjxh" to be "success or failure"
Dec 10 14:24:54.486: INFO: Pod "downwardapi-volume-5cee30e6-fc87-11e8-a36b-7e9ed3de7210": Phase="Pending", Reason="", readiness=false. Elapsed: 6.185051ms
Dec 10 14:24:56.491: INFO: Pod "downwardapi-volume-5cee30e6-fc87-11e8-a36b-7e9ed3de7210": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010856488s
Dec 10 14:24:58.495: INFO: Pod "downwardapi-volume-5cee30e6-fc87-11e8-a36b-7e9ed3de7210": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014697259s
STEP: Saw pod success
Dec 10 14:24:58.495: INFO: Pod "downwardapi-volume-5cee30e6-fc87-11e8-a36b-7e9ed3de7210" satisfied condition "success or failure"
Dec 10 14:24:58.498: INFO: Trying to get logs from node conformance-cluster1-k8s-node-2 pod downwardapi-volume-5cee30e6-fc87-11e8-a36b-7e9ed3de7210 container client-container: <nil>
STEP: delete the pod
Dec 10 14:24:58.525: INFO: Waiting for pod downwardapi-volume-5cee30e6-fc87-11e8-a36b-7e9ed3de7210 to disappear
Dec 10 14:24:58.528: INFO: Pod downwardapi-volume-5cee30e6-fc87-11e8-a36b-7e9ed3de7210 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 10 14:24:58.529: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-tdjxh" for this suite.
Dec 10 14:25:04.547: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 14:25:04.590: INFO: namespace: e2e-tests-projected-tdjxh, resource: bindings, ignored listing per whitelist
Dec 10 14:25:04.649: INFO: namespace e2e-tests-projected-tdjxh deletion completed in 6.115772595s

• [SLOW TEST:10.246 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Projected 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 10 14:25:04.651: INFO: >>> kubeConfig: /tmp/kubeconfig-578738756
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with configMap that has name projected-configmap-test-upd-630c1672-fc87-11e8-a36b-7e9ed3de7210
STEP: Creating the pod
STEP: Updating configmap projected-configmap-test-upd-630c1672-fc87-11e8-a36b-7e9ed3de7210
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 10 14:25:08.796: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-7xsnw" for this suite.
Dec 10 14:25:30.820: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 14:25:30.897: INFO: namespace: e2e-tests-projected-7xsnw, resource: bindings, ignored listing per whitelist
Dec 10 14:25:30.923: INFO: namespace e2e-tests-projected-7xsnw deletion completed in 22.120458042s

• [SLOW TEST:26.273 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-api-machinery] Downward API 
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 10 14:25:30.924: INFO: >>> kubeConfig: /tmp/kubeconfig-578738756
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Dec 10 14:25:31.010: INFO: Waiting up to 5m0s for pod "downward-api-72b346f6-fc87-11e8-a36b-7e9ed3de7210" in namespace "e2e-tests-downward-api-nrt82" to be "success or failure"
Dec 10 14:25:31.015: INFO: Pod "downward-api-72b346f6-fc87-11e8-a36b-7e9ed3de7210": Phase="Pending", Reason="", readiness=false. Elapsed: 4.808786ms
Dec 10 14:25:33.019: INFO: Pod "downward-api-72b346f6-fc87-11e8-a36b-7e9ed3de7210": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008969547s
STEP: Saw pod success
Dec 10 14:25:33.019: INFO: Pod "downward-api-72b346f6-fc87-11e8-a36b-7e9ed3de7210" satisfied condition "success or failure"
Dec 10 14:25:33.028: INFO: Trying to get logs from node conformance-cluster1-k8s-node-2 pod downward-api-72b346f6-fc87-11e8-a36b-7e9ed3de7210 container dapi-container: <nil>
STEP: delete the pod
Dec 10 14:25:33.061: INFO: Waiting for pod downward-api-72b346f6-fc87-11e8-a36b-7e9ed3de7210 to disappear
Dec 10 14:25:33.064: INFO: Pod downward-api-72b346f6-fc87-11e8-a36b-7e9ed3de7210 no longer exists
[AfterEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 10 14:25:33.064: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-nrt82" for this suite.
Dec 10 14:25:39.086: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 14:25:39.103: INFO: namespace: e2e-tests-downward-api-nrt82, resource: bindings, ignored listing per whitelist
Dec 10 14:25:39.197: INFO: namespace e2e-tests-downward-api-nrt82 deletion completed in 6.128454527s

• [SLOW TEST:8.273 seconds]
[sig-api-machinery] Downward API
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[k8s.io] [sig-node] Events 
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 10 14:25:39.197: INFO: >>> kubeConfig: /tmp/kubeconfig-578738756
STEP: Building a namespace api object, basename events
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: retrieving the pod
Dec 10 14:25:41.291: INFO: &Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:send-events-77a13581-fc87-11e8-a36b-7e9ed3de7210,GenerateName:,Namespace:e2e-tests-events-5w7rz,SelfLink:/api/v1/namespaces/e2e-tests-events-5w7rz/pods/send-events-77a13581-fc87-11e8-a36b-7e9ed3de7210,UID:77a1ce08-fc87-11e8-8690-fa163e74bd5a,ResourceVersion:13705,Generation:0,CreationTimestamp:2018-12-10 14:25:39 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: foo,time: 263838255,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-9qpzw {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-9qpzw,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{p gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1 [] []  [{ 0 80 TCP }] [] [] {map[] map[]} [{default-token-9qpzw true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*30,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:conformance-cluster1-k8s-node-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc4227d5880} {node.kubernetes.io/unreachable Exists  NoExecute 0xc4227d58a0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-10 14:25:39 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-12-10 14:25:40 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2018-12-10 14:25:40 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-10 14:25:39 +0000 UTC  }],Message:,Reason:,HostIP:10.0.0.10,PodIP:10.233.122.212,StartTime:2018-12-10 14:25:39 +0000 UTC,ContainerStatuses:[{p {nil ContainerStateRunning{StartedAt:2018-12-10 14:25:40 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1 docker-pullable://gcr.io/kubernetes-e2e-test-images/serve-hostname@sha256:bab70473a6d8ef65a22625dc9a1b0f0452e811530fdbe77e4408523460177ff1 docker://35f4985ffe150819a87d97792f147fd25d079a7310e2ba47f0d0cf6cd2bdb085}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}

STEP: checking for scheduler event about the pod
Dec 10 14:25:43.295: INFO: Saw scheduler event for our pod.
STEP: checking for kubelet event about the pod
Dec 10 14:25:45.305: INFO: Saw kubelet event for our pod.
STEP: deleting the pod
[AfterEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 10 14:25:45.313: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-events-5w7rz" for this suite.
Dec 10 14:26:31.338: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 14:26:31.370: INFO: namespace: e2e-tests-events-5w7rz, resource: bindings, ignored listing per whitelist
Dec 10 14:26:31.445: INFO: namespace e2e-tests-events-5w7rz deletion completed in 46.127242259s

• [SLOW TEST:52.248 seconds]
[k8s.io] [sig-node] Events
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 10 14:26:31.446: INFO: >>> kubeConfig: /tmp/kubeconfig-578738756
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-map-96c4d08c-fc87-11e8-a36b-7e9ed3de7210
STEP: Creating a pod to test consume configMaps
Dec 10 14:26:31.528: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-96c5de1b-fc87-11e8-a36b-7e9ed3de7210" in namespace "e2e-tests-projected-rpbmj" to be "success or failure"
Dec 10 14:26:31.539: INFO: Pod "pod-projected-configmaps-96c5de1b-fc87-11e8-a36b-7e9ed3de7210": Phase="Pending", Reason="", readiness=false. Elapsed: 10.28192ms
Dec 10 14:26:33.543: INFO: Pod "pod-projected-configmaps-96c5de1b-fc87-11e8-a36b-7e9ed3de7210": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.014685326s
STEP: Saw pod success
Dec 10 14:26:33.543: INFO: Pod "pod-projected-configmaps-96c5de1b-fc87-11e8-a36b-7e9ed3de7210" satisfied condition "success or failure"
Dec 10 14:26:33.547: INFO: Trying to get logs from node conformance-cluster1-k8s-node-2 pod pod-projected-configmaps-96c5de1b-fc87-11e8-a36b-7e9ed3de7210 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Dec 10 14:26:33.589: INFO: Waiting for pod pod-projected-configmaps-96c5de1b-fc87-11e8-a36b-7e9ed3de7210 to disappear
Dec 10 14:26:33.593: INFO: Pod pod-projected-configmaps-96c5de1b-fc87-11e8-a36b-7e9ed3de7210 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 10 14:26:33.593: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-rpbmj" for this suite.
Dec 10 14:26:39.613: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 14:26:39.630: INFO: namespace: e2e-tests-projected-rpbmj, resource: bindings, ignored listing per whitelist
Dec 10 14:26:39.723: INFO: namespace e2e-tests-projected-rpbmj deletion completed in 6.125850769s

• [SLOW TEST:8.278 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[k8s.io] Pods 
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 10 14:26:39.723: INFO: >>> kubeConfig: /tmp/kubeconfig-578738756
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Dec 10 14:26:41.835: INFO: Waiting up to 5m0s for pod "client-envvars-9cebefd2-fc87-11e8-a36b-7e9ed3de7210" in namespace "e2e-tests-pods-fzw92" to be "success or failure"
Dec 10 14:26:41.838: INFO: Pod "client-envvars-9cebefd2-fc87-11e8-a36b-7e9ed3de7210": Phase="Pending", Reason="", readiness=false. Elapsed: 3.257138ms
Dec 10 14:26:43.843: INFO: Pod "client-envvars-9cebefd2-fc87-11e8-a36b-7e9ed3de7210": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008180273s
STEP: Saw pod success
Dec 10 14:26:43.843: INFO: Pod "client-envvars-9cebefd2-fc87-11e8-a36b-7e9ed3de7210" satisfied condition "success or failure"
Dec 10 14:26:43.847: INFO: Trying to get logs from node conformance-cluster1-k8s-node-2 pod client-envvars-9cebefd2-fc87-11e8-a36b-7e9ed3de7210 container env3cont: <nil>
STEP: delete the pod
Dec 10 14:26:43.873: INFO: Waiting for pod client-envvars-9cebefd2-fc87-11e8-a36b-7e9ed3de7210 to disappear
Dec 10 14:26:43.877: INFO: Pod client-envvars-9cebefd2-fc87-11e8-a36b-7e9ed3de7210 no longer exists
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 10 14:26:43.877: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-fzw92" for this suite.
Dec 10 14:27:29.903: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 14:27:29.959: INFO: namespace: e2e-tests-pods-fzw92, resource: bindings, ignored listing per whitelist
Dec 10 14:27:30.018: INFO: namespace e2e-tests-pods-fzw92 deletion completed in 46.136328879s

• [SLOW TEST:50.294 seconds]
[k8s.io] Pods
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 10 14:27:30.018: INFO: >>> kubeConfig: /tmp/kubeconfig-578738756
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-4m2pw
[It] Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Looking for a node to schedule stateful set and pod
STEP: Creating pod with conflicting port in namespace e2e-tests-statefulset-4m2pw
STEP: Creating statefulset with conflicting port in namespace e2e-tests-statefulset-4m2pw
STEP: Waiting until pod test-pod will start running in namespace e2e-tests-statefulset-4m2pw
STEP: Waiting until stateful pod ss-0 will be recreated and deleted at least once in namespace e2e-tests-statefulset-4m2pw
Dec 10 14:27:34.133: INFO: Observed stateful pod in namespace: e2e-tests-statefulset-4m2pw, name: ss-0, uid: bbfc6ce0-fc87-11e8-808b-fa163e6bf550, status phase: Pending. Waiting for statefulset controller to delete.
Dec 10 14:27:34.528: INFO: Observed stateful pod in namespace: e2e-tests-statefulset-4m2pw, name: ss-0, uid: bbfc6ce0-fc87-11e8-808b-fa163e6bf550, status phase: Failed. Waiting for statefulset controller to delete.
Dec 10 14:27:34.537: INFO: Observed stateful pod in namespace: e2e-tests-statefulset-4m2pw, name: ss-0, uid: bbfc6ce0-fc87-11e8-808b-fa163e6bf550, status phase: Failed. Waiting for statefulset controller to delete.
Dec 10 14:27:34.549: INFO: Observed delete event for stateful pod ss-0 in namespace e2e-tests-statefulset-4m2pw
STEP: Removing pod with conflicting port in namespace e2e-tests-statefulset-4m2pw
STEP: Waiting when stateful pod ss-0 will be recreated in namespace e2e-tests-statefulset-4m2pw and will be in running state
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Dec 10 14:27:38.588: INFO: Deleting all statefulset in ns e2e-tests-statefulset-4m2pw
Dec 10 14:27:38.592: INFO: Scaling statefulset ss to 0
Dec 10 14:27:48.613: INFO: Waiting for statefulset status.replicas updated to 0
Dec 10 14:27:48.617: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 10 14:27:48.632: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-4m2pw" for this suite.
Dec 10 14:27:54.652: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 14:27:54.680: INFO: namespace: e2e-tests-statefulset-4m2pw, resource: bindings, ignored listing per whitelist
Dec 10 14:27:54.754: INFO: namespace e2e-tests-statefulset-4m2pw deletion completed in 6.11797744s

• [SLOW TEST:24.736 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    Should recreate evicted statefulset [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 10 14:27:54.754: INFO: >>> kubeConfig: /tmp/kubeconfig-578738756
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-c86d1678-fc87-11e8-a36b-7e9ed3de7210
STEP: Creating a pod to test consume configMaps
Dec 10 14:27:54.834: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-c86e6d95-fc87-11e8-a36b-7e9ed3de7210" in namespace "e2e-tests-projected-8scz9" to be "success or failure"
Dec 10 14:27:54.841: INFO: Pod "pod-projected-configmaps-c86e6d95-fc87-11e8-a36b-7e9ed3de7210": Phase="Pending", Reason="", readiness=false. Elapsed: 6.53045ms
Dec 10 14:27:56.850: INFO: Pod "pod-projected-configmaps-c86e6d95-fc87-11e8-a36b-7e9ed3de7210": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.015966066s
STEP: Saw pod success
Dec 10 14:27:56.850: INFO: Pod "pod-projected-configmaps-c86e6d95-fc87-11e8-a36b-7e9ed3de7210" satisfied condition "success or failure"
Dec 10 14:27:56.856: INFO: Trying to get logs from node conformance-cluster1-k8s-node-2 pod pod-projected-configmaps-c86e6d95-fc87-11e8-a36b-7e9ed3de7210 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Dec 10 14:27:56.882: INFO: Waiting for pod pod-projected-configmaps-c86e6d95-fc87-11e8-a36b-7e9ed3de7210 to disappear
Dec 10 14:27:56.885: INFO: Pod pod-projected-configmaps-c86e6d95-fc87-11e8-a36b-7e9ed3de7210 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 10 14:27:56.885: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-8scz9" for this suite.
Dec 10 14:28:02.903: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 14:28:02.970: INFO: namespace: e2e-tests-projected-8scz9, resource: bindings, ignored listing per whitelist
Dec 10 14:28:03.014: INFO: namespace e2e-tests-projected-8scz9 deletion completed in 6.125214189s

• [SLOW TEST:8.260 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] Projected 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 10 14:28:03.015: INFO: >>> kubeConfig: /tmp/kubeconfig-578738756
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Dec 10 14:28:03.137: INFO: Waiting up to 5m0s for pod "downwardapi-volume-cd60ef80-fc87-11e8-a36b-7e9ed3de7210" in namespace "e2e-tests-projected-wjjl5" to be "success or failure"
Dec 10 14:28:03.144: INFO: Pod "downwardapi-volume-cd60ef80-fc87-11e8-a36b-7e9ed3de7210": Phase="Pending", Reason="", readiness=false. Elapsed: 7.030121ms
Dec 10 14:28:05.149: INFO: Pod "downwardapi-volume-cd60ef80-fc87-11e8-a36b-7e9ed3de7210": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011332281s
Dec 10 14:28:07.153: INFO: Pod "downwardapi-volume-cd60ef80-fc87-11e8-a36b-7e9ed3de7210": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.01529859s
STEP: Saw pod success
Dec 10 14:28:07.153: INFO: Pod "downwardapi-volume-cd60ef80-fc87-11e8-a36b-7e9ed3de7210" satisfied condition "success or failure"
Dec 10 14:28:07.156: INFO: Trying to get logs from node conformance-cluster1-k8s-node-1 pod downwardapi-volume-cd60ef80-fc87-11e8-a36b-7e9ed3de7210 container client-container: <nil>
STEP: delete the pod
Dec 10 14:28:07.180: INFO: Waiting for pod downwardapi-volume-cd60ef80-fc87-11e8-a36b-7e9ed3de7210 to disappear
Dec 10 14:28:07.183: INFO: Pod downwardapi-volume-cd60ef80-fc87-11e8-a36b-7e9ed3de7210 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 10 14:28:07.183: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-wjjl5" for this suite.
Dec 10 14:28:13.204: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 14:28:13.301: INFO: namespace: e2e-tests-projected-wjjl5, resource: bindings, ignored listing per whitelist
Dec 10 14:28:13.329: INFO: namespace e2e-tests-projected-wjjl5 deletion completed in 6.141068685s

• [SLOW TEST:10.314 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Downward API volume 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 10 14:28:13.329: INFO: >>> kubeConfig: /tmp/kubeconfig-578738756
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating the pod
Dec 10 14:28:15.944: INFO: Successfully updated pod "labelsupdated37fdd36-fc87-11e8-a36b-7e9ed3de7210"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 10 14:28:17.977: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-b6zq2" for this suite.
Dec 10 14:28:40.006: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 14:28:40.058: INFO: namespace: e2e-tests-downward-api-b6zq2, resource: bindings, ignored listing per whitelist
Dec 10 14:28:40.114: INFO: namespace e2e-tests-downward-api-b6zq2 deletion completed in 22.12869037s

• [SLOW TEST:26.786 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 10 14:28:40.115: INFO: >>> kubeConfig: /tmp/kubeconfig-578738756
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating the pod
Dec 10 14:28:42.737: INFO: Successfully updated pod "labelsupdatee3778d40-fc87-11e8-a36b-7e9ed3de7210"
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 10 14:28:46.770: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-ql79d" for this suite.
Dec 10 14:29:08.790: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 14:29:08.820: INFO: namespace: e2e-tests-projected-ql79d, resource: bindings, ignored listing per whitelist
Dec 10 14:29:08.900: INFO: namespace e2e-tests-projected-ql79d deletion completed in 22.125818015s

• [SLOW TEST:28.785 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 10 14:29:08.900: INFO: >>> kubeConfig: /tmp/kubeconfig-578738756
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Dec 10 14:29:08.977: INFO: Waiting up to 5m0s for pod "downwardapi-volume-f49ef301-fc87-11e8-a36b-7e9ed3de7210" in namespace "e2e-tests-downward-api-zkfzp" to be "success or failure"
Dec 10 14:29:08.987: INFO: Pod "downwardapi-volume-f49ef301-fc87-11e8-a36b-7e9ed3de7210": Phase="Pending", Reason="", readiness=false. Elapsed: 9.639334ms
Dec 10 14:29:10.994: INFO: Pod "downwardapi-volume-f49ef301-fc87-11e8-a36b-7e9ed3de7210": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.016794908s
STEP: Saw pod success
Dec 10 14:29:10.996: INFO: Pod "downwardapi-volume-f49ef301-fc87-11e8-a36b-7e9ed3de7210" satisfied condition "success or failure"
Dec 10 14:29:11.002: INFO: Trying to get logs from node conformance-cluster1-k8s-node-2 pod downwardapi-volume-f49ef301-fc87-11e8-a36b-7e9ed3de7210 container client-container: <nil>
STEP: delete the pod
Dec 10 14:29:11.029: INFO: Waiting for pod downwardapi-volume-f49ef301-fc87-11e8-a36b-7e9ed3de7210 to disappear
Dec 10 14:29:11.033: INFO: Pod downwardapi-volume-f49ef301-fc87-11e8-a36b-7e9ed3de7210 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 10 14:29:11.033: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-zkfzp" for this suite.
Dec 10 14:29:17.055: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 14:29:17.072: INFO: namespace: e2e-tests-downward-api-zkfzp, resource: bindings, ignored listing per whitelist
Dec 10 14:29:17.239: INFO: namespace e2e-tests-downward-api-zkfzp deletion completed in 6.19947744s

• [SLOW TEST:8.339 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 10 14:29:17.239: INFO: >>> kubeConfig: /tmp/kubeconfig-578738756
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Dec 10 14:29:17.303: INFO: Waiting up to 5m0s for pod "downwardapi-volume-f995d4fa-fc87-11e8-a36b-7e9ed3de7210" in namespace "e2e-tests-downward-api-9l7hf" to be "success or failure"
Dec 10 14:29:17.309: INFO: Pod "downwardapi-volume-f995d4fa-fc87-11e8-a36b-7e9ed3de7210": Phase="Pending", Reason="", readiness=false. Elapsed: 5.88343ms
Dec 10 14:29:19.313: INFO: Pod "downwardapi-volume-f995d4fa-fc87-11e8-a36b-7e9ed3de7210": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.0104164s
STEP: Saw pod success
Dec 10 14:29:19.313: INFO: Pod "downwardapi-volume-f995d4fa-fc87-11e8-a36b-7e9ed3de7210" satisfied condition "success or failure"
Dec 10 14:29:19.317: INFO: Trying to get logs from node conformance-cluster1-k8s-node-2 pod downwardapi-volume-f995d4fa-fc87-11e8-a36b-7e9ed3de7210 container client-container: <nil>
STEP: delete the pod
Dec 10 14:29:19.347: INFO: Waiting for pod downwardapi-volume-f995d4fa-fc87-11e8-a36b-7e9ed3de7210 to disappear
Dec 10 14:29:19.350: INFO: Pod downwardapi-volume-f995d4fa-fc87-11e8-a36b-7e9ed3de7210 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 10 14:29:19.350: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-9l7hf" for this suite.
Dec 10 14:29:25.373: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 14:29:25.455: INFO: namespace: e2e-tests-downward-api-9l7hf, resource: bindings, ignored listing per whitelist
Dec 10 14:29:25.475: INFO: namespace e2e-tests-downward-api-9l7hf deletion completed in 6.120830345s

• [SLOW TEST:8.236 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run deployment 
  should create a deployment from an image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 10 14:29:25.476: INFO: >>> kubeConfig: /tmp/kubeconfig-578738756
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Kubectl run deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1347
[It] should create a deployment from an image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Dec 10 14:29:25.537: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-578738756 run e2e-test-nginx-deployment --image=docker.io/library/nginx:1.14-alpine --generator=deployment/v1beta1 --namespace=e2e-tests-kubectl-wvz2p'
Dec 10 14:29:25.692: INFO: stderr: "kubectl run --generator=deployment/v1beta1 is DEPRECATED and will be removed in a future version. Use kubectl create instead.\n"
Dec 10 14:29:25.692: INFO: stdout: "deployment.extensions/e2e-test-nginx-deployment created\n"
STEP: verifying the deployment e2e-test-nginx-deployment was created
STEP: verifying the pod controlled by deployment e2e-test-nginx-deployment was created
[AfterEach] [k8s.io] Kubectl run deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1352
Dec 10 14:29:29.708: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-578738756 delete deployment e2e-test-nginx-deployment --namespace=e2e-tests-kubectl-wvz2p'
Dec 10 14:29:29.805: INFO: stderr: ""
Dec 10 14:29:29.805: INFO: stdout: "deployment.extensions \"e2e-test-nginx-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 10 14:29:29.805: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-wvz2p" for this suite.
Dec 10 14:29:51.824: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 14:29:51.918: INFO: namespace: e2e-tests-kubectl-wvz2p, resource: bindings, ignored listing per whitelist
Dec 10 14:29:51.930: INFO: namespace e2e-tests-kubectl-wvz2p deletion completed in 22.120874917s

• [SLOW TEST:26.454 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create a deployment from an image  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] version v1
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 10 14:29:51.932: INFO: >>> kubeConfig: /tmp/kubeconfig-578738756
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Dec 10 14:29:52.008: INFO: (0) /api/v1/nodes/conformance-cluster1-k8s-node-1:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 4.041833ms)
Dec 10 14:29:52.011: INFO: (1) /api/v1/nodes/conformance-cluster1-k8s-node-1:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 3.476945ms)
Dec 10 14:29:52.015: INFO: (2) /api/v1/nodes/conformance-cluster1-k8s-node-1:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 3.724416ms)
Dec 10 14:29:52.019: INFO: (3) /api/v1/nodes/conformance-cluster1-k8s-node-1:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 3.839789ms)
Dec 10 14:29:52.023: INFO: (4) /api/v1/nodes/conformance-cluster1-k8s-node-1:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 3.540463ms)
Dec 10 14:29:52.027: INFO: (5) /api/v1/nodes/conformance-cluster1-k8s-node-1:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 4.673877ms)
Dec 10 14:29:52.031: INFO: (6) /api/v1/nodes/conformance-cluster1-k8s-node-1:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 3.56969ms)
Dec 10 14:29:52.035: INFO: (7) /api/v1/nodes/conformance-cluster1-k8s-node-1:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 3.838223ms)
Dec 10 14:29:52.038: INFO: (8) /api/v1/nodes/conformance-cluster1-k8s-node-1:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 3.440452ms)
Dec 10 14:29:52.042: INFO: (9) /api/v1/nodes/conformance-cluster1-k8s-node-1:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 3.973341ms)
Dec 10 14:29:52.046: INFO: (10) /api/v1/nodes/conformance-cluster1-k8s-node-1:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 3.717133ms)
Dec 10 14:29:52.050: INFO: (11) /api/v1/nodes/conformance-cluster1-k8s-node-1:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 4.090278ms)
Dec 10 14:29:52.058: INFO: (12) /api/v1/nodes/conformance-cluster1-k8s-node-1:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 7.408823ms)
Dec 10 14:29:52.063: INFO: (13) /api/v1/nodes/conformance-cluster1-k8s-node-1:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 5.026441ms)
Dec 10 14:29:52.067: INFO: (14) /api/v1/nodes/conformance-cluster1-k8s-node-1:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 4.684968ms)
Dec 10 14:29:52.072: INFO: (15) /api/v1/nodes/conformance-cluster1-k8s-node-1:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 4.461587ms)
Dec 10 14:29:52.078: INFO: (16) /api/v1/nodes/conformance-cluster1-k8s-node-1:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 5.532575ms)
Dec 10 14:29:52.082: INFO: (17) /api/v1/nodes/conformance-cluster1-k8s-node-1:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 4.1011ms)
Dec 10 14:29:52.086: INFO: (18) /api/v1/nodes/conformance-cluster1-k8s-node-1:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 4.077495ms)
Dec 10 14:29:52.090: INFO: (19) /api/v1/nodes/conformance-cluster1-k8s-node-1:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 3.945806ms)
[AfterEach] version v1
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 10 14:29:52.090: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-proxy-vv2lx" for this suite.
Dec 10 14:29:58.113: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 14:29:58.148: INFO: namespace: e2e-tests-proxy-vv2lx, resource: bindings, ignored listing per whitelist
Dec 10 14:29:58.226: INFO: namespace e2e-tests-proxy-vv2lx deletion completed in 6.132241966s

• [SLOW TEST:6.294 seconds]
[sig-network] Proxy
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 10 14:29:58.227: INFO: >>> kubeConfig: /tmp/kubeconfig-578738756
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating replication controller my-hostname-basic-1204a12b-fc88-11e8-a36b-7e9ed3de7210
Dec 10 14:29:58.296: INFO: Pod name my-hostname-basic-1204a12b-fc88-11e8-a36b-7e9ed3de7210: Found 0 pods out of 1
Dec 10 14:30:03.300: INFO: Pod name my-hostname-basic-1204a12b-fc88-11e8-a36b-7e9ed3de7210: Found 1 pods out of 1
Dec 10 14:30:03.300: INFO: Ensuring all pods for ReplicationController "my-hostname-basic-1204a12b-fc88-11e8-a36b-7e9ed3de7210" are running
Dec 10 14:30:03.304: INFO: Pod "my-hostname-basic-1204a12b-fc88-11e8-a36b-7e9ed3de7210-56k7v" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2018-12-10 14:29:58 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2018-12-10 14:30:00 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2018-12-10 14:30:00 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2018-12-10 14:29:58 +0000 UTC Reason: Message:}])
Dec 10 14:30:03.304: INFO: Trying to dial the pod
Dec 10 14:30:08.323: INFO: Controller my-hostname-basic-1204a12b-fc88-11e8-a36b-7e9ed3de7210: Got expected result from replica 1 [my-hostname-basic-1204a12b-fc88-11e8-a36b-7e9ed3de7210-56k7v]: "my-hostname-basic-1204a12b-fc88-11e8-a36b-7e9ed3de7210-56k7v", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 10 14:30:08.323: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-replication-controller-2hksz" for this suite.
Dec 10 14:30:14.344: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 14:30:14.396: INFO: namespace: e2e-tests-replication-controller-2hksz, resource: bindings, ignored listing per whitelist
Dec 10 14:30:14.450: INFO: namespace e2e-tests-replication-controller-2hksz deletion completed in 6.121860269s

• [SLOW TEST:16.223 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 10 14:30:14.450: INFO: >>> kubeConfig: /tmp/kubeconfig-578738756
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-1bb24365-fc88-11e8-a36b-7e9ed3de7210
STEP: Creating a pod to test consume secrets
Dec 10 14:30:14.537: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-1bb345b4-fc88-11e8-a36b-7e9ed3de7210" in namespace "e2e-tests-projected-x2lmf" to be "success or failure"
Dec 10 14:30:14.541: INFO: Pod "pod-projected-secrets-1bb345b4-fc88-11e8-a36b-7e9ed3de7210": Phase="Pending", Reason="", readiness=false. Elapsed: 3.927049ms
Dec 10 14:30:16.545: INFO: Pod "pod-projected-secrets-1bb345b4-fc88-11e8-a36b-7e9ed3de7210": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008055927s
Dec 10 14:30:18.555: INFO: Pod "pod-projected-secrets-1bb345b4-fc88-11e8-a36b-7e9ed3de7210": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.017631958s
STEP: Saw pod success
Dec 10 14:30:18.555: INFO: Pod "pod-projected-secrets-1bb345b4-fc88-11e8-a36b-7e9ed3de7210" satisfied condition "success or failure"
Dec 10 14:30:18.558: INFO: Trying to get logs from node conformance-cluster1-k8s-node-2 pod pod-projected-secrets-1bb345b4-fc88-11e8-a36b-7e9ed3de7210 container projected-secret-volume-test: <nil>
STEP: delete the pod
Dec 10 14:30:18.581: INFO: Waiting for pod pod-projected-secrets-1bb345b4-fc88-11e8-a36b-7e9ed3de7210 to disappear
Dec 10 14:30:18.584: INFO: Pod pod-projected-secrets-1bb345b4-fc88-11e8-a36b-7e9ed3de7210 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 10 14:30:18.584: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-x2lmf" for this suite.
Dec 10 14:30:24.603: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 14:30:24.624: INFO: namespace: e2e-tests-projected-x2lmf, resource: bindings, ignored listing per whitelist
Dec 10 14:30:24.716: INFO: namespace e2e-tests-projected-x2lmf deletion completed in 6.127648752s

• [SLOW TEST:10.266 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 10 14:30:24.717: INFO: >>> kubeConfig: /tmp/kubeconfig-578738756
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the pods
STEP: Gathering metrics
W1210 14:31:04.827036      15 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Dec 10 14:31:04.827: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 10 14:31:04.827: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-74tm8" for this suite.
Dec 10 14:31:10.846: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 14:31:10.940: INFO: namespace: e2e-tests-gc-74tm8, resource: bindings, ignored listing per whitelist
Dec 10 14:31:10.997: INFO: namespace e2e-tests-gc-74tm8 deletion completed in 6.166527504s

• [SLOW TEST:46.280 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 10 14:31:10.998: INFO: >>> kubeConfig: /tmp/kubeconfig-578738756
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Dec 10 14:31:11.138: INFO: Waiting up to 5m0s for pod "downwardapi-volume-3d6decf5-fc88-11e8-a36b-7e9ed3de7210" in namespace "e2e-tests-downward-api-t6n2m" to be "success or failure"
Dec 10 14:31:11.149: INFO: Pod "downwardapi-volume-3d6decf5-fc88-11e8-a36b-7e9ed3de7210": Phase="Pending", Reason="", readiness=false. Elapsed: 11.144084ms
Dec 10 14:31:13.154: INFO: Pod "downwardapi-volume-3d6decf5-fc88-11e8-a36b-7e9ed3de7210": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01589184s
Dec 10 14:31:15.163: INFO: Pod "downwardapi-volume-3d6decf5-fc88-11e8-a36b-7e9ed3de7210": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.025034331s
STEP: Saw pod success
Dec 10 14:31:15.163: INFO: Pod "downwardapi-volume-3d6decf5-fc88-11e8-a36b-7e9ed3de7210" satisfied condition "success or failure"
Dec 10 14:31:15.166: INFO: Trying to get logs from node conformance-cluster1-k8s-node-2 pod downwardapi-volume-3d6decf5-fc88-11e8-a36b-7e9ed3de7210 container client-container: <nil>
STEP: delete the pod
Dec 10 14:31:15.194: INFO: Waiting for pod downwardapi-volume-3d6decf5-fc88-11e8-a36b-7e9ed3de7210 to disappear
Dec 10 14:31:15.197: INFO: Pod downwardapi-volume-3d6decf5-fc88-11e8-a36b-7e9ed3de7210 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 10 14:31:15.197: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-t6n2m" for this suite.
Dec 10 14:31:21.220: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 14:31:21.320: INFO: namespace: e2e-tests-downward-api-t6n2m, resource: bindings, ignored listing per whitelist
Dec 10 14:31:21.326: INFO: namespace e2e-tests-downward-api-t6n2m deletion completed in 6.123675453s

• [SLOW TEST:10.329 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-api-machinery] Downward API 
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 10 14:31:21.327: INFO: >>> kubeConfig: /tmp/kubeconfig-578738756
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Dec 10 14:31:21.406: INFO: Waiting up to 5m0s for pod "downward-api-438de84f-fc88-11e8-a36b-7e9ed3de7210" in namespace "e2e-tests-downward-api-4kckk" to be "success or failure"
Dec 10 14:31:21.412: INFO: Pod "downward-api-438de84f-fc88-11e8-a36b-7e9ed3de7210": Phase="Pending", Reason="", readiness=false. Elapsed: 6.206227ms
Dec 10 14:31:23.417: INFO: Pod "downward-api-438de84f-fc88-11e8-a36b-7e9ed3de7210": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.011080488s
STEP: Saw pod success
Dec 10 14:31:23.417: INFO: Pod "downward-api-438de84f-fc88-11e8-a36b-7e9ed3de7210" satisfied condition "success or failure"
Dec 10 14:31:23.420: INFO: Trying to get logs from node conformance-cluster1-k8s-node-2 pod downward-api-438de84f-fc88-11e8-a36b-7e9ed3de7210 container dapi-container: <nil>
STEP: delete the pod
Dec 10 14:31:23.452: INFO: Waiting for pod downward-api-438de84f-fc88-11e8-a36b-7e9ed3de7210 to disappear
Dec 10 14:31:23.456: INFO: Pod downward-api-438de84f-fc88-11e8-a36b-7e9ed3de7210 no longer exists
[AfterEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 10 14:31:23.456: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-4kckk" for this suite.
Dec 10 14:31:29.476: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 14:31:29.564: INFO: namespace: e2e-tests-downward-api-4kckk, resource: bindings, ignored listing per whitelist
Dec 10 14:31:29.586: INFO: namespace e2e-tests-downward-api-4kckk deletion completed in 6.125824476s

• [SLOW TEST:8.260 seconds]
[sig-api-machinery] Downward API
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Projected 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 10 14:31:29.587: INFO: >>> kubeConfig: /tmp/kubeconfig-578738756
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name cm-test-opt-del-487a9dd7-fc88-11e8-a36b-7e9ed3de7210
STEP: Creating configMap with name cm-test-opt-upd-487a9e0b-fc88-11e8-a36b-7e9ed3de7210
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-487a9dd7-fc88-11e8-a36b-7e9ed3de7210
STEP: Updating configmap cm-test-opt-upd-487a9e0b-fc88-11e8-a36b-7e9ed3de7210
STEP: Creating configMap with name cm-test-opt-create-487a9e1f-fc88-11e8-a36b-7e9ed3de7210
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 10 14:31:33.785: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-4qbl5" for this suite.
Dec 10 14:31:55.804: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 14:31:55.891: INFO: namespace: e2e-tests-projected-4qbl5, resource: bindings, ignored listing per whitelist
Dec 10 14:31:55.921: INFO: namespace e2e-tests-projected-4qbl5 deletion completed in 22.131222501s

• [SLOW TEST:26.334 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[k8s.io] [sig-node] Pods Extended [k8s.io] Pods Set QOS Class 
  should be submitted and removed  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 10 14:31:55.921: INFO: >>> kubeConfig: /tmp/kubeconfig-578738756
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pods.go:204
[It] should be submitted and removed  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying QOS class is set on the pod
[AfterEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 10 14:31:56.009: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-68t9j" for this suite.
Dec 10 14:32:18.032: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 14:32:18.103: INFO: namespace: e2e-tests-pods-68t9j, resource: bindings, ignored listing per whitelist
Dec 10 14:32:18.138: INFO: namespace e2e-tests-pods-68t9j deletion completed in 22.12358415s

• [SLOW TEST:22.218 seconds]
[k8s.io] [sig-node] Pods Extended
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should be submitted and removed  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[k8s.io] [sig-node] PreStop 
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 10 14:32:18.139: INFO: >>> kubeConfig: /tmp/kubeconfig-578738756
STEP: Building a namespace api object, basename prestop
STEP: Waiting for a default service account to be provisioned in namespace
[It] should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating server pod server in namespace e2e-tests-prestop-7m59z
STEP: Waiting for pods to come up.
STEP: Creating tester pod tester in namespace e2e-tests-prestop-7m59z
STEP: Deleting pre-stop pod
Dec 10 14:32:31.263: INFO: Saw: {
	"Hostname": "server",
	"Sent": null,
	"Received": {
		"prestop": 1
	},
	"Errors": null,
	"Log": [
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up."
	],
	"StillContactingPeers": true
}
STEP: Deleting the server pod
[AfterEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 10 14:32:31.271: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-prestop-7m59z" for this suite.
Dec 10 14:33:09.292: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 14:33:09.395: INFO: namespace: e2e-tests-prestop-7m59z, resource: bindings, ignored listing per whitelist
Dec 10 14:33:09.409: INFO: namespace e2e-tests-prestop-7m59z deletion completed in 38.133137536s

• [SLOW TEST:51.270 seconds]
[k8s.io] [sig-node] PreStop
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run job 
  should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 10 14:33:09.410: INFO: >>> kubeConfig: /tmp/kubeconfig-578738756
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Kubectl run job
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1402
[It] should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Dec 10 14:33:09.476: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-578738756 run e2e-test-nginx-job --restart=OnFailure --generator=job/v1 --image=docker.io/library/nginx:1.14-alpine --namespace=e2e-tests-kubectl-wg52f'
Dec 10 14:33:09.568: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl create instead.\n"
Dec 10 14:33:09.568: INFO: stdout: "job.batch/e2e-test-nginx-job created\n"
STEP: verifying the job e2e-test-nginx-job was created
[AfterEach] [k8s.io] Kubectl run job
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1407
Dec 10 14:33:09.573: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-578738756 delete jobs e2e-test-nginx-job --namespace=e2e-tests-kubectl-wg52f'
Dec 10 14:33:09.697: INFO: stderr: ""
Dec 10 14:33:09.697: INFO: stdout: "job.batch \"e2e-test-nginx-job\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 10 14:33:09.697: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-wg52f" for this suite.
Dec 10 14:33:15.725: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 14:33:15.812: INFO: namespace: e2e-tests-kubectl-wg52f, resource: bindings, ignored listing per whitelist
Dec 10 14:33:15.829: INFO: namespace e2e-tests-kubectl-wg52f deletion completed in 6.125786177s

• [SLOW TEST:6.420 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run job
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create a job from an image when restart is OnFailure  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl api-versions 
  should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 10 14:33:15.830: INFO: >>> kubeConfig: /tmp/kubeconfig-578738756
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: validating api versions
Dec 10 14:33:15.888: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-578738756 api-versions'
Dec 10 14:33:15.965: INFO: stderr: ""
Dec 10 14:33:15.965: INFO: stdout: "admissionregistration.k8s.io/v1alpha1\nadmissionregistration.k8s.io/v1beta1\napiextensions.k8s.io/v1beta1\napiregistration.k8s.io/v1\napiregistration.k8s.io/v1beta1\napps/v1\napps/v1beta1\napps/v1beta2\nauthentication.k8s.io/v1\nauthentication.k8s.io/v1beta1\nauthorization.k8s.io/v1\nauthorization.k8s.io/v1beta1\nautoscaling/v1\nautoscaling/v2beta1\nautoscaling/v2beta2\nbatch/v1\nbatch/v1beta1\ncertificates.k8s.io/v1beta1\ncoordination.k8s.io/v1beta1\nevents.k8s.io/v1beta1\nextensions/v1beta1\nmetrics.k8s.io/v1beta1\nnetworking.k8s.io/v1\npolicy/v1beta1\nrbac.authorization.k8s.io/v1\nrbac.authorization.k8s.io/v1beta1\nscheduling.k8s.io/v1beta1\nstorage.k8s.io/v1\nstorage.k8s.io/v1beta1\nv1\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 10 14:33:15.965: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-xbk6n" for this suite.
Dec 10 14:33:21.986: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 14:33:22.065: INFO: namespace: e2e-tests-kubectl-xbk6n, resource: bindings, ignored listing per whitelist
Dec 10 14:33:22.092: INFO: namespace e2e-tests-kubectl-xbk6n deletion completed in 6.121640387s

• [SLOW TEST:6.262 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl api-versions
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should check if v1 is in available api versions  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 10 14:33:22.092: INFO: >>> kubeConfig: /tmp/kubeconfig-578738756
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:98
[It] should run and stop complex daemon [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Dec 10 14:33:22.163: INFO: Creating daemon "daemon-set" with a node selector
STEP: Initially, daemon pods should not be running on any nodes.
Dec 10 14:33:22.176: INFO: Number of nodes with available pods: 0
Dec 10 14:33:22.176: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Change node label to blue, check that daemon pod is launched.
Dec 10 14:33:22.197: INFO: Number of nodes with available pods: 0
Dec 10 14:33:22.197: INFO: Node conformance-cluster1-k8s-node-1 is running more than one daemon pod
Dec 10 14:33:23.202: INFO: Number of nodes with available pods: 0
Dec 10 14:33:23.202: INFO: Node conformance-cluster1-k8s-node-1 is running more than one daemon pod
Dec 10 14:33:24.202: INFO: Number of nodes with available pods: 1
Dec 10 14:33:24.202: INFO: Number of running nodes: 1, number of available pods: 1
STEP: Update the node label to green, and wait for daemons to be unscheduled
Dec 10 14:33:24.220: INFO: Number of nodes with available pods: 1
Dec 10 14:33:24.220: INFO: Number of running nodes: 0, number of available pods: 1
Dec 10 14:33:25.225: INFO: Number of nodes with available pods: 0
Dec 10 14:33:25.225: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Update DaemonSet node selector to green, and change its update strategy to RollingUpdate
Dec 10 14:33:25.236: INFO: Number of nodes with available pods: 0
Dec 10 14:33:25.236: INFO: Node conformance-cluster1-k8s-node-1 is running more than one daemon pod
Dec 10 14:33:26.247: INFO: Number of nodes with available pods: 0
Dec 10 14:33:26.247: INFO: Node conformance-cluster1-k8s-node-1 is running more than one daemon pod
Dec 10 14:33:27.241: INFO: Number of nodes with available pods: 0
Dec 10 14:33:27.242: INFO: Node conformance-cluster1-k8s-node-1 is running more than one daemon pod
Dec 10 14:33:28.241: INFO: Number of nodes with available pods: 0
Dec 10 14:33:28.241: INFO: Node conformance-cluster1-k8s-node-1 is running more than one daemon pod
Dec 10 14:33:29.241: INFO: Number of nodes with available pods: 0
Dec 10 14:33:29.241: INFO: Node conformance-cluster1-k8s-node-1 is running more than one daemon pod
Dec 10 14:33:30.241: INFO: Number of nodes with available pods: 0
Dec 10 14:33:30.241: INFO: Node conformance-cluster1-k8s-node-1 is running more than one daemon pod
Dec 10 14:33:31.241: INFO: Number of nodes with available pods: 0
Dec 10 14:33:31.241: INFO: Node conformance-cluster1-k8s-node-1 is running more than one daemon pod
Dec 10 14:33:32.241: INFO: Number of nodes with available pods: 0
Dec 10 14:33:32.241: INFO: Node conformance-cluster1-k8s-node-1 is running more than one daemon pod
Dec 10 14:33:33.241: INFO: Number of nodes with available pods: 0
Dec 10 14:33:33.241: INFO: Node conformance-cluster1-k8s-node-1 is running more than one daemon pod
Dec 10 14:33:34.241: INFO: Number of nodes with available pods: 0
Dec 10 14:33:34.242: INFO: Node conformance-cluster1-k8s-node-1 is running more than one daemon pod
Dec 10 14:33:35.241: INFO: Number of nodes with available pods: 0
Dec 10 14:33:35.241: INFO: Node conformance-cluster1-k8s-node-1 is running more than one daemon pod
Dec 10 14:33:36.242: INFO: Number of nodes with available pods: 0
Dec 10 14:33:36.242: INFO: Node conformance-cluster1-k8s-node-1 is running more than one daemon pod
Dec 10 14:33:37.247: INFO: Number of nodes with available pods: 0
Dec 10 14:33:37.247: INFO: Node conformance-cluster1-k8s-node-1 is running more than one daemon pod
Dec 10 14:33:38.241: INFO: Number of nodes with available pods: 0
Dec 10 14:33:38.241: INFO: Node conformance-cluster1-k8s-node-1 is running more than one daemon pod
Dec 10 14:33:39.240: INFO: Number of nodes with available pods: 0
Dec 10 14:33:39.241: INFO: Node conformance-cluster1-k8s-node-1 is running more than one daemon pod
Dec 10 14:33:40.241: INFO: Number of nodes with available pods: 0
Dec 10 14:33:40.241: INFO: Node conformance-cluster1-k8s-node-1 is running more than one daemon pod
Dec 10 14:33:41.241: INFO: Number of nodes with available pods: 0
Dec 10 14:33:41.241: INFO: Node conformance-cluster1-k8s-node-1 is running more than one daemon pod
Dec 10 14:33:42.241: INFO: Number of nodes with available pods: 0
Dec 10 14:33:42.241: INFO: Node conformance-cluster1-k8s-node-1 is running more than one daemon pod
Dec 10 14:33:43.241: INFO: Number of nodes with available pods: 0
Dec 10 14:33:43.241: INFO: Node conformance-cluster1-k8s-node-1 is running more than one daemon pod
Dec 10 14:33:44.241: INFO: Number of nodes with available pods: 0
Dec 10 14:33:44.241: INFO: Node conformance-cluster1-k8s-node-1 is running more than one daemon pod
Dec 10 14:33:45.241: INFO: Number of nodes with available pods: 0
Dec 10 14:33:45.242: INFO: Node conformance-cluster1-k8s-node-1 is running more than one daemon pod
Dec 10 14:33:46.241: INFO: Number of nodes with available pods: 0
Dec 10 14:33:46.241: INFO: Node conformance-cluster1-k8s-node-1 is running more than one daemon pod
Dec 10 14:33:47.241: INFO: Number of nodes with available pods: 0
Dec 10 14:33:47.241: INFO: Node conformance-cluster1-k8s-node-1 is running more than one daemon pod
Dec 10 14:33:48.247: INFO: Number of nodes with available pods: 0
Dec 10 14:33:48.247: INFO: Node conformance-cluster1-k8s-node-1 is running more than one daemon pod
Dec 10 14:33:49.241: INFO: Number of nodes with available pods: 0
Dec 10 14:33:49.241: INFO: Node conformance-cluster1-k8s-node-1 is running more than one daemon pod
Dec 10 14:33:50.241: INFO: Number of nodes with available pods: 0
Dec 10 14:33:50.241: INFO: Node conformance-cluster1-k8s-node-1 is running more than one daemon pod
Dec 10 14:33:51.241: INFO: Number of nodes with available pods: 0
Dec 10 14:33:51.241: INFO: Node conformance-cluster1-k8s-node-1 is running more than one daemon pod
Dec 10 14:33:52.241: INFO: Number of nodes with available pods: 0
Dec 10 14:33:52.242: INFO: Node conformance-cluster1-k8s-node-1 is running more than one daemon pod
Dec 10 14:33:53.241: INFO: Number of nodes with available pods: 0
Dec 10 14:33:53.241: INFO: Node conformance-cluster1-k8s-node-1 is running more than one daemon pod
Dec 10 14:33:54.241: INFO: Number of nodes with available pods: 0
Dec 10 14:33:54.242: INFO: Node conformance-cluster1-k8s-node-1 is running more than one daemon pod
Dec 10 14:33:55.241: INFO: Number of nodes with available pods: 0
Dec 10 14:33:55.241: INFO: Node conformance-cluster1-k8s-node-1 is running more than one daemon pod
Dec 10 14:33:56.241: INFO: Number of nodes with available pods: 0
Dec 10 14:33:56.242: INFO: Node conformance-cluster1-k8s-node-1 is running more than one daemon pod
Dec 10 14:33:57.241: INFO: Number of nodes with available pods: 0
Dec 10 14:33:57.241: INFO: Node conformance-cluster1-k8s-node-1 is running more than one daemon pod
Dec 10 14:33:58.241: INFO: Number of nodes with available pods: 0
Dec 10 14:33:58.241: INFO: Node conformance-cluster1-k8s-node-1 is running more than one daemon pod
Dec 10 14:33:59.246: INFO: Number of nodes with available pods: 0
Dec 10 14:33:59.246: INFO: Node conformance-cluster1-k8s-node-1 is running more than one daemon pod
Dec 10 14:34:00.241: INFO: Number of nodes with available pods: 0
Dec 10 14:34:00.241: INFO: Node conformance-cluster1-k8s-node-1 is running more than one daemon pod
Dec 10 14:34:01.241: INFO: Number of nodes with available pods: 0
Dec 10 14:34:01.241: INFO: Node conformance-cluster1-k8s-node-1 is running more than one daemon pod
Dec 10 14:34:02.241: INFO: Number of nodes with available pods: 0
Dec 10 14:34:02.241: INFO: Node conformance-cluster1-k8s-node-1 is running more than one daemon pod
Dec 10 14:34:03.241: INFO: Number of nodes with available pods: 0
Dec 10 14:34:03.241: INFO: Node conformance-cluster1-k8s-node-1 is running more than one daemon pod
Dec 10 14:34:04.242: INFO: Number of nodes with available pods: 0
Dec 10 14:34:04.242: INFO: Node conformance-cluster1-k8s-node-1 is running more than one daemon pod
Dec 10 14:34:05.241: INFO: Number of nodes with available pods: 0
Dec 10 14:34:05.241: INFO: Node conformance-cluster1-k8s-node-1 is running more than one daemon pod
Dec 10 14:34:06.241: INFO: Number of nodes with available pods: 0
Dec 10 14:34:06.241: INFO: Node conformance-cluster1-k8s-node-1 is running more than one daemon pod
Dec 10 14:34:07.240: INFO: Number of nodes with available pods: 0
Dec 10 14:34:07.241: INFO: Node conformance-cluster1-k8s-node-1 is running more than one daemon pod
Dec 10 14:34:08.241: INFO: Number of nodes with available pods: 0
Dec 10 14:34:08.241: INFO: Node conformance-cluster1-k8s-node-1 is running more than one daemon pod
Dec 10 14:34:09.241: INFO: Number of nodes with available pods: 0
Dec 10 14:34:09.241: INFO: Node conformance-cluster1-k8s-node-1 is running more than one daemon pod
Dec 10 14:34:10.246: INFO: Number of nodes with available pods: 1
Dec 10 14:34:10.246: INFO: Number of running nodes: 1, number of available pods: 1
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:64
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting {extensions DaemonSet} daemon-set in namespace e2e-tests-daemonsets-kt2wb, will wait for the garbage collector to delete the pods
Dec 10 14:34:10.317: INFO: Deleting {extensions DaemonSet} daemon-set took: 10.475464ms
Dec 10 14:34:10.417: INFO: Terminating {extensions DaemonSet} daemon-set pods took: 100.195087ms
Dec 10 14:34:44.427: INFO: Number of nodes with available pods: 0
Dec 10 14:34:44.427: INFO: Number of running nodes: 0, number of available pods: 0
Dec 10 14:34:44.430: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-kt2wb/daemonsets","resourceVersion":"15865"},"items":null}

Dec 10 14:34:44.433: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-kt2wb/pods","resourceVersion":"15865"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 10 14:34:44.453: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-kt2wb" for this suite.
Dec 10 14:34:50.473: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 14:34:50.576: INFO: namespace: e2e-tests-daemonsets-kt2wb, resource: bindings, ignored listing per whitelist
Dec 10 14:34:50.579: INFO: namespace e2e-tests-daemonsets-kt2wb deletion completed in 6.121891886s

• [SLOW TEST:88.488 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 10 14:34:50.579: INFO: >>> kubeConfig: /tmp/kubeconfig-578738756
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-c04754eb-fc88-11e8-a36b-7e9ed3de7210
STEP: Creating a pod to test consume secrets
Dec 10 14:34:50.660: INFO: Waiting up to 5m0s for pod "pod-secrets-c0484ea9-fc88-11e8-a36b-7e9ed3de7210" in namespace "e2e-tests-secrets-lbh7k" to be "success or failure"
Dec 10 14:34:50.664: INFO: Pod "pod-secrets-c0484ea9-fc88-11e8-a36b-7e9ed3de7210": Phase="Pending", Reason="", readiness=false. Elapsed: 4.137899ms
Dec 10 14:34:52.668: INFO: Pod "pod-secrets-c0484ea9-fc88-11e8-a36b-7e9ed3de7210": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008445009s
STEP: Saw pod success
Dec 10 14:34:52.668: INFO: Pod "pod-secrets-c0484ea9-fc88-11e8-a36b-7e9ed3de7210" satisfied condition "success or failure"
Dec 10 14:34:52.672: INFO: Trying to get logs from node conformance-cluster1-k8s-node-2 pod pod-secrets-c0484ea9-fc88-11e8-a36b-7e9ed3de7210 container secret-volume-test: <nil>
STEP: delete the pod
Dec 10 14:34:52.700: INFO: Waiting for pod pod-secrets-c0484ea9-fc88-11e8-a36b-7e9ed3de7210 to disappear
Dec 10 14:34:52.703: INFO: Pod pod-secrets-c0484ea9-fc88-11e8-a36b-7e9ed3de7210 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 10 14:34:52.703: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-lbh7k" for this suite.
Dec 10 14:34:58.721: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 14:34:58.778: INFO: namespace: e2e-tests-secrets-lbh7k, resource: bindings, ignored listing per whitelist
Dec 10 14:34:58.842: INFO: namespace e2e-tests-secrets-lbh7k deletion completed in 6.134925244s

• [SLOW TEST:8.263 seconds]
[sig-storage] Secrets
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[k8s.io] KubeletManagedEtcHosts 
  should test kubelet managed /etc/hosts file [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 10 14:34:58.842: INFO: >>> kubeConfig: /tmp/kubeconfig-578738756
STEP: Building a namespace api object, basename e2e-kubelet-etc-hosts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should test kubelet managed /etc/hosts file [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Setting up the test
STEP: Creating hostNetwork=false pod
STEP: Creating hostNetwork=true pod
STEP: Running the test
STEP: Verifying /etc/hosts of container is kubelet-managed for pod with hostNetwork=false
Dec 10 14:35:04.941: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-qswqx PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 10 14:35:04.941: INFO: >>> kubeConfig: /tmp/kubeconfig-578738756
Dec 10 14:35:05.047: INFO: Exec stderr: ""
Dec 10 14:35:05.047: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-qswqx PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 10 14:35:05.047: INFO: >>> kubeConfig: /tmp/kubeconfig-578738756
Dec 10 14:35:05.172: INFO: Exec stderr: ""
Dec 10 14:35:05.172: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-qswqx PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 10 14:35:05.172: INFO: >>> kubeConfig: /tmp/kubeconfig-578738756
Dec 10 14:35:05.277: INFO: Exec stderr: ""
Dec 10 14:35:05.277: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-qswqx PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 10 14:35:05.277: INFO: >>> kubeConfig: /tmp/kubeconfig-578738756
Dec 10 14:35:05.381: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts of container is not kubelet-managed since container specifies /etc/hosts mount
Dec 10 14:35:05.381: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-qswqx PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 10 14:35:05.381: INFO: >>> kubeConfig: /tmp/kubeconfig-578738756
Dec 10 14:35:05.479: INFO: Exec stderr: ""
Dec 10 14:35:05.479: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-qswqx PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 10 14:35:05.479: INFO: >>> kubeConfig: /tmp/kubeconfig-578738756
Dec 10 14:35:05.589: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts content of container is not kubelet-managed for pod with hostNetwork=true
Dec 10 14:35:05.589: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-qswqx PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 10 14:35:05.589: INFO: >>> kubeConfig: /tmp/kubeconfig-578738756
Dec 10 14:35:05.695: INFO: Exec stderr: ""
Dec 10 14:35:05.695: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-qswqx PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 10 14:35:05.695: INFO: >>> kubeConfig: /tmp/kubeconfig-578738756
Dec 10 14:35:05.824: INFO: Exec stderr: ""
Dec 10 14:35:05.824: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-qswqx PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 10 14:35:05.824: INFO: >>> kubeConfig: /tmp/kubeconfig-578738756
Dec 10 14:35:05.926: INFO: Exec stderr: ""
Dec 10 14:35:05.926: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-qswqx PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 10 14:35:05.926: INFO: >>> kubeConfig: /tmp/kubeconfig-578738756
Dec 10 14:35:06.042: INFO: Exec stderr: ""
[AfterEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 10 14:35:06.042: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-e2e-kubelet-etc-hosts-qswqx" for this suite.
Dec 10 14:35:52.067: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 14:35:52.133: INFO: namespace: e2e-tests-e2e-kubelet-etc-hosts-qswqx, resource: bindings, ignored listing per whitelist
Dec 10 14:35:52.180: INFO: namespace e2e-tests-e2e-kubelet-etc-hosts-qswqx deletion completed in 46.132534514s

• [SLOW TEST:53.338 seconds]
[k8s.io] KubeletManagedEtcHosts
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should test kubelet managed /etc/hosts file [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Secrets 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 10 14:35:52.180: INFO: >>> kubeConfig: /tmp/kubeconfig-578738756
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name s-test-opt-del-e4ff7f2c-fc88-11e8-a36b-7e9ed3de7210
STEP: Creating secret with name s-test-opt-upd-e4ff7f63-fc88-11e8-a36b-7e9ed3de7210
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-e4ff7f2c-fc88-11e8-a36b-7e9ed3de7210
STEP: Updating secret s-test-opt-upd-e4ff7f63-fc88-11e8-a36b-7e9ed3de7210
STEP: Creating secret with name s-test-opt-create-e4ff7f7d-fc88-11e8-a36b-7e9ed3de7210
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 10 14:35:56.382: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-bwcfm" for this suite.
Dec 10 14:36:18.401: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 14:36:18.434: INFO: namespace: e2e-tests-secrets-bwcfm, resource: bindings, ignored listing per whitelist
Dec 10 14:36:18.512: INFO: namespace e2e-tests-secrets-bwcfm deletion completed in 22.126076854s

• [SLOW TEST:26.332 seconds]
[sig-storage] Secrets
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-api-machinery] Garbage collector 
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 10 14:36:18.513: INFO: >>> kubeConfig: /tmp/kubeconfig-578738756
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Dec 10 14:36:18.615: INFO: pod1.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod3", UID:"f4b46abb-fc88-11e8-8690-fa163e74bd5a", Controller:(*bool)(0xc420fa4c9e), BlockOwnerDeletion:(*bool)(0xc420fa4c9f)}}
Dec 10 14:36:18.621: INFO: pod2.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod1", UID:"f4b18208-fc88-11e8-8690-fa163e74bd5a", Controller:(*bool)(0xc4220a41fe), BlockOwnerDeletion:(*bool)(0xc4220a41ff)}}
Dec 10 14:36:18.626: INFO: pod3.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod2", UID:"f4b33010-fc88-11e8-8690-fa163e74bd5a", Controller:(*bool)(0xc420fa4ebe), BlockOwnerDeletion:(*bool)(0xc420fa4ebf)}}
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 10 14:36:23.645: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-twlzk" for this suite.
Dec 10 14:36:29.664: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 14:36:29.715: INFO: namespace: e2e-tests-gc-twlzk, resource: bindings, ignored listing per whitelist
Dec 10 14:36:29.784: INFO: namespace e2e-tests-gc-twlzk deletion completed in 6.134686693s

• [SLOW TEST:11.271 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl replace 
  should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 10 14:36:29.784: INFO: >>> kubeConfig: /tmp/kubeconfig-578738756
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Kubectl replace
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1511
[It] should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Dec 10 14:36:29.861: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-578738756 run e2e-test-nginx-pod --generator=run-pod/v1 --image=docker.io/library/nginx:1.14-alpine --labels=run=e2e-test-nginx-pod --namespace=e2e-tests-kubectl-gbhj9'
Dec 10 14:36:29.952: INFO: stderr: ""
Dec 10 14:36:29.952: INFO: stdout: "pod/e2e-test-nginx-pod created\n"
STEP: verifying the pod e2e-test-nginx-pod is running
STEP: verifying the pod e2e-test-nginx-pod was created
Dec 10 14:36:35.003: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-578738756 get pod e2e-test-nginx-pod --namespace=e2e-tests-kubectl-gbhj9 -o json'
Dec 10 14:36:35.111: INFO: stderr: ""
Dec 10 14:36:35.111: INFO: stdout: "{\n    \"apiVersion\": \"v1\",\n    \"kind\": \"Pod\",\n    \"metadata\": {\n        \"creationTimestamp\": \"2018-12-10T14:36:29Z\",\n        \"labels\": {\n            \"run\": \"e2e-test-nginx-pod\"\n        },\n        \"name\": \"e2e-test-nginx-pod\",\n        \"namespace\": \"e2e-tests-kubectl-gbhj9\",\n        \"resourceVersion\": \"16285\",\n        \"selfLink\": \"/api/v1/namespaces/e2e-tests-kubectl-gbhj9/pods/e2e-test-nginx-pod\",\n        \"uid\": \"fb762d6b-fc88-11e8-808b-fa163e6bf550\"\n    },\n    \"spec\": {\n        \"containers\": [\n            {\n                \"image\": \"docker.io/library/nginx:1.14-alpine\",\n                \"imagePullPolicy\": \"IfNotPresent\",\n                \"name\": \"e2e-test-nginx-pod\",\n                \"resources\": {},\n                \"terminationMessagePath\": \"/dev/termination-log\",\n                \"terminationMessagePolicy\": \"File\",\n                \"volumeMounts\": [\n                    {\n                        \"mountPath\": \"/var/run/secrets/kubernetes.io/serviceaccount\",\n                        \"name\": \"default-token-l9n28\",\n                        \"readOnly\": true\n                    }\n                ]\n            }\n        ],\n        \"dnsPolicy\": \"ClusterFirst\",\n        \"nodeName\": \"conformance-cluster1-k8s-node-2\",\n        \"priority\": 0,\n        \"restartPolicy\": \"Always\",\n        \"schedulerName\": \"default-scheduler\",\n        \"securityContext\": {},\n        \"serviceAccount\": \"default\",\n        \"serviceAccountName\": \"default\",\n        \"terminationGracePeriodSeconds\": 30,\n        \"tolerations\": [\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/not-ready\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            },\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/unreachable\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            }\n        ],\n        \"volumes\": [\n            {\n                \"name\": \"default-token-l9n28\",\n                \"secret\": {\n                    \"defaultMode\": 420,\n                    \"secretName\": \"default-token-l9n28\"\n                }\n            }\n        ]\n    },\n    \"status\": {\n        \"conditions\": [\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2018-12-10T14:36:29Z\",\n                \"status\": \"True\",\n                \"type\": \"Initialized\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2018-12-10T14:36:31Z\",\n                \"status\": \"True\",\n                \"type\": \"Ready\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2018-12-10T14:36:31Z\",\n                \"status\": \"True\",\n                \"type\": \"ContainersReady\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2018-12-10T14:36:29Z\",\n                \"status\": \"True\",\n                \"type\": \"PodScheduled\"\n            }\n        ],\n        \"containerStatuses\": [\n            {\n                \"containerID\": \"docker://7d752ef2e6f8120566a5074a81e9b7a74d28c81b802d07983a6d2ca45937724c\",\n                \"image\": \"nginx:1.14-alpine\",\n                \"imageID\": \"docker-pullable://nginx@sha256:2abeba7cab34eb197ff7363486a2aa590027388eafd8e740efae7aae1bed28b6\",\n                \"lastState\": {},\n                \"name\": \"e2e-test-nginx-pod\",\n                \"ready\": true,\n                \"restartCount\": 0,\n                \"state\": {\n                    \"running\": {\n                        \"startedAt\": \"2018-12-10T14:36:31Z\"\n                    }\n                }\n            }\n        ],\n        \"hostIP\": \"10.0.0.10\",\n        \"phase\": \"Running\",\n        \"podIP\": \"10.233.122.237\",\n        \"qosClass\": \"BestEffort\",\n        \"startTime\": \"2018-12-10T14:36:29Z\"\n    }\n}\n"
STEP: replace the image in the pod
Dec 10 14:36:35.111: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-578738756 replace -f - --namespace=e2e-tests-kubectl-gbhj9'
Dec 10 14:36:35.273: INFO: stderr: ""
Dec 10 14:36:35.273: INFO: stdout: "pod/e2e-test-nginx-pod replaced\n"
STEP: verifying the pod e2e-test-nginx-pod has the right image docker.io/library/busybox:1.29
[AfterEach] [k8s.io] Kubectl replace
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1516
Dec 10 14:36:35.277: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-578738756 delete pods e2e-test-nginx-pod --namespace=e2e-tests-kubectl-gbhj9'
Dec 10 14:36:48.172: INFO: stderr: ""
Dec 10 14:36:48.172: INFO: stdout: "pod \"e2e-test-nginx-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 10 14:36:48.172: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-gbhj9" for this suite.
Dec 10 14:36:54.198: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 14:36:54.269: INFO: namespace: e2e-tests-kubectl-gbhj9, resource: bindings, ignored listing per whitelist
Dec 10 14:36:54.309: INFO: namespace e2e-tests-kubectl-gbhj9 deletion completed in 6.127157273s

• [SLOW TEST:24.525 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl replace
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should update a single-container pod's image  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 10 14:36:54.309: INFO: >>> kubeConfig: /tmp/kubeconfig-578738756
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Dec 10 14:36:54.393: INFO: Waiting up to 5m0s for pod "downwardapi-volume-0a07c384-fc89-11e8-a36b-7e9ed3de7210" in namespace "e2e-tests-projected-4pptw" to be "success or failure"
Dec 10 14:36:54.398: INFO: Pod "downwardapi-volume-0a07c384-fc89-11e8-a36b-7e9ed3de7210": Phase="Pending", Reason="", readiness=false. Elapsed: 5.010998ms
Dec 10 14:36:56.409: INFO: Pod "downwardapi-volume-0a07c384-fc89-11e8-a36b-7e9ed3de7210": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.016358091s
STEP: Saw pod success
Dec 10 14:36:56.409: INFO: Pod "downwardapi-volume-0a07c384-fc89-11e8-a36b-7e9ed3de7210" satisfied condition "success or failure"
Dec 10 14:36:56.414: INFO: Trying to get logs from node conformance-cluster1-k8s-node-1 pod downwardapi-volume-0a07c384-fc89-11e8-a36b-7e9ed3de7210 container client-container: <nil>
STEP: delete the pod
Dec 10 14:36:56.443: INFO: Waiting for pod downwardapi-volume-0a07c384-fc89-11e8-a36b-7e9ed3de7210 to disappear
Dec 10 14:36:56.446: INFO: Pod downwardapi-volume-0a07c384-fc89-11e8-a36b-7e9ed3de7210 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 10 14:36:56.447: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-4pptw" for this suite.
Dec 10 14:37:02.468: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 14:37:02.508: INFO: namespace: e2e-tests-projected-4pptw, resource: bindings, ignored listing per whitelist
Dec 10 14:37:02.572: INFO: namespace e2e-tests-projected-4pptw deletion completed in 6.120892735s

• [SLOW TEST:8.263 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 10 14:37:02.573: INFO: >>> kubeConfig: /tmp/kubeconfig-578738756
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0666 on node default medium
Dec 10 14:37:02.641: INFO: Waiting up to 5m0s for pod "pod-0ef2916c-fc89-11e8-a36b-7e9ed3de7210" in namespace "e2e-tests-emptydir-q6fm7" to be "success or failure"
Dec 10 14:37:02.647: INFO: Pod "pod-0ef2916c-fc89-11e8-a36b-7e9ed3de7210": Phase="Pending", Reason="", readiness=false. Elapsed: 6.018219ms
Dec 10 14:37:04.651: INFO: Pod "pod-0ef2916c-fc89-11e8-a36b-7e9ed3de7210": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010359842s
STEP: Saw pod success
Dec 10 14:37:04.651: INFO: Pod "pod-0ef2916c-fc89-11e8-a36b-7e9ed3de7210" satisfied condition "success or failure"
Dec 10 14:37:04.655: INFO: Trying to get logs from node conformance-cluster1-k8s-node-2 pod pod-0ef2916c-fc89-11e8-a36b-7e9ed3de7210 container test-container: <nil>
STEP: delete the pod
Dec 10 14:37:04.680: INFO: Waiting for pod pod-0ef2916c-fc89-11e8-a36b-7e9ed3de7210 to disappear
Dec 10 14:37:04.683: INFO: Pod pod-0ef2916c-fc89-11e8-a36b-7e9ed3de7210 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 10 14:37:04.683: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-q6fm7" for this suite.
Dec 10 14:37:10.707: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 14:37:10.737: INFO: namespace: e2e-tests-emptydir-q6fm7, resource: bindings, ignored listing per whitelist
Dec 10 14:37:10.812: INFO: namespace e2e-tests-emptydir-q6fm7 deletion completed in 6.124721859s

• [SLOW TEST:8.239 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-network] Service endpoints latency 
  should not be very high  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 10 14:37:10.812: INFO: >>> kubeConfig: /tmp/kubeconfig-578738756
STEP: Building a namespace api object, basename svc-latency
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be very high  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating replication controller svc-latency-rc in namespace e2e-tests-svc-latency-jzsgk
I1210 14:37:10.887062      15 runners.go:180] Created replication controller with name: svc-latency-rc, namespace: e2e-tests-svc-latency-jzsgk, replica count: 1
I1210 14:37:11.937375      15 runners.go:180] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1210 14:37:12.937586      15 runners.go:180] svc-latency-rc Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Dec 10 14:37:13.050: INFO: Created: latency-svc-f5st2
Dec 10 14:37:13.063: INFO: Got endpoints: latency-svc-f5st2 [25.471087ms]
Dec 10 14:37:13.077: INFO: Created: latency-svc-k6v8t
Dec 10 14:37:13.081: INFO: Got endpoints: latency-svc-k6v8t [17.820649ms]
Dec 10 14:37:13.086: INFO: Created: latency-svc-9qmjt
Dec 10 14:37:13.092: INFO: Got endpoints: latency-svc-9qmjt [28.765409ms]
Dec 10 14:37:13.095: INFO: Created: latency-svc-m65l4
Dec 10 14:37:13.098: INFO: Got endpoints: latency-svc-m65l4 [34.940992ms]
Dec 10 14:37:13.106: INFO: Created: latency-svc-7r2xj
Dec 10 14:37:13.110: INFO: Got endpoints: latency-svc-7r2xj [46.086929ms]
Dec 10 14:37:13.115: INFO: Created: latency-svc-smfxk
Dec 10 14:37:13.120: INFO: Got endpoints: latency-svc-smfxk [56.350539ms]
Dec 10 14:37:13.125: INFO: Created: latency-svc-sg7fd
Dec 10 14:37:13.131: INFO: Got endpoints: latency-svc-sg7fd [66.759128ms]
Dec 10 14:37:13.135: INFO: Created: latency-svc-fgsj5
Dec 10 14:37:13.137: INFO: Got endpoints: latency-svc-fgsj5 [73.378754ms]
Dec 10 14:37:13.145: INFO: Created: latency-svc-zrn9s
Dec 10 14:37:13.150: INFO: Got endpoints: latency-svc-zrn9s [86.500807ms]
Dec 10 14:37:13.153: INFO: Created: latency-svc-h8lc2
Dec 10 14:37:13.156: INFO: Got endpoints: latency-svc-h8lc2 [92.270404ms]
Dec 10 14:37:13.163: INFO: Created: latency-svc-v9h2f
Dec 10 14:37:13.169: INFO: Got endpoints: latency-svc-v9h2f [104.690914ms]
Dec 10 14:37:13.173: INFO: Created: latency-svc-z9jsw
Dec 10 14:37:13.178: INFO: Got endpoints: latency-svc-z9jsw [113.622253ms]
Dec 10 14:37:13.183: INFO: Created: latency-svc-jz8v5
Dec 10 14:37:13.188: INFO: Got endpoints: latency-svc-jz8v5 [123.886883ms]
Dec 10 14:37:13.192: INFO: Created: latency-svc-f6hb6
Dec 10 14:37:13.195: INFO: Got endpoints: latency-svc-f6hb6 [130.507135ms]
Dec 10 14:37:13.201: INFO: Created: latency-svc-gn4bn
Dec 10 14:37:13.203: INFO: Got endpoints: latency-svc-gn4bn [139.389477ms]
Dec 10 14:37:13.214: INFO: Created: latency-svc-4d25p
Dec 10 14:37:13.217: INFO: Got endpoints: latency-svc-4d25p [152.490055ms]
Dec 10 14:37:13.225: INFO: Created: latency-svc-8nhf9
Dec 10 14:37:13.232: INFO: Got endpoints: latency-svc-8nhf9 [150.841676ms]
Dec 10 14:37:13.237: INFO: Created: latency-svc-fc8zh
Dec 10 14:37:13.243: INFO: Got endpoints: latency-svc-fc8zh [150.752638ms]
Dec 10 14:37:13.248: INFO: Created: latency-svc-fbq7t
Dec 10 14:37:13.253: INFO: Got endpoints: latency-svc-fbq7t [154.407036ms]
Dec 10 14:37:13.259: INFO: Created: latency-svc-zr5ww
Dec 10 14:37:13.263: INFO: Got endpoints: latency-svc-zr5ww [153.138786ms]
Dec 10 14:37:13.268: INFO: Created: latency-svc-zxcs6
Dec 10 14:37:13.273: INFO: Got endpoints: latency-svc-zxcs6 [152.961952ms]
Dec 10 14:37:13.281: INFO: Created: latency-svc-qlr6p
Dec 10 14:37:13.282: INFO: Got endpoints: latency-svc-qlr6p [151.517867ms]
Dec 10 14:37:13.291: INFO: Created: latency-svc-4btmr
Dec 10 14:37:13.296: INFO: Got endpoints: latency-svc-4btmr [159.160912ms]
Dec 10 14:37:13.301: INFO: Created: latency-svc-ghcxc
Dec 10 14:37:13.306: INFO: Got endpoints: latency-svc-ghcxc [155.433646ms]
Dec 10 14:37:13.311: INFO: Created: latency-svc-9f7zc
Dec 10 14:37:13.314: INFO: Got endpoints: latency-svc-9f7zc [157.641303ms]
Dec 10 14:37:13.318: INFO: Created: latency-svc-vtz5h
Dec 10 14:37:13.325: INFO: Got endpoints: latency-svc-vtz5h [156.366118ms]
Dec 10 14:37:13.329: INFO: Created: latency-svc-8l4ld
Dec 10 14:37:13.333: INFO: Got endpoints: latency-svc-8l4ld [155.653729ms]
Dec 10 14:37:13.339: INFO: Created: latency-svc-pkvp6
Dec 10 14:37:13.342: INFO: Got endpoints: latency-svc-pkvp6 [154.435987ms]
Dec 10 14:37:13.351: INFO: Created: latency-svc-plp97
Dec 10 14:37:13.354: INFO: Got endpoints: latency-svc-plp97 [159.175695ms]
Dec 10 14:37:13.363: INFO: Created: latency-svc-4tq9d
Dec 10 14:37:13.367: INFO: Got endpoints: latency-svc-4tq9d [162.960171ms]
Dec 10 14:37:13.372: INFO: Created: latency-svc-pcztj
Dec 10 14:37:13.379: INFO: Got endpoints: latency-svc-pcztj [162.226191ms]
Dec 10 14:37:13.383: INFO: Created: latency-svc-5462b
Dec 10 14:37:13.388: INFO: Got endpoints: latency-svc-5462b [20.815783ms]
Dec 10 14:37:13.397: INFO: Created: latency-svc-57gb2
Dec 10 14:37:13.403: INFO: Got endpoints: latency-svc-57gb2 [171.5001ms]
Dec 10 14:37:13.409: INFO: Created: latency-svc-w8sln
Dec 10 14:37:13.411: INFO: Got endpoints: latency-svc-w8sln [167.404647ms]
Dec 10 14:37:13.424: INFO: Created: latency-svc-l8624
Dec 10 14:37:13.429: INFO: Got endpoints: latency-svc-l8624 [175.800223ms]
Dec 10 14:37:13.438: INFO: Created: latency-svc-jkbst
Dec 10 14:37:13.443: INFO: Got endpoints: latency-svc-jkbst [180.20528ms]
Dec 10 14:37:13.446: INFO: Created: latency-svc-pd4w7
Dec 10 14:37:13.453: INFO: Got endpoints: latency-svc-pd4w7 [180.236702ms]
Dec 10 14:37:13.458: INFO: Created: latency-svc-pskzd
Dec 10 14:37:13.463: INFO: Got endpoints: latency-svc-pskzd [180.897716ms]
Dec 10 14:37:13.467: INFO: Created: latency-svc-gj658
Dec 10 14:37:13.477: INFO: Created: latency-svc-n2vhr
Dec 10 14:37:13.486: INFO: Created: latency-svc-tnd98
Dec 10 14:37:13.492: INFO: Created: latency-svc-vhtrw
Dec 10 14:37:13.499: INFO: Created: latency-svc-qz72q
Dec 10 14:37:13.504: INFO: Got endpoints: latency-svc-gj658 [207.319051ms]
Dec 10 14:37:13.507: INFO: Created: latency-svc-hclw5
Dec 10 14:37:13.518: INFO: Created: latency-svc-ldprq
Dec 10 14:37:13.527: INFO: Created: latency-svc-2rj6c
Dec 10 14:37:13.535: INFO: Created: latency-svc-pqbsj
Dec 10 14:37:13.544: INFO: Created: latency-svc-2zrnk
Dec 10 14:37:13.553: INFO: Created: latency-svc-f5k9j
Dec 10 14:37:13.555: INFO: Got endpoints: latency-svc-n2vhr [248.915322ms]
Dec 10 14:37:13.564: INFO: Created: latency-svc-x5bw8
Dec 10 14:37:13.571: INFO: Created: latency-svc-pvrv9
Dec 10 14:37:13.578: INFO: Created: latency-svc-wm4rh
Dec 10 14:37:13.588: INFO: Created: latency-svc-8j5hl
Dec 10 14:37:13.595: INFO: Created: latency-svc-h2c7r
Dec 10 14:37:13.606: INFO: Got endpoints: latency-svc-tnd98 [291.525676ms]
Dec 10 14:37:13.606: INFO: Created: latency-svc-jxcl2
Dec 10 14:37:13.619: INFO: Created: latency-svc-h6gsf
Dec 10 14:37:13.656: INFO: Got endpoints: latency-svc-vhtrw [330.890988ms]
Dec 10 14:37:13.670: INFO: Created: latency-svc-n4bss
Dec 10 14:37:13.708: INFO: Got endpoints: latency-svc-qz72q [374.110484ms]
Dec 10 14:37:13.722: INFO: Created: latency-svc-jx8m8
Dec 10 14:37:13.756: INFO: Got endpoints: latency-svc-hclw5 [413.535066ms]
Dec 10 14:37:13.771: INFO: Created: latency-svc-csrbh
Dec 10 14:37:13.804: INFO: Got endpoints: latency-svc-ldprq [450.181491ms]
Dec 10 14:37:13.819: INFO: Created: latency-svc-znh6d
Dec 10 14:37:13.854: INFO: Got endpoints: latency-svc-2rj6c [475.257908ms]
Dec 10 14:37:13.872: INFO: Created: latency-svc-6k842
Dec 10 14:37:13.905: INFO: Got endpoints: latency-svc-pqbsj [516.805166ms]
Dec 10 14:37:13.918: INFO: Created: latency-svc-8q4xp
Dec 10 14:37:13.954: INFO: Got endpoints: latency-svc-2zrnk [550.983448ms]
Dec 10 14:37:13.967: INFO: Created: latency-svc-xt2gd
Dec 10 14:37:14.006: INFO: Got endpoints: latency-svc-f5k9j [594.588331ms]
Dec 10 14:37:14.019: INFO: Created: latency-svc-vkkxh
Dec 10 14:37:14.054: INFO: Got endpoints: latency-svc-x5bw8 [625.216095ms]
Dec 10 14:37:14.068: INFO: Created: latency-svc-48hjr
Dec 10 14:37:14.105: INFO: Got endpoints: latency-svc-pvrv9 [661.870175ms]
Dec 10 14:37:14.118: INFO: Created: latency-svc-wrfm7
Dec 10 14:37:14.155: INFO: Got endpoints: latency-svc-wm4rh [701.657518ms]
Dec 10 14:37:14.170: INFO: Created: latency-svc-4gtr4
Dec 10 14:37:14.208: INFO: Got endpoints: latency-svc-8j5hl [744.499148ms]
Dec 10 14:37:14.221: INFO: Created: latency-svc-lvppk
Dec 10 14:37:14.255: INFO: Got endpoints: latency-svc-h2c7r [750.492504ms]
Dec 10 14:37:14.268: INFO: Created: latency-svc-826w7
Dec 10 14:37:14.305: INFO: Got endpoints: latency-svc-jxcl2 [749.736112ms]
Dec 10 14:37:14.321: INFO: Created: latency-svc-gvb2p
Dec 10 14:37:14.357: INFO: Got endpoints: latency-svc-h6gsf [751.776542ms]
Dec 10 14:37:14.370: INFO: Created: latency-svc-mqh84
Dec 10 14:37:14.406: INFO: Got endpoints: latency-svc-n4bss [749.699562ms]
Dec 10 14:37:14.421: INFO: Created: latency-svc-b7jnp
Dec 10 14:37:14.455: INFO: Got endpoints: latency-svc-jx8m8 [747.080594ms]
Dec 10 14:37:14.471: INFO: Created: latency-svc-tnwdr
Dec 10 14:37:14.504: INFO: Got endpoints: latency-svc-csrbh [748.13436ms]
Dec 10 14:37:14.520: INFO: Created: latency-svc-2q226
Dec 10 14:37:14.559: INFO: Got endpoints: latency-svc-znh6d [754.563693ms]
Dec 10 14:37:14.575: INFO: Created: latency-svc-5s4mq
Dec 10 14:37:14.605: INFO: Got endpoints: latency-svc-6k842 [749.976006ms]
Dec 10 14:37:14.619: INFO: Created: latency-svc-vksdz
Dec 10 14:37:14.654: INFO: Got endpoints: latency-svc-8q4xp [749.530146ms]
Dec 10 14:37:14.670: INFO: Created: latency-svc-hh9mz
Dec 10 14:37:14.704: INFO: Got endpoints: latency-svc-xt2gd [750.020409ms]
Dec 10 14:37:14.720: INFO: Created: latency-svc-d8r4g
Dec 10 14:37:14.756: INFO: Got endpoints: latency-svc-vkkxh [750.806269ms]
Dec 10 14:37:14.770: INFO: Created: latency-svc-qfwxg
Dec 10 14:37:14.805: INFO: Got endpoints: latency-svc-48hjr [750.391223ms]
Dec 10 14:37:14.818: INFO: Created: latency-svc-kvczk
Dec 10 14:37:14.856: INFO: Got endpoints: latency-svc-wrfm7 [750.169001ms]
Dec 10 14:37:14.869: INFO: Created: latency-svc-5p8lm
Dec 10 14:37:14.905: INFO: Got endpoints: latency-svc-4gtr4 [749.904854ms]
Dec 10 14:37:14.918: INFO: Created: latency-svc-4z9gz
Dec 10 14:37:14.955: INFO: Got endpoints: latency-svc-lvppk [747.005904ms]
Dec 10 14:37:14.969: INFO: Created: latency-svc-sg87j
Dec 10 14:37:15.006: INFO: Got endpoints: latency-svc-826w7 [750.811932ms]
Dec 10 14:37:15.020: INFO: Created: latency-svc-rvgjl
Dec 10 14:37:15.054: INFO: Got endpoints: latency-svc-gvb2p [749.398906ms]
Dec 10 14:37:15.069: INFO: Created: latency-svc-lmvsq
Dec 10 14:37:15.104: INFO: Got endpoints: latency-svc-mqh84 [746.980439ms]
Dec 10 14:37:15.120: INFO: Created: latency-svc-nxxwf
Dec 10 14:37:15.154: INFO: Got endpoints: latency-svc-b7jnp [747.800525ms]
Dec 10 14:37:15.168: INFO: Created: latency-svc-hl85r
Dec 10 14:37:15.206: INFO: Got endpoints: latency-svc-tnwdr [751.202809ms]
Dec 10 14:37:15.221: INFO: Created: latency-svc-ddzkb
Dec 10 14:37:15.255: INFO: Got endpoints: latency-svc-2q226 [749.962697ms]
Dec 10 14:37:15.270: INFO: Created: latency-svc-hhnhw
Dec 10 14:37:15.306: INFO: Got endpoints: latency-svc-5s4mq [746.645482ms]
Dec 10 14:37:15.320: INFO: Created: latency-svc-djcfb
Dec 10 14:37:15.354: INFO: Got endpoints: latency-svc-vksdz [749.368188ms]
Dec 10 14:37:15.368: INFO: Created: latency-svc-tcfwm
Dec 10 14:37:15.405: INFO: Got endpoints: latency-svc-hh9mz [749.957043ms]
Dec 10 14:37:15.419: INFO: Created: latency-svc-9l8xv
Dec 10 14:37:15.457: INFO: Got endpoints: latency-svc-d8r4g [751.954013ms]
Dec 10 14:37:15.472: INFO: Created: latency-svc-fxzqw
Dec 10 14:37:15.507: INFO: Got endpoints: latency-svc-qfwxg [750.39927ms]
Dec 10 14:37:15.520: INFO: Created: latency-svc-kjvvn
Dec 10 14:37:15.556: INFO: Got endpoints: latency-svc-kvczk [750.836996ms]
Dec 10 14:37:15.569: INFO: Created: latency-svc-9htcc
Dec 10 14:37:15.607: INFO: Got endpoints: latency-svc-5p8lm [750.893093ms]
Dec 10 14:37:15.620: INFO: Created: latency-svc-kvkxp
Dec 10 14:37:15.654: INFO: Got endpoints: latency-svc-4z9gz [749.117668ms]
Dec 10 14:37:15.671: INFO: Created: latency-svc-p5rjg
Dec 10 14:37:15.705: INFO: Got endpoints: latency-svc-sg87j [750.190827ms]
Dec 10 14:37:15.718: INFO: Created: latency-svc-b4pgr
Dec 10 14:37:15.755: INFO: Got endpoints: latency-svc-rvgjl [748.832998ms]
Dec 10 14:37:15.769: INFO: Created: latency-svc-5wdwm
Dec 10 14:37:15.805: INFO: Got endpoints: latency-svc-lmvsq [750.258085ms]
Dec 10 14:37:15.818: INFO: Created: latency-svc-d57gh
Dec 10 14:37:15.855: INFO: Got endpoints: latency-svc-nxxwf [750.044383ms]
Dec 10 14:37:15.869: INFO: Created: latency-svc-7xkfz
Dec 10 14:37:15.907: INFO: Got endpoints: latency-svc-hl85r [752.709969ms]
Dec 10 14:37:15.920: INFO: Created: latency-svc-n7cx2
Dec 10 14:37:15.956: INFO: Got endpoints: latency-svc-ddzkb [749.169385ms]
Dec 10 14:37:15.971: INFO: Created: latency-svc-wkq8h
Dec 10 14:37:16.004: INFO: Got endpoints: latency-svc-hhnhw [749.55707ms]
Dec 10 14:37:16.019: INFO: Created: latency-svc-spwx6
Dec 10 14:37:16.055: INFO: Got endpoints: latency-svc-djcfb [748.16613ms]
Dec 10 14:37:16.070: INFO: Created: latency-svc-2kvr2
Dec 10 14:37:16.105: INFO: Got endpoints: latency-svc-tcfwm [750.062148ms]
Dec 10 14:37:16.122: INFO: Created: latency-svc-cmzdd
Dec 10 14:37:16.154: INFO: Got endpoints: latency-svc-9l8xv [749.528649ms]
Dec 10 14:37:16.169: INFO: Created: latency-svc-p2n25
Dec 10 14:37:16.204: INFO: Got endpoints: latency-svc-fxzqw [747.25736ms]
Dec 10 14:37:16.221: INFO: Created: latency-svc-2k7lv
Dec 10 14:37:16.254: INFO: Got endpoints: latency-svc-kjvvn [747.221359ms]
Dec 10 14:37:16.268: INFO: Created: latency-svc-bgcpj
Dec 10 14:37:16.314: INFO: Got endpoints: latency-svc-9htcc [757.628996ms]
Dec 10 14:37:16.327: INFO: Created: latency-svc-nglkm
Dec 10 14:37:16.355: INFO: Got endpoints: latency-svc-kvkxp [748.066862ms]
Dec 10 14:37:16.371: INFO: Created: latency-svc-htxt4
Dec 10 14:37:16.406: INFO: Got endpoints: latency-svc-p5rjg [751.837112ms]
Dec 10 14:37:16.420: INFO: Created: latency-svc-kp9ld
Dec 10 14:37:16.455: INFO: Got endpoints: latency-svc-b4pgr [749.264268ms]
Dec 10 14:37:16.470: INFO: Created: latency-svc-2p4k9
Dec 10 14:37:16.505: INFO: Got endpoints: latency-svc-5wdwm [749.947451ms]
Dec 10 14:37:16.517: INFO: Created: latency-svc-m7hdt
Dec 10 14:37:16.554: INFO: Got endpoints: latency-svc-d57gh [749.288527ms]
Dec 10 14:37:16.569: INFO: Created: latency-svc-4r786
Dec 10 14:37:16.604: INFO: Got endpoints: latency-svc-7xkfz [749.707922ms]
Dec 10 14:37:16.618: INFO: Created: latency-svc-q75d8
Dec 10 14:37:16.656: INFO: Got endpoints: latency-svc-n7cx2 [748.120065ms]
Dec 10 14:37:16.668: INFO: Created: latency-svc-bc2bp
Dec 10 14:37:16.705: INFO: Got endpoints: latency-svc-wkq8h [748.604869ms]
Dec 10 14:37:16.718: INFO: Created: latency-svc-czpvl
Dec 10 14:37:16.756: INFO: Got endpoints: latency-svc-spwx6 [751.180149ms]
Dec 10 14:37:16.770: INFO: Created: latency-svc-fd7sv
Dec 10 14:37:16.807: INFO: Got endpoints: latency-svc-2kvr2 [751.064346ms]
Dec 10 14:37:16.821: INFO: Created: latency-svc-7wvp2
Dec 10 14:37:16.854: INFO: Got endpoints: latency-svc-cmzdd [748.933446ms]
Dec 10 14:37:16.867: INFO: Created: latency-svc-w6vmk
Dec 10 14:37:16.905: INFO: Got endpoints: latency-svc-p2n25 [749.780887ms]
Dec 10 14:37:16.919: INFO: Created: latency-svc-7lxtf
Dec 10 14:37:16.956: INFO: Got endpoints: latency-svc-2k7lv [751.69701ms]
Dec 10 14:37:16.972: INFO: Created: latency-svc-smdm7
Dec 10 14:37:17.004: INFO: Got endpoints: latency-svc-bgcpj [749.338521ms]
Dec 10 14:37:17.017: INFO: Created: latency-svc-dtk4q
Dec 10 14:37:17.056: INFO: Got endpoints: latency-svc-nglkm [742.084248ms]
Dec 10 14:37:17.069: INFO: Created: latency-svc-wwcfs
Dec 10 14:37:17.105: INFO: Got endpoints: latency-svc-htxt4 [750.051664ms]
Dec 10 14:37:17.117: INFO: Created: latency-svc-vwr2d
Dec 10 14:37:17.154: INFO: Got endpoints: latency-svc-kp9ld [747.690286ms]
Dec 10 14:37:17.167: INFO: Created: latency-svc-nsd5z
Dec 10 14:37:17.206: INFO: Got endpoints: latency-svc-2p4k9 [750.376473ms]
Dec 10 14:37:17.219: INFO: Created: latency-svc-qjv84
Dec 10 14:37:17.255: INFO: Got endpoints: latency-svc-m7hdt [750.726606ms]
Dec 10 14:37:17.268: INFO: Created: latency-svc-xh66s
Dec 10 14:37:17.305: INFO: Got endpoints: latency-svc-4r786 [750.40935ms]
Dec 10 14:37:17.320: INFO: Created: latency-svc-h4r9w
Dec 10 14:37:17.357: INFO: Got endpoints: latency-svc-q75d8 [753.03165ms]
Dec 10 14:37:17.369: INFO: Created: latency-svc-9sctr
Dec 10 14:37:17.408: INFO: Got endpoints: latency-svc-bc2bp [752.62701ms]
Dec 10 14:37:17.424: INFO: Created: latency-svc-5r96z
Dec 10 14:37:17.456: INFO: Got endpoints: latency-svc-czpvl [751.518353ms]
Dec 10 14:37:17.470: INFO: Created: latency-svc-7lrkt
Dec 10 14:37:17.506: INFO: Got endpoints: latency-svc-fd7sv [750.07364ms]
Dec 10 14:37:17.521: INFO: Created: latency-svc-8g7ns
Dec 10 14:37:17.556: INFO: Got endpoints: latency-svc-7wvp2 [749.019815ms]
Dec 10 14:37:17.570: INFO: Created: latency-svc-wr7d7
Dec 10 14:37:17.605: INFO: Got endpoints: latency-svc-w6vmk [750.473203ms]
Dec 10 14:37:17.622: INFO: Created: latency-svc-j725s
Dec 10 14:37:17.654: INFO: Got endpoints: latency-svc-7lxtf [749.214311ms]
Dec 10 14:37:17.668: INFO: Created: latency-svc-42flt
Dec 10 14:37:17.705: INFO: Got endpoints: latency-svc-smdm7 [749.177956ms]
Dec 10 14:37:17.718: INFO: Created: latency-svc-vw2k2
Dec 10 14:37:17.756: INFO: Got endpoints: latency-svc-dtk4q [752.117934ms]
Dec 10 14:37:17.769: INFO: Created: latency-svc-xmhd9
Dec 10 14:37:17.804: INFO: Got endpoints: latency-svc-wwcfs [748.319535ms]
Dec 10 14:37:17.822: INFO: Created: latency-svc-q5drf
Dec 10 14:37:17.857: INFO: Got endpoints: latency-svc-vwr2d [751.437864ms]
Dec 10 14:37:17.871: INFO: Created: latency-svc-njgvw
Dec 10 14:37:17.905: INFO: Got endpoints: latency-svc-nsd5z [750.451055ms]
Dec 10 14:37:17.921: INFO: Created: latency-svc-b7nnk
Dec 10 14:37:17.958: INFO: Got endpoints: latency-svc-qjv84 [752.100438ms]
Dec 10 14:37:17.973: INFO: Created: latency-svc-2pc8z
Dec 10 14:37:18.004: INFO: Got endpoints: latency-svc-xh66s [748.67729ms]
Dec 10 14:37:18.019: INFO: Created: latency-svc-xjcxh
Dec 10 14:37:18.055: INFO: Got endpoints: latency-svc-h4r9w [750.070813ms]
Dec 10 14:37:18.068: INFO: Created: latency-svc-kw2vq
Dec 10 14:37:18.106: INFO: Got endpoints: latency-svc-9sctr [748.883771ms]
Dec 10 14:37:18.119: INFO: Created: latency-svc-62r7s
Dec 10 14:37:18.155: INFO: Got endpoints: latency-svc-5r96z [746.390745ms]
Dec 10 14:37:18.167: INFO: Created: latency-svc-ccmqh
Dec 10 14:37:18.206: INFO: Got endpoints: latency-svc-7lrkt [749.626861ms]
Dec 10 14:37:18.219: INFO: Created: latency-svc-6645c
Dec 10 14:37:18.255: INFO: Got endpoints: latency-svc-8g7ns [749.09563ms]
Dec 10 14:37:18.269: INFO: Created: latency-svc-rkczv
Dec 10 14:37:18.305: INFO: Got endpoints: latency-svc-wr7d7 [749.139431ms]
Dec 10 14:37:18.324: INFO: Created: latency-svc-mpq57
Dec 10 14:37:18.355: INFO: Got endpoints: latency-svc-j725s [749.786027ms]
Dec 10 14:37:18.370: INFO: Created: latency-svc-mhk4b
Dec 10 14:37:18.406: INFO: Got endpoints: latency-svc-42flt [751.514711ms]
Dec 10 14:37:18.419: INFO: Created: latency-svc-8kxc8
Dec 10 14:37:18.454: INFO: Got endpoints: latency-svc-vw2k2 [748.654488ms]
Dec 10 14:37:18.467: INFO: Created: latency-svc-txs8p
Dec 10 14:37:18.505: INFO: Got endpoints: latency-svc-xmhd9 [748.659056ms]
Dec 10 14:37:18.522: INFO: Created: latency-svc-6t8z4
Dec 10 14:37:18.557: INFO: Got endpoints: latency-svc-q5drf [752.566703ms]
Dec 10 14:37:18.570: INFO: Created: latency-svc-zd6h4
Dec 10 14:37:18.605: INFO: Got endpoints: latency-svc-njgvw [748.439123ms]
Dec 10 14:37:18.622: INFO: Created: latency-svc-nmqfk
Dec 10 14:37:18.655: INFO: Got endpoints: latency-svc-b7nnk [749.647986ms]
Dec 10 14:37:18.670: INFO: Created: latency-svc-nv7fw
Dec 10 14:37:18.705: INFO: Got endpoints: latency-svc-2pc8z [747.223716ms]
Dec 10 14:37:18.719: INFO: Created: latency-svc-7hn8v
Dec 10 14:37:18.756: INFO: Got endpoints: latency-svc-xjcxh [751.177002ms]
Dec 10 14:37:18.774: INFO: Created: latency-svc-vtb5f
Dec 10 14:37:18.807: INFO: Got endpoints: latency-svc-kw2vq [751.642177ms]
Dec 10 14:37:18.822: INFO: Created: latency-svc-fvmbs
Dec 10 14:37:18.855: INFO: Got endpoints: latency-svc-62r7s [748.353644ms]
Dec 10 14:37:18.870: INFO: Created: latency-svc-f28zz
Dec 10 14:37:18.906: INFO: Got endpoints: latency-svc-ccmqh [751.276511ms]
Dec 10 14:37:18.919: INFO: Created: latency-svc-rdqhf
Dec 10 14:37:18.954: INFO: Got endpoints: latency-svc-6645c [748.267474ms]
Dec 10 14:37:18.969: INFO: Created: latency-svc-nmzpc
Dec 10 14:37:19.008: INFO: Got endpoints: latency-svc-rkczv [753.037953ms]
Dec 10 14:37:19.023: INFO: Created: latency-svc-9qhmf
Dec 10 14:37:19.056: INFO: Got endpoints: latency-svc-mpq57 [750.680532ms]
Dec 10 14:37:19.072: INFO: Created: latency-svc-8f6tq
Dec 10 14:37:19.106: INFO: Got endpoints: latency-svc-mhk4b [751.333852ms]
Dec 10 14:37:19.119: INFO: Created: latency-svc-4dsj7
Dec 10 14:37:19.160: INFO: Got endpoints: latency-svc-8kxc8 [753.753436ms]
Dec 10 14:37:19.173: INFO: Created: latency-svc-lg8hn
Dec 10 14:37:19.205: INFO: Got endpoints: latency-svc-txs8p [750.981545ms]
Dec 10 14:37:19.222: INFO: Created: latency-svc-nn557
Dec 10 14:37:19.255: INFO: Got endpoints: latency-svc-6t8z4 [749.360495ms]
Dec 10 14:37:19.270: INFO: Created: latency-svc-zkzxp
Dec 10 14:37:19.306: INFO: Got endpoints: latency-svc-zd6h4 [748.389612ms]
Dec 10 14:37:19.319: INFO: Created: latency-svc-8vp9m
Dec 10 14:37:19.354: INFO: Got endpoints: latency-svc-nmqfk [749.018884ms]
Dec 10 14:37:19.372: INFO: Created: latency-svc-qsnl4
Dec 10 14:37:19.404: INFO: Got endpoints: latency-svc-nv7fw [749.366364ms]
Dec 10 14:37:19.419: INFO: Created: latency-svc-5cknm
Dec 10 14:37:19.455: INFO: Got endpoints: latency-svc-7hn8v [749.168854ms]
Dec 10 14:37:19.471: INFO: Created: latency-svc-7z8xp
Dec 10 14:37:19.505: INFO: Got endpoints: latency-svc-vtb5f [749.660644ms]
Dec 10 14:37:19.519: INFO: Created: latency-svc-wxz9k
Dec 10 14:37:19.555: INFO: Got endpoints: latency-svc-fvmbs [748.329259ms]
Dec 10 14:37:19.570: INFO: Created: latency-svc-sttzv
Dec 10 14:37:19.606: INFO: Got endpoints: latency-svc-f28zz [750.812276ms]
Dec 10 14:37:19.622: INFO: Created: latency-svc-kh4cj
Dec 10 14:37:19.655: INFO: Got endpoints: latency-svc-rdqhf [748.883932ms]
Dec 10 14:37:19.668: INFO: Created: latency-svc-g5pmt
Dec 10 14:37:19.706: INFO: Got endpoints: latency-svc-nmzpc [751.497352ms]
Dec 10 14:37:19.720: INFO: Created: latency-svc-hwfn8
Dec 10 14:37:19.755: INFO: Got endpoints: latency-svc-9qhmf [746.609978ms]
Dec 10 14:37:19.769: INFO: Created: latency-svc-hqn6l
Dec 10 14:37:19.805: INFO: Got endpoints: latency-svc-8f6tq [748.581633ms]
Dec 10 14:37:19.819: INFO: Created: latency-svc-jzp5m
Dec 10 14:37:19.855: INFO: Got endpoints: latency-svc-4dsj7 [749.077925ms]
Dec 10 14:37:19.870: INFO: Created: latency-svc-cb767
Dec 10 14:37:19.906: INFO: Got endpoints: latency-svc-lg8hn [745.747428ms]
Dec 10 14:37:19.919: INFO: Created: latency-svc-qmcpn
Dec 10 14:37:19.956: INFO: Got endpoints: latency-svc-nn557 [750.260413ms]
Dec 10 14:37:19.970: INFO: Created: latency-svc-8b94x
Dec 10 14:37:20.004: INFO: Got endpoints: latency-svc-zkzxp [749.596414ms]
Dec 10 14:37:20.017: INFO: Created: latency-svc-mjfp8
Dec 10 14:37:20.056: INFO: Got endpoints: latency-svc-8vp9m [749.904983ms]
Dec 10 14:37:20.069: INFO: Created: latency-svc-ksr7m
Dec 10 14:37:20.104: INFO: Got endpoints: latency-svc-qsnl4 [749.4519ms]
Dec 10 14:37:20.116: INFO: Created: latency-svc-spnp6
Dec 10 14:37:20.156: INFO: Got endpoints: latency-svc-5cknm [751.097995ms]
Dec 10 14:37:20.169: INFO: Created: latency-svc-drmnt
Dec 10 14:37:20.204: INFO: Got endpoints: latency-svc-7z8xp [749.830476ms]
Dec 10 14:37:20.218: INFO: Created: latency-svc-424v6
Dec 10 14:37:20.259: INFO: Got endpoints: latency-svc-wxz9k [753.408937ms]
Dec 10 14:37:20.276: INFO: Created: latency-svc-rz657
Dec 10 14:37:20.306: INFO: Got endpoints: latency-svc-sttzv [751.158338ms]
Dec 10 14:37:20.319: INFO: Created: latency-svc-2r2kk
Dec 10 14:37:20.354: INFO: Got endpoints: latency-svc-kh4cj [748.403433ms]
Dec 10 14:37:20.369: INFO: Created: latency-svc-stxgz
Dec 10 14:37:20.406: INFO: Got endpoints: latency-svc-g5pmt [751.236383ms]
Dec 10 14:37:20.420: INFO: Created: latency-svc-4sxgl
Dec 10 14:37:20.456: INFO: Got endpoints: latency-svc-hwfn8 [749.514011ms]
Dec 10 14:37:20.469: INFO: Created: latency-svc-9xmqv
Dec 10 14:37:20.505: INFO: Got endpoints: latency-svc-hqn6l [749.559076ms]
Dec 10 14:37:20.519: INFO: Created: latency-svc-jjm9c
Dec 10 14:37:20.555: INFO: Got endpoints: latency-svc-jzp5m [750.233876ms]
Dec 10 14:37:20.568: INFO: Created: latency-svc-ncn5r
Dec 10 14:37:20.606: INFO: Got endpoints: latency-svc-cb767 [750.113099ms]
Dec 10 14:37:20.619: INFO: Created: latency-svc-nmjvr
Dec 10 14:37:20.659: INFO: Got endpoints: latency-svc-qmcpn [753.465482ms]
Dec 10 14:37:20.673: INFO: Created: latency-svc-gxtx4
Dec 10 14:37:20.705: INFO: Got endpoints: latency-svc-8b94x [749.187794ms]
Dec 10 14:37:20.718: INFO: Created: latency-svc-82h4f
Dec 10 14:37:20.755: INFO: Got endpoints: latency-svc-mjfp8 [750.12796ms]
Dec 10 14:37:20.767: INFO: Created: latency-svc-4n879
Dec 10 14:37:20.806: INFO: Got endpoints: latency-svc-ksr7m [749.934453ms]
Dec 10 14:37:20.817: INFO: Created: latency-svc-vs2bd
Dec 10 14:37:20.856: INFO: Got endpoints: latency-svc-spnp6 [752.309415ms]
Dec 10 14:37:20.871: INFO: Created: latency-svc-crjnx
Dec 10 14:37:20.908: INFO: Got endpoints: latency-svc-drmnt [752.22901ms]
Dec 10 14:37:20.955: INFO: Got endpoints: latency-svc-424v6 [750.157616ms]
Dec 10 14:37:21.015: INFO: Got endpoints: latency-svc-rz657 [755.532234ms]
Dec 10 14:37:21.054: INFO: Got endpoints: latency-svc-2r2kk [748.141092ms]
Dec 10 14:37:21.106: INFO: Got endpoints: latency-svc-stxgz [751.28453ms]
Dec 10 14:37:21.155: INFO: Got endpoints: latency-svc-4sxgl [748.080661ms]
Dec 10 14:37:21.205: INFO: Got endpoints: latency-svc-9xmqv [748.950496ms]
Dec 10 14:37:21.257: INFO: Got endpoints: latency-svc-jjm9c [752.183121ms]
Dec 10 14:37:21.304: INFO: Got endpoints: latency-svc-ncn5r [748.911087ms]
Dec 10 14:37:21.356: INFO: Got endpoints: latency-svc-nmjvr [750.126081ms]
Dec 10 14:37:21.409: INFO: Got endpoints: latency-svc-gxtx4 [749.036399ms]
Dec 10 14:37:21.456: INFO: Got endpoints: latency-svc-82h4f [751.226567ms]
Dec 10 14:37:21.506: INFO: Got endpoints: latency-svc-4n879 [751.315888ms]
Dec 10 14:37:21.555: INFO: Got endpoints: latency-svc-vs2bd [749.26368ms]
Dec 10 14:37:21.606: INFO: Got endpoints: latency-svc-crjnx [749.090354ms]
Dec 10 14:37:21.606: INFO: Latencies: [17.820649ms 20.815783ms 28.765409ms 34.940992ms 46.086929ms 56.350539ms 66.759128ms 73.378754ms 86.500807ms 92.270404ms 104.690914ms 113.622253ms 123.886883ms 130.507135ms 139.389477ms 150.752638ms 150.841676ms 151.517867ms 152.490055ms 152.961952ms 153.138786ms 154.407036ms 154.435987ms 155.433646ms 155.653729ms 156.366118ms 157.641303ms 159.160912ms 159.175695ms 162.226191ms 162.960171ms 167.404647ms 171.5001ms 175.800223ms 180.20528ms 180.236702ms 180.897716ms 207.319051ms 248.915322ms 291.525676ms 330.890988ms 374.110484ms 413.535066ms 450.181491ms 475.257908ms 516.805166ms 550.983448ms 594.588331ms 625.216095ms 661.870175ms 701.657518ms 742.084248ms 744.499148ms 745.747428ms 746.390745ms 746.609978ms 746.645482ms 746.980439ms 747.005904ms 747.080594ms 747.221359ms 747.223716ms 747.25736ms 747.690286ms 747.800525ms 748.066862ms 748.080661ms 748.120065ms 748.13436ms 748.141092ms 748.16613ms 748.267474ms 748.319535ms 748.329259ms 748.353644ms 748.389612ms 748.403433ms 748.439123ms 748.581633ms 748.604869ms 748.654488ms 748.659056ms 748.67729ms 748.832998ms 748.883771ms 748.883932ms 748.911087ms 748.933446ms 748.950496ms 749.018884ms 749.019815ms 749.036399ms 749.077925ms 749.090354ms 749.09563ms 749.117668ms 749.139431ms 749.168854ms 749.169385ms 749.177956ms 749.187794ms 749.214311ms 749.26368ms 749.264268ms 749.288527ms 749.338521ms 749.360495ms 749.366364ms 749.368188ms 749.398906ms 749.4519ms 749.514011ms 749.528649ms 749.530146ms 749.55707ms 749.559076ms 749.596414ms 749.626861ms 749.647986ms 749.660644ms 749.699562ms 749.707922ms 749.736112ms 749.780887ms 749.786027ms 749.830476ms 749.904854ms 749.904983ms 749.934453ms 749.947451ms 749.957043ms 749.962697ms 749.976006ms 750.020409ms 750.044383ms 750.051664ms 750.062148ms 750.070813ms 750.07364ms 750.113099ms 750.126081ms 750.12796ms 750.157616ms 750.169001ms 750.190827ms 750.233876ms 750.258085ms 750.260413ms 750.376473ms 750.391223ms 750.39927ms 750.40935ms 750.451055ms 750.473203ms 750.492504ms 750.680532ms 750.726606ms 750.806269ms 750.811932ms 750.812276ms 750.836996ms 750.893093ms 750.981545ms 751.064346ms 751.097995ms 751.158338ms 751.177002ms 751.180149ms 751.202809ms 751.226567ms 751.236383ms 751.276511ms 751.28453ms 751.315888ms 751.333852ms 751.437864ms 751.497352ms 751.514711ms 751.518353ms 751.642177ms 751.69701ms 751.776542ms 751.837112ms 751.954013ms 752.100438ms 752.117934ms 752.183121ms 752.22901ms 752.309415ms 752.566703ms 752.62701ms 752.709969ms 753.03165ms 753.037953ms 753.408937ms 753.465482ms 753.753436ms 754.563693ms 755.532234ms 757.628996ms]
Dec 10 14:37:21.606: INFO: 50 %ile: 749.187794ms
Dec 10 14:37:21.606: INFO: 90 %ile: 751.69701ms
Dec 10 14:37:21.606: INFO: 99 %ile: 755.532234ms
Dec 10 14:37:21.607: INFO: Total sample count: 200
[AfterEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 10 14:37:21.607: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-svc-latency-jzsgk" for this suite.
Dec 10 14:37:39.632: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 14:37:39.710: INFO: namespace: e2e-tests-svc-latency-jzsgk, resource: bindings, ignored listing per whitelist
Dec 10 14:37:39.748: INFO: namespace e2e-tests-svc-latency-jzsgk deletion completed in 18.136628816s

• [SLOW TEST:28.937 seconds]
[sig-network] Service endpoints latency
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should not be very high  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-api-machinery] Watchers 
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 10 14:37:39.748: INFO: >>> kubeConfig: /tmp/kubeconfig-578738756
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a watch on configmaps with a certain label
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: changing the label value of the configmap
STEP: Expecting to observe a delete notification for the watched object
Dec 10 14:37:39.851: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-tc9fw,SelfLink:/api/v1/namespaces/e2e-tests-watch-tc9fw/configmaps/e2e-watch-test-label-changed,UID:251ed320-fc89-11e8-8690-fa163e74bd5a,ResourceVersion:17752,Generation:0,CreationTimestamp:2018-12-10 14:37:39 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Dec 10 14:37:39.851: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-tc9fw,SelfLink:/api/v1/namespaces/e2e-tests-watch-tc9fw/configmaps/e2e-watch-test-label-changed,UID:251ed320-fc89-11e8-8690-fa163e74bd5a,ResourceVersion:17753,Generation:0,CreationTimestamp:2018-12-10 14:37:39 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Dec 10 14:37:39.852: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-tc9fw,SelfLink:/api/v1/namespaces/e2e-tests-watch-tc9fw/configmaps/e2e-watch-test-label-changed,UID:251ed320-fc89-11e8-8690-fa163e74bd5a,ResourceVersion:17754,Generation:0,CreationTimestamp:2018-12-10 14:37:39 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time
STEP: Expecting not to observe a notification because the object no longer meets the selector's requirements
STEP: changing the label value of the configmap back
STEP: modifying the configmap a third time
STEP: deleting the configmap
STEP: Expecting to observe an add notification for the watched object when the label value was restored
Dec 10 14:37:49.889: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-tc9fw,SelfLink:/api/v1/namespaces/e2e-tests-watch-tc9fw/configmaps/e2e-watch-test-label-changed,UID:251ed320-fc89-11e8-8690-fa163e74bd5a,ResourceVersion:17775,Generation:0,CreationTimestamp:2018-12-10 14:37:39 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Dec 10 14:37:49.889: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-tc9fw,SelfLink:/api/v1/namespaces/e2e-tests-watch-tc9fw/configmaps/e2e-watch-test-label-changed,UID:251ed320-fc89-11e8-8690-fa163e74bd5a,ResourceVersion:17776,Generation:0,CreationTimestamp:2018-12-10 14:37:39 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
Dec 10 14:37:49.889: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-tc9fw,SelfLink:/api/v1/namespaces/e2e-tests-watch-tc9fw/configmaps/e2e-watch-test-label-changed,UID:251ed320-fc89-11e8-8690-fa163e74bd5a,ResourceVersion:17777,Generation:0,CreationTimestamp:2018-12-10 14:37:39 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 10 14:37:49.889: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-tc9fw" for this suite.
Dec 10 14:37:55.908: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 14:37:55.921: INFO: namespace: e2e-tests-watch-tc9fw, resource: bindings, ignored listing per whitelist
Dec 10 14:37:56.016: INFO: namespace e2e-tests-watch-tc9fw deletion completed in 6.122300139s

• [SLOW TEST:16.267 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[k8s.io] Pods 
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 10 14:37:56.017: INFO: >>> kubeConfig: /tmp/kubeconfig-578738756
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Dec 10 14:37:58.628: INFO: Successfully updated pod "pod-update-2ecfaad7-fc89-11e8-a36b-7e9ed3de7210"
STEP: verifying the updated pod is in kubernetes
Dec 10 14:37:58.634: INFO: Pod update OK
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 10 14:37:58.634: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-lkj88" for this suite.
Dec 10 14:38:20.652: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 14:38:20.724: INFO: namespace: e2e-tests-pods-lkj88, resource: bindings, ignored listing per whitelist
Dec 10 14:38:20.759: INFO: namespace e2e-tests-pods-lkj88 deletion completed in 22.120444962s

• [SLOW TEST:24.742 seconds]
[k8s.io] Pods
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 10 14:38:20.759: INFO: >>> kubeConfig: /tmp/kubeconfig-578738756
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test override command
Dec 10 14:38:20.833: INFO: Waiting up to 5m0s for pod "client-containers-3d8de6c8-fc89-11e8-a36b-7e9ed3de7210" in namespace "e2e-tests-containers-fs7md" to be "success or failure"
Dec 10 14:38:20.838: INFO: Pod "client-containers-3d8de6c8-fc89-11e8-a36b-7e9ed3de7210": Phase="Pending", Reason="", readiness=false. Elapsed: 4.954645ms
Dec 10 14:38:22.848: INFO: Pod "client-containers-3d8de6c8-fc89-11e8-a36b-7e9ed3de7210": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.01522593s
STEP: Saw pod success
Dec 10 14:38:22.848: INFO: Pod "client-containers-3d8de6c8-fc89-11e8-a36b-7e9ed3de7210" satisfied condition "success or failure"
Dec 10 14:38:22.852: INFO: Trying to get logs from node conformance-cluster1-k8s-node-2 pod client-containers-3d8de6c8-fc89-11e8-a36b-7e9ed3de7210 container test-container: <nil>
STEP: delete the pod
Dec 10 14:38:22.875: INFO: Waiting for pod client-containers-3d8de6c8-fc89-11e8-a36b-7e9ed3de7210 to disappear
Dec 10 14:38:22.878: INFO: Pod client-containers-3d8de6c8-fc89-11e8-a36b-7e9ed3de7210 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 10 14:38:22.878: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-fs7md" for this suite.
Dec 10 14:38:28.896: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 14:38:28.948: INFO: namespace: e2e-tests-containers-fs7md, resource: bindings, ignored listing per whitelist
Dec 10 14:38:29.009: INFO: namespace e2e-tests-containers-fs7md deletion completed in 6.12731437s

• [SLOW TEST:8.250 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 10 14:38:29.010: INFO: >>> kubeConfig: /tmp/kubeconfig-578738756
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0644 on tmpfs
Dec 10 14:38:29.090: INFO: Waiting up to 5m0s for pod "pod-4279477d-fc89-11e8-a36b-7e9ed3de7210" in namespace "e2e-tests-emptydir-26jkm" to be "success or failure"
Dec 10 14:38:29.096: INFO: Pod "pod-4279477d-fc89-11e8-a36b-7e9ed3de7210": Phase="Pending", Reason="", readiness=false. Elapsed: 5.443376ms
Dec 10 14:38:31.100: INFO: Pod "pod-4279477d-fc89-11e8-a36b-7e9ed3de7210": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009779762s
STEP: Saw pod success
Dec 10 14:38:31.100: INFO: Pod "pod-4279477d-fc89-11e8-a36b-7e9ed3de7210" satisfied condition "success or failure"
Dec 10 14:38:31.104: INFO: Trying to get logs from node conformance-cluster1-k8s-node-2 pod pod-4279477d-fc89-11e8-a36b-7e9ed3de7210 container test-container: <nil>
STEP: delete the pod
Dec 10 14:38:31.129: INFO: Waiting for pod pod-4279477d-fc89-11e8-a36b-7e9ed3de7210 to disappear
Dec 10 14:38:31.132: INFO: Pod pod-4279477d-fc89-11e8-a36b-7e9ed3de7210 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 10 14:38:31.132: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-26jkm" for this suite.
Dec 10 14:38:37.153: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 14:38:37.225: INFO: namespace: e2e-tests-emptydir-26jkm, resource: bindings, ignored listing per whitelist
Dec 10 14:38:37.262: INFO: namespace e2e-tests-emptydir-26jkm deletion completed in 6.125649193s

• [SLOW TEST:8.252 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[k8s.io] Pods 
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 10 14:38:37.263: INFO: >>> kubeConfig: /tmp/kubeconfig-578738756
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Dec 10 14:38:39.871: INFO: Successfully updated pod "pod-update-activedeadlineseconds-4764b564-fc89-11e8-a36b-7e9ed3de7210"
Dec 10 14:38:39.871: INFO: Waiting up to 5m0s for pod "pod-update-activedeadlineseconds-4764b564-fc89-11e8-a36b-7e9ed3de7210" in namespace "e2e-tests-pods-smbll" to be "terminated due to deadline exceeded"
Dec 10 14:38:39.875: INFO: Pod "pod-update-activedeadlineseconds-4764b564-fc89-11e8-a36b-7e9ed3de7210": Phase="Running", Reason="", readiness=true. Elapsed: 3.449797ms
Dec 10 14:38:41.879: INFO: Pod "pod-update-activedeadlineseconds-4764b564-fc89-11e8-a36b-7e9ed3de7210": Phase="Running", Reason="", readiness=true. Elapsed: 2.007506055s
Dec 10 14:38:43.888: INFO: Pod "pod-update-activedeadlineseconds-4764b564-fc89-11e8-a36b-7e9ed3de7210": Phase="Failed", Reason="DeadlineExceeded", readiness=false. Elapsed: 4.016922594s
Dec 10 14:38:43.888: INFO: Pod "pod-update-activedeadlineseconds-4764b564-fc89-11e8-a36b-7e9ed3de7210" satisfied condition "terminated due to deadline exceeded"
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 10 14:38:43.888: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-smbll" for this suite.
Dec 10 14:38:49.909: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 14:38:49.937: INFO: namespace: e2e-tests-pods-smbll, resource: bindings, ignored listing per whitelist
Dec 10 14:38:50.018: INFO: namespace e2e-tests-pods-smbll deletion completed in 6.125100327s

• [SLOW TEST:12.755 seconds]
[k8s.io] Pods
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Projected 
  should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 10 14:38:50.018: INFO: >>> kubeConfig: /tmp/kubeconfig-578738756
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Dec 10 14:38:50.103: INFO: Waiting up to 5m0s for pod "downwardapi-volume-4efff43b-fc89-11e8-a36b-7e9ed3de7210" in namespace "e2e-tests-projected-j5zdq" to be "success or failure"
Dec 10 14:38:50.108: INFO: Pod "downwardapi-volume-4efff43b-fc89-11e8-a36b-7e9ed3de7210": Phase="Pending", Reason="", readiness=false. Elapsed: 4.250207ms
Dec 10 14:38:52.113: INFO: Pod "downwardapi-volume-4efff43b-fc89-11e8-a36b-7e9ed3de7210": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009117661s
STEP: Saw pod success
Dec 10 14:38:52.113: INFO: Pod "downwardapi-volume-4efff43b-fc89-11e8-a36b-7e9ed3de7210" satisfied condition "success or failure"
Dec 10 14:38:52.117: INFO: Trying to get logs from node conformance-cluster1-k8s-node-2 pod downwardapi-volume-4efff43b-fc89-11e8-a36b-7e9ed3de7210 container client-container: <nil>
STEP: delete the pod
Dec 10 14:38:52.142: INFO: Waiting for pod downwardapi-volume-4efff43b-fc89-11e8-a36b-7e9ed3de7210 to disappear
Dec 10 14:38:52.145: INFO: Pod downwardapi-volume-4efff43b-fc89-11e8-a36b-7e9ed3de7210 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 10 14:38:52.145: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-j5zdq" for this suite.
Dec 10 14:38:58.163: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 14:38:58.172: INFO: namespace: e2e-tests-projected-j5zdq, resource: bindings, ignored listing per whitelist
Dec 10 14:38:58.281: INFO: namespace e2e-tests-projected-j5zdq deletion completed in 6.131664866s

• [SLOW TEST:8.263 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] version v1
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 10 14:38:58.281: INFO: >>> kubeConfig: /tmp/kubeconfig-578738756
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Dec 10 14:38:58.351: INFO: (0) /api/v1/nodes/conformance-cluster1-k8s-node-1/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 3.916789ms)
Dec 10 14:38:58.355: INFO: (1) /api/v1/nodes/conformance-cluster1-k8s-node-1/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 4.047433ms)
Dec 10 14:38:58.359: INFO: (2) /api/v1/nodes/conformance-cluster1-k8s-node-1/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 3.784145ms)
Dec 10 14:38:58.363: INFO: (3) /api/v1/nodes/conformance-cluster1-k8s-node-1/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 3.841284ms)
Dec 10 14:38:58.367: INFO: (4) /api/v1/nodes/conformance-cluster1-k8s-node-1/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 4.256144ms)
Dec 10 14:38:58.374: INFO: (5) /api/v1/nodes/conformance-cluster1-k8s-node-1/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 6.189614ms)
Dec 10 14:38:58.379: INFO: (6) /api/v1/nodes/conformance-cluster1-k8s-node-1/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 5.267993ms)
Dec 10 14:38:58.387: INFO: (7) /api/v1/nodes/conformance-cluster1-k8s-node-1/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 8.34217ms)
Dec 10 14:38:58.392: INFO: (8) /api/v1/nodes/conformance-cluster1-k8s-node-1/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 4.743342ms)
Dec 10 14:38:58.397: INFO: (9) /api/v1/nodes/conformance-cluster1-k8s-node-1/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 4.377082ms)
Dec 10 14:38:58.401: INFO: (10) /api/v1/nodes/conformance-cluster1-k8s-node-1/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 4.536655ms)
Dec 10 14:38:58.406: INFO: (11) /api/v1/nodes/conformance-cluster1-k8s-node-1/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 4.183204ms)
Dec 10 14:38:58.410: INFO: (12) /api/v1/nodes/conformance-cluster1-k8s-node-1/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 4.066572ms)
Dec 10 14:38:58.414: INFO: (13) /api/v1/nodes/conformance-cluster1-k8s-node-1/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 3.958438ms)
Dec 10 14:38:58.418: INFO: (14) /api/v1/nodes/conformance-cluster1-k8s-node-1/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 3.937179ms)
Dec 10 14:38:58.421: INFO: (15) /api/v1/nodes/conformance-cluster1-k8s-node-1/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 3.721502ms)
Dec 10 14:38:58.425: INFO: (16) /api/v1/nodes/conformance-cluster1-k8s-node-1/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 3.796721ms)
Dec 10 14:38:58.429: INFO: (17) /api/v1/nodes/conformance-cluster1-k8s-node-1/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 3.72997ms)
Dec 10 14:38:58.433: INFO: (18) /api/v1/nodes/conformance-cluster1-k8s-node-1/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 3.913801ms)
Dec 10 14:38:58.437: INFO: (19) /api/v1/nodes/conformance-cluster1-k8s-node-1/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 3.964332ms)
[AfterEach] version v1
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 10 14:38:58.437: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-proxy-dltc2" for this suite.
Dec 10 14:39:04.460: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 14:39:04.515: INFO: namespace: e2e-tests-proxy-dltc2, resource: bindings, ignored listing per whitelist
Dec 10 14:39:04.568: INFO: namespace e2e-tests-proxy-dltc2 deletion completed in 6.127431714s

• [SLOW TEST:6.287 seconds]
[sig-network] Proxy
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy logs on node using proxy subresource  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 10 14:39:04.569: INFO: >>> kubeConfig: /tmp/kubeconfig-578738756
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-exec in namespace e2e-tests-container-probe-qj7pq
Dec 10 14:39:06.653: INFO: Started pod liveness-exec in namespace e2e-tests-container-probe-qj7pq
STEP: checking the pod's current state and verifying that restartCount is present
Dec 10 14:39:06.657: INFO: Initial restart count of pod liveness-exec is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 10 14:43:07.337: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-qj7pq" for this suite.
Dec 10 14:43:13.358: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 14:43:13.436: INFO: namespace: e2e-tests-container-probe-qj7pq, resource: bindings, ignored listing per whitelist
Dec 10 14:43:13.490: INFO: namespace e2e-tests-container-probe-qj7pq deletion completed in 6.147435904s

• [SLOW TEST:248.921 seconds]
[k8s.io] Probing container
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-apps] Deployment 
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 10 14:43:13.492: INFO: >>> kubeConfig: /tmp/kubeconfig-578738756
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Dec 10 14:43:13.564: INFO: Creating replica set "test-rolling-update-controller" (going to be adopted)
Dec 10 14:43:13.578: INFO: Pod name sample-pod: Found 0 pods out of 1
Dec 10 14:43:18.588: INFO: Pod name sample-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Dec 10 14:43:18.588: INFO: Creating deployment "test-rolling-update-deployment"
Dec 10 14:43:18.594: INFO: Ensuring deployment "test-rolling-update-deployment" gets the next revision from the one the adopted replica set "test-rolling-update-controller" has
Dec 10 14:43:18.601: INFO: new replicaset for deployment "test-rolling-update-deployment" is yet to be created
Dec 10 14:43:20.608: INFO: Ensuring status for deployment "test-rolling-update-deployment" is the expected
Dec 10 14:43:20.611: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:2, UpdatedReplicas:1, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63680049798, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63680049798, loc:(*time.Location)(0x6c43b60)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63680049798, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63680049798, loc:(*time.Location)(0x6c43b60)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rolling-update-deployment-65b7695dcf\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec 10 14:43:22.616: INFO: Ensuring deployment "test-rolling-update-deployment" has one old replica set (the one it adopted)
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Dec 10 14:43:22.627: INFO: Deployment "test-rolling-update-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment,GenerateName:,Namespace:e2e-tests-deployment-h5td7,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-h5td7/deployments/test-rolling-update-deployment,UID:ef097107-fc89-11e8-8690-fa163e74bd5a,ResourceVersion:18716,Generation:1,CreationTimestamp:2018-12-10 14:43:18 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,},Annotations:map[string]string{deployment.kubernetes.io/revision: 3546343826724305833,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[{Available True 2018-12-10 14:43:18 +0000 UTC 2018-12-10 14:43:18 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2018-12-10 14:43:20 +0000 UTC 2018-12-10 14:43:18 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-rolling-update-deployment-65b7695dcf" has successfully progressed.}],ReadyReplicas:1,CollisionCount:nil,},}

Dec 10 14:43:22.632: INFO: New ReplicaSet "test-rolling-update-deployment-65b7695dcf" of Deployment "test-rolling-update-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment-65b7695dcf,GenerateName:,Namespace:e2e-tests-deployment-h5td7,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-h5td7/replicasets/test-rolling-update-deployment-65b7695dcf,UID:ef0d1773-fc89-11e8-808b-fa163e6bf550,ResourceVersion:18707,Generation:1,CreationTimestamp:2018-12-10 14:43:18 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 65b7695dcf,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 3546343826724305833,},OwnerReferences:[{apps/v1 Deployment test-rolling-update-deployment ef097107-fc89-11e8-8690-fa163e74bd5a 0xc42137fe17 0xc42137fe18}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod-template-hash: 65b7695dcf,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 65b7695dcf,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Dec 10 14:43:22.632: INFO: All old ReplicaSets of Deployment "test-rolling-update-deployment":
Dec 10 14:43:22.632: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-controller,GenerateName:,Namespace:e2e-tests-deployment-h5td7,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-h5td7/replicasets/test-rolling-update-controller,UID:ec0ad985-fc89-11e8-8690-fa163e74bd5a,ResourceVersion:18715,Generation:2,CreationTimestamp:2018-12-10 14:43:13 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod: nginx,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 3546343826724305832,},OwnerReferences:[{apps/v1 Deployment test-rolling-update-deployment ef097107-fc89-11e8-8690-fa163e74bd5a 0xc42137fd4e 0xc42137fd4f}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Dec 10 14:43:22.636: INFO: Pod "test-rolling-update-deployment-65b7695dcf-fwv7q" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment-65b7695dcf-fwv7q,GenerateName:test-rolling-update-deployment-65b7695dcf-,Namespace:e2e-tests-deployment-h5td7,SelfLink:/api/v1/namespaces/e2e-tests-deployment-h5td7/pods/test-rolling-update-deployment-65b7695dcf-fwv7q,UID:ef0dfe75-fc89-11e8-808b-fa163e6bf550,ResourceVersion:18706,Generation:0,CreationTimestamp:2018-12-10 14:43:18 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 65b7695dcf,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet test-rolling-update-deployment-65b7695dcf ef0d1773-fc89-11e8-808b-fa163e6bf550 0xc4211174e7 0xc4211174e8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-bl4h2 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-bl4h2,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-bl4h2 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:conformance-cluster1-k8s-node-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc4211175d0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc4211175f0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-10 14:43:18 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-12-10 14:43:20 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2018-12-10 14:43:20 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-10 14:43:18 +0000 UTC  }],Message:,Reason:,HostIP:10.0.0.6,PodIP:10.233.64.137,StartTime:2018-12-10 14:43:18 +0000 UTC,ContainerStatuses:[{redis {nil ContainerStateRunning{StartedAt:2018-12-10 14:43:19 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/redis:1.0 docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830 docker://3697b5366c28893a764364b4f59f7afe44891dc14dfa22f2fffe09fc35440c9c}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 10 14:43:22.636: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-h5td7" for this suite.
Dec 10 14:43:28.662: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 14:43:28.763: INFO: namespace: e2e-tests-deployment-h5td7, resource: bindings, ignored listing per whitelist
Dec 10 14:43:28.772: INFO: namespace e2e-tests-deployment-h5td7 deletion completed in 6.131146572s

• [SLOW TEST:15.280 seconds]
[sig-apps] Deployment
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 10 14:43:28.772: INFO: >>> kubeConfig: /tmp/kubeconfig-578738756
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Dec 10 14:43:28.849: INFO: Waiting up to 5m0s for pod "downwardapi-volume-f5252348-fc89-11e8-a36b-7e9ed3de7210" in namespace "e2e-tests-downward-api-kntp2" to be "success or failure"
Dec 10 14:43:28.856: INFO: Pod "downwardapi-volume-f5252348-fc89-11e8-a36b-7e9ed3de7210": Phase="Pending", Reason="", readiness=false. Elapsed: 7.220712ms
Dec 10 14:43:30.861: INFO: Pod "downwardapi-volume-f5252348-fc89-11e8-a36b-7e9ed3de7210": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.012219309s
STEP: Saw pod success
Dec 10 14:43:30.862: INFO: Pod "downwardapi-volume-f5252348-fc89-11e8-a36b-7e9ed3de7210" satisfied condition "success or failure"
Dec 10 14:43:30.866: INFO: Trying to get logs from node conformance-cluster1-k8s-node-2 pod downwardapi-volume-f5252348-fc89-11e8-a36b-7e9ed3de7210 container client-container: <nil>
STEP: delete the pod
Dec 10 14:43:30.895: INFO: Waiting for pod downwardapi-volume-f5252348-fc89-11e8-a36b-7e9ed3de7210 to disappear
Dec 10 14:43:30.899: INFO: Pod downwardapi-volume-f5252348-fc89-11e8-a36b-7e9ed3de7210 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 10 14:43:30.899: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-kntp2" for this suite.
Dec 10 14:43:36.919: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 14:43:36.988: INFO: namespace: e2e-tests-downward-api-kntp2, resource: bindings, ignored listing per whitelist
Dec 10 14:43:37.033: INFO: namespace e2e-tests-downward-api-kntp2 deletion completed in 6.130131948s

• [SLOW TEST:8.261 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-cli] Kubectl client [k8s.io] Proxy server 
  should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 10 14:43:37.034: INFO: >>> kubeConfig: /tmp/kubeconfig-578738756
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Starting the proxy
Dec 10 14:43:37.095: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-578738756 proxy --unix-socket=/tmp/kubectl-proxy-unix545515219/test'
STEP: retrieving proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 10 14:43:37.157: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-8fqq8" for this suite.
Dec 10 14:43:43.176: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 14:43:43.220: INFO: namespace: e2e-tests-kubectl-8fqq8, resource: bindings, ignored listing per whitelist
Dec 10 14:43:43.284: INFO: namespace e2e-tests-kubectl-8fqq8 deletion completed in 6.121419336s

• [SLOW TEST:6.250 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Proxy server
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should support --unix-socket=/path  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-storage] Projected 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 10 14:43:43.284: INFO: >>> kubeConfig: /tmp/kubeconfig-578738756
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Dec 10 14:43:43.361: INFO: Waiting up to 5m0s for pod "downwardapi-volume-fdcb6311-fc89-11e8-a36b-7e9ed3de7210" in namespace "e2e-tests-projected-q9lh9" to be "success or failure"
Dec 10 14:43:43.367: INFO: Pod "downwardapi-volume-fdcb6311-fc89-11e8-a36b-7e9ed3de7210": Phase="Pending", Reason="", readiness=false. Elapsed: 6.112395ms
Dec 10 14:43:45.373: INFO: Pod "downwardapi-volume-fdcb6311-fc89-11e8-a36b-7e9ed3de7210": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.012204143s
STEP: Saw pod success
Dec 10 14:43:45.373: INFO: Pod "downwardapi-volume-fdcb6311-fc89-11e8-a36b-7e9ed3de7210" satisfied condition "success or failure"
Dec 10 14:43:45.377: INFO: Trying to get logs from node conformance-cluster1-k8s-node-1 pod downwardapi-volume-fdcb6311-fc89-11e8-a36b-7e9ed3de7210 container client-container: <nil>
STEP: delete the pod
Dec 10 14:43:45.403: INFO: Waiting for pod downwardapi-volume-fdcb6311-fc89-11e8-a36b-7e9ed3de7210 to disappear
Dec 10 14:43:45.407: INFO: Pod downwardapi-volume-fdcb6311-fc89-11e8-a36b-7e9ed3de7210 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 10 14:43:45.407: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-q9lh9" for this suite.
Dec 10 14:43:51.428: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 14:43:51.453: INFO: namespace: e2e-tests-projected-q9lh9, resource: bindings, ignored listing per whitelist
Dec 10 14:43:51.530: INFO: namespace e2e-tests-projected-q9lh9 deletion completed in 6.117772272s

• [SLOW TEST:8.246 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Projected 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 10 14:43:51.530: INFO: >>> kubeConfig: /tmp/kubeconfig-578738756
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Dec 10 14:43:51.597: INFO: Waiting up to 5m0s for pod "downwardapi-volume-02b469a3-fc8a-11e8-a36b-7e9ed3de7210" in namespace "e2e-tests-projected-sqtwj" to be "success or failure"
Dec 10 14:43:51.602: INFO: Pod "downwardapi-volume-02b469a3-fc8a-11e8-a36b-7e9ed3de7210": Phase="Pending", Reason="", readiness=false. Elapsed: 5.456746ms
Dec 10 14:43:53.606: INFO: Pod "downwardapi-volume-02b469a3-fc8a-11e8-a36b-7e9ed3de7210": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009905982s
Dec 10 14:43:55.611: INFO: Pod "downwardapi-volume-02b469a3-fc8a-11e8-a36b-7e9ed3de7210": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014263378s
STEP: Saw pod success
Dec 10 14:43:55.611: INFO: Pod "downwardapi-volume-02b469a3-fc8a-11e8-a36b-7e9ed3de7210" satisfied condition "success or failure"
Dec 10 14:43:55.614: INFO: Trying to get logs from node conformance-cluster1-k8s-node-2 pod downwardapi-volume-02b469a3-fc8a-11e8-a36b-7e9ed3de7210 container client-container: <nil>
STEP: delete the pod
Dec 10 14:43:55.639: INFO: Waiting for pod downwardapi-volume-02b469a3-fc8a-11e8-a36b-7e9ed3de7210 to disappear
Dec 10 14:43:55.642: INFO: Pod downwardapi-volume-02b469a3-fc8a-11e8-a36b-7e9ed3de7210 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 10 14:43:55.642: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-sqtwj" for this suite.
Dec 10 14:44:01.659: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 14:44:01.716: INFO: namespace: e2e-tests-projected-sqtwj, resource: bindings, ignored listing per whitelist
Dec 10 14:44:01.769: INFO: namespace e2e-tests-projected-sqtwj deletion completed in 6.123003508s

• [SLOW TEST:10.239 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 10 14:44:01.769: INFO: >>> kubeConfig: /tmp/kubeconfig-578738756
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-v7cfc
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Dec 10 14:44:01.838: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Dec 10 14:44:19.926: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.233.122.250:8080/dial?request=hostName&protocol=udp&host=10.233.64.136&port=8081&tries=1'] Namespace:e2e-tests-pod-network-test-v7cfc PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 10 14:44:19.926: INFO: >>> kubeConfig: /tmp/kubeconfig-578738756
Dec 10 14:44:20.042: INFO: Waiting for endpoints: map[]
Dec 10 14:44:20.046: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.233.122.250:8080/dial?request=hostName&protocol=udp&host=10.233.122.249&port=8081&tries=1'] Namespace:e2e-tests-pod-network-test-v7cfc PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 10 14:44:20.046: INFO: >>> kubeConfig: /tmp/kubeconfig-578738756
Dec 10 14:44:20.172: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 10 14:44:20.172: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-v7cfc" for this suite.
Dec 10 14:44:42.197: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 14:44:42.300: INFO: namespace: e2e-tests-pod-network-test-v7cfc, resource: bindings, ignored listing per whitelist
Dec 10 14:44:42.309: INFO: namespace e2e-tests-pod-network-test-v7cfc deletion completed in 22.132286517s

• [SLOW TEST:40.540 seconds]
[sig-network] Networking
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: udp [NodeConformance] [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources Simple CustomResourceDefinition 
  creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 10 14:44:42.311: INFO: >>> kubeConfig: /tmp/kubeconfig-578738756
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Waiting for a default service account to be provisioned in namespace
[It] creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Dec 10 14:44:42.380: INFO: >>> kubeConfig: /tmp/kubeconfig-578738756
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 10 14:44:48.449: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-custom-resource-definition-7jqhq" for this suite.
Dec 10 14:44:54.469: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 14:44:54.534: INFO: namespace: e2e-tests-custom-resource-definition-7jqhq, resource: bindings, ignored listing per whitelist
Dec 10 14:44:54.579: INFO: namespace e2e-tests-custom-resource-definition-7jqhq deletion completed in 6.124511407s

• [SLOW TEST:12.268 seconds]
[sig-api-machinery] CustomResourceDefinition resources
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  Simple CustomResourceDefinition
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/custom_resource_definition.go:35
    creating/deleting custom resource definition objects works  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with downward pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 10 14:44:54.579: INFO: >>> kubeConfig: /tmp/kubeconfig-578738756
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with downward pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-downwardapi-pzgr
STEP: Creating a pod to test atomic-volume-subpath
Dec 10 14:44:54.665: INFO: Waiting up to 5m0s for pod "pod-subpath-test-downwardapi-pzgr" in namespace "e2e-tests-subpath-gjc7v" to be "success or failure"
Dec 10 14:44:54.669: INFO: Pod "pod-subpath-test-downwardapi-pzgr": Phase="Pending", Reason="", readiness=false. Elapsed: 3.691173ms
Dec 10 14:44:56.673: INFO: Pod "pod-subpath-test-downwardapi-pzgr": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007850436s
Dec 10 14:44:58.677: INFO: Pod "pod-subpath-test-downwardapi-pzgr": Phase="Running", Reason="", readiness=false. Elapsed: 4.012094885s
Dec 10 14:45:00.682: INFO: Pod "pod-subpath-test-downwardapi-pzgr": Phase="Running", Reason="", readiness=false. Elapsed: 6.016942164s
Dec 10 14:45:02.692: INFO: Pod "pod-subpath-test-downwardapi-pzgr": Phase="Running", Reason="", readiness=false. Elapsed: 8.027087297s
Dec 10 14:45:04.698: INFO: Pod "pod-subpath-test-downwardapi-pzgr": Phase="Running", Reason="", readiness=false. Elapsed: 10.03281238s
Dec 10 14:45:06.702: INFO: Pod "pod-subpath-test-downwardapi-pzgr": Phase="Running", Reason="", readiness=false. Elapsed: 12.037246099s
Dec 10 14:45:08.707: INFO: Pod "pod-subpath-test-downwardapi-pzgr": Phase="Running", Reason="", readiness=false. Elapsed: 14.042040405s
Dec 10 14:45:10.711: INFO: Pod "pod-subpath-test-downwardapi-pzgr": Phase="Running", Reason="", readiness=false. Elapsed: 16.046147752s
Dec 10 14:45:12.721: INFO: Pod "pod-subpath-test-downwardapi-pzgr": Phase="Running", Reason="", readiness=false. Elapsed: 18.05606354s
Dec 10 14:45:14.726: INFO: Pod "pod-subpath-test-downwardapi-pzgr": Phase="Running", Reason="", readiness=false. Elapsed: 20.060645053s
Dec 10 14:45:16.730: INFO: Pod "pod-subpath-test-downwardapi-pzgr": Phase="Running", Reason="", readiness=false. Elapsed: 22.065026028s
Dec 10 14:45:18.735: INFO: Pod "pod-subpath-test-downwardapi-pzgr": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.069862734s
STEP: Saw pod success
Dec 10 14:45:18.735: INFO: Pod "pod-subpath-test-downwardapi-pzgr" satisfied condition "success or failure"
Dec 10 14:45:18.739: INFO: Trying to get logs from node conformance-cluster1-k8s-node-2 pod pod-subpath-test-downwardapi-pzgr container test-container-subpath-downwardapi-pzgr: <nil>
STEP: delete the pod
Dec 10 14:45:18.764: INFO: Waiting for pod pod-subpath-test-downwardapi-pzgr to disappear
Dec 10 14:45:18.767: INFO: Pod pod-subpath-test-downwardapi-pzgr no longer exists
STEP: Deleting pod pod-subpath-test-downwardapi-pzgr
Dec 10 14:45:18.767: INFO: Deleting pod "pod-subpath-test-downwardapi-pzgr" in namespace "e2e-tests-subpath-gjc7v"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 10 14:45:18.771: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-gjc7v" for this suite.
Dec 10 14:45:24.792: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 14:45:24.894: INFO: namespace: e2e-tests-subpath-gjc7v, resource: bindings, ignored listing per whitelist
Dec 10 14:45:24.907: INFO: namespace e2e-tests-subpath-gjc7v deletion completed in 6.131111785s

• [SLOW TEST:30.328 seconds]
[sig-storage] Subpath
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with downward pod [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 10 14:45:24.907: INFO: >>> kubeConfig: /tmp/kubeconfig-578738756
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(dig +notcp +noall +answer +search kubernetes.default A)" && echo OK > /results/wheezy_udp@kubernetes.default;test -n "$$(dig +tcp +noall +answer +search kubernetes.default A)" && echo OK > /results/wheezy_tcp@kubernetes.default;test -n "$$(dig +notcp +noall +answer +search kubernetes.default.svc A)" && echo OK > /results/wheezy_udp@kubernetes.default.svc;test -n "$$(dig +tcp +noall +answer +search kubernetes.default.svc A)" && echo OK > /results/wheezy_tcp@kubernetes.default.svc;test -n "$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && echo OK > /results/wheezy_udp@kubernetes.default.svc.cluster.local;test -n "$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && echo OK > /results/wheezy_tcp@kubernetes.default.svc.cluster.local;test -n "$$(getent hosts dns-querier-1.dns-test-service.e2e-tests-dns-dw9v5.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-1.dns-test-service.e2e-tests-dns-dw9v5.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/wheezy_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-dw9v5.pod.cluster.local"}');test -n "$$(dig +notcp +noall +answer +search $${podARec} A)" && echo OK > /results/wheezy_udp@PodARecord;test -n "$$(dig +tcp +noall +answer +search $${podARec} A)" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(dig +notcp +noall +answer +search kubernetes.default A)" && echo OK > /results/jessie_udp@kubernetes.default;test -n "$$(dig +tcp +noall +answer +search kubernetes.default A)" && echo OK > /results/jessie_tcp@kubernetes.default;test -n "$$(dig +notcp +noall +answer +search kubernetes.default.svc A)" && echo OK > /results/jessie_udp@kubernetes.default.svc;test -n "$$(dig +tcp +noall +answer +search kubernetes.default.svc A)" && echo OK > /results/jessie_tcp@kubernetes.default.svc;test -n "$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && echo OK > /results/jessie_udp@kubernetes.default.svc.cluster.local;test -n "$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && echo OK > /results/jessie_tcp@kubernetes.default.svc.cluster.local;test -n "$$(getent hosts dns-querier-1.dns-test-service.e2e-tests-dns-dw9v5.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-1.dns-test-service.e2e-tests-dns-dw9v5.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/jessie_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-dw9v5.pod.cluster.local"}');test -n "$$(dig +notcp +noall +answer +search $${podARec} A)" && echo OK > /results/jessie_udp@PodARecord;test -n "$$(dig +tcp +noall +answer +search $${podARec} A)" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Dec 10 14:45:37.095: INFO: DNS probes using e2e-tests-dns-dw9v5/dns-test-3a5e1d3b-fc8a-11e8-a36b-7e9ed3de7210 succeeded

STEP: deleting the pod
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 10 14:45:37.112: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-dns-dw9v5" for this suite.
Dec 10 14:45:43.130: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 14:45:43.148: INFO: namespace: e2e-tests-dns-dw9v5, resource: bindings, ignored listing per whitelist
Dec 10 14:45:43.242: INFO: namespace e2e-tests-dns-dw9v5 deletion completed in 6.125783565s

• [SLOW TEST:18.335 seconds]
[sig-network] DNS
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Burst scaling should run to completion even with unhealthy pods [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 10 14:45:43.243: INFO: >>> kubeConfig: /tmp/kubeconfig-578738756
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-m5m6z
[It] Burst scaling should run to completion even with unhealthy pods [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating stateful set ss in namespace e2e-tests-statefulset-m5m6z
STEP: Waiting until all stateful set ss replicas will be running in namespace e2e-tests-statefulset-m5m6z
Dec 10 14:45:43.326: INFO: Found 0 stateful pods, waiting for 1
Dec 10 14:45:53.335: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will not halt with unhealthy stateful pod
Dec 10 14:45:53.339: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-578738756 exec --namespace=e2e-tests-statefulset-m5m6z ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Dec 10 14:45:53.539: INFO: stderr: ""
Dec 10 14:45:53.539: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Dec 10 14:45:53.539: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Dec 10 14:45:53.545: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Dec 10 14:46:03.554: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Dec 10 14:46:03.554: INFO: Waiting for statefulset status.replicas updated to 0
Dec 10 14:46:03.570: INFO: POD   NODE                             PHASE    GRACE  CONDITIONS
Dec 10 14:46:03.570: INFO: ss-0  conformance-cluster1-k8s-node-2  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-10 14:45:43 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-10 14:45:53 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-10 14:45:53 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-10 14:45:43 +0000 UTC  }]
Dec 10 14:46:03.570: INFO: 
Dec 10 14:46:03.570: INFO: StatefulSet ss has not reached scale 3, at 1
Dec 10 14:46:04.576: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.996327863s
Dec 10 14:46:05.580: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.990901977s
Dec 10 14:46:06.586: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.986078001s
Dec 10 14:46:07.591: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.980798966s
Dec 10 14:46:08.595: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.975899955s
Dec 10 14:46:09.600: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.971097101s
Dec 10 14:46:10.605: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.966360106s
Dec 10 14:46:11.609: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.961518058s
Dec 10 14:46:12.615: INFO: Verifying statefulset ss doesn't scale past 3 for another 957.02156ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace e2e-tests-statefulset-m5m6z
Dec 10 14:46:13.625: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-578738756 exec --namespace=e2e-tests-statefulset-m5m6z ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec 10 14:46:13.823: INFO: stderr: ""
Dec 10 14:46:13.823: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Dec 10 14:46:13.823: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Dec 10 14:46:13.823: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-578738756 exec --namespace=e2e-tests-statefulset-m5m6z ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec 10 14:46:14.009: INFO: stderr: "mv: can't rename '/tmp/index.html': No such file or directory\n"
Dec 10 14:46:14.009: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Dec 10 14:46:14.009: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Dec 10 14:46:14.009: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-578738756 exec --namespace=e2e-tests-statefulset-m5m6z ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec 10 14:46:14.224: INFO: stderr: "mv: can't rename '/tmp/index.html': No such file or directory\n"
Dec 10 14:46:14.224: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Dec 10 14:46:14.224: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-2: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Dec 10 14:46:14.228: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=false
Dec 10 14:46:24.238: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Dec 10 14:46:24.238: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Dec 10 14:46:24.238: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Scale down will not halt with unhealthy stateful pod
Dec 10 14:46:24.242: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-578738756 exec --namespace=e2e-tests-statefulset-m5m6z ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Dec 10 14:46:24.472: INFO: stderr: ""
Dec 10 14:46:24.472: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Dec 10 14:46:24.472: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Dec 10 14:46:24.473: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-578738756 exec --namespace=e2e-tests-statefulset-m5m6z ss-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Dec 10 14:46:24.652: INFO: stderr: ""
Dec 10 14:46:24.652: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Dec 10 14:46:24.652: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Dec 10 14:46:24.652: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-578738756 exec --namespace=e2e-tests-statefulset-m5m6z ss-2 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Dec 10 14:46:24.861: INFO: stderr: ""
Dec 10 14:46:24.861: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Dec 10 14:46:24.861: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-2: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Dec 10 14:46:24.861: INFO: Waiting for statefulset status.replicas updated to 0
Dec 10 14:46:24.865: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 2
Dec 10 14:46:34.878: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Dec 10 14:46:34.878: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Dec 10 14:46:34.878: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Dec 10 14:46:34.891: INFO: POD   NODE                             PHASE    GRACE  CONDITIONS
Dec 10 14:46:34.891: INFO: ss-0  conformance-cluster1-k8s-node-2  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-10 14:45:43 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-10 14:46:24 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-10 14:46:24 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-10 14:45:43 +0000 UTC  }]
Dec 10 14:46:34.891: INFO: ss-1  conformance-cluster1-k8s-node-1  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-10 14:46:03 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-10 14:46:25 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-10 14:46:25 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-10 14:46:03 +0000 UTC  }]
Dec 10 14:46:34.891: INFO: ss-2  conformance-cluster1-k8s-node-2  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-10 14:46:03 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-10 14:46:24 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-10 14:46:24 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-10 14:46:03 +0000 UTC  }]
Dec 10 14:46:34.891: INFO: 
Dec 10 14:46:34.891: INFO: StatefulSet ss has not reached scale 0, at 3
Dec 10 14:46:35.896: INFO: POD   NODE                             PHASE    GRACE  CONDITIONS
Dec 10 14:46:35.896: INFO: ss-0  conformance-cluster1-k8s-node-2  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-10 14:45:43 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-10 14:46:24 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-10 14:46:24 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-10 14:45:43 +0000 UTC  }]
Dec 10 14:46:35.896: INFO: ss-1  conformance-cluster1-k8s-node-1  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-10 14:46:03 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-10 14:46:25 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-10 14:46:25 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-10 14:46:03 +0000 UTC  }]
Dec 10 14:46:35.896: INFO: ss-2  conformance-cluster1-k8s-node-2  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-10 14:46:03 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-10 14:46:24 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-10 14:46:24 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-10 14:46:03 +0000 UTC  }]
Dec 10 14:46:35.896: INFO: 
Dec 10 14:46:35.896: INFO: StatefulSet ss has not reached scale 0, at 3
Dec 10 14:46:36.901: INFO: POD   NODE                             PHASE    GRACE  CONDITIONS
Dec 10 14:46:36.901: INFO: ss-0  conformance-cluster1-k8s-node-2  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-10 14:45:43 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-10 14:46:24 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-10 14:46:24 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-10 14:45:43 +0000 UTC  }]
Dec 10 14:46:36.901: INFO: ss-1  conformance-cluster1-k8s-node-1  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-10 14:46:03 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-10 14:46:25 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-10 14:46:25 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-10 14:46:03 +0000 UTC  }]
Dec 10 14:46:36.901: INFO: ss-2  conformance-cluster1-k8s-node-2  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-10 14:46:03 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-10 14:46:24 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-10 14:46:24 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-10 14:46:03 +0000 UTC  }]
Dec 10 14:46:36.901: INFO: 
Dec 10 14:46:36.901: INFO: StatefulSet ss has not reached scale 0, at 3
Dec 10 14:46:37.906: INFO: POD   NODE                             PHASE    GRACE  CONDITIONS
Dec 10 14:46:37.906: INFO: ss-0  conformance-cluster1-k8s-node-2  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-10 14:45:43 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-10 14:46:24 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-10 14:46:24 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-10 14:45:43 +0000 UTC  }]
Dec 10 14:46:37.906: INFO: ss-1  conformance-cluster1-k8s-node-1  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-10 14:46:03 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-10 14:46:25 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-10 14:46:25 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-10 14:46:03 +0000 UTC  }]
Dec 10 14:46:37.906: INFO: ss-2  conformance-cluster1-k8s-node-2  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-10 14:46:03 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-10 14:46:24 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-10 14:46:24 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-10 14:46:03 +0000 UTC  }]
Dec 10 14:46:37.906: INFO: 
Dec 10 14:46:37.906: INFO: StatefulSet ss has not reached scale 0, at 3
Dec 10 14:46:38.910: INFO: POD   NODE                             PHASE    GRACE  CONDITIONS
Dec 10 14:46:38.910: INFO: ss-0  conformance-cluster1-k8s-node-2  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-10 14:45:43 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-10 14:46:24 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-10 14:46:24 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-10 14:45:43 +0000 UTC  }]
Dec 10 14:46:38.910: INFO: ss-1  conformance-cluster1-k8s-node-1  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-10 14:46:03 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-10 14:46:25 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-10 14:46:25 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-10 14:46:03 +0000 UTC  }]
Dec 10 14:46:38.910: INFO: ss-2  conformance-cluster1-k8s-node-2  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-10 14:46:03 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-10 14:46:24 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-10 14:46:24 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-10 14:46:03 +0000 UTC  }]
Dec 10 14:46:38.910: INFO: 
Dec 10 14:46:38.910: INFO: StatefulSet ss has not reached scale 0, at 3
Dec 10 14:46:39.915: INFO: POD   NODE                             PHASE    GRACE  CONDITIONS
Dec 10 14:46:39.915: INFO: ss-0  conformance-cluster1-k8s-node-2  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-10 14:45:43 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-10 14:46:24 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-10 14:46:24 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-10 14:45:43 +0000 UTC  }]
Dec 10 14:46:39.915: INFO: ss-1  conformance-cluster1-k8s-node-1  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-10 14:46:03 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-10 14:46:25 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-10 14:46:25 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-10 14:46:03 +0000 UTC  }]
Dec 10 14:46:39.915: INFO: ss-2  conformance-cluster1-k8s-node-2  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-10 14:46:03 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-10 14:46:24 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-10 14:46:24 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-10 14:46:03 +0000 UTC  }]
Dec 10 14:46:39.915: INFO: 
Dec 10 14:46:39.915: INFO: StatefulSet ss has not reached scale 0, at 3
Dec 10 14:46:40.920: INFO: POD   NODE                             PHASE    GRACE  CONDITIONS
Dec 10 14:46:40.920: INFO: ss-0  conformance-cluster1-k8s-node-2  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-10 14:45:43 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-10 14:46:24 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-10 14:46:24 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-10 14:45:43 +0000 UTC  }]
Dec 10 14:46:40.920: INFO: ss-1  conformance-cluster1-k8s-node-1  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-10 14:46:03 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-10 14:46:25 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-10 14:46:25 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-10 14:46:03 +0000 UTC  }]
Dec 10 14:46:40.920: INFO: ss-2  conformance-cluster1-k8s-node-2  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-10 14:46:03 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-10 14:46:24 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-10 14:46:24 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-10 14:46:03 +0000 UTC  }]
Dec 10 14:46:40.920: INFO: 
Dec 10 14:46:40.920: INFO: StatefulSet ss has not reached scale 0, at 3
Dec 10 14:46:41.925: INFO: POD   NODE                             PHASE    GRACE  CONDITIONS
Dec 10 14:46:41.925: INFO: ss-0  conformance-cluster1-k8s-node-2  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-10 14:45:43 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-10 14:46:24 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-10 14:46:24 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-10 14:45:43 +0000 UTC  }]
Dec 10 14:46:41.925: INFO: ss-1  conformance-cluster1-k8s-node-1  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-10 14:46:03 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-10 14:46:25 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-10 14:46:25 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-10 14:46:03 +0000 UTC  }]
Dec 10 14:46:41.925: INFO: ss-2  conformance-cluster1-k8s-node-2  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-10 14:46:03 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-10 14:46:24 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-10 14:46:24 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-10 14:46:03 +0000 UTC  }]
Dec 10 14:46:41.925: INFO: 
Dec 10 14:46:41.925: INFO: StatefulSet ss has not reached scale 0, at 3
Dec 10 14:46:42.935: INFO: POD   NODE                             PHASE    GRACE  CONDITIONS
Dec 10 14:46:42.935: INFO: ss-0  conformance-cluster1-k8s-node-2  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-10 14:45:43 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-10 14:46:24 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-10 14:46:24 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-10 14:45:43 +0000 UTC  }]
Dec 10 14:46:42.935: INFO: ss-1  conformance-cluster1-k8s-node-1  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-10 14:46:03 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-10 14:46:25 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-10 14:46:25 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-10 14:46:03 +0000 UTC  }]
Dec 10 14:46:42.935: INFO: ss-2  conformance-cluster1-k8s-node-2  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-10 14:46:03 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-10 14:46:24 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-10 14:46:24 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-10 14:46:03 +0000 UTC  }]
Dec 10 14:46:42.935: INFO: 
Dec 10 14:46:42.935: INFO: StatefulSet ss has not reached scale 0, at 3
Dec 10 14:46:43.941: INFO: POD   NODE                             PHASE    GRACE  CONDITIONS
Dec 10 14:46:43.941: INFO: ss-0  conformance-cluster1-k8s-node-2  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-10 14:45:43 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-10 14:46:24 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-10 14:46:24 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-10 14:45:43 +0000 UTC  }]
Dec 10 14:46:43.941: INFO: ss-1  conformance-cluster1-k8s-node-1  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-10 14:46:03 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-10 14:46:25 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-10 14:46:25 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-10 14:46:03 +0000 UTC  }]
Dec 10 14:46:43.941: INFO: ss-2  conformance-cluster1-k8s-node-2  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-10 14:46:03 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-10 14:46:24 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-10 14:46:24 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-10 14:46:03 +0000 UTC  }]
Dec 10 14:46:43.941: INFO: 
Dec 10 14:46:43.941: INFO: StatefulSet ss has not reached scale 0, at 3
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacee2e-tests-statefulset-m5m6z
Dec 10 14:46:44.951: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-578738756 exec --namespace=e2e-tests-statefulset-m5m6z ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec 10 14:46:45.087: INFO: rc: 1
Dec 10 14:46:45.087: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-578738756 exec --namespace=e2e-tests-statefulset-m5m6z ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  error: unable to upgrade connection: container not found ("nginx")
 [] <nil> 0xc420d491a0 exit status 1 <nil> <nil> true [0xc420ed8040 0xc420ed8080 0xc420ed80a8] [0xc420ed8040 0xc420ed8080 0xc420ed80a8] [0xc420ed8070 0xc420ed80a0] [0x8fd520 0x8fd520] 0xc421a18480 <nil>}:
Command stdout:

stderr:
error: unable to upgrade connection: container not found ("nginx")

error:
exit status 1

Dec 10 14:46:55.087: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-578738756 exec --namespace=e2e-tests-statefulset-m5m6z ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec 10 14:46:55.163: INFO: rc: 1
Dec 10 14:46:55.163: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-578738756 exec --namespace=e2e-tests-statefulset-m5m6z ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc420d49620 exit status 1 <nil> <nil> true [0xc420ed80c0 0xc420ed8180 0xc420ed81e8] [0xc420ed80c0 0xc420ed8180 0xc420ed81e8] [0xc420ed8170 0xc420ed81b8] [0x8fd520 0x8fd520] 0xc421a18660 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Dec 10 14:47:05.163: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-578738756 exec --namespace=e2e-tests-statefulset-m5m6z ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec 10 14:47:05.243: INFO: rc: 1
Dec 10 14:47:05.243: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-578738756 exec --namespace=e2e-tests-statefulset-m5m6z ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc4211e20c0 exit status 1 <nil> <nil> true [0xc420ed8208 0xc420ed8288 0xc420ed82d0] [0xc420ed8208 0xc420ed8288 0xc420ed82d0] [0xc420ed8248 0xc420ed82b8] [0x8fd520 0x8fd520] 0xc421a18780 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Dec 10 14:47:15.244: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-578738756 exec --namespace=e2e-tests-statefulset-m5m6z ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec 10 14:47:15.325: INFO: rc: 1
Dec 10 14:47:15.325: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-578738756 exec --namespace=e2e-tests-statefulset-m5m6z ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc4211e24b0 exit status 1 <nil> <nil> true [0xc420ed82e8 0xc420ed8338 0xc420ed83c8] [0xc420ed82e8 0xc420ed8338 0xc420ed83c8] [0xc420ed8318 0xc420ed83a8] [0x8fd520 0x8fd520] 0xc421a188a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Dec 10 14:47:25.326: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-578738756 exec --namespace=e2e-tests-statefulset-m5m6z ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec 10 14:47:25.413: INFO: rc: 1
Dec 10 14:47:25.413: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-578738756 exec --namespace=e2e-tests-statefulset-m5m6z ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc4211e28d0 exit status 1 <nil> <nil> true [0xc420ed8408 0xc420ed8530 0xc420ed85e0] [0xc420ed8408 0xc420ed8530 0xc420ed85e0] [0xc420ed8458 0xc420ed8588] [0x8fd520 0x8fd520] 0xc421a189c0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Dec 10 14:47:35.413: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-578738756 exec --namespace=e2e-tests-statefulset-m5m6z ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec 10 14:47:35.516: INFO: rc: 1
Dec 10 14:47:35.516: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-578738756 exec --namespace=e2e-tests-statefulset-m5m6z ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc4211e2d20 exit status 1 <nil> <nil> true [0xc420ed85f0 0xc420ed86d8 0xc420ed8728] [0xc420ed85f0 0xc420ed86d8 0xc420ed8728] [0xc420ed8690 0xc420ed8720] [0x8fd520 0x8fd520] 0xc421a18ae0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Dec 10 14:47:45.516: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-578738756 exec --namespace=e2e-tests-statefulset-m5m6z ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec 10 14:47:45.597: INFO: rc: 1
Dec 10 14:47:45.597: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-578738756 exec --namespace=e2e-tests-statefulset-m5m6z ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc4211f24e0 exit status 1 <nil> <nil> true [0xc421474028 0xc421474040 0xc421474058] [0xc421474028 0xc421474040 0xc421474058] [0xc421474038 0xc421474050] [0x8fd520 0x8fd520] 0xc421316540 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Dec 10 14:47:55.597: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-578738756 exec --namespace=e2e-tests-statefulset-m5m6z ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec 10 14:47:55.674: INFO: rc: 1
Dec 10 14:47:55.674: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-578738756 exec --namespace=e2e-tests-statefulset-m5m6z ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc4211e3200 exit status 1 <nil> <nil> true [0xc420ed8740 0xc420ed87a8 0xc420ed8848] [0xc420ed8740 0xc420ed87a8 0xc420ed8848] [0xc420ed87a0 0xc420ed87d8] [0x8fd520 0x8fd520] 0xc421a18c00 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Dec 10 14:48:05.674: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-578738756 exec --namespace=e2e-tests-statefulset-m5m6z ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec 10 14:48:05.752: INFO: rc: 1
Dec 10 14:48:05.752: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-578738756 exec --namespace=e2e-tests-statefulset-m5m6z ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc4211e3740 exit status 1 <nil> <nil> true [0xc420ed8868 0xc420ed88e8 0xc420ed8930] [0xc420ed8868 0xc420ed88e8 0xc420ed8930] [0xc420ed88c8 0xc420ed8918] [0x8fd520 0x8fd520] 0xc421a18d20 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Dec 10 14:48:15.752: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-578738756 exec --namespace=e2e-tests-statefulset-m5m6z ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec 10 14:48:15.834: INFO: rc: 1
Dec 10 14:48:15.834: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-578738756 exec --namespace=e2e-tests-statefulset-m5m6z ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc4211f2ab0 exit status 1 <nil> <nil> true [0xc421474060 0xc421474078 0xc421474090] [0xc421474060 0xc421474078 0xc421474090] [0xc421474070 0xc421474088] [0x8fd520 0x8fd520] 0xc421316660 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Dec 10 14:48:25.834: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-578738756 exec --namespace=e2e-tests-statefulset-m5m6z ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec 10 14:48:25.909: INFO: rc: 1
Dec 10 14:48:25.910: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-578738756 exec --namespace=e2e-tests-statefulset-m5m6z ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc4211f2fc0 exit status 1 <nil> <nil> true [0xc421474098 0xc4214740b0 0xc4214740c8] [0xc421474098 0xc4214740b0 0xc4214740c8] [0xc4214740a8 0xc4214740c0] [0x8fd520 0x8fd520] 0xc421316780 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Dec 10 14:48:35.910: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-578738756 exec --namespace=e2e-tests-statefulset-m5m6z ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec 10 14:48:35.988: INFO: rc: 1
Dec 10 14:48:35.988: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-578738756 exec --namespace=e2e-tests-statefulset-m5m6z ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc4211f33b0 exit status 1 <nil> <nil> true [0xc4214740d0 0xc4214740e8 0xc421474100] [0xc4214740d0 0xc4214740e8 0xc421474100] [0xc4214740e0 0xc4214740f8] [0x8fd520 0x8fd520] 0xc4213168a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Dec 10 14:48:45.988: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-578738756 exec --namespace=e2e-tests-statefulset-m5m6z ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec 10 14:48:46.081: INFO: rc: 1
Dec 10 14:48:46.081: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-578738756 exec --namespace=e2e-tests-statefulset-m5m6z ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc420d483c0 exit status 1 <nil> <nil> true [0xc420ed8008 0xc420ed8030 0xc420ed8070] [0xc420ed8008 0xc420ed8030 0xc420ed8070] [0xc420ed8028 0xc420ed8050] [0x8fd520 0x8fd520] 0xc421a18060 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Dec 10 14:48:56.081: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-578738756 exec --namespace=e2e-tests-statefulset-m5m6z ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec 10 14:48:56.159: INFO: rc: 1
Dec 10 14:48:56.159: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-578738756 exec --namespace=e2e-tests-statefulset-m5m6z ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc420d487e0 exit status 1 <nil> <nil> true [0xc420ed8080 0xc420ed80a8 0xc420ed8170] [0xc420ed8080 0xc420ed80a8 0xc420ed8170] [0xc420ed80a0 0xc420ed80f0] [0x8fd520 0x8fd520] 0xc421a18180 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Dec 10 14:49:06.159: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-578738756 exec --namespace=e2e-tests-statefulset-m5m6z ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec 10 14:49:06.234: INFO: rc: 1
Dec 10 14:49:06.234: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-578738756 exec --namespace=e2e-tests-statefulset-m5m6z ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc420d491d0 exit status 1 <nil> <nil> true [0xc420ed8180 0xc420ed81e8 0xc420ed8248] [0xc420ed8180 0xc420ed81e8 0xc420ed8248] [0xc420ed81b8 0xc420ed8238] [0x8fd520 0x8fd520] 0xc421a18480 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Dec 10 14:49:16.234: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-578738756 exec --namespace=e2e-tests-statefulset-m5m6z ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec 10 14:49:16.323: INFO: rc: 1
Dec 10 14:49:16.323: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-578738756 exec --namespace=e2e-tests-statefulset-m5m6z ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc4211e2420 exit status 1 <nil> <nil> true [0xc421474000 0xc421474018 0xc421474030] [0xc421474000 0xc421474018 0xc421474030] [0xc421474010 0xc421474028] [0x8fd520 0x8fd520] 0xc4213164e0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Dec 10 14:49:26.323: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-578738756 exec --namespace=e2e-tests-statefulset-m5m6z ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec 10 14:49:26.397: INFO: rc: 1
Dec 10 14:49:26.398: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-578738756 exec --namespace=e2e-tests-statefulset-m5m6z ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc420d495f0 exit status 1 <nil> <nil> true [0xc420ed8288 0xc420ed82d0 0xc420ed8318] [0xc420ed8288 0xc420ed82d0 0xc420ed8318] [0xc420ed82b8 0xc420ed8300] [0x8fd520 0x8fd520] 0xc421a18660 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Dec 10 14:49:36.398: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-578738756 exec --namespace=e2e-tests-statefulset-m5m6z ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec 10 14:49:36.470: INFO: rc: 1
Dec 10 14:49:36.470: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-578738756 exec --namespace=e2e-tests-statefulset-m5m6z ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc4211e2840 exit status 1 <nil> <nil> true [0xc421474038 0xc421474050 0xc421474068] [0xc421474038 0xc421474050 0xc421474068] [0xc421474048 0xc421474060] [0x8fd520 0x8fd520] 0xc421316600 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Dec 10 14:49:46.470: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-578738756 exec --namespace=e2e-tests-statefulset-m5m6z ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec 10 14:49:46.565: INFO: rc: 1
Dec 10 14:49:46.565: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-578738756 exec --namespace=e2e-tests-statefulset-m5m6z ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc4211e2cc0 exit status 1 <nil> <nil> true [0xc421474070 0xc421474088 0xc4214740a0] [0xc421474070 0xc421474088 0xc4214740a0] [0xc421474080 0xc421474098] [0x8fd520 0x8fd520] 0xc421316720 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Dec 10 14:49:56.565: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-578738756 exec --namespace=e2e-tests-statefulset-m5m6z ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec 10 14:49:56.642: INFO: rc: 1
Dec 10 14:49:56.642: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-578738756 exec --namespace=e2e-tests-statefulset-m5m6z ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc4211e31d0 exit status 1 <nil> <nil> true [0xc4214740a8 0xc4214740c0 0xc4214740d8] [0xc4214740a8 0xc4214740c0 0xc4214740d8] [0xc4214740b8 0xc4214740d0] [0x8fd520 0x8fd520] 0xc421316840 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Dec 10 14:50:06.643: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-578738756 exec --namespace=e2e-tests-statefulset-m5m6z ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec 10 14:50:06.717: INFO: rc: 1
Dec 10 14:50:06.717: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-578738756 exec --namespace=e2e-tests-statefulset-m5m6z ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc4211e37a0 exit status 1 <nil> <nil> true [0xc4214740e0 0xc4214740f8 0xc421474110] [0xc4214740e0 0xc4214740f8 0xc421474110] [0xc4214740f0 0xc421474108] [0x8fd520 0x8fd520] 0xc421316960 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Dec 10 14:50:16.717: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-578738756 exec --namespace=e2e-tests-statefulset-m5m6z ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec 10 14:50:16.800: INFO: rc: 1
Dec 10 14:50:16.800: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-578738756 exec --namespace=e2e-tests-statefulset-m5m6z ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc4211f20c0 exit status 1 <nil> <nil> true [0xc420ed8338 0xc420ed83c8 0xc420ed8458] [0xc420ed8338 0xc420ed83c8 0xc420ed8458] [0xc420ed83a8 0xc420ed8440] [0x8fd520 0x8fd520] 0xc421a18780 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Dec 10 14:50:26.800: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-578738756 exec --namespace=e2e-tests-statefulset-m5m6z ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec 10 14:50:26.878: INFO: rc: 1
Dec 10 14:50:26.878: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-578738756 exec --namespace=e2e-tests-statefulset-m5m6z ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc4211e3ce0 exit status 1 <nil> <nil> true [0xc421474118 0xc421474130 0xc421474148] [0xc421474118 0xc421474130 0xc421474148] [0xc421474128 0xc421474140] [0x8fd520 0x8fd520] 0xc421316ae0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Dec 10 14:50:36.878: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-578738756 exec --namespace=e2e-tests-statefulset-m5m6z ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec 10 14:50:36.954: INFO: rc: 1
Dec 10 14:50:36.954: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-578738756 exec --namespace=e2e-tests-statefulset-m5m6z ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc420de2240 exit status 1 <nil> <nil> true [0xc421474150 0xc421474168 0xc421474180] [0xc421474150 0xc421474168 0xc421474180] [0xc421474160 0xc421474178] [0x8fd520 0x8fd520] 0xc421316c60 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Dec 10 14:50:46.954: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-578738756 exec --namespace=e2e-tests-statefulset-m5m6z ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec 10 14:50:47.043: INFO: rc: 1
Dec 10 14:50:47.043: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-578738756 exec --namespace=e2e-tests-statefulset-m5m6z ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc420d483f0 exit status 1 <nil> <nil> true [0xc421474008 0xc421474020 0xc421474038] [0xc421474008 0xc421474020 0xc421474038] [0xc421474018 0xc421474030] [0x8fd520 0x8fd520] 0xc4213164e0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Dec 10 14:50:57.043: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-578738756 exec --namespace=e2e-tests-statefulset-m5m6z ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec 10 14:50:57.121: INFO: rc: 1
Dec 10 14:50:57.121: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-578738756 exec --namespace=e2e-tests-statefulset-m5m6z ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc420d48de0 exit status 1 <nil> <nil> true [0xc421474040 0xc421474058 0xc421474070] [0xc421474040 0xc421474058 0xc421474070] [0xc421474050 0xc421474068] [0x8fd520 0x8fd520] 0xc421316600 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Dec 10 14:51:07.122: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-578738756 exec --namespace=e2e-tests-statefulset-m5m6z ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec 10 14:51:07.213: INFO: rc: 1
Dec 10 14:51:07.213: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-578738756 exec --namespace=e2e-tests-statefulset-m5m6z ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc4211e23c0 exit status 1 <nil> <nil> true [0xc420ed8000 0xc420ed8028 0xc420ed8050] [0xc420ed8000 0xc420ed8028 0xc420ed8050] [0xc420ed8020 0xc420ed8040] [0x8fd520 0x8fd520] 0xc421a18060 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Dec 10 14:51:17.214: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-578738756 exec --namespace=e2e-tests-statefulset-m5m6z ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec 10 14:51:17.302: INFO: rc: 1
Dec 10 14:51:17.302: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-578738756 exec --namespace=e2e-tests-statefulset-m5m6z ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc420d49260 exit status 1 <nil> <nil> true [0xc421474078 0xc421474090 0xc4214740a8] [0xc421474078 0xc421474090 0xc4214740a8] [0xc421474088 0xc4214740a0] [0x8fd520 0x8fd520] 0xc421316720 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Dec 10 14:51:27.303: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-578738756 exec --namespace=e2e-tests-statefulset-m5m6z ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec 10 14:51:27.385: INFO: rc: 1
Dec 10 14:51:27.385: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-578738756 exec --namespace=e2e-tests-statefulset-m5m6z ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc4211e2810 exit status 1 <nil> <nil> true [0xc420ed8070 0xc420ed80a0 0xc420ed80f0] [0xc420ed8070 0xc420ed80a0 0xc420ed80f0] [0xc420ed8088 0xc420ed80c0] [0x8fd520 0x8fd520] 0xc421a18180 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Dec 10 14:51:37.385: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-578738756 exec --namespace=e2e-tests-statefulset-m5m6z ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec 10 14:51:37.463: INFO: rc: 1
Dec 10 14:51:37.463: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-578738756 exec --namespace=e2e-tests-statefulset-m5m6z ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc420d49860 exit status 1 <nil> <nil> true [0xc4214740b0 0xc4214740c8 0xc4214740e0] [0xc4214740b0 0xc4214740c8 0xc4214740e0] [0xc4214740c0 0xc4214740d8] [0x8fd520 0x8fd520] 0xc421316840 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1

Dec 10 14:51:47.463: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-578738756 exec --namespace=e2e-tests-statefulset-m5m6z ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec 10 14:51:47.552: INFO: rc: 1
Dec 10 14:51:47.552: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: 
Dec 10 14:51:47.552: INFO: Scaling statefulset ss to 0
Dec 10 14:51:47.567: INFO: Waiting for statefulset status.replicas updated to 0
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Dec 10 14:51:47.570: INFO: Deleting all statefulset in ns e2e-tests-statefulset-m5m6z
Dec 10 14:51:47.573: INFO: Scaling statefulset ss to 0
Dec 10 14:51:47.582: INFO: Waiting for statefulset status.replicas updated to 0
Dec 10 14:51:47.584: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 10 14:51:47.599: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-m5m6z" for this suite.
Dec 10 14:51:53.620: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 14:51:53.701: INFO: namespace: e2e-tests-statefulset-m5m6z, resource: bindings, ignored listing per whitelist
Dec 10 14:51:53.727: INFO: namespace e2e-tests-statefulset-m5m6z deletion completed in 6.122398111s

• [SLOW TEST:370.484 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    Burst scaling should run to completion even with unhealthy pods [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 10 14:51:53.728: INFO: >>> kubeConfig: /tmp/kubeconfig-578738756
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:293
[It] should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a replication controller
Dec 10 14:51:53.793: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-578738756 create -f - --namespace=e2e-tests-kubectl-7pcsv'
Dec 10 14:51:54.073: INFO: stderr: ""
Dec 10 14:51:54.073: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Dec 10 14:51:54.073: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-578738756 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-7pcsv'
Dec 10 14:51:54.167: INFO: stderr: ""
Dec 10 14:51:54.167: INFO: stdout: "update-demo-nautilus-24fr5 update-demo-nautilus-95tcs "
Dec 10 14:51:54.167: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-578738756 get pods update-demo-nautilus-24fr5 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-7pcsv'
Dec 10 14:51:54.260: INFO: stderr: ""
Dec 10 14:51:54.260: INFO: stdout: ""
Dec 10 14:51:54.260: INFO: update-demo-nautilus-24fr5 is created but not running
Dec 10 14:51:59.260: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-578738756 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-7pcsv'
Dec 10 14:51:59.354: INFO: stderr: ""
Dec 10 14:51:59.355: INFO: stdout: "update-demo-nautilus-24fr5 update-demo-nautilus-95tcs "
Dec 10 14:51:59.355: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-578738756 get pods update-demo-nautilus-24fr5 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-7pcsv'
Dec 10 14:51:59.438: INFO: stderr: ""
Dec 10 14:51:59.438: INFO: stdout: "true"
Dec 10 14:51:59.439: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-578738756 get pods update-demo-nautilus-24fr5 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-7pcsv'
Dec 10 14:51:59.543: INFO: stderr: ""
Dec 10 14:51:59.544: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Dec 10 14:51:59.544: INFO: validating pod update-demo-nautilus-24fr5
Dec 10 14:51:59.549: INFO: got data: {
  "image": "nautilus.jpg"
}

Dec 10 14:51:59.549: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Dec 10 14:51:59.549: INFO: update-demo-nautilus-24fr5 is verified up and running
Dec 10 14:51:59.549: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-578738756 get pods update-demo-nautilus-95tcs -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-7pcsv'
Dec 10 14:51:59.642: INFO: stderr: ""
Dec 10 14:51:59.642: INFO: stdout: "true"
Dec 10 14:51:59.643: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-578738756 get pods update-demo-nautilus-95tcs -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-7pcsv'
Dec 10 14:51:59.725: INFO: stderr: ""
Dec 10 14:51:59.725: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Dec 10 14:51:59.725: INFO: validating pod update-demo-nautilus-95tcs
Dec 10 14:51:59.732: INFO: got data: {
  "image": "nautilus.jpg"
}

Dec 10 14:51:59.732: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Dec 10 14:51:59.732: INFO: update-demo-nautilus-95tcs is verified up and running
STEP: using delete to clean up resources
Dec 10 14:51:59.732: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-578738756 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-7pcsv'
Dec 10 14:51:59.820: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Dec 10 14:51:59.820: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Dec 10 14:51:59.820: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-578738756 get rc,svc -l name=update-demo --no-headers --namespace=e2e-tests-kubectl-7pcsv'
Dec 10 14:51:59.949: INFO: stderr: "No resources found.\n"
Dec 10 14:51:59.949: INFO: stdout: ""
Dec 10 14:51:59.949: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-578738756 get pods -l name=update-demo --namespace=e2e-tests-kubectl-7pcsv -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Dec 10 14:52:00.100: INFO: stderr: ""
Dec 10 14:52:00.100: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 10 14:52:00.100: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-7pcsv" for this suite.
Dec 10 14:52:22.127: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 14:52:22.160: INFO: namespace: e2e-tests-kubectl-7pcsv, resource: bindings, ignored listing per whitelist
Dec 10 14:52:22.231: INFO: namespace e2e-tests-kubectl-7pcsv deletion completed in 22.124943238s

• [SLOW TEST:28.503 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Update Demo
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create and stop a replication controller  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 10 14:52:22.232: INFO: >>> kubeConfig: /tmp/kubeconfig-578738756
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-tvkrl
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Dec 10 14:52:22.299: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Dec 10 14:52:42.395: INFO: ExecWithOptions {Command:[/bin/sh -c timeout -t 15 curl -g -q -s --connect-timeout 1 http://10.233.122.195:8080/hostName | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-tvkrl PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 10 14:52:42.395: INFO: >>> kubeConfig: /tmp/kubeconfig-578738756
Dec 10 14:52:42.509: INFO: Found all expected endpoints: [netserver-0]
Dec 10 14:52:42.513: INFO: ExecWithOptions {Command:[/bin/sh -c timeout -t 15 curl -g -q -s --connect-timeout 1 http://10.233.64.139:8080/hostName | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-tvkrl PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 10 14:52:42.513: INFO: >>> kubeConfig: /tmp/kubeconfig-578738756
Dec 10 14:52:42.638: INFO: Found all expected endpoints: [netserver-1]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 10 14:52:42.638: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-tvkrl" for this suite.
Dec 10 14:53:04.664: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 14:53:04.789: INFO: namespace: e2e-tests-pod-network-test-tvkrl, resource: bindings, ignored listing per whitelist
Dec 10 14:53:04.789: INFO: namespace e2e-tests-pod-network-test-tvkrl deletion completed in 22.146442362s

• [SLOW TEST:42.558 seconds]
[sig-network] Networking
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: http [NodeConformance] [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[k8s.io] Probing container 
  should have monotonically increasing restart count [Slow][NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 10 14:53:04.789: INFO: >>> kubeConfig: /tmp/kubeconfig-578738756
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should have monotonically increasing restart count [Slow][NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-http in namespace e2e-tests-container-probe-xv4ng
Dec 10 14:53:06.877: INFO: Started pod liveness-http in namespace e2e-tests-container-probe-xv4ng
STEP: checking the pod's current state and verifying that restartCount is present
Dec 10 14:53:06.880: INFO: Initial restart count of pod liveness-http is 0
Dec 10 14:53:24.933: INFO: Restart count of pod e2e-tests-container-probe-xv4ng/liveness-http is now 1 (18.05267978s elapsed)
Dec 10 14:53:44.987: INFO: Restart count of pod e2e-tests-container-probe-xv4ng/liveness-http is now 2 (38.107017147s elapsed)
Dec 10 14:54:05.044: INFO: Restart count of pod e2e-tests-container-probe-xv4ng/liveness-http is now 3 (58.163817705s elapsed)
Dec 10 14:54:25.098: INFO: Restart count of pod e2e-tests-container-probe-xv4ng/liveness-http is now 4 (1m18.217649345s elapsed)
Dec 10 14:55:35.296: INFO: Restart count of pod e2e-tests-container-probe-xv4ng/liveness-http is now 5 (2m28.415833753s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 10 14:55:35.311: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-xv4ng" for this suite.
Dec 10 14:55:41.330: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 14:55:41.359: INFO: namespace: e2e-tests-container-probe-xv4ng, resource: bindings, ignored listing per whitelist
Dec 10 14:55:41.443: INFO: namespace e2e-tests-container-probe-xv4ng deletion completed in 6.128327108s

• [SLOW TEST:156.654 seconds]
[k8s.io] Probing container
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should have monotonically increasing restart count [Slow][NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl logs 
  should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 10 14:55:41.443: INFO: >>> kubeConfig: /tmp/kubeconfig-578738756
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Kubectl logs
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1083
STEP: creating an rc
Dec 10 14:55:41.507: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-578738756 create -f - --namespace=e2e-tests-kubectl-486c7'
Dec 10 14:55:41.698: INFO: stderr: ""
Dec 10 14:55:41.698: INFO: stdout: "replicationcontroller/redis-master created\n"
[It] should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Waiting for Redis master to start.
Dec 10 14:55:42.703: INFO: Selector matched 1 pods for map[app:redis]
Dec 10 14:55:42.703: INFO: Found 0 / 1
Dec 10 14:55:43.702: INFO: Selector matched 1 pods for map[app:redis]
Dec 10 14:55:43.702: INFO: Found 1 / 1
Dec 10 14:55:43.702: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Dec 10 14:55:43.705: INFO: Selector matched 1 pods for map[app:redis]
Dec 10 14:55:43.705: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
STEP: checking for a matching strings
Dec 10 14:55:43.705: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-578738756 logs redis-master-4hwxt redis-master --namespace=e2e-tests-kubectl-486c7'
Dec 10 14:55:43.813: INFO: stderr: ""
Dec 10 14:55:43.813: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 10 Dec 14:55:42.827 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 10 Dec 14:55:42.827 # Server started, Redis version 3.2.12\n1:M 10 Dec 14:55:42.827 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 10 Dec 14:55:42.827 * The server is now ready to accept connections on port 6379\n"
STEP: limiting log lines
Dec 10 14:55:43.813: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-578738756 log redis-master-4hwxt redis-master --namespace=e2e-tests-kubectl-486c7 --tail=1'
Dec 10 14:55:43.925: INFO: stderr: ""
Dec 10 14:55:43.925: INFO: stdout: "1:M 10 Dec 14:55:42.827 * The server is now ready to accept connections on port 6379\n"
STEP: limiting log bytes
Dec 10 14:55:43.925: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-578738756 log redis-master-4hwxt redis-master --namespace=e2e-tests-kubectl-486c7 --limit-bytes=1'
Dec 10 14:55:44.026: INFO: stderr: ""
Dec 10 14:55:44.026: INFO: stdout: " "
STEP: exposing timestamps
Dec 10 14:55:44.026: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-578738756 log redis-master-4hwxt redis-master --namespace=e2e-tests-kubectl-486c7 --tail=1 --timestamps'
Dec 10 14:55:44.122: INFO: stderr: ""
Dec 10 14:55:44.122: INFO: stdout: "2018-12-10T14:55:42.828441881Z 1:M 10 Dec 14:55:42.827 * The server is now ready to accept connections on port 6379\n"
STEP: restricting to a time range
Dec 10 14:55:46.622: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-578738756 log redis-master-4hwxt redis-master --namespace=e2e-tests-kubectl-486c7 --since=1s'
Dec 10 14:55:46.725: INFO: stderr: ""
Dec 10 14:55:46.725: INFO: stdout: ""
Dec 10 14:55:46.725: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-578738756 log redis-master-4hwxt redis-master --namespace=e2e-tests-kubectl-486c7 --since=24h'
Dec 10 14:55:46.830: INFO: stderr: ""
Dec 10 14:55:46.830: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 10 Dec 14:55:42.827 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 10 Dec 14:55:42.827 # Server started, Redis version 3.2.12\n1:M 10 Dec 14:55:42.827 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 10 Dec 14:55:42.827 * The server is now ready to accept connections on port 6379\n"
[AfterEach] [k8s.io] Kubectl logs
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1088
STEP: using delete to clean up resources
Dec 10 14:55:46.830: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-578738756 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-486c7'
Dec 10 14:55:46.923: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Dec 10 14:55:46.923: INFO: stdout: "replicationcontroller \"redis-master\" force deleted\n"
Dec 10 14:55:46.923: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-578738756 get rc,svc -l name=nginx --no-headers --namespace=e2e-tests-kubectl-486c7'
Dec 10 14:55:47.011: INFO: stderr: "No resources found.\n"
Dec 10 14:55:47.011: INFO: stdout: ""
Dec 10 14:55:47.012: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-578738756 get pods -l name=nginx --namespace=e2e-tests-kubectl-486c7 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Dec 10 14:55:47.120: INFO: stderr: ""
Dec 10 14:55:47.120: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 10 14:55:47.120: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-486c7" for this suite.
Dec 10 14:55:53.142: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 14:55:53.211: INFO: namespace: e2e-tests-kubectl-486c7, resource: bindings, ignored listing per whitelist
Dec 10 14:55:53.253: INFO: namespace e2e-tests-kubectl-486c7 deletion completed in 6.127250774s

• [SLOW TEST:11.809 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl logs
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should be able to retrieve and filter logs  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl cluster-info 
  should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 10 14:55:53.253: INFO: >>> kubeConfig: /tmp/kubeconfig-578738756
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: validating cluster-info
Dec 10 14:55:53.329: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-578738756 cluster-info'
Dec 10 14:55:53.411: INFO: stderr: ""
Dec 10 14:55:53.411: INFO: stdout: "\x1b[0;32mKubernetes master\x1b[0m is running at \x1b[0;33mhttps://10.233.0.1:443\x1b[0m\n\x1b[0;32mcoredns\x1b[0m is running at \x1b[0;33mhttps://10.233.0.1:443/api/v1/namespaces/kube-system/services/coredns:dns/proxy\x1b[0m\n\x1b[0;32mkubernetes-dashboard\x1b[0m is running at \x1b[0;33mhttps://10.233.0.1:443/api/v1/namespaces/kube-system/services/https:kubernetes-dashboard:/proxy\x1b[0m\n\x1b[0;32mmetrics-server\x1b[0m is running at \x1b[0;33mhttps://10.233.0.1:443/api/v1/namespaces/kube-system/services/https:metrics-server:/proxy\x1b[0m\n\nTo further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 10 14:55:53.411: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-lkwkr" for this suite.
Dec 10 14:55:59.434: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 14:55:59.452: INFO: namespace: e2e-tests-kubectl-lkwkr, resource: bindings, ignored listing per whitelist
Dec 10 14:55:59.549: INFO: namespace e2e-tests-kubectl-lkwkr deletion completed in 6.131278179s

• [SLOW TEST:6.296 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl cluster-info
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should check if Kubernetes master services is included in cluster-info  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 10 14:55:59.550: INFO: >>> kubeConfig: /tmp/kubeconfig-578738756
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with configmap pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-configmap-v5rj
STEP: Creating a pod to test atomic-volume-subpath
Dec 10 14:55:59.631: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-v5rj" in namespace "e2e-tests-subpath-cxbd2" to be "success or failure"
Dec 10 14:55:59.638: INFO: Pod "pod-subpath-test-configmap-v5rj": Phase="Pending", Reason="", readiness=false. Elapsed: 7.343301ms
Dec 10 14:56:01.643: INFO: Pod "pod-subpath-test-configmap-v5rj": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012213121s
Dec 10 14:56:03.648: INFO: Pod "pod-subpath-test-configmap-v5rj": Phase="Running", Reason="", readiness=false. Elapsed: 4.016697693s
Dec 10 14:56:05.652: INFO: Pod "pod-subpath-test-configmap-v5rj": Phase="Running", Reason="", readiness=false. Elapsed: 6.020982873s
Dec 10 14:56:07.662: INFO: Pod "pod-subpath-test-configmap-v5rj": Phase="Running", Reason="", readiness=false. Elapsed: 8.030852229s
Dec 10 14:56:09.666: INFO: Pod "pod-subpath-test-configmap-v5rj": Phase="Running", Reason="", readiness=false. Elapsed: 10.035122802s
Dec 10 14:56:11.670: INFO: Pod "pod-subpath-test-configmap-v5rj": Phase="Running", Reason="", readiness=false. Elapsed: 12.039380362s
Dec 10 14:56:13.675: INFO: Pod "pod-subpath-test-configmap-v5rj": Phase="Running", Reason="", readiness=false. Elapsed: 14.044207834s
Dec 10 14:56:15.680: INFO: Pod "pod-subpath-test-configmap-v5rj": Phase="Running", Reason="", readiness=false. Elapsed: 16.048915621s
Dec 10 14:56:17.689: INFO: Pod "pod-subpath-test-configmap-v5rj": Phase="Running", Reason="", readiness=false. Elapsed: 18.05855058s
Dec 10 14:56:19.694: INFO: Pod "pod-subpath-test-configmap-v5rj": Phase="Running", Reason="", readiness=false. Elapsed: 20.06333941s
Dec 10 14:56:21.699: INFO: Pod "pod-subpath-test-configmap-v5rj": Phase="Running", Reason="", readiness=false. Elapsed: 22.067881181s
Dec 10 14:56:23.703: INFO: Pod "pod-subpath-test-configmap-v5rj": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.072418434s
STEP: Saw pod success
Dec 10 14:56:23.703: INFO: Pod "pod-subpath-test-configmap-v5rj" satisfied condition "success or failure"
Dec 10 14:56:23.706: INFO: Trying to get logs from node conformance-cluster1-k8s-node-2 pod pod-subpath-test-configmap-v5rj container test-container-subpath-configmap-v5rj: <nil>
STEP: delete the pod
Dec 10 14:56:23.731: INFO: Waiting for pod pod-subpath-test-configmap-v5rj to disappear
Dec 10 14:56:23.734: INFO: Pod pod-subpath-test-configmap-v5rj no longer exists
STEP: Deleting pod pod-subpath-test-configmap-v5rj
Dec 10 14:56:23.734: INFO: Deleting pod "pod-subpath-test-configmap-v5rj" in namespace "e2e-tests-subpath-cxbd2"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 10 14:56:23.738: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-cxbd2" for this suite.
Dec 10 14:56:29.756: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 14:56:29.809: INFO: namespace: e2e-tests-subpath-cxbd2, resource: bindings, ignored listing per whitelist
Dec 10 14:56:29.861: INFO: namespace e2e-tests-subpath-cxbd2 deletion completed in 6.119037975s

• [SLOW TEST:30.311 seconds]
[sig-storage] Subpath
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with configmap pod [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 10 14:56:29.861: INFO: >>> kubeConfig: /tmp/kubeconfig-578738756
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-c6b64c1b-fc8b-11e8-a36b-7e9ed3de7210
STEP: Creating a pod to test consume secrets
Dec 10 14:56:29.943: INFO: Waiting up to 5m0s for pod "pod-secrets-c6b74bec-fc8b-11e8-a36b-7e9ed3de7210" in namespace "e2e-tests-secrets-d6n8b" to be "success or failure"
Dec 10 14:56:29.949: INFO: Pod "pod-secrets-c6b74bec-fc8b-11e8-a36b-7e9ed3de7210": Phase="Pending", Reason="", readiness=false. Elapsed: 6.869929ms
Dec 10 14:56:31.954: INFO: Pod "pod-secrets-c6b74bec-fc8b-11e8-a36b-7e9ed3de7210": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.01159999s
STEP: Saw pod success
Dec 10 14:56:31.954: INFO: Pod "pod-secrets-c6b74bec-fc8b-11e8-a36b-7e9ed3de7210" satisfied condition "success or failure"
Dec 10 14:56:31.958: INFO: Trying to get logs from node conformance-cluster1-k8s-node-2 pod pod-secrets-c6b74bec-fc8b-11e8-a36b-7e9ed3de7210 container secret-volume-test: <nil>
STEP: delete the pod
Dec 10 14:56:31.983: INFO: Waiting for pod pod-secrets-c6b74bec-fc8b-11e8-a36b-7e9ed3de7210 to disappear
Dec 10 14:56:31.987: INFO: Pod pod-secrets-c6b74bec-fc8b-11e8-a36b-7e9ed3de7210 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 10 14:56:31.987: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-d6n8b" for this suite.
Dec 10 14:56:38.012: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 14:56:38.018: INFO: namespace: e2e-tests-secrets-d6n8b, resource: bindings, ignored listing per whitelist
Dec 10 14:56:38.116: INFO: namespace e2e-tests-secrets-d6n8b deletion completed in 6.124222365s

• [SLOW TEST:8.255 seconds]
[sig-storage] Secrets
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 10 14:56:38.117: INFO: >>> kubeConfig: /tmp/kubeconfig-578738756
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
Dec 10 14:56:38.177: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 10 14:56:42.303: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-init-container-58gqn" for this suite.
Dec 10 14:57:04.324: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 14:57:04.340: INFO: namespace: e2e-tests-init-container-58gqn, resource: bindings, ignored listing per whitelist
Dec 10 14:57:04.431: INFO: namespace e2e-tests-init-container-58gqn deletion completed in 22.123036942s

• [SLOW TEST:26.314 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl rolling-update 
  should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 10 14:57:04.432: INFO: >>> kubeConfig: /tmp/kubeconfig-578738756
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1306
[It] should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Dec 10 14:57:04.503: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-578738756 run e2e-test-nginx-rc --image=docker.io/library/nginx:1.14-alpine --generator=run/v1 --namespace=e2e-tests-kubectl-6rlz4'
Dec 10 14:57:04.589: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl create instead.\n"
Dec 10 14:57:04.589: INFO: stdout: "replicationcontroller/e2e-test-nginx-rc created\n"
STEP: verifying the rc e2e-test-nginx-rc was created
Dec 10 14:57:04.595: INFO: Waiting for rc e2e-test-nginx-rc to stabilize, generation 1 observed generation 0 spec.replicas 1 status.replicas 0
Dec 10 14:57:04.608: INFO: Waiting for rc e2e-test-nginx-rc to stabilize, generation 1 observed generation 1 spec.replicas 1 status.replicas 0
STEP: rolling-update to same image controller
Dec 10 14:57:04.619: INFO: scanned /root for discovery docs: <nil>
Dec 10 14:57:04.619: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-578738756 rolling-update e2e-test-nginx-rc --update-period=1s --image=docker.io/library/nginx:1.14-alpine --image-pull-policy=IfNotPresent --namespace=e2e-tests-kubectl-6rlz4'
Dec 10 14:57:20.447: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Dec 10 14:57:20.447: INFO: stdout: "Created e2e-test-nginx-rc-37cb1d5de56850f31a8319668919ca3d\nScaling up e2e-test-nginx-rc-37cb1d5de56850f31a8319668919ca3d from 0 to 1, scaling down e2e-test-nginx-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-nginx-rc-37cb1d5de56850f31a8319668919ca3d up to 1\nScaling e2e-test-nginx-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-nginx-rc\nRenaming e2e-test-nginx-rc-37cb1d5de56850f31a8319668919ca3d to e2e-test-nginx-rc\nreplicationcontroller/e2e-test-nginx-rc rolling updated\n"
Dec 10 14:57:20.447: INFO: stdout: "Created e2e-test-nginx-rc-37cb1d5de56850f31a8319668919ca3d\nScaling up e2e-test-nginx-rc-37cb1d5de56850f31a8319668919ca3d from 0 to 1, scaling down e2e-test-nginx-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-nginx-rc-37cb1d5de56850f31a8319668919ca3d up to 1\nScaling e2e-test-nginx-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-nginx-rc\nRenaming e2e-test-nginx-rc-37cb1d5de56850f31a8319668919ca3d to e2e-test-nginx-rc\nreplicationcontroller/e2e-test-nginx-rc rolling updated\n"
STEP: waiting for all containers in run=e2e-test-nginx-rc pods to come up.
Dec 10 14:57:20.447: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-578738756 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l run=e2e-test-nginx-rc --namespace=e2e-tests-kubectl-6rlz4'
Dec 10 14:57:20.543: INFO: stderr: ""
Dec 10 14:57:20.544: INFO: stdout: "e2e-test-nginx-rc-37cb1d5de56850f31a8319668919ca3d-s59zp "
Dec 10 14:57:20.544: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-578738756 get pods e2e-test-nginx-rc-37cb1d5de56850f31a8319668919ca3d-s59zp -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "e2e-test-nginx-rc") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-6rlz4'
Dec 10 14:57:20.624: INFO: stderr: ""
Dec 10 14:57:20.624: INFO: stdout: "true"
Dec 10 14:57:20.624: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-578738756 get pods e2e-test-nginx-rc-37cb1d5de56850f31a8319668919ca3d-s59zp -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "e2e-test-nginx-rc"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-6rlz4'
Dec 10 14:57:20.704: INFO: stderr: ""
Dec 10 14:57:20.704: INFO: stdout: "nginx:1.14-alpine"
Dec 10 14:57:20.704: INFO: e2e-test-nginx-rc-37cb1d5de56850f31a8319668919ca3d-s59zp is verified up and running
[AfterEach] [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1312
Dec 10 14:57:20.704: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-578738756 delete rc e2e-test-nginx-rc --namespace=e2e-tests-kubectl-6rlz4'
Dec 10 14:57:20.791: INFO: stderr: ""
Dec 10 14:57:20.791: INFO: stdout: "replicationcontroller \"e2e-test-nginx-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 10 14:57:20.791: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-6rlz4" for this suite.
Dec 10 14:57:26.814: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 14:57:26.849: INFO: namespace: e2e-tests-kubectl-6rlz4, resource: bindings, ignored listing per whitelist
Dec 10 14:57:26.921: INFO: namespace e2e-tests-kubectl-6rlz4 deletion completed in 6.125073203s

• [SLOW TEST:22.489 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should support rolling-update to same image  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run default 
  should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 10 14:57:26.922: INFO: >>> kubeConfig: /tmp/kubeconfig-578738756
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Kubectl run default
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1210
[It] should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Dec 10 14:57:26.989: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-578738756 run e2e-test-nginx-deployment --image=docker.io/library/nginx:1.14-alpine --namespace=e2e-tests-kubectl-5c7np'
Dec 10 14:57:27.083: INFO: stderr: "kubectl run --generator=deployment/apps.v1beta1 is DEPRECATED and will be removed in a future version. Use kubectl create instead.\n"
Dec 10 14:57:27.083: INFO: stdout: "deployment.apps/e2e-test-nginx-deployment created\n"
STEP: verifying the pod controlled by e2e-test-nginx-deployment gets created
[AfterEach] [k8s.io] Kubectl run default
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1216
Dec 10 14:57:29.094: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-578738756 delete deployment e2e-test-nginx-deployment --namespace=e2e-tests-kubectl-5c7np'
Dec 10 14:57:29.205: INFO: stderr: ""
Dec 10 14:57:29.205: INFO: stdout: "deployment.extensions \"e2e-test-nginx-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 10 14:57:29.205: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-5c7np" for this suite.
Dec 10 14:57:51.228: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 14:57:51.276: INFO: namespace: e2e-tests-kubectl-5c7np, resource: bindings, ignored listing per whitelist
Dec 10 14:57:51.338: INFO: namespace e2e-tests-kubectl-5c7np deletion completed in 22.127087054s

• [SLOW TEST:24.415 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run default
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create an rc or deployment from an image  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 10 14:57:51.338: INFO: >>> kubeConfig: /tmp/kubeconfig-578738756
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Dec 10 14:57:51.415: INFO: Waiting up to 5m0s for pod "downwardapi-volume-f7464c1c-fc8b-11e8-a36b-7e9ed3de7210" in namespace "e2e-tests-downward-api-xmt8c" to be "success or failure"
Dec 10 14:57:51.423: INFO: Pod "downwardapi-volume-f7464c1c-fc8b-11e8-a36b-7e9ed3de7210": Phase="Pending", Reason="", readiness=false. Elapsed: 7.135362ms
Dec 10 14:57:53.432: INFO: Pod "downwardapi-volume-f7464c1c-fc8b-11e8-a36b-7e9ed3de7210": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.016741356s
STEP: Saw pod success
Dec 10 14:57:53.432: INFO: Pod "downwardapi-volume-f7464c1c-fc8b-11e8-a36b-7e9ed3de7210" satisfied condition "success or failure"
Dec 10 14:57:53.436: INFO: Trying to get logs from node conformance-cluster1-k8s-node-2 pod downwardapi-volume-f7464c1c-fc8b-11e8-a36b-7e9ed3de7210 container client-container: <nil>
STEP: delete the pod
Dec 10 14:57:53.460: INFO: Waiting for pod downwardapi-volume-f7464c1c-fc8b-11e8-a36b-7e9ed3de7210 to disappear
Dec 10 14:57:53.463: INFO: Pod downwardapi-volume-f7464c1c-fc8b-11e8-a36b-7e9ed3de7210 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 10 14:57:53.463: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-xmt8c" for this suite.
Dec 10 14:57:59.481: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 14:57:59.515: INFO: namespace: e2e-tests-downward-api-xmt8c, resource: bindings, ignored listing per whitelist
Dec 10 14:57:59.591: INFO: namespace e2e-tests-downward-api-xmt8c deletion completed in 6.12393955s

• [SLOW TEST:8.253 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-api-machinery] Watchers 
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 10 14:57:59.591: INFO: >>> kubeConfig: /tmp/kubeconfig-578738756
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a watch on configmaps
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: closing the watch once it receives two notifications
Dec 10 14:57:59.660: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-6bbhj,SelfLink:/api/v1/namespaces/e2e-tests-watch-6bbhj/configmaps/e2e-watch-test-watch-closed,UID:fc3041fa-fc8b-11e8-8690-fa163e74bd5a,ResourceVersion:21420,Generation:0,CreationTimestamp:2018-12-10 14:57:59 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Dec 10 14:57:59.660: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-6bbhj,SelfLink:/api/v1/namespaces/e2e-tests-watch-6bbhj/configmaps/e2e-watch-test-watch-closed,UID:fc3041fa-fc8b-11e8-8690-fa163e74bd5a,ResourceVersion:21421,Generation:0,CreationTimestamp:2018-12-10 14:57:59 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time, while the watch is closed
STEP: creating a new watch on configmaps from the last resource version observed by the first watch
STEP: deleting the configmap
STEP: Expecting to observe notifications for all changes to the configmap since the first watch closed
Dec 10 14:57:59.679: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-6bbhj,SelfLink:/api/v1/namespaces/e2e-tests-watch-6bbhj/configmaps/e2e-watch-test-watch-closed,UID:fc3041fa-fc8b-11e8-8690-fa163e74bd5a,ResourceVersion:21422,Generation:0,CreationTimestamp:2018-12-10 14:57:59 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Dec 10 14:57:59.680: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-6bbhj,SelfLink:/api/v1/namespaces/e2e-tests-watch-6bbhj/configmaps/e2e-watch-test-watch-closed,UID:fc3041fa-fc8b-11e8-8690-fa163e74bd5a,ResourceVersion:21424,Generation:0,CreationTimestamp:2018-12-10 14:57:59 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 10 14:57:59.680: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-6bbhj" for this suite.
Dec 10 14:58:05.702: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 14:58:05.735: INFO: namespace: e2e-tests-watch-6bbhj, resource: bindings, ignored listing per whitelist
Dec 10 14:58:05.813: INFO: namespace e2e-tests-watch-6bbhj deletion completed in 6.129575212s

• [SLOW TEST:6.222 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 10 14:58:05.814: INFO: >>> kubeConfig: /tmp/kubeconfig-578738756
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-map-ffe6d5b7-fc8b-11e8-a36b-7e9ed3de7210
STEP: Creating a pod to test consume configMaps
Dec 10 14:58:05.897: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-ffe8293c-fc8b-11e8-a36b-7e9ed3de7210" in namespace "e2e-tests-projected-slrdj" to be "success or failure"
Dec 10 14:58:05.903: INFO: Pod "pod-projected-configmaps-ffe8293c-fc8b-11e8-a36b-7e9ed3de7210": Phase="Pending", Reason="", readiness=false. Elapsed: 5.98022ms
Dec 10 14:58:07.908: INFO: Pod "pod-projected-configmaps-ffe8293c-fc8b-11e8-a36b-7e9ed3de7210": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010945951s
STEP: Saw pod success
Dec 10 14:58:07.908: INFO: Pod "pod-projected-configmaps-ffe8293c-fc8b-11e8-a36b-7e9ed3de7210" satisfied condition "success or failure"
Dec 10 14:58:07.912: INFO: Trying to get logs from node conformance-cluster1-k8s-node-2 pod pod-projected-configmaps-ffe8293c-fc8b-11e8-a36b-7e9ed3de7210 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Dec 10 14:58:07.946: INFO: Waiting for pod pod-projected-configmaps-ffe8293c-fc8b-11e8-a36b-7e9ed3de7210 to disappear
Dec 10 14:58:07.949: INFO: Pod pod-projected-configmaps-ffe8293c-fc8b-11e8-a36b-7e9ed3de7210 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 10 14:58:07.949: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-slrdj" for this suite.
Dec 10 14:58:13.973: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 14:58:13.987: INFO: namespace: e2e-tests-projected-slrdj, resource: bindings, ignored listing per whitelist
Dec 10 14:58:14.084: INFO: namespace e2e-tests-projected-slrdj deletion completed in 6.129998704s

• [SLOW TEST:8.270 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 10 14:58:14.084: INFO: >>> kubeConfig: /tmp/kubeconfig-578738756
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test env composition
Dec 10 14:58:14.148: INFO: Waiting up to 5m0s for pod "var-expansion-04d3351f-fc8c-11e8-a36b-7e9ed3de7210" in namespace "e2e-tests-var-expansion-pzrqt" to be "success or failure"
Dec 10 14:58:14.154: INFO: Pod "var-expansion-04d3351f-fc8c-11e8-a36b-7e9ed3de7210": Phase="Pending", Reason="", readiness=false. Elapsed: 6.495688ms
Dec 10 14:58:16.159: INFO: Pod "var-expansion-04d3351f-fc8c-11e8-a36b-7e9ed3de7210": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.011129792s
STEP: Saw pod success
Dec 10 14:58:16.159: INFO: Pod "var-expansion-04d3351f-fc8c-11e8-a36b-7e9ed3de7210" satisfied condition "success or failure"
Dec 10 14:58:16.162: INFO: Trying to get logs from node conformance-cluster1-k8s-node-2 pod var-expansion-04d3351f-fc8c-11e8-a36b-7e9ed3de7210 container dapi-container: <nil>
STEP: delete the pod
Dec 10 14:58:16.187: INFO: Waiting for pod var-expansion-04d3351f-fc8c-11e8-a36b-7e9ed3de7210 to disappear
Dec 10 14:58:16.190: INFO: Pod var-expansion-04d3351f-fc8c-11e8-a36b-7e9ed3de7210 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 10 14:58:16.190: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-var-expansion-pzrqt" for this suite.
Dec 10 14:58:22.208: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 14:58:22.236: INFO: namespace: e2e-tests-var-expansion-pzrqt, resource: bindings, ignored listing per whitelist
Dec 10 14:58:22.340: INFO: namespace e2e-tests-var-expansion-pzrqt deletion completed in 6.145545479s

• [SLOW TEST:8.256 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[k8s.io] Pods 
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 10 14:58:22.340: INFO: >>> kubeConfig: /tmp/kubeconfig-578738756
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating pod
Dec 10 14:58:24.441: INFO: Pod pod-hostip-09c1403d-fc8c-11e8-a36b-7e9ed3de7210 has hostIP: 10.0.0.10
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 10 14:58:24.441: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-4djz5" for this suite.
Dec 10 14:58:46.470: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 14:58:46.554: INFO: namespace: e2e-tests-pods-4djz5, resource: bindings, ignored listing per whitelist
Dec 10 14:58:46.576: INFO: namespace e2e-tests-pods-4djz5 deletion completed in 22.126981506s

• [SLOW TEST:24.236 seconds]
[k8s.io] Pods
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 10 14:58:46.578: INFO: >>> kubeConfig: /tmp/kubeconfig-578738756
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-18341468-fc8c-11e8-a36b-7e9ed3de7210
STEP: Creating a pod to test consume configMaps
Dec 10 14:58:46.665: INFO: Waiting up to 5m0s for pod "pod-configmaps-18352111-fc8c-11e8-a36b-7e9ed3de7210" in namespace "e2e-tests-configmap-sd9kb" to be "success or failure"
Dec 10 14:58:46.672: INFO: Pod "pod-configmaps-18352111-fc8c-11e8-a36b-7e9ed3de7210": Phase="Pending", Reason="", readiness=false. Elapsed: 7.260475ms
Dec 10 14:58:48.677: INFO: Pod "pod-configmaps-18352111-fc8c-11e8-a36b-7e9ed3de7210": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.011708694s
STEP: Saw pod success
Dec 10 14:58:48.677: INFO: Pod "pod-configmaps-18352111-fc8c-11e8-a36b-7e9ed3de7210" satisfied condition "success or failure"
Dec 10 14:58:48.680: INFO: Trying to get logs from node conformance-cluster1-k8s-node-2 pod pod-configmaps-18352111-fc8c-11e8-a36b-7e9ed3de7210 container configmap-volume-test: <nil>
STEP: delete the pod
Dec 10 14:58:48.710: INFO: Waiting for pod pod-configmaps-18352111-fc8c-11e8-a36b-7e9ed3de7210 to disappear
Dec 10 14:58:48.714: INFO: Pod pod-configmaps-18352111-fc8c-11e8-a36b-7e9ed3de7210 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 10 14:58:48.714: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-sd9kb" for this suite.
Dec 10 14:58:54.734: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 14:58:54.754: INFO: namespace: e2e-tests-configmap-sd9kb, resource: bindings, ignored listing per whitelist
Dec 10 14:58:54.850: INFO: namespace e2e-tests-configmap-sd9kb deletion completed in 6.131508373s

• [SLOW TEST:8.272 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 10 14:58:54.851: INFO: >>> kubeConfig: /tmp/kubeconfig-578738756
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-map-1d215f2b-fc8c-11e8-a36b-7e9ed3de7210
STEP: Creating a pod to test consume secrets
Dec 10 14:58:54.933: INFO: Waiting up to 5m0s for pod "pod-secrets-1d22d27c-fc8c-11e8-a36b-7e9ed3de7210" in namespace "e2e-tests-secrets-qgsw7" to be "success or failure"
Dec 10 14:58:54.942: INFO: Pod "pod-secrets-1d22d27c-fc8c-11e8-a36b-7e9ed3de7210": Phase="Pending", Reason="", readiness=false. Elapsed: 9.108073ms
Dec 10 14:58:56.952: INFO: Pod "pod-secrets-1d22d27c-fc8c-11e8-a36b-7e9ed3de7210": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.01879936s
STEP: Saw pod success
Dec 10 14:58:56.952: INFO: Pod "pod-secrets-1d22d27c-fc8c-11e8-a36b-7e9ed3de7210" satisfied condition "success or failure"
Dec 10 14:58:56.957: INFO: Trying to get logs from node conformance-cluster1-k8s-node-2 pod pod-secrets-1d22d27c-fc8c-11e8-a36b-7e9ed3de7210 container secret-volume-test: <nil>
STEP: delete the pod
Dec 10 14:58:56.983: INFO: Waiting for pod pod-secrets-1d22d27c-fc8c-11e8-a36b-7e9ed3de7210 to disappear
Dec 10 14:58:56.986: INFO: Pod pod-secrets-1d22d27c-fc8c-11e8-a36b-7e9ed3de7210 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 10 14:58:56.986: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-qgsw7" for this suite.
Dec 10 14:59:03.004: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 14:59:03.012: INFO: namespace: e2e-tests-secrets-qgsw7, resource: bindings, ignored listing per whitelist
Dec 10 14:59:03.123: INFO: namespace e2e-tests-secrets-qgsw7 deletion completed in 6.133487165s

• [SLOW TEST:8.272 seconds]
[sig-storage] Secrets
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-auth] ServiceAccounts 
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 10 14:59:03.125: INFO: >>> kubeConfig: /tmp/kubeconfig-578738756
STEP: Building a namespace api object, basename svcaccounts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: getting the auto-created API token
Dec 10 14:59:03.720: INFO: created pod pod-service-account-defaultsa
Dec 10 14:59:03.720: INFO: pod pod-service-account-defaultsa service account token volume mount: true
Dec 10 14:59:03.727: INFO: created pod pod-service-account-mountsa
Dec 10 14:59:03.727: INFO: pod pod-service-account-mountsa service account token volume mount: true
Dec 10 14:59:03.737: INFO: created pod pod-service-account-nomountsa
Dec 10 14:59:03.737: INFO: pod pod-service-account-nomountsa service account token volume mount: false
Dec 10 14:59:03.746: INFO: created pod pod-service-account-defaultsa-mountspec
Dec 10 14:59:03.746: INFO: pod pod-service-account-defaultsa-mountspec service account token volume mount: true
Dec 10 14:59:03.754: INFO: created pod pod-service-account-mountsa-mountspec
Dec 10 14:59:03.754: INFO: pod pod-service-account-mountsa-mountspec service account token volume mount: true
Dec 10 14:59:03.761: INFO: created pod pod-service-account-nomountsa-mountspec
Dec 10 14:59:03.761: INFO: pod pod-service-account-nomountsa-mountspec service account token volume mount: true
Dec 10 14:59:03.770: INFO: created pod pod-service-account-defaultsa-nomountspec
Dec 10 14:59:03.770: INFO: pod pod-service-account-defaultsa-nomountspec service account token volume mount: false
Dec 10 14:59:03.787: INFO: created pod pod-service-account-mountsa-nomountspec
Dec 10 14:59:03.787: INFO: pod pod-service-account-mountsa-nomountspec service account token volume mount: false
Dec 10 14:59:03.799: INFO: created pod pod-service-account-nomountsa-nomountspec
Dec 10 14:59:03.799: INFO: pod pod-service-account-nomountsa-nomountspec service account token volume mount: false
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 10 14:59:03.799: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-svcaccounts-fvs42" for this suite.
Dec 10 14:59:09.826: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 14:59:09.870: INFO: namespace: e2e-tests-svcaccounts-fvs42, resource: bindings, ignored listing per whitelist
Dec 10 14:59:09.942: INFO: namespace e2e-tests-svcaccounts-fvs42 deletion completed in 6.136336061s

• [SLOW TEST:6.817 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:22
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 10 14:59:09.943: INFO: >>> kubeConfig: /tmp/kubeconfig-578738756
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-lb4ss
[It] should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a new StaefulSet
Dec 10 14:59:10.020: INFO: Found 0 stateful pods, waiting for 3
Dec 10 14:59:20.032: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Dec 10 14:59:20.032: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Dec 10 14:59:20.032: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Updating stateful set template: update image from docker.io/library/nginx:1.14-alpine to docker.io/library/nginx:1.15-alpine
Dec 10 14:59:20.064: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Not applying an update when the partition is greater than the number of replicas
STEP: Performing a canary update
Dec 10 14:59:30.106: INFO: Updating stateful set ss2
Dec 10 14:59:30.112: INFO: Waiting for Pod e2e-tests-statefulset-lb4ss/ss2-2 to have revision ss2-c79899b9 update revision ss2-787997d666
STEP: Restoring Pods to the correct revision when they are deleted
Dec 10 14:59:40.180: INFO: Found 2 stateful pods, waiting for 3
Dec 10 14:59:50.190: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Dec 10 14:59:50.190: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Dec 10 14:59:50.190: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Performing a phased rolling update
Dec 10 14:59:50.216: INFO: Updating stateful set ss2
Dec 10 14:59:50.222: INFO: Waiting for Pod e2e-tests-statefulset-lb4ss/ss2-1 to have revision ss2-c79899b9 update revision ss2-787997d666
Dec 10 15:00:00.256: INFO: Updating stateful set ss2
Dec 10 15:00:00.263: INFO: Waiting for StatefulSet e2e-tests-statefulset-lb4ss/ss2 to complete update
Dec 10 15:00:00.263: INFO: Waiting for Pod e2e-tests-statefulset-lb4ss/ss2-0 to have revision ss2-c79899b9 update revision ss2-787997d666
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Dec 10 15:00:10.277: INFO: Deleting all statefulset in ns e2e-tests-statefulset-lb4ss
Dec 10 15:00:10.280: INFO: Scaling statefulset ss2 to 0
Dec 10 15:00:30.297: INFO: Waiting for statefulset status.replicas updated to 0
Dec 10 15:00:30.301: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 10 15:00:30.323: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-lb4ss" for this suite.
Dec 10 15:00:36.343: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 15:00:36.380: INFO: namespace: e2e-tests-statefulset-lb4ss, resource: bindings, ignored listing per whitelist
Dec 10 15:00:36.453: INFO: namespace e2e-tests-statefulset-lb4ss deletion completed in 6.125360153s

• [SLOW TEST:86.510 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should perform canary updates and phased rolling updates of template modifications [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 10 15:00:36.453: INFO: >>> kubeConfig: /tmp/kubeconfig-578738756
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-map-59b101d9-fc8c-11e8-a36b-7e9ed3de7210
STEP: Creating a pod to test consume secrets
Dec 10 15:00:36.535: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-59b21086-fc8c-11e8-a36b-7e9ed3de7210" in namespace "e2e-tests-projected-kxkpx" to be "success or failure"
Dec 10 15:00:36.542: INFO: Pod "pod-projected-secrets-59b21086-fc8c-11e8-a36b-7e9ed3de7210": Phase="Pending", Reason="", readiness=false. Elapsed: 6.72616ms
Dec 10 15:00:38.546: INFO: Pod "pod-projected-secrets-59b21086-fc8c-11e8-a36b-7e9ed3de7210": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.011220872s
STEP: Saw pod success
Dec 10 15:00:38.547: INFO: Pod "pod-projected-secrets-59b21086-fc8c-11e8-a36b-7e9ed3de7210" satisfied condition "success or failure"
Dec 10 15:00:38.550: INFO: Trying to get logs from node conformance-cluster1-k8s-node-2 pod pod-projected-secrets-59b21086-fc8c-11e8-a36b-7e9ed3de7210 container projected-secret-volume-test: <nil>
STEP: delete the pod
Dec 10 15:00:38.574: INFO: Waiting for pod pod-projected-secrets-59b21086-fc8c-11e8-a36b-7e9ed3de7210 to disappear
Dec 10 15:00:38.578: INFO: Pod pod-projected-secrets-59b21086-fc8c-11e8-a36b-7e9ed3de7210 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 10 15:00:38.578: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-kxkpx" for this suite.
Dec 10 15:00:44.602: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 15:00:44.636: INFO: namespace: e2e-tests-projected-kxkpx, resource: bindings, ignored listing per whitelist
Dec 10 15:00:44.709: INFO: namespace e2e-tests-projected-kxkpx deletion completed in 6.126966303s

• [SLOW TEST:8.256 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Projected 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 10 15:00:44.710: INFO: >>> kubeConfig: /tmp/kubeconfig-578738756
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name projected-secret-test-5e9c2304-fc8c-11e8-a36b-7e9ed3de7210
STEP: Creating a pod to test consume secrets
Dec 10 15:00:44.790: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-5e9d92e7-fc8c-11e8-a36b-7e9ed3de7210" in namespace "e2e-tests-projected-dz4ch" to be "success or failure"
Dec 10 15:00:44.797: INFO: Pod "pod-projected-secrets-5e9d92e7-fc8c-11e8-a36b-7e9ed3de7210": Phase="Pending", Reason="", readiness=false. Elapsed: 6.696679ms
Dec 10 15:00:46.801: INFO: Pod "pod-projected-secrets-5e9d92e7-fc8c-11e8-a36b-7e9ed3de7210": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010807578s
STEP: Saw pod success
Dec 10 15:00:46.801: INFO: Pod "pod-projected-secrets-5e9d92e7-fc8c-11e8-a36b-7e9ed3de7210" satisfied condition "success or failure"
Dec 10 15:00:46.805: INFO: Trying to get logs from node conformance-cluster1-k8s-node-2 pod pod-projected-secrets-5e9d92e7-fc8c-11e8-a36b-7e9ed3de7210 container secret-volume-test: <nil>
STEP: delete the pod
Dec 10 15:00:46.832: INFO: Waiting for pod pod-projected-secrets-5e9d92e7-fc8c-11e8-a36b-7e9ed3de7210 to disappear
Dec 10 15:00:46.836: INFO: Pod pod-projected-secrets-5e9d92e7-fc8c-11e8-a36b-7e9ed3de7210 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 10 15:00:46.836: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-dz4ch" for this suite.
Dec 10 15:00:52.856: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 15:00:52.917: INFO: namespace: e2e-tests-projected-dz4ch, resource: bindings, ignored listing per whitelist
Dec 10 15:00:52.975: INFO: namespace e2e-tests-projected-dz4ch deletion completed in 6.134536339s

• [SLOW TEST:8.265 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Projected 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 10 15:00:52.975: INFO: >>> kubeConfig: /tmp/kubeconfig-578738756
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Dec 10 15:00:53.064: INFO: Waiting up to 5m0s for pod "downwardapi-volume-638b9757-fc8c-11e8-a36b-7e9ed3de7210" in namespace "e2e-tests-projected-xhv4f" to be "success or failure"
Dec 10 15:00:53.078: INFO: Pod "downwardapi-volume-638b9757-fc8c-11e8-a36b-7e9ed3de7210": Phase="Pending", Reason="", readiness=false. Elapsed: 14.658873ms
Dec 10 15:00:55.084: INFO: Pod "downwardapi-volume-638b9757-fc8c-11e8-a36b-7e9ed3de7210": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.020302671s
STEP: Saw pod success
Dec 10 15:00:55.084: INFO: Pod "downwardapi-volume-638b9757-fc8c-11e8-a36b-7e9ed3de7210" satisfied condition "success or failure"
Dec 10 15:00:55.089: INFO: Trying to get logs from node conformance-cluster1-k8s-node-1 pod downwardapi-volume-638b9757-fc8c-11e8-a36b-7e9ed3de7210 container client-container: <nil>
STEP: delete the pod
Dec 10 15:00:55.114: INFO: Waiting for pod downwardapi-volume-638b9757-fc8c-11e8-a36b-7e9ed3de7210 to disappear
Dec 10 15:00:55.120: INFO: Pod downwardapi-volume-638b9757-fc8c-11e8-a36b-7e9ed3de7210 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 10 15:00:55.120: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-xhv4f" for this suite.
Dec 10 15:01:01.147: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 15:01:01.162: INFO: namespace: e2e-tests-projected-xhv4f, resource: bindings, ignored listing per whitelist
Dec 10 15:01:01.268: INFO: namespace e2e-tests-projected-xhv4f deletion completed in 6.143493456s

• [SLOW TEST:8.293 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 10 15:01:01.269: INFO: >>> kubeConfig: /tmp/kubeconfig-578738756
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-687ad1ca-fc8c-11e8-a36b-7e9ed3de7210
STEP: Creating a pod to test consume secrets
Dec 10 15:01:01.346: INFO: Waiting up to 5m0s for pod "pod-secrets-687c1d44-fc8c-11e8-a36b-7e9ed3de7210" in namespace "e2e-tests-secrets-jvzn4" to be "success or failure"
Dec 10 15:01:01.351: INFO: Pod "pod-secrets-687c1d44-fc8c-11e8-a36b-7e9ed3de7210": Phase="Pending", Reason="", readiness=false. Elapsed: 5.269803ms
Dec 10 15:01:03.356: INFO: Pod "pod-secrets-687c1d44-fc8c-11e8-a36b-7e9ed3de7210": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009909012s
STEP: Saw pod success
Dec 10 15:01:03.356: INFO: Pod "pod-secrets-687c1d44-fc8c-11e8-a36b-7e9ed3de7210" satisfied condition "success or failure"
Dec 10 15:01:03.360: INFO: Trying to get logs from node conformance-cluster1-k8s-node-2 pod pod-secrets-687c1d44-fc8c-11e8-a36b-7e9ed3de7210 container secret-volume-test: <nil>
STEP: delete the pod
Dec 10 15:01:03.390: INFO: Waiting for pod pod-secrets-687c1d44-fc8c-11e8-a36b-7e9ed3de7210 to disappear
Dec 10 15:01:03.393: INFO: Pod pod-secrets-687c1d44-fc8c-11e8-a36b-7e9ed3de7210 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 10 15:01:03.393: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-jvzn4" for this suite.
Dec 10 15:01:09.413: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 15:01:09.427: INFO: namespace: e2e-tests-secrets-jvzn4, resource: bindings, ignored listing per whitelist
Dec 10 15:01:09.525: INFO: namespace e2e-tests-secrets-jvzn4 deletion completed in 6.127677705s

• [SLOW TEST:8.256 seconds]
[sig-storage] Secrets
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-network] Services 
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 10 15:01:09.526: INFO: >>> kubeConfig: /tmp/kubeconfig-578738756
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:83
[It] should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating service endpoint-test2 in namespace e2e-tests-services-kngbc
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-kngbc to expose endpoints map[]
Dec 10 15:01:09.612: INFO: Get endpoints failed (3.234325ms elapsed, ignoring for 5s): endpoints "endpoint-test2" not found
Dec 10 15:01:10.616: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-kngbc exposes endpoints map[] (1.007683687s elapsed)
STEP: Creating pod pod1 in namespace e2e-tests-services-kngbc
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-kngbc to expose endpoints map[pod1:[80]]
Dec 10 15:01:12.658: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-kngbc exposes endpoints map[pod1:[80]] (2.032697655s elapsed)
STEP: Creating pod pod2 in namespace e2e-tests-services-kngbc
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-kngbc to expose endpoints map[pod1:[80] pod2:[80]]
Dec 10 15:01:14.700: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-kngbc exposes endpoints map[pod1:[80] pod2:[80]] (2.036650458s elapsed)
STEP: Deleting pod pod1 in namespace e2e-tests-services-kngbc
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-kngbc to expose endpoints map[pod2:[80]]
Dec 10 15:01:15.724: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-kngbc exposes endpoints map[pod2:[80]] (1.015465835s elapsed)
STEP: Deleting pod pod2 in namespace e2e-tests-services-kngbc
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-kngbc to expose endpoints map[]
Dec 10 15:01:15.737: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-kngbc exposes endpoints map[] (3.769969ms elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 10 15:01:15.765: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-services-kngbc" for this suite.
Dec 10 15:01:37.785: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 15:01:37.825: INFO: namespace: e2e-tests-services-kngbc, resource: bindings, ignored listing per whitelist
Dec 10 15:01:37.894: INFO: namespace e2e-tests-services-kngbc deletion completed in 22.123507931s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:88

• [SLOW TEST:28.368 seconds]
[sig-network] Services
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on default medium should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 10 15:01:37.894: INFO: >>> kubeConfig: /tmp/kubeconfig-578738756
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on default medium should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir volume type on node default medium
Dec 10 15:01:37.973: INFO: Waiting up to 5m0s for pod "pod-7e505ace-fc8c-11e8-a36b-7e9ed3de7210" in namespace "e2e-tests-emptydir-wm9pk" to be "success or failure"
Dec 10 15:01:37.978: INFO: Pod "pod-7e505ace-fc8c-11e8-a36b-7e9ed3de7210": Phase="Pending", Reason="", readiness=false. Elapsed: 5.013803ms
Dec 10 15:01:39.983: INFO: Pod "pod-7e505ace-fc8c-11e8-a36b-7e9ed3de7210": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009972932s
STEP: Saw pod success
Dec 10 15:01:39.983: INFO: Pod "pod-7e505ace-fc8c-11e8-a36b-7e9ed3de7210" satisfied condition "success or failure"
Dec 10 15:01:39.987: INFO: Trying to get logs from node conformance-cluster1-k8s-node-2 pod pod-7e505ace-fc8c-11e8-a36b-7e9ed3de7210 container test-container: <nil>
STEP: delete the pod
Dec 10 15:01:40.016: INFO: Waiting for pod pod-7e505ace-fc8c-11e8-a36b-7e9ed3de7210 to disappear
Dec 10 15:01:40.019: INFO: Pod pod-7e505ace-fc8c-11e8-a36b-7e9ed3de7210 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 10 15:01:40.019: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-wm9pk" for this suite.
Dec 10 15:01:46.038: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 15:01:46.165: INFO: namespace: e2e-tests-emptydir-wm9pk, resource: bindings, ignored listing per whitelist
Dec 10 15:01:46.165: INFO: namespace e2e-tests-emptydir-wm9pk deletion completed in 6.141442236s

• [SLOW TEST:8.271 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  volume on default medium should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should scale a replication controller  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 10 15:01:46.165: INFO: >>> kubeConfig: /tmp/kubeconfig-578738756
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:293
[It] should scale a replication controller  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a replication controller
Dec 10 15:01:46.222: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-578738756 create -f - --namespace=e2e-tests-kubectl-f98t8'
Dec 10 15:01:46.389: INFO: stderr: ""
Dec 10 15:01:46.389: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Dec 10 15:01:46.389: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-578738756 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-f98t8'
Dec 10 15:01:46.488: INFO: stderr: ""
Dec 10 15:01:46.488: INFO: stdout: "update-demo-nautilus-hn7mk update-demo-nautilus-tztpk "
Dec 10 15:01:46.488: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-578738756 get pods update-demo-nautilus-hn7mk -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-f98t8'
Dec 10 15:01:46.579: INFO: stderr: ""
Dec 10 15:01:46.579: INFO: stdout: ""
Dec 10 15:01:46.579: INFO: update-demo-nautilus-hn7mk is created but not running
Dec 10 15:01:51.579: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-578738756 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-f98t8'
Dec 10 15:01:51.666: INFO: stderr: ""
Dec 10 15:01:51.666: INFO: stdout: "update-demo-nautilus-hn7mk update-demo-nautilus-tztpk "
Dec 10 15:01:51.666: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-578738756 get pods update-demo-nautilus-hn7mk -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-f98t8'
Dec 10 15:01:51.754: INFO: stderr: ""
Dec 10 15:01:51.754: INFO: stdout: "true"
Dec 10 15:01:51.754: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-578738756 get pods update-demo-nautilus-hn7mk -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-f98t8'
Dec 10 15:01:51.844: INFO: stderr: ""
Dec 10 15:01:51.844: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Dec 10 15:01:51.844: INFO: validating pod update-demo-nautilus-hn7mk
Dec 10 15:01:51.851: INFO: got data: {
  "image": "nautilus.jpg"
}

Dec 10 15:01:51.851: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Dec 10 15:01:51.851: INFO: update-demo-nautilus-hn7mk is verified up and running
Dec 10 15:01:51.851: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-578738756 get pods update-demo-nautilus-tztpk -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-f98t8'
Dec 10 15:01:51.931: INFO: stderr: ""
Dec 10 15:01:51.931: INFO: stdout: "true"
Dec 10 15:01:51.931: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-578738756 get pods update-demo-nautilus-tztpk -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-f98t8'
Dec 10 15:01:52.020: INFO: stderr: ""
Dec 10 15:01:52.020: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Dec 10 15:01:52.020: INFO: validating pod update-demo-nautilus-tztpk
Dec 10 15:01:52.027: INFO: got data: {
  "image": "nautilus.jpg"
}

Dec 10 15:01:52.027: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Dec 10 15:01:52.027: INFO: update-demo-nautilus-tztpk is verified up and running
STEP: scaling down the replication controller
Dec 10 15:01:52.029: INFO: scanned /root for discovery docs: <nil>
Dec 10 15:01:52.029: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-578738756 scale rc update-demo-nautilus --replicas=1 --timeout=5m --namespace=e2e-tests-kubectl-f98t8'
Dec 10 15:01:53.147: INFO: stderr: ""
Dec 10 15:01:53.147: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Dec 10 15:01:53.147: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-578738756 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-f98t8'
Dec 10 15:01:53.234: INFO: stderr: ""
Dec 10 15:01:53.235: INFO: stdout: "update-demo-nautilus-hn7mk update-demo-nautilus-tztpk "
STEP: Replicas for name=update-demo: expected=1 actual=2
Dec 10 15:01:58.235: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-578738756 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-f98t8'
Dec 10 15:01:58.377: INFO: stderr: ""
Dec 10 15:01:58.377: INFO: stdout: "update-demo-nautilus-hn7mk "
Dec 10 15:01:58.377: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-578738756 get pods update-demo-nautilus-hn7mk -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-f98t8'
Dec 10 15:01:58.463: INFO: stderr: ""
Dec 10 15:01:58.463: INFO: stdout: "true"
Dec 10 15:01:58.463: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-578738756 get pods update-demo-nautilus-hn7mk -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-f98t8'
Dec 10 15:01:58.547: INFO: stderr: ""
Dec 10 15:01:58.547: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Dec 10 15:01:58.547: INFO: validating pod update-demo-nautilus-hn7mk
Dec 10 15:01:58.552: INFO: got data: {
  "image": "nautilus.jpg"
}

Dec 10 15:01:58.552: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Dec 10 15:01:58.552: INFO: update-demo-nautilus-hn7mk is verified up and running
STEP: scaling up the replication controller
Dec 10 15:01:58.553: INFO: scanned /root for discovery docs: <nil>
Dec 10 15:01:58.553: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-578738756 scale rc update-demo-nautilus --replicas=2 --timeout=5m --namespace=e2e-tests-kubectl-f98t8'
Dec 10 15:01:59.670: INFO: stderr: ""
Dec 10 15:01:59.670: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Dec 10 15:01:59.670: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-578738756 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-f98t8'
Dec 10 15:01:59.775: INFO: stderr: ""
Dec 10 15:01:59.775: INFO: stdout: "update-demo-nautilus-h2rfx update-demo-nautilus-hn7mk "
Dec 10 15:01:59.775: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-578738756 get pods update-demo-nautilus-h2rfx -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-f98t8'
Dec 10 15:01:59.863: INFO: stderr: ""
Dec 10 15:01:59.863: INFO: stdout: ""
Dec 10 15:01:59.863: INFO: update-demo-nautilus-h2rfx is created but not running
Dec 10 15:02:04.863: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-578738756 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-f98t8'
Dec 10 15:02:04.944: INFO: stderr: ""
Dec 10 15:02:04.944: INFO: stdout: "update-demo-nautilus-h2rfx update-demo-nautilus-hn7mk "
Dec 10 15:02:04.944: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-578738756 get pods update-demo-nautilus-h2rfx -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-f98t8'
Dec 10 15:02:05.026: INFO: stderr: ""
Dec 10 15:02:05.026: INFO: stdout: "true"
Dec 10 15:02:05.026: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-578738756 get pods update-demo-nautilus-h2rfx -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-f98t8'
Dec 10 15:02:05.103: INFO: stderr: ""
Dec 10 15:02:05.103: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Dec 10 15:02:05.103: INFO: validating pod update-demo-nautilus-h2rfx
Dec 10 15:02:05.109: INFO: got data: {
  "image": "nautilus.jpg"
}

Dec 10 15:02:05.109: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Dec 10 15:02:05.109: INFO: update-demo-nautilus-h2rfx is verified up and running
Dec 10 15:02:05.109: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-578738756 get pods update-demo-nautilus-hn7mk -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-f98t8'
Dec 10 15:02:05.193: INFO: stderr: ""
Dec 10 15:02:05.193: INFO: stdout: "true"
Dec 10 15:02:05.193: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-578738756 get pods update-demo-nautilus-hn7mk -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-f98t8'
Dec 10 15:02:05.275: INFO: stderr: ""
Dec 10 15:02:05.275: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Dec 10 15:02:05.275: INFO: validating pod update-demo-nautilus-hn7mk
Dec 10 15:02:05.281: INFO: got data: {
  "image": "nautilus.jpg"
}

Dec 10 15:02:05.281: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Dec 10 15:02:05.281: INFO: update-demo-nautilus-hn7mk is verified up and running
STEP: using delete to clean up resources
Dec 10 15:02:05.281: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-578738756 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-f98t8'
Dec 10 15:02:05.372: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Dec 10 15:02:05.372: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Dec 10 15:02:05.373: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-578738756 get rc,svc -l name=update-demo --no-headers --namespace=e2e-tests-kubectl-f98t8'
Dec 10 15:02:05.512: INFO: stderr: "No resources found.\n"
Dec 10 15:02:05.512: INFO: stdout: ""
Dec 10 15:02:05.512: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-578738756 get pods -l name=update-demo --namespace=e2e-tests-kubectl-f98t8 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Dec 10 15:02:05.634: INFO: stderr: ""
Dec 10 15:02:05.634: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 10 15:02:05.634: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-f98t8" for this suite.
Dec 10 15:02:27.664: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 15:02:27.715: INFO: namespace: e2e-tests-kubectl-f98t8, resource: bindings, ignored listing per whitelist
Dec 10 15:02:27.775: INFO: namespace e2e-tests-kubectl-f98t8 deletion completed in 22.130896944s

• [SLOW TEST:41.611 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Update Demo
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should scale a replication controller  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-api-machinery] Watchers 
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 10 15:02:27.776: INFO: >>> kubeConfig: /tmp/kubeconfig-578738756
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: modifying the configmap a second time
STEP: deleting the configmap
STEP: creating a watch on configmaps from the resource version returned by the first update
STEP: Expecting to observe notifications for all changes to the configmap after the first update
Dec 10 15:02:27.882: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-resource-version,GenerateName:,Namespace:e2e-tests-watch-8rxt4,SelfLink:/api/v1/namespaces/e2e-tests-watch-8rxt4/configmaps/e2e-watch-test-resource-version,UID:9c0bf303-fc8c-11e8-8690-fa163e74bd5a,ResourceVersion:22886,Generation:0,CreationTimestamp:2018-12-10 15:02:27 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: from-resource-version,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Dec 10 15:02:27.882: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-resource-version,GenerateName:,Namespace:e2e-tests-watch-8rxt4,SelfLink:/api/v1/namespaces/e2e-tests-watch-8rxt4/configmaps/e2e-watch-test-resource-version,UID:9c0bf303-fc8c-11e8-8690-fa163e74bd5a,ResourceVersion:22888,Generation:0,CreationTimestamp:2018-12-10 15:02:27 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: from-resource-version,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 10 15:02:27.883: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-8rxt4" for this suite.
Dec 10 15:02:33.902: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 15:02:33.948: INFO: namespace: e2e-tests-watch-8rxt4, resource: bindings, ignored listing per whitelist
Dec 10 15:02:34.008: INFO: namespace e2e-tests-watch-8rxt4 deletion completed in 6.121410548s

• [SLOW TEST:6.233 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 10 15:02:34.009: INFO: >>> kubeConfig: /tmp/kubeconfig-578738756
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-9fc2c4de-fc8c-11e8-a36b-7e9ed3de7210
STEP: Creating a pod to test consume secrets
Dec 10 15:02:34.090: INFO: Waiting up to 5m0s for pod "pod-secrets-9fc3c2ca-fc8c-11e8-a36b-7e9ed3de7210" in namespace "e2e-tests-secrets-95gd2" to be "success or failure"
Dec 10 15:02:34.096: INFO: Pod "pod-secrets-9fc3c2ca-fc8c-11e8-a36b-7e9ed3de7210": Phase="Pending", Reason="", readiness=false. Elapsed: 5.670805ms
Dec 10 15:02:36.101: INFO: Pod "pod-secrets-9fc3c2ca-fc8c-11e8-a36b-7e9ed3de7210": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010234132s
STEP: Saw pod success
Dec 10 15:02:36.101: INFO: Pod "pod-secrets-9fc3c2ca-fc8c-11e8-a36b-7e9ed3de7210" satisfied condition "success or failure"
Dec 10 15:02:36.104: INFO: Trying to get logs from node conformance-cluster1-k8s-node-2 pod pod-secrets-9fc3c2ca-fc8c-11e8-a36b-7e9ed3de7210 container secret-volume-test: <nil>
STEP: delete the pod
Dec 10 15:02:36.130: INFO: Waiting for pod pod-secrets-9fc3c2ca-fc8c-11e8-a36b-7e9ed3de7210 to disappear
Dec 10 15:02:36.133: INFO: Pod pod-secrets-9fc3c2ca-fc8c-11e8-a36b-7e9ed3de7210 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 10 15:02:36.133: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-95gd2" for this suite.
Dec 10 15:02:42.158: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 15:02:42.261: INFO: namespace: e2e-tests-secrets-95gd2, resource: bindings, ignored listing per whitelist
Dec 10 15:02:42.267: INFO: namespace e2e-tests-secrets-95gd2 deletion completed in 6.12927111s

• [SLOW TEST:8.258 seconds]
[sig-storage] Secrets
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[k8s.io] Docker Containers 
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 10 15:02:42.267: INFO: >>> kubeConfig: /tmp/kubeconfig-578738756
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test use defaults
Dec 10 15:02:42.350: INFO: Waiting up to 5m0s for pod "client-containers-a4af74bc-fc8c-11e8-a36b-7e9ed3de7210" in namespace "e2e-tests-containers-xk2k9" to be "success or failure"
Dec 10 15:02:42.355: INFO: Pod "client-containers-a4af74bc-fc8c-11e8-a36b-7e9ed3de7210": Phase="Pending", Reason="", readiness=false. Elapsed: 5.566162ms
Dec 10 15:02:44.360: INFO: Pod "client-containers-a4af74bc-fc8c-11e8-a36b-7e9ed3de7210": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010155077s
STEP: Saw pod success
Dec 10 15:02:44.360: INFO: Pod "client-containers-a4af74bc-fc8c-11e8-a36b-7e9ed3de7210" satisfied condition "success or failure"
Dec 10 15:02:44.364: INFO: Trying to get logs from node conformance-cluster1-k8s-node-2 pod client-containers-a4af74bc-fc8c-11e8-a36b-7e9ed3de7210 container test-container: <nil>
STEP: delete the pod
Dec 10 15:02:44.394: INFO: Waiting for pod client-containers-a4af74bc-fc8c-11e8-a36b-7e9ed3de7210 to disappear
Dec 10 15:02:44.397: INFO: Pod client-containers-a4af74bc-fc8c-11e8-a36b-7e9ed3de7210 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 10 15:02:44.397: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-xk2k9" for this suite.
Dec 10 15:02:50.416: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 15:02:50.458: INFO: namespace: e2e-tests-containers-xk2k9, resource: bindings, ignored listing per whitelist
Dec 10 15:02:50.534: INFO: namespace e2e-tests-containers-xk2k9 deletion completed in 6.131931845s

• [SLOW TEST:8.267 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-apps] Daemon set [Serial] 
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 10 15:02:50.534: INFO: >>> kubeConfig: /tmp/kubeconfig-578738756
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:98
[It] should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Dec 10 15:02:50.618: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 15:02:50.618: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 15:02:50.618: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 15:02:50.623: INFO: Number of nodes with available pods: 0
Dec 10 15:02:50.623: INFO: Node conformance-cluster1-k8s-node-1 is running more than one daemon pod
Dec 10 15:02:51.629: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 15:02:51.629: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 15:02:51.629: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 15:02:51.633: INFO: Number of nodes with available pods: 0
Dec 10 15:02:51.633: INFO: Node conformance-cluster1-k8s-node-1 is running more than one daemon pod
Dec 10 15:02:52.634: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 15:02:52.634: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 15:02:52.635: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 15:02:52.638: INFO: Number of nodes with available pods: 2
Dec 10 15:02:52.638: INFO: Number of running nodes: 2, number of available pods: 2
STEP: Set a daemon pod's phase to 'Failed', check that the daemon pod is revived.
Dec 10 15:02:52.657: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 15:02:52.657: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 15:02:52.657: INFO: DaemonSet pods can't tolerate node conformance-cluster1-k8s-master-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 10 15:02:52.662: INFO: Number of nodes with available pods: 2
Dec 10 15:02:52.662: INFO: Number of running nodes: 2, number of available pods: 2
STEP: Wait for the failed daemon pod to be completely deleted.
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:64
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting {extensions DaemonSet} daemon-set in namespace e2e-tests-daemonsets-n69c5, will wait for the garbage collector to delete the pods
Dec 10 15:02:53.737: INFO: Deleting {extensions DaemonSet} daemon-set took: 10.161549ms
Dec 10 15:02:53.837: INFO: Terminating {extensions DaemonSet} daemon-set pods took: 100.180656ms
Dec 10 15:03:28.247: INFO: Number of nodes with available pods: 0
Dec 10 15:03:28.247: INFO: Number of running nodes: 0, number of available pods: 0
Dec 10 15:03:28.250: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-n69c5/daemonsets","resourceVersion":"23145"},"items":null}

Dec 10 15:03:28.253: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-n69c5/pods","resourceVersion":"23145"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 10 15:03:28.263: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-n69c5" for this suite.
Dec 10 15:03:34.287: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 15:03:34.328: INFO: namespace: e2e-tests-daemonsets-n69c5, resource: bindings, ignored listing per whitelist
Dec 10 15:03:34.391: INFO: namespace e2e-tests-daemonsets-n69c5 deletion completed in 6.123633518s

• [SLOW TEST:43.857 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 10 15:03:34.391: INFO: >>> kubeConfig: /tmp/kubeconfig-578738756
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test override all
Dec 10 15:03:34.471: INFO: Waiting up to 5m0s for pod "client-containers-c3c05ebe-fc8c-11e8-a36b-7e9ed3de7210" in namespace "e2e-tests-containers-wn5ff" to be "success or failure"
Dec 10 15:03:34.476: INFO: Pod "client-containers-c3c05ebe-fc8c-11e8-a36b-7e9ed3de7210": Phase="Pending", Reason="", readiness=false. Elapsed: 4.246889ms
Dec 10 15:03:36.479: INFO: Pod "client-containers-c3c05ebe-fc8c-11e8-a36b-7e9ed3de7210": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008155107s
STEP: Saw pod success
Dec 10 15:03:36.480: INFO: Pod "client-containers-c3c05ebe-fc8c-11e8-a36b-7e9ed3de7210" satisfied condition "success or failure"
Dec 10 15:03:36.486: INFO: Trying to get logs from node conformance-cluster1-k8s-node-2 pod client-containers-c3c05ebe-fc8c-11e8-a36b-7e9ed3de7210 container test-container: <nil>
STEP: delete the pod
Dec 10 15:03:36.511: INFO: Waiting for pod client-containers-c3c05ebe-fc8c-11e8-a36b-7e9ed3de7210 to disappear
Dec 10 15:03:36.515: INFO: Pod client-containers-c3c05ebe-fc8c-11e8-a36b-7e9ed3de7210 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 10 15:03:36.515: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-wn5ff" for this suite.
Dec 10 15:03:42.533: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 15:03:42.547: INFO: namespace: e2e-tests-containers-wn5ff, resource: bindings, ignored listing per whitelist
Dec 10 15:03:42.629: INFO: namespace e2e-tests-containers-wn5ff deletion completed in 6.110733299s

• [SLOW TEST:8.239 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Secrets 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 10 15:03:42.630: INFO: >>> kubeConfig: /tmp/kubeconfig-578738756
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating secret e2e-tests-secrets-xzhcn/secret-test-c8a7e0a6-fc8c-11e8-a36b-7e9ed3de7210
STEP: Creating a pod to test consume secrets
Dec 10 15:03:42.701: INFO: Waiting up to 5m0s for pod "pod-configmaps-c8a90f48-fc8c-11e8-a36b-7e9ed3de7210" in namespace "e2e-tests-secrets-xzhcn" to be "success or failure"
Dec 10 15:03:42.710: INFO: Pod "pod-configmaps-c8a90f48-fc8c-11e8-a36b-7e9ed3de7210": Phase="Pending", Reason="", readiness=false. Elapsed: 8.982505ms
Dec 10 15:03:44.714: INFO: Pod "pod-configmaps-c8a90f48-fc8c-11e8-a36b-7e9ed3de7210": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013621912s
Dec 10 15:03:46.719: INFO: Pod "pod-configmaps-c8a90f48-fc8c-11e8-a36b-7e9ed3de7210": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.017810973s
STEP: Saw pod success
Dec 10 15:03:46.719: INFO: Pod "pod-configmaps-c8a90f48-fc8c-11e8-a36b-7e9ed3de7210" satisfied condition "success or failure"
Dec 10 15:03:46.723: INFO: Trying to get logs from node conformance-cluster1-k8s-node-2 pod pod-configmaps-c8a90f48-fc8c-11e8-a36b-7e9ed3de7210 container env-test: <nil>
STEP: delete the pod
Dec 10 15:03:46.753: INFO: Waiting for pod pod-configmaps-c8a90f48-fc8c-11e8-a36b-7e9ed3de7210 to disappear
Dec 10 15:03:46.757: INFO: Pod pod-configmaps-c8a90f48-fc8c-11e8-a36b-7e9ed3de7210 no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 10 15:03:46.757: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-xzhcn" for this suite.
Dec 10 15:03:52.778: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 15:03:52.827: INFO: namespace: e2e-tests-secrets-xzhcn, resource: bindings, ignored listing per whitelist
Dec 10 15:03:52.885: INFO: namespace e2e-tests-secrets-xzhcn deletion completed in 6.123693518s

• [SLOW TEST:10.255 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:31
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 10 15:03:52.886: INFO: >>> kubeConfig: /tmp/kubeconfig-578738756
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-map-cec5fac7-fc8c-11e8-a36b-7e9ed3de7210
STEP: Creating a pod to test consume secrets
Dec 10 15:03:52.965: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-cec71001-fc8c-11e8-a36b-7e9ed3de7210" in namespace "e2e-tests-projected-rg56p" to be "success or failure"
Dec 10 15:03:52.971: INFO: Pod "pod-projected-secrets-cec71001-fc8c-11e8-a36b-7e9ed3de7210": Phase="Pending", Reason="", readiness=false. Elapsed: 6.026471ms
Dec 10 15:03:54.975: INFO: Pod "pod-projected-secrets-cec71001-fc8c-11e8-a36b-7e9ed3de7210": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010194102s
STEP: Saw pod success
Dec 10 15:03:54.975: INFO: Pod "pod-projected-secrets-cec71001-fc8c-11e8-a36b-7e9ed3de7210" satisfied condition "success or failure"
Dec 10 15:03:54.979: INFO: Trying to get logs from node conformance-cluster1-k8s-node-2 pod pod-projected-secrets-cec71001-fc8c-11e8-a36b-7e9ed3de7210 container projected-secret-volume-test: <nil>
STEP: delete the pod
Dec 10 15:03:55.003: INFO: Waiting for pod pod-projected-secrets-cec71001-fc8c-11e8-a36b-7e9ed3de7210 to disappear
Dec 10 15:03:55.006: INFO: Pod pod-projected-secrets-cec71001-fc8c-11e8-a36b-7e9ed3de7210 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 10 15:03:55.007: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-rg56p" for this suite.
Dec 10 15:04:01.029: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 15:04:01.089: INFO: namespace: e2e-tests-projected-rg56p, resource: bindings, ignored listing per whitelist
Dec 10 15:04:01.141: INFO: namespace e2e-tests-projected-rg56p deletion completed in 6.127045464s

• [SLOW TEST:8.255 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 10 15:04:01.142: INFO: >>> kubeConfig: /tmp/kubeconfig-578738756
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0777 on node default medium
Dec 10 15:04:01.211: INFO: Waiting up to 5m0s for pod "pod-d3b0f2b0-fc8c-11e8-a36b-7e9ed3de7210" in namespace "e2e-tests-emptydir-8tgm6" to be "success or failure"
Dec 10 15:04:01.218: INFO: Pod "pod-d3b0f2b0-fc8c-11e8-a36b-7e9ed3de7210": Phase="Pending", Reason="", readiness=false. Elapsed: 7.097707ms
Dec 10 15:04:03.225: INFO: Pod "pod-d3b0f2b0-fc8c-11e8-a36b-7e9ed3de7210": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.014368949s
STEP: Saw pod success
Dec 10 15:04:03.225: INFO: Pod "pod-d3b0f2b0-fc8c-11e8-a36b-7e9ed3de7210" satisfied condition "success or failure"
Dec 10 15:04:03.229: INFO: Trying to get logs from node conformance-cluster1-k8s-node-2 pod pod-d3b0f2b0-fc8c-11e8-a36b-7e9ed3de7210 container test-container: <nil>
STEP: delete the pod
Dec 10 15:04:03.257: INFO: Waiting for pod pod-d3b0f2b0-fc8c-11e8-a36b-7e9ed3de7210 to disappear
Dec 10 15:04:03.261: INFO: Pod pod-d3b0f2b0-fc8c-11e8-a36b-7e9ed3de7210 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 10 15:04:03.261: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-8tgm6" for this suite.
Dec 10 15:04:09.286: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 15:04:09.372: INFO: namespace: e2e-tests-emptydir-8tgm6, resource: bindings, ignored listing per whitelist
Dec 10 15:04:09.397: INFO: namespace e2e-tests-emptydir-8tgm6 deletion completed in 6.13128261s

• [SLOW TEST:8.255 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run pod 
  should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 10 15:04:09.397: INFO: >>> kubeConfig: /tmp/kubeconfig-578738756
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Kubectl run pod
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1475
[It] should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Dec 10 15:04:09.468: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-578738756 run e2e-test-nginx-pod --restart=Never --generator=run-pod/v1 --image=docker.io/library/nginx:1.14-alpine --namespace=e2e-tests-kubectl-m4dlv'
Dec 10 15:04:09.575: INFO: stderr: ""
Dec 10 15:04:09.575: INFO: stdout: "pod/e2e-test-nginx-pod created\n"
STEP: verifying the pod e2e-test-nginx-pod was created
[AfterEach] [k8s.io] Kubectl run pod
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1480
Dec 10 15:04:09.580: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-578738756 delete pods e2e-test-nginx-pod --namespace=e2e-tests-kubectl-m4dlv'
Dec 10 15:04:18.169: INFO: stderr: ""
Dec 10 15:04:18.169: INFO: stdout: "pod \"e2e-test-nginx-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 10 15:04:18.170: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-m4dlv" for this suite.
Dec 10 15:04:24.189: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 15:04:24.296: INFO: namespace: e2e-tests-kubectl-m4dlv, resource: bindings, ignored listing per whitelist
Dec 10 15:04:24.302: INFO: namespace e2e-tests-kubectl-m4dlv deletion completed in 6.12737648s

• [SLOW TEST:14.905 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run pod
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create a pod from an image when restart is Never  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 10 15:04:24.304: INFO: >>> kubeConfig: /tmp/kubeconfig-578738756
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0666 on node default medium
Dec 10 15:04:24.378: INFO: Waiting up to 5m0s for pod "pod-e17f72cf-fc8c-11e8-a36b-7e9ed3de7210" in namespace "e2e-tests-emptydir-w6qxn" to be "success or failure"
Dec 10 15:04:24.385: INFO: Pod "pod-e17f72cf-fc8c-11e8-a36b-7e9ed3de7210": Phase="Pending", Reason="", readiness=false. Elapsed: 7.037139ms
Dec 10 15:04:26.389: INFO: Pod "pod-e17f72cf-fc8c-11e8-a36b-7e9ed3de7210": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.011133882s
STEP: Saw pod success
Dec 10 15:04:26.390: INFO: Pod "pod-e17f72cf-fc8c-11e8-a36b-7e9ed3de7210" satisfied condition "success or failure"
Dec 10 15:04:26.393: INFO: Trying to get logs from node conformance-cluster1-k8s-node-2 pod pod-e17f72cf-fc8c-11e8-a36b-7e9ed3de7210 container test-container: <nil>
STEP: delete the pod
Dec 10 15:04:26.421: INFO: Waiting for pod pod-e17f72cf-fc8c-11e8-a36b-7e9ed3de7210 to disappear
Dec 10 15:04:26.424: INFO: Pod pod-e17f72cf-fc8c-11e8-a36b-7e9ed3de7210 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 10 15:04:26.424: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-w6qxn" for this suite.
Dec 10 15:04:32.443: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 15:04:32.482: INFO: namespace: e2e-tests-emptydir-w6qxn, resource: bindings, ignored listing per whitelist
Dec 10 15:04:32.548: INFO: namespace e2e-tests-emptydir-w6qxn deletion completed in 6.118925196s

• [SLOW TEST:8.244 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod with mountPath of existing file [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 10 15:04:32.548: INFO: >>> kubeConfig: /tmp/kubeconfig-578738756
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with configmap pod with mountPath of existing file [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-configmap-4bx8
STEP: Creating a pod to test atomic-volume-subpath
Dec 10 15:04:32.628: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-4bx8" in namespace "e2e-tests-subpath-xfgsx" to be "success or failure"
Dec 10 15:04:32.634: INFO: Pod "pod-subpath-test-configmap-4bx8": Phase="Pending", Reason="", readiness=false. Elapsed: 6.325915ms
Dec 10 15:04:34.639: INFO: Pod "pod-subpath-test-configmap-4bx8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011281211s
Dec 10 15:04:36.643: INFO: Pod "pod-subpath-test-configmap-4bx8": Phase="Running", Reason="", readiness=false. Elapsed: 4.015575307s
Dec 10 15:04:38.648: INFO: Pod "pod-subpath-test-configmap-4bx8": Phase="Running", Reason="", readiness=false. Elapsed: 6.020219462s
Dec 10 15:04:40.657: INFO: Pod "pod-subpath-test-configmap-4bx8": Phase="Running", Reason="", readiness=false. Elapsed: 8.029293753s
Dec 10 15:04:42.662: INFO: Pod "pod-subpath-test-configmap-4bx8": Phase="Running", Reason="", readiness=false. Elapsed: 10.033656015s
Dec 10 15:04:44.666: INFO: Pod "pod-subpath-test-configmap-4bx8": Phase="Running", Reason="", readiness=false. Elapsed: 12.037977599s
Dec 10 15:04:46.670: INFO: Pod "pod-subpath-test-configmap-4bx8": Phase="Running", Reason="", readiness=false. Elapsed: 14.042087111s
Dec 10 15:04:48.675: INFO: Pod "pod-subpath-test-configmap-4bx8": Phase="Running", Reason="", readiness=false. Elapsed: 16.047017357s
Dec 10 15:04:50.684: INFO: Pod "pod-subpath-test-configmap-4bx8": Phase="Running", Reason="", readiness=false. Elapsed: 18.056452725s
Dec 10 15:04:52.689: INFO: Pod "pod-subpath-test-configmap-4bx8": Phase="Running", Reason="", readiness=false. Elapsed: 20.061052877s
Dec 10 15:04:54.694: INFO: Pod "pod-subpath-test-configmap-4bx8": Phase="Running", Reason="", readiness=false. Elapsed: 22.065640507s
Dec 10 15:04:56.698: INFO: Pod "pod-subpath-test-configmap-4bx8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.070029202s
STEP: Saw pod success
Dec 10 15:04:56.698: INFO: Pod "pod-subpath-test-configmap-4bx8" satisfied condition "success or failure"
Dec 10 15:04:56.701: INFO: Trying to get logs from node conformance-cluster1-k8s-node-2 pod pod-subpath-test-configmap-4bx8 container test-container-subpath-configmap-4bx8: <nil>
STEP: delete the pod
Dec 10 15:04:56.725: INFO: Waiting for pod pod-subpath-test-configmap-4bx8 to disappear
Dec 10 15:04:56.729: INFO: Pod pod-subpath-test-configmap-4bx8 no longer exists
STEP: Deleting pod pod-subpath-test-configmap-4bx8
Dec 10 15:04:56.730: INFO: Deleting pod "pod-subpath-test-configmap-4bx8" in namespace "e2e-tests-subpath-xfgsx"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 10 15:04:56.733: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-xfgsx" for this suite.
Dec 10 15:05:02.752: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 15:05:02.809: INFO: namespace: e2e-tests-subpath-xfgsx, resource: bindings, ignored listing per whitelist
Dec 10 15:05:02.862: INFO: namespace e2e-tests-subpath-xfgsx deletion completed in 6.124496719s

• [SLOW TEST:30.314 seconds]
[sig-storage] Subpath
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with configmap pod with mountPath of existing file [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 10 15:05:02.862: INFO: >>> kubeConfig: /tmp/kubeconfig-578738756
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for all rs to be garbage collected
STEP: expected 0 pods, got 2 pods
STEP: expected 0 rs, got 1 rs
STEP: Gathering metrics
W1210 15:05:03.986740      15 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Dec 10 15:05:03.986: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 10 15:05:03.986: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-w6pbf" for this suite.
Dec 10 15:05:10.006: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 15:05:10.074: INFO: namespace: e2e-tests-gc-w6pbf, resource: bindings, ignored listing per whitelist
Dec 10 15:05:10.113: INFO: namespace e2e-tests-gc-w6pbf deletion completed in 6.122428992s

• [SLOW TEST:7.252 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 10 15:05:10.114: INFO: >>> kubeConfig: /tmp/kubeconfig-578738756
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-fccc15ac-fc8c-11e8-a36b-7e9ed3de7210
STEP: Creating a pod to test consume secrets
Dec 10 15:05:10.184: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-fccd28cb-fc8c-11e8-a36b-7e9ed3de7210" in namespace "e2e-tests-projected-kv4mr" to be "success or failure"
Dec 10 15:05:10.194: INFO: Pod "pod-projected-secrets-fccd28cb-fc8c-11e8-a36b-7e9ed3de7210": Phase="Pending", Reason="", readiness=false. Elapsed: 9.555489ms
Dec 10 15:05:12.203: INFO: Pod "pod-projected-secrets-fccd28cb-fc8c-11e8-a36b-7e9ed3de7210": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.018953299s
STEP: Saw pod success
Dec 10 15:05:12.203: INFO: Pod "pod-projected-secrets-fccd28cb-fc8c-11e8-a36b-7e9ed3de7210" satisfied condition "success or failure"
Dec 10 15:05:12.206: INFO: Trying to get logs from node conformance-cluster1-k8s-node-2 pod pod-projected-secrets-fccd28cb-fc8c-11e8-a36b-7e9ed3de7210 container projected-secret-volume-test: <nil>
STEP: delete the pod
Dec 10 15:05:12.235: INFO: Waiting for pod pod-projected-secrets-fccd28cb-fc8c-11e8-a36b-7e9ed3de7210 to disappear
Dec 10 15:05:12.238: INFO: Pod pod-projected-secrets-fccd28cb-fc8c-11e8-a36b-7e9ed3de7210 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 10 15:05:12.238: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-kv4mr" for this suite.
Dec 10 15:05:18.256: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 15:05:18.327: INFO: namespace: e2e-tests-projected-kv4mr, resource: bindings, ignored listing per whitelist
Dec 10 15:05:18.367: INFO: namespace e2e-tests-projected-kv4mr deletion completed in 6.125226163s

• [SLOW TEST:8.254 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on tmpfs should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 10 15:05:18.367: INFO: >>> kubeConfig: /tmp/kubeconfig-578738756
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on tmpfs should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir volume type on tmpfs
Dec 10 15:05:18.441: INFO: Waiting up to 5m0s for pod "pod-01b8ed6e-fc8d-11e8-a36b-7e9ed3de7210" in namespace "e2e-tests-emptydir-grcxz" to be "success or failure"
Dec 10 15:05:18.445: INFO: Pod "pod-01b8ed6e-fc8d-11e8-a36b-7e9ed3de7210": Phase="Pending", Reason="", readiness=false. Elapsed: 4.254597ms
Dec 10 15:05:20.449: INFO: Pod "pod-01b8ed6e-fc8d-11e8-a36b-7e9ed3de7210": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00848061s
STEP: Saw pod success
Dec 10 15:05:20.450: INFO: Pod "pod-01b8ed6e-fc8d-11e8-a36b-7e9ed3de7210" satisfied condition "success or failure"
Dec 10 15:05:20.453: INFO: Trying to get logs from node conformance-cluster1-k8s-node-2 pod pod-01b8ed6e-fc8d-11e8-a36b-7e9ed3de7210 container test-container: <nil>
STEP: delete the pod
Dec 10 15:05:20.478: INFO: Waiting for pod pod-01b8ed6e-fc8d-11e8-a36b-7e9ed3de7210 to disappear
Dec 10 15:05:20.482: INFO: Pod pod-01b8ed6e-fc8d-11e8-a36b-7e9ed3de7210 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 10 15:05:20.482: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-grcxz" for this suite.
Dec 10 15:05:26.504: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 15:05:26.616: INFO: namespace: e2e-tests-emptydir-grcxz, resource: bindings, ignored listing per whitelist
Dec 10 15:05:26.623: INFO: namespace e2e-tests-emptydir-grcxz deletion completed in 6.136150403s

• [SLOW TEST:8.255 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  volume on tmpfs should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 10 15:05:26.623: INFO: >>> kubeConfig: /tmp/kubeconfig-578738756
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Dec 10 15:05:30.749: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Dec 10 15:05:30.752: INFO: Pod pod-with-poststart-http-hook still exists
Dec 10 15:05:32.752: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Dec 10 15:05:32.768: INFO: Pod pod-with-poststart-http-hook still exists
Dec 10 15:05:34.752: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Dec 10 15:05:34.757: INFO: Pod pod-with-poststart-http-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 10 15:05:34.757: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-lifecycle-hook-46fqf" for this suite.
Dec 10 15:05:56.777: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 15:05:56.801: INFO: namespace: e2e-tests-container-lifecycle-hook-46fqf, resource: bindings, ignored listing per whitelist
Dec 10 15:05:56.882: INFO: namespace e2e-tests-container-lifecycle-hook-46fqf deletion completed in 22.120979785s

• [SLOW TEST:30.260 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when create a pod with lifecycle hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute poststart http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-storage] Downward API volume 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 10 15:05:56.883: INFO: >>> kubeConfig: /tmp/kubeconfig-578738756
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating the pod
Dec 10 15:05:59.510: INFO: Successfully updated pod "annotationupdate18aeb47a-fc8d-11e8-a36b-7e9ed3de7210"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 10 15:06:01.531: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-9lxpx" for this suite.
Dec 10 15:06:23.551: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 15:06:23.603: INFO: namespace: e2e-tests-downward-api-9lxpx, resource: bindings, ignored listing per whitelist
Dec 10 15:06:23.658: INFO: namespace e2e-tests-downward-api-9lxpx deletion completed in 22.12278503s

• [SLOW TEST:26.776 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with projected pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 10 15:06:23.659: INFO: >>> kubeConfig: /tmp/kubeconfig-578738756
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with projected pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-projected-npv4
STEP: Creating a pod to test atomic-volume-subpath
Dec 10 15:06:23.743: INFO: Waiting up to 5m0s for pod "pod-subpath-test-projected-npv4" in namespace "e2e-tests-subpath-sr9wz" to be "success or failure"
Dec 10 15:06:23.749: INFO: Pod "pod-subpath-test-projected-npv4": Phase="Pending", Reason="", readiness=false. Elapsed: 5.885948ms
Dec 10 15:06:25.754: INFO: Pod "pod-subpath-test-projected-npv4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010542975s
Dec 10 15:06:27.763: INFO: Pod "pod-subpath-test-projected-npv4": Phase="Running", Reason="", readiness=false. Elapsed: 4.019858415s
Dec 10 15:06:29.767: INFO: Pod "pod-subpath-test-projected-npv4": Phase="Running", Reason="", readiness=false. Elapsed: 6.023893935s
Dec 10 15:06:31.772: INFO: Pod "pod-subpath-test-projected-npv4": Phase="Running", Reason="", readiness=false. Elapsed: 8.028762347s
Dec 10 15:06:33.776: INFO: Pod "pod-subpath-test-projected-npv4": Phase="Running", Reason="", readiness=false. Elapsed: 10.033152799s
Dec 10 15:06:35.780: INFO: Pod "pod-subpath-test-projected-npv4": Phase="Running", Reason="", readiness=false. Elapsed: 12.037417394s
Dec 10 15:06:37.790: INFO: Pod "pod-subpath-test-projected-npv4": Phase="Running", Reason="", readiness=false. Elapsed: 14.046837301s
Dec 10 15:06:39.794: INFO: Pod "pod-subpath-test-projected-npv4": Phase="Running", Reason="", readiness=false. Elapsed: 16.050918136s
Dec 10 15:06:41.798: INFO: Pod "pod-subpath-test-projected-npv4": Phase="Running", Reason="", readiness=false. Elapsed: 18.055166666s
Dec 10 15:06:43.803: INFO: Pod "pod-subpath-test-projected-npv4": Phase="Running", Reason="", readiness=false. Elapsed: 20.060134425s
Dec 10 15:06:45.808: INFO: Pod "pod-subpath-test-projected-npv4": Phase="Running", Reason="", readiness=false. Elapsed: 22.064653061s
Dec 10 15:06:47.820: INFO: Pod "pod-subpath-test-projected-npv4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.077360216s
STEP: Saw pod success
Dec 10 15:06:47.821: INFO: Pod "pod-subpath-test-projected-npv4" satisfied condition "success or failure"
Dec 10 15:06:47.825: INFO: Trying to get logs from node conformance-cluster1-k8s-node-2 pod pod-subpath-test-projected-npv4 container test-container-subpath-projected-npv4: <nil>
STEP: delete the pod
Dec 10 15:06:47.853: INFO: Waiting for pod pod-subpath-test-projected-npv4 to disappear
Dec 10 15:06:47.857: INFO: Pod pod-subpath-test-projected-npv4 no longer exists
STEP: Deleting pod pod-subpath-test-projected-npv4
Dec 10 15:06:47.857: INFO: Deleting pod "pod-subpath-test-projected-npv4" in namespace "e2e-tests-subpath-sr9wz"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 10 15:06:47.860: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-sr9wz" for this suite.
Dec 10 15:06:53.880: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 15:06:53.928: INFO: namespace: e2e-tests-subpath-sr9wz, resource: bindings, ignored listing per whitelist
Dec 10 15:06:53.984: INFO: namespace e2e-tests-subpath-sr9wz deletion completed in 6.118928851s

• [SLOW TEST:30.325 seconds]
[sig-storage] Subpath
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with projected pod [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-api-machinery] Garbage collector 
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 10 15:06:53.984: INFO: >>> kubeConfig: /tmp/kubeconfig-578738756
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the rc
STEP: delete the rc
STEP: wait for all pods to be garbage collected
STEP: Gathering metrics
W1210 15:07:04.089766      15 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Dec 10 15:07:04.089: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 10 15:07:04.089: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-9kjh9" for this suite.
Dec 10 15:07:10.118: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 10 15:07:10.160: INFO: namespace: e2e-tests-gc-9kjh9, resource: bindings, ignored listing per whitelist
Dec 10 15:07:10.225: INFO: namespace e2e-tests-gc-9kjh9 deletion completed in 6.131759956s

• [SLOW TEST:16.241 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSDec 10 15:07:10.225: INFO: Running AfterSuite actions on all node
Dec 10 15:07:10.225: INFO: Running AfterSuite actions on node 1
Dec 10 15:07:10.225: INFO: Skipping dumping logs from cluster

Ran 187 of 1814 Specs in 5032.930 seconds
SUCCESS! -- 187 Passed | 0 Failed | 0 Pending | 1627 Skipped PASS

Ginkgo ran 1 suite in 1h23m53.708888684s
Test Suite Passed
