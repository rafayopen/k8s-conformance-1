Conformance test: not doing test setup.
Mar  1 07:47:29.889: INFO: Overriding default scale value of zero to 1
Mar  1 07:47:29.889: INFO: Overriding default milliseconds value of zero to 5000
I0301 07:47:30.496254   31889 e2e.go:304] Starting e2e run "43d7ac57-3bf6-11e9-a72e-ce8290b78775" on Ginkgo node 1
Running Suite: Kubernetes e2e suite
===================================
Random Seed: 1551426449 - Will randomize all specs
Will run 188 of 2011 specs

Mar  1 07:47:30.849: INFO: >>> kubeConfig: /tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
Mar  1 07:47:30.855: INFO: Waiting up to 30m0s for all (but 0) nodes to be schedulable
Mar  1 07:47:31.061: INFO: Waiting up to 10m0s for all pods (need at least 0) in namespace 'kube-system' to be running and ready
Mar  1 07:47:31.253: INFO: 14 / 14 pods in namespace 'kube-system' are running and ready (0 seconds elapsed)
Mar  1 07:47:31.253: INFO: expected 8 pod replicas in namespace 'kube-system', 8 are Running and Ready.
Mar  1 07:47:31.253: INFO: Waiting up to 5m0s for all daemonsets in namespace 'kube-system' to start
Mar  1 07:47:31.294: INFO: 2 / 2 pods ready in namespace 'kube-system' in daemonset 'calico-node' (0 seconds elapsed)
Mar  1 07:47:31.294: INFO: 2 / 2 pods ready in namespace 'kube-system' in daemonset 'kube-proxy' (0 seconds elapsed)
Mar  1 07:47:31.294: INFO: 2 / 2 pods ready in namespace 'kube-system' in daemonset 'node-exporter' (0 seconds elapsed)
Mar  1 07:47:31.294: INFO: e2e test version: v1.12.5
Mar  1 07:47:31.328: INFO: kube-apiserver version: v1.12.5
SSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform rolling updates and roll backs of template modifications [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 07:47:31.328: INFO: >>> kubeConfig: /tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename statefulset
Mar  1 07:47:33.007: INFO: Found PodSecurityPolicies; assuming PodSecurityPolicy is enabled.
Mar  1 07:47:33.117: INFO: Found ClusterRoles; assuming RBAC is enabled.
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-statefulset-qbplg
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-qbplg
[It] should perform rolling updates and roll backs of template modifications [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a new StatefulSet
Mar  1 07:47:33.481: INFO: Found 0 stateful pods, waiting for 3
Mar  1 07:47:43.518: INFO: Found 2 stateful pods, waiting for 3
Mar  1 07:47:53.517: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Mar  1 07:47:53.518: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Mar  1 07:47:53.518: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
Mar  1 07:47:53.626: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-az-nl4q9.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-qbplg ss2-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Mar  1 07:47:54.496: INFO: stderr: ""
Mar  1 07:47:54.496: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Mar  1 07:47:54.496: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss2-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

STEP: Updating StatefulSet template: update image from docker.io/library/nginx:1.14-alpine to docker.io/library/nginx:1.15-alpine
Mar  1 07:48:04.721: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Updating Pods in reverse ordinal order
Mar  1 07:48:04.862: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-az-nl4q9.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-qbplg ss2-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar  1 07:48:05.822: INFO: stderr: ""
Mar  1 07:48:05.822: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Mar  1 07:48:05.822: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss2-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Mar  1 07:48:16.046: INFO: Waiting for StatefulSet e2e-tests-statefulset-qbplg/ss2 to complete update
Mar  1 07:48:16.048: INFO: Waiting for Pod e2e-tests-statefulset-qbplg/ss2-0 to have revision ss2-c79899b9 update revision ss2-787997d666
Mar  1 07:48:16.049: INFO: Waiting for Pod e2e-tests-statefulset-qbplg/ss2-1 to have revision ss2-c79899b9 update revision ss2-787997d666
Mar  1 07:48:26.120: INFO: Waiting for StatefulSet e2e-tests-statefulset-qbplg/ss2 to complete update
Mar  1 07:48:26.120: INFO: Waiting for Pod e2e-tests-statefulset-qbplg/ss2-0 to have revision ss2-c79899b9 update revision ss2-787997d666
Mar  1 07:48:26.120: INFO: Waiting for Pod e2e-tests-statefulset-qbplg/ss2-1 to have revision ss2-c79899b9 update revision ss2-787997d666
Mar  1 07:48:36.129: INFO: Waiting for StatefulSet e2e-tests-statefulset-qbplg/ss2 to complete update
STEP: Rolling back to a previous revision
Mar  1 07:48:46.123: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-az-nl4q9.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-qbplg ss2-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Mar  1 07:48:47.088: INFO: stderr: ""
Mar  1 07:48:47.088: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Mar  1 07:48:47.088: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss2-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Mar  1 07:48:57.317: INFO: Updating stateful set ss2
STEP: Rolling back update in reverse ordinal order
Mar  1 07:48:57.440: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-az-nl4q9.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-qbplg ss2-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar  1 07:48:58.391: INFO: stderr: ""
Mar  1 07:48:58.391: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Mar  1 07:48:58.391: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss2-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Mar  1 07:49:08.610: INFO: Waiting for StatefulSet e2e-tests-statefulset-qbplg/ss2 to complete update
Mar  1 07:49:08.610: INFO: Waiting for Pod e2e-tests-statefulset-qbplg/ss2-0 to have revision ss2-787997d666 update revision ss2-c79899b9
Mar  1 07:49:08.610: INFO: Waiting for Pod e2e-tests-statefulset-qbplg/ss2-1 to have revision ss2-787997d666 update revision ss2-c79899b9
Mar  1 07:49:08.610: INFO: Waiting for Pod e2e-tests-statefulset-qbplg/ss2-2 to have revision ss2-787997d666 update revision ss2-c79899b9
Mar  1 07:49:18.687: INFO: Waiting for StatefulSet e2e-tests-statefulset-qbplg/ss2 to complete update
Mar  1 07:49:18.687: INFO: Waiting for Pod e2e-tests-statefulset-qbplg/ss2-0 to have revision ss2-787997d666 update revision ss2-c79899b9
Mar  1 07:49:18.687: INFO: Waiting for Pod e2e-tests-statefulset-qbplg/ss2-1 to have revision ss2-787997d666 update revision ss2-c79899b9
Mar  1 07:49:28.682: INFO: Waiting for StatefulSet e2e-tests-statefulset-qbplg/ss2 to complete update
Mar  1 07:49:28.682: INFO: Waiting for Pod e2e-tests-statefulset-qbplg/ss2-0 to have revision ss2-787997d666 update revision ss2-c79899b9
Mar  1 07:49:38.685: INFO: Waiting for StatefulSet e2e-tests-statefulset-qbplg/ss2 to complete update
Mar  1 07:49:38.685: INFO: Waiting for Pod e2e-tests-statefulset-qbplg/ss2-0 to have revision ss2-787997d666 update revision ss2-c79899b9
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Mar  1 07:49:48.682: INFO: Deleting all statefulset in ns e2e-tests-statefulset-qbplg
Mar  1 07:49:48.720: INFO: Scaling statefulset ss2 to 0
Mar  1 07:50:18.873: INFO: Waiting for statefulset status.replicas updated to 0
Mar  1 07:50:18.908: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 07:50:19.016: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-qbplg" for this suite.
Mar  1 07:50:27.160: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 07:50:27.761: INFO: namespace: e2e-tests-statefulset-qbplg, resource: bindings, ignored listing per whitelist
Mar  1 07:50:28.532: INFO: namespace e2e-tests-statefulset-qbplg deletion completed in 9.480583766s

• [SLOW TEST:177.204 seconds]
[sig-apps] StatefulSet
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should perform rolling updates and roll backs of template modifications [Conformance]
    /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-apps] Daemon set [Serial] 
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 07:50:28.532: INFO: >>> kubeConfig: /tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-daemonsets-2q2k9
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Mar  1 07:50:30.253: INFO: Creating simple daemon set daemon-set
STEP: Check that daemon pods launch on every node of the cluster.
Mar  1 07:50:30.392: INFO: Number of nodes with available pods: 0
Mar  1 07:50:30.392: INFO: Node shoot--it--pub-az-nl4q9-cpu-worker-7dd9bbfd9c-7fp9l is running more than one daemon pod
Mar  1 07:50:31.471: INFO: Number of nodes with available pods: 0
Mar  1 07:50:31.471: INFO: Node shoot--it--pub-az-nl4q9-cpu-worker-7dd9bbfd9c-7fp9l is running more than one daemon pod
Mar  1 07:50:32.485: INFO: Number of nodes with available pods: 0
Mar  1 07:50:32.485: INFO: Node shoot--it--pub-az-nl4q9-cpu-worker-7dd9bbfd9c-7fp9l is running more than one daemon pod
Mar  1 07:50:33.463: INFO: Number of nodes with available pods: 0
Mar  1 07:50:33.463: INFO: Node shoot--it--pub-az-nl4q9-cpu-worker-7dd9bbfd9c-7fp9l is running more than one daemon pod
Mar  1 07:50:34.474: INFO: Number of nodes with available pods: 1
Mar  1 07:50:34.474: INFO: Node shoot--it--pub-az-nl4q9-cpu-worker-7dd9bbfd9c-gwjjt is running more than one daemon pod
Mar  1 07:50:35.464: INFO: Number of nodes with available pods: 2
Mar  1 07:50:35.464: INFO: Number of running nodes: 2, number of available pods: 2
STEP: Update daemon pods image.
STEP: Check that daemon pods images are updated.
Mar  1 07:50:35.678: INFO: Wrong image for pod: daemon-set-nl82v. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 07:50:35.678: INFO: Wrong image for pod: daemon-set-r68rq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 07:50:36.753: INFO: Wrong image for pod: daemon-set-nl82v. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 07:50:36.753: INFO: Wrong image for pod: daemon-set-r68rq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 07:50:37.751: INFO: Wrong image for pod: daemon-set-nl82v. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 07:50:37.751: INFO: Wrong image for pod: daemon-set-r68rq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 07:50:38.750: INFO: Wrong image for pod: daemon-set-nl82v. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 07:50:38.750: INFO: Wrong image for pod: daemon-set-r68rq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 07:50:39.750: INFO: Wrong image for pod: daemon-set-nl82v. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 07:50:39.750: INFO: Wrong image for pod: daemon-set-r68rq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 07:50:40.750: INFO: Wrong image for pod: daemon-set-nl82v. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 07:50:40.751: INFO: Wrong image for pod: daemon-set-r68rq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 07:50:41.751: INFO: Wrong image for pod: daemon-set-nl82v. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 07:50:41.751: INFO: Wrong image for pod: daemon-set-r68rq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 07:50:42.751: INFO: Wrong image for pod: daemon-set-nl82v. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 07:50:42.751: INFO: Wrong image for pod: daemon-set-r68rq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 07:50:43.750: INFO: Wrong image for pod: daemon-set-nl82v. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 07:50:43.750: INFO: Wrong image for pod: daemon-set-r68rq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 07:50:44.750: INFO: Wrong image for pod: daemon-set-nl82v. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 07:50:44.750: INFO: Wrong image for pod: daemon-set-r68rq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 07:50:45.750: INFO: Wrong image for pod: daemon-set-nl82v. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 07:50:45.750: INFO: Wrong image for pod: daemon-set-r68rq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 07:50:46.750: INFO: Wrong image for pod: daemon-set-nl82v. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 07:50:46.750: INFO: Wrong image for pod: daemon-set-r68rq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 07:50:47.750: INFO: Wrong image for pod: daemon-set-nl82v. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 07:50:47.750: INFO: Wrong image for pod: daemon-set-r68rq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 07:50:48.750: INFO: Wrong image for pod: daemon-set-nl82v. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 07:50:48.750: INFO: Wrong image for pod: daemon-set-r68rq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 07:50:49.750: INFO: Wrong image for pod: daemon-set-nl82v. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 07:50:49.750: INFO: Wrong image for pod: daemon-set-r68rq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 07:50:50.749: INFO: Wrong image for pod: daemon-set-nl82v. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 07:50:50.749: INFO: Wrong image for pod: daemon-set-r68rq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 07:50:51.750: INFO: Wrong image for pod: daemon-set-nl82v. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 07:50:51.750: INFO: Wrong image for pod: daemon-set-r68rq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 07:50:52.752: INFO: Wrong image for pod: daemon-set-nl82v. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 07:50:52.752: INFO: Wrong image for pod: daemon-set-r68rq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 07:50:53.750: INFO: Wrong image for pod: daemon-set-nl82v. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 07:50:53.750: INFO: Wrong image for pod: daemon-set-r68rq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 07:50:54.750: INFO: Wrong image for pod: daemon-set-nl82v. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 07:50:54.750: INFO: Wrong image for pod: daemon-set-r68rq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 07:50:55.749: INFO: Wrong image for pod: daemon-set-nl82v. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 07:50:55.749: INFO: Wrong image for pod: daemon-set-r68rq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 07:50:56.752: INFO: Wrong image for pod: daemon-set-nl82v. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 07:50:56.753: INFO: Wrong image for pod: daemon-set-r68rq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 07:50:57.750: INFO: Wrong image for pod: daemon-set-nl82v. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 07:50:57.750: INFO: Wrong image for pod: daemon-set-r68rq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 07:50:58.750: INFO: Wrong image for pod: daemon-set-nl82v. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 07:50:58.750: INFO: Wrong image for pod: daemon-set-r68rq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 07:50:59.750: INFO: Wrong image for pod: daemon-set-nl82v. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 07:50:59.750: INFO: Wrong image for pod: daemon-set-r68rq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 07:51:00.750: INFO: Wrong image for pod: daemon-set-nl82v. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 07:51:00.750: INFO: Wrong image for pod: daemon-set-r68rq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 07:51:01.750: INFO: Wrong image for pod: daemon-set-nl82v. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 07:51:01.750: INFO: Wrong image for pod: daemon-set-r68rq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 07:51:02.750: INFO: Wrong image for pod: daemon-set-nl82v. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 07:51:02.750: INFO: Wrong image for pod: daemon-set-r68rq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 07:51:03.750: INFO: Wrong image for pod: daemon-set-nl82v. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 07:51:03.750: INFO: Wrong image for pod: daemon-set-r68rq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 07:51:04.750: INFO: Wrong image for pod: daemon-set-nl82v. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 07:51:04.750: INFO: Wrong image for pod: daemon-set-r68rq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 07:51:05.750: INFO: Wrong image for pod: daemon-set-nl82v. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 07:51:05.750: INFO: Wrong image for pod: daemon-set-r68rq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 07:51:06.751: INFO: Wrong image for pod: daemon-set-nl82v. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 07:51:06.751: INFO: Wrong image for pod: daemon-set-r68rq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 07:51:07.759: INFO: Wrong image for pod: daemon-set-nl82v. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 07:51:07.759: INFO: Wrong image for pod: daemon-set-r68rq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 07:51:07.759: INFO: Pod daemon-set-r68rq is not available
Mar  1 07:51:08.749: INFO: Wrong image for pod: daemon-set-nl82v. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 07:51:08.749: INFO: Wrong image for pod: daemon-set-r68rq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 07:51:08.749: INFO: Pod daemon-set-r68rq is not available
Mar  1 07:51:09.751: INFO: Wrong image for pod: daemon-set-nl82v. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 07:51:09.751: INFO: Wrong image for pod: daemon-set-r68rq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 07:51:09.751: INFO: Pod daemon-set-r68rq is not available
Mar  1 07:51:10.749: INFO: Wrong image for pod: daemon-set-nl82v. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 07:51:10.750: INFO: Wrong image for pod: daemon-set-r68rq. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 07:51:10.750: INFO: Pod daemon-set-r68rq is not available
Mar  1 07:51:11.751: INFO: Pod daemon-set-6f67m is not available
Mar  1 07:51:11.751: INFO: Wrong image for pod: daemon-set-nl82v. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 07:51:12.750: INFO: Pod daemon-set-6f67m is not available
Mar  1 07:51:12.750: INFO: Wrong image for pod: daemon-set-nl82v. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 07:51:13.750: INFO: Pod daemon-set-6f67m is not available
Mar  1 07:51:13.750: INFO: Wrong image for pod: daemon-set-nl82v. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 07:51:14.750: INFO: Pod daemon-set-6f67m is not available
Mar  1 07:51:14.750: INFO: Wrong image for pod: daemon-set-nl82v. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 07:51:15.750: INFO: Wrong image for pod: daemon-set-nl82v. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 07:51:16.750: INFO: Wrong image for pod: daemon-set-nl82v. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 07:51:17.750: INFO: Wrong image for pod: daemon-set-nl82v. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 07:51:18.750: INFO: Wrong image for pod: daemon-set-nl82v. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 07:51:19.750: INFO: Wrong image for pod: daemon-set-nl82v. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 07:51:20.750: INFO: Wrong image for pod: daemon-set-nl82v. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 07:51:21.750: INFO: Wrong image for pod: daemon-set-nl82v. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 07:51:22.751: INFO: Wrong image for pod: daemon-set-nl82v. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 07:51:23.749: INFO: Wrong image for pod: daemon-set-nl82v. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 07:51:24.750: INFO: Wrong image for pod: daemon-set-nl82v. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 07:51:25.750: INFO: Wrong image for pod: daemon-set-nl82v. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 07:51:26.749: INFO: Wrong image for pod: daemon-set-nl82v. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 07:51:27.750: INFO: Wrong image for pod: daemon-set-nl82v. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 07:51:28.749: INFO: Wrong image for pod: daemon-set-nl82v. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 07:51:29.752: INFO: Wrong image for pod: daemon-set-nl82v. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 07:51:30.750: INFO: Wrong image for pod: daemon-set-nl82v. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 07:51:31.750: INFO: Wrong image for pod: daemon-set-nl82v. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 07:51:32.749: INFO: Wrong image for pod: daemon-set-nl82v. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 07:51:33.750: INFO: Wrong image for pod: daemon-set-nl82v. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 07:51:34.764: INFO: Wrong image for pod: daemon-set-nl82v. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 07:51:35.750: INFO: Wrong image for pod: daemon-set-nl82v. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 07:51:36.750: INFO: Wrong image for pod: daemon-set-nl82v. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 07:51:37.755: INFO: Wrong image for pod: daemon-set-nl82v. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 07:51:38.758: INFO: Wrong image for pod: daemon-set-nl82v. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 07:51:39.750: INFO: Wrong image for pod: daemon-set-nl82v. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 07:51:40.749: INFO: Wrong image for pod: daemon-set-nl82v. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 07:51:41.752: INFO: Wrong image for pod: daemon-set-nl82v. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 07:51:42.750: INFO: Wrong image for pod: daemon-set-nl82v. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 07:51:43.750: INFO: Wrong image for pod: daemon-set-nl82v. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 07:51:44.749: INFO: Wrong image for pod: daemon-set-nl82v. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 07:51:45.751: INFO: Wrong image for pod: daemon-set-nl82v. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 07:51:46.750: INFO: Wrong image for pod: daemon-set-nl82v. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 07:51:47.750: INFO: Wrong image for pod: daemon-set-nl82v. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 07:51:47.750: INFO: Pod daemon-set-nl82v is not available
Mar  1 07:51:48.750: INFO: Pod daemon-set-j7zpb is not available
STEP: Check that daemon pods are still running on every node of the cluster.
Mar  1 07:51:48.895: INFO: Number of nodes with available pods: 1
Mar  1 07:51:48.896: INFO: Node shoot--it--pub-az-nl4q9-cpu-worker-7dd9bbfd9c-gwjjt is running more than one daemon pod
Mar  1 07:51:49.968: INFO: Number of nodes with available pods: 1
Mar  1 07:51:49.968: INFO: Node shoot--it--pub-az-nl4q9-cpu-worker-7dd9bbfd9c-gwjjt is running more than one daemon pod
Mar  1 07:51:50.968: INFO: Number of nodes with available pods: 1
Mar  1 07:51:50.968: INFO: Node shoot--it--pub-az-nl4q9-cpu-worker-7dd9bbfd9c-gwjjt is running more than one daemon pod
Mar  1 07:51:51.968: INFO: Number of nodes with available pods: 1
Mar  1 07:51:51.968: INFO: Node shoot--it--pub-az-nl4q9-cpu-worker-7dd9bbfd9c-gwjjt is running more than one daemon pod
Mar  1 07:51:52.967: INFO: Number of nodes with available pods: 2
Mar  1 07:51:52.967: INFO: Number of running nodes: 2, number of available pods: 2
[AfterEach] [sig-apps] Daemon set [Serial]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting {extensions DaemonSet} daemon-set in namespace e2e-tests-daemonsets-2q2k9, will wait for the garbage collector to delete the pods
Mar  1 07:51:53.268: INFO: Deleting {extensions DaemonSet} daemon-set took: 37.922044ms
Mar  1 07:51:53.368: INFO: Terminating {extensions DaemonSet} daemon-set pods took: 100.231965ms
Mar  1 07:52:01.303: INFO: Number of nodes with available pods: 0
Mar  1 07:52:01.303: INFO: Number of running nodes: 0, number of available pods: 0
Mar  1 07:52:01.338: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-2q2k9/daemonsets","resourceVersion":"4769"},"items":null}

Mar  1 07:52:01.372: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-2q2k9/pods","resourceVersion":"4769"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 07:52:01.477: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-2q2k9" for this suite.
Mar  1 07:52:34.428: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 07:52:34.922: INFO: namespace: e2e-tests-daemonsets-2q2k9, resource: bindings, ignored listing per whitelist
Mar  1 07:52:35.834: INFO: namespace e2e-tests-daemonsets-2q2k9 deletion completed in 34.321591159s

• [SLOW TEST:127.302 seconds]
[sig-apps] Daemon set [Serial]
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 07:52:35.835: INFO: >>> kubeConfig: /tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-57zmd
STEP: Waiting for a default service account to be provisioned in namespace
[It] binary data should be reflected in volume [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-upd-fb45ceb6-3bf6-11e9-a72e-ce8290b78775
STEP: Creating the pod
STEP: Waiting for pod with text data
STEP: Waiting for pod with binary data
[AfterEach] [sig-storage] ConfigMap
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 07:52:45.920: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-57zmd" for this suite.
Mar  1 07:53:10.062: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 07:53:10.626: INFO: namespace: e2e-tests-configmap-57zmd, resource: bindings, ignored listing per whitelist
Mar  1 07:53:11.461: INFO: namespace e2e-tests-configmap-57zmd deletion completed in 25.506305269s

• [SLOW TEST:35.627 seconds]
[sig-storage] ConfigMap
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if not matching  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 07:53:11.462: INFO: >>> kubeConfig: /tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename sched-pred
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-sched-pred-hbwj4
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:78
Mar  1 07:53:12.985: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Mar  1 07:53:13.056: INFO: Waiting for terminating namespaces to be deleted...
Mar  1 07:53:13.092: INFO: 
Logging pods the kubelet thinks is on node shoot--it--pub-az-nl4q9-cpu-worker-7dd9bbfd9c-7fp9l before test
Mar  1 07:53:13.135: INFO: node-exporter-h6r77 from kube-system started at 2019-03-01 07:21:56 +0000 UTC (1 container statuses recorded)
Mar  1 07:53:13.135: INFO: 	Container node-exporter ready: true, restart count 0
Mar  1 07:53:13.135: INFO: kube-proxy-cq7cz from kube-system started at 2019-03-01 07:21:56 +0000 UTC (1 container statuses recorded)
Mar  1 07:53:13.135: INFO: 	Container kube-proxy ready: true, restart count 0
Mar  1 07:53:13.135: INFO: calico-node-mdbnz from kube-system started at 2019-03-01 07:21:56 +0000 UTC (1 container statuses recorded)
Mar  1 07:53:13.135: INFO: 	Container calico-node ready: true, restart count 0
Mar  1 07:53:13.135: INFO: 
Logging pods the kubelet thinks is on node shoot--it--pub-az-nl4q9-cpu-worker-7dd9bbfd9c-gwjjt before test
Mar  1 07:53:13.275: INFO: calico-node-tkxc4 from kube-system started at 2019-03-01 07:21:41 +0000 UTC (1 container statuses recorded)
Mar  1 07:53:13.275: INFO: 	Container calico-node ready: true, restart count 0
Mar  1 07:53:13.275: INFO: addons-nginx-ingress-nginx-ingress-k8s-backend-6498456576-4xrkj from kube-system started at 2019-03-01 07:21:41 +0000 UTC (1 container statuses recorded)
Mar  1 07:53:13.275: INFO: 	Container nginx-ingress-nginx-ingress-k8s-backend ready: true, restart count 0
Mar  1 07:53:13.275: INFO: coredns-5f4748c5f-rdst8 from kube-system started at 2019-03-01 07:21:41 +0000 UTC (1 container statuses recorded)
Mar  1 07:53:13.275: INFO: 	Container coredns ready: true, restart count 0
Mar  1 07:53:13.275: INFO: addons-nginx-ingress-controller-8f975c795-r87j9 from kube-system started at 2019-03-01 07:21:41 +0000 UTC (1 container statuses recorded)
Mar  1 07:53:13.275: INFO: 	Container nginx-ingress-controller ready: true, restart count 0
Mar  1 07:53:13.275: INFO: blackbox-exporter-58fd9b8556-jpgx4 from kube-system started at 2019-03-01 07:21:41 +0000 UTC (1 container statuses recorded)
Mar  1 07:53:13.275: INFO: 	Container blackbox-exporter ready: true, restart count 0
Mar  1 07:53:13.275: INFO: kube-proxy-dj7cg from kube-system started at 2019-03-01 07:21:41 +0000 UTC (1 container statuses recorded)
Mar  1 07:53:13.275: INFO: 	Container kube-proxy ready: true, restart count 0
Mar  1 07:53:13.275: INFO: addons-kube-lego-648f8c9f5c-ll4nb from kube-system started at 2019-03-01 07:21:41 +0000 UTC (1 container statuses recorded)
Mar  1 07:53:13.275: INFO: 	Container kube-lego ready: true, restart count 0
Mar  1 07:53:13.275: INFO: vpn-shoot-84b4694876-cv69m from kube-system started at 2019-03-01 07:21:41 +0000 UTC (1 container statuses recorded)
Mar  1 07:53:13.275: INFO: 	Container vpn-shoot ready: true, restart count 0
Mar  1 07:53:13.275: INFO: metrics-server-966574b4f-vwjz9 from kube-system started at 2019-03-01 07:21:41 +0000 UTC (1 container statuses recorded)
Mar  1 07:53:13.275: INFO: 	Container metrics-server ready: true, restart count 0
Mar  1 07:53:13.275: INFO: addons-kubernetes-dashboard-5f64f76bd-ksndd from kube-system started at 2019-03-01 07:21:41 +0000 UTC (1 container statuses recorded)
Mar  1 07:53:13.275: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
Mar  1 07:53:13.275: INFO: node-exporter-jrqgj from kube-system started at 2019-03-01 07:21:41 +0000 UTC (1 container statuses recorded)
Mar  1 07:53:13.275: INFO: 	Container node-exporter ready: true, restart count 0
[It] validates that NodeSelector is respected if not matching  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Trying to schedule Pod with nonempty NodeSelector.
STEP: Considering event: 
Type = [Warning], Name = [restricted-pod.1587c672e3f6f294], Reason = [FailedScheduling], Message = [0/2 nodes are available: 2 node(s) didn't match node selector.]
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 07:53:14.458: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-sched-pred-hbwj4" for this suite.
Mar  1 07:53:20.601: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 07:53:21.322: INFO: namespace: e2e-tests-sched-pred-hbwj4, resource: bindings, ignored listing per whitelist
Mar  1 07:53:21.996: INFO: namespace e2e-tests-sched-pred-hbwj4 deletion completed in 7.50242596s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:69

• [SLOW TEST:10.534 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates that NodeSelector is respected if not matching  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,default) [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 07:53:21.996: INFO: >>> kubeConfig: /tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-zrzg7
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,default) [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0666 on node default medium
Mar  1 07:53:23.678: INFO: Waiting up to 5m0s for pod "pod-16c3c7f9-3bf7-11e9-a72e-ce8290b78775" in namespace "e2e-tests-emptydir-zrzg7" to be "success or failure"
Mar  1 07:53:23.713: INFO: Pod "pod-16c3c7f9-3bf7-11e9-a72e-ce8290b78775": Phase="Pending", Reason="", readiness=false. Elapsed: 34.881311ms
Mar  1 07:53:25.798: INFO: Pod "pod-16c3c7f9-3bf7-11e9-a72e-ce8290b78775": Phase="Pending", Reason="", readiness=false. Elapsed: 2.120015588s
Mar  1 07:53:27.834: INFO: Pod "pod-16c3c7f9-3bf7-11e9-a72e-ce8290b78775": Phase="Pending", Reason="", readiness=false. Elapsed: 4.156358742s
Mar  1 07:53:29.888: INFO: Pod "pod-16c3c7f9-3bf7-11e9-a72e-ce8290b78775": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.209840384s
STEP: Saw pod success
Mar  1 07:53:29.888: INFO: Pod "pod-16c3c7f9-3bf7-11e9-a72e-ce8290b78775" satisfied condition "success or failure"
Mar  1 07:53:29.924: INFO: Trying to get logs from node shoot--it--pub-az-nl4q9-cpu-worker-7dd9bbfd9c-7fp9l pod pod-16c3c7f9-3bf7-11e9-a72e-ce8290b78775 container test-container: <nil>
STEP: delete the pod
Mar  1 07:53:30.007: INFO: Waiting for pod pod-16c3c7f9-3bf7-11e9-a72e-ce8290b78775 to disappear
Mar  1 07:53:30.068: INFO: Pod pod-16c3c7f9-3bf7-11e9-a72e-ce8290b78775 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 07:53:30.068: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-zrzg7" for this suite.
Mar  1 07:53:36.218: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 07:53:36.461: INFO: namespace: e2e-tests-emptydir-zrzg7, resource: bindings, ignored listing per whitelist
Mar  1 07:53:37.695: INFO: namespace e2e-tests-emptydir-zrzg7 deletion completed in 7.586955107s

• [SLOW TEST:15.699 seconds]
[sig-storage] EmptyDir volumes
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0666,default) [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide podname only [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 07:53:37.695: INFO: >>> kubeConfig: /tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-jf4nt
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide podname only [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Mar  1 07:53:39.407: INFO: Waiting up to 5m0s for pod "downwardapi-volume-2023ce7a-3bf7-11e9-a72e-ce8290b78775" in namespace "e2e-tests-downward-api-jf4nt" to be "success or failure"
Mar  1 07:53:39.443: INFO: Pod "downwardapi-volume-2023ce7a-3bf7-11e9-a72e-ce8290b78775": Phase="Pending", Reason="", readiness=false. Elapsed: 35.346732ms
Mar  1 07:53:41.478: INFO: Pod "downwardapi-volume-2023ce7a-3bf7-11e9-a72e-ce8290b78775": Phase="Pending", Reason="", readiness=false. Elapsed: 2.070929722s
Mar  1 07:53:43.514: INFO: Pod "downwardapi-volume-2023ce7a-3bf7-11e9-a72e-ce8290b78775": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.10653013s
STEP: Saw pod success
Mar  1 07:53:43.514: INFO: Pod "downwardapi-volume-2023ce7a-3bf7-11e9-a72e-ce8290b78775" satisfied condition "success or failure"
Mar  1 07:53:43.549: INFO: Trying to get logs from node shoot--it--pub-az-nl4q9-cpu-worker-7dd9bbfd9c-7fp9l pod downwardapi-volume-2023ce7a-3bf7-11e9-a72e-ce8290b78775 container client-container: <nil>
STEP: delete the pod
Mar  1 07:53:43.633: INFO: Waiting for pod downwardapi-volume-2023ce7a-3bf7-11e9-a72e-ce8290b78775 to disappear
Mar  1 07:53:43.668: INFO: Pod downwardapi-volume-2023ce7a-3bf7-11e9-a72e-ce8290b78775 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 07:53:43.668: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-jf4nt" for this suite.
Mar  1 07:53:49.816: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 07:53:51.078: INFO: namespace: e2e-tests-downward-api-jf4nt, resource: bindings, ignored listing per whitelist
Mar  1 07:53:51.251: INFO: namespace e2e-tests-downward-api-jf4nt deletion completed in 7.542237854s

• [SLOW TEST:13.556 seconds]
[sig-storage] Downward API volume
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide podname only [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node using proxy subresource  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] version v1
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 07:53:51.251: INFO: >>> kubeConfig: /tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename proxy
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-proxy-dhrvh
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node using proxy subresource  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Mar  1 07:53:52.886: INFO: (0) /api/v1/nodes/shoot--it--pub-az-nl4q9-cpu-worker-7dd9bbfd9c-7fp9l/proxy/logs/: <pre>
<a href="azure/">azure/</a>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<... (200; 39.991012ms)
Mar  1 07:53:52.929: INFO: (1) /api/v1/nodes/shoot--it--pub-az-nl4q9-cpu-worker-7dd9bbfd9c-7fp9l/proxy/logs/: <pre>
<a href="azure/">azure/</a>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<... (200; 43.03679ms)
Mar  1 07:53:52.966: INFO: (2) /api/v1/nodes/shoot--it--pub-az-nl4q9-cpu-worker-7dd9bbfd9c-7fp9l/proxy/logs/: <pre>
<a href="azure/">azure/</a>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<... (200; 36.884211ms)
Mar  1 07:53:53.003: INFO: (3) /api/v1/nodes/shoot--it--pub-az-nl4q9-cpu-worker-7dd9bbfd9c-7fp9l/proxy/logs/: <pre>
<a href="azure/">azure/</a>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<... (200; 37.004112ms)
Mar  1 07:53:53.040: INFO: (4) /api/v1/nodes/shoot--it--pub-az-nl4q9-cpu-worker-7dd9bbfd9c-7fp9l/proxy/logs/: <pre>
<a href="azure/">azure/</a>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<... (200; 37.622812ms)
Mar  1 07:53:53.078: INFO: (5) /api/v1/nodes/shoot--it--pub-az-nl4q9-cpu-worker-7dd9bbfd9c-7fp9l/proxy/logs/: <pre>
<a href="azure/">azure/</a>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<... (200; 37.137826ms)
Mar  1 07:53:53.115: INFO: (6) /api/v1/nodes/shoot--it--pub-az-nl4q9-cpu-worker-7dd9bbfd9c-7fp9l/proxy/logs/: <pre>
<a href="azure/">azure/</a>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<... (200; 37.331778ms)
Mar  1 07:53:53.153: INFO: (7) /api/v1/nodes/shoot--it--pub-az-nl4q9-cpu-worker-7dd9bbfd9c-7fp9l/proxy/logs/: <pre>
<a href="azure/">azure/</a>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<... (200; 37.813538ms)
Mar  1 07:53:53.190: INFO: (8) /api/v1/nodes/shoot--it--pub-az-nl4q9-cpu-worker-7dd9bbfd9c-7fp9l/proxy/logs/: <pre>
<a href="azure/">azure/</a>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<... (200; 37.366601ms)
Mar  1 07:53:53.228: INFO: (9) /api/v1/nodes/shoot--it--pub-az-nl4q9-cpu-worker-7dd9bbfd9c-7fp9l/proxy/logs/: <pre>
<a href="azure/">azure/</a>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<... (200; 37.82026ms)
Mar  1 07:53:53.265: INFO: (10) /api/v1/nodes/shoot--it--pub-az-nl4q9-cpu-worker-7dd9bbfd9c-7fp9l/proxy/logs/: <pre>
<a href="azure/">azure/</a>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<... (200; 36.976533ms)
Mar  1 07:53:53.303: INFO: (11) /api/v1/nodes/shoot--it--pub-az-nl4q9-cpu-worker-7dd9bbfd9c-7fp9l/proxy/logs/: <pre>
<a href="azure/">azure/</a>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<... (200; 37.446386ms)
Mar  1 07:53:53.340: INFO: (12) /api/v1/nodes/shoot--it--pub-az-nl4q9-cpu-worker-7dd9bbfd9c-7fp9l/proxy/logs/: <pre>
<a href="azure/">azure/</a>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<... (200; 36.846966ms)
Mar  1 07:53:53.378: INFO: (13) /api/v1/nodes/shoot--it--pub-az-nl4q9-cpu-worker-7dd9bbfd9c-7fp9l/proxy/logs/: <pre>
<a href="azure/">azure/</a>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<... (200; 38.612448ms)
Mar  1 07:53:53.416: INFO: (14) /api/v1/nodes/shoot--it--pub-az-nl4q9-cpu-worker-7dd9bbfd9c-7fp9l/proxy/logs/: <pre>
<a href="azure/">azure/</a>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<... (200; 37.259094ms)
Mar  1 07:53:53.453: INFO: (15) /api/v1/nodes/shoot--it--pub-az-nl4q9-cpu-worker-7dd9bbfd9c-7fp9l/proxy/logs/: <pre>
<a href="azure/">azure/</a>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<... (200; 37.624242ms)
Mar  1 07:53:53.491: INFO: (16) /api/v1/nodes/shoot--it--pub-az-nl4q9-cpu-worker-7dd9bbfd9c-7fp9l/proxy/logs/: <pre>
<a href="azure/">azure/</a>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<... (200; 37.722172ms)
Mar  1 07:53:53.529: INFO: (17) /api/v1/nodes/shoot--it--pub-az-nl4q9-cpu-worker-7dd9bbfd9c-7fp9l/proxy/logs/: <pre>
<a href="azure/">azure/</a>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<... (200; 37.237776ms)
Mar  1 07:53:53.566: INFO: (18) /api/v1/nodes/shoot--it--pub-az-nl4q9-cpu-worker-7dd9bbfd9c-7fp9l/proxy/logs/: <pre>
<a href="azure/">azure/</a>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<... (200; 37.087402ms)
Mar  1 07:53:53.602: INFO: (19) /api/v1/nodes/shoot--it--pub-az-nl4q9-cpu-worker-7dd9bbfd9c-7fp9l/proxy/logs/: <pre>
<a href="azure/">azure/</a>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<... (200; 36.341689ms)
[AfterEach] version v1
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 07:53:53.602: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-proxy-dhrvh" for this suite.
Mar  1 07:53:59.745: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 07:54:00.142: INFO: namespace: e2e-tests-proxy-dhrvh, resource: bindings, ignored listing per whitelist
Mar  1 07:54:01.172: INFO: namespace e2e-tests-proxy-dhrvh deletion completed in 7.534801092s

• [SLOW TEST:9.921 seconds]
[sig-network] Proxy
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy logs on node using proxy subresource  [Conformance]
    /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates resource limits of pods that are allowed to run  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 07:54:01.173: INFO: >>> kubeConfig: /tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename sched-pred
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-sched-pred-rvfhm
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:78
Mar  1 07:54:02.877: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Mar  1 07:54:02.951: INFO: Waiting for terminating namespaces to be deleted...
Mar  1 07:54:02.987: INFO: 
Logging pods the kubelet thinks is on node shoot--it--pub-az-nl4q9-cpu-worker-7dd9bbfd9c-7fp9l before test
Mar  1 07:54:03.026: INFO: calico-node-mdbnz from kube-system started at 2019-03-01 07:21:56 +0000 UTC (1 container statuses recorded)
Mar  1 07:54:03.026: INFO: 	Container calico-node ready: true, restart count 0
Mar  1 07:54:03.026: INFO: node-exporter-h6r77 from kube-system started at 2019-03-01 07:21:56 +0000 UTC (1 container statuses recorded)
Mar  1 07:54:03.026: INFO: 	Container node-exporter ready: true, restart count 0
Mar  1 07:54:03.026: INFO: kube-proxy-cq7cz from kube-system started at 2019-03-01 07:21:56 +0000 UTC (1 container statuses recorded)
Mar  1 07:54:03.026: INFO: 	Container kube-proxy ready: true, restart count 0
Mar  1 07:54:03.026: INFO: 
Logging pods the kubelet thinks is on node shoot--it--pub-az-nl4q9-cpu-worker-7dd9bbfd9c-gwjjt before test
Mar  1 07:54:03.071: INFO: node-exporter-jrqgj from kube-system started at 2019-03-01 07:21:41 +0000 UTC (1 container statuses recorded)
Mar  1 07:54:03.071: INFO: 	Container node-exporter ready: true, restart count 0
Mar  1 07:54:03.071: INFO: addons-kube-lego-648f8c9f5c-ll4nb from kube-system started at 2019-03-01 07:21:41 +0000 UTC (1 container statuses recorded)
Mar  1 07:54:03.071: INFO: 	Container kube-lego ready: true, restart count 0
Mar  1 07:54:03.071: INFO: vpn-shoot-84b4694876-cv69m from kube-system started at 2019-03-01 07:21:41 +0000 UTC (1 container statuses recorded)
Mar  1 07:54:03.071: INFO: 	Container vpn-shoot ready: true, restart count 0
Mar  1 07:54:03.071: INFO: metrics-server-966574b4f-vwjz9 from kube-system started at 2019-03-01 07:21:41 +0000 UTC (1 container statuses recorded)
Mar  1 07:54:03.071: INFO: 	Container metrics-server ready: true, restart count 0
Mar  1 07:54:03.071: INFO: addons-kubernetes-dashboard-5f64f76bd-ksndd from kube-system started at 2019-03-01 07:21:41 +0000 UTC (1 container statuses recorded)
Mar  1 07:54:03.071: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
Mar  1 07:54:03.071: INFO: kube-proxy-dj7cg from kube-system started at 2019-03-01 07:21:41 +0000 UTC (1 container statuses recorded)
Mar  1 07:54:03.071: INFO: 	Container kube-proxy ready: true, restart count 0
Mar  1 07:54:03.071: INFO: calico-node-tkxc4 from kube-system started at 2019-03-01 07:21:41 +0000 UTC (1 container statuses recorded)
Mar  1 07:54:03.071: INFO: 	Container calico-node ready: true, restart count 0
Mar  1 07:54:03.071: INFO: addons-nginx-ingress-nginx-ingress-k8s-backend-6498456576-4xrkj from kube-system started at 2019-03-01 07:21:41 +0000 UTC (1 container statuses recorded)
Mar  1 07:54:03.071: INFO: 	Container nginx-ingress-nginx-ingress-k8s-backend ready: true, restart count 0
Mar  1 07:54:03.071: INFO: coredns-5f4748c5f-rdst8 from kube-system started at 2019-03-01 07:21:41 +0000 UTC (1 container statuses recorded)
Mar  1 07:54:03.071: INFO: 	Container coredns ready: true, restart count 0
Mar  1 07:54:03.071: INFO: addons-nginx-ingress-controller-8f975c795-r87j9 from kube-system started at 2019-03-01 07:21:41 +0000 UTC (1 container statuses recorded)
Mar  1 07:54:03.071: INFO: 	Container nginx-ingress-controller ready: true, restart count 0
Mar  1 07:54:03.071: INFO: blackbox-exporter-58fd9b8556-jpgx4 from kube-system started at 2019-03-01 07:21:41 +0000 UTC (1 container statuses recorded)
Mar  1 07:54:03.071: INFO: 	Container blackbox-exporter ready: true, restart count 0
[It] validates resource limits of pods that are allowed to run  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: verifying the node has the label node shoot--it--pub-az-nl4q9-cpu-worker-7dd9bbfd9c-7fp9l
STEP: verifying the node has the label node shoot--it--pub-az-nl4q9-cpu-worker-7dd9bbfd9c-gwjjt
Mar  1 07:54:03.299: INFO: Pod addons-kube-lego-648f8c9f5c-ll4nb requesting resource cpu=20m on Node shoot--it--pub-az-nl4q9-cpu-worker-7dd9bbfd9c-gwjjt
Mar  1 07:54:03.299: INFO: Pod addons-kubernetes-dashboard-5f64f76bd-ksndd requesting resource cpu=50m on Node shoot--it--pub-az-nl4q9-cpu-worker-7dd9bbfd9c-gwjjt
Mar  1 07:54:03.299: INFO: Pod addons-nginx-ingress-controller-8f975c795-r87j9 requesting resource cpu=100m on Node shoot--it--pub-az-nl4q9-cpu-worker-7dd9bbfd9c-gwjjt
Mar  1 07:54:03.299: INFO: Pod addons-nginx-ingress-nginx-ingress-k8s-backend-6498456576-4xrkj requesting resource cpu=0m on Node shoot--it--pub-az-nl4q9-cpu-worker-7dd9bbfd9c-gwjjt
Mar  1 07:54:03.299: INFO: Pod blackbox-exporter-58fd9b8556-jpgx4 requesting resource cpu=5m on Node shoot--it--pub-az-nl4q9-cpu-worker-7dd9bbfd9c-gwjjt
Mar  1 07:54:03.299: INFO: Pod calico-node-mdbnz requesting resource cpu=100m on Node shoot--it--pub-az-nl4q9-cpu-worker-7dd9bbfd9c-7fp9l
Mar  1 07:54:03.299: INFO: Pod calico-node-tkxc4 requesting resource cpu=100m on Node shoot--it--pub-az-nl4q9-cpu-worker-7dd9bbfd9c-gwjjt
Mar  1 07:54:03.299: INFO: Pod coredns-5f4748c5f-rdst8 requesting resource cpu=50m on Node shoot--it--pub-az-nl4q9-cpu-worker-7dd9bbfd9c-gwjjt
Mar  1 07:54:03.299: INFO: Pod kube-proxy-cq7cz requesting resource cpu=20m on Node shoot--it--pub-az-nl4q9-cpu-worker-7dd9bbfd9c-7fp9l
Mar  1 07:54:03.299: INFO: Pod kube-proxy-dj7cg requesting resource cpu=20m on Node shoot--it--pub-az-nl4q9-cpu-worker-7dd9bbfd9c-gwjjt
Mar  1 07:54:03.299: INFO: Pod metrics-server-966574b4f-vwjz9 requesting resource cpu=20m on Node shoot--it--pub-az-nl4q9-cpu-worker-7dd9bbfd9c-gwjjt
Mar  1 07:54:03.299: INFO: Pod node-exporter-h6r77 requesting resource cpu=5m on Node shoot--it--pub-az-nl4q9-cpu-worker-7dd9bbfd9c-7fp9l
Mar  1 07:54:03.299: INFO: Pod node-exporter-jrqgj requesting resource cpu=5m on Node shoot--it--pub-az-nl4q9-cpu-worker-7dd9bbfd9c-gwjjt
Mar  1 07:54:03.299: INFO: Pod vpn-shoot-84b4694876-cv69m requesting resource cpu=50m on Node shoot--it--pub-az-nl4q9-cpu-worker-7dd9bbfd9c-gwjjt
STEP: Starting Pods to consume most of the cluster CPU.
STEP: Creating another pod that requires unavailable amount of CPU.
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-2e676308-3bf7-11e9-a72e-ce8290b78775.1587c67e841eb5cd], Reason = [Scheduled], Message = [Successfully assigned e2e-tests-sched-pred-rvfhm/filler-pod-2e676308-3bf7-11e9-a72e-ce8290b78775 to shoot--it--pub-az-nl4q9-cpu-worker-7dd9bbfd9c-gwjjt]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-2e676308-3bf7-11e9-a72e-ce8290b78775.1587c67ed05dd782], Reason = [Pulling], Message = [pulling image "k8s.gcr.io/pause:3.1"]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-2e676308-3bf7-11e9-a72e-ce8290b78775.1587c67ef03ca547], Reason = [Pulled], Message = [Successfully pulled image "k8s.gcr.io/pause:3.1"]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-2e676308-3bf7-11e9-a72e-ce8290b78775.1587c67f0754f41f], Reason = [Created], Message = [Created container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-2e676308-3bf7-11e9-a72e-ce8290b78775.1587c67f10cf073d], Reason = [Started], Message = [Started container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-2e6df0f7-3bf7-11e9-a72e-ce8290b78775.1587c67e86c16afc], Reason = [Scheduled], Message = [Successfully assigned e2e-tests-sched-pred-rvfhm/filler-pod-2e6df0f7-3bf7-11e9-a72e-ce8290b78775 to shoot--it--pub-az-nl4q9-cpu-worker-7dd9bbfd9c-7fp9l]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-2e6df0f7-3bf7-11e9-a72e-ce8290b78775.1587c67ed55047f0], Reason = [Pulling], Message = [pulling image "k8s.gcr.io/pause:3.1"]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-2e6df0f7-3bf7-11e9-a72e-ce8290b78775.1587c67f06493dc9], Reason = [Pulled], Message = [Successfully pulled image "k8s.gcr.io/pause:3.1"]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-2e6df0f7-3bf7-11e9-a72e-ce8290b78775.1587c67f23e1428d], Reason = [Created], Message = [Created container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-2e6df0f7-3bf7-11e9-a72e-ce8290b78775.1587c67f2ec6b2fe], Reason = [Started], Message = [Started container]
STEP: Considering event: 
Type = [Warning], Name = [additional-pod.1587c67f8107f703], Reason = [FailedScheduling], Message = [0/2 nodes are available: 2 Insufficient cpu.]
STEP: removing the label node off the node shoot--it--pub-az-nl4q9-cpu-worker-7dd9bbfd9c-7fp9l
STEP: verifying the node doesn't have the label node
STEP: removing the label node off the node shoot--it--pub-az-nl4q9-cpu-worker-7dd9bbfd9c-gwjjt
STEP: verifying the node doesn't have the label node
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 07:54:08.861: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-sched-pred-rvfhm" for this suite.
Mar  1 07:54:17.009: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 07:54:17.771: INFO: namespace: e2e-tests-sched-pred-rvfhm, resource: bindings, ignored listing per whitelist
Mar  1 07:54:18.533: INFO: namespace e2e-tests-sched-pred-rvfhm deletion completed in 9.636095787s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:69

• [SLOW TEST:17.360 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates resource limits of pods that are allowed to run  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl logs 
  should be able to retrieve and filter logs  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 07:54:18.533: INFO: >>> kubeConfig: /tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-swhrs
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Kubectl logs
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1083
STEP: creating an rc
Mar  1 07:54:20.091: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-az-nl4q9.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml create -f - --namespace=e2e-tests-kubectl-swhrs'
Mar  1 07:54:20.778: INFO: stderr: ""
Mar  1 07:54:20.778: INFO: stdout: "replicationcontroller/redis-master created\n"
[It] should be able to retrieve and filter logs  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Waiting for Redis master to start.
Mar  1 07:54:21.817: INFO: Selector matched 1 pods for map[app:redis]
Mar  1 07:54:21.817: INFO: Found 0 / 1
Mar  1 07:54:22.814: INFO: Selector matched 1 pods for map[app:redis]
Mar  1 07:54:22.814: INFO: Found 0 / 1
Mar  1 07:54:23.814: INFO: Selector matched 1 pods for map[app:redis]
Mar  1 07:54:23.814: INFO: Found 1 / 1
Mar  1 07:54:23.814: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Mar  1 07:54:23.850: INFO: Selector matched 1 pods for map[app:redis]
Mar  1 07:54:23.850: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
STEP: checking for a matching strings
Mar  1 07:54:23.850: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-az-nl4q9.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml logs redis-master-j75sg redis-master --namespace=e2e-tests-kubectl-swhrs'
Mar  1 07:54:24.226: INFO: stderr: ""
Mar  1 07:54:24.226: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 01 Mar 07:54:22.512 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 01 Mar 07:54:22.512 # Server started, Redis version 3.2.12\n1:M 01 Mar 07:54:22.512 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 01 Mar 07:54:22.513 * The server is now ready to accept connections on port 6379\n"
STEP: limiting log lines
Mar  1 07:54:24.226: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-az-nl4q9.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml log redis-master-j75sg redis-master --namespace=e2e-tests-kubectl-swhrs --tail=1'
Mar  1 07:54:24.554: INFO: stderr: ""
Mar  1 07:54:24.554: INFO: stdout: "1:M 01 Mar 07:54:22.513 * The server is now ready to accept connections on port 6379\n"
STEP: limiting log bytes
Mar  1 07:54:24.554: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-az-nl4q9.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml log redis-master-j75sg redis-master --namespace=e2e-tests-kubectl-swhrs --limit-bytes=1'
Mar  1 07:54:24.917: INFO: stderr: ""
Mar  1 07:54:24.917: INFO: stdout: " "
STEP: exposing timestamps
Mar  1 07:54:24.917: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-az-nl4q9.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml log redis-master-j75sg redis-master --namespace=e2e-tests-kubectl-swhrs --tail=1 --timestamps'
Mar  1 07:54:25.253: INFO: stderr: ""
Mar  1 07:54:25.253: INFO: stdout: "2019-03-01T07:54:22.51309277Z 1:M 01 Mar 07:54:22.513 * The server is now ready to accept connections on port 6379\n"
STEP: restricting to a time range
Mar  1 07:54:27.754: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-az-nl4q9.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml log redis-master-j75sg redis-master --namespace=e2e-tests-kubectl-swhrs --since=1s'
Mar  1 07:54:28.067: INFO: stderr: ""
Mar  1 07:54:28.067: INFO: stdout: ""
Mar  1 07:54:28.067: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-az-nl4q9.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml log redis-master-j75sg redis-master --namespace=e2e-tests-kubectl-swhrs --since=24h'
Mar  1 07:54:28.405: INFO: stderr: ""
Mar  1 07:54:28.405: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 01 Mar 07:54:22.512 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 01 Mar 07:54:22.512 # Server started, Redis version 3.2.12\n1:M 01 Mar 07:54:22.512 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 01 Mar 07:54:22.513 * The server is now ready to accept connections on port 6379\n"
[AfterEach] [k8s.io] Kubectl logs
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1088
STEP: using delete to clean up resources
Mar  1 07:54:28.405: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-az-nl4q9.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-swhrs'
Mar  1 07:54:28.688: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Mar  1 07:54:28.688: INFO: stdout: "replicationcontroller \"redis-master\" force deleted\n"
Mar  1 07:54:28.688: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-az-nl4q9.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml get rc,svc -l name=nginx --no-headers --namespace=e2e-tests-kubectl-swhrs'
Mar  1 07:54:29.012: INFO: stderr: "No resources found.\n"
Mar  1 07:54:29.012: INFO: stdout: ""
Mar  1 07:54:29.012: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-az-nl4q9.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml get pods -l name=nginx --namespace=e2e-tests-kubectl-swhrs -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Mar  1 07:54:29.373: INFO: stderr: ""
Mar  1 07:54:29.373: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 07:54:29.373: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-swhrs" for this suite.
Mar  1 07:54:51.517: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 07:54:52.189: INFO: namespace: e2e-tests-kubectl-swhrs, resource: bindings, ignored listing per whitelist
Mar  1 07:54:52.956: INFO: namespace e2e-tests-kubectl-swhrs deletion completed in 23.545700054s

• [SLOW TEST:34.423 seconds]
[sig-cli] Kubectl client
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl logs
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should be able to retrieve and filter logs  [Conformance]
    /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with downward pod [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 07:54:52.956: INFO: >>> kubeConfig: /tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-subpath-5jcs6
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with downward pod [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-downwardapi-94np
STEP: Creating a pod to test atomic-volume-subpath
Mar  1 07:54:54.594: INFO: Waiting up to 5m0s for pod "pod-subpath-test-downwardapi-94np" in namespace "e2e-tests-subpath-5jcs6" to be "success or failure"
Mar  1 07:54:54.630: INFO: Pod "pod-subpath-test-downwardapi-94np": Phase="Pending", Reason="", readiness=false. Elapsed: 35.139338ms
Mar  1 07:54:56.673: INFO: Pod "pod-subpath-test-downwardapi-94np": Phase="Pending", Reason="", readiness=false. Elapsed: 2.079582891s
Mar  1 07:54:58.710: INFO: Pod "pod-subpath-test-downwardapi-94np": Phase="Pending", Reason="", readiness=false. Elapsed: 4.115677544s
Mar  1 07:55:00.746: INFO: Pod "pod-subpath-test-downwardapi-94np": Phase="Running", Reason="", readiness=false. Elapsed: 6.152225342s
Mar  1 07:55:02.782: INFO: Pod "pod-subpath-test-downwardapi-94np": Phase="Running", Reason="", readiness=false. Elapsed: 8.188267353s
Mar  1 07:55:04.818: INFO: Pod "pod-subpath-test-downwardapi-94np": Phase="Running", Reason="", readiness=false. Elapsed: 10.224302834s
Mar  1 07:55:06.854: INFO: Pod "pod-subpath-test-downwardapi-94np": Phase="Running", Reason="", readiness=false. Elapsed: 12.260376796s
Mar  1 07:55:08.894: INFO: Pod "pod-subpath-test-downwardapi-94np": Phase="Running", Reason="", readiness=false. Elapsed: 14.30046786s
Mar  1 07:55:10.932: INFO: Pod "pod-subpath-test-downwardapi-94np": Phase="Running", Reason="", readiness=false. Elapsed: 16.338240265s
Mar  1 07:55:12.969: INFO: Pod "pod-subpath-test-downwardapi-94np": Phase="Running", Reason="", readiness=false. Elapsed: 18.375355128s
Mar  1 07:55:15.006: INFO: Pod "pod-subpath-test-downwardapi-94np": Phase="Running", Reason="", readiness=false. Elapsed: 20.411702434s
Mar  1 07:55:17.042: INFO: Pod "pod-subpath-test-downwardapi-94np": Phase="Running", Reason="", readiness=false. Elapsed: 22.448124023s
Mar  1 07:55:19.077: INFO: Pod "pod-subpath-test-downwardapi-94np": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.483491844s
STEP: Saw pod success
Mar  1 07:55:19.077: INFO: Pod "pod-subpath-test-downwardapi-94np" satisfied condition "success or failure"
Mar  1 07:55:19.113: INFO: Trying to get logs from node shoot--it--pub-az-nl4q9-cpu-worker-7dd9bbfd9c-7fp9l pod pod-subpath-test-downwardapi-94np container test-container-subpath-downwardapi-94np: <nil>
STEP: delete the pod
Mar  1 07:55:19.205: INFO: Waiting for pod pod-subpath-test-downwardapi-94np to disappear
Mar  1 07:55:19.248: INFO: Pod pod-subpath-test-downwardapi-94np no longer exists
STEP: Deleting pod pod-subpath-test-downwardapi-94np
Mar  1 07:55:19.248: INFO: Deleting pod "pod-subpath-test-downwardapi-94np" in namespace "e2e-tests-subpath-5jcs6"
[AfterEach] [sig-storage] Subpath
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 07:55:19.283: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-5jcs6" for this suite.
Mar  1 07:55:25.425: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 07:55:26.267: INFO: namespace: e2e-tests-subpath-5jcs6, resource: bindings, ignored listing per whitelist
Mar  1 07:55:26.820: INFO: namespace e2e-tests-subpath-5jcs6 deletion completed in 7.501583884s

• [SLOW TEST:33.864 seconds]
[sig-storage] Subpath
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with downward pod [Conformance]
    /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Projected 
  should set DefaultMode on files [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 07:55:26.820: INFO: >>> kubeConfig: /tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-jz5pc
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should set DefaultMode on files [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Mar  1 07:55:28.449: INFO: Waiting up to 5m0s for pod "downwardapi-volume-612231e1-3bf7-11e9-a72e-ce8290b78775" in namespace "e2e-tests-projected-jz5pc" to be "success or failure"
Mar  1 07:55:28.485: INFO: Pod "downwardapi-volume-612231e1-3bf7-11e9-a72e-ce8290b78775": Phase="Pending", Reason="", readiness=false. Elapsed: 35.834897ms
Mar  1 07:55:30.520: INFO: Pod "downwardapi-volume-612231e1-3bf7-11e9-a72e-ce8290b78775": Phase="Pending", Reason="", readiness=false. Elapsed: 2.071285896s
Mar  1 07:55:32.556: INFO: Pod "downwardapi-volume-612231e1-3bf7-11e9-a72e-ce8290b78775": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.10677639s
STEP: Saw pod success
Mar  1 07:55:32.556: INFO: Pod "downwardapi-volume-612231e1-3bf7-11e9-a72e-ce8290b78775" satisfied condition "success or failure"
Mar  1 07:55:32.590: INFO: Trying to get logs from node shoot--it--pub-az-nl4q9-cpu-worker-7dd9bbfd9c-7fp9l pod downwardapi-volume-612231e1-3bf7-11e9-a72e-ce8290b78775 container client-container: <nil>
STEP: delete the pod
Mar  1 07:55:32.673: INFO: Waiting for pod downwardapi-volume-612231e1-3bf7-11e9-a72e-ce8290b78775 to disappear
Mar  1 07:55:32.708: INFO: Pod downwardapi-volume-612231e1-3bf7-11e9-a72e-ce8290b78775 no longer exists
[AfterEach] [sig-storage] Projected
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 07:55:32.708: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-jz5pc" for this suite.
Mar  1 07:55:38.849: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 07:55:40.218: INFO: namespace: e2e-tests-projected-jz5pc, resource: bindings, ignored listing per whitelist
Mar  1 07:55:40.290: INFO: namespace e2e-tests-projected-jz5pc deletion completed in 7.546898451s

• [SLOW TEST:13.470 seconds]
[sig-storage] Projected
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should set DefaultMode on files [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 07:55:40.290: INFO: >>> kubeConfig: /tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-t4chk
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-692c8500-3bf7-11e9-a72e-ce8290b78775
STEP: Creating a pod to test consume secrets
Mar  1 07:55:41.975: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-6931fa51-3bf7-11e9-a72e-ce8290b78775" in namespace "e2e-tests-projected-t4chk" to be "success or failure"
Mar  1 07:55:42.010: INFO: Pod "pod-projected-secrets-6931fa51-3bf7-11e9-a72e-ce8290b78775": Phase="Pending", Reason="", readiness=false. Elapsed: 34.925564ms
Mar  1 07:55:44.046: INFO: Pod "pod-projected-secrets-6931fa51-3bf7-11e9-a72e-ce8290b78775": Phase="Pending", Reason="", readiness=false. Elapsed: 2.070444429s
Mar  1 07:55:46.082: INFO: Pod "pod-projected-secrets-6931fa51-3bf7-11e9-a72e-ce8290b78775": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.106251072s
STEP: Saw pod success
Mar  1 07:55:46.082: INFO: Pod "pod-projected-secrets-6931fa51-3bf7-11e9-a72e-ce8290b78775" satisfied condition "success or failure"
Mar  1 07:55:46.117: INFO: Trying to get logs from node shoot--it--pub-az-nl4q9-cpu-worker-7dd9bbfd9c-7fp9l pod pod-projected-secrets-6931fa51-3bf7-11e9-a72e-ce8290b78775 container projected-secret-volume-test: <nil>
STEP: delete the pod
Mar  1 07:55:46.200: INFO: Waiting for pod pod-projected-secrets-6931fa51-3bf7-11e9-a72e-ce8290b78775 to disappear
Mar  1 07:55:46.234: INFO: Pod pod-projected-secrets-6931fa51-3bf7-11e9-a72e-ce8290b78775 no longer exists
[AfterEach] [sig-storage] Projected
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 07:55:46.234: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-t4chk" for this suite.
Mar  1 07:55:52.380: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 07:55:52.829: INFO: namespace: e2e-tests-projected-t4chk, resource: bindings, ignored listing per whitelist
Mar  1 07:55:53.752: INFO: namespace e2e-tests-projected-t4chk deletion completed in 7.478912059s

• [SLOW TEST:13.462 seconds]
[sig-storage] Projected
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 07:55:53.753: INFO: >>> kubeConfig: /tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-statefulset-brnmg
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-brnmg
[It] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Initializing watcher for selector baz=blah,foo=bar
STEP: Creating stateful set ss in namespace e2e-tests-statefulset-brnmg
STEP: Waiting until all stateful set ss replicas will be running in namespace e2e-tests-statefulset-brnmg
Mar  1 07:55:55.518: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Pending - Ready=false
Mar  1 07:56:05.554: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will halt with unhealthy stateful pod
Mar  1 07:56:05.589: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-az-nl4q9.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-brnmg ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Mar  1 07:56:06.579: INFO: stderr: ""
Mar  1 07:56:06.579: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Mar  1 07:56:06.579: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Mar  1 07:56:06.614: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Mar  1 07:56:16.659: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Mar  1 07:56:16.659: INFO: Waiting for statefulset status.replicas updated to 0
Mar  1 07:56:16.801: INFO: Verifying statefulset ss doesn't scale past 1 for another 9.999999572s
Mar  1 07:56:17.837: INFO: Verifying statefulset ss doesn't scale past 1 for another 8.964394525s
Mar  1 07:56:18.874: INFO: Verifying statefulset ss doesn't scale past 1 for another 7.92828061s
Mar  1 07:56:19.918: INFO: Verifying statefulset ss doesn't scale past 1 for another 6.892066686s
Mar  1 07:56:20.955: INFO: Verifying statefulset ss doesn't scale past 1 for another 5.847709085s
Mar  1 07:56:21.991: INFO: Verifying statefulset ss doesn't scale past 1 for another 4.810959909s
Mar  1 07:56:23.028: INFO: Verifying statefulset ss doesn't scale past 1 for another 3.77452495s
Mar  1 07:56:24.071: INFO: Verifying statefulset ss doesn't scale past 1 for another 2.737511005s
Mar  1 07:56:25.108: INFO: Verifying statefulset ss doesn't scale past 1 for another 1.694777261s
Mar  1 07:56:26.144: INFO: Verifying statefulset ss doesn't scale past 1 for another 658.080873ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace e2e-tests-statefulset-brnmg
Mar  1 07:56:27.180: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-az-nl4q9.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-brnmg ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar  1 07:56:28.110: INFO: stderr: ""
Mar  1 07:56:28.110: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Mar  1 07:56:28.110: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Mar  1 07:56:28.147: INFO: Found 1 stateful pods, waiting for 3
Mar  1 07:56:38.185: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Mar  1 07:56:38.185: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Mar  1 07:56:38.185: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Verifying that stateful set ss was scaled up in order
STEP: Scale down will halt with unhealthy stateful pod
Mar  1 07:56:38.254: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-az-nl4q9.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-brnmg ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Mar  1 07:56:39.134: INFO: stderr: ""
Mar  1 07:56:39.134: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Mar  1 07:56:39.134: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Mar  1 07:56:39.134: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-az-nl4q9.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-brnmg ss-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Mar  1 07:56:39.961: INFO: stderr: ""
Mar  1 07:56:39.961: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Mar  1 07:56:39.961: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Mar  1 07:56:39.962: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-az-nl4q9.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-brnmg ss-2 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Mar  1 07:56:40.835: INFO: stderr: ""
Mar  1 07:56:40.836: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Mar  1 07:56:40.836: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-2: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Mar  1 07:56:40.836: INFO: Waiting for statefulset status.replicas updated to 0
Mar  1 07:56:40.873: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 1
Mar  1 07:56:50.946: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Mar  1 07:56:50.946: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Mar  1 07:56:50.946: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Mar  1 07:56:51.053: INFO: Verifying statefulset ss doesn't scale past 3 for another 9.999999587s
Mar  1 07:56:52.089: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.964138926s
Mar  1 07:56:53.126: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.928109136s
Mar  1 07:56:54.162: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.891101796s
Mar  1 07:56:55.199: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.855122996s
Mar  1 07:56:56.236: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.818777489s
Mar  1 07:56:57.273: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.781506846s
Mar  1 07:56:58.312: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.744696294s
Mar  1 07:56:59.348: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.705578588s
Mar  1 07:57:00.385: INFO: Verifying statefulset ss doesn't scale past 3 for another 668.827646ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacee2e-tests-statefulset-brnmg
Mar  1 07:57:01.421: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-az-nl4q9.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-brnmg ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar  1 07:57:02.394: INFO: stderr: ""
Mar  1 07:57:02.394: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Mar  1 07:57:02.394: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Mar  1 07:57:02.394: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-az-nl4q9.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-brnmg ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar  1 07:57:03.255: INFO: stderr: ""
Mar  1 07:57:03.255: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Mar  1 07:57:03.255: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Mar  1 07:57:03.255: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-az-nl4q9.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-brnmg ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar  1 07:57:04.026: INFO: rc: 1
Mar  1 07:57:04.026: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/go/src/k8s.io/kubernetes/_output/bin/kubectl [kubectl --server=https://api.pub-az-nl4q9.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-brnmg ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server: 
 [] <nil> 0xc00110f1d0 exit status 1 <nil> <nil> true [0xc0000f8b88 0xc0000f8bc8 0xc0000f8bf8] [0xc0000f8b88 0xc0000f8bc8 0xc0000f8bf8] [0xc0000f8bc0 0xc0000f8bd8] [0x932420 0x932420] 0xc00191c720 <nil>}:
Command stdout:

stderr:
Error from server: 

error:
exit status 1

Mar  1 07:57:14.026: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-az-nl4q9.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-brnmg ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar  1 07:57:14.318: INFO: rc: 1
Mar  1 07:57:14.318: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/go/src/k8s.io/kubernetes/_output/bin/kubectl [kubectl --server=https://api.pub-az-nl4q9.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-brnmg ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc00110f4a0 exit status 1 <nil> <nil> true [0xc0000f8c10 0xc0000f8c28 0xc0000f8c68] [0xc0000f8c10 0xc0000f8c28 0xc0000f8c68] [0xc0000f8c20 0xc0000f8c60] [0x932420 0x932420] 0xc00191cae0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Mar  1 07:57:24.319: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-az-nl4q9.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-brnmg ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar  1 07:57:24.602: INFO: rc: 1
Mar  1 07:57:24.602: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/go/src/k8s.io/kubernetes/_output/bin/kubectl [kubectl --server=https://api.pub-az-nl4q9.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-brnmg ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc0012c7890 exit status 1 <nil> <nil> true [0xc0015e8930 0xc0015e8980 0xc0015e89f0] [0xc0015e8930 0xc0015e8980 0xc0015e89f0] [0xc0015e8968 0xc0015e89e0] [0x932420 0x932420] 0xc001e75620 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Mar  1 07:57:34.602: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-az-nl4q9.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-brnmg ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar  1 07:57:34.876: INFO: rc: 1
Mar  1 07:57:34.876: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/go/src/k8s.io/kubernetes/_output/bin/kubectl [kubectl --server=https://api.pub-az-nl4q9.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-brnmg ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc000f1d2f0 exit status 1 <nil> <nil> true [0xc00000ed18 0xc00000ee38 0xc00000ef30] [0xc00000ed18 0xc00000ee38 0xc00000ef30] [0xc00000ee20 0xc00000ee98] [0x932420 0x932420] 0xc0017a9920 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Mar  1 07:57:44.877: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-az-nl4q9.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-brnmg ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar  1 07:57:45.166: INFO: rc: 1
Mar  1 07:57:45.166: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/go/src/k8s.io/kubernetes/_output/bin/kubectl [kubectl --server=https://api.pub-az-nl4q9.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-brnmg ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc000f1d5c0 exit status 1 <nil> <nil> true [0xc00000ef98 0xc00000efd0 0xc00000f098] [0xc00000ef98 0xc00000efd0 0xc00000f098] [0xc00000efa8 0xc00000f090] [0x932420 0x932420] 0xc0017a9c20 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Mar  1 07:57:55.168: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-az-nl4q9.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-brnmg ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar  1 07:57:55.475: INFO: rc: 1
Mar  1 07:57:55.475: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/go/src/k8s.io/kubernetes/_output/bin/kubectl [kubectl --server=https://api.pub-az-nl4q9.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-brnmg ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc0012c7b60 exit status 1 <nil> <nil> true [0xc0015e8a08 0xc0015e8a48 0xc0015e8ab8] [0xc0015e8a08 0xc0015e8a48 0xc0015e8ab8] [0xc0015e8a38 0xc0015e8aa0] [0x932420 0x932420] 0xc001e75aa0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Mar  1 07:58:05.476: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-az-nl4q9.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-brnmg ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar  1 07:58:05.754: INFO: rc: 1
Mar  1 07:58:05.754: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/go/src/k8s.io/kubernetes/_output/bin/kubectl [kubectl --server=https://api.pub-az-nl4q9.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-brnmg ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc00110f740 exit status 1 <nil> <nil> true [0xc0000f8c78 0xc0000f8d58 0xc0000f8d98] [0xc0000f8c78 0xc0000f8d58 0xc0000f8d98] [0xc0000f8d50 0xc0000f8d78] [0x932420 0x932420] 0xc00191cde0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Mar  1 07:58:15.754: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-az-nl4q9.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-brnmg ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar  1 07:58:15.980: INFO: rc: 1
Mar  1 07:58:15.980: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/go/src/k8s.io/kubernetes/_output/bin/kubectl [kubectl --server=https://api.pub-az-nl4q9.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-brnmg ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc000f1d890 exit status 1 <nil> <nil> true [0xc00000f0d0 0xc00000f170 0xc00000f230] [0xc00000f0d0 0xc00000f170 0xc00000f230] [0xc00000f0f8 0xc00000f1f0] [0x932420 0x932420] 0xc0017a9f20 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Mar  1 07:58:25.980: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-az-nl4q9.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-brnmg ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar  1 07:58:26.295: INFO: rc: 1
Mar  1 07:58:26.295: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/go/src/k8s.io/kubernetes/_output/bin/kubectl [kubectl --server=https://api.pub-az-nl4q9.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-brnmg ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc001b322a0 exit status 1 <nil> <nil> true [0xc0007ac120 0xc0007ac380 0xc0007ac3e0] [0xc0007ac120 0xc0007ac380 0xc0007ac3e0] [0xc0007ac348 0xc0007ac3d8] [0x932420 0x932420] 0xc0012c0300 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Mar  1 07:58:36.295: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-az-nl4q9.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-brnmg ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar  1 07:58:36.766: INFO: rc: 1
Mar  1 07:58:36.767: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/go/src/k8s.io/kubernetes/_output/bin/kubectl [kubectl --server=https://api.pub-az-nl4q9.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-brnmg ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc0019262a0 exit status 1 <nil> <nil> true [0xc0000f8030 0xc0000f8258 0xc0000f8288] [0xc0000f8030 0xc0000f8258 0xc0000f8288] [0xc0000f81b8 0xc0000f8280] [0x932420 0x932420] 0xc0017a8d20 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Mar  1 07:58:46.768: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-az-nl4q9.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-brnmg ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar  1 07:58:47.159: INFO: rc: 1
Mar  1 07:58:47.159: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/go/src/k8s.io/kubernetes/_output/bin/kubectl [kubectl --server=https://api.pub-az-nl4q9.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-brnmg ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc000704f30 exit status 1 <nil> <nil> true [0xc00000e078 0xc00000e1c0 0xc00000e2e0] [0xc00000e078 0xc00000e1c0 0xc00000e2e0] [0xc00000e130 0xc00000e2a8] [0x932420 0x932420] 0xc002006240 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Mar  1 07:58:57.160: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-az-nl4q9.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-brnmg ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar  1 07:58:57.445: INFO: rc: 1
Mar  1 07:58:57.445: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/go/src/k8s.io/kubernetes/_output/bin/kubectl [kubectl --server=https://api.pub-az-nl4q9.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-brnmg ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc001926540 exit status 1 <nil> <nil> true [0xc0000f8290 0xc0000f82d0 0xc0000f8350] [0xc0000f8290 0xc0000f82d0 0xc0000f8350] [0xc0000f82a8 0xc0000f82f8] [0x932420 0x932420] 0xc0017a9140 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Mar  1 07:59:07.445: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-az-nl4q9.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-brnmg ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar  1 07:59:07.770: INFO: rc: 1
Mar  1 07:59:07.770: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/go/src/k8s.io/kubernetes/_output/bin/kubectl [kubectl --server=https://api.pub-az-nl4q9.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-brnmg ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc001b32540 exit status 1 <nil> <nil> true [0xc0007ac3f0 0xc0007ac4b8 0xc0007ac5d0] [0xc0007ac3f0 0xc0007ac4b8 0xc0007ac5d0] [0xc0007ac4a8 0xc0007ac5b8] [0x932420 0x932420] 0xc0012c0600 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Mar  1 07:59:17.771: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-az-nl4q9.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-brnmg ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar  1 07:59:18.256: INFO: rc: 1
Mar  1 07:59:18.259: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/go/src/k8s.io/kubernetes/_output/bin/kubectl [kubectl --server=https://api.pub-az-nl4q9.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-brnmg ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc001b328d0 exit status 1 <nil> <nil> true [0xc0007ac5e8 0xc0007ac668 0xc0007ac790] [0xc0007ac5e8 0xc0007ac668 0xc0007ac790] [0xc0007ac618 0xc0007ac730] [0x932420 0x932420] 0xc0012c09c0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Mar  1 07:59:28.260: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-az-nl4q9.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-brnmg ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar  1 07:59:28.533: INFO: rc: 1
Mar  1 07:59:28.534: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/go/src/k8s.io/kubernetes/_output/bin/kubectl [kubectl --server=https://api.pub-az-nl4q9.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-brnmg ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc001b32c60 exit status 1 <nil> <nil> true [0xc0007ac838 0xc0007ac940 0xc0007ac9f8] [0xc0007ac838 0xc0007ac940 0xc0007ac9f8] [0xc0007ac8e8 0xc0007ac978] [0x932420 0x932420] 0xc0012c0cc0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Mar  1 07:59:38.534: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-az-nl4q9.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-brnmg ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar  1 07:59:38.850: INFO: rc: 1
Mar  1 07:59:38.850: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/go/src/k8s.io/kubernetes/_output/bin/kubectl [kubectl --server=https://api.pub-az-nl4q9.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-brnmg ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc001926840 exit status 1 <nil> <nil> true [0xc0000f8368 0xc0000f8388 0xc0000f83a0] [0xc0000f8368 0xc0000f8388 0xc0000f83a0] [0xc0000f8380 0xc0000f8398] [0x932420 0x932420] 0xc0017a9440 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Mar  1 07:59:48.850: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-az-nl4q9.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-brnmg ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar  1 07:59:49.115: INFO: rc: 1
Mar  1 07:59:49.115: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/go/src/k8s.io/kubernetes/_output/bin/kubectl [kubectl --server=https://api.pub-az-nl4q9.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-brnmg ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc001926bd0 exit status 1 <nil> <nil> true [0xc0000f83a8 0xc0000f83c0 0xc0000f83e8] [0xc0000f83a8 0xc0000f83c0 0xc0000f83e8] [0xc0000f83b8 0xc0000f83d8] [0x932420 0x932420] 0xc0017a9740 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Mar  1 07:59:59.115: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-az-nl4q9.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-brnmg ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar  1 07:59:59.400: INFO: rc: 1
Mar  1 07:59:59.400: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/go/src/k8s.io/kubernetes/_output/bin/kubectl [kubectl --server=https://api.pub-az-nl4q9.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-brnmg ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc001926ff0 exit status 1 <nil> <nil> true [0xc0000f83f0 0xc0000f8408 0xc0000f8450] [0xc0000f83f0 0xc0000f8408 0xc0000f8450] [0xc0000f8400 0xc0000f8448] [0x932420 0x932420] 0xc0017a9a40 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Mar  1 08:00:09.400: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-az-nl4q9.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-brnmg ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar  1 08:00:09.681: INFO: rc: 1
Mar  1 08:00:09.681: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/go/src/k8s.io/kubernetes/_output/bin/kubectl [kubectl --server=https://api.pub-az-nl4q9.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-brnmg ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc0019273e0 exit status 1 <nil> <nil> true [0xc0000f8458 0xc0000f8490 0xc0000f84c8] [0xc0000f8458 0xc0000f8490 0xc0000f84c8] [0xc0000f8488 0xc0000f84c0] [0x932420 0x932420] 0xc0017a9d40 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Mar  1 08:00:19.682: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-az-nl4q9.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-brnmg ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar  1 08:00:20.054: INFO: rc: 1
Mar  1 08:00:20.054: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/go/src/k8s.io/kubernetes/_output/bin/kubectl [kubectl --server=https://api.pub-az-nl4q9.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-brnmg ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc0019276b0 exit status 1 <nil> <nil> true [0xc0000f84d0 0xc0000f8520 0xc0000f85b8] [0xc0000f84d0 0xc0000f8520 0xc0000f85b8] [0xc0000f8500 0xc0000f8568] [0x932420 0x932420] 0xc00191c1e0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Mar  1 08:00:30.055: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-az-nl4q9.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-brnmg ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar  1 08:00:30.277: INFO: rc: 1
Mar  1 08:00:30.277: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/go/src/k8s.io/kubernetes/_output/bin/kubectl [kubectl --server=https://api.pub-az-nl4q9.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-brnmg ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc0007e76e0 exit status 1 <nil> <nil> true [0xc0000f8110 0xc0000f8278 0xc0000f8290] [0xc0000f8110 0xc0000f8278 0xc0000f8290] [0xc0000f8258 0xc0000f8288] [0x932420 0x932420] 0xc0017a8d20 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Mar  1 08:00:40.277: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-az-nl4q9.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-brnmg ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar  1 08:00:40.756: INFO: rc: 1
Mar  1 08:00:40.756: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/go/src/k8s.io/kubernetes/_output/bin/kubectl [kubectl --server=https://api.pub-az-nl4q9.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-brnmg ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc0007e79e0 exit status 1 <nil> <nil> true [0xc0000f82a0 0xc0000f82f0 0xc0000f8368] [0xc0000f82a0 0xc0000f82f0 0xc0000f8368] [0xc0000f82d0 0xc0000f8350] [0x932420 0x932420] 0xc0017a9140 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Mar  1 08:00:50.757: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-az-nl4q9.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-brnmg ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar  1 08:00:51.035: INFO: rc: 1
Mar  1 08:00:51.035: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/go/src/k8s.io/kubernetes/_output/bin/kubectl [kubectl --server=https://api.pub-az-nl4q9.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-brnmg ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc001926300 exit status 1 <nil> <nil> true [0xc0007ac0b8 0xc0007ac348 0xc0007ac3d8] [0xc0007ac0b8 0xc0007ac348 0xc0007ac3d8] [0xc0007ac2f0 0xc0007ac3c8] [0x932420 0x932420] 0xc00191c3c0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Mar  1 08:01:01.035: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-az-nl4q9.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-brnmg ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar  1 08:01:01.257: INFO: rc: 1
Mar  1 08:01:01.257: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/go/src/k8s.io/kubernetes/_output/bin/kubectl [kubectl --server=https://api.pub-az-nl4q9.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-brnmg ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc0007e7c80 exit status 1 <nil> <nil> true [0xc0000f8378 0xc0000f8390 0xc0000f83a8] [0xc0000f8378 0xc0000f8390 0xc0000f83a8] [0xc0000f8388 0xc0000f83a0] [0x932420 0x932420] 0xc0017a9440 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Mar  1 08:01:11.257: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-az-nl4q9.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-brnmg ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar  1 08:01:11.539: INFO: rc: 1
Mar  1 08:01:11.539: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/go/src/k8s.io/kubernetes/_output/bin/kubectl [kubectl --server=https://api.pub-az-nl4q9.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-brnmg ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc001926630 exit status 1 <nil> <nil> true [0xc0007ac3e0 0xc0007ac4a8 0xc0007ac5b8] [0xc0007ac3e0 0xc0007ac4a8 0xc0007ac5b8] [0xc0007ac428 0xc0007ac560] [0x932420 0x932420] 0xc00191c900 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Mar  1 08:01:21.539: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-az-nl4q9.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-brnmg ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar  1 08:01:21.802: INFO: rc: 1
Mar  1 08:01:21.802: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/go/src/k8s.io/kubernetes/_output/bin/kubectl [kubectl --server=https://api.pub-az-nl4q9.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-brnmg ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc001926960 exit status 1 <nil> <nil> true [0xc0007ac5d0 0xc0007ac618 0xc0007ac730] [0xc0007ac5d0 0xc0007ac618 0xc0007ac730] [0xc0007ac5f8 0xc0007ac670] [0x932420 0x932420] 0xc00191cc00 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Mar  1 08:01:31.802: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-az-nl4q9.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-brnmg ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar  1 08:01:32.056: INFO: rc: 1
Mar  1 08:01:32.056: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/go/src/k8s.io/kubernetes/_output/bin/kubectl [kubectl --server=https://api.pub-az-nl4q9.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-brnmg ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc001926cc0 exit status 1 <nil> <nil> true [0xc0007ac790 0xc0007ac8e8 0xc0007ac978] [0xc0007ac790 0xc0007ac8e8 0xc0007ac978] [0xc0007ac880 0xc0007ac950] [0x932420 0x932420] 0xc00191cf00 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Mar  1 08:01:42.056: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-az-nl4q9.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-brnmg ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar  1 08:01:42.358: INFO: rc: 1
Mar  1 08:01:42.358: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/go/src/k8s.io/kubernetes/_output/bin/kubectl [kubectl --server=https://api.pub-az-nl4q9.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-brnmg ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc000704f60 exit status 1 <nil> <nil> true [0xc00000e078 0xc00000e1c0 0xc00000e2e0] [0xc00000e078 0xc00000e1c0 0xc00000e2e0] [0xc00000e130 0xc00000e2a8] [0x932420 0x932420] 0xc0012c0300 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Mar  1 08:01:52.358: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-az-nl4q9.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-brnmg ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar  1 08:01:52.616: INFO: rc: 1
Mar  1 08:01:52.617: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/go/src/k8s.io/kubernetes/_output/bin/kubectl [kubectl --server=https://api.pub-az-nl4q9.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-brnmg ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc0019271d0 exit status 1 <nil> <nil> true [0xc0007ac9f8 0xc0007acb80 0xc0007acc58] [0xc0007ac9f8 0xc0007acb80 0xc0007acc58] [0xc0007acac0 0xc0007acc28] [0x932420 0x932420] 0xc00191d200 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Mar  1 08:02:02.617: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-az-nl4q9.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-brnmg ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar  1 08:02:02.852: INFO: rc: 1
Mar  1 08:02:02.852: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/go/src/k8s.io/kubernetes/_output/bin/kubectl [kubectl --server=https://api.pub-az-nl4q9.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-brnmg ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc001b32300 exit status 1 <nil> <nil> true [0xc0015e8008 0xc0015e8130 0xc0015e8220] [0xc0015e8008 0xc0015e8130 0xc0015e8220] [0xc0015e8108 0xc0015e81d0] [0x932420 0x932420] 0xc002006240 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Mar  1 08:02:12.853: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-az-nl4q9.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-brnmg ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar  1 08:02:13.136: INFO: rc: 1
Mar  1 08:02:13.136: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-2: 
Mar  1 08:02:13.136: INFO: Scaling statefulset ss to 0
STEP: Verifying that stateful set ss was scaled down in reverse order
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Mar  1 08:02:13.248: INFO: Deleting all statefulset in ns e2e-tests-statefulset-brnmg
Mar  1 08:02:13.283: INFO: Scaling statefulset ss to 0
Mar  1 08:02:13.397: INFO: Waiting for statefulset status.replicas updated to 0
Mar  1 08:02:13.433: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 08:02:25.096: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-brnmg" for this suite.
Mar  1 08:02:31.255: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 08:02:32.760: INFO: namespace: e2e-tests-statefulset-brnmg, resource: bindings, ignored listing per whitelist
Mar  1 08:02:32.867: INFO: namespace e2e-tests-statefulset-brnmg deletion completed in 7.735497935s

• [SLOW TEST:399.115 seconds]
[sig-apps] StatefulSet
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
    /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Burst scaling should run to completion even with unhealthy pods [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 08:02:32.867: INFO: >>> kubeConfig: /tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-statefulset-cqpdc
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-cqpdc
[It] Burst scaling should run to completion even with unhealthy pods [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating stateful set ss in namespace e2e-tests-statefulset-cqpdc
STEP: Waiting until all stateful set ss replicas will be running in namespace e2e-tests-statefulset-cqpdc
Mar  1 08:02:34.594: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Pending - Ready=false
Mar  1 08:02:44.631: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will not halt with unhealthy stateful pod
Mar  1 08:02:44.667: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-az-nl4q9.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-cqpdc ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Mar  1 08:02:45.655: INFO: stderr: ""
Mar  1 08:02:45.655: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Mar  1 08:02:45.655: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Mar  1 08:02:45.692: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Mar  1 08:02:55.729: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Mar  1 08:02:55.729: INFO: Waiting for statefulset status.replicas updated to 0
Mar  1 08:02:55.877: INFO: Verifying statefulset ss doesn't scale past 3 for another 9.999999374s
Mar  1 08:02:56.913: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.963168422s
Mar  1 08:02:57.950: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.926892359s
Mar  1 08:02:58.987: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.890385313s
Mar  1 08:03:00.024: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.853527411s
Mar  1 08:03:01.061: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.816189807s
Mar  1 08:03:02.098: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.779062392s
Mar  1 08:03:03.135: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.742557235s
Mar  1 08:03:04.172: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.705479659s
Mar  1 08:03:05.209: INFO: Verifying statefulset ss doesn't scale past 3 for another 668.310106ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace e2e-tests-statefulset-cqpdc
Mar  1 08:03:06.245: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-az-nl4q9.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-cqpdc ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar  1 08:03:07.048: INFO: stderr: ""
Mar  1 08:03:07.048: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Mar  1 08:03:07.048: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Mar  1 08:03:07.048: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-az-nl4q9.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-cqpdc ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar  1 08:03:07.989: INFO: stderr: "mv: can't rename '/tmp/index.html': No such file or directory\n"
Mar  1 08:03:07.989: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Mar  1 08:03:07.989: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Mar  1 08:03:07.989: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-az-nl4q9.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-cqpdc ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar  1 08:03:08.954: INFO: stderr: "mv: can't rename '/tmp/index.html': No such file or directory\n"
Mar  1 08:03:08.954: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Mar  1 08:03:08.954: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-2: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Mar  1 08:03:08.991: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Mar  1 08:03:08.991: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Mar  1 08:03:08.991: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Scale down will not halt with unhealthy stateful pod
Mar  1 08:03:09.027: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-az-nl4q9.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-cqpdc ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Mar  1 08:03:09.921: INFO: stderr: ""
Mar  1 08:03:09.921: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Mar  1 08:03:09.921: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Mar  1 08:03:09.921: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-az-nl4q9.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-cqpdc ss-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Mar  1 08:03:10.754: INFO: stderr: ""
Mar  1 08:03:10.754: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Mar  1 08:03:10.754: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Mar  1 08:03:10.754: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-az-nl4q9.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml exec --namespace=e2e-tests-statefulset-cqpdc ss-2 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Mar  1 08:03:11.623: INFO: stderr: ""
Mar  1 08:03:11.623: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Mar  1 08:03:11.623: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-2: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Mar  1 08:03:11.623: INFO: Waiting for statefulset status.replicas updated to 0
Mar  1 08:03:11.659: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 1
Mar  1 08:03:21.732: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Mar  1 08:03:21.732: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Mar  1 08:03:21.732: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Mar  1 08:03:21.855: INFO: POD   NODE                                                 PHASE    GRACE  CONDITIONS
Mar  1 08:03:21.855: INFO: ss-0  shoot--it--pub-az-nl4q9-cpu-worker-7dd9bbfd9c-7fp9l  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 08:02:34 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-01 08:03:10 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-01 08:03:10 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 08:02:34 +0000 UTC  }]
Mar  1 08:03:21.855: INFO: ss-1  shoot--it--pub-az-nl4q9-cpu-worker-7dd9bbfd9c-gwjjt  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 08:02:55 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-01 08:03:11 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-01 08:03:11 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 08:02:55 +0000 UTC  }]
Mar  1 08:03:21.855: INFO: ss-2  shoot--it--pub-az-nl4q9-cpu-worker-7dd9bbfd9c-7fp9l  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 08:02:55 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-01 08:03:11 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-01 08:03:11 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 08:02:55 +0000 UTC  }]
Mar  1 08:03:21.855: INFO: 
Mar  1 08:03:21.855: INFO: StatefulSet ss has not reached scale 0, at 3
Mar  1 08:03:22.892: INFO: POD   NODE                                                 PHASE    GRACE  CONDITIONS
Mar  1 08:03:22.892: INFO: ss-0  shoot--it--pub-az-nl4q9-cpu-worker-7dd9bbfd9c-7fp9l  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 08:02:34 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-01 08:03:10 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-01 08:03:10 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 08:02:34 +0000 UTC  }]
Mar  1 08:03:22.892: INFO: ss-1  shoot--it--pub-az-nl4q9-cpu-worker-7dd9bbfd9c-gwjjt  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 08:02:55 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-01 08:03:11 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-01 08:03:11 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 08:02:55 +0000 UTC  }]
Mar  1 08:03:22.892: INFO: ss-2  shoot--it--pub-az-nl4q9-cpu-worker-7dd9bbfd9c-7fp9l  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 08:02:55 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-01 08:03:11 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-01 08:03:11 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 08:02:55 +0000 UTC  }]
Mar  1 08:03:22.892: INFO: 
Mar  1 08:03:22.892: INFO: StatefulSet ss has not reached scale 0, at 3
Mar  1 08:03:23.929: INFO: POD   NODE                                                 PHASE    GRACE  CONDITIONS
Mar  1 08:03:23.929: INFO: ss-0  shoot--it--pub-az-nl4q9-cpu-worker-7dd9bbfd9c-7fp9l  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 08:02:34 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-01 08:03:10 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-01 08:03:10 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 08:02:34 +0000 UTC  }]
Mar  1 08:03:23.929: INFO: ss-1  shoot--it--pub-az-nl4q9-cpu-worker-7dd9bbfd9c-gwjjt  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 08:02:55 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-01 08:03:11 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-01 08:03:11 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 08:02:55 +0000 UTC  }]
Mar  1 08:03:23.929: INFO: ss-2  shoot--it--pub-az-nl4q9-cpu-worker-7dd9bbfd9c-7fp9l  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 08:02:55 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-01 08:03:11 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-01 08:03:11 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 08:02:55 +0000 UTC  }]
Mar  1 08:03:23.929: INFO: 
Mar  1 08:03:23.929: INFO: StatefulSet ss has not reached scale 0, at 3
Mar  1 08:03:24.966: INFO: POD   NODE                                                 PHASE    GRACE  CONDITIONS
Mar  1 08:03:24.966: INFO: ss-0  shoot--it--pub-az-nl4q9-cpu-worker-7dd9bbfd9c-7fp9l  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 08:02:34 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-01 08:03:10 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-01 08:03:10 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 08:02:34 +0000 UTC  }]
Mar  1 08:03:24.966: INFO: ss-2  shoot--it--pub-az-nl4q9-cpu-worker-7dd9bbfd9c-7fp9l  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 08:02:55 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-01 08:03:11 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-01 08:03:11 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 08:02:55 +0000 UTC  }]
Mar  1 08:03:24.966: INFO: 
Mar  1 08:03:24.966: INFO: StatefulSet ss has not reached scale 0, at 2
Mar  1 08:03:26.004: INFO: POD   NODE                                                 PHASE    GRACE  CONDITIONS
Mar  1 08:03:26.004: INFO: ss-0  shoot--it--pub-az-nl4q9-cpu-worker-7dd9bbfd9c-7fp9l  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 08:02:34 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-01 08:03:10 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-01 08:03:10 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 08:02:34 +0000 UTC  }]
Mar  1 08:03:26.004: INFO: ss-2  shoot--it--pub-az-nl4q9-cpu-worker-7dd9bbfd9c-7fp9l  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 08:02:55 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-01 08:03:11 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-01 08:03:11 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 08:02:55 +0000 UTC  }]
Mar  1 08:03:26.004: INFO: 
Mar  1 08:03:26.004: INFO: StatefulSet ss has not reached scale 0, at 2
Mar  1 08:03:27.041: INFO: POD   NODE                                                 PHASE    GRACE  CONDITIONS
Mar  1 08:03:27.041: INFO: ss-0  shoot--it--pub-az-nl4q9-cpu-worker-7dd9bbfd9c-7fp9l  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 08:02:34 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-01 08:03:10 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-01 08:03:10 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 08:02:34 +0000 UTC  }]
Mar  1 08:03:27.041: INFO: ss-2  shoot--it--pub-az-nl4q9-cpu-worker-7dd9bbfd9c-7fp9l  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 08:02:55 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-01 08:03:11 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-01 08:03:11 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 08:02:55 +0000 UTC  }]
Mar  1 08:03:27.041: INFO: 
Mar  1 08:03:27.041: INFO: StatefulSet ss has not reached scale 0, at 2
Mar  1 08:03:28.080: INFO: POD   NODE                                                 PHASE    GRACE  CONDITIONS
Mar  1 08:03:28.080: INFO: ss-0  shoot--it--pub-az-nl4q9-cpu-worker-7dd9bbfd9c-7fp9l  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 08:02:34 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-01 08:03:10 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-01 08:03:10 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 08:02:34 +0000 UTC  }]
Mar  1 08:03:28.080: INFO: ss-2  shoot--it--pub-az-nl4q9-cpu-worker-7dd9bbfd9c-7fp9l  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 08:02:55 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-01 08:03:11 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-01 08:03:11 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 08:02:55 +0000 UTC  }]
Mar  1 08:03:28.080: INFO: 
Mar  1 08:03:28.080: INFO: StatefulSet ss has not reached scale 0, at 2
Mar  1 08:03:29.117: INFO: POD   NODE                                                 PHASE    GRACE  CONDITIONS
Mar  1 08:03:29.117: INFO: ss-0  shoot--it--pub-az-nl4q9-cpu-worker-7dd9bbfd9c-7fp9l  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 08:02:34 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-01 08:03:10 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-01 08:03:10 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 08:02:34 +0000 UTC  }]
Mar  1 08:03:29.117: INFO: ss-2  shoot--it--pub-az-nl4q9-cpu-worker-7dd9bbfd9c-7fp9l  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 08:02:55 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-01 08:03:11 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-01 08:03:11 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 08:02:55 +0000 UTC  }]
Mar  1 08:03:29.117: INFO: 
Mar  1 08:03:29.117: INFO: StatefulSet ss has not reached scale 0, at 2
Mar  1 08:03:30.154: INFO: POD   NODE                                                 PHASE    GRACE  CONDITIONS
Mar  1 08:03:30.154: INFO: ss-0  shoot--it--pub-az-nl4q9-cpu-worker-7dd9bbfd9c-7fp9l  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 08:02:34 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-01 08:03:10 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-01 08:03:10 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 08:02:34 +0000 UTC  }]
Mar  1 08:03:30.154: INFO: ss-2  shoot--it--pub-az-nl4q9-cpu-worker-7dd9bbfd9c-7fp9l  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 08:02:55 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-01 08:03:11 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-01 08:03:11 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 08:02:55 +0000 UTC  }]
Mar  1 08:03:30.154: INFO: 
Mar  1 08:03:30.154: INFO: StatefulSet ss has not reached scale 0, at 2
Mar  1 08:03:31.190: INFO: POD   NODE                                                 PHASE    GRACE  CONDITIONS
Mar  1 08:03:31.190: INFO: ss-0  shoot--it--pub-az-nl4q9-cpu-worker-7dd9bbfd9c-7fp9l  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 08:02:34 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-01 08:03:10 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-01 08:03:10 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 08:02:34 +0000 UTC  }]
Mar  1 08:03:31.190: INFO: ss-2  shoot--it--pub-az-nl4q9-cpu-worker-7dd9bbfd9c-7fp9l  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 08:02:55 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-01 08:03:11 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-01 08:03:11 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 08:02:55 +0000 UTC  }]
Mar  1 08:03:31.190: INFO: 
Mar  1 08:03:31.190: INFO: StatefulSet ss has not reached scale 0, at 2
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacee2e-tests-statefulset-cqpdc
Mar  1 08:03:32.227: INFO: Scaling statefulset ss to 0
Mar  1 08:03:32.336: INFO: Waiting for statefulset status.replicas updated to 0
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Mar  1 08:03:32.371: INFO: Deleting all statefulset in ns e2e-tests-statefulset-cqpdc
Mar  1 08:03:32.407: INFO: Scaling statefulset ss to 0
Mar  1 08:03:32.513: INFO: Waiting for statefulset status.replicas updated to 0
Mar  1 08:03:32.549: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 08:03:32.658: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-cqpdc" for this suite.
Mar  1 08:03:38.803: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 08:03:39.354: INFO: namespace: e2e-tests-statefulset-cqpdc, resource: bindings, ignored listing per whitelist
Mar  1 08:03:40.268: INFO: namespace e2e-tests-statefulset-cqpdc deletion completed in 7.57405615s

• [SLOW TEST:67.401 seconds]
[sig-apps] StatefulSet
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    Burst scaling should run to completion even with unhealthy pods [Conformance]
    /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod with mountPath of existing file [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 08:03:40.269: INFO: >>> kubeConfig: /tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-subpath-lgwqq
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with configmap pod with mountPath of existing file [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-configmap-f4h2
STEP: Creating a pod to test atomic-volume-subpath
Mar  1 08:03:41.995: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-f4h2" in namespace "e2e-tests-subpath-lgwqq" to be "success or failure"
Mar  1 08:03:42.031: INFO: Pod "pod-subpath-test-configmap-f4h2": Phase="Pending", Reason="", readiness=false. Elapsed: 36.00291ms
Mar  1 08:03:44.067: INFO: Pod "pod-subpath-test-configmap-f4h2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.072666187s
Mar  1 08:03:46.104: INFO: Pod "pod-subpath-test-configmap-f4h2": Phase="Pending", Reason="", readiness=false. Elapsed: 4.109156646s
Mar  1 08:03:48.140: INFO: Pod "pod-subpath-test-configmap-f4h2": Phase="Running", Reason="", readiness=false. Elapsed: 6.145254921s
Mar  1 08:03:50.176: INFO: Pod "pod-subpath-test-configmap-f4h2": Phase="Running", Reason="", readiness=false. Elapsed: 8.18162453s
Mar  1 08:03:52.213: INFO: Pod "pod-subpath-test-configmap-f4h2": Phase="Running", Reason="", readiness=false. Elapsed: 10.218190071s
Mar  1 08:03:54.251: INFO: Pod "pod-subpath-test-configmap-f4h2": Phase="Running", Reason="", readiness=false. Elapsed: 12.256305893s
Mar  1 08:03:56.287: INFO: Pod "pod-subpath-test-configmap-f4h2": Phase="Running", Reason="", readiness=false. Elapsed: 14.292408568s
Mar  1 08:03:58.325: INFO: Pod "pod-subpath-test-configmap-f4h2": Phase="Running", Reason="", readiness=false. Elapsed: 16.330309325s
Mar  1 08:04:00.363: INFO: Pod "pod-subpath-test-configmap-f4h2": Phase="Running", Reason="", readiness=false. Elapsed: 18.368460169s
Mar  1 08:04:02.399: INFO: Pod "pod-subpath-test-configmap-f4h2": Phase="Running", Reason="", readiness=false. Elapsed: 20.404560174s
Mar  1 08:04:04.436: INFO: Pod "pod-subpath-test-configmap-f4h2": Phase="Running", Reason="", readiness=false. Elapsed: 22.440943878s
Mar  1 08:04:06.473: INFO: Pod "pod-subpath-test-configmap-f4h2": Phase="Running", Reason="", readiness=false. Elapsed: 24.477773777s
Mar  1 08:04:08.509: INFO: Pod "pod-subpath-test-configmap-f4h2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 26.514535956s
STEP: Saw pod success
Mar  1 08:04:08.509: INFO: Pod "pod-subpath-test-configmap-f4h2" satisfied condition "success or failure"
Mar  1 08:04:08.545: INFO: Trying to get logs from node shoot--it--pub-az-nl4q9-cpu-worker-7dd9bbfd9c-7fp9l pod pod-subpath-test-configmap-f4h2 container test-container-subpath-configmap-f4h2: <nil>
STEP: delete the pod
Mar  1 08:04:08.643: INFO: Waiting for pod pod-subpath-test-configmap-f4h2 to disappear
Mar  1 08:04:08.678: INFO: Pod pod-subpath-test-configmap-f4h2 no longer exists
STEP: Deleting pod pod-subpath-test-configmap-f4h2
Mar  1 08:04:08.678: INFO: Deleting pod "pod-subpath-test-configmap-f4h2" in namespace "e2e-tests-subpath-lgwqq"
[AfterEach] [sig-storage] Subpath
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 08:04:08.716: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-lgwqq" for this suite.
Mar  1 08:04:14.866: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 08:04:15.138: INFO: namespace: e2e-tests-subpath-lgwqq, resource: bindings, ignored listing per whitelist
Mar  1 08:04:16.318: INFO: namespace e2e-tests-subpath-lgwqq deletion completed in 7.565545177s

• [SLOW TEST:36.049 seconds]
[sig-storage] Subpath
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with configmap pod with mountPath of existing file [Conformance]
    /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 08:04:16.318: INFO: >>> kubeConfig: /tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-pwfcr
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-9cc866f3-3bf8-11e9-a72e-ce8290b78775
STEP: Creating a pod to test consume configMaps
Mar  1 08:04:18.071: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-9cd02c72-3bf8-11e9-a72e-ce8290b78775" in namespace "e2e-tests-projected-pwfcr" to be "success or failure"
Mar  1 08:04:18.107: INFO: Pod "pod-projected-configmaps-9cd02c72-3bf8-11e9-a72e-ce8290b78775": Phase="Pending", Reason="", readiness=false. Elapsed: 35.782324ms
Mar  1 08:04:20.143: INFO: Pod "pod-projected-configmaps-9cd02c72-3bf8-11e9-a72e-ce8290b78775": Phase="Pending", Reason="", readiness=false. Elapsed: 2.071817867s
Mar  1 08:04:22.179: INFO: Pod "pod-projected-configmaps-9cd02c72-3bf8-11e9-a72e-ce8290b78775": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.108548301s
STEP: Saw pod success
Mar  1 08:04:22.180: INFO: Pod "pod-projected-configmaps-9cd02c72-3bf8-11e9-a72e-ce8290b78775" satisfied condition "success or failure"
Mar  1 08:04:22.215: INFO: Trying to get logs from node shoot--it--pub-az-nl4q9-cpu-worker-7dd9bbfd9c-7fp9l pod pod-projected-configmaps-9cd02c72-3bf8-11e9-a72e-ce8290b78775 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Mar  1 08:04:22.299: INFO: Waiting for pod pod-projected-configmaps-9cd02c72-3bf8-11e9-a72e-ce8290b78775 to disappear
Mar  1 08:04:22.335: INFO: Pod pod-projected-configmaps-9cd02c72-3bf8-11e9-a72e-ce8290b78775 no longer exists
[AfterEach] [sig-storage] Projected
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 08:04:22.335: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-pwfcr" for this suite.
Mar  1 08:04:28.479: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 08:04:28.798: INFO: namespace: e2e-tests-projected-pwfcr, resource: bindings, ignored listing per whitelist
Mar  1 08:04:29.863: INFO: namespace e2e-tests-projected-pwfcr deletion completed in 7.492974069s

• [SLOW TEST:13.546 seconds]
[sig-storage] Projected
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl version 
  should check is all data is printed  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 08:04:29.864: INFO: >>> kubeConfig: /tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-988nt
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should check is all data is printed  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Mar  1 08:04:31.483: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-az-nl4q9.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml version'
Mar  1 08:04:31.759: INFO: stderr: ""
Mar  1 08:04:31.759: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"12\", GitVersion:\"v1.12.5\", GitCommit:\"51dd616cdd25d6ee22c83a858773b607328a18ec\", GitTreeState:\"archive\", BuildDate:\"2019-03-01T07:45:25Z\", GoVersion:\"go1.11.4\", Compiler:\"gc\", Platform:\"linux/amd64\"}\nServer Version: version.Info{Major:\"1\", Minor:\"12\", GitVersion:\"v1.12.5\", GitCommit:\"51dd616cdd25d6ee22c83a858773b607328a18ec\", GitTreeState:\"clean\", BuildDate:\"2019-01-16T18:14:49Z\", GoVersion:\"go1.10.7\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
[AfterEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 08:04:31.759: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-988nt" for this suite.
Mar  1 08:04:37.913: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 08:04:38.159: INFO: namespace: e2e-tests-kubectl-988nt, resource: bindings, ignored listing per whitelist
Mar  1 08:04:39.258: INFO: namespace e2e-tests-kubectl-988nt deletion completed in 7.463520376s

• [SLOW TEST:9.394 seconds]
[sig-cli] Kubectl client
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl version
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should check is all data is printed  [Conformance]
    /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Variable Expansion
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 08:04:39.258: INFO: >>> kubeConfig: /tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename var-expansion
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-var-expansion-rff4g
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test env composition
Mar  1 08:04:40.830: INFO: Waiting up to 5m0s for pod "var-expansion-aa60ef73-3bf8-11e9-a72e-ce8290b78775" in namespace "e2e-tests-var-expansion-rff4g" to be "success or failure"
Mar  1 08:04:40.865: INFO: Pod "var-expansion-aa60ef73-3bf8-11e9-a72e-ce8290b78775": Phase="Pending", Reason="", readiness=false. Elapsed: 34.930598ms
Mar  1 08:04:42.903: INFO: Pod "var-expansion-aa60ef73-3bf8-11e9-a72e-ce8290b78775": Phase="Pending", Reason="", readiness=false. Elapsed: 2.073444254s
Mar  1 08:04:44.939: INFO: Pod "var-expansion-aa60ef73-3bf8-11e9-a72e-ce8290b78775": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.109579156s
STEP: Saw pod success
Mar  1 08:04:44.940: INFO: Pod "var-expansion-aa60ef73-3bf8-11e9-a72e-ce8290b78775" satisfied condition "success or failure"
Mar  1 08:04:44.974: INFO: Trying to get logs from node shoot--it--pub-az-nl4q9-cpu-worker-7dd9bbfd9c-7fp9l pod var-expansion-aa60ef73-3bf8-11e9-a72e-ce8290b78775 container dapi-container: <nil>
STEP: delete the pod
Mar  1 08:04:45.066: INFO: Waiting for pod var-expansion-aa60ef73-3bf8-11e9-a72e-ce8290b78775 to disappear
Mar  1 08:04:45.101: INFO: Pod var-expansion-aa60ef73-3bf8-11e9-a72e-ce8290b78775 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 08:04:45.102: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-var-expansion-rff4g" for this suite.
Mar  1 08:04:51.269: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 08:04:51.943: INFO: namespace: e2e-tests-var-expansion-rff4g, resource: bindings, ignored listing per whitelist
Mar  1 08:04:52.656: INFO: namespace e2e-tests-var-expansion-rff4g deletion completed in 7.519106896s

• [SLOW TEST:13.398 seconds]
[k8s.io] Variable Expansion
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart exec hook properly [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 08:04:52.657: INFO: >>> kubeConfig: /tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-container-lifecycle-hook-bswp8
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart exec hook properly [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Mar  1 08:05:06.728: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Mar  1 08:05:06.764: INFO: Pod pod-with-poststart-exec-hook still exists
Mar  1 08:05:08.764: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Mar  1 08:05:08.800: INFO: Pod pod-with-poststart-exec-hook still exists
Mar  1 08:05:10.765: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Mar  1 08:05:10.800: INFO: Pod pod-with-poststart-exec-hook still exists
Mar  1 08:05:12.764: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Mar  1 08:05:12.801: INFO: Pod pod-with-poststart-exec-hook still exists
Mar  1 08:05:14.765: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Mar  1 08:05:14.801: INFO: Pod pod-with-poststart-exec-hook still exists
Mar  1 08:05:16.765: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Mar  1 08:05:16.800: INFO: Pod pod-with-poststart-exec-hook still exists
Mar  1 08:05:18.764: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Mar  1 08:05:18.800: INFO: Pod pod-with-poststart-exec-hook still exists
Mar  1 08:05:20.765: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Mar  1 08:05:20.801: INFO: Pod pod-with-poststart-exec-hook still exists
Mar  1 08:05:22.765: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Mar  1 08:05:22.801: INFO: Pod pod-with-poststart-exec-hook still exists
Mar  1 08:05:24.765: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Mar  1 08:05:24.801: INFO: Pod pod-with-poststart-exec-hook still exists
Mar  1 08:05:26.765: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Mar  1 08:05:26.801: INFO: Pod pod-with-poststart-exec-hook still exists
Mar  1 08:05:28.765: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Mar  1 08:05:28.801: INFO: Pod pod-with-poststart-exec-hook still exists
Mar  1 08:05:30.764: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Mar  1 08:05:30.800: INFO: Pod pod-with-poststart-exec-hook still exists
Mar  1 08:05:32.764: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Mar  1 08:05:32.801: INFO: Pod pod-with-poststart-exec-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 08:05:32.801: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-lifecycle-hook-bswp8" for this suite.
Mar  1 08:05:54.945: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 08:05:55.208: INFO: namespace: e2e-tests-container-lifecycle-hook-bswp8, resource: bindings, ignored listing per whitelist
Mar  1 08:05:56.455: INFO: namespace e2e-tests-container-lifecycle-hook-bswp8 deletion completed in 23.618289978s

• [SLOW TEST:63.799 seconds]
[k8s.io] Container Lifecycle Hook
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when create a pod with lifecycle hook
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute poststart exec hook properly [NodeConformance] [Conformance]
    /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected 
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 08:05:56.455: INFO: >>> kubeConfig: /tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-4248t
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-projected-all-test-volume-d8727344-3bf8-11e9-a72e-ce8290b78775
STEP: Creating secret with name secret-projected-all-test-volume-d8727330-3bf8-11e9-a72e-ce8290b78775
STEP: Creating a pod to test Check all projections for projected volume plugin
Mar  1 08:05:58.192: INFO: Waiting up to 5m0s for pod "projected-volume-d8727300-3bf8-11e9-a72e-ce8290b78775" in namespace "e2e-tests-projected-4248t" to be "success or failure"
Mar  1 08:05:58.227: INFO: Pod "projected-volume-d8727300-3bf8-11e9-a72e-ce8290b78775": Phase="Pending", Reason="", readiness=false. Elapsed: 35.293861ms
Mar  1 08:06:00.264: INFO: Pod "projected-volume-d8727300-3bf8-11e9-a72e-ce8290b78775": Phase="Pending", Reason="", readiness=false. Elapsed: 2.071572242s
Mar  1 08:06:02.300: INFO: Pod "projected-volume-d8727300-3bf8-11e9-a72e-ce8290b78775": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.108264113s
STEP: Saw pod success
Mar  1 08:06:02.300: INFO: Pod "projected-volume-d8727300-3bf8-11e9-a72e-ce8290b78775" satisfied condition "success or failure"
Mar  1 08:06:02.335: INFO: Trying to get logs from node shoot--it--pub-az-nl4q9-cpu-worker-7dd9bbfd9c-7fp9l pod projected-volume-d8727300-3bf8-11e9-a72e-ce8290b78775 container projected-all-volume-test: <nil>
STEP: delete the pod
Mar  1 08:06:02.473: INFO: Waiting for pod projected-volume-d8727300-3bf8-11e9-a72e-ce8290b78775 to disappear
Mar  1 08:06:02.509: INFO: Pod projected-volume-d8727300-3bf8-11e9-a72e-ce8290b78775 no longer exists
[AfterEach] [sig-storage] Projected
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 08:06:02.509: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-4248t" for this suite.
Mar  1 08:06:10.654: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 08:06:11.812: INFO: namespace: e2e-tests-projected-4248t, resource: bindings, ignored listing per whitelist
Mar  1 08:06:12.065: INFO: namespace e2e-tests-projected-4248t deletion completed in 9.520036249s

• [SLOW TEST:15.610 seconds]
[sig-storage] Projected
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-network] Proxy version v1 
  should proxy through a service and a pod  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] version v1
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 08:06:12.066: INFO: >>> kubeConfig: /tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename proxy
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-proxy-jgftx
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy through a service and a pod  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: starting an echo server on multiple ports
STEP: creating replication controller proxy-service-hfgm2 in namespace e2e-tests-proxy-jgftx
I0301 08:06:13.801476   31889 runners.go:180] Created replication controller with name: proxy-service-hfgm2, namespace: e2e-tests-proxy-jgftx, replica count: 1
I0301 08:06:14.851940   31889 runners.go:180] proxy-service-hfgm2 Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0301 08:06:15.852199   31889 runners.go:180] proxy-service-hfgm2 Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0301 08:06:16.852411   31889 runners.go:180] proxy-service-hfgm2 Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0301 08:06:17.852625   31889 runners.go:180] proxy-service-hfgm2 Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0301 08:06:18.852885   31889 runners.go:180] proxy-service-hfgm2 Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0301 08:06:19.853209   31889 runners.go:180] proxy-service-hfgm2 Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0301 08:06:20.853436   31889 runners.go:180] proxy-service-hfgm2 Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0301 08:06:21.853707   31889 runners.go:180] proxy-service-hfgm2 Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Mar  1 08:06:21.889: INFO: setup took 8.181561726s, starting test cases
STEP: running 16 cases, 20 attempts per case, 320 total attempts
Mar  1 08:06:21.931: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-jgftx/pods/proxy-service-hfgm2-rvq64:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jgftx/pods/proxy-service-hfgm2-rvq64:1080/proxy/rewri... (200; 41.602599ms)
Mar  1 08:06:21.931: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-jgftx/pods/http:proxy-service-hfgm2-rvq64:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jgftx/pods/http:proxy-service-hfgm2-rvq64:1080/proxy/... (200; 41.712259ms)
Mar  1 08:06:21.931: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-jgftx/pods/proxy-service-hfgm2-rvq64/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jgftx/pods/proxy-service-hfgm2-rvq64/proxy/rewriteme"... (200; 41.708953ms)
Mar  1 08:06:21.931: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-jgftx/services/http:proxy-service-hfgm2:portname2/proxy/: bar (200; 41.656234ms)
Mar  1 08:06:21.935: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-jgftx/services/http:proxy-service-hfgm2:portname1/proxy/: foo (200; 45.51743ms)
Mar  1 08:06:21.935: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-jgftx/pods/http:proxy-service-hfgm2-rvq64:162/proxy/: bar (200; 45.649171ms)
Mar  1 08:06:21.935: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-jgftx/services/proxy-service-hfgm2:portname2/proxy/: bar (200; 46.146456ms)
Mar  1 08:06:21.935: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-jgftx/pods/proxy-service-hfgm2-rvq64:162/proxy/: bar (200; 46.201557ms)
Mar  1 08:06:21.941: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-jgftx/pods/http:proxy-service-hfgm2-rvq64:160/proxy/: foo (200; 52.025674ms)
Mar  1 08:06:21.941: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-jgftx/pods/proxy-service-hfgm2-rvq64:160/proxy/: foo (200; 51.932905ms)
Mar  1 08:06:21.941: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-jgftx/services/proxy-service-hfgm2:portname1/proxy/: foo (200; 52.062805ms)
Mar  1 08:06:21.943: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-jgftx/pods/https:proxy-service-hfgm2-rvq64:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jgftx/pods/https:proxy-service-hfgm2-rvq64:443/proxy/... (200; 53.981964ms)
Mar  1 08:06:21.944: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-jgftx/services/https:proxy-service-hfgm2:tlsportname2/proxy/: tls qux (200; 54.526104ms)
Mar  1 08:06:21.945: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-jgftx/pods/https:proxy-service-hfgm2-rvq64:462/proxy/: tls qux (200; 55.832775ms)
Mar  1 08:06:21.945: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-jgftx/services/https:proxy-service-hfgm2:tlsportname1/proxy/: tls baz (200; 55.813042ms)
Mar  1 08:06:21.949: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-jgftx/pods/https:proxy-service-hfgm2-rvq64:460/proxy/: tls baz (200; 59.94809ms)
Mar  1 08:06:21.988: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-jgftx/pods/https:proxy-service-hfgm2-rvq64:462/proxy/: tls qux (200; 38.227562ms)
Mar  1 08:06:21.988: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-jgftx/pods/http:proxy-service-hfgm2-rvq64:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jgftx/pods/http:proxy-service-hfgm2-rvq64:1080/proxy/... (200; 38.448226ms)
Mar  1 08:06:21.988: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-jgftx/pods/proxy-service-hfgm2-rvq64:162/proxy/: bar (200; 38.010909ms)
Mar  1 08:06:21.988: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-jgftx/services/https:proxy-service-hfgm2:tlsportname2/proxy/: tls qux (200; 38.705865ms)
Mar  1 08:06:21.988: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-jgftx/pods/https:proxy-service-hfgm2-rvq64:460/proxy/: tls baz (200; 38.55184ms)
Mar  1 08:06:21.988: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-jgftx/pods/https:proxy-service-hfgm2-rvq64:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jgftx/pods/https:proxy-service-hfgm2-rvq64:443/proxy/... (200; 38.9635ms)
Mar  1 08:06:21.988: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-jgftx/services/https:proxy-service-hfgm2:tlsportname1/proxy/: tls baz (200; 38.191792ms)
Mar  1 08:06:21.988: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-jgftx/pods/proxy-service-hfgm2-rvq64/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jgftx/pods/proxy-service-hfgm2-rvq64/proxy/rewriteme"... (200; 38.442246ms)
Mar  1 08:06:21.988: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-jgftx/pods/proxy-service-hfgm2-rvq64:160/proxy/: foo (200; 38.187341ms)
Mar  1 08:06:21.988: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-jgftx/services/proxy-service-hfgm2:portname2/proxy/: bar (200; 38.496641ms)
Mar  1 08:06:21.988: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-jgftx/services/http:proxy-service-hfgm2:portname1/proxy/: foo (200; 38.862856ms)
Mar  1 08:06:21.989: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-jgftx/pods/proxy-service-hfgm2-rvq64:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jgftx/pods/proxy-service-hfgm2-rvq64:1080/proxy/rewri... (200; 38.524753ms)
Mar  1 08:06:22.006: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-jgftx/pods/http:proxy-service-hfgm2-rvq64:162/proxy/: bar (200; 56.002306ms)
Mar  1 08:06:22.006: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-jgftx/pods/http:proxy-service-hfgm2-rvq64:160/proxy/: foo (200; 56.097173ms)
Mar  1 08:06:22.006: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-jgftx/services/proxy-service-hfgm2:portname1/proxy/: foo (200; 56.297534ms)
Mar  1 08:06:22.006: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-jgftx/services/http:proxy-service-hfgm2:portname2/proxy/: bar (200; 55.711334ms)
Mar  1 08:06:22.049: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-jgftx/pods/http:proxy-service-hfgm2-rvq64:162/proxy/: bar (200; 42.988405ms)
Mar  1 08:06:22.049: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-jgftx/pods/proxy-service-hfgm2-rvq64/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jgftx/pods/proxy-service-hfgm2-rvq64/proxy/rewriteme"... (200; 42.887796ms)
Mar  1 08:06:22.049: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-jgftx/pods/http:proxy-service-hfgm2-rvq64:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jgftx/pods/http:proxy-service-hfgm2-rvq64:1080/proxy/... (200; 43.102981ms)
Mar  1 08:06:22.049: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-jgftx/pods/https:proxy-service-hfgm2-rvq64:460/proxy/: tls baz (200; 42.941744ms)
Mar  1 08:06:22.049: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-jgftx/pods/proxy-service-hfgm2-rvq64:162/proxy/: bar (200; 42.924043ms)
Mar  1 08:06:22.049: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-jgftx/pods/https:proxy-service-hfgm2-rvq64:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jgftx/pods/https:proxy-service-hfgm2-rvq64:443/proxy/... (200; 42.834207ms)
Mar  1 08:06:22.049: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-jgftx/pods/https:proxy-service-hfgm2-rvq64:462/proxy/: tls qux (200; 42.861637ms)
Mar  1 08:06:22.049: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-jgftx/pods/proxy-service-hfgm2-rvq64:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jgftx/pods/proxy-service-hfgm2-rvq64:1080/proxy/rewri... (200; 42.891928ms)
Mar  1 08:06:22.049: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-jgftx/pods/http:proxy-service-hfgm2-rvq64:160/proxy/: foo (200; 42.955371ms)
Mar  1 08:06:22.049: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-jgftx/pods/proxy-service-hfgm2-rvq64:160/proxy/: foo (200; 42.881291ms)
Mar  1 08:06:22.054: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-jgftx/services/proxy-service-hfgm2:portname2/proxy/: bar (200; 47.388924ms)
Mar  1 08:06:22.054: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-jgftx/services/proxy-service-hfgm2:portname1/proxy/: foo (200; 47.586165ms)
Mar  1 08:06:22.054: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-jgftx/services/https:proxy-service-hfgm2:tlsportname2/proxy/: tls qux (200; 47.546103ms)
Mar  1 08:06:22.054: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-jgftx/services/https:proxy-service-hfgm2:tlsportname1/proxy/: tls baz (200; 47.556938ms)
Mar  1 08:06:22.054: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-jgftx/services/http:proxy-service-hfgm2:portname2/proxy/: bar (200; 47.646761ms)
Mar  1 08:06:22.054: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-jgftx/services/http:proxy-service-hfgm2:portname1/proxy/: foo (200; 47.538208ms)
Mar  1 08:06:22.092: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-jgftx/pods/proxy-service-hfgm2-rvq64:160/proxy/: foo (200; 37.850554ms)
Mar  1 08:06:22.092: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-jgftx/pods/https:proxy-service-hfgm2-rvq64:462/proxy/: tls qux (200; 37.92981ms)
Mar  1 08:06:22.092: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-jgftx/pods/proxy-service-hfgm2-rvq64/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jgftx/pods/proxy-service-hfgm2-rvq64/proxy/rewriteme"... (200; 37.781993ms)
Mar  1 08:06:22.092: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-jgftx/pods/http:proxy-service-hfgm2-rvq64:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jgftx/pods/http:proxy-service-hfgm2-rvq64:1080/proxy/... (200; 37.825728ms)
Mar  1 08:06:22.092: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-jgftx/pods/https:proxy-service-hfgm2-rvq64:460/proxy/: tls baz (200; 37.693306ms)
Mar  1 08:06:22.092: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-jgftx/pods/https:proxy-service-hfgm2-rvq64:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jgftx/pods/https:proxy-service-hfgm2-rvq64:443/proxy/... (200; 37.838026ms)
Mar  1 08:06:22.092: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-jgftx/pods/proxy-service-hfgm2-rvq64:162/proxy/: bar (200; 37.869158ms)
Mar  1 08:06:22.092: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-jgftx/pods/http:proxy-service-hfgm2-rvq64:160/proxy/: foo (200; 37.915686ms)
Mar  1 08:06:22.092: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-jgftx/pods/http:proxy-service-hfgm2-rvq64:162/proxy/: bar (200; 37.804152ms)
Mar  1 08:06:22.092: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-jgftx/pods/proxy-service-hfgm2-rvq64:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jgftx/pods/proxy-service-hfgm2-rvq64:1080/proxy/rewri... (200; 37.752491ms)
Mar  1 08:06:22.104: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-jgftx/services/https:proxy-service-hfgm2:tlsportname2/proxy/: tls qux (200; 50.186554ms)
Mar  1 08:06:22.104: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-jgftx/services/proxy-service-hfgm2:portname2/proxy/: bar (200; 50.142039ms)
Mar  1 08:06:22.104: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-jgftx/services/https:proxy-service-hfgm2:tlsportname1/proxy/: tls baz (200; 50.253314ms)
Mar  1 08:06:22.104: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-jgftx/services/proxy-service-hfgm2:portname1/proxy/: foo (200; 50.249713ms)
Mar  1 08:06:22.104: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-jgftx/services/http:proxy-service-hfgm2:portname2/proxy/: bar (200; 50.266983ms)
Mar  1 08:06:22.104: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-jgftx/services/http:proxy-service-hfgm2:portname1/proxy/: foo (200; 50.253304ms)
Mar  1 08:06:22.143: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-jgftx/pods/http:proxy-service-hfgm2-rvq64:162/proxy/: bar (200; 38.581601ms)
Mar  1 08:06:22.143: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-jgftx/pods/https:proxy-service-hfgm2-rvq64:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jgftx/pods/https:proxy-service-hfgm2-rvq64:443/proxy/... (200; 38.761904ms)
Mar  1 08:06:22.143: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-jgftx/services/https:proxy-service-hfgm2:tlsportname2/proxy/: tls qux (200; 38.686136ms)
Mar  1 08:06:22.143: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-jgftx/pods/proxy-service-hfgm2-rvq64/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jgftx/pods/proxy-service-hfgm2-rvq64/proxy/rewriteme"... (200; 38.689581ms)
Mar  1 08:06:22.143: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-jgftx/pods/http:proxy-service-hfgm2-rvq64:160/proxy/: foo (200; 38.782376ms)
Mar  1 08:06:22.143: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-jgftx/services/https:proxy-service-hfgm2:tlsportname1/proxy/: tls baz (200; 38.62314ms)
Mar  1 08:06:22.143: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-jgftx/pods/proxy-service-hfgm2-rvq64:160/proxy/: foo (200; 38.649011ms)
Mar  1 08:06:22.143: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-jgftx/pods/proxy-service-hfgm2-rvq64:162/proxy/: bar (200; 38.65448ms)
Mar  1 08:06:22.143: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-jgftx/pods/http:proxy-service-hfgm2-rvq64:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jgftx/pods/http:proxy-service-hfgm2-rvq64:1080/proxy/... (200; 38.666646ms)
Mar  1 08:06:22.143: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-jgftx/pods/https:proxy-service-hfgm2-rvq64:460/proxy/: tls baz (200; 38.716576ms)
Mar  1 08:06:22.143: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-jgftx/pods/proxy-service-hfgm2-rvq64:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jgftx/pods/proxy-service-hfgm2-rvq64:1080/proxy/rewri... (200; 38.762007ms)
Mar  1 08:06:22.143: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-jgftx/pods/https:proxy-service-hfgm2-rvq64:462/proxy/: tls qux (200; 38.760423ms)
Mar  1 08:06:22.144: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-jgftx/services/proxy-service-hfgm2:portname1/proxy/: foo (200; 40.117842ms)
Mar  1 08:06:22.186: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-jgftx/services/http:proxy-service-hfgm2:portname2/proxy/: bar (200; 81.58172ms)
Mar  1 08:06:22.186: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-jgftx/services/proxy-service-hfgm2:portname2/proxy/: bar (200; 81.655823ms)
Mar  1 08:06:22.186: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-jgftx/services/http:proxy-service-hfgm2:portname1/proxy/: foo (200; 81.595386ms)
Mar  1 08:06:22.225: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-jgftx/pods/proxy-service-hfgm2-rvq64:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jgftx/pods/proxy-service-hfgm2-rvq64:1080/proxy/rewri... (200; 38.584959ms)
Mar  1 08:06:22.225: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-jgftx/pods/proxy-service-hfgm2-rvq64/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jgftx/pods/proxy-service-hfgm2-rvq64/proxy/rewriteme"... (200; 38.781754ms)
Mar  1 08:06:22.225: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-jgftx/pods/https:proxy-service-hfgm2-rvq64:462/proxy/: tls qux (200; 38.663321ms)
Mar  1 08:06:22.225: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-jgftx/pods/https:proxy-service-hfgm2-rvq64:460/proxy/: tls baz (200; 38.682443ms)
Mar  1 08:06:22.225: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-jgftx/pods/http:proxy-service-hfgm2-rvq64:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jgftx/pods/http:proxy-service-hfgm2-rvq64:1080/proxy/... (200; 38.79368ms)
Mar  1 08:06:22.225: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-jgftx/pods/proxy-service-hfgm2-rvq64:160/proxy/: foo (200; 38.754794ms)
Mar  1 08:06:22.225: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-jgftx/pods/proxy-service-hfgm2-rvq64:162/proxy/: bar (200; 38.730151ms)
Mar  1 08:06:22.225: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-jgftx/pods/http:proxy-service-hfgm2-rvq64:162/proxy/: bar (200; 39.182584ms)
Mar  1 08:06:22.225: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-jgftx/pods/http:proxy-service-hfgm2-rvq64:160/proxy/: foo (200; 39.111238ms)
Mar  1 08:06:22.225: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-jgftx/pods/https:proxy-service-hfgm2-rvq64:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jgftx/pods/https:proxy-service-hfgm2-rvq64:443/proxy/... (200; 39.119104ms)
Mar  1 08:06:22.227: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-jgftx/services/proxy-service-hfgm2:portname2/proxy/: bar (200; 41.416105ms)
Mar  1 08:06:22.228: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-jgftx/services/https:proxy-service-hfgm2:tlsportname2/proxy/: tls qux (200; 41.481869ms)
Mar  1 08:06:22.228: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-jgftx/services/proxy-service-hfgm2:portname1/proxy/: foo (200; 41.558337ms)
Mar  1 08:06:22.228: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-jgftx/services/https:proxy-service-hfgm2:tlsportname1/proxy/: tls baz (200; 42.344323ms)
Mar  1 08:06:22.228: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-jgftx/services/http:proxy-service-hfgm2:portname1/proxy/: foo (200; 42.411264ms)
Mar  1 08:06:22.228: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-jgftx/services/http:proxy-service-hfgm2:portname2/proxy/: bar (200; 42.410284ms)
Mar  1 08:06:22.268: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-jgftx/pods/proxy-service-hfgm2-rvq64:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jgftx/pods/proxy-service-hfgm2-rvq64:1080/proxy/rewri... (200; 38.410471ms)
Mar  1 08:06:22.268: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-jgftx/pods/http:proxy-service-hfgm2-rvq64:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jgftx/pods/http:proxy-service-hfgm2-rvq64:1080/proxy/... (200; 38.449015ms)
Mar  1 08:06:22.268: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-jgftx/pods/https:proxy-service-hfgm2-rvq64:460/proxy/: tls baz (200; 38.38415ms)
Mar  1 08:06:22.268: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-jgftx/pods/http:proxy-service-hfgm2-rvq64:162/proxy/: bar (200; 38.54189ms)
Mar  1 08:06:22.268: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-jgftx/pods/proxy-service-hfgm2-rvq64:160/proxy/: foo (200; 39.060681ms)
Mar  1 08:06:22.268: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-jgftx/pods/proxy-service-hfgm2-rvq64:162/proxy/: bar (200; 38.972822ms)
Mar  1 08:06:22.268: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-jgftx/pods/http:proxy-service-hfgm2-rvq64:160/proxy/: foo (200; 38.642787ms)
Mar  1 08:06:22.268: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-jgftx/pods/https:proxy-service-hfgm2-rvq64:462/proxy/: tls qux (200; 38.545666ms)
Mar  1 08:06:22.268: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-jgftx/pods/proxy-service-hfgm2-rvq64/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jgftx/pods/proxy-service-hfgm2-rvq64/proxy/rewriteme"... (200; 39.274703ms)
Mar  1 08:06:22.268: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-jgftx/pods/https:proxy-service-hfgm2-rvq64:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jgftx/pods/https:proxy-service-hfgm2-rvq64:443/proxy/... (200; 38.97276ms)
Mar  1 08:06:22.268: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-jgftx/services/https:proxy-service-hfgm2:tlsportname2/proxy/: tls qux (200; 38.780803ms)
Mar  1 08:06:22.268: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-jgftx/services/https:proxy-service-hfgm2:tlsportname1/proxy/: tls baz (200; 38.872843ms)
Mar  1 08:06:22.268: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-jgftx/services/proxy-service-hfgm2:portname2/proxy/: bar (200; 38.960048ms)
Mar  1 08:06:22.269: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-jgftx/services/http:proxy-service-hfgm2:portname2/proxy/: bar (200; 40.54707ms)
Mar  1 08:06:22.269: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-jgftx/services/http:proxy-service-hfgm2:portname1/proxy/: foo (200; 40.177232ms)
Mar  1 08:06:22.270: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-jgftx/services/proxy-service-hfgm2:portname1/proxy/: foo (200; 40.380759ms)
Mar  1 08:06:22.318: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-jgftx/pods/http:proxy-service-hfgm2-rvq64:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jgftx/pods/http:proxy-service-hfgm2-rvq64:1080/proxy/... (200; 48.449163ms)
Mar  1 08:06:22.318: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-jgftx/pods/https:proxy-service-hfgm2-rvq64:462/proxy/: tls qux (200; 48.399791ms)
Mar  1 08:06:22.318: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-jgftx/pods/https:proxy-service-hfgm2-rvq64:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jgftx/pods/https:proxy-service-hfgm2-rvq64:443/proxy/... (200; 48.512687ms)
Mar  1 08:06:22.318: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-jgftx/pods/https:proxy-service-hfgm2-rvq64:460/proxy/: tls baz (200; 48.391298ms)
Mar  1 08:06:22.318: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-jgftx/pods/proxy-service-hfgm2-rvq64:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jgftx/pods/proxy-service-hfgm2-rvq64:1080/proxy/rewri... (200; 48.578783ms)
Mar  1 08:06:22.318: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-jgftx/pods/proxy-service-hfgm2-rvq64/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jgftx/pods/proxy-service-hfgm2-rvq64/proxy/rewriteme"... (200; 48.506765ms)
Mar  1 08:06:22.318: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-jgftx/pods/http:proxy-service-hfgm2-rvq64:162/proxy/: bar (200; 48.408205ms)
Mar  1 08:06:22.318: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-jgftx/pods/proxy-service-hfgm2-rvq64:162/proxy/: bar (200; 48.454104ms)
Mar  1 08:06:22.318: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-jgftx/pods/proxy-service-hfgm2-rvq64:160/proxy/: foo (200; 48.494926ms)
Mar  1 08:06:22.318: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-jgftx/pods/http:proxy-service-hfgm2-rvq64:160/proxy/: foo (200; 48.444677ms)
Mar  1 08:06:22.331: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-jgftx/services/proxy-service-hfgm2:portname2/proxy/: bar (200; 61.036045ms)
Mar  1 08:06:22.331: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-jgftx/services/proxy-service-hfgm2:portname1/proxy/: foo (200; 61.173338ms)
Mar  1 08:06:22.331: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-jgftx/services/https:proxy-service-hfgm2:tlsportname1/proxy/: tls baz (200; 61.055826ms)
Mar  1 08:06:22.331: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-jgftx/services/http:proxy-service-hfgm2:portname1/proxy/: foo (200; 61.05421ms)
Mar  1 08:06:22.331: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-jgftx/services/http:proxy-service-hfgm2:portname2/proxy/: bar (200; 61.086084ms)
Mar  1 08:06:22.331: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-jgftx/services/https:proxy-service-hfgm2:tlsportname2/proxy/: tls qux (200; 61.131189ms)
Mar  1 08:06:22.369: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-jgftx/pods/https:proxy-service-hfgm2-rvq64:462/proxy/: tls qux (200; 38.268897ms)
Mar  1 08:06:22.369: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-jgftx/pods/proxy-service-hfgm2-rvq64:162/proxy/: bar (200; 38.365719ms)
Mar  1 08:06:22.369: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-jgftx/pods/http:proxy-service-hfgm2-rvq64:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jgftx/pods/http:proxy-service-hfgm2-rvq64:1080/proxy/... (200; 38.33117ms)
Mar  1 08:06:22.369: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-jgftx/pods/proxy-service-hfgm2-rvq64:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jgftx/pods/proxy-service-hfgm2-rvq64:1080/proxy/rewri... (200; 38.315563ms)
Mar  1 08:06:22.369: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-jgftx/pods/http:proxy-service-hfgm2-rvq64:162/proxy/: bar (200; 38.439722ms)
Mar  1 08:06:22.369: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-jgftx/pods/https:proxy-service-hfgm2-rvq64:460/proxy/: tls baz (200; 38.291607ms)
Mar  1 08:06:22.369: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-jgftx/pods/http:proxy-service-hfgm2-rvq64:160/proxy/: foo (200; 38.333791ms)
Mar  1 08:06:22.369: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-jgftx/pods/proxy-service-hfgm2-rvq64/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jgftx/pods/proxy-service-hfgm2-rvq64/proxy/rewriteme"... (200; 38.505886ms)
Mar  1 08:06:22.369: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-jgftx/pods/proxy-service-hfgm2-rvq64:160/proxy/: foo (200; 38.398277ms)
Mar  1 08:06:22.369: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-jgftx/pods/https:proxy-service-hfgm2-rvq64:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jgftx/pods/https:proxy-service-hfgm2-rvq64:443/proxy/... (200; 38.38564ms)
Mar  1 08:06:22.388: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-jgftx/services/https:proxy-service-hfgm2:tlsportname2/proxy/: tls qux (200; 56.997592ms)
Mar  1 08:06:22.388: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-jgftx/services/https:proxy-service-hfgm2:tlsportname1/proxy/: tls baz (200; 57.097312ms)
Mar  1 08:06:22.388: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-jgftx/services/proxy-service-hfgm2:portname2/proxy/: bar (200; 56.907382ms)
Mar  1 08:06:22.388: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-jgftx/services/http:proxy-service-hfgm2:portname2/proxy/: bar (200; 56.904265ms)
Mar  1 08:06:22.388: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-jgftx/services/http:proxy-service-hfgm2:portname1/proxy/: foo (200; 56.992844ms)
Mar  1 08:06:22.388: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-jgftx/services/proxy-service-hfgm2:portname1/proxy/: foo (200; 57.023203ms)
Mar  1 08:06:22.478: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-jgftx/pods/http:proxy-service-hfgm2-rvq64:160/proxy/: foo (200; 89.736463ms)
Mar  1 08:06:22.478: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-jgftx/pods/http:proxy-service-hfgm2-rvq64:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jgftx/pods/http:proxy-service-hfgm2-rvq64:1080/proxy/... (200; 89.761713ms)
Mar  1 08:06:22.478: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-jgftx/pods/proxy-service-hfgm2-rvq64:162/proxy/: bar (200; 89.890519ms)
Mar  1 08:06:22.478: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-jgftx/pods/http:proxy-service-hfgm2-rvq64:162/proxy/: bar (200; 89.795127ms)
Mar  1 08:06:22.478: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-jgftx/pods/proxy-service-hfgm2-rvq64:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jgftx/pods/proxy-service-hfgm2-rvq64:1080/proxy/rewri... (200; 89.996973ms)
Mar  1 08:06:22.478: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-jgftx/pods/https:proxy-service-hfgm2-rvq64:460/proxy/: tls baz (200; 90.076128ms)
Mar  1 08:06:22.478: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-jgftx/pods/https:proxy-service-hfgm2-rvq64:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jgftx/pods/https:proxy-service-hfgm2-rvq64:443/proxy/... (200; 89.904741ms)
Mar  1 08:06:22.478: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-jgftx/pods/proxy-service-hfgm2-rvq64/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jgftx/pods/proxy-service-hfgm2-rvq64/proxy/rewriteme"... (200; 89.828911ms)
Mar  1 08:06:22.478: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-jgftx/pods/https:proxy-service-hfgm2-rvq64:462/proxy/: tls qux (200; 89.924212ms)
Mar  1 08:06:22.478: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-jgftx/pods/proxy-service-hfgm2-rvq64:160/proxy/: foo (200; 89.992979ms)
Mar  1 08:06:22.485: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-jgftx/services/proxy-service-hfgm2:portname2/proxy/: bar (200; 96.449998ms)
Mar  1 08:06:22.501: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-jgftx/services/proxy-service-hfgm2:portname1/proxy/: foo (200; 112.839771ms)
Mar  1 08:06:22.501: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-jgftx/services/https:proxy-service-hfgm2:tlsportname2/proxy/: tls qux (200; 112.842195ms)
Mar  1 08:06:22.501: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-jgftx/services/https:proxy-service-hfgm2:tlsportname1/proxy/: tls baz (200; 112.796706ms)
Mar  1 08:06:22.501: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-jgftx/services/http:proxy-service-hfgm2:portname1/proxy/: foo (200; 112.955207ms)
Mar  1 08:06:22.501: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-jgftx/services/http:proxy-service-hfgm2:portname2/proxy/: bar (200; 112.868036ms)
Mar  1 08:06:22.540: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-jgftx/pods/proxy-service-hfgm2-rvq64:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jgftx/pods/proxy-service-hfgm2-rvq64:1080/proxy/rewri... (200; 38.043583ms)
Mar  1 08:06:22.540: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-jgftx/pods/http:proxy-service-hfgm2-rvq64:160/proxy/: foo (200; 38.098131ms)
Mar  1 08:06:22.540: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-jgftx/pods/proxy-service-hfgm2-rvq64/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jgftx/pods/proxy-service-hfgm2-rvq64/proxy/rewriteme"... (200; 38.136798ms)
Mar  1 08:06:22.540: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-jgftx/pods/https:proxy-service-hfgm2-rvq64:460/proxy/: tls baz (200; 38.087782ms)
Mar  1 08:06:22.540: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-jgftx/pods/https:proxy-service-hfgm2-rvq64:462/proxy/: tls qux (200; 38.330658ms)
Mar  1 08:06:22.540: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-jgftx/pods/proxy-service-hfgm2-rvq64:162/proxy/: bar (200; 38.266322ms)
Mar  1 08:06:22.540: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-jgftx/pods/http:proxy-service-hfgm2-rvq64:162/proxy/: bar (200; 38.13465ms)
Mar  1 08:06:22.540: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-jgftx/pods/proxy-service-hfgm2-rvq64:160/proxy/: foo (200; 38.246275ms)
Mar  1 08:06:22.540: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-jgftx/pods/https:proxy-service-hfgm2-rvq64:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jgftx/pods/https:proxy-service-hfgm2-rvq64:443/proxy/... (200; 38.330984ms)
Mar  1 08:06:22.540: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-jgftx/pods/http:proxy-service-hfgm2-rvq64:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jgftx/pods/http:proxy-service-hfgm2-rvq64:1080/proxy/... (200; 38.235471ms)
Mar  1 08:06:22.540: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-jgftx/services/https:proxy-service-hfgm2:tlsportname2/proxy/: tls qux (200; 38.354435ms)
Mar  1 08:06:22.541: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-jgftx/services/https:proxy-service-hfgm2:tlsportname1/proxy/: tls baz (200; 39.279555ms)
Mar  1 08:06:22.542: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-jgftx/services/http:proxy-service-hfgm2:portname2/proxy/: bar (200; 40.106974ms)
Mar  1 08:06:22.542: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-jgftx/services/proxy-service-hfgm2:portname1/proxy/: foo (200; 40.099459ms)
Mar  1 08:06:22.542: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-jgftx/services/http:proxy-service-hfgm2:portname1/proxy/: foo (200; 40.098462ms)
Mar  1 08:06:22.542: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-jgftx/services/proxy-service-hfgm2:portname2/proxy/: bar (200; 40.073599ms)
Mar  1 08:06:22.588: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-jgftx/pods/proxy-service-hfgm2-rvq64:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jgftx/pods/proxy-service-hfgm2-rvq64:1080/proxy/rewri... (200; 46.327202ms)
Mar  1 08:06:22.588: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-jgftx/pods/http:proxy-service-hfgm2-rvq64:160/proxy/: foo (200; 46.217684ms)
Mar  1 08:06:22.588: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-jgftx/pods/https:proxy-service-hfgm2-rvq64:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jgftx/pods/https:proxy-service-hfgm2-rvq64:443/proxy/... (200; 46.306349ms)
Mar  1 08:06:22.588: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-jgftx/pods/http:proxy-service-hfgm2-rvq64:162/proxy/: bar (200; 46.185311ms)
Mar  1 08:06:22.588: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-jgftx/pods/https:proxy-service-hfgm2-rvq64:460/proxy/: tls baz (200; 46.366535ms)
Mar  1 08:06:22.588: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-jgftx/pods/https:proxy-service-hfgm2-rvq64:462/proxy/: tls qux (200; 46.272762ms)
Mar  1 08:06:22.588: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-jgftx/pods/http:proxy-service-hfgm2-rvq64:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jgftx/pods/http:proxy-service-hfgm2-rvq64:1080/proxy/... (200; 46.167386ms)
Mar  1 08:06:22.588: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-jgftx/pods/proxy-service-hfgm2-rvq64/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jgftx/pods/proxy-service-hfgm2-rvq64/proxy/rewriteme"... (200; 46.178595ms)
Mar  1 08:06:22.588: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-jgftx/pods/proxy-service-hfgm2-rvq64:162/proxy/: bar (200; 46.226589ms)
Mar  1 08:06:22.588: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-jgftx/pods/proxy-service-hfgm2-rvq64:160/proxy/: foo (200; 46.252615ms)
Mar  1 08:06:22.588: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-jgftx/services/https:proxy-service-hfgm2:tlsportname1/proxy/: tls baz (200; 46.62705ms)
Mar  1 08:06:22.589: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-jgftx/services/proxy-service-hfgm2:portname1/proxy/: foo (200; 47.623637ms)
Mar  1 08:06:22.589: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-jgftx/services/http:proxy-service-hfgm2:portname1/proxy/: foo (200; 47.612768ms)
Mar  1 08:06:22.589: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-jgftx/services/proxy-service-hfgm2:portname2/proxy/: bar (200; 47.551733ms)
Mar  1 08:06:22.589: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-jgftx/services/http:proxy-service-hfgm2:portname2/proxy/: bar (200; 47.622743ms)
Mar  1 08:06:22.589: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-jgftx/services/https:proxy-service-hfgm2:tlsportname2/proxy/: tls qux (200; 47.606116ms)
Mar  1 08:06:22.628: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-jgftx/pods/http:proxy-service-hfgm2-rvq64:162/proxy/: bar (200; 37.817025ms)
Mar  1 08:06:22.628: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-jgftx/pods/http:proxy-service-hfgm2-rvq64:160/proxy/: foo (200; 37.955976ms)
Mar  1 08:06:22.628: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-jgftx/pods/https:proxy-service-hfgm2-rvq64:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jgftx/pods/https:proxy-service-hfgm2-rvq64:443/proxy/... (200; 37.885879ms)
Mar  1 08:06:22.628: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-jgftx/pods/proxy-service-hfgm2-rvq64:162/proxy/: bar (200; 37.9257ms)
Mar  1 08:06:22.628: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-jgftx/pods/https:proxy-service-hfgm2-rvq64:462/proxy/: tls qux (200; 38.138147ms)
Mar  1 08:06:22.628: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-jgftx/pods/proxy-service-hfgm2-rvq64:160/proxy/: foo (200; 37.963148ms)
Mar  1 08:06:22.628: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-jgftx/pods/https:proxy-service-hfgm2-rvq64:460/proxy/: tls baz (200; 37.750764ms)
Mar  1 08:06:22.628: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-jgftx/pods/http:proxy-service-hfgm2-rvq64:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jgftx/pods/http:proxy-service-hfgm2-rvq64:1080/proxy/... (200; 38.06671ms)
Mar  1 08:06:22.628: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-jgftx/pods/proxy-service-hfgm2-rvq64/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jgftx/pods/proxy-service-hfgm2-rvq64/proxy/rewriteme"... (200; 37.740726ms)
Mar  1 08:06:22.628: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-jgftx/pods/proxy-service-hfgm2-rvq64:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jgftx/pods/proxy-service-hfgm2-rvq64:1080/proxy/rewri... (200; 37.917042ms)
Mar  1 08:06:22.656: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-jgftx/services/http:proxy-service-hfgm2:portname1/proxy/: foo (200; 66.53325ms)
Mar  1 08:06:22.656: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-jgftx/services/http:proxy-service-hfgm2:portname2/proxy/: bar (200; 66.564556ms)
Mar  1 08:06:22.656: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-jgftx/services/proxy-service-hfgm2:portname2/proxy/: bar (200; 66.23259ms)
Mar  1 08:06:22.656: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-jgftx/services/https:proxy-service-hfgm2:tlsportname2/proxy/: tls qux (200; 66.467075ms)
Mar  1 08:06:22.656: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-jgftx/services/https:proxy-service-hfgm2:tlsportname1/proxy/: tls baz (200; 66.427919ms)
Mar  1 08:06:22.656: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-jgftx/services/proxy-service-hfgm2:portname1/proxy/: foo (200; 66.187726ms)
Mar  1 08:06:22.696: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-jgftx/pods/proxy-service-hfgm2-rvq64/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jgftx/pods/proxy-service-hfgm2-rvq64/proxy/rewriteme"... (200; 39.273234ms)
Mar  1 08:06:22.696: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-jgftx/pods/http:proxy-service-hfgm2-rvq64:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jgftx/pods/http:proxy-service-hfgm2-rvq64:1080/proxy/... (200; 39.429901ms)
Mar  1 08:06:22.696: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-jgftx/pods/proxy-service-hfgm2-rvq64:160/proxy/: foo (200; 39.367092ms)
Mar  1 08:06:22.696: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-jgftx/pods/proxy-service-hfgm2-rvq64:162/proxy/: bar (200; 39.241085ms)
Mar  1 08:06:22.695: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-jgftx/pods/https:proxy-service-hfgm2-rvq64:462/proxy/: tls qux (200; 39.265442ms)
Mar  1 08:06:22.696: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-jgftx/pods/proxy-service-hfgm2-rvq64:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jgftx/pods/proxy-service-hfgm2-rvq64:1080/proxy/rewri... (200; 39.333057ms)
Mar  1 08:06:22.696: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-jgftx/pods/https:proxy-service-hfgm2-rvq64:460/proxy/: tls baz (200; 39.283718ms)
Mar  1 08:06:22.696: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-jgftx/pods/http:proxy-service-hfgm2-rvq64:160/proxy/: foo (200; 39.281578ms)
Mar  1 08:06:22.696: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-jgftx/pods/https:proxy-service-hfgm2-rvq64:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jgftx/pods/https:proxy-service-hfgm2-rvq64:443/proxy/... (200; 39.373314ms)
Mar  1 08:06:22.696: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-jgftx/pods/http:proxy-service-hfgm2-rvq64:162/proxy/: bar (200; 39.364257ms)
Mar  1 08:06:22.696: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-jgftx/services/https:proxy-service-hfgm2:tlsportname1/proxy/: tls baz (200; 40.177019ms)
Mar  1 08:06:22.697: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-jgftx/services/https:proxy-service-hfgm2:tlsportname2/proxy/: tls qux (200; 40.216151ms)
Mar  1 08:06:22.697: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-jgftx/services/proxy-service-hfgm2:portname2/proxy/: bar (200; 40.417553ms)
Mar  1 08:06:22.697: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-jgftx/services/proxy-service-hfgm2:portname1/proxy/: foo (200; 40.455413ms)
Mar  1 08:06:22.698: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-jgftx/services/http:proxy-service-hfgm2:portname1/proxy/: foo (200; 41.246066ms)
Mar  1 08:06:22.698: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-jgftx/services/http:proxy-service-hfgm2:portname2/proxy/: bar (200; 41.328504ms)
Mar  1 08:06:22.736: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-jgftx/pods/https:proxy-service-hfgm2-rvq64:460/proxy/: tls baz (200; 38.528844ms)
Mar  1 08:06:22.737: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-jgftx/pods/http:proxy-service-hfgm2-rvq64:162/proxy/: bar (200; 38.659789ms)
Mar  1 08:06:22.737: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-jgftx/pods/http:proxy-service-hfgm2-rvq64:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jgftx/pods/http:proxy-service-hfgm2-rvq64:1080/proxy/... (200; 38.867899ms)
Mar  1 08:06:22.737: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-jgftx/pods/proxy-service-hfgm2-rvq64:160/proxy/: foo (200; 38.73121ms)
Mar  1 08:06:22.737: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-jgftx/pods/proxy-service-hfgm2-rvq64:162/proxy/: bar (200; 38.6533ms)
Mar  1 08:06:22.737: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-jgftx/pods/https:proxy-service-hfgm2-rvq64:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jgftx/pods/https:proxy-service-hfgm2-rvq64:443/proxy/... (200; 38.582858ms)
Mar  1 08:06:22.738: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-jgftx/pods/https:proxy-service-hfgm2-rvq64:462/proxy/: tls qux (200; 40.004068ms)
Mar  1 08:06:22.738: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-jgftx/pods/proxy-service-hfgm2-rvq64:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jgftx/pods/proxy-service-hfgm2-rvq64:1080/proxy/rewri... (200; 40.089359ms)
Mar  1 08:06:22.738: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-jgftx/pods/proxy-service-hfgm2-rvq64/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jgftx/pods/proxy-service-hfgm2-rvq64/proxy/rewriteme"... (200; 40.106291ms)
Mar  1 08:06:22.738: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-jgftx/pods/http:proxy-service-hfgm2-rvq64:160/proxy/: foo (200; 39.96356ms)
Mar  1 08:06:22.773: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-jgftx/services/https:proxy-service-hfgm2:tlsportname2/proxy/: tls qux (200; 75.562158ms)
Mar  1 08:06:22.773: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-jgftx/services/http:proxy-service-hfgm2:portname1/proxy/: foo (200; 75.673403ms)
Mar  1 08:06:22.774: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-jgftx/services/proxy-service-hfgm2:portname2/proxy/: bar (200; 75.674836ms)
Mar  1 08:06:22.774: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-jgftx/services/https:proxy-service-hfgm2:tlsportname1/proxy/: tls baz (200; 75.607375ms)
Mar  1 08:06:22.774: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-jgftx/services/http:proxy-service-hfgm2:portname2/proxy/: bar (200; 75.724601ms)
Mar  1 08:06:22.774: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-jgftx/services/proxy-service-hfgm2:portname1/proxy/: foo (200; 75.560435ms)
Mar  1 08:06:22.811: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-jgftx/pods/http:proxy-service-hfgm2-rvq64:160/proxy/: foo (200; 37.718503ms)
Mar  1 08:06:22.811: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-jgftx/pods/proxy-service-hfgm2-rvq64:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jgftx/pods/proxy-service-hfgm2-rvq64:1080/proxy/rewri... (200; 37.75799ms)
Mar  1 08:06:22.811: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-jgftx/pods/https:proxy-service-hfgm2-rvq64:462/proxy/: tls qux (200; 37.785603ms)
Mar  1 08:06:22.812: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-jgftx/pods/proxy-service-hfgm2-rvq64/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jgftx/pods/proxy-service-hfgm2-rvq64/proxy/rewriteme"... (200; 37.805871ms)
Mar  1 08:06:22.812: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-jgftx/pods/proxy-service-hfgm2-rvq64:162/proxy/: bar (200; 37.921146ms)
Mar  1 08:06:22.812: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-jgftx/pods/http:proxy-service-hfgm2-rvq64:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jgftx/pods/http:proxy-service-hfgm2-rvq64:1080/proxy/... (200; 37.961698ms)
Mar  1 08:06:22.812: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-jgftx/pods/http:proxy-service-hfgm2-rvq64:162/proxy/: bar (200; 37.813947ms)
Mar  1 08:06:22.812: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-jgftx/pods/https:proxy-service-hfgm2-rvq64:460/proxy/: tls baz (200; 37.799591ms)
Mar  1 08:06:22.812: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-jgftx/pods/proxy-service-hfgm2-rvq64:160/proxy/: foo (200; 37.868931ms)
Mar  1 08:06:22.812: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-jgftx/pods/https:proxy-service-hfgm2-rvq64:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jgftx/pods/https:proxy-service-hfgm2-rvq64:443/proxy/... (200; 37.88265ms)
Mar  1 08:06:22.812: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-jgftx/services/https:proxy-service-hfgm2:tlsportname1/proxy/: tls baz (200; 38.590532ms)
Mar  1 08:06:22.854: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-jgftx/services/https:proxy-service-hfgm2:tlsportname2/proxy/: tls qux (200; 80.119515ms)
Mar  1 08:06:22.854: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-jgftx/services/http:proxy-service-hfgm2:portname2/proxy/: bar (200; 80.154988ms)
Mar  1 08:06:22.854: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-jgftx/services/http:proxy-service-hfgm2:portname1/proxy/: foo (200; 80.140601ms)
Mar  1 08:06:22.854: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-jgftx/services/proxy-service-hfgm2:portname1/proxy/: foo (200; 80.191778ms)
Mar  1 08:06:22.854: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-jgftx/services/proxy-service-hfgm2:portname2/proxy/: bar (200; 80.27044ms)
Mar  1 08:06:22.893: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-jgftx/pods/https:proxy-service-hfgm2-rvq64:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jgftx/pods/https:proxy-service-hfgm2-rvq64:443/proxy/... (200; 38.154366ms)
Mar  1 08:06:22.893: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-jgftx/services/https:proxy-service-hfgm2:tlsportname1/proxy/: tls baz (200; 38.55426ms)
Mar  1 08:06:22.893: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-jgftx/pods/http:proxy-service-hfgm2-rvq64:160/proxy/: foo (200; 38.034939ms)
Mar  1 08:06:22.893: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-jgftx/pods/http:proxy-service-hfgm2-rvq64:162/proxy/: bar (200; 37.998448ms)
Mar  1 08:06:22.893: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-jgftx/pods/proxy-service-hfgm2-rvq64:160/proxy/: foo (200; 38.510074ms)
Mar  1 08:06:22.893: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-jgftx/pods/proxy-service-hfgm2-rvq64:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jgftx/pods/proxy-service-hfgm2-rvq64:1080/proxy/rewri... (200; 37.694822ms)
Mar  1 08:06:22.893: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-jgftx/pods/https:proxy-service-hfgm2-rvq64:462/proxy/: tls qux (200; 38.875096ms)
Mar  1 08:06:22.893: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-jgftx/pods/http:proxy-service-hfgm2-rvq64:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jgftx/pods/http:proxy-service-hfgm2-rvq64:1080/proxy/... (200; 37.966277ms)
Mar  1 08:06:22.893: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-jgftx/pods/https:proxy-service-hfgm2-rvq64:460/proxy/: tls baz (200; 38.032613ms)
Mar  1 08:06:22.893: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-jgftx/pods/proxy-service-hfgm2-rvq64/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jgftx/pods/proxy-service-hfgm2-rvq64/proxy/rewriteme"... (200; 37.844366ms)
Mar  1 08:06:22.893: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-jgftx/pods/proxy-service-hfgm2-rvq64:162/proxy/: bar (200; 38.592132ms)
Mar  1 08:06:22.893: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-jgftx/services/https:proxy-service-hfgm2:tlsportname2/proxy/: tls qux (200; 38.67822ms)
Mar  1 08:06:22.935: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-jgftx/services/proxy-service-hfgm2:portname1/proxy/: foo (200; 80.043071ms)
Mar  1 08:06:22.935: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-jgftx/services/proxy-service-hfgm2:portname2/proxy/: bar (200; 79.59508ms)
Mar  1 08:06:22.935: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-jgftx/services/http:proxy-service-hfgm2:portname1/proxy/: foo (200; 80.022735ms)
Mar  1 08:06:22.935: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-jgftx/services/http:proxy-service-hfgm2:portname2/proxy/: bar (200; 80.510659ms)
Mar  1 08:06:22.974: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-jgftx/pods/http:proxy-service-hfgm2-rvq64:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jgftx/pods/http:proxy-service-hfgm2-rvq64:1080/proxy/... (200; 39.079002ms)
Mar  1 08:06:22.974: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-jgftx/pods/proxy-service-hfgm2-rvq64:160/proxy/: foo (200; 39.009379ms)
Mar  1 08:06:22.974: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-jgftx/pods/https:proxy-service-hfgm2-rvq64:462/proxy/: tls qux (200; 39.163416ms)
Mar  1 08:06:22.974: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-jgftx/services/https:proxy-service-hfgm2:tlsportname1/proxy/: tls baz (200; 39.149575ms)
Mar  1 08:06:22.974: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-jgftx/pods/http:proxy-service-hfgm2-rvq64:160/proxy/: foo (200; 39.033726ms)
Mar  1 08:06:22.974: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-jgftx/pods/proxy-service-hfgm2-rvq64:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jgftx/pods/proxy-service-hfgm2-rvq64:1080/proxy/rewri... (200; 39.11331ms)
Mar  1 08:06:22.974: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-jgftx/pods/http:proxy-service-hfgm2-rvq64:162/proxy/: bar (200; 39.055068ms)
Mar  1 08:06:22.974: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-jgftx/pods/proxy-service-hfgm2-rvq64:162/proxy/: bar (200; 39.199175ms)
Mar  1 08:06:22.974: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-jgftx/pods/proxy-service-hfgm2-rvq64/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jgftx/pods/proxy-service-hfgm2-rvq64/proxy/rewriteme"... (200; 39.19266ms)
Mar  1 08:06:22.974: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-jgftx/pods/https:proxy-service-hfgm2-rvq64:460/proxy/: tls baz (200; 39.140144ms)
Mar  1 08:06:22.974: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-jgftx/pods/https:proxy-service-hfgm2-rvq64:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jgftx/pods/https:proxy-service-hfgm2-rvq64:443/proxy/... (200; 39.210278ms)
Mar  1 08:06:22.974: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-jgftx/services/https:proxy-service-hfgm2:tlsportname2/proxy/: tls qux (200; 39.379052ms)
Mar  1 08:06:22.975: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-jgftx/services/http:proxy-service-hfgm2:portname1/proxy/: foo (200; 39.895484ms)
Mar  1 08:06:22.975: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-jgftx/services/proxy-service-hfgm2:portname2/proxy/: bar (200; 40.780505ms)
Mar  1 08:06:22.975: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-jgftx/services/proxy-service-hfgm2:portname1/proxy/: foo (200; 40.511362ms)
Mar  1 08:06:22.976: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-jgftx/services/http:proxy-service-hfgm2:portname2/proxy/: bar (200; 41.118842ms)
Mar  1 08:06:23.014: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-jgftx/pods/http:proxy-service-hfgm2-rvq64:162/proxy/: bar (200; 37.29832ms)
Mar  1 08:06:23.014: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-jgftx/pods/http:proxy-service-hfgm2-rvq64:160/proxy/: foo (200; 37.354248ms)
Mar  1 08:06:23.014: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-jgftx/pods/http:proxy-service-hfgm2-rvq64:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jgftx/pods/http:proxy-service-hfgm2-rvq64:1080/proxy/... (200; 38.142905ms)
Mar  1 08:06:23.014: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-jgftx/pods/proxy-service-hfgm2-rvq64:162/proxy/: bar (200; 38.236201ms)
Mar  1 08:06:23.014: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-jgftx/pods/https:proxy-service-hfgm2-rvq64:460/proxy/: tls baz (200; 38.145864ms)
Mar  1 08:06:23.014: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-jgftx/pods/https:proxy-service-hfgm2-rvq64:462/proxy/: tls qux (200; 38.171284ms)
Mar  1 08:06:23.014: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-jgftx/pods/proxy-service-hfgm2-rvq64:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jgftx/pods/proxy-service-hfgm2-rvq64:1080/proxy/rewri... (200; 38.175181ms)
Mar  1 08:06:23.014: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-jgftx/pods/proxy-service-hfgm2-rvq64/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jgftx/pods/proxy-service-hfgm2-rvq64/proxy/rewriteme"... (200; 38.21548ms)
Mar  1 08:06:23.014: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-jgftx/pods/https:proxy-service-hfgm2-rvq64:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jgftx/pods/https:proxy-service-hfgm2-rvq64:443/proxy/... (200; 38.305254ms)
Mar  1 08:06:23.015: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-jgftx/services/https:proxy-service-hfgm2:tlsportname1/proxy/: tls baz (200; 38.254645ms)
Mar  1 08:06:23.015: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-jgftx/pods/proxy-service-hfgm2-rvq64:160/proxy/: foo (200; 38.267953ms)
Mar  1 08:06:23.015: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-jgftx/services/proxy-service-hfgm2:portname1/proxy/: foo (200; 39.019386ms)
Mar  1 08:06:23.016: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-jgftx/services/https:proxy-service-hfgm2:tlsportname2/proxy/: tls qux (200; 39.383532ms)
Mar  1 08:06:23.016: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-jgftx/services/http:proxy-service-hfgm2:portname2/proxy/: bar (200; 39.398509ms)
Mar  1 08:06:23.016: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-jgftx/services/proxy-service-hfgm2:portname2/proxy/: bar (200; 39.80118ms)
Mar  1 08:06:23.017: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-jgftx/services/http:proxy-service-hfgm2:portname1/proxy/: foo (200; 40.485952ms)
Mar  1 08:06:23.055: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-jgftx/pods/proxy-service-hfgm2-rvq64:160/proxy/: foo (200; 37.407976ms)
Mar  1 08:06:23.055: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-jgftx/pods/proxy-service-hfgm2-rvq64:162/proxy/: bar (200; 37.350901ms)
Mar  1 08:06:23.055: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-jgftx/pods/https:proxy-service-hfgm2-rvq64:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jgftx/pods/https:proxy-service-hfgm2-rvq64:443/proxy/... (200; 37.758079ms)
Mar  1 08:06:23.055: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-jgftx/pods/http:proxy-service-hfgm2-rvq64:162/proxy/: bar (200; 37.409429ms)
Mar  1 08:06:23.055: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-jgftx/pods/proxy-service-hfgm2-rvq64:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jgftx/pods/proxy-service-hfgm2-rvq64:1080/proxy/rewri... (200; 37.336597ms)
Mar  1 08:06:23.055: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-jgftx/pods/http:proxy-service-hfgm2-rvq64:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jgftx/pods/http:proxy-service-hfgm2-rvq64:1080/proxy/... (200; 37.341614ms)
Mar  1 08:06:23.055: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-jgftx/pods/proxy-service-hfgm2-rvq64/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-jgftx/pods/proxy-service-hfgm2-rvq64/proxy/rewriteme"... (200; 37.385043ms)
Mar  1 08:06:23.055: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-jgftx/services/https:proxy-service-hfgm2:tlsportname2/proxy/: tls qux (200; 37.579985ms)
Mar  1 08:06:23.055: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-jgftx/pods/https:proxy-service-hfgm2-rvq64:462/proxy/: tls qux (200; 37.995378ms)
Mar  1 08:06:23.055: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-jgftx/pods/https:proxy-service-hfgm2-rvq64:460/proxy/: tls baz (200; 37.516154ms)
Mar  1 08:06:23.055: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-jgftx/services/https:proxy-service-hfgm2:tlsportname1/proxy/: tls baz (200; 37.707967ms)
Mar  1 08:06:23.055: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-jgftx/pods/http:proxy-service-hfgm2-rvq64:160/proxy/: foo (200; 37.425957ms)
Mar  1 08:06:23.056: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-jgftx/services/proxy-service-hfgm2:portname2/proxy/: bar (200; 38.74799ms)
Mar  1 08:06:23.056: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-jgftx/services/http:proxy-service-hfgm2:portname1/proxy/: foo (200; 38.763741ms)
Mar  1 08:06:23.057: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-jgftx/services/http:proxy-service-hfgm2:portname2/proxy/: bar (200; 40.347759ms)
Mar  1 08:06:23.058: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-jgftx/services/proxy-service-hfgm2:portname1/proxy/: foo (200; 40.469816ms)
STEP: deleting { ReplicationController} proxy-service-hfgm2 in namespace e2e-tests-proxy-jgftx, will wait for the garbage collector to delete the pods
Mar  1 08:06:23.182: INFO: Deleting { ReplicationController} proxy-service-hfgm2 took: 38.094669ms
Mar  1 08:06:23.282: INFO: Terminating { ReplicationController} proxy-service-hfgm2 pods took: 100.320719ms
[AfterEach] version v1
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 08:06:31.282: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-proxy-jgftx" for this suite.
Mar  1 08:06:37.428: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 08:06:37.605: INFO: namespace: e2e-tests-proxy-jgftx, resource: bindings, ignored listing per whitelist
Mar  1 08:06:38.789: INFO: namespace e2e-tests-proxy-jgftx deletion completed in 7.470342319s

• [SLOW TEST:26.723 seconds]
[sig-network] Proxy
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy through a service and a pod  [Conformance]
    /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] Projected 
  should provide container's memory limit [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 08:06:38.789: INFO: >>> kubeConfig: /tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-4mwg8
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Mar  1 08:06:40.417: INFO: Waiting up to 5m0s for pod "downwardapi-volume-f1a845b7-3bf8-11e9-a72e-ce8290b78775" in namespace "e2e-tests-projected-4mwg8" to be "success or failure"
Mar  1 08:06:40.453: INFO: Pod "downwardapi-volume-f1a845b7-3bf8-11e9-a72e-ce8290b78775": Phase="Pending", Reason="", readiness=false. Elapsed: 35.505412ms
Mar  1 08:06:42.489: INFO: Pod "downwardapi-volume-f1a845b7-3bf8-11e9-a72e-ce8290b78775": Phase="Pending", Reason="", readiness=false. Elapsed: 2.07203297s
Mar  1 08:06:44.525: INFO: Pod "downwardapi-volume-f1a845b7-3bf8-11e9-a72e-ce8290b78775": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.108374752s
STEP: Saw pod success
Mar  1 08:06:44.526: INFO: Pod "downwardapi-volume-f1a845b7-3bf8-11e9-a72e-ce8290b78775" satisfied condition "success or failure"
Mar  1 08:06:44.561: INFO: Trying to get logs from node shoot--it--pub-az-nl4q9-cpu-worker-7dd9bbfd9c-7fp9l pod downwardapi-volume-f1a845b7-3bf8-11e9-a72e-ce8290b78775 container client-container: <nil>
STEP: delete the pod
Mar  1 08:06:44.651: INFO: Waiting for pod downwardapi-volume-f1a845b7-3bf8-11e9-a72e-ce8290b78775 to disappear
Mar  1 08:06:44.686: INFO: Pod downwardapi-volume-f1a845b7-3bf8-11e9-a72e-ce8290b78775 no longer exists
[AfterEach] [sig-storage] Projected
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 08:06:44.686: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-4mwg8" for this suite.
Mar  1 08:06:50.830: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 08:06:52.015: INFO: namespace: e2e-tests-projected-4mwg8, resource: bindings, ignored listing per whitelist
Mar  1 08:06:52.241: INFO: namespace e2e-tests-projected-4mwg8 deletion completed in 7.518455257s

• [SLOW TEST:13.452 seconds]
[sig-storage] Projected
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should provide container's memory limit [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-api-machinery] Secrets 
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Secrets
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 08:06:52.241: INFO: >>> kubeConfig: /tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-secrets-6mvn2
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in env vars [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-f9b72cf6-3bf8-11e9-a72e-ce8290b78775
STEP: Creating a pod to test consume secrets
Mar  1 08:06:53.971: INFO: Waiting up to 5m0s for pod "pod-secrets-f9bca82b-3bf8-11e9-a72e-ce8290b78775" in namespace "e2e-tests-secrets-6mvn2" to be "success or failure"
Mar  1 08:06:54.015: INFO: Pod "pod-secrets-f9bca82b-3bf8-11e9-a72e-ce8290b78775": Phase="Pending", Reason="", readiness=false. Elapsed: 43.845805ms
Mar  1 08:06:56.051: INFO: Pod "pod-secrets-f9bca82b-3bf8-11e9-a72e-ce8290b78775": Phase="Pending", Reason="", readiness=false. Elapsed: 2.079717857s
Mar  1 08:06:58.087: INFO: Pod "pod-secrets-f9bca82b-3bf8-11e9-a72e-ce8290b78775": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.115903466s
STEP: Saw pod success
Mar  1 08:06:58.087: INFO: Pod "pod-secrets-f9bca82b-3bf8-11e9-a72e-ce8290b78775" satisfied condition "success or failure"
Mar  1 08:06:58.123: INFO: Trying to get logs from node shoot--it--pub-az-nl4q9-cpu-worker-7dd9bbfd9c-7fp9l pod pod-secrets-f9bca82b-3bf8-11e9-a72e-ce8290b78775 container secret-env-test: <nil>
STEP: delete the pod
Mar  1 08:06:58.212: INFO: Waiting for pod pod-secrets-f9bca82b-3bf8-11e9-a72e-ce8290b78775 to disappear
Mar  1 08:06:58.262: INFO: Pod pod-secrets-f9bca82b-3bf8-11e9-a72e-ce8290b78775 no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 08:06:58.262: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-6mvn2" for this suite.
Mar  1 08:07:04.427: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 08:07:05.342: INFO: namespace: e2e-tests-secrets-6mvn2, resource: bindings, ignored listing per whitelist
Mar  1 08:07:05.818: INFO: namespace e2e-tests-secrets-6mvn2 deletion completed in 7.520441538s

• [SLOW TEST:13.578 seconds]
[sig-api-machinery] Secrets
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:31
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 08:07:05.819: INFO: >>> kubeConfig: /tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-hfkz7
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Mar  1 08:07:07.422: INFO: Waiting up to 5m0s for pod "downwardapi-volume-01c0ded7-3bf9-11e9-a72e-ce8290b78775" in namespace "e2e-tests-downward-api-hfkz7" to be "success or failure"
Mar  1 08:07:07.457: INFO: Pod "downwardapi-volume-01c0ded7-3bf9-11e9-a72e-ce8290b78775": Phase="Pending", Reason="", readiness=false. Elapsed: 35.409409ms
Mar  1 08:07:09.496: INFO: Pod "downwardapi-volume-01c0ded7-3bf9-11e9-a72e-ce8290b78775": Phase="Pending", Reason="", readiness=false. Elapsed: 2.073885886s
Mar  1 08:07:11.533: INFO: Pod "downwardapi-volume-01c0ded7-3bf9-11e9-a72e-ce8290b78775": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.111265964s
STEP: Saw pod success
Mar  1 08:07:11.533: INFO: Pod "downwardapi-volume-01c0ded7-3bf9-11e9-a72e-ce8290b78775" satisfied condition "success or failure"
Mar  1 08:07:11.571: INFO: Trying to get logs from node shoot--it--pub-az-nl4q9-cpu-worker-7dd9bbfd9c-7fp9l pod downwardapi-volume-01c0ded7-3bf9-11e9-a72e-ce8290b78775 container client-container: <nil>
STEP: delete the pod
Mar  1 08:07:11.656: INFO: Waiting for pod downwardapi-volume-01c0ded7-3bf9-11e9-a72e-ce8290b78775 to disappear
Mar  1 08:07:11.722: INFO: Pod downwardapi-volume-01c0ded7-3bf9-11e9-a72e-ce8290b78775 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 08:07:11.722: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-hfkz7" for this suite.
Mar  1 08:07:17.872: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 08:07:18.711: INFO: namespace: e2e-tests-downward-api-hfkz7, resource: bindings, ignored listing per whitelist
Mar  1 08:07:19.312: INFO: namespace e2e-tests-downward-api-hfkz7 deletion completed in 7.553278208s

• [SLOW TEST:13.493 seconds]
[sig-storage] Downward API volume
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Secrets 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 08:07:19.312: INFO: >>> kubeConfig: /tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-secrets-kvvm4
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name s-test-opt-del-09d307e2-3bf9-11e9-a72e-ce8290b78775
STEP: Creating secret with name s-test-opt-upd-09d30830-3bf9-11e9-a72e-ce8290b78775
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-09d307e2-3bf9-11e9-a72e-ce8290b78775
STEP: Updating secret s-test-opt-upd-09d30830-3bf9-11e9-a72e-ce8290b78775
STEP: Creating secret with name s-test-opt-create-09d3084a-3bf9-11e9-a72e-ce8290b78775
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Secrets
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 08:07:27.718: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-kvvm4" for this suite.
Mar  1 08:07:51.866: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 08:07:52.937: INFO: namespace: e2e-tests-secrets-kvvm4, resource: bindings, ignored listing per whitelist
Mar  1 08:07:53.263: INFO: namespace e2e-tests-secrets-kvvm4 deletion completed in 25.507417391s

• [SLOW TEST:33.951 seconds]
[sig-storage] Secrets
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl cluster-info 
  should check if Kubernetes master services is included in cluster-info  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 08:07:53.263: INFO: >>> kubeConfig: /tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-l2mr5
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should check if Kubernetes master services is included in cluster-info  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: validating cluster-info
Mar  1 08:07:54.921: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-az-nl4q9.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml cluster-info'
Mar  1 08:07:55.974: INFO: stderr: ""
Mar  1 08:07:55.974: INFO: stdout: "\x1b[0;32mKubernetes master\x1b[0m is running at \x1b[0;33mhttps://api.pub-az-nl4q9.it.shoot.dev.k8s-hana.ondemand.com\x1b[0m\n\x1b[0;32mCoreDNS\x1b[0m is running at \x1b[0;33mhttps://api.pub-az-nl4q9.it.shoot.dev.k8s-hana.ondemand.com/api/v1/namespaces/kube-system/services/kube-dns:dns/proxy\x1b[0m\n\x1b[0;32mkubernetes-dashboard\x1b[0m is running at \x1b[0;33mhttps://api.pub-az-nl4q9.it.shoot.dev.k8s-hana.ondemand.com/api/v1/namespaces/kube-system/services/https:kubernetes-dashboard:/proxy\x1b[0m\n\nTo further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.\n"
[AfterEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 08:07:55.974: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-l2mr5" for this suite.
Mar  1 08:08:02.125: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 08:08:02.968: INFO: namespace: e2e-tests-kubectl-l2mr5, resource: bindings, ignored listing per whitelist
Mar  1 08:08:03.543: INFO: namespace e2e-tests-kubectl-l2mr5 deletion completed in 7.532271112s

• [SLOW TEST:10.281 seconds]
[sig-cli] Kubectl client
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl cluster-info
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should check if Kubernetes master services is included in cluster-info  [Conformance]
    /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop http hook properly [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 08:08:03.544: INFO: >>> kubeConfig: /tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-container-lifecycle-hook-p2snq
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop http hook properly [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Mar  1 08:08:13.601: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Mar  1 08:08:13.637: INFO: Pod pod-with-prestop-http-hook still exists
Mar  1 08:08:15.637: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Mar  1 08:08:15.674: INFO: Pod pod-with-prestop-http-hook still exists
Mar  1 08:08:17.637: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Mar  1 08:08:17.674: INFO: Pod pod-with-prestop-http-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 08:08:17.757: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-lifecycle-hook-p2snq" for this suite.
Mar  1 08:08:39.900: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 08:08:40.297: INFO: namespace: e2e-tests-container-lifecycle-hook-p2snq, resource: bindings, ignored listing per whitelist
Mar  1 08:08:41.287: INFO: namespace e2e-tests-container-lifecycle-hook-p2snq deletion completed in 23.494344125s

• [SLOW TEST:37.743 seconds]
[k8s.io] Container Lifecycle Hook
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when create a pod with lifecycle hook
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute prestop http hook properly [NodeConformance] [Conformance]
    /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Variable Expansion
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 08:08:41.287: INFO: >>> kubeConfig: /tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename var-expansion
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-var-expansion-tmmrk
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's command [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test substitution in container's command
Mar  1 08:08:43.018: INFO: Waiting up to 5m0s for pod "var-expansion-3abb99cb-3bf9-11e9-a72e-ce8290b78775" in namespace "e2e-tests-var-expansion-tmmrk" to be "success or failure"
Mar  1 08:08:43.054: INFO: Pod "var-expansion-3abb99cb-3bf9-11e9-a72e-ce8290b78775": Phase="Pending", Reason="", readiness=false. Elapsed: 35.7116ms
Mar  1 08:08:45.093: INFO: Pod "var-expansion-3abb99cb-3bf9-11e9-a72e-ce8290b78775": Phase="Pending", Reason="", readiness=false. Elapsed: 2.075333334s
Mar  1 08:08:47.129: INFO: Pod "var-expansion-3abb99cb-3bf9-11e9-a72e-ce8290b78775": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.111412868s
STEP: Saw pod success
Mar  1 08:08:47.130: INFO: Pod "var-expansion-3abb99cb-3bf9-11e9-a72e-ce8290b78775" satisfied condition "success or failure"
Mar  1 08:08:47.172: INFO: Trying to get logs from node shoot--it--pub-az-nl4q9-cpu-worker-7dd9bbfd9c-7fp9l pod var-expansion-3abb99cb-3bf9-11e9-a72e-ce8290b78775 container dapi-container: <nil>
STEP: delete the pod
Mar  1 08:08:47.260: INFO: Waiting for pod var-expansion-3abb99cb-3bf9-11e9-a72e-ce8290b78775 to disappear
Mar  1 08:08:47.296: INFO: Pod var-expansion-3abb99cb-3bf9-11e9-a72e-ce8290b78775 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 08:08:47.296: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-var-expansion-tmmrk" for this suite.
Mar  1 08:08:53.442: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 08:08:54.767: INFO: namespace: e2e-tests-var-expansion-tmmrk, resource: bindings, ignored listing per whitelist
Mar  1 08:08:54.837: INFO: namespace e2e-tests-var-expansion-tmmrk deletion completed in 7.504784141s

• [SLOW TEST:13.550 seconds]
[k8s.io] Variable Expansion
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-network] Services 
  should serve a basic endpoint from pods  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Services
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 08:08:54.837: INFO: >>> kubeConfig: /tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-services-kfmcw
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/network/service.go:84
[It] should serve a basic endpoint from pods  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating service endpoint-test2 in namespace e2e-tests-services-kfmcw
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-kfmcw to expose endpoints map[]
Mar  1 08:08:56.608: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-kfmcw exposes endpoints map[] (44.025491ms elapsed)
STEP: Creating pod pod1 in namespace e2e-tests-services-kfmcw
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-kfmcw to expose endpoints map[pod1:[80]]
Mar  1 08:08:59.962: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-kfmcw exposes endpoints map[pod1:[80]] (3.315212549s elapsed)
STEP: Creating pod pod2 in namespace e2e-tests-services-kfmcw
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-kfmcw to expose endpoints map[pod1:[80] pod2:[80]]
Mar  1 08:09:02.380: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-kfmcw exposes endpoints map[pod2:[80] pod1:[80]] (2.381171845s elapsed)
STEP: Deleting pod pod1 in namespace e2e-tests-services-kfmcw
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-kfmcw to expose endpoints map[pod2:[80]]
Mar  1 08:09:02.494: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-kfmcw exposes endpoints map[pod2:[80]] (74.138342ms elapsed)
STEP: Deleting pod pod2 in namespace e2e-tests-services-kfmcw
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-kfmcw to expose endpoints map[]
Mar  1 08:09:02.570: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-kfmcw exposes endpoints map[] (38.608506ms elapsed)
[AfterEach] [sig-network] Services
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 08:09:02.649: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-services-kfmcw" for this suite.
Mar  1 08:09:24.810: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 08:09:25.684: INFO: namespace: e2e-tests-services-kfmcw, resource: bindings, ignored listing per whitelist
Mar  1 08:09:26.235: INFO: namespace e2e-tests-services-kfmcw deletion completed in 23.533816841s
[AfterEach] [sig-network] Services
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/network/service.go:89

• [SLOW TEST:31.397 seconds]
[sig-network] Services
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should serve a basic endpoint from pods  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Downward API 
  should provide host IP as an env var [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Downward API
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 08:09:26.235: INFO: >>> kubeConfig: /tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-cmkjh
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide host IP as an env var [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Mar  1 08:09:27.941: INFO: Waiting up to 5m0s for pod "downward-api-55825bc0-3bf9-11e9-a72e-ce8290b78775" in namespace "e2e-tests-downward-api-cmkjh" to be "success or failure"
Mar  1 08:09:27.976: INFO: Pod "downward-api-55825bc0-3bf9-11e9-a72e-ce8290b78775": Phase="Pending", Reason="", readiness=false. Elapsed: 35.195931ms
Mar  1 08:09:30.013: INFO: Pod "downward-api-55825bc0-3bf9-11e9-a72e-ce8290b78775": Phase="Pending", Reason="", readiness=false. Elapsed: 2.071770586s
Mar  1 08:09:32.050: INFO: Pod "downward-api-55825bc0-3bf9-11e9-a72e-ce8290b78775": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.109192315s
STEP: Saw pod success
Mar  1 08:09:32.050: INFO: Pod "downward-api-55825bc0-3bf9-11e9-a72e-ce8290b78775" satisfied condition "success or failure"
Mar  1 08:09:32.086: INFO: Trying to get logs from node shoot--it--pub-az-nl4q9-cpu-worker-7dd9bbfd9c-7fp9l pod downward-api-55825bc0-3bf9-11e9-a72e-ce8290b78775 container dapi-container: <nil>
STEP: delete the pod
Mar  1 08:09:32.178: INFO: Waiting for pod downward-api-55825bc0-3bf9-11e9-a72e-ce8290b78775 to disappear
Mar  1 08:09:32.213: INFO: Pod downward-api-55825bc0-3bf9-11e9-a72e-ce8290b78775 no longer exists
[AfterEach] [sig-api-machinery] Downward API
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 08:09:32.213: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-cmkjh" for this suite.
Mar  1 08:09:38.368: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 08:09:39.432: INFO: namespace: e2e-tests-downward-api-cmkjh, resource: bindings, ignored listing per whitelist
Mar  1 08:09:39.900: INFO: namespace e2e-tests-downward-api-cmkjh deletion completed in 7.648491388s

• [SLOW TEST:13.665 seconds]
[sig-api-machinery] Downward API
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide host IP as an env var [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-api-machinery] Watchers 
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Watchers
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 08:09:39.900: INFO: >>> kubeConfig: /tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-watch-6fls5
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a watch on configmaps
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: closing the watch once it receives two notifications
Mar  1 08:09:41.625: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-6fls5,SelfLink:/api/v1/namespaces/e2e-tests-watch-6fls5/configmaps/e2e-watch-test-watch-closed,UID:5da28ce5-3bf9-11e9-b4e8-fa9e8069966e,ResourceVersion:7563,Generation:0,CreationTimestamp:2019-03-01 08:09:41 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Mar  1 08:09:41.633: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-6fls5,SelfLink:/api/v1/namespaces/e2e-tests-watch-6fls5/configmaps/e2e-watch-test-watch-closed,UID:5da28ce5-3bf9-11e9-b4e8-fa9e8069966e,ResourceVersion:7564,Generation:0,CreationTimestamp:2019-03-01 08:09:41 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time, while the watch is closed
STEP: creating a new watch on configmaps from the last resource version observed by the first watch
STEP: deleting the configmap
STEP: Expecting to observe notifications for all changes to the configmap since the first watch closed
Mar  1 08:09:41.777: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-6fls5,SelfLink:/api/v1/namespaces/e2e-tests-watch-6fls5/configmaps/e2e-watch-test-watch-closed,UID:5da28ce5-3bf9-11e9-b4e8-fa9e8069966e,ResourceVersion:7565,Generation:0,CreationTimestamp:2019-03-01 08:09:41 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Mar  1 08:09:41.777: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-6fls5,SelfLink:/api/v1/namespaces/e2e-tests-watch-6fls5/configmaps/e2e-watch-test-watch-closed,UID:5da28ce5-3bf9-11e9-b4e8-fa9e8069966e,ResourceVersion:7566,Generation:0,CreationTimestamp:2019-03-01 08:09:41 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 08:09:41.777: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-6fls5" for this suite.
Mar  1 08:09:49.927: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 08:09:50.395: INFO: namespace: e2e-tests-watch-6fls5, resource: bindings, ignored listing per whitelist
Mar  1 08:09:51.381: INFO: namespace e2e-tests-watch-6fls5 deletion completed in 9.567668869s

• [SLOW TEST:11.481 seconds]
[sig-api-machinery] Watchers
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] Projected 
  should provide container's cpu request [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 08:09:51.381: INFO: >>> kubeConfig: /tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-9r5sh
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Mar  1 08:09:53.209: INFO: Waiting up to 5m0s for pod "downwardapi-volume-64920976-3bf9-11e9-a72e-ce8290b78775" in namespace "e2e-tests-projected-9r5sh" to be "success or failure"
Mar  1 08:09:53.245: INFO: Pod "downwardapi-volume-64920976-3bf9-11e9-a72e-ce8290b78775": Phase="Pending", Reason="", readiness=false. Elapsed: 35.984975ms
Mar  1 08:09:55.282: INFO: Pod "downwardapi-volume-64920976-3bf9-11e9-a72e-ce8290b78775": Phase="Pending", Reason="", readiness=false. Elapsed: 2.072703281s
Mar  1 08:09:57.318: INFO: Pod "downwardapi-volume-64920976-3bf9-11e9-a72e-ce8290b78775": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.108626897s
STEP: Saw pod success
Mar  1 08:09:57.318: INFO: Pod "downwardapi-volume-64920976-3bf9-11e9-a72e-ce8290b78775" satisfied condition "success or failure"
Mar  1 08:09:57.353: INFO: Trying to get logs from node shoot--it--pub-az-nl4q9-cpu-worker-7dd9bbfd9c-7fp9l pod downwardapi-volume-64920976-3bf9-11e9-a72e-ce8290b78775 container client-container: <nil>
STEP: delete the pod
Mar  1 08:09:57.456: INFO: Waiting for pod downwardapi-volume-64920976-3bf9-11e9-a72e-ce8290b78775 to disappear
Mar  1 08:09:57.491: INFO: Pod downwardapi-volume-64920976-3bf9-11e9-a72e-ce8290b78775 no longer exists
[AfterEach] [sig-storage] Projected
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 08:09:57.491: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-9r5sh" for this suite.
Mar  1 08:10:03.646: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 08:10:03.751: INFO: namespace: e2e-tests-projected-9r5sh, resource: bindings, ignored listing per whitelist
Mar  1 08:10:05.128: INFO: namespace e2e-tests-projected-9r5sh deletion completed in 7.589627143s

• [SLOW TEST:13.746 seconds]
[sig-storage] Projected
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should provide container's cpu request [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 08:10:05.128: INFO: >>> kubeConfig: /tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-vkbwn
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-6ca25733-3bf9-11e9-a72e-ce8290b78775
STEP: Creating a pod to test consume configMaps
Mar  1 08:10:06.795: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-6ca807f7-3bf9-11e9-a72e-ce8290b78775" in namespace "e2e-tests-projected-vkbwn" to be "success or failure"
Mar  1 08:10:06.834: INFO: Pod "pod-projected-configmaps-6ca807f7-3bf9-11e9-a72e-ce8290b78775": Phase="Pending", Reason="", readiness=false. Elapsed: 39.465493ms
Mar  1 08:10:08.872: INFO: Pod "pod-projected-configmaps-6ca807f7-3bf9-11e9-a72e-ce8290b78775": Phase="Pending", Reason="", readiness=false. Elapsed: 2.076931898s
Mar  1 08:10:10.909: INFO: Pod "pod-projected-configmaps-6ca807f7-3bf9-11e9-a72e-ce8290b78775": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.113944521s
STEP: Saw pod success
Mar  1 08:10:10.909: INFO: Pod "pod-projected-configmaps-6ca807f7-3bf9-11e9-a72e-ce8290b78775" satisfied condition "success or failure"
Mar  1 08:10:10.954: INFO: Trying to get logs from node shoot--it--pub-az-nl4q9-cpu-worker-7dd9bbfd9c-7fp9l pod pod-projected-configmaps-6ca807f7-3bf9-11e9-a72e-ce8290b78775 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Mar  1 08:10:11.038: INFO: Waiting for pod pod-projected-configmaps-6ca807f7-3bf9-11e9-a72e-ce8290b78775 to disappear
Mar  1 08:10:11.075: INFO: Pod pod-projected-configmaps-6ca807f7-3bf9-11e9-a72e-ce8290b78775 no longer exists
[AfterEach] [sig-storage] Projected
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 08:10:11.075: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-vkbwn" for this suite.
Mar  1 08:10:17.228: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 08:10:17.950: INFO: namespace: e2e-tests-projected-vkbwn, resource: bindings, ignored listing per whitelist
Mar  1 08:10:18.671: INFO: namespace e2e-tests-projected-vkbwn deletion completed in 7.560268305s

• [SLOW TEST:13.544 seconds]
[sig-storage] Projected
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 08:10:18.672: INFO: >>> kubeConfig: /tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-lkxrc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-map-74bc2cb9-3bf9-11e9-a72e-ce8290b78775
STEP: Creating a pod to test consume configMaps
Mar  1 08:10:20.364: INFO: Waiting up to 5m0s for pod "pod-configmaps-74c1b2b0-3bf9-11e9-a72e-ce8290b78775" in namespace "e2e-tests-configmap-lkxrc" to be "success or failure"
Mar  1 08:10:20.399: INFO: Pod "pod-configmaps-74c1b2b0-3bf9-11e9-a72e-ce8290b78775": Phase="Pending", Reason="", readiness=false. Elapsed: 35.045602ms
Mar  1 08:10:22.437: INFO: Pod "pod-configmaps-74c1b2b0-3bf9-11e9-a72e-ce8290b78775": Phase="Pending", Reason="", readiness=false. Elapsed: 2.073188307s
Mar  1 08:10:24.474: INFO: Pod "pod-configmaps-74c1b2b0-3bf9-11e9-a72e-ce8290b78775": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.110013966s
STEP: Saw pod success
Mar  1 08:10:24.474: INFO: Pod "pod-configmaps-74c1b2b0-3bf9-11e9-a72e-ce8290b78775" satisfied condition "success or failure"
Mar  1 08:10:24.509: INFO: Trying to get logs from node shoot--it--pub-az-nl4q9-cpu-worker-7dd9bbfd9c-7fp9l pod pod-configmaps-74c1b2b0-3bf9-11e9-a72e-ce8290b78775 container configmap-volume-test: <nil>
STEP: delete the pod
Mar  1 08:10:24.600: INFO: Waiting for pod pod-configmaps-74c1b2b0-3bf9-11e9-a72e-ce8290b78775 to disappear
Mar  1 08:10:24.635: INFO: Pod pod-configmaps-74c1b2b0-3bf9-11e9-a72e-ce8290b78775 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 08:10:24.635: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-lkxrc" for this suite.
Mar  1 08:10:30.783: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 08:10:31.074: INFO: namespace: e2e-tests-configmap-lkxrc, resource: bindings, ignored listing per whitelist
Mar  1 08:10:32.261: INFO: namespace e2e-tests-configmap-lkxrc deletion completed in 7.588360656s

• [SLOW TEST:13.590 seconds]
[sig-storage] ConfigMap
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 08:10:32.282: INFO: >>> kubeConfig: /tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-mlswn
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Mar  1 08:10:33.934: INFO: Waiting up to 5m0s for pod "downwardapi-volume-7cd800b9-3bf9-11e9-a72e-ce8290b78775" in namespace "e2e-tests-projected-mlswn" to be "success or failure"
Mar  1 08:10:33.969: INFO: Pod "downwardapi-volume-7cd800b9-3bf9-11e9-a72e-ce8290b78775": Phase="Pending", Reason="", readiness=false. Elapsed: 35.370638ms
Mar  1 08:10:36.006: INFO: Pod "downwardapi-volume-7cd800b9-3bf9-11e9-a72e-ce8290b78775": Phase="Pending", Reason="", readiness=false. Elapsed: 2.071945503s
Mar  1 08:10:38.043: INFO: Pod "downwardapi-volume-7cd800b9-3bf9-11e9-a72e-ce8290b78775": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.108512563s
STEP: Saw pod success
Mar  1 08:10:38.043: INFO: Pod "downwardapi-volume-7cd800b9-3bf9-11e9-a72e-ce8290b78775" satisfied condition "success or failure"
Mar  1 08:10:38.078: INFO: Trying to get logs from node shoot--it--pub-az-nl4q9-cpu-worker-7dd9bbfd9c-7fp9l pod downwardapi-volume-7cd800b9-3bf9-11e9-a72e-ce8290b78775 container client-container: <nil>
STEP: delete the pod
Mar  1 08:10:38.172: INFO: Waiting for pod downwardapi-volume-7cd800b9-3bf9-11e9-a72e-ce8290b78775 to disappear
Mar  1 08:10:38.208: INFO: Pod downwardapi-volume-7cd800b9-3bf9-11e9-a72e-ce8290b78775 no longer exists
[AfterEach] [sig-storage] Projected
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 08:10:38.208: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-mlswn" for this suite.
Mar  1 08:10:44.362: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 08:10:44.615: INFO: namespace: e2e-tests-projected-mlswn, resource: bindings, ignored listing per whitelist
Mar  1 08:10:45.861: INFO: namespace e2e-tests-projected-mlswn deletion completed in 7.606496928s

• [SLOW TEST:13.579 seconds]
[sig-storage] Projected
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 08:10:45.861: INFO: >>> kubeConfig: /tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-5jfst
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name projected-secret-test-84f1e99c-3bf9-11e9-a72e-ce8290b78775
STEP: Creating a pod to test consume secrets
Mar  1 08:10:47.559: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-84f75c10-3bf9-11e9-a72e-ce8290b78775" in namespace "e2e-tests-projected-5jfst" to be "success or failure"
Mar  1 08:10:47.602: INFO: Pod "pod-projected-secrets-84f75c10-3bf9-11e9-a72e-ce8290b78775": Phase="Pending", Reason="", readiness=false. Elapsed: 42.54702ms
Mar  1 08:10:49.647: INFO: Pod "pod-projected-secrets-84f75c10-3bf9-11e9-a72e-ce8290b78775": Phase="Pending", Reason="", readiness=false. Elapsed: 2.088209625s
Mar  1 08:10:51.684: INFO: Pod "pod-projected-secrets-84f75c10-3bf9-11e9-a72e-ce8290b78775": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.12522907s
STEP: Saw pod success
Mar  1 08:10:51.684: INFO: Pod "pod-projected-secrets-84f75c10-3bf9-11e9-a72e-ce8290b78775" satisfied condition "success or failure"
Mar  1 08:10:51.735: INFO: Trying to get logs from node shoot--it--pub-az-nl4q9-cpu-worker-7dd9bbfd9c-7fp9l pod pod-projected-secrets-84f75c10-3bf9-11e9-a72e-ce8290b78775 container secret-volume-test: <nil>
STEP: delete the pod
Mar  1 08:10:51.838: INFO: Waiting for pod pod-projected-secrets-84f75c10-3bf9-11e9-a72e-ce8290b78775 to disappear
Mar  1 08:10:51.874: INFO: Pod pod-projected-secrets-84f75c10-3bf9-11e9-a72e-ce8290b78775 no longer exists
[AfterEach] [sig-storage] Projected
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 08:10:51.874: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-5jfst" for this suite.
Mar  1 08:10:58.020: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 08:10:58.460: INFO: namespace: e2e-tests-projected-5jfst, resource: bindings, ignored listing per whitelist
Mar  1 08:10:59.424: INFO: namespace e2e-tests-projected-5jfst deletion completed in 7.514101371s

• [SLOW TEST:13.562 seconds]
[sig-storage] Projected
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts 
  should allow opting out of API token automount  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-auth] ServiceAccounts
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 08:10:59.424: INFO: >>> kubeConfig: /tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename svcaccounts
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-svcaccounts-vgvpl
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow opting out of API token automount  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: getting the auto-created API token
Mar  1 08:11:01.797: INFO: created pod pod-service-account-defaultsa
Mar  1 08:11:01.797: INFO: pod pod-service-account-defaultsa service account token volume mount: true
Mar  1 08:11:01.842: INFO: created pod pod-service-account-mountsa
Mar  1 08:11:01.842: INFO: pod pod-service-account-mountsa service account token volume mount: true
Mar  1 08:11:01.878: INFO: created pod pod-service-account-nomountsa
Mar  1 08:11:01.878: INFO: pod pod-service-account-nomountsa service account token volume mount: false
Mar  1 08:11:01.914: INFO: created pod pod-service-account-defaultsa-mountspec
Mar  1 08:11:01.914: INFO: pod pod-service-account-defaultsa-mountspec service account token volume mount: true
Mar  1 08:11:01.959: INFO: created pod pod-service-account-mountsa-mountspec
Mar  1 08:11:01.959: INFO: pod pod-service-account-mountsa-mountspec service account token volume mount: true
Mar  1 08:11:01.997: INFO: created pod pod-service-account-nomountsa-mountspec
Mar  1 08:11:01.997: INFO: pod pod-service-account-nomountsa-mountspec service account token volume mount: true
Mar  1 08:11:02.033: INFO: created pod pod-service-account-defaultsa-nomountspec
Mar  1 08:11:02.033: INFO: pod pod-service-account-defaultsa-nomountspec service account token volume mount: false
Mar  1 08:11:02.079: INFO: created pod pod-service-account-mountsa-nomountspec
Mar  1 08:11:02.079: INFO: pod pod-service-account-mountsa-nomountspec service account token volume mount: false
Mar  1 08:11:02.115: INFO: created pod pod-service-account-nomountsa-nomountspec
Mar  1 08:11:02.115: INFO: pod pod-service-account-nomountsa-nomountspec service account token volume mount: false
[AfterEach] [sig-auth] ServiceAccounts
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 08:11:02.115: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-svcaccounts-vgvpl" for this suite.
Mar  1 08:11:26.287: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 08:11:26.678: INFO: namespace: e2e-tests-svcaccounts-vgvpl, resource: bindings, ignored listing per whitelist
Mar  1 08:11:27.764: INFO: namespace e2e-tests-svcaccounts-vgvpl deletion completed in 25.613291934s

• [SLOW TEST:28.340 seconds]
[sig-auth] ServiceAccounts
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:22
  should allow opting out of API token automount  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] ConfigMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 08:11:27.764: INFO: >>> kubeConfig: /tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-msndh
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-upd-9df00bb7-3bf9-11e9-a72e-ce8290b78775
STEP: Creating the pod
STEP: Updating configmap configmap-test-upd-9df00bb7-3bf9-11e9-a72e-ce8290b78775
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 08:13:01.726: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-msndh" for this suite.
Mar  1 08:13:23.873: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 08:13:24.381: INFO: namespace: e2e-tests-configmap-msndh, resource: bindings, ignored listing per whitelist
Mar  1 08:13:25.299: INFO: namespace e2e-tests-configmap-msndh deletion completed in 23.536731168s

• [SLOW TEST:117.535 seconds]
[sig-storage] ConfigMap
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  updates should be reflected in volume [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-api-machinery] Downward API 
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Downward API
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 08:13:25.299: INFO: >>> kubeConfig: /tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-xm498
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Mar  1 08:13:27.019: INFO: Waiting up to 5m0s for pod "downward-api-e402b96b-3bf9-11e9-a72e-ce8290b78775" in namespace "e2e-tests-downward-api-xm498" to be "success or failure"
Mar  1 08:13:27.105: INFO: Pod "downward-api-e402b96b-3bf9-11e9-a72e-ce8290b78775": Phase="Pending", Reason="", readiness=false. Elapsed: 85.831689ms
Mar  1 08:13:29.143: INFO: Pod "downward-api-e402b96b-3bf9-11e9-a72e-ce8290b78775": Phase="Pending", Reason="", readiness=false. Elapsed: 2.123639929s
Mar  1 08:13:31.179: INFO: Pod "downward-api-e402b96b-3bf9-11e9-a72e-ce8290b78775": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.159959767s
STEP: Saw pod success
Mar  1 08:13:31.179: INFO: Pod "downward-api-e402b96b-3bf9-11e9-a72e-ce8290b78775" satisfied condition "success or failure"
Mar  1 08:13:31.215: INFO: Trying to get logs from node shoot--it--pub-az-nl4q9-cpu-worker-7dd9bbfd9c-7fp9l pod downward-api-e402b96b-3bf9-11e9-a72e-ce8290b78775 container dapi-container: <nil>
STEP: delete the pod
Mar  1 08:13:31.300: INFO: Waiting for pod downward-api-e402b96b-3bf9-11e9-a72e-ce8290b78775 to disappear
Mar  1 08:13:31.336: INFO: Pod downward-api-e402b96b-3bf9-11e9-a72e-ce8290b78775 no longer exists
[AfterEach] [sig-api-machinery] Downward API
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 08:13:31.336: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-xm498" for this suite.
Mar  1 08:13:37.486: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 08:13:37.666: INFO: namespace: e2e-tests-downward-api-xm498, resource: bindings, ignored listing per whitelist
Mar  1 08:13:38.898: INFO: namespace e2e-tests-downward-api-xm498 deletion completed in 7.524564045s

• [SLOW TEST:13.599 seconds]
[sig-api-machinery] Downward API
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[k8s.io] Probing container 
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 08:13:38.898: INFO: >>> kubeConfig: /tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-container-probe-rfl4l
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Mar  1 08:14:02.731: INFO: Container started at 2019-03-01 08:13:43 +0000 UTC, pod became ready at 2019-03-01 08:14:01 +0000 UTC
[AfterEach] [k8s.io] Probing container
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 08:14:02.731: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-rfl4l" for this suite.
Mar  1 08:14:26.877: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 08:14:27.802: INFO: namespace: e2e-tests-container-probe-rfl4l, resource: bindings, ignored listing per whitelist
Mar  1 08:14:28.242: INFO: namespace e2e-tests-container-probe-rfl4l deletion completed in 25.474940526s

• [SLOW TEST:49.345 seconds]
[k8s.io] Probing container
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[k8s.io] Pods 
  should be submitted and removed [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 08:14:28.242: INFO: >>> kubeConfig: /tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-pods-qmfrx
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should be submitted and removed [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: setting up watch
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: verifying pod creation was observed
Mar  1 08:14:34.035: INFO: running pod: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-submit-remove-0972062f-3bfa-11e9-a72e-ce8290b78775", GenerateName:"", Namespace:"e2e-tests-pods-qmfrx", SelfLink:"/api/v1/namespaces/e2e-tests-pods-qmfrx/pods/pod-submit-remove-0972062f-3bfa-11e9-a72e-ce8290b78775", UID:"097fd89d-3bfa-11e9-b4e8-fa9e8069966e", ResourceVersion:"8411", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63687024869, loc:(*time.Location)(0x78fbda0)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"784124978"}, Annotations:map[string]string{"cni.projectcalico.org/podIP":"100.96.1.56/32", "kubernetes.io/psp":"e2e-test-privileged-psp"}, OwnerReferences:[]v1.OwnerReference(nil), Initializers:(*v1.Initializers)(nil), Finalizers:[]string(nil), ClusterName:""}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"default-token-gvv2n", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(0xc001c36780), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil)}}}, InitContainers:[]v1.Container(nil), Containers:[]v1.Container{v1.Container{Name:"nginx", Image:"docker.io/library/nginx:1.14-alpine", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-gvv2n", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc0028046e8), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"shoot--it--pub-az-nl4q9-cpu-worker-7dd9bbfd9c-7fp9l", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc002050840), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc002804d60)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc002804d80)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc002804d88), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil)}, Status:v1.PodStatus{Phase:"Running", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63687024869, loc:(*time.Location)(0x78fbda0)}}, Reason:"", Message:""}, v1.PodCondition{Type:"Ready", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63687024872, loc:(*time.Location)(0x78fbda0)}}, Reason:"", Message:""}, v1.PodCondition{Type:"ContainersReady", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63687024872, loc:(*time.Location)(0x78fbda0)}}, Reason:"", Message:""}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63687024869, loc:(*time.Location)(0x78fbda0)}}, Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"10.250.0.4", PodIP:"100.96.1.56", StartTime:(*v1.Time)(0xc001a6e3c0), InitContainerStatuses:[]v1.ContainerStatus(nil), ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"nginx", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(0xc001a6e3e0), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:true, RestartCount:0, Image:"nginx:1.14-alpine", ImageID:"docker-pullable://nginx@sha256:b96aeeb1687703c49096f4969358d44f8520b671da94848309a3ba5be5b4c632", ContainerID:"docker://106b19ef39e8aa0b2b1c7fc9a9e48043c40a9ba4f91d46dae3f4ac964447fdd4"}}, QOSClass:"BestEffort"}}
STEP: deleting the pod gracefully
STEP: verifying the kubelet observed the termination notice
STEP: verifying pod deletion was observed
[AfterEach] [k8s.io] Pods
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 08:14:41.240: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-qmfrx" for this suite.
Mar  1 08:14:47.386: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 08:14:48.688: INFO: namespace: e2e-tests-pods-qmfrx, resource: bindings, ignored listing per whitelist
Mar  1 08:14:48.795: INFO: namespace e2e-tests-pods-qmfrx deletion completed in 7.517584369s

• [SLOW TEST:20.552 seconds]
[k8s.io] Pods
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be submitted and removed [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run pod 
  should create a pod from an image when restart is Never  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 08:14:48.796: INFO: >>> kubeConfig: /tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-fk726
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Kubectl run pod
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1475
[It] should create a pod from an image when restart is Never  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Mar  1 08:14:50.383: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-az-nl4q9.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml run e2e-test-nginx-pod --restart=Never --generator=run-pod/v1 --image=docker.io/library/nginx:1.14-alpine --namespace=e2e-tests-kubectl-fk726'
Mar  1 08:14:50.841: INFO: stderr: ""
Mar  1 08:14:50.841: INFO: stdout: "pod/e2e-test-nginx-pod created\n"
STEP: verifying the pod e2e-test-nginx-pod was created
[AfterEach] [k8s.io] Kubectl run pod
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1480
Mar  1 08:14:50.878: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-az-nl4q9.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml delete pods e2e-test-nginx-pod --namespace=e2e-tests-kubectl-fk726'
Mar  1 08:14:54.400: INFO: stderr: ""
Mar  1 08:14:54.400: INFO: stdout: "pod \"e2e-test-nginx-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 08:14:54.400: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-fk726" for this suite.
Mar  1 08:15:00.550: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 08:15:01.411: INFO: namespace: e2e-tests-kubectl-fk726, resource: bindings, ignored listing per whitelist
Mar  1 08:15:01.946: INFO: namespace e2e-tests-kubectl-fk726 deletion completed in 7.502960785s

• [SLOW TEST:13.150 seconds]
[sig-cli] Kubectl client
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run pod
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create a pod from an image when restart is Never  [Conformance]
    /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 08:15:01.946: INFO: >>> kubeConfig: /tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-container-probe-nl5sw
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [k8s.io] Probing container
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 08:16:03.659: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-nl5sw" for this suite.
Mar  1 08:16:27.802: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 08:16:28.714: INFO: namespace: e2e-tests-container-probe-nl5sw, resource: bindings, ignored listing per whitelist
Mar  1 08:16:29.194: INFO: namespace e2e-tests-container-probe-nl5sw deletion completed in 25.499699047s

• [SLOW TEST:87.248 seconds]
[k8s.io] Probing container
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] HostPath 
  should give a volume the correct mode [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] HostPath
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 08:16:29.194: INFO: >>> kubeConfig: /tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename hostpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-hostpath-9n7td
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] HostPath
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:37
[It] should give a volume the correct mode [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test hostPath mode
Mar  1 08:16:30.918: INFO: Waiting up to 5m0s for pod "pod-host-path-test" in namespace "e2e-tests-hostpath-9n7td" to be "success or failure"
Mar  1 08:16:30.961: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 43.402048ms
Mar  1 08:16:32.997: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 2.07931463s
Mar  1 08:16:35.033: INFO: Pod "pod-host-path-test": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.11557661s
STEP: Saw pod success
Mar  1 08:16:35.033: INFO: Pod "pod-host-path-test" satisfied condition "success or failure"
Mar  1 08:16:35.074: INFO: Trying to get logs from node shoot--it--pub-az-nl4q9-cpu-worker-7dd9bbfd9c-7fp9l pod pod-host-path-test container test-container-1: <nil>
STEP: delete the pod
Mar  1 08:16:35.161: INFO: Waiting for pod pod-host-path-test to disappear
Mar  1 08:16:35.196: INFO: Pod pod-host-path-test no longer exists
[AfterEach] [sig-storage] HostPath
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 08:16:35.196: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-hostpath-9n7td" for this suite.
Mar  1 08:16:41.340: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 08:16:42.383: INFO: namespace: e2e-tests-hostpath-9n7td, resource: bindings, ignored listing per whitelist
Mar  1 08:16:42.741: INFO: namespace e2e-tests-hostpath-9n7td deletion completed in 7.509061798s

• [SLOW TEST:13.547 seconds]
[sig-storage] HostPath
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:34
  should give a volume the correct mode [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Projected 
  should provide podname only [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 08:16:42.741: INFO: >>> kubeConfig: /tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-hql27
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should provide podname only [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Mar  1 08:16:44.522: INFO: Waiting up to 5m0s for pod "downwardapi-volume-59bb96f4-3bfa-11e9-a72e-ce8290b78775" in namespace "e2e-tests-projected-hql27" to be "success or failure"
Mar  1 08:16:44.559: INFO: Pod "downwardapi-volume-59bb96f4-3bfa-11e9-a72e-ce8290b78775": Phase="Pending", Reason="", readiness=false. Elapsed: 36.467901ms
Mar  1 08:16:46.596: INFO: Pod "downwardapi-volume-59bb96f4-3bfa-11e9-a72e-ce8290b78775": Phase="Pending", Reason="", readiness=false. Elapsed: 2.073709621s
Mar  1 08:16:48.635: INFO: Pod "downwardapi-volume-59bb96f4-3bfa-11e9-a72e-ce8290b78775": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.112562566s
STEP: Saw pod success
Mar  1 08:16:48.635: INFO: Pod "downwardapi-volume-59bb96f4-3bfa-11e9-a72e-ce8290b78775" satisfied condition "success or failure"
Mar  1 08:16:48.671: INFO: Trying to get logs from node shoot--it--pub-az-nl4q9-cpu-worker-7dd9bbfd9c-7fp9l pod downwardapi-volume-59bb96f4-3bfa-11e9-a72e-ce8290b78775 container client-container: <nil>
STEP: delete the pod
Mar  1 08:16:48.755: INFO: Waiting for pod downwardapi-volume-59bb96f4-3bfa-11e9-a72e-ce8290b78775 to disappear
Mar  1 08:16:48.790: INFO: Pod downwardapi-volume-59bb96f4-3bfa-11e9-a72e-ce8290b78775 no longer exists
[AfterEach] [sig-storage] Projected
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 08:16:48.790: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-hql27" for this suite.
Mar  1 08:16:54.934: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 08:16:55.681: INFO: namespace: e2e-tests-projected-hql27, resource: bindings, ignored listing per whitelist
Mar  1 08:16:56.324: INFO: namespace e2e-tests-projected-hql27 deletion completed in 7.497719543s

• [SLOW TEST:13.582 seconds]
[sig-storage] Projected
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should provide podname only [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[k8s.io] Probing container 
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 08:16:56.324: INFO: >>> kubeConfig: /tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-container-probe-d9bf6
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-exec in namespace e2e-tests-container-probe-d9bf6
Mar  1 08:17:02.008: INFO: Started pod liveness-exec in namespace e2e-tests-container-probe-d9bf6
STEP: checking the pod's current state and verifying that restartCount is present
Mar  1 08:17:02.043: INFO: Initial restart count of pod liveness-exec is 0
Mar  1 08:17:48.921: INFO: Restart count of pod e2e-tests-container-probe-d9bf6/liveness-exec is now 1 (46.877116623s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 08:17:48.969: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-d9bf6" for this suite.
Mar  1 08:17:55.113: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 08:17:56.050: INFO: namespace: e2e-tests-container-probe-d9bf6, resource: bindings, ignored listing per whitelist
Mar  1 08:17:56.601: INFO: namespace e2e-tests-container-probe-d9bf6 deletion completed in 7.596101567s

• [SLOW TEST:60.277 seconds]
[k8s.io] Probing container
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Docker Containers
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 08:17:56.601: INFO: >>> kubeConfig: /tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename containers
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-containers-9hsmx
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test override all
Mar  1 08:17:58.346: INFO: Waiting up to 5m0s for pod "client-containers-85bc1baf-3bfa-11e9-a72e-ce8290b78775" in namespace "e2e-tests-containers-9hsmx" to be "success or failure"
Mar  1 08:17:58.381: INFO: Pod "client-containers-85bc1baf-3bfa-11e9-a72e-ce8290b78775": Phase="Pending", Reason="", readiness=false. Elapsed: 35.142448ms
Mar  1 08:18:00.418: INFO: Pod "client-containers-85bc1baf-3bfa-11e9-a72e-ce8290b78775": Phase="Pending", Reason="", readiness=false. Elapsed: 2.072235292s
Mar  1 08:18:02.454: INFO: Pod "client-containers-85bc1baf-3bfa-11e9-a72e-ce8290b78775": Phase="Pending", Reason="", readiness=false. Elapsed: 4.10834579s
Mar  1 08:18:04.490: INFO: Pod "client-containers-85bc1baf-3bfa-11e9-a72e-ce8290b78775": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.14460964s
STEP: Saw pod success
Mar  1 08:18:04.490: INFO: Pod "client-containers-85bc1baf-3bfa-11e9-a72e-ce8290b78775" satisfied condition "success or failure"
Mar  1 08:18:04.525: INFO: Trying to get logs from node shoot--it--pub-az-nl4q9-cpu-worker-7dd9bbfd9c-7fp9l pod client-containers-85bc1baf-3bfa-11e9-a72e-ce8290b78775 container test-container: <nil>
STEP: delete the pod
Mar  1 08:18:04.619: INFO: Waiting for pod client-containers-85bc1baf-3bfa-11e9-a72e-ce8290b78775 to disappear
Mar  1 08:18:04.654: INFO: Pod client-containers-85bc1baf-3bfa-11e9-a72e-ce8290b78775 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 08:18:04.654: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-9hsmx" for this suite.
Mar  1 08:18:10.798: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 08:18:11.229: INFO: namespace: e2e-tests-containers-9hsmx, resource: bindings, ignored listing per whitelist
Mar  1 08:18:12.261: INFO: namespace e2e-tests-containers-9hsmx deletion completed in 7.571376131s

• [SLOW TEST:15.660 seconds]
[k8s.io] Docker Containers
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should support rollover [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 08:18:12.262: INFO: >>> kubeConfig: /tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-deployment-2cjdw
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should support rollover [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Mar  1 08:18:13.976: INFO: Pod name rollover-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Mar  1 08:18:18.050: INFO: Waiting for pods owned by replica set "test-rollover-controller" to become ready
Mar  1 08:18:20.086: INFO: Creating deployment "test-rollover-deployment"
Mar  1 08:18:20.173: INFO: Make sure deployment "test-rollover-deployment" performs scaling operations
Mar  1 08:18:20.220: INFO: Check revision of new replica set for deployment "test-rollover-deployment"
Mar  1 08:18:20.292: INFO: Ensure that both replica sets have 1 created replica
Mar  1 08:18:20.363: INFO: Rollover old replica sets for deployment "test-rollover-deployment" with new image update
Mar  1 08:18:20.435: INFO: Updating deployment test-rollover-deployment
Mar  1 08:18:20.435: INFO: Wait deployment "test-rollover-deployment" to be observed by the deployment controller
Mar  1 08:18:22.516: INFO: Wait for revision update of deployment "test-rollover-deployment" to 2
Mar  1 08:18:22.588: INFO: Make sure deployment "test-rollover-deployment" is complete
Mar  1 08:18:22.660: INFO: all replica sets need to contain the pod-template-hash label
Mar  1 08:18:22.660: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63687025100, loc:(*time.Location)(0x78fbda0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63687025100, loc:(*time.Location)(0x78fbda0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63687025100, loc:(*time.Location)(0x78fbda0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63687025100, loc:(*time.Location)(0x78fbda0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-5b76ff8c4\" is progressing."}}, CollisionCount:(*int32)(nil)}
Mar  1 08:18:24.731: INFO: all replica sets need to contain the pod-template-hash label
Mar  1 08:18:24.731: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63687025100, loc:(*time.Location)(0x78fbda0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63687025100, loc:(*time.Location)(0x78fbda0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63687025104, loc:(*time.Location)(0x78fbda0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63687025100, loc:(*time.Location)(0x78fbda0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-5b76ff8c4\" is progressing."}}, CollisionCount:(*int32)(nil)}
Mar  1 08:18:26.755: INFO: all replica sets need to contain the pod-template-hash label
Mar  1 08:18:26.755: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63687025100, loc:(*time.Location)(0x78fbda0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63687025100, loc:(*time.Location)(0x78fbda0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63687025104, loc:(*time.Location)(0x78fbda0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63687025100, loc:(*time.Location)(0x78fbda0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-5b76ff8c4\" is progressing."}}, CollisionCount:(*int32)(nil)}
Mar  1 08:18:28.732: INFO: all replica sets need to contain the pod-template-hash label
Mar  1 08:18:28.732: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63687025100, loc:(*time.Location)(0x78fbda0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63687025100, loc:(*time.Location)(0x78fbda0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63687025104, loc:(*time.Location)(0x78fbda0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63687025100, loc:(*time.Location)(0x78fbda0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-5b76ff8c4\" is progressing."}}, CollisionCount:(*int32)(nil)}
Mar  1 08:18:30.736: INFO: all replica sets need to contain the pod-template-hash label
Mar  1 08:18:30.736: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63687025100, loc:(*time.Location)(0x78fbda0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63687025100, loc:(*time.Location)(0x78fbda0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63687025104, loc:(*time.Location)(0x78fbda0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63687025100, loc:(*time.Location)(0x78fbda0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-5b76ff8c4\" is progressing."}}, CollisionCount:(*int32)(nil)}
Mar  1 08:18:32.736: INFO: all replica sets need to contain the pod-template-hash label
Mar  1 08:18:32.737: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63687025100, loc:(*time.Location)(0x78fbda0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63687025100, loc:(*time.Location)(0x78fbda0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63687025104, loc:(*time.Location)(0x78fbda0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63687025100, loc:(*time.Location)(0x78fbda0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-5b76ff8c4\" is progressing."}}, CollisionCount:(*int32)(nil)}
Mar  1 08:18:34.732: INFO: 
Mar  1 08:18:34.732: INFO: Ensure that both old replica sets have no replicas
[AfterEach] [sig-apps] Deployment
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Mar  1 08:18:34.840: INFO: Deployment "test-rollover-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment,GenerateName:,Namespace:e2e-tests-deployment-2cjdw,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-2cjdw/deployments/test-rollover-deployment,UID:92ba1f69-3bfa-11e9-b4e8-fa9e8069966e,ResourceVersion:9063,Generation:2,CreationTimestamp:2019-03-01 08:18:20 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:0,MaxSurge:1,},},MinReadySeconds:10,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[{Available True 2019-03-01 08:18:20 +0000 UTC 2019-03-01 08:18:20 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2019-03-01 08:18:34 +0000 UTC 2019-03-01 08:18:20 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-rollover-deployment-5b76ff8c4" has successfully progressed.}],ReadyReplicas:1,CollisionCount:nil,},}

Mar  1 08:18:34.876: INFO: New ReplicaSet "test-rollover-deployment-5b76ff8c4" of Deployment "test-rollover-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-5b76ff8c4,GenerateName:,Namespace:e2e-tests-deployment-2cjdw,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-2cjdw/replicasets/test-rollover-deployment-5b76ff8c4,UID:92ea536e-3bfa-11e9-b4e8-fa9e8069966e,ResourceVersion:9056,Generation:2,CreationTimestamp:2019-03-01 08:18:20 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 5b76ff8c4,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment 92ba1f69-3bfa-11e9-b4e8-fa9e8069966e 0xc00289f700 0xc00289f701}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 5b76ff8c4,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 5b76ff8c4,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:2,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Mar  1 08:18:34.876: INFO: All old ReplicaSets of Deployment "test-rollover-deployment":
Mar  1 08:18:34.876: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-controller,GenerateName:,Namespace:e2e-tests-deployment-2cjdw,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-2cjdw/replicasets/test-rollover-controller,UID:8f08b797-3bfa-11e9-b4e8-fa9e8069966e,ResourceVersion:9062,Generation:2,CreationTimestamp:2019-03-01 08:18:13 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod: nginx,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment 92ba1f69-3bfa-11e9-b4e8-fa9e8069966e 0xc00289f63f 0xc00289f650}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Mar  1 08:18:34.876: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-6975f4fb87,GenerateName:,Namespace:e2e-tests-deployment-2cjdw,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-2cjdw/replicasets/test-rollover-deployment-6975f4fb87,UID:92be5fa1-3bfa-11e9-b4e8-fa9e8069966e,ResourceVersion:9023,Generation:2,CreationTimestamp:2019-03-01 08:18:20 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6975f4fb87,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment 92ba1f69-3bfa-11e9-b4e8-fa9e8069966e 0xc00289f7b7 0xc00289f7b8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 6975f4fb87,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6975f4fb87,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis-slave gcr.io/google_samples/gb-redisslave:nonexistent [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Mar  1 08:18:34.913: INFO: Pod "test-rollover-deployment-5b76ff8c4-6nw4d" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-5b76ff8c4-6nw4d,GenerateName:test-rollover-deployment-5b76ff8c4-,Namespace:e2e-tests-deployment-2cjdw,SelfLink:/api/v1/namespaces/e2e-tests-deployment-2cjdw/pods/test-rollover-deployment-5b76ff8c4-6nw4d,UID:92f11faf-3bfa-11e9-b4e8-fa9e8069966e,ResourceVersion:9034,Generation:0,CreationTimestamp:2019-03-01 08:18:20 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 5b76ff8c4,},Annotations:map[string]string{cni.projectcalico.org/podIP: 100.96.1.66/32,kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet test-rollover-deployment-5b76ff8c4 92ea536e-3bfa-11e9-b4e8-fa9e8069966e 0xc002016bc0 0xc002016bc1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-mbm2b {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-mbm2b,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-mbm2b true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--pub-az-nl4q9-cpu-worker-7dd9bbfd9c-7fp9l,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002016c20} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002016c40}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 08:18:20 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 08:18:23 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 08:18:23 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 08:18:20 +0000 UTC  }],Message:,Reason:,HostIP:10.250.0.4,PodIP:100.96.1.66,StartTime:2019-03-01 08:18:20 +0000 UTC,ContainerStatuses:[{redis {nil ContainerStateRunning{StartedAt:2019-03-01 08:18:22 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/redis:1.0 docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830 docker://bc8a1675452d205007524691adb273d57883284ba45e8b83698fb1ec0eed30da}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 08:18:34.913: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-2cjdw" for this suite.
Mar  1 08:18:43.059: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 08:18:44.224: INFO: namespace: e2e-tests-deployment-2cjdw, resource: bindings, ignored listing per whitelist
Mar  1 08:18:44.444: INFO: namespace e2e-tests-deployment-2cjdw deletion completed in 9.494803122s

• [SLOW TEST:32.182 seconds]
[sig-apps] Deployment
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  deployment should support rollover [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[k8s.io] Pods 
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 08:18:44.444: INFO: >>> kubeConfig: /tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-pods-cvsb8
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Mar  1 08:18:50.845: INFO: Successfully updated pod "pod-update-activedeadlineseconds-a235ff78-3bfa-11e9-a72e-ce8290b78775"
Mar  1 08:18:50.845: INFO: Waiting up to 5m0s for pod "pod-update-activedeadlineseconds-a235ff78-3bfa-11e9-a72e-ce8290b78775" in namespace "e2e-tests-pods-cvsb8" to be "terminated due to deadline exceeded"
Mar  1 08:18:50.883: INFO: Pod "pod-update-activedeadlineseconds-a235ff78-3bfa-11e9-a72e-ce8290b78775": Phase="Running", Reason="", readiness=true. Elapsed: 37.116787ms
Mar  1 08:18:52.920: INFO: Pod "pod-update-activedeadlineseconds-a235ff78-3bfa-11e9-a72e-ce8290b78775": Phase="Failed", Reason="DeadlineExceeded", readiness=false. Elapsed: 2.074615913s
Mar  1 08:18:52.920: INFO: Pod "pod-update-activedeadlineseconds-a235ff78-3bfa-11e9-a72e-ce8290b78775" satisfied condition "terminated due to deadline exceeded"
[AfterEach] [k8s.io] Pods
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 08:18:52.920: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-cvsb8" for this suite.
Mar  1 08:18:59.066: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 08:18:59.485: INFO: namespace: e2e-tests-pods-cvsb8, resource: bindings, ignored listing per whitelist
Mar  1 08:19:00.481: INFO: namespace e2e-tests-pods-cvsb8 deletion completed in 7.524686887s

• [SLOW TEST:16.037 seconds]
[k8s.io] Pods
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on tmpfs should have the correct mode [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 08:19:00.481: INFO: >>> kubeConfig: /tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-c24cc
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on tmpfs should have the correct mode [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir volume type on tmpfs
Mar  1 08:19:02.120: INFO: Waiting up to 5m0s for pod "pod-abbf663e-3bfa-11e9-a72e-ce8290b78775" in namespace "e2e-tests-emptydir-c24cc" to be "success or failure"
Mar  1 08:19:02.162: INFO: Pod "pod-abbf663e-3bfa-11e9-a72e-ce8290b78775": Phase="Pending", Reason="", readiness=false. Elapsed: 41.307357ms
Mar  1 08:19:04.199: INFO: Pod "pod-abbf663e-3bfa-11e9-a72e-ce8290b78775": Phase="Pending", Reason="", readiness=false. Elapsed: 2.078253796s
Mar  1 08:19:06.234: INFO: Pod "pod-abbf663e-3bfa-11e9-a72e-ce8290b78775": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.114047983s
STEP: Saw pod success
Mar  1 08:19:06.235: INFO: Pod "pod-abbf663e-3bfa-11e9-a72e-ce8290b78775" satisfied condition "success or failure"
Mar  1 08:19:06.270: INFO: Trying to get logs from node shoot--it--pub-az-nl4q9-cpu-worker-7dd9bbfd9c-7fp9l pod pod-abbf663e-3bfa-11e9-a72e-ce8290b78775 container test-container: <nil>
STEP: delete the pod
Mar  1 08:19:06.355: INFO: Waiting for pod pod-abbf663e-3bfa-11e9-a72e-ce8290b78775 to disappear
Mar  1 08:19:06.391: INFO: Pod pod-abbf663e-3bfa-11e9-a72e-ce8290b78775 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 08:19:06.391: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-c24cc" for this suite.
Mar  1 08:19:12.540: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 08:19:12.897: INFO: namespace: e2e-tests-emptydir-c24cc, resource: bindings, ignored listing per whitelist
Mar  1 08:19:13.919: INFO: namespace e2e-tests-emptydir-c24cc deletion completed in 7.491458175s

• [SLOW TEST:13.438 seconds]
[sig-storage] EmptyDir volumes
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  volume on tmpfs should have the correct mode [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl patch 
  should add annotations for pods in rc  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 08:19:13.919: INFO: >>> kubeConfig: /tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-dsxmn
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should add annotations for pods in rc  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating Redis RC
Mar  1 08:19:15.569: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-az-nl4q9.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml create -f - --namespace=e2e-tests-kubectl-dsxmn'
Mar  1 08:19:17.824: INFO: stderr: ""
Mar  1 08:19:17.824: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
Mar  1 08:19:18.860: INFO: Selector matched 1 pods for map[app:redis]
Mar  1 08:19:18.860: INFO: Found 0 / 1
Mar  1 08:19:19.860: INFO: Selector matched 1 pods for map[app:redis]
Mar  1 08:19:19.860: INFO: Found 0 / 1
Mar  1 08:19:20.861: INFO: Selector matched 1 pods for map[app:redis]
Mar  1 08:19:20.861: INFO: Found 1 / 1
Mar  1 08:19:20.861: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
STEP: patching all pods
Mar  1 08:19:20.897: INFO: Selector matched 1 pods for map[app:redis]
Mar  1 08:19:20.897: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Mar  1 08:19:20.897: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-az-nl4q9.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml patch pod redis-master-jsvtq --namespace=e2e-tests-kubectl-dsxmn -p {"metadata":{"annotations":{"x":"y"}}}'
Mar  1 08:19:21.157: INFO: stderr: ""
Mar  1 08:19:21.157: INFO: stdout: "pod/redis-master-jsvtq patched\n"
STEP: checking annotations
Mar  1 08:19:21.193: INFO: Selector matched 1 pods for map[app:redis]
Mar  1 08:19:21.193: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
[AfterEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 08:19:21.193: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-dsxmn" for this suite.
Mar  1 08:19:43.337: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 08:19:44.190: INFO: namespace: e2e-tests-kubectl-dsxmn, resource: bindings, ignored listing per whitelist
Mar  1 08:19:44.719: INFO: namespace e2e-tests-kubectl-dsxmn deletion completed in 23.489906267s

• [SLOW TEST:30.800 seconds]
[sig-cli] Kubectl client
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl patch
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should add annotations for pods in rc  [Conformance]
    /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected 
  should set mode on item file [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 08:19:44.719: INFO: >>> kubeConfig: /tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-zp5rf
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should set mode on item file [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Mar  1 08:19:46.334: INFO: Waiting up to 5m0s for pod "downwardapi-volume-c619a9ff-3bfa-11e9-a72e-ce8290b78775" in namespace "e2e-tests-projected-zp5rf" to be "success or failure"
Mar  1 08:19:46.380: INFO: Pod "downwardapi-volume-c619a9ff-3bfa-11e9-a72e-ce8290b78775": Phase="Pending", Reason="", readiness=false. Elapsed: 46.645701ms
Mar  1 08:19:48.417: INFO: Pod "downwardapi-volume-c619a9ff-3bfa-11e9-a72e-ce8290b78775": Phase="Pending", Reason="", readiness=false. Elapsed: 2.083418416s
Mar  1 08:19:50.453: INFO: Pod "downwardapi-volume-c619a9ff-3bfa-11e9-a72e-ce8290b78775": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.119654175s
STEP: Saw pod success
Mar  1 08:19:50.453: INFO: Pod "downwardapi-volume-c619a9ff-3bfa-11e9-a72e-ce8290b78775" satisfied condition "success or failure"
Mar  1 08:19:50.489: INFO: Trying to get logs from node shoot--it--pub-az-nl4q9-cpu-worker-7dd9bbfd9c-7fp9l pod downwardapi-volume-c619a9ff-3bfa-11e9-a72e-ce8290b78775 container client-container: <nil>
STEP: delete the pod
Mar  1 08:19:50.581: INFO: Waiting for pod downwardapi-volume-c619a9ff-3bfa-11e9-a72e-ce8290b78775 to disappear
Mar  1 08:19:50.616: INFO: Pod downwardapi-volume-c619a9ff-3bfa-11e9-a72e-ce8290b78775 no longer exists
[AfterEach] [sig-storage] Projected
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 08:19:50.616: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-zp5rf" for this suite.
Mar  1 08:19:56.771: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 08:19:57.450: INFO: namespace: e2e-tests-projected-zp5rf, resource: bindings, ignored listing per whitelist
Mar  1 08:19:58.180: INFO: namespace e2e-tests-projected-zp5rf deletion completed in 7.517225511s

• [SLOW TEST:13.461 seconds]
[sig-storage] Projected
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should set mode on item file [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with projected pod [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 08:19:58.180: INFO: >>> kubeConfig: /tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-subpath-6wf6g
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with projected pod [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-projected-rvm7
STEP: Creating a pod to test atomic-volume-subpath
Mar  1 08:19:59.906: INFO: Waiting up to 5m0s for pod "pod-subpath-test-projected-rvm7" in namespace "e2e-tests-subpath-6wf6g" to be "success or failure"
Mar  1 08:19:59.941: INFO: Pod "pod-subpath-test-projected-rvm7": Phase="Pending", Reason="", readiness=false. Elapsed: 35.374868ms
Mar  1 08:20:01.977: INFO: Pod "pod-subpath-test-projected-rvm7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.071459172s
Mar  1 08:20:04.014: INFO: Pod "pod-subpath-test-projected-rvm7": Phase="Pending", Reason="", readiness=false. Elapsed: 4.108110669s
Mar  1 08:20:06.052: INFO: Pod "pod-subpath-test-projected-rvm7": Phase="Running", Reason="", readiness=false. Elapsed: 6.146152591s
Mar  1 08:20:08.089: INFO: Pod "pod-subpath-test-projected-rvm7": Phase="Running", Reason="", readiness=false. Elapsed: 8.183325603s
Mar  1 08:20:10.126: INFO: Pod "pod-subpath-test-projected-rvm7": Phase="Running", Reason="", readiness=false. Elapsed: 10.22029462s
Mar  1 08:20:12.163: INFO: Pod "pod-subpath-test-projected-rvm7": Phase="Running", Reason="", readiness=false. Elapsed: 12.257375325s
Mar  1 08:20:14.199: INFO: Pod "pod-subpath-test-projected-rvm7": Phase="Running", Reason="", readiness=false. Elapsed: 14.293199575s
Mar  1 08:20:16.239: INFO: Pod "pod-subpath-test-projected-rvm7": Phase="Running", Reason="", readiness=false. Elapsed: 16.332918511s
Mar  1 08:20:18.287: INFO: Pod "pod-subpath-test-projected-rvm7": Phase="Running", Reason="", readiness=false. Elapsed: 18.381343728s
Mar  1 08:20:20.323: INFO: Pod "pod-subpath-test-projected-rvm7": Phase="Running", Reason="", readiness=false. Elapsed: 20.417420145s
Mar  1 08:20:22.360: INFO: Pod "pod-subpath-test-projected-rvm7": Phase="Running", Reason="", readiness=false. Elapsed: 22.454486733s
Mar  1 08:20:24.396: INFO: Pod "pod-subpath-test-projected-rvm7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.490704732s
STEP: Saw pod success
Mar  1 08:20:24.396: INFO: Pod "pod-subpath-test-projected-rvm7" satisfied condition "success or failure"
Mar  1 08:20:24.434: INFO: Trying to get logs from node shoot--it--pub-az-nl4q9-cpu-worker-7dd9bbfd9c-7fp9l pod pod-subpath-test-projected-rvm7 container test-container-subpath-projected-rvm7: <nil>
STEP: delete the pod
Mar  1 08:20:24.525: INFO: Waiting for pod pod-subpath-test-projected-rvm7 to disappear
Mar  1 08:20:24.560: INFO: Pod pod-subpath-test-projected-rvm7 no longer exists
STEP: Deleting pod pod-subpath-test-projected-rvm7
Mar  1 08:20:24.560: INFO: Deleting pod "pod-subpath-test-projected-rvm7" in namespace "e2e-tests-subpath-6wf6g"
[AfterEach] [sig-storage] Subpath
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 08:20:24.596: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-6wf6g" for this suite.
Mar  1 08:20:30.741: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 08:20:31.060: INFO: namespace: e2e-tests-subpath-6wf6g, resource: bindings, ignored listing per whitelist
Mar  1 08:20:32.099: INFO: namespace e2e-tests-subpath-6wf6g deletion completed in 7.467132701s

• [SLOW TEST:33.919 seconds]
[sig-storage] Subpath
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with projected pod [Conformance]
    /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-api-machinery] Garbage collector 
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 08:20:32.100: INFO: >>> kubeConfig: /tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-gc-qjv2w
STEP: Waiting for a default service account to be provisioned in namespace
[It] should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: Gathering metrics
W0301 08:20:39.959422   31889 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Mar  1 08:20:39.959: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 08:20:39.959: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-qjv2w" for this suite.
Mar  1 08:20:48.112: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 08:20:49.079: INFO: namespace: e2e-tests-gc-qjv2w, resource: bindings, ignored listing per whitelist
Mar  1 08:20:49.503: INFO: namespace e2e-tests-gc-qjv2w deletion completed in 9.508899483s

• [SLOW TEST:17.404 seconds]
[sig-api-machinery] Garbage collector
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-network] Service endpoints latency 
  should not be very high  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Service endpoints latency
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 08:20:49.504: INFO: >>> kubeConfig: /tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename svc-latency
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-svc-latency-gvl99
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be very high  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating replication controller svc-latency-rc in namespace e2e-tests-svc-latency-gvl99
I0301 08:20:51.126719   31889 runners.go:180] Created replication controller with name: svc-latency-rc, namespace: e2e-tests-svc-latency-gvl99, replica count: 1
I0301 08:20:52.177171   31889 runners.go:180] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0301 08:20:53.177366   31889 runners.go:180] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0301 08:20:54.177556   31889 runners.go:180] svc-latency-rc Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Mar  1 08:20:54.365: INFO: Created: latency-svc-5jkwf
Mar  1 08:20:54.381: INFO: Got endpoints: latency-svc-5jkwf [103.7918ms]
Mar  1 08:20:54.434: INFO: Created: latency-svc-g98p2
Mar  1 08:20:54.445: INFO: Got endpoints: latency-svc-g98p2 [63.7697ms]
Mar  1 08:20:54.454: INFO: Created: latency-svc-6jmlk
Mar  1 08:20:54.476: INFO: Got endpoints: latency-svc-6jmlk [94.525419ms]
Mar  1 08:20:54.477: INFO: Created: latency-svc-v9nc4
Mar  1 08:20:54.488: INFO: Got endpoints: latency-svc-v9nc4 [106.103308ms]
Mar  1 08:20:54.504: INFO: Created: latency-svc-pvc9m
Mar  1 08:20:54.516: INFO: Got endpoints: latency-svc-pvc9m [134.088636ms]
Mar  1 08:20:54.530: INFO: Created: latency-svc-jz4rj
Mar  1 08:20:54.540: INFO: Got endpoints: latency-svc-jz4rj [158.961901ms]
Mar  1 08:20:54.551: INFO: Created: latency-svc-cl2wl
Mar  1 08:20:54.571: INFO: Got endpoints: latency-svc-cl2wl [189.627791ms]
Mar  1 08:20:54.603: INFO: Created: latency-svc-22qwb
Mar  1 08:20:54.619: INFO: Got endpoints: latency-svc-22qwb [237.794747ms]
Mar  1 08:20:54.619: INFO: Created: latency-svc-kbkrx
Mar  1 08:20:54.635: INFO: Got endpoints: latency-svc-kbkrx [253.181463ms]
Mar  1 08:20:54.644: INFO: Created: latency-svc-cznmg
Mar  1 08:20:54.656: INFO: Got endpoints: latency-svc-cznmg [274.150008ms]
Mar  1 08:20:54.688: INFO: Created: latency-svc-zkxxm
Mar  1 08:20:54.699: INFO: Got endpoints: latency-svc-zkxxm [317.852646ms]
Mar  1 08:20:54.732: INFO: Created: latency-svc-vfjx5
Mar  1 08:20:54.750: INFO: Created: latency-svc-swdjz
Mar  1 08:20:54.750: INFO: Got endpoints: latency-svc-vfjx5 [368.352344ms]
Mar  1 08:20:54.761: INFO: Got endpoints: latency-svc-swdjz [379.487323ms]
Mar  1 08:20:54.771: INFO: Created: latency-svc-sflqp
Mar  1 08:20:54.782: INFO: Got endpoints: latency-svc-sflqp [400.775813ms]
Mar  1 08:20:54.793: INFO: Created: latency-svc-wnhzd
Mar  1 08:20:54.804: INFO: Got endpoints: latency-svc-wnhzd [422.766023ms]
Mar  1 08:20:54.814: INFO: Created: latency-svc-5bgzp
Mar  1 08:20:54.825: INFO: Got endpoints: latency-svc-5bgzp [444.020748ms]
Mar  1 08:20:54.859: INFO: Created: latency-svc-8zcd4
Mar  1 08:20:54.872: INFO: Got endpoints: latency-svc-8zcd4 [426.675215ms]
Mar  1 08:20:54.872: INFO: Created: latency-svc-gnfsg
Mar  1 08:20:54.883: INFO: Got endpoints: latency-svc-gnfsg [407.184055ms]
Mar  1 08:20:54.893: INFO: Created: latency-svc-z4pkc
Mar  1 08:20:54.910: INFO: Got endpoints: latency-svc-z4pkc [422.514218ms]
Mar  1 08:20:54.956: INFO: Created: latency-svc-qcc4s
Mar  1 08:20:55.010: INFO: Got endpoints: latency-svc-qcc4s [494.678633ms]
Mar  1 08:20:55.012: INFO: Created: latency-svc-rrvhw
Mar  1 08:20:55.015: INFO: Got endpoints: latency-svc-rrvhw [474.94371ms]
Mar  1 08:20:55.038: INFO: Created: latency-svc-hv9gk
Mar  1 08:20:55.051: INFO: Got endpoints: latency-svc-hv9gk [480.02013ms]
Mar  1 08:20:55.062: INFO: Created: latency-svc-qq844
Mar  1 08:20:55.074: INFO: Got endpoints: latency-svc-qq844 [454.919381ms]
Mar  1 08:20:55.144: INFO: Created: latency-svc-g56vv
Mar  1 08:20:55.148: INFO: Got endpoints: latency-svc-g56vv [513.106735ms]
Mar  1 08:20:55.158: INFO: Created: latency-svc-l56vx
Mar  1 08:20:55.169: INFO: Got endpoints: latency-svc-l56vx [513.815768ms]
Mar  1 08:20:55.180: INFO: Created: latency-svc-vl5lt
Mar  1 08:20:55.198: INFO: Got endpoints: latency-svc-vl5lt [498.676957ms]
Mar  1 08:20:55.248: INFO: Created: latency-svc-2kxlt
Mar  1 08:20:55.260: INFO: Got endpoints: latency-svc-2kxlt [509.627336ms]
Mar  1 08:20:55.270: INFO: Created: latency-svc-7zr7s
Mar  1 08:20:55.281: INFO: Got endpoints: latency-svc-7zr7s [520.027336ms]
Mar  1 08:20:55.312: INFO: Created: latency-svc-d7n28
Mar  1 08:20:55.323: INFO: Got endpoints: latency-svc-d7n28 [540.296166ms]
Mar  1 08:20:55.333: INFO: Created: latency-svc-5npng
Mar  1 08:20:55.363: INFO: Got endpoints: latency-svc-5npng [558.751491ms]
Mar  1 08:20:55.378: INFO: Created: latency-svc-kx7jj
Mar  1 08:20:55.387: INFO: Got endpoints: latency-svc-kx7jj [561.875778ms]
Mar  1 08:20:55.396: INFO: Created: latency-svc-p79mm
Mar  1 08:20:55.407: INFO: Got endpoints: latency-svc-p79mm [535.263402ms]
Mar  1 08:20:55.417: INFO: Created: latency-svc-fz6b7
Mar  1 08:20:55.427: INFO: Got endpoints: latency-svc-fz6b7 [544.225069ms]
Mar  1 08:20:55.437: INFO: Created: latency-svc-76w79
Mar  1 08:20:55.449: INFO: Got endpoints: latency-svc-76w79 [538.320474ms]
Mar  1 08:20:55.458: INFO: Created: latency-svc-p6fkf
Mar  1 08:20:55.491: INFO: Got endpoints: latency-svc-p6fkf [480.921083ms]
Mar  1 08:20:55.493: INFO: Created: latency-svc-msd2x
Mar  1 08:20:55.496: INFO: Got endpoints: latency-svc-msd2x [480.316489ms]
Mar  1 08:20:55.523: INFO: Created: latency-svc-fn948
Mar  1 08:20:55.535: INFO: Got endpoints: latency-svc-fn948 [483.401111ms]
Mar  1 08:20:55.544: INFO: Created: latency-svc-qmzvh
Mar  1 08:20:55.555: INFO: Got endpoints: latency-svc-qmzvh [480.997276ms]
Mar  1 08:20:55.567: INFO: Created: latency-svc-fmnlb
Mar  1 08:20:55.578: INFO: Got endpoints: latency-svc-fmnlb [430.111852ms]
Mar  1 08:20:55.588: INFO: Created: latency-svc-vktxq
Mar  1 08:20:55.618: INFO: Got endpoints: latency-svc-vktxq [448.346973ms]
Mar  1 08:20:55.625: INFO: Created: latency-svc-x5lrx
Mar  1 08:20:55.636: INFO: Got endpoints: latency-svc-x5lrx [437.908624ms]
Mar  1 08:20:55.646: INFO: Created: latency-svc-sq4mw
Mar  1 08:20:55.657: INFO: Got endpoints: latency-svc-sq4mw [397.129484ms]
Mar  1 08:20:55.669: INFO: Created: latency-svc-2klkt
Mar  1 08:20:55.680: INFO: Got endpoints: latency-svc-2klkt [398.588624ms]
Mar  1 08:20:55.690: INFO: Created: latency-svc-qbxq7
Mar  1 08:20:55.701: INFO: Got endpoints: latency-svc-qbxq7 [378.737835ms]
Mar  1 08:20:55.776: INFO: Created: latency-svc-jbpr8
Mar  1 08:20:55.782: INFO: Got endpoints: latency-svc-jbpr8 [419.36778ms]
Mar  1 08:20:55.791: INFO: Created: latency-svc-btsds
Mar  1 08:20:55.802: INFO: Got endpoints: latency-svc-btsds [415.240254ms]
Mar  1 08:20:55.812: INFO: Created: latency-svc-kw2sk
Mar  1 08:20:55.823: INFO: Got endpoints: latency-svc-kw2sk [415.914194ms]
Mar  1 08:20:55.833: INFO: Created: latency-svc-nr9kd
Mar  1 08:20:55.844: INFO: Got endpoints: latency-svc-nr9kd [416.069326ms]
Mar  1 08:20:55.862: INFO: Created: latency-svc-svtzp
Mar  1 08:20:55.873: INFO: Got endpoints: latency-svc-svtzp [424.625654ms]
Mar  1 08:20:55.892: INFO: Created: latency-svc-b4r8x
Mar  1 08:20:55.894: INFO: Got endpoints: latency-svc-b4r8x [402.679125ms]
Mar  1 08:20:55.923: INFO: Created: latency-svc-gwp7x
Mar  1 08:20:55.934: INFO: Got endpoints: latency-svc-gwp7x [438.210103ms]
Mar  1 08:20:55.944: INFO: Created: latency-svc-hc45t
Mar  1 08:20:55.957: INFO: Got endpoints: latency-svc-hc45t [422.157466ms]
Mar  1 08:20:55.968: INFO: Created: latency-svc-wtfp4
Mar  1 08:20:55.979: INFO: Got endpoints: latency-svc-wtfp4 [423.906915ms]
Mar  1 08:20:55.989: INFO: Created: latency-svc-s7qpr
Mar  1 08:20:56.020: INFO: Got endpoints: latency-svc-s7qpr [442.235689ms]
Mar  1 08:20:56.026: INFO: Created: latency-svc-tjksv
Mar  1 08:20:56.105: INFO: Created: latency-svc-9wvpq
Mar  1 08:20:56.113: INFO: Got endpoints: latency-svc-9wvpq [476.609259ms]
Mar  1 08:20:56.113: INFO: Got endpoints: latency-svc-tjksv [494.989578ms]
Mar  1 08:20:56.168: INFO: Created: latency-svc-s996v
Mar  1 08:20:56.179: INFO: Got endpoints: latency-svc-s996v [522.279309ms]
Mar  1 08:20:56.195: INFO: Created: latency-svc-hvtc6
Mar  1 08:20:56.207: INFO: Got endpoints: latency-svc-hvtc6 [527.308142ms]
Mar  1 08:20:56.222: INFO: Created: latency-svc-bdxzv
Mar  1 08:20:56.234: INFO: Got endpoints: latency-svc-bdxzv [532.032439ms]
Mar  1 08:20:56.278: INFO: Created: latency-svc-fg5ml
Mar  1 08:20:56.293: INFO: Created: latency-svc-mj2z5
Mar  1 08:20:56.293: INFO: Got endpoints: latency-svc-fg5ml [510.514522ms]
Mar  1 08:20:56.311: INFO: Got endpoints: latency-svc-mj2z5 [508.243ms]
Mar  1 08:20:56.329: INFO: Created: latency-svc-jfnr4
Mar  1 08:20:56.341: INFO: Got endpoints: latency-svc-jfnr4 [517.42189ms]
Mar  1 08:20:56.351: INFO: Created: latency-svc-qbrrx
Mar  1 08:20:56.363: INFO: Got endpoints: latency-svc-qbrrx [519.184847ms]
Mar  1 08:20:56.375: INFO: Created: latency-svc-kcnbc
Mar  1 08:20:56.409: INFO: Got endpoints: latency-svc-kcnbc [535.596643ms]
Mar  1 08:20:56.409: INFO: Created: latency-svc-j7vmv
Mar  1 08:20:56.413: INFO: Got endpoints: latency-svc-j7vmv [518.445105ms]
Mar  1 08:20:56.431: INFO: Created: latency-svc-msnrt
Mar  1 08:20:56.445: INFO: Got endpoints: latency-svc-msnrt [510.482007ms]
Mar  1 08:20:56.454: INFO: Created: latency-svc-f2c9n
Mar  1 08:20:56.465: INFO: Got endpoints: latency-svc-f2c9n [508.307262ms]
Mar  1 08:20:56.484: INFO: Created: latency-svc-swggx
Mar  1 08:20:56.496: INFO: Got endpoints: latency-svc-swggx [516.680451ms]
Mar  1 08:20:56.506: INFO: Created: latency-svc-4zhjl
Mar  1 08:20:56.541: INFO: Got endpoints: latency-svc-4zhjl [520.825496ms]
Mar  1 08:20:56.542: INFO: Created: latency-svc-dfjv9
Mar  1 08:20:56.547: INFO: Got endpoints: latency-svc-dfjv9 [434.193974ms]
Mar  1 08:20:56.558: INFO: Created: latency-svc-tqnqx
Mar  1 08:20:56.577: INFO: Got endpoints: latency-svc-tqnqx [464.423138ms]
Mar  1 08:20:56.595: INFO: Created: latency-svc-ld78b
Mar  1 08:20:56.607: INFO: Got endpoints: latency-svc-ld78b [428.277507ms]
Mar  1 08:20:56.618: INFO: Created: latency-svc-pqlrf
Mar  1 08:20:56.630: INFO: Got endpoints: latency-svc-pqlrf [421.655553ms]
Mar  1 08:20:56.682: INFO: Created: latency-svc-vmg9g
Mar  1 08:20:56.697: INFO: Created: latency-svc-6m2dv
Mar  1 08:20:56.697: INFO: Got endpoints: latency-svc-vmg9g [463.570433ms]
Mar  1 08:20:56.714: INFO: Got endpoints: latency-svc-6m2dv [421.380836ms]
Mar  1 08:20:56.731: INFO: Created: latency-svc-jqtdq
Mar  1 08:20:56.742: INFO: Got endpoints: latency-svc-jqtdq [431.629494ms]
Mar  1 08:20:56.752: INFO: Created: latency-svc-c77cj
Mar  1 08:20:56.763: INFO: Got endpoints: latency-svc-c77cj [422.607374ms]
Mar  1 08:20:56.773: INFO: Created: latency-svc-w9h6l
Mar  1 08:20:56.811: INFO: Got endpoints: latency-svc-w9h6l [448.650469ms]
Mar  1 08:20:56.812: INFO: Created: latency-svc-6c759
Mar  1 08:20:56.836: INFO: Created: latency-svc-v785s
Mar  1 08:20:56.847: INFO: Got endpoints: latency-svc-6c759 [437.600124ms]
Mar  1 08:20:56.858: INFO: Created: latency-svc-mzrkh
Mar  1 08:20:56.885: INFO: Created: latency-svc-nlpb5
Mar  1 08:20:56.897: INFO: Got endpoints: latency-svc-v785s [484.069203ms]
Mar  1 08:20:56.909: INFO: Created: latency-svc-xjz8d
Mar  1 08:20:56.942: INFO: Got endpoints: latency-svc-mzrkh [497.143163ms]
Mar  1 08:20:56.943: INFO: Created: latency-svc-zqwbq
Mar  1 08:20:56.963: INFO: Created: latency-svc-87p27
Mar  1 08:20:56.990: INFO: Created: latency-svc-8nhw8
Mar  1 08:20:56.990: INFO: Got endpoints: latency-svc-nlpb5 [524.600707ms]
Mar  1 08:20:57.015: INFO: Created: latency-svc-8mmzb
Mar  1 08:20:57.070: INFO: Got endpoints: latency-svc-xjz8d [573.611869ms]
Mar  1 08:20:57.070: INFO: Created: latency-svc-z9wtq
Mar  1 08:20:57.089: INFO: Created: latency-svc-md25k
Mar  1 08:20:57.089: INFO: Got endpoints: latency-svc-zqwbq [547.660365ms]
Mar  1 08:20:57.118: INFO: Created: latency-svc-dzphn
Mar  1 08:20:57.142: INFO: Created: latency-svc-vpzfk
Mar  1 08:20:57.142: INFO: Got endpoints: latency-svc-87p27 [595.39742ms]
Mar  1 08:20:57.199: INFO: Created: latency-svc-m62mm
Mar  1 08:20:57.199: INFO: Got endpoints: latency-svc-8nhw8 [621.819354ms]
Mar  1 08:20:57.213: INFO: Created: latency-svc-d5h68
Mar  1 08:20:57.244: INFO: Created: latency-svc-m7kd2
Mar  1 08:20:57.244: INFO: Got endpoints: latency-svc-8mmzb [637.061027ms]
Mar  1 08:20:57.266: INFO: Created: latency-svc-vfbpr
Mar  1 08:20:57.288: INFO: Created: latency-svc-sgsql
Mar  1 08:20:57.288: INFO: Got endpoints: latency-svc-z9wtq [658.518027ms]
Mar  1 08:20:57.336: INFO: Created: latency-svc-5hstb
Mar  1 08:20:57.348: INFO: Got endpoints: latency-svc-md25k [650.803586ms]
Mar  1 08:20:57.362: INFO: Created: latency-svc-gfwnf
Mar  1 08:20:57.385: INFO: Created: latency-svc-gshpj
Mar  1 08:20:57.409: INFO: Created: latency-svc-rp2bd
Mar  1 08:20:57.456: INFO: Created: latency-svc-jp8dp
Mar  1 08:20:57.482: INFO: Got endpoints: latency-svc-dzphn [767.660146ms]
Mar  1 08:20:57.482: INFO: Got endpoints: latency-svc-vpzfk [739.488544ms]
Mar  1 08:20:57.482: INFO: Created: latency-svc-hsdvz
Mar  1 08:20:57.511: INFO: Created: latency-svc-2fn8p
Mar  1 08:20:57.536: INFO: Created: latency-svc-k4jzj
Mar  1 08:20:57.547: INFO: Got endpoints: latency-svc-d5h68 [735.931938ms]
Mar  1 08:20:57.635: INFO: Created: latency-svc-nr5rb
Mar  1 08:20:57.646: INFO: Created: latency-svc-7qtg2
Mar  1 08:20:57.668: INFO: Created: latency-svc-2tvxz
Mar  1 08:20:57.680: INFO: Got endpoints: latency-svc-m7kd2 [832.934433ms]
Mar  1 08:20:57.680: INFO: Got endpoints: latency-svc-m62mm [916.257631ms]
Mar  1 08:20:57.680: INFO: Got endpoints: latency-svc-vfbpr [782.092096ms]
Mar  1 08:20:57.687: INFO: Got endpoints: latency-svc-5hstb [696.722594ms]
Mar  1 08:20:57.729: INFO: Created: latency-svc-ph47z
Mar  1 08:20:57.767: INFO: Got endpoints: latency-svc-sgsql [825.106396ms]
Mar  1 08:20:57.768: INFO: Created: latency-svc-q87k4
Mar  1 08:20:57.786: INFO: Created: latency-svc-t2jgb
Mar  1 08:20:57.797: INFO: Got endpoints: latency-svc-gfwnf [727.469762ms]
Mar  1 08:20:57.809: INFO: Created: latency-svc-2h4m7
Mar  1 08:20:57.848: INFO: Created: latency-svc-qdnsr
Mar  1 08:20:57.848: INFO: Got endpoints: latency-svc-gshpj [758.74081ms]
Mar  1 08:20:57.908: INFO: Created: latency-svc-kb89v
Mar  1 08:20:57.907: INFO: Got endpoints: latency-svc-rp2bd [764.880172ms]
Mar  1 08:20:57.921: INFO: Created: latency-svc-h7n5p
Mar  1 08:20:57.946: INFO: Got endpoints: latency-svc-jp8dp [746.500021ms]
Mar  1 08:20:57.968: INFO: Created: latency-svc-92xnl
Mar  1 08:20:57.995: INFO: Got endpoints: latency-svc-hsdvz [750.688471ms]
Mar  1 08:20:57.996: INFO: Created: latency-svc-kvktx
Mar  1 08:20:58.037: INFO: Got endpoints: latency-svc-2fn8p [748.481419ms]
Mar  1 08:20:58.054: INFO: Created: latency-svc-4wgk2
Mar  1 08:20:58.088: INFO: Created: latency-svc-t9l5n
Mar  1 08:20:58.090: INFO: Got endpoints: latency-svc-k4jzj [741.773892ms]
Mar  1 08:20:58.160: INFO: Got endpoints: latency-svc-nr5rb [678.01501ms]
Mar  1 08:20:58.160: INFO: Created: latency-svc-qggh2
Mar  1 08:20:58.187: INFO: Got endpoints: latency-svc-7qtg2 [705.256312ms]
Mar  1 08:20:58.213: INFO: Created: latency-svc-q825x
Mar  1 08:20:58.238: INFO: Got endpoints: latency-svc-2tvxz [690.70239ms]
Mar  1 08:20:58.239: INFO: Created: latency-svc-js7jv
Mar  1 08:20:58.307: INFO: Got endpoints: latency-svc-ph47z [627.807245ms]
Mar  1 08:20:58.324: INFO: Created: latency-svc-hgdzm
Mar  1 08:20:58.337: INFO: Got endpoints: latency-svc-q87k4 [657.681888ms]
Mar  1 08:20:58.366: INFO: Created: latency-svc-c2429
Mar  1 08:20:58.393: INFO: Got endpoints: latency-svc-t2jgb [713.355207ms]
Mar  1 08:20:58.393: INFO: Created: latency-svc-glq54
Mar  1 08:20:58.441: INFO: Got endpoints: latency-svc-2h4m7 [754.151763ms]
Mar  1 08:20:58.466: INFO: Created: latency-svc-ck9ft
Mar  1 08:20:58.494: INFO: Created: latency-svc-5p5zh
Mar  1 08:20:58.494: INFO: Got endpoints: latency-svc-qdnsr [726.545008ms]
Mar  1 08:20:58.577: INFO: Got endpoints: latency-svc-kb89v [779.532497ms]
Mar  1 08:20:58.577: INFO: Created: latency-svc-kl6d7
Mar  1 08:20:58.588: INFO: Got endpoints: latency-svc-h7n5p [739.953358ms]
Mar  1 08:20:58.629: INFO: Created: latency-svc-r4qkr
Mar  1 08:20:58.639: INFO: Got endpoints: latency-svc-92xnl [731.077322ms]
Mar  1 08:20:58.649: INFO: Created: latency-svc-ntkcv
Mar  1 08:20:58.702: INFO: Got endpoints: latency-svc-kvktx [756.143598ms]
Mar  1 08:20:58.705: INFO: Created: latency-svc-w257v
Mar  1 08:20:58.740: INFO: Got endpoints: latency-svc-4wgk2 [744.59387ms]
Mar  1 08:20:58.751: INFO: Created: latency-svc-zfqxk
Mar  1 08:20:58.789: INFO: Got endpoints: latency-svc-t9l5n [752.003274ms]
Mar  1 08:20:58.789: INFO: Created: latency-svc-hzzch
Mar  1 08:20:58.840: INFO: Got endpoints: latency-svc-qggh2 [750.428893ms]
Mar  1 08:20:58.841: INFO: Created: latency-svc-kxz47
Mar  1 08:20:58.889: INFO: Got endpoints: latency-svc-q825x [729.051366ms]
Mar  1 08:20:58.890: INFO: Created: latency-svc-cvqqk
Mar  1 08:20:58.974: INFO: Got endpoints: latency-svc-js7jv [786.813959ms]
Mar  1 08:20:58.980: INFO: Created: latency-svc-hsxbv
Mar  1 08:20:58.992: INFO: Got endpoints: latency-svc-hgdzm [754.008517ms]
Mar  1 08:20:59.024: INFO: Created: latency-svc-44fwt
Mar  1 08:20:59.039: INFO: Got endpoints: latency-svc-c2429 [731.490159ms]
Mar  1 08:20:59.051: INFO: Created: latency-svc-csnpt
Mar  1 08:20:59.099: INFO: Got endpoints: latency-svc-glq54 [761.452863ms]
Mar  1 08:20:59.114: INFO: Created: latency-svc-2whvj
Mar  1 08:20:59.137: INFO: Got endpoints: latency-svc-ck9ft [744.273283ms]
Mar  1 08:20:59.162: INFO: Created: latency-svc-mz9gw
Mar  1 08:20:59.241: INFO: Created: latency-svc-hlmvd
Mar  1 08:20:59.241: INFO: Got endpoints: latency-svc-kl6d7 [747.644977ms]
Mar  1 08:20:59.241: INFO: Got endpoints: latency-svc-5p5zh [800.525173ms]
Mar  1 08:20:59.290: INFO: Created: latency-svc-6cbs4
Mar  1 08:20:59.290: INFO: Got endpoints: latency-svc-r4qkr [713.512246ms]
Mar  1 08:20:59.313: INFO: Created: latency-svc-wbhnr
Mar  1 08:20:59.340: INFO: Created: latency-svc-8pr4h
Mar  1 08:20:59.340: INFO: Got endpoints: latency-svc-ntkcv [752.486947ms]
Mar  1 08:20:59.389: INFO: Got endpoints: latency-svc-w257v [749.935239ms]
Mar  1 08:20:59.389: INFO: Created: latency-svc-2wbbc
Mar  1 08:20:59.437: INFO: Created: latency-svc-qfdlx
Mar  1 08:20:59.448: INFO: Got endpoints: latency-svc-hzzch [708.230951ms]
Mar  1 08:20:59.505: INFO: Got endpoints: latency-svc-zfqxk [802.745422ms]
Mar  1 08:20:59.529: INFO: Created: latency-svc-svbl5
Mar  1 08:20:59.539: INFO: Got endpoints: latency-svc-kxz47 [750.412782ms]
Mar  1 08:20:59.559: INFO: Created: latency-svc-5rcls
Mar  1 08:20:59.596: INFO: Got endpoints: latency-svc-cvqqk [755.963003ms]
Mar  1 08:20:59.597: INFO: Created: latency-svc-kt5bk
Mar  1 08:20:59.680: INFO: Got endpoints: latency-svc-hsxbv [790.678684ms]
Mar  1 08:20:59.680: INFO: Created: latency-svc-dtsh4
Mar  1 08:20:59.691: INFO: Got endpoints: latency-svc-44fwt [717.051154ms]
Mar  1 08:20:59.729: INFO: Created: latency-svc-259sf
Mar  1 08:20:59.762: INFO: Got endpoints: latency-svc-csnpt [769.755495ms]
Mar  1 08:20:59.764: INFO: Created: latency-svc-njwlb
Mar  1 08:20:59.787: INFO: Got endpoints: latency-svc-2whvj [748.333628ms]
Mar  1 08:20:59.817: INFO: Created: latency-svc-vbzr2
Mar  1 08:20:59.850: INFO: Created: latency-svc-lsjkq
Mar  1 08:20:59.850: INFO: Got endpoints: latency-svc-mz9gw [750.808449ms]
Mar  1 08:20:59.889: INFO: Got endpoints: latency-svc-hlmvd [751.578192ms]
Mar  1 08:20:59.917: INFO: Created: latency-svc-bbxt8
Mar  1 08:20:59.975: INFO: Created: latency-svc-48wjt
Mar  1 08:20:59.975: INFO: Got endpoints: latency-svc-6cbs4 [733.637748ms]
Mar  1 08:20:59.987: INFO: Got endpoints: latency-svc-wbhnr [745.803036ms]
Mar  1 08:21:00.038: INFO: Got endpoints: latency-svc-8pr4h [747.817323ms]
Mar  1 08:21:00.039: INFO: Created: latency-svc-2mkgj
Mar  1 08:21:00.060: INFO: Created: latency-svc-phv8p
Mar  1 08:21:00.097: INFO: Created: latency-svc-9rglg
Mar  1 08:21:00.097: INFO: Got endpoints: latency-svc-2wbbc [756.560354ms]
Mar  1 08:21:00.151: INFO: Got endpoints: latency-svc-qfdlx [761.900745ms]
Mar  1 08:21:00.165: INFO: Created: latency-svc-cdck9
Mar  1 08:21:00.188: INFO: Got endpoints: latency-svc-svbl5 [739.307923ms]
Mar  1 08:21:00.208: INFO: Created: latency-svc-xxl9g
Mar  1 08:21:00.239: INFO: Created: latency-svc-7986k
Mar  1 08:21:00.239: INFO: Got endpoints: latency-svc-5rcls [733.956844ms]
Mar  1 08:21:00.310: INFO: Got endpoints: latency-svc-kt5bk [770.922802ms]
Mar  1 08:21:00.325: INFO: Created: latency-svc-lczdt
Mar  1 08:21:00.338: INFO: Got endpoints: latency-svc-dtsh4 [741.262977ms]
Mar  1 08:21:00.360: INFO: Created: latency-svc-tsd4r
Mar  1 08:21:00.387: INFO: Got endpoints: latency-svc-259sf [707.494676ms]
Mar  1 08:21:00.388: INFO: Created: latency-svc-487c8
Mar  1 08:21:00.449: INFO: Got endpoints: latency-svc-njwlb [758.032623ms]
Mar  1 08:21:00.476: INFO: Created: latency-svc-tjt9j
Mar  1 08:21:00.487: INFO: Got endpoints: latency-svc-vbzr2 [725.104201ms]
Mar  1 08:21:00.502: INFO: Created: latency-svc-b9cvv
Mar  1 08:21:00.536: INFO: Created: latency-svc-bhg5s
Mar  1 08:21:00.547: INFO: Got endpoints: latency-svc-lsjkq [759.255316ms]
Mar  1 08:21:00.597: INFO: Created: latency-svc-dft6n
Mar  1 08:21:00.597: INFO: Got endpoints: latency-svc-bbxt8 [746.841983ms]
Mar  1 08:21:00.647: INFO: Created: latency-svc-jlhcx
Mar  1 08:21:00.647: INFO: Got endpoints: latency-svc-48wjt [758.319672ms]
Mar  1 08:21:00.699: INFO: Got endpoints: latency-svc-2mkgj [723.97387ms]
Mar  1 08:21:00.716: INFO: Created: latency-svc-wpxxr
Mar  1 08:21:00.737: INFO: Got endpoints: latency-svc-phv8p [749.909878ms]
Mar  1 08:21:00.770: INFO: Created: latency-svc-vs4hp
Mar  1 08:21:00.835: INFO: Got endpoints: latency-svc-9rglg [796.991049ms]
Mar  1 08:21:00.835: INFO: Created: latency-svc-tm6g2
Mar  1 08:21:00.837: INFO: Got endpoints: latency-svc-cdck9 [740.18304ms]
Mar  1 08:21:00.885: INFO: Created: latency-svc-tld7c
Mar  1 08:21:00.896: INFO: Got endpoints: latency-svc-xxl9g [744.870831ms]
Mar  1 08:21:00.929: INFO: Created: latency-svc-4kcvp
Mar  1 08:21:00.961: INFO: Got endpoints: latency-svc-7986k [773.39399ms]
Mar  1 08:21:00.974: INFO: Created: latency-svc-cj8lc
Mar  1 08:21:00.987: INFO: Got endpoints: latency-svc-lczdt [748.073526ms]
Mar  1 08:21:01.023: INFO: Created: latency-svc-h4kp2
Mar  1 08:21:01.048: INFO: Created: latency-svc-dsxf2
Mar  1 08:21:01.048: INFO: Got endpoints: latency-svc-tsd4r [737.181079ms]
Mar  1 08:21:01.089: INFO: Got endpoints: latency-svc-487c8 [751.552838ms]
Mar  1 08:21:01.108: INFO: Created: latency-svc-pjwmp
Mar  1 08:21:01.144: INFO: Got endpoints: latency-svc-tjt9j [756.015987ms]
Mar  1 08:21:01.144: INFO: Created: latency-svc-zgsdb
Mar  1 08:21:01.265: INFO: Created: latency-svc-ltl7c
Mar  1 08:21:01.265: INFO: Got endpoints: latency-svc-bhg5s [777.479016ms]
Mar  1 08:21:01.265: INFO: Got endpoints: latency-svc-b9cvv [815.377322ms]
Mar  1 08:21:01.287: INFO: Got endpoints: latency-svc-dft6n [740.313433ms]
Mar  1 08:21:01.314: INFO: Created: latency-svc-f9sdd
Mar  1 08:21:01.349: INFO: Got endpoints: latency-svc-jlhcx [752.61699ms]
Mar  1 08:21:01.350: INFO: Created: latency-svc-cxljc
Mar  1 08:21:01.408: INFO: Created: latency-svc-jqv8j
Mar  1 08:21:01.408: INFO: Got endpoints: latency-svc-wpxxr [760.387037ms]
Mar  1 08:21:01.421: INFO: Created: latency-svc-v8chb
Mar  1 08:21:01.437: INFO: Got endpoints: latency-svc-vs4hp [738.019699ms]
Mar  1 08:21:01.457: INFO: Created: latency-svc-dw2ql
Mar  1 08:21:01.491: INFO: Got endpoints: latency-svc-tm6g2 [753.682706ms]
Mar  1 08:21:01.491: INFO: Created: latency-svc-9mbxc
Mar  1 08:21:01.543: INFO: Got endpoints: latency-svc-tld7c [707.936731ms]
Mar  1 08:21:01.559: INFO: Created: latency-svc-qnfdn
Mar  1 08:21:01.595: INFO: Got endpoints: latency-svc-4kcvp [757.724886ms]
Mar  1 08:21:01.595: INFO: Created: latency-svc-fj8kr
Mar  1 08:21:01.688: INFO: Created: latency-svc-l22bm
Mar  1 08:21:01.688: INFO: Got endpoints: latency-svc-h4kp2 [727.331663ms]
Mar  1 08:21:01.689: INFO: Got endpoints: latency-svc-cj8lc [792.816835ms]
Mar  1 08:21:01.737: INFO: Created: latency-svc-j5dlh
Mar  1 08:21:01.748: INFO: Got endpoints: latency-svc-dsxf2 [760.986799ms]
Mar  1 08:21:01.758: INFO: Created: latency-svc-jzzv7
Mar  1 08:21:01.807: INFO: Got endpoints: latency-svc-pjwmp [759.62781ms]
Mar  1 08:21:01.808: INFO: Created: latency-svc-s79rf
Mar  1 08:21:01.839: INFO: Got endpoints: latency-svc-zgsdb [749.25442ms]
Mar  1 08:21:01.861: INFO: Created: latency-svc-8gnmg
Mar  1 08:21:01.891: INFO: Got endpoints: latency-svc-ltl7c [747.061387ms]
Mar  1 08:21:01.891: INFO: Created: latency-svc-lpnxj
Mar  1 08:21:01.941: INFO: Got endpoints: latency-svc-f9sdd [676.570667ms]
Mar  1 08:21:01.978: INFO: Created: latency-svc-5x8fz
Mar  1 08:21:01.991: INFO: Got endpoints: latency-svc-cxljc [725.789284ms]
Mar  1 08:21:02.005: INFO: Created: latency-svc-sp9cc
Mar  1 08:21:02.041: INFO: Created: latency-svc-p7fl2
Mar  1 08:21:02.041: INFO: Got endpoints: latency-svc-jqv8j [754.397252ms]
Mar  1 08:21:02.090: INFO: Got endpoints: latency-svc-v8chb [740.913062ms]
Mar  1 08:21:02.090: INFO: Created: latency-svc-jlcvp
Mar  1 08:21:02.139: INFO: Got endpoints: latency-svc-dw2ql [731.399769ms]
Mar  1 08:21:02.139: INFO: Created: latency-svc-snvcz
Mar  1 08:21:02.199: INFO: Got endpoints: latency-svc-9mbxc [761.509993ms]
Mar  1 08:21:02.254: INFO: Created: latency-svc-nn489
Mar  1 08:21:02.255: INFO: Got endpoints: latency-svc-qnfdn [764.518237ms]
Mar  1 08:21:02.272: INFO: Created: latency-svc-vnfx5
Mar  1 08:21:02.356: INFO: Got endpoints: latency-svc-l22bm [760.644023ms]
Mar  1 08:21:02.365: INFO: Got endpoints: latency-svc-fj8kr [821.162382ms]
Mar  1 08:21:02.387: INFO: Got endpoints: latency-svc-j5dlh [698.518207ms]
Mar  1 08:21:02.437: INFO: Got endpoints: latency-svc-jzzv7 [748.906824ms]
Mar  1 08:21:02.487: INFO: Got endpoints: latency-svc-s79rf [739.047322ms]
Mar  1 08:21:02.550: INFO: Got endpoints: latency-svc-8gnmg [742.305657ms]
Mar  1 08:21:02.588: INFO: Got endpoints: latency-svc-lpnxj [749.071605ms]
Mar  1 08:21:02.638: INFO: Got endpoints: latency-svc-5x8fz [746.848551ms]
Mar  1 08:21:02.687: INFO: Got endpoints: latency-svc-sp9cc [746.024316ms]
Mar  1 08:21:02.737: INFO: Got endpoints: latency-svc-p7fl2 [746.693414ms]
Mar  1 08:21:02.787: INFO: Got endpoints: latency-svc-jlcvp [745.973319ms]
Mar  1 08:21:02.837: INFO: Got endpoints: latency-svc-snvcz [746.673252ms]
Mar  1 08:21:02.891: INFO: Got endpoints: latency-svc-nn489 [751.682101ms]
Mar  1 08:21:02.937: INFO: Got endpoints: latency-svc-vnfx5 [737.980863ms]
Mar  1 08:21:02.937: INFO: Latencies: [63.7697ms 94.525419ms 106.103308ms 134.088636ms 158.961901ms 189.627791ms 237.794747ms 253.181463ms 274.150008ms 317.852646ms 368.352344ms 378.737835ms 379.487323ms 397.129484ms 398.588624ms 400.775813ms 402.679125ms 407.184055ms 415.240254ms 415.914194ms 416.069326ms 419.36778ms 421.380836ms 421.655553ms 422.157466ms 422.514218ms 422.607374ms 422.766023ms 423.906915ms 424.625654ms 426.675215ms 428.277507ms 430.111852ms 431.629494ms 434.193974ms 437.600124ms 437.908624ms 438.210103ms 442.235689ms 444.020748ms 448.346973ms 448.650469ms 454.919381ms 463.570433ms 464.423138ms 474.94371ms 476.609259ms 480.02013ms 480.316489ms 480.921083ms 480.997276ms 483.401111ms 484.069203ms 494.678633ms 494.989578ms 497.143163ms 498.676957ms 508.243ms 508.307262ms 509.627336ms 510.482007ms 510.514522ms 513.106735ms 513.815768ms 516.680451ms 517.42189ms 518.445105ms 519.184847ms 520.027336ms 520.825496ms 522.279309ms 524.600707ms 527.308142ms 532.032439ms 535.263402ms 535.596643ms 538.320474ms 540.296166ms 544.225069ms 547.660365ms 558.751491ms 561.875778ms 573.611869ms 595.39742ms 621.819354ms 627.807245ms 637.061027ms 650.803586ms 657.681888ms 658.518027ms 676.570667ms 678.01501ms 690.70239ms 696.722594ms 698.518207ms 705.256312ms 707.494676ms 707.936731ms 708.230951ms 713.355207ms 713.512246ms 717.051154ms 723.97387ms 725.104201ms 725.789284ms 726.545008ms 727.331663ms 727.469762ms 729.051366ms 731.077322ms 731.399769ms 731.490159ms 733.637748ms 733.956844ms 735.931938ms 737.181079ms 737.980863ms 738.019699ms 739.047322ms 739.307923ms 739.488544ms 739.953358ms 740.18304ms 740.313433ms 740.913062ms 741.262977ms 741.773892ms 742.305657ms 744.273283ms 744.59387ms 744.870831ms 745.803036ms 745.973319ms 746.024316ms 746.500021ms 746.673252ms 746.693414ms 746.841983ms 746.848551ms 747.061387ms 747.644977ms 747.817323ms 748.073526ms 748.333628ms 748.481419ms 748.906824ms 749.071605ms 749.25442ms 749.909878ms 749.935239ms 750.412782ms 750.428893ms 750.688471ms 750.808449ms 751.552838ms 751.578192ms 751.682101ms 752.003274ms 752.486947ms 752.61699ms 753.682706ms 754.008517ms 754.151763ms 754.397252ms 755.963003ms 756.015987ms 756.143598ms 756.560354ms 757.724886ms 758.032623ms 758.319672ms 758.74081ms 759.255316ms 759.62781ms 760.387037ms 760.644023ms 760.986799ms 761.452863ms 761.509993ms 761.900745ms 764.518237ms 764.880172ms 767.660146ms 769.755495ms 770.922802ms 773.39399ms 777.479016ms 779.532497ms 782.092096ms 786.813959ms 790.678684ms 792.816835ms 796.991049ms 800.525173ms 802.745422ms 815.377322ms 821.162382ms 825.106396ms 832.934433ms 916.257631ms]
Mar  1 08:21:02.937: INFO: 50 %ile: 713.512246ms
Mar  1 08:21:02.937: INFO: 90 %ile: 764.518237ms
Mar  1 08:21:02.937: INFO: 99 %ile: 832.934433ms
Mar  1 08:21:02.937: INFO: Total sample count: 200
[AfterEach] [sig-network] Service endpoints latency
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 08:21:02.937: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-svc-latency-gvl99" for this suite.
Mar  1 08:21:35.083: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 08:21:35.264: INFO: namespace: e2e-tests-svc-latency-gvl99, resource: bindings, ignored listing per whitelist
Mar  1 08:21:36.485: INFO: namespace e2e-tests-svc-latency-gvl99 deletion completed in 33.511767418s

• [SLOW TEST:46.981 seconds]
[sig-network] Service endpoints latency
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should not be very high  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Proxy server 
  should support proxy with --port 0  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 08:21:36.485: INFO: >>> kubeConfig: /tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-k78q8
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should support proxy with --port 0  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: starting the proxy server
Mar  1 08:21:38.084: INFO: Asynchronously running '/go/src/k8s.io/kubernetes/_output/bin/kubectl kubectl --server=https://api.pub-az-nl4q9.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml proxy -p 0 --disable-filter'
STEP: curling proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 08:21:38.504: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-k78q8" for this suite.
Mar  1 08:21:44.683: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 08:21:45.428: INFO: namespace: e2e-tests-kubectl-k78q8, resource: bindings, ignored listing per whitelist
Mar  1 08:21:46.034: INFO: namespace e2e-tests-kubectl-k78q8 deletion completed in 7.493875828s

• [SLOW TEST:9.549 seconds]
[sig-cli] Kubectl client
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Proxy server
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should support proxy with --port 0  [Conformance]
    /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources Simple CustomResourceDefinition 
  creating/deleting custom resource definition objects works  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 08:21:46.035: INFO: >>> kubeConfig: /tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-custom-resource-definition-fwwq5
STEP: Waiting for a default service account to be provisioned in namespace
[It] creating/deleting custom resource definition objects works  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Mar  1 08:21:47.803: INFO: >>> kubeConfig: /tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 08:21:48.607: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-custom-resource-definition-fwwq5" for this suite.
Mar  1 08:21:54.752: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 08:21:55.503: INFO: namespace: e2e-tests-custom-resource-definition-fwwq5, resource: bindings, ignored listing per whitelist
Mar  1 08:21:56.160: INFO: namespace e2e-tests-custom-resource-definition-fwwq5 deletion completed in 7.515730466s

• [SLOW TEST:10.125 seconds]
[sig-api-machinery] CustomResourceDefinition resources
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  Simple CustomResourceDefinition
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apimachinery/custom_resource_definition.go:35
    creating/deleting custom resource definition objects works  [Conformance]
    /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Projected 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 08:21:56.160: INFO: >>> kubeConfig: /tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-m5h48
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name s-test-opt-del-1480646c-3bfb-11e9-a72e-ce8290b78775
STEP: Creating secret with name s-test-opt-upd-148064c3-3bfb-11e9-a72e-ce8290b78775
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-1480646c-3bfb-11e9-a72e-ce8290b78775
STEP: Updating secret s-test-opt-upd-148064c3-3bfb-11e9-a72e-ce8290b78775
STEP: Creating secret with name s-test-opt-create-148064e7-3bfb-11e9-a72e-ce8290b78775
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 08:22:04.643: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-m5h48" for this suite.
Mar  1 08:22:26.788: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 08:22:26.963: INFO: namespace: e2e-tests-projected-m5h48, resource: bindings, ignored listing per whitelist
Mar  1 08:22:28.186: INFO: namespace e2e-tests-projected-m5h48 deletion completed in 23.506069506s

• [SLOW TEST:32.026 seconds]
[sig-storage] Projected
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Projected 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 08:22:28.186: INFO: >>> kubeConfig: /tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-lrnrj
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with configMap that has name projected-configmap-test-upd-27a3cff0-3bfb-11e9-a72e-ce8290b78775
STEP: Creating the pod
STEP: Updating configmap projected-configmap-test-upd-27a3cff0-3bfb-11e9-a72e-ce8290b78775
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 08:24:00.140: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-lrnrj" for this suite.
Mar  1 08:24:22.293: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 08:24:23.006: INFO: namespace: e2e-tests-projected-lrnrj, resource: bindings, ignored listing per whitelist
Mar  1 08:24:23.693: INFO: namespace e2e-tests-projected-lrnrj deletion completed in 23.515345096s

• [SLOW TEST:115.507 seconds]
[sig-storage] Projected
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  updates should be reflected in volume [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 08:24:23.694: INFO: >>> kubeConfig: /tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-m5ssp
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-6c630b93-3bfb-11e9-a72e-ce8290b78775
STEP: Creating a pod to test consume configMaps
Mar  1 08:24:25.355: INFO: Waiting up to 5m0s for pod "pod-configmaps-6c689db3-3bfb-11e9-a72e-ce8290b78775" in namespace "e2e-tests-configmap-m5ssp" to be "success or failure"
Mar  1 08:24:25.391: INFO: Pod "pod-configmaps-6c689db3-3bfb-11e9-a72e-ce8290b78775": Phase="Pending", Reason="", readiness=false. Elapsed: 35.289271ms
Mar  1 08:24:27.428: INFO: Pod "pod-configmaps-6c689db3-3bfb-11e9-a72e-ce8290b78775": Phase="Pending", Reason="", readiness=false. Elapsed: 2.072304234s
Mar  1 08:24:29.464: INFO: Pod "pod-configmaps-6c689db3-3bfb-11e9-a72e-ce8290b78775": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.108269623s
STEP: Saw pod success
Mar  1 08:24:29.464: INFO: Pod "pod-configmaps-6c689db3-3bfb-11e9-a72e-ce8290b78775" satisfied condition "success or failure"
Mar  1 08:24:29.499: INFO: Trying to get logs from node shoot--it--pub-az-nl4q9-cpu-worker-7dd9bbfd9c-7fp9l pod pod-configmaps-6c689db3-3bfb-11e9-a72e-ce8290b78775 container configmap-volume-test: <nil>
STEP: delete the pod
Mar  1 08:24:29.584: INFO: Waiting for pod pod-configmaps-6c689db3-3bfb-11e9-a72e-ce8290b78775 to disappear
Mar  1 08:24:29.620: INFO: Pod pod-configmaps-6c689db3-3bfb-11e9-a72e-ce8290b78775 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 08:24:29.620: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-m5ssp" for this suite.
Mar  1 08:24:35.765: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 08:24:36.205: INFO: namespace: e2e-tests-configmap-m5ssp, resource: bindings, ignored listing per whitelist
Mar  1 08:24:37.278: INFO: namespace e2e-tests-configmap-m5ssp deletion completed in 7.622404587s

• [SLOW TEST:13.584 seconds]
[sig-storage] ConfigMap
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 08:24:37.278: INFO: >>> kubeConfig: /tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-r5b67
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-map-747ec031-3bfb-11e9-a72e-ce8290b78775
STEP: Creating a pod to test consume configMaps
Mar  1 08:24:38.956: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-7484617e-3bfb-11e9-a72e-ce8290b78775" in namespace "e2e-tests-projected-r5b67" to be "success or failure"
Mar  1 08:24:38.993: INFO: Pod "pod-projected-configmaps-7484617e-3bfb-11e9-a72e-ce8290b78775": Phase="Pending", Reason="", readiness=false. Elapsed: 37.358372ms
Mar  1 08:24:41.031: INFO: Pod "pod-projected-configmaps-7484617e-3bfb-11e9-a72e-ce8290b78775": Phase="Pending", Reason="", readiness=false. Elapsed: 2.074734118s
Mar  1 08:24:43.070: INFO: Pod "pod-projected-configmaps-7484617e-3bfb-11e9-a72e-ce8290b78775": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.113760916s
STEP: Saw pod success
Mar  1 08:24:43.070: INFO: Pod "pod-projected-configmaps-7484617e-3bfb-11e9-a72e-ce8290b78775" satisfied condition "success or failure"
Mar  1 08:24:43.106: INFO: Trying to get logs from node shoot--it--pub-az-nl4q9-cpu-worker-7dd9bbfd9c-7fp9l pod pod-projected-configmaps-7484617e-3bfb-11e9-a72e-ce8290b78775 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Mar  1 08:24:43.273: INFO: Waiting for pod pod-projected-configmaps-7484617e-3bfb-11e9-a72e-ce8290b78775 to disappear
Mar  1 08:24:43.308: INFO: Pod pod-projected-configmaps-7484617e-3bfb-11e9-a72e-ce8290b78775 no longer exists
[AfterEach] [sig-storage] Projected
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 08:24:43.308: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-r5b67" for this suite.
Mar  1 08:24:49.483: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 08:24:50.237: INFO: namespace: e2e-tests-projected-r5b67, resource: bindings, ignored listing per whitelist
Mar  1 08:24:50.916: INFO: namespace e2e-tests-projected-r5b67 deletion completed in 7.571781706s

• [SLOW TEST:13.638 seconds]
[sig-storage] Projected
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 08:24:50.916: INFO: >>> kubeConfig: /tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-tz7zv
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-map-7c9cd73e-3bfb-11e9-a72e-ce8290b78775
STEP: Creating a pod to test consume configMaps
Mar  1 08:24:52.584: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-7ca3dd9e-3bfb-11e9-a72e-ce8290b78775" in namespace "e2e-tests-projected-tz7zv" to be "success or failure"
Mar  1 08:24:52.621: INFO: Pod "pod-projected-configmaps-7ca3dd9e-3bfb-11e9-a72e-ce8290b78775": Phase="Pending", Reason="", readiness=false. Elapsed: 37.177713ms
Mar  1 08:24:54.657: INFO: Pod "pod-projected-configmaps-7ca3dd9e-3bfb-11e9-a72e-ce8290b78775": Phase="Pending", Reason="", readiness=false. Elapsed: 2.073462562s
Mar  1 08:24:56.694: INFO: Pod "pod-projected-configmaps-7ca3dd9e-3bfb-11e9-a72e-ce8290b78775": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.109792654s
STEP: Saw pod success
Mar  1 08:24:56.694: INFO: Pod "pod-projected-configmaps-7ca3dd9e-3bfb-11e9-a72e-ce8290b78775" satisfied condition "success or failure"
Mar  1 08:24:56.729: INFO: Trying to get logs from node shoot--it--pub-az-nl4q9-cpu-worker-7dd9bbfd9c-7fp9l pod pod-projected-configmaps-7ca3dd9e-3bfb-11e9-a72e-ce8290b78775 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Mar  1 08:24:56.830: INFO: Waiting for pod pod-projected-configmaps-7ca3dd9e-3bfb-11e9-a72e-ce8290b78775 to disappear
Mar  1 08:24:56.865: INFO: Pod pod-projected-configmaps-7ca3dd9e-3bfb-11e9-a72e-ce8290b78775 no longer exists
[AfterEach] [sig-storage] Projected
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 08:24:56.865: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-tz7zv" for this suite.
Mar  1 08:25:03.011: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 08:25:03.346: INFO: namespace: e2e-tests-projected-tz7zv, resource: bindings, ignored listing per whitelist
Mar  1 08:25:04.461: INFO: namespace e2e-tests-projected-tz7zv deletion completed in 7.560311854s

• [SLOW TEST:13.545 seconds]
[sig-storage] Projected
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 08:25:04.461: INFO: >>> kubeConfig: /tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-container-probe-2s7bj
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-exec in namespace e2e-tests-container-probe-2s7bj
Mar  1 08:25:10.213: INFO: Started pod liveness-exec in namespace e2e-tests-container-probe-2s7bj
STEP: checking the pod's current state and verifying that restartCount is present
Mar  1 08:25:10.249: INFO: Initial restart count of pod liveness-exec is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 08:29:10.690: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-2s7bj" for this suite.
Mar  1 08:29:16.837: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 08:29:17.835: INFO: namespace: e2e-tests-container-probe-2s7bj, resource: bindings, ignored listing per whitelist
Mar  1 08:29:18.227: INFO: namespace e2e-tests-container-probe-2s7bj deletion completed in 7.499146877s

• [SLOW TEST:253.766 seconds]
[k8s.io] Probing container
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop complex daemon [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 08:29:18.227: INFO: >>> kubeConfig: /tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-daemonsets-d2str
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should run and stop complex daemon [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Mar  1 08:29:19.952: INFO: Creating daemon "daemon-set" with a node selector
STEP: Initially, daemon pods should not be running on any nodes.
Mar  1 08:29:20.024: INFO: Number of nodes with available pods: 0
Mar  1 08:29:20.024: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Change node label to blue, check that daemon pod is launched.
Mar  1 08:29:20.199: INFO: Number of nodes with available pods: 0
Mar  1 08:29:20.199: INFO: Node shoot--it--pub-az-nl4q9-cpu-worker-7dd9bbfd9c-7fp9l is running more than one daemon pod
Mar  1 08:29:21.236: INFO: Number of nodes with available pods: 0
Mar  1 08:29:21.236: INFO: Node shoot--it--pub-az-nl4q9-cpu-worker-7dd9bbfd9c-7fp9l is running more than one daemon pod
Mar  1 08:29:22.236: INFO: Number of nodes with available pods: 0
Mar  1 08:29:22.236: INFO: Node shoot--it--pub-az-nl4q9-cpu-worker-7dd9bbfd9c-7fp9l is running more than one daemon pod
Mar  1 08:29:23.236: INFO: Number of nodes with available pods: 1
Mar  1 08:29:23.236: INFO: Number of running nodes: 1, number of available pods: 1
STEP: Update the node label to green, and wait for daemons to be unscheduled
Mar  1 08:29:23.387: INFO: Number of nodes with available pods: 0
Mar  1 08:29:23.387: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Update DaemonSet node selector to green, and change its update strategy to RollingUpdate
Mar  1 08:29:23.462: INFO: Number of nodes with available pods: 0
Mar  1 08:29:23.462: INFO: Node shoot--it--pub-az-nl4q9-cpu-worker-7dd9bbfd9c-7fp9l is running more than one daemon pod
Mar  1 08:29:24.498: INFO: Number of nodes with available pods: 0
Mar  1 08:29:24.498: INFO: Node shoot--it--pub-az-nl4q9-cpu-worker-7dd9bbfd9c-7fp9l is running more than one daemon pod
Mar  1 08:29:25.498: INFO: Number of nodes with available pods: 0
Mar  1 08:29:25.498: INFO: Node shoot--it--pub-az-nl4q9-cpu-worker-7dd9bbfd9c-7fp9l is running more than one daemon pod
Mar  1 08:29:26.498: INFO: Number of nodes with available pods: 0
Mar  1 08:29:26.499: INFO: Node shoot--it--pub-az-nl4q9-cpu-worker-7dd9bbfd9c-7fp9l is running more than one daemon pod
Mar  1 08:29:27.498: INFO: Number of nodes with available pods: 0
Mar  1 08:29:27.498: INFO: Node shoot--it--pub-az-nl4q9-cpu-worker-7dd9bbfd9c-7fp9l is running more than one daemon pod
Mar  1 08:29:28.498: INFO: Number of nodes with available pods: 0
Mar  1 08:29:28.498: INFO: Node shoot--it--pub-az-nl4q9-cpu-worker-7dd9bbfd9c-7fp9l is running more than one daemon pod
Mar  1 08:29:29.498: INFO: Number of nodes with available pods: 0
Mar  1 08:29:29.498: INFO: Node shoot--it--pub-az-nl4q9-cpu-worker-7dd9bbfd9c-7fp9l is running more than one daemon pod
Mar  1 08:29:30.499: INFO: Number of nodes with available pods: 0
Mar  1 08:29:30.499: INFO: Node shoot--it--pub-az-nl4q9-cpu-worker-7dd9bbfd9c-7fp9l is running more than one daemon pod
Mar  1 08:29:31.499: INFO: Number of nodes with available pods: 0
Mar  1 08:29:31.499: INFO: Node shoot--it--pub-az-nl4q9-cpu-worker-7dd9bbfd9c-7fp9l is running more than one daemon pod
Mar  1 08:29:32.498: INFO: Number of nodes with available pods: 0
Mar  1 08:29:32.498: INFO: Node shoot--it--pub-az-nl4q9-cpu-worker-7dd9bbfd9c-7fp9l is running more than one daemon pod
Mar  1 08:29:33.499: INFO: Number of nodes with available pods: 0
Mar  1 08:29:33.499: INFO: Node shoot--it--pub-az-nl4q9-cpu-worker-7dd9bbfd9c-7fp9l is running more than one daemon pod
Mar  1 08:29:34.499: INFO: Number of nodes with available pods: 0
Mar  1 08:29:34.499: INFO: Node shoot--it--pub-az-nl4q9-cpu-worker-7dd9bbfd9c-7fp9l is running more than one daemon pod
Mar  1 08:29:35.500: INFO: Number of nodes with available pods: 0
Mar  1 08:29:35.500: INFO: Node shoot--it--pub-az-nl4q9-cpu-worker-7dd9bbfd9c-7fp9l is running more than one daemon pod
Mar  1 08:29:36.499: INFO: Number of nodes with available pods: 0
Mar  1 08:29:36.499: INFO: Node shoot--it--pub-az-nl4q9-cpu-worker-7dd9bbfd9c-7fp9l is running more than one daemon pod
Mar  1 08:29:37.502: INFO: Number of nodes with available pods: 0
Mar  1 08:29:37.502: INFO: Node shoot--it--pub-az-nl4q9-cpu-worker-7dd9bbfd9c-7fp9l is running more than one daemon pod
Mar  1 08:29:38.498: INFO: Number of nodes with available pods: 0
Mar  1 08:29:38.498: INFO: Node shoot--it--pub-az-nl4q9-cpu-worker-7dd9bbfd9c-7fp9l is running more than one daemon pod
Mar  1 08:29:39.498: INFO: Number of nodes with available pods: 0
Mar  1 08:29:39.498: INFO: Node shoot--it--pub-az-nl4q9-cpu-worker-7dd9bbfd9c-7fp9l is running more than one daemon pod
Mar  1 08:29:40.498: INFO: Number of nodes with available pods: 0
Mar  1 08:29:40.498: INFO: Node shoot--it--pub-az-nl4q9-cpu-worker-7dd9bbfd9c-7fp9l is running more than one daemon pod
Mar  1 08:29:41.500: INFO: Number of nodes with available pods: 0
Mar  1 08:29:41.500: INFO: Node shoot--it--pub-az-nl4q9-cpu-worker-7dd9bbfd9c-7fp9l is running more than one daemon pod
Mar  1 08:29:42.499: INFO: Number of nodes with available pods: 0
Mar  1 08:29:42.499: INFO: Node shoot--it--pub-az-nl4q9-cpu-worker-7dd9bbfd9c-7fp9l is running more than one daemon pod
Mar  1 08:29:43.499: INFO: Number of nodes with available pods: 0
Mar  1 08:29:43.499: INFO: Node shoot--it--pub-az-nl4q9-cpu-worker-7dd9bbfd9c-7fp9l is running more than one daemon pod
Mar  1 08:29:44.498: INFO: Number of nodes with available pods: 0
Mar  1 08:29:44.498: INFO: Node shoot--it--pub-az-nl4q9-cpu-worker-7dd9bbfd9c-7fp9l is running more than one daemon pod
Mar  1 08:29:45.498: INFO: Number of nodes with available pods: 0
Mar  1 08:29:45.498: INFO: Node shoot--it--pub-az-nl4q9-cpu-worker-7dd9bbfd9c-7fp9l is running more than one daemon pod
Mar  1 08:29:46.498: INFO: Number of nodes with available pods: 0
Mar  1 08:29:46.498: INFO: Node shoot--it--pub-az-nl4q9-cpu-worker-7dd9bbfd9c-7fp9l is running more than one daemon pod
Mar  1 08:29:47.498: INFO: Number of nodes with available pods: 0
Mar  1 08:29:47.498: INFO: Node shoot--it--pub-az-nl4q9-cpu-worker-7dd9bbfd9c-7fp9l is running more than one daemon pod
Mar  1 08:29:48.498: INFO: Number of nodes with available pods: 0
Mar  1 08:29:48.498: INFO: Node shoot--it--pub-az-nl4q9-cpu-worker-7dd9bbfd9c-7fp9l is running more than one daemon pod
Mar  1 08:29:49.498: INFO: Number of nodes with available pods: 0
Mar  1 08:29:49.498: INFO: Node shoot--it--pub-az-nl4q9-cpu-worker-7dd9bbfd9c-7fp9l is running more than one daemon pod
Mar  1 08:29:50.498: INFO: Number of nodes with available pods: 0
Mar  1 08:29:50.498: INFO: Node shoot--it--pub-az-nl4q9-cpu-worker-7dd9bbfd9c-7fp9l is running more than one daemon pod
Mar  1 08:29:51.498: INFO: Number of nodes with available pods: 0
Mar  1 08:29:51.498: INFO: Node shoot--it--pub-az-nl4q9-cpu-worker-7dd9bbfd9c-7fp9l is running more than one daemon pod
Mar  1 08:29:52.498: INFO: Number of nodes with available pods: 0
Mar  1 08:29:52.499: INFO: Node shoot--it--pub-az-nl4q9-cpu-worker-7dd9bbfd9c-7fp9l is running more than one daemon pod
Mar  1 08:29:53.499: INFO: Number of nodes with available pods: 0
Mar  1 08:29:53.499: INFO: Node shoot--it--pub-az-nl4q9-cpu-worker-7dd9bbfd9c-7fp9l is running more than one daemon pod
Mar  1 08:29:54.499: INFO: Number of nodes with available pods: 0
Mar  1 08:29:54.499: INFO: Node shoot--it--pub-az-nl4q9-cpu-worker-7dd9bbfd9c-7fp9l is running more than one daemon pod
Mar  1 08:29:55.498: INFO: Number of nodes with available pods: 0
Mar  1 08:29:55.498: INFO: Node shoot--it--pub-az-nl4q9-cpu-worker-7dd9bbfd9c-7fp9l is running more than one daemon pod
Mar  1 08:29:56.498: INFO: Number of nodes with available pods: 0
Mar  1 08:29:56.498: INFO: Node shoot--it--pub-az-nl4q9-cpu-worker-7dd9bbfd9c-7fp9l is running more than one daemon pod
Mar  1 08:29:57.500: INFO: Number of nodes with available pods: 0
Mar  1 08:29:57.500: INFO: Node shoot--it--pub-az-nl4q9-cpu-worker-7dd9bbfd9c-7fp9l is running more than one daemon pod
Mar  1 08:29:58.499: INFO: Number of nodes with available pods: 0
Mar  1 08:29:58.499: INFO: Node shoot--it--pub-az-nl4q9-cpu-worker-7dd9bbfd9c-7fp9l is running more than one daemon pod
Mar  1 08:29:59.500: INFO: Number of nodes with available pods: 0
Mar  1 08:29:59.500: INFO: Node shoot--it--pub-az-nl4q9-cpu-worker-7dd9bbfd9c-7fp9l is running more than one daemon pod
Mar  1 08:30:00.498: INFO: Number of nodes with available pods: 0
Mar  1 08:30:00.498: INFO: Node shoot--it--pub-az-nl4q9-cpu-worker-7dd9bbfd9c-7fp9l is running more than one daemon pod
Mar  1 08:30:01.498: INFO: Number of nodes with available pods: 0
Mar  1 08:30:01.498: INFO: Node shoot--it--pub-az-nl4q9-cpu-worker-7dd9bbfd9c-7fp9l is running more than one daemon pod
Mar  1 08:30:02.498: INFO: Number of nodes with available pods: 0
Mar  1 08:30:02.498: INFO: Node shoot--it--pub-az-nl4q9-cpu-worker-7dd9bbfd9c-7fp9l is running more than one daemon pod
Mar  1 08:30:03.498: INFO: Number of nodes with available pods: 1
Mar  1 08:30:03.498: INFO: Number of running nodes: 1, number of available pods: 1
[AfterEach] [sig-apps] Daemon set [Serial]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting {extensions DaemonSet} daemon-set in namespace e2e-tests-daemonsets-d2str, will wait for the garbage collector to delete the pods
Mar  1 08:30:03.694: INFO: Deleting {extensions DaemonSet} daemon-set took: 38.326564ms
Mar  1 08:30:03.794: INFO: Terminating {extensions DaemonSet} daemon-set pods took: 100.268373ms
Mar  1 08:30:37.629: INFO: Number of nodes with available pods: 0
Mar  1 08:30:37.629: INFO: Number of running nodes: 0, number of available pods: 0
Mar  1 08:30:37.666: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-d2str/daemonsets","resourceVersion":"12120"},"items":null}

Mar  1 08:30:37.701: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-d2str/pods","resourceVersion":"12120"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 08:30:37.845: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-d2str" for this suite.
Mar  1 08:30:43.993: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 08:30:44.285: INFO: namespace: e2e-tests-daemonsets-d2str, resource: bindings, ignored listing per whitelist
Mar  1 08:30:45.397: INFO: namespace e2e-tests-daemonsets-d2str deletion completed in 7.51401407s

• [SLOW TEST:87.170 seconds]
[sig-apps] Daemon set [Serial]
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should run and stop complex daemon [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Docker Containers
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 08:30:45.397: INFO: >>> kubeConfig: /tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename containers
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-containers-8tlvx
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test override command
Mar  1 08:30:47.026: INFO: Waiting up to 5m0s for pod "client-containers-4fe75d3b-3bfc-11e9-a72e-ce8290b78775" in namespace "e2e-tests-containers-8tlvx" to be "success or failure"
Mar  1 08:30:47.061: INFO: Pod "client-containers-4fe75d3b-3bfc-11e9-a72e-ce8290b78775": Phase="Pending", Reason="", readiness=false. Elapsed: 35.147864ms
Mar  1 08:30:49.099: INFO: Pod "client-containers-4fe75d3b-3bfc-11e9-a72e-ce8290b78775": Phase="Pending", Reason="", readiness=false. Elapsed: 2.07298343s
Mar  1 08:30:51.136: INFO: Pod "client-containers-4fe75d3b-3bfc-11e9-a72e-ce8290b78775": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.109715297s
STEP: Saw pod success
Mar  1 08:30:51.136: INFO: Pod "client-containers-4fe75d3b-3bfc-11e9-a72e-ce8290b78775" satisfied condition "success or failure"
Mar  1 08:30:51.176: INFO: Trying to get logs from node shoot--it--pub-az-nl4q9-cpu-worker-7dd9bbfd9c-7fp9l pod client-containers-4fe75d3b-3bfc-11e9-a72e-ce8290b78775 container test-container: <nil>
STEP: delete the pod
Mar  1 08:30:51.260: INFO: Waiting for pod client-containers-4fe75d3b-3bfc-11e9-a72e-ce8290b78775 to disappear
Mar  1 08:30:51.303: INFO: Pod client-containers-4fe75d3b-3bfc-11e9-a72e-ce8290b78775 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 08:30:51.303: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-8tlvx" for this suite.
Mar  1 08:30:57.478: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 08:30:58.441: INFO: namespace: e2e-tests-containers-8tlvx, resource: bindings, ignored listing per whitelist
Mar  1 08:30:58.901: INFO: namespace e2e-tests-containers-8tlvx deletion completed in 7.562230583s

• [SLOW TEST:13.504 seconds]
[k8s.io] Docker Containers
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 08:30:58.901: INFO: >>> kubeConfig: /tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-8sw96
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-580256ce-3bfc-11e9-a72e-ce8290b78775
STEP: Creating a pod to test consume configMaps
Mar  1 08:31:00.662: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-5807cdca-3bfc-11e9-a72e-ce8290b78775" in namespace "e2e-tests-projected-8sw96" to be "success or failure"
Mar  1 08:31:00.700: INFO: Pod "pod-projected-configmaps-5807cdca-3bfc-11e9-a72e-ce8290b78775": Phase="Pending", Reason="", readiness=false. Elapsed: 38.49251ms
Mar  1 08:31:02.736: INFO: Pod "pod-projected-configmaps-5807cdca-3bfc-11e9-a72e-ce8290b78775": Phase="Pending", Reason="", readiness=false. Elapsed: 2.074240904s
Mar  1 08:31:04.773: INFO: Pod "pod-projected-configmaps-5807cdca-3bfc-11e9-a72e-ce8290b78775": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.110626335s
STEP: Saw pod success
Mar  1 08:31:04.773: INFO: Pod "pod-projected-configmaps-5807cdca-3bfc-11e9-a72e-ce8290b78775" satisfied condition "success or failure"
Mar  1 08:31:04.808: INFO: Trying to get logs from node shoot--it--pub-az-nl4q9-cpu-worker-7dd9bbfd9c-7fp9l pod pod-projected-configmaps-5807cdca-3bfc-11e9-a72e-ce8290b78775 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Mar  1 08:31:04.900: INFO: Waiting for pod pod-projected-configmaps-5807cdca-3bfc-11e9-a72e-ce8290b78775 to disappear
Mar  1 08:31:04.936: INFO: Pod pod-projected-configmaps-5807cdca-3bfc-11e9-a72e-ce8290b78775 no longer exists
[AfterEach] [sig-storage] Projected
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 08:31:04.936: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-8sw96" for this suite.
Mar  1 08:31:11.084: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 08:31:11.460: INFO: namespace: e2e-tests-projected-8sw96, resource: bindings, ignored listing per whitelist
Mar  1 08:31:12.550: INFO: namespace e2e-tests-projected-8sw96 deletion completed in 7.578613583s

• [SLOW TEST:13.649 seconds]
[sig-storage] Projected
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-apps] ReplicaSet 
  should serve a basic image on each replica with a public image  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] ReplicaSet
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 08:31:12.550: INFO: >>> kubeConfig: /tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename replicaset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-replicaset-7r6vd
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Mar  1 08:31:14.084: INFO: Creating ReplicaSet my-hostname-basic-600e2c09-3bfc-11e9-a72e-ce8290b78775
Mar  1 08:31:14.166: INFO: Pod name my-hostname-basic-600e2c09-3bfc-11e9-a72e-ce8290b78775: Found 1 pods out of 1
Mar  1 08:31:14.166: INFO: Ensuring a pod for ReplicaSet "my-hostname-basic-600e2c09-3bfc-11e9-a72e-ce8290b78775" is running
Mar  1 08:31:18.244: INFO: Pod "my-hostname-basic-600e2c09-3bfc-11e9-a72e-ce8290b78775-7p4lq" is running (conditions: [{Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-03-01 08:31:14 +0000 UTC Reason: Message:}])
Mar  1 08:31:18.245: INFO: Trying to dial the pod
Mar  1 08:31:23.438: INFO: Controller my-hostname-basic-600e2c09-3bfc-11e9-a72e-ce8290b78775: Got expected result from replica 1 [my-hostname-basic-600e2c09-3bfc-11e9-a72e-ce8290b78775-7p4lq]: "my-hostname-basic-600e2c09-3bfc-11e9-a72e-ce8290b78775-7p4lq", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicaSet
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 08:31:23.438: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-replicaset-7r6vd" for this suite.
Mar  1 08:31:29.587: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 08:31:30.013: INFO: namespace: e2e-tests-replicaset-7r6vd, resource: bindings, ignored listing per whitelist
Mar  1 08:31:30.982: INFO: namespace e2e-tests-replicaset-7r6vd deletion completed in 7.508145853s

• [SLOW TEST:18.432 seconds]
[sig-apps] ReplicaSet
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should serve a basic image on each replica with a public image  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should contain environment variables for services [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 08:31:30.983: INFO: >>> kubeConfig: /tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-pods-7rjcn
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should contain environment variables for services [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Mar  1 08:31:36.937: INFO: Waiting up to 5m0s for pod "client-envvars-6da6837e-3bfc-11e9-a72e-ce8290b78775" in namespace "e2e-tests-pods-7rjcn" to be "success or failure"
Mar  1 08:31:36.973: INFO: Pod "client-envvars-6da6837e-3bfc-11e9-a72e-ce8290b78775": Phase="Pending", Reason="", readiness=false. Elapsed: 35.634691ms
Mar  1 08:31:39.009: INFO: Pod "client-envvars-6da6837e-3bfc-11e9-a72e-ce8290b78775": Phase="Pending", Reason="", readiness=false. Elapsed: 2.071893321s
Mar  1 08:31:41.048: INFO: Pod "client-envvars-6da6837e-3bfc-11e9-a72e-ce8290b78775": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.110573705s
STEP: Saw pod success
Mar  1 08:31:41.048: INFO: Pod "client-envvars-6da6837e-3bfc-11e9-a72e-ce8290b78775" satisfied condition "success or failure"
Mar  1 08:31:41.085: INFO: Trying to get logs from node shoot--it--pub-az-nl4q9-cpu-worker-7dd9bbfd9c-7fp9l pod client-envvars-6da6837e-3bfc-11e9-a72e-ce8290b78775 container env3cont: <nil>
STEP: delete the pod
Mar  1 08:31:41.188: INFO: Waiting for pod client-envvars-6da6837e-3bfc-11e9-a72e-ce8290b78775 to disappear
Mar  1 08:31:41.223: INFO: Pod client-envvars-6da6837e-3bfc-11e9-a72e-ce8290b78775 no longer exists
[AfterEach] [k8s.io] Pods
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 08:31:41.223: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-7rjcn" for this suite.
Mar  1 08:32:23.369: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 08:32:23.864: INFO: namespace: e2e-tests-pods-7rjcn, resource: bindings, ignored listing per whitelist
Mar  1 08:32:24.733: INFO: namespace e2e-tests-pods-7rjcn deletion completed in 43.473977926s

• [SLOW TEST:53.750 seconds]
[k8s.io] Pods
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should contain environment variables for services [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[k8s.io] Pods 
  should get a host IP [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 08:32:24.733: INFO: >>> kubeConfig: /tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-pods-xf74d
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should get a host IP [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating pod
Mar  1 08:32:30.467: INFO: Pod pod-hostip-8b166039-3bfc-11e9-a72e-ce8290b78775 has hostIP: 10.250.0.4
[AfterEach] [k8s.io] Pods
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 08:32:30.467: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-xf74d" for this suite.
Mar  1 08:32:54.611: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 08:32:55.076: INFO: namespace: e2e-tests-pods-xf74d, resource: bindings, ignored listing per whitelist
Mar  1 08:32:56.004: INFO: namespace e2e-tests-pods-xf74d deletion completed in 25.501228286s

• [SLOW TEST:31.271 seconds]
[k8s.io] Pods
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should get a host IP [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,tmpfs) [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 08:32:56.004: INFO: >>> kubeConfig: /tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-vr64d
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,tmpfs) [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0777 on tmpfs
Mar  1 08:32:57.660: INFO: Waiting up to 5m0s for pod "pod-9dc4b653-3bfc-11e9-a72e-ce8290b78775" in namespace "e2e-tests-emptydir-vr64d" to be "success or failure"
Mar  1 08:32:57.703: INFO: Pod "pod-9dc4b653-3bfc-11e9-a72e-ce8290b78775": Phase="Pending", Reason="", readiness=false. Elapsed: 42.128954ms
Mar  1 08:32:59.739: INFO: Pod "pod-9dc4b653-3bfc-11e9-a72e-ce8290b78775": Phase="Pending", Reason="", readiness=false. Elapsed: 2.078763665s
Mar  1 08:33:01.778: INFO: Pod "pod-9dc4b653-3bfc-11e9-a72e-ce8290b78775": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.117132095s
STEP: Saw pod success
Mar  1 08:33:01.778: INFO: Pod "pod-9dc4b653-3bfc-11e9-a72e-ce8290b78775" satisfied condition "success or failure"
Mar  1 08:33:01.813: INFO: Trying to get logs from node shoot--it--pub-az-nl4q9-cpu-worker-7dd9bbfd9c-7fp9l pod pod-9dc4b653-3bfc-11e9-a72e-ce8290b78775 container test-container: <nil>
STEP: delete the pod
Mar  1 08:33:01.903: INFO: Waiting for pod pod-9dc4b653-3bfc-11e9-a72e-ce8290b78775 to disappear
Mar  1 08:33:01.938: INFO: Pod pod-9dc4b653-3bfc-11e9-a72e-ce8290b78775 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 08:33:01.938: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-vr64d" for this suite.
Mar  1 08:33:08.082: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 08:33:08.652: INFO: namespace: e2e-tests-emptydir-vr64d, resource: bindings, ignored listing per whitelist
Mar  1 08:33:09.493: INFO: namespace e2e-tests-emptydir-vr64d deletion completed in 7.518354215s

• [SLOW TEST:13.488 seconds]
[sig-storage] EmptyDir volumes
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0777,tmpfs) [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run --rm job 
  should create a job from an image, then delete the job  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 08:33:09.493: INFO: >>> kubeConfig: /tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-sr4pz
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should create a job from an image, then delete the job  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: executing a command with run --rm and attach with stdin
Mar  1 08:33:11.117: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-az-nl4q9.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml --namespace=e2e-tests-kubectl-sr4pz run e2e-test-rm-busybox-job --image=docker.io/library/busybox:1.29 --rm=true --generator=job/v1 --restart=OnFailure --attach=true --stdin -- sh -c cat && echo 'stdin closed''
Mar  1 08:33:17.281: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl create instead.\nIf you don't see a command prompt, try pressing enter.\n"
Mar  1 08:33:17.281: INFO: stdout: "abcd1234stdin closed\njob.batch \"e2e-test-rm-busybox-job\" deleted\n"
STEP: verifying the job e2e-test-rm-busybox-job was deleted
[AfterEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 08:33:19.353: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-sr4pz" for this suite.
Mar  1 08:33:25.497: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 08:33:25.742: INFO: namespace: e2e-tests-kubectl-sr4pz, resource: bindings, ignored listing per whitelist
Mar  1 08:33:26.907: INFO: namespace e2e-tests-kubectl-sr4pz deletion completed in 7.518509573s

• [SLOW TEST:17.414 seconds]
[sig-cli] Kubectl client
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run --rm job
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create a job from an image, then delete the job  [Conformance]
    /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] Projected 
  should update labels on modification [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 08:33:26.908: INFO: >>> kubeConfig: /tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-gjmgb
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should update labels on modification [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating the pod
Mar  1 08:33:33.262: INFO: Successfully updated pod "labelsupdateb02b24dc-3bfc-11e9-a72e-ce8290b78775"
[AfterEach] [sig-storage] Projected
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 08:33:35.349: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-gjmgb" for this suite.
Mar  1 08:33:57.494: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 08:33:57.894: INFO: namespace: e2e-tests-projected-gjmgb, resource: bindings, ignored listing per whitelist
Mar  1 08:33:58.886: INFO: namespace e2e-tests-projected-gjmgb deletion completed in 23.501117208s

• [SLOW TEST:31.979 seconds]
[sig-storage] Projected
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should update labels on modification [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,tmpfs) [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 08:33:58.886: INFO: >>> kubeConfig: /tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-nbwzs
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,tmpfs) [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0644 on tmpfs
Mar  1 08:34:00.606: INFO: Waiting up to 5m0s for pod "pod-c3497ab1-3bfc-11e9-a72e-ce8290b78775" in namespace "e2e-tests-emptydir-nbwzs" to be "success or failure"
Mar  1 08:34:00.641: INFO: Pod "pod-c3497ab1-3bfc-11e9-a72e-ce8290b78775": Phase="Pending", Reason="", readiness=false. Elapsed: 34.866452ms
Mar  1 08:34:02.678: INFO: Pod "pod-c3497ab1-3bfc-11e9-a72e-ce8290b78775": Phase="Pending", Reason="", readiness=false. Elapsed: 2.071369875s
Mar  1 08:34:04.714: INFO: Pod "pod-c3497ab1-3bfc-11e9-a72e-ce8290b78775": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.107616527s
STEP: Saw pod success
Mar  1 08:34:04.714: INFO: Pod "pod-c3497ab1-3bfc-11e9-a72e-ce8290b78775" satisfied condition "success or failure"
Mar  1 08:34:04.750: INFO: Trying to get logs from node shoot--it--pub-az-nl4q9-cpu-worker-7dd9bbfd9c-7fp9l pod pod-c3497ab1-3bfc-11e9-a72e-ce8290b78775 container test-container: <nil>
STEP: delete the pod
Mar  1 08:34:04.834: INFO: Waiting for pod pod-c3497ab1-3bfc-11e9-a72e-ce8290b78775 to disappear
Mar  1 08:34:04.870: INFO: Pod pod-c3497ab1-3bfc-11e9-a72e-ce8290b78775 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 08:34:04.870: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-nbwzs" for this suite.
Mar  1 08:34:11.017: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 08:34:11.122: INFO: namespace: e2e-tests-emptydir-nbwzs, resource: bindings, ignored listing per whitelist
Mar  1 08:34:12.432: INFO: namespace e2e-tests-emptydir-nbwzs deletion completed in 7.525735008s

• [SLOW TEST:13.545 seconds]
[sig-storage] EmptyDir volumes
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0644,tmpfs) [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl rolling-update 
  should support rolling-update to same image  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 08:34:12.432: INFO: >>> kubeConfig: /tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-nh6vp
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Kubectl rolling-update
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1306
[It] should support rolling-update to same image  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Mar  1 08:34:14.075: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-az-nl4q9.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml run e2e-test-nginx-rc --image=docker.io/library/nginx:1.14-alpine --generator=run/v1 --namespace=e2e-tests-kubectl-nh6vp'
Mar  1 08:34:14.513: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl create instead.\n"
Mar  1 08:34:14.513: INFO: stdout: "replicationcontroller/e2e-test-nginx-rc created\n"
STEP: verifying the rc e2e-test-nginx-rc was created
STEP: rolling-update to same image controller
Mar  1 08:34:14.606: INFO: scanned /root for discovery docs: <nil>
Mar  1 08:34:14.606: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-az-nl4q9.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml rolling-update e2e-test-nginx-rc --update-period=1s --image=docker.io/library/nginx:1.14-alpine --image-pull-policy=IfNotPresent --namespace=e2e-tests-kubectl-nh6vp'
Mar  1 08:34:28.172: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Mar  1 08:34:28.172: INFO: stdout: "Created e2e-test-nginx-rc-31497c1ae1157cdecf68379109d1f89b\nScaling up e2e-test-nginx-rc-31497c1ae1157cdecf68379109d1f89b from 0 to 1, scaling down e2e-test-nginx-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-nginx-rc-31497c1ae1157cdecf68379109d1f89b up to 1\nScaling e2e-test-nginx-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-nginx-rc\nRenaming e2e-test-nginx-rc-31497c1ae1157cdecf68379109d1f89b to e2e-test-nginx-rc\nreplicationcontroller/e2e-test-nginx-rc rolling updated\n"
Mar  1 08:34:28.172: INFO: stdout: "Created e2e-test-nginx-rc-31497c1ae1157cdecf68379109d1f89b\nScaling up e2e-test-nginx-rc-31497c1ae1157cdecf68379109d1f89b from 0 to 1, scaling down e2e-test-nginx-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-nginx-rc-31497c1ae1157cdecf68379109d1f89b up to 1\nScaling e2e-test-nginx-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-nginx-rc\nRenaming e2e-test-nginx-rc-31497c1ae1157cdecf68379109d1f89b to e2e-test-nginx-rc\nreplicationcontroller/e2e-test-nginx-rc rolling updated\n"
STEP: waiting for all containers in run=e2e-test-nginx-rc pods to come up.
Mar  1 08:34:28.172: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-az-nl4q9.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l run=e2e-test-nginx-rc --namespace=e2e-tests-kubectl-nh6vp'
Mar  1 08:34:28.402: INFO: stderr: ""
Mar  1 08:34:28.402: INFO: stdout: "e2e-test-nginx-rc-31497c1ae1157cdecf68379109d1f89b-9pjnb e2e-test-nginx-rc-gx4zt "
STEP: Replicas for run=e2e-test-nginx-rc: expected=1 actual=2
Mar  1 08:34:33.403: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-az-nl4q9.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l run=e2e-test-nginx-rc --namespace=e2e-tests-kubectl-nh6vp'
Mar  1 08:34:33.637: INFO: stderr: ""
Mar  1 08:34:33.637: INFO: stdout: "e2e-test-nginx-rc-31497c1ae1157cdecf68379109d1f89b-9pjnb "
Mar  1 08:34:33.637: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-az-nl4q9.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml get pods e2e-test-nginx-rc-31497c1ae1157cdecf68379109d1f89b-9pjnb -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "e2e-test-nginx-rc") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-nh6vp'
Mar  1 08:34:33.863: INFO: stderr: ""
Mar  1 08:34:33.863: INFO: stdout: "true"
Mar  1 08:34:33.863: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-az-nl4q9.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml get pods e2e-test-nginx-rc-31497c1ae1157cdecf68379109d1f89b-9pjnb -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "e2e-test-nginx-rc"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-nh6vp'
Mar  1 08:34:34.089: INFO: stderr: ""
Mar  1 08:34:34.089: INFO: stdout: "nginx:1.14-alpine"
Mar  1 08:34:34.089: INFO: e2e-test-nginx-rc-31497c1ae1157cdecf68379109d1f89b-9pjnb is verified up and running
[AfterEach] [k8s.io] Kubectl rolling-update
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1312
Mar  1 08:34:34.089: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-az-nl4q9.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml delete rc e2e-test-nginx-rc --namespace=e2e-tests-kubectl-nh6vp'
Mar  1 08:34:34.359: INFO: stderr: ""
Mar  1 08:34:34.359: INFO: stdout: "replicationcontroller \"e2e-test-nginx-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 08:34:34.359: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-nh6vp" for this suite.
Mar  1 08:34:58.524: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 08:34:59.408: INFO: namespace: e2e-tests-kubectl-nh6vp, resource: bindings, ignored listing per whitelist
Mar  1 08:34:59.874: INFO: namespace e2e-tests-kubectl-nh6vp deletion completed in 25.478799115s

• [SLOW TEST:47.442 seconds]
[sig-cli] Kubectl client
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl rolling-update
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should support rolling-update to same image  [Conformance]
    /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if matching  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 08:34:59.874: INFO: >>> kubeConfig: /tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename sched-pred
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-sched-pred-5q9s2
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:78
Mar  1 08:35:01.497: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Mar  1 08:35:01.572: INFO: Waiting for terminating namespaces to be deleted...
Mar  1 08:35:01.608: INFO: 
Logging pods the kubelet thinks is on node shoot--it--pub-az-nl4q9-cpu-worker-7dd9bbfd9c-7fp9l before test
Mar  1 08:35:01.648: INFO: node-exporter-h6r77 from kube-system started at 2019-03-01 07:21:56 +0000 UTC (1 container statuses recorded)
Mar  1 08:35:01.648: INFO: 	Container node-exporter ready: true, restart count 0
Mar  1 08:35:01.648: INFO: kube-proxy-cq7cz from kube-system started at 2019-03-01 07:21:56 +0000 UTC (1 container statuses recorded)
Mar  1 08:35:01.648: INFO: 	Container kube-proxy ready: true, restart count 0
Mar  1 08:35:01.648: INFO: calico-node-mdbnz from kube-system started at 2019-03-01 07:21:56 +0000 UTC (1 container statuses recorded)
Mar  1 08:35:01.648: INFO: 	Container calico-node ready: true, restart count 0
Mar  1 08:35:01.648: INFO: 
Logging pods the kubelet thinks is on node shoot--it--pub-az-nl4q9-cpu-worker-7dd9bbfd9c-gwjjt before test
Mar  1 08:35:01.693: INFO: addons-kubernetes-dashboard-5f64f76bd-ksndd from kube-system started at 2019-03-01 07:21:41 +0000 UTC (1 container statuses recorded)
Mar  1 08:35:01.693: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
Mar  1 08:35:01.693: INFO: node-exporter-jrqgj from kube-system started at 2019-03-01 07:21:41 +0000 UTC (1 container statuses recorded)
Mar  1 08:35:01.693: INFO: 	Container node-exporter ready: true, restart count 0
Mar  1 08:35:01.693: INFO: vpn-shoot-84b4694876-cv69m from kube-system started at 2019-03-01 07:21:41 +0000 UTC (1 container statuses recorded)
Mar  1 08:35:01.693: INFO: 	Container vpn-shoot ready: true, restart count 0
Mar  1 08:35:01.693: INFO: blackbox-exporter-58fd9b8556-jpgx4 from kube-system started at 2019-03-01 07:21:41 +0000 UTC (1 container statuses recorded)
Mar  1 08:35:01.693: INFO: 	Container blackbox-exporter ready: true, restart count 0
Mar  1 08:35:01.693: INFO: kube-proxy-dj7cg from kube-system started at 2019-03-01 07:21:41 +0000 UTC (1 container statuses recorded)
Mar  1 08:35:01.693: INFO: 	Container kube-proxy ready: true, restart count 0
Mar  1 08:35:01.693: INFO: calico-node-tkxc4 from kube-system started at 2019-03-01 07:21:41 +0000 UTC (1 container statuses recorded)
Mar  1 08:35:01.693: INFO: 	Container calico-node ready: true, restart count 0
Mar  1 08:35:01.693: INFO: addons-nginx-ingress-controller-8f975c795-r87j9 from kube-system started at 2019-03-01 07:21:41 +0000 UTC (1 container statuses recorded)
Mar  1 08:35:01.693: INFO: 	Container nginx-ingress-controller ready: true, restart count 0
Mar  1 08:35:01.693: INFO: metrics-server-966574b4f-vwjz9 from kube-system started at 2019-03-01 07:21:41 +0000 UTC (1 container statuses recorded)
Mar  1 08:35:01.693: INFO: 	Container metrics-server ready: true, restart count 0
Mar  1 08:35:01.693: INFO: addons-kube-lego-648f8c9f5c-ll4nb from kube-system started at 2019-03-01 07:21:41 +0000 UTC (1 container statuses recorded)
Mar  1 08:35:01.693: INFO: 	Container kube-lego ready: true, restart count 0
Mar  1 08:35:01.693: INFO: coredns-5f4748c5f-rdst8 from kube-system started at 2019-03-01 07:21:41 +0000 UTC (1 container statuses recorded)
Mar  1 08:35:01.693: INFO: 	Container coredns ready: true, restart count 0
Mar  1 08:35:01.693: INFO: addons-nginx-ingress-nginx-ingress-k8s-backend-6498456576-4xrkj from kube-system started at 2019-03-01 07:21:41 +0000 UTC (1 container statuses recorded)
Mar  1 08:35:01.693: INFO: 	Container nginx-ingress-nginx-ingress-k8s-backend ready: true, restart count 0
[It] validates that NodeSelector is respected if matching  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Trying to launch a pod without a label to get a node which can launch it.
STEP: Explicitly delete pod here to free the resource it takes.
STEP: Trying to apply a random label on the found node.
STEP: verifying the node has the label kubernetes.io/e2e-ea38fcbc-3bfc-11e9-a72e-ce8290b78775 42
STEP: Trying to relaunch the pod, now with labels.
STEP: removing the label kubernetes.io/e2e-ea38fcbc-3bfc-11e9-a72e-ce8290b78775 off the node shoot--it--pub-az-nl4q9-cpu-worker-7dd9bbfd9c-7fp9l
STEP: verifying the node doesn't have the label kubernetes.io/e2e-ea38fcbc-3bfc-11e9-a72e-ce8290b78775
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 08:35:10.226: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-sched-pred-5q9s2" for this suite.
Mar  1 08:35:18.370: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 08:35:19.512: INFO: namespace: e2e-tests-sched-pred-5q9s2, resource: bindings, ignored listing per whitelist
Mar  1 08:35:19.728: INFO: namespace e2e-tests-sched-pred-5q9s2 deletion completed in 9.465571415s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:69

• [SLOW TEST:19.855 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates that NodeSelector is respected if matching  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should scale a replication controller  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 08:35:19.729: INFO: >>> kubeConfig: /tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-v9crg
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Update Demo
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:293
[It] should scale a replication controller  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a replication controller
Mar  1 08:35:21.387: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-az-nl4q9.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml create -f - --namespace=e2e-tests-kubectl-v9crg'
Mar  1 08:35:22.095: INFO: stderr: ""
Mar  1 08:35:22.095: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Mar  1 08:35:22.095: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-az-nl4q9.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-v9crg'
Mar  1 08:35:22.361: INFO: stderr: ""
Mar  1 08:35:22.361: INFO: stdout: "update-demo-nautilus-5zqwl update-demo-nautilus-jqtdh "
Mar  1 08:35:22.361: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-az-nl4q9.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml get pods update-demo-nautilus-5zqwl -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-v9crg'
Mar  1 08:35:22.601: INFO: stderr: ""
Mar  1 08:35:22.601: INFO: stdout: ""
Mar  1 08:35:22.601: INFO: update-demo-nautilus-5zqwl is created but not running
Mar  1 08:35:27.602: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-az-nl4q9.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-v9crg'
Mar  1 08:35:27.859: INFO: stderr: ""
Mar  1 08:35:27.859: INFO: stdout: "update-demo-nautilus-5zqwl update-demo-nautilus-jqtdh "
Mar  1 08:35:27.859: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-az-nl4q9.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml get pods update-demo-nautilus-5zqwl -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-v9crg'
Mar  1 08:35:28.086: INFO: stderr: ""
Mar  1 08:35:28.086: INFO: stdout: "true"
Mar  1 08:35:28.086: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-az-nl4q9.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml get pods update-demo-nautilus-5zqwl -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-v9crg'
Mar  1 08:35:28.319: INFO: stderr: ""
Mar  1 08:35:28.319: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Mar  1 08:35:28.319: INFO: validating pod update-demo-nautilus-5zqwl
Mar  1 08:35:28.439: INFO: got data: {
  "image": "nautilus.jpg"
}

Mar  1 08:35:28.440: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Mar  1 08:35:28.440: INFO: update-demo-nautilus-5zqwl is verified up and running
Mar  1 08:35:28.440: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-az-nl4q9.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml get pods update-demo-nautilus-jqtdh -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-v9crg'
Mar  1 08:35:28.671: INFO: stderr: ""
Mar  1 08:35:28.671: INFO: stdout: "true"
Mar  1 08:35:28.671: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-az-nl4q9.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml get pods update-demo-nautilus-jqtdh -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-v9crg'
Mar  1 08:35:28.926: INFO: stderr: ""
Mar  1 08:35:28.926: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Mar  1 08:35:28.926: INFO: validating pod update-demo-nautilus-jqtdh
Mar  1 08:35:29.047: INFO: got data: {
  "image": "nautilus.jpg"
}

Mar  1 08:35:29.047: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Mar  1 08:35:29.047: INFO: update-demo-nautilus-jqtdh is verified up and running
STEP: scaling down the replication controller
Mar  1 08:35:29.051: INFO: scanned /root for discovery docs: <nil>
Mar  1 08:35:29.051: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-az-nl4q9.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml scale rc update-demo-nautilus --replicas=1 --timeout=5m --namespace=e2e-tests-kubectl-v9crg'
Mar  1 08:35:29.449: INFO: stderr: ""
Mar  1 08:35:29.449: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Mar  1 08:35:29.449: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-az-nl4q9.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-v9crg'
Mar  1 08:35:29.689: INFO: stderr: ""
Mar  1 08:35:29.689: INFO: stdout: "update-demo-nautilus-5zqwl update-demo-nautilus-jqtdh "
STEP: Replicas for name=update-demo: expected=1 actual=2
Mar  1 08:35:34.690: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-az-nl4q9.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-v9crg'
Mar  1 08:35:34.922: INFO: stderr: ""
Mar  1 08:35:34.922: INFO: stdout: "update-demo-nautilus-5zqwl "
Mar  1 08:35:34.922: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-az-nl4q9.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml get pods update-demo-nautilus-5zqwl -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-v9crg'
Mar  1 08:35:35.145: INFO: stderr: ""
Mar  1 08:35:35.145: INFO: stdout: "true"
Mar  1 08:35:35.145: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-az-nl4q9.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml get pods update-demo-nautilus-5zqwl -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-v9crg'
Mar  1 08:35:35.368: INFO: stderr: ""
Mar  1 08:35:35.368: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Mar  1 08:35:35.368: INFO: validating pod update-demo-nautilus-5zqwl
Mar  1 08:35:35.406: INFO: got data: {
  "image": "nautilus.jpg"
}

Mar  1 08:35:35.406: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Mar  1 08:35:35.406: INFO: update-demo-nautilus-5zqwl is verified up and running
STEP: scaling up the replication controller
Mar  1 08:35:35.411: INFO: scanned /root for discovery docs: <nil>
Mar  1 08:35:35.411: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-az-nl4q9.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml scale rc update-demo-nautilus --replicas=2 --timeout=5m --namespace=e2e-tests-kubectl-v9crg'
Mar  1 08:35:35.827: INFO: stderr: ""
Mar  1 08:35:35.827: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Mar  1 08:35:35.827: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-az-nl4q9.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-v9crg'
Mar  1 08:35:36.060: INFO: stderr: ""
Mar  1 08:35:36.060: INFO: stdout: "update-demo-nautilus-5zqwl update-demo-nautilus-8kjh7 "
Mar  1 08:35:36.060: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-az-nl4q9.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml get pods update-demo-nautilus-5zqwl -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-v9crg'
Mar  1 08:35:36.282: INFO: stderr: ""
Mar  1 08:35:36.282: INFO: stdout: "true"
Mar  1 08:35:36.282: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-az-nl4q9.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml get pods update-demo-nautilus-5zqwl -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-v9crg'
Mar  1 08:35:36.513: INFO: stderr: ""
Mar  1 08:35:36.513: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Mar  1 08:35:36.513: INFO: validating pod update-demo-nautilus-5zqwl
Mar  1 08:35:36.551: INFO: got data: {
  "image": "nautilus.jpg"
}

Mar  1 08:35:36.551: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Mar  1 08:35:36.551: INFO: update-demo-nautilus-5zqwl is verified up and running
Mar  1 08:35:36.551: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-az-nl4q9.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml get pods update-demo-nautilus-8kjh7 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-v9crg'
Mar  1 08:35:36.779: INFO: stderr: ""
Mar  1 08:35:36.779: INFO: stdout: ""
Mar  1 08:35:36.779: INFO: update-demo-nautilus-8kjh7 is created but not running
Mar  1 08:35:41.779: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-az-nl4q9.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-v9crg'
Mar  1 08:35:42.017: INFO: stderr: ""
Mar  1 08:35:42.017: INFO: stdout: "update-demo-nautilus-5zqwl update-demo-nautilus-8kjh7 "
Mar  1 08:35:42.017: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-az-nl4q9.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml get pods update-demo-nautilus-5zqwl -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-v9crg'
Mar  1 08:35:42.263: INFO: stderr: ""
Mar  1 08:35:42.263: INFO: stdout: "true"
Mar  1 08:35:42.263: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-az-nl4q9.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml get pods update-demo-nautilus-5zqwl -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-v9crg'
Mar  1 08:35:42.512: INFO: stderr: ""
Mar  1 08:35:42.512: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Mar  1 08:35:42.512: INFO: validating pod update-demo-nautilus-5zqwl
Mar  1 08:35:42.553: INFO: got data: {
  "image": "nautilus.jpg"
}

Mar  1 08:35:42.553: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Mar  1 08:35:42.553: INFO: update-demo-nautilus-5zqwl is verified up and running
Mar  1 08:35:42.553: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-az-nl4q9.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml get pods update-demo-nautilus-8kjh7 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-v9crg'
Mar  1 08:35:42.811: INFO: stderr: ""
Mar  1 08:35:42.812: INFO: stdout: "true"
Mar  1 08:35:42.812: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-az-nl4q9.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml get pods update-demo-nautilus-8kjh7 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-v9crg'
Mar  1 08:35:43.064: INFO: stderr: ""
Mar  1 08:35:43.064: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Mar  1 08:35:43.064: INFO: validating pod update-demo-nautilus-8kjh7
Mar  1 08:35:43.189: INFO: got data: {
  "image": "nautilus.jpg"
}

Mar  1 08:35:43.189: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Mar  1 08:35:43.189: INFO: update-demo-nautilus-8kjh7 is verified up and running
STEP: using delete to clean up resources
Mar  1 08:35:43.189: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-az-nl4q9.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-v9crg'
Mar  1 08:35:43.467: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Mar  1 08:35:43.467: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Mar  1 08:35:43.468: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-az-nl4q9.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml get rc,svc -l name=update-demo --no-headers --namespace=e2e-tests-kubectl-v9crg'
Mar  1 08:35:43.755: INFO: stderr: "No resources found.\n"
Mar  1 08:35:43.755: INFO: stdout: ""
Mar  1 08:35:43.755: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-az-nl4q9.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml get pods -l name=update-demo --namespace=e2e-tests-kubectl-v9crg -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Mar  1 08:35:43.989: INFO: stderr: ""
Mar  1 08:35:43.989: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 08:35:43.989: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-v9crg" for this suite.
Mar  1 08:36:08.133: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 08:36:08.454: INFO: namespace: e2e-tests-kubectl-v9crg, resource: bindings, ignored listing per whitelist
Mar  1 08:36:09.503: INFO: namespace e2e-tests-kubectl-v9crg deletion completed in 25.477613556s

• [SLOW TEST:49.774 seconds]
[sig-cli] Kubectl client
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Update Demo
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should scale a replication controller  [Conformance]
    /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: http [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Networking
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 08:36:09.503: INFO: >>> kubeConfig: /tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename pod-network-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-pod-network-test-p7gxs
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: http [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-p7gxs
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Mar  1 08:36:11.108: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Mar  1 08:36:37.815: INFO: ExecWithOptions {Command:[/bin/sh -c timeout -t 15 curl -g -q -s --connect-timeout 1 http://100.96.0.28:8080/hostName | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-p7gxs PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar  1 08:36:37.815: INFO: >>> kubeConfig: /tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
Mar  1 08:36:38.649: INFO: Found all expected endpoints: [netserver-0]
Mar  1 08:36:38.686: INFO: ExecWithOptions {Command:[/bin/sh -c timeout -t 15 curl -g -q -s --connect-timeout 1 http://100.96.1.107:8080/hostName | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-p7gxs PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar  1 08:36:38.686: INFO: >>> kubeConfig: /tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
Mar  1 08:36:39.255: INFO: Found all expected endpoints: [netserver-1]
[AfterEach] [sig-network] Networking
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 08:36:39.255: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-p7gxs" for this suite.
Mar  1 08:37:03.418: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 08:37:04.031: INFO: namespace: e2e-tests-pod-network-test-p7gxs, resource: bindings, ignored listing per whitelist
Mar  1 08:37:04.773: INFO: namespace e2e-tests-pod-network-test-p7gxs deletion completed in 25.481377041s

• [SLOW TEST:55.270 seconds]
[sig-network] Networking
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: http [NodeConformance] [Conformance]
    /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should do a rolling update of a replication controller  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 08:37:04.773: INFO: >>> kubeConfig: /tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-mlj8p
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Update Demo
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:293
[It] should do a rolling update of a replication controller  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the initial replication controller
Mar  1 08:37:06.420: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-az-nl4q9.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml create -f - --namespace=e2e-tests-kubectl-mlj8p'
Mar  1 08:37:06.912: INFO: stderr: ""
Mar  1 08:37:06.912: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Mar  1 08:37:06.912: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-az-nl4q9.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-mlj8p'
Mar  1 08:37:07.168: INFO: stderr: ""
Mar  1 08:37:07.168: INFO: stdout: "update-demo-nautilus-tzjk2 update-demo-nautilus-z4cz6 "
Mar  1 08:37:07.168: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-az-nl4q9.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml get pods update-demo-nautilus-tzjk2 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-mlj8p'
Mar  1 08:37:07.417: INFO: stderr: ""
Mar  1 08:37:07.417: INFO: stdout: ""
Mar  1 08:37:07.417: INFO: update-demo-nautilus-tzjk2 is created but not running
Mar  1 08:37:12.417: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-az-nl4q9.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-mlj8p'
Mar  1 08:37:12.702: INFO: stderr: ""
Mar  1 08:37:12.702: INFO: stdout: "update-demo-nautilus-tzjk2 update-demo-nautilus-z4cz6 "
Mar  1 08:37:12.702: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-az-nl4q9.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml get pods update-demo-nautilus-tzjk2 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-mlj8p'
Mar  1 08:37:12.951: INFO: stderr: ""
Mar  1 08:37:12.951: INFO: stdout: "true"
Mar  1 08:37:12.951: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-az-nl4q9.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml get pods update-demo-nautilus-tzjk2 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-mlj8p'
Mar  1 08:37:13.190: INFO: stderr: ""
Mar  1 08:37:13.190: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Mar  1 08:37:13.190: INFO: validating pod update-demo-nautilus-tzjk2
Mar  1 08:37:13.311: INFO: got data: {
  "image": "nautilus.jpg"
}

Mar  1 08:37:13.311: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Mar  1 08:37:13.311: INFO: update-demo-nautilus-tzjk2 is verified up and running
Mar  1 08:37:13.311: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-az-nl4q9.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml get pods update-demo-nautilus-z4cz6 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-mlj8p'
Mar  1 08:37:13.566: INFO: stderr: ""
Mar  1 08:37:13.566: INFO: stdout: "true"
Mar  1 08:37:13.566: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-az-nl4q9.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml get pods update-demo-nautilus-z4cz6 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-mlj8p'
Mar  1 08:37:13.819: INFO: stderr: ""
Mar  1 08:37:13.819: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Mar  1 08:37:13.819: INFO: validating pod update-demo-nautilus-z4cz6
Mar  1 08:37:13.940: INFO: got data: {
  "image": "nautilus.jpg"
}

Mar  1 08:37:13.940: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Mar  1 08:37:13.940: INFO: update-demo-nautilus-z4cz6 is verified up and running
STEP: rolling-update to new replication controller
Mar  1 08:37:13.944: INFO: scanned /root for discovery docs: <nil>
Mar  1 08:37:13.944: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-az-nl4q9.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml rolling-update update-demo-nautilus --update-period=1s -f - --namespace=e2e-tests-kubectl-mlj8p'
Mar  1 08:37:36.083: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Mar  1 08:37:36.083: INFO: stdout: "Created update-demo-kitten\nScaling up update-demo-kitten from 0 to 2, scaling down update-demo-nautilus from 2 to 0 (keep 2 pods available, don't exceed 3 pods)\nScaling update-demo-kitten up to 1\nScaling update-demo-nautilus down to 1\nScaling update-demo-kitten up to 2\nScaling update-demo-nautilus down to 0\nUpdate succeeded. Deleting old controller: update-demo-nautilus\nRenaming update-demo-kitten to update-demo-nautilus\nreplicationcontroller/update-demo-nautilus rolling updated\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Mar  1 08:37:36.083: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-az-nl4q9.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-mlj8p'
Mar  1 08:37:36.499: INFO: stderr: ""
Mar  1 08:37:36.499: INFO: stdout: "update-demo-kitten-kkrjs update-demo-kitten-q54zq "
Mar  1 08:37:36.499: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-az-nl4q9.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml get pods update-demo-kitten-kkrjs -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-mlj8p'
Mar  1 08:37:36.721: INFO: stderr: ""
Mar  1 08:37:36.721: INFO: stdout: "true"
Mar  1 08:37:36.722: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-az-nl4q9.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml get pods update-demo-kitten-kkrjs -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-mlj8p'
Mar  1 08:37:36.949: INFO: stderr: ""
Mar  1 08:37:36.949: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
Mar  1 08:37:36.949: INFO: validating pod update-demo-kitten-kkrjs
Mar  1 08:37:37.072: INFO: got data: {
  "image": "kitten.jpg"
}

Mar  1 08:37:37.072: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Mar  1 08:37:37.072: INFO: update-demo-kitten-kkrjs is verified up and running
Mar  1 08:37:37.072: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-az-nl4q9.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml get pods update-demo-kitten-q54zq -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-mlj8p'
Mar  1 08:37:37.322: INFO: stderr: ""
Mar  1 08:37:37.322: INFO: stdout: "true"
Mar  1 08:37:37.322: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-az-nl4q9.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml get pods update-demo-kitten-q54zq -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-mlj8p'
Mar  1 08:37:37.550: INFO: stderr: ""
Mar  1 08:37:37.550: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
Mar  1 08:37:37.550: INFO: validating pod update-demo-kitten-q54zq
Mar  1 08:37:37.670: INFO: got data: {
  "image": "kitten.jpg"
}

Mar  1 08:37:37.670: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Mar  1 08:37:37.670: INFO: update-demo-kitten-q54zq is verified up and running
[AfterEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 08:37:37.670: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-mlj8p" for this suite.
Mar  1 08:38:01.817: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 08:38:03.047: INFO: namespace: e2e-tests-kubectl-mlj8p, resource: bindings, ignored listing per whitelist
Mar  1 08:38:03.222: INFO: namespace e2e-tests-kubectl-mlj8p deletion completed in 25.516399955s

• [SLOW TEST:58.449 seconds]
[sig-cli] Kubectl client
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Update Demo
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should do a rolling update of a replication controller  [Conformance]
    /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Downward API volume 
  should set mode on item file [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 08:38:03.222: INFO: >>> kubeConfig: /tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-vhw4x
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should set mode on item file [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Mar  1 08:38:04.912: INFO: Waiting up to 5m0s for pod "downwardapi-volume-54e7a647-3bfd-11e9-a72e-ce8290b78775" in namespace "e2e-tests-downward-api-vhw4x" to be "success or failure"
Mar  1 08:38:04.948: INFO: Pod "downwardapi-volume-54e7a647-3bfd-11e9-a72e-ce8290b78775": Phase="Pending", Reason="", readiness=false. Elapsed: 35.427451ms
Mar  1 08:38:06.984: INFO: Pod "downwardapi-volume-54e7a647-3bfd-11e9-a72e-ce8290b78775": Phase="Pending", Reason="", readiness=false. Elapsed: 2.071740185s
Mar  1 08:38:09.020: INFO: Pod "downwardapi-volume-54e7a647-3bfd-11e9-a72e-ce8290b78775": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.107673897s
STEP: Saw pod success
Mar  1 08:38:09.020: INFO: Pod "downwardapi-volume-54e7a647-3bfd-11e9-a72e-ce8290b78775" satisfied condition "success or failure"
Mar  1 08:38:09.055: INFO: Trying to get logs from node shoot--it--pub-az-nl4q9-cpu-worker-7dd9bbfd9c-7fp9l pod downwardapi-volume-54e7a647-3bfd-11e9-a72e-ce8290b78775 container client-container: <nil>
STEP: delete the pod
Mar  1 08:38:09.145: INFO: Waiting for pod downwardapi-volume-54e7a647-3bfd-11e9-a72e-ce8290b78775 to disappear
Mar  1 08:38:09.180: INFO: Pod downwardapi-volume-54e7a647-3bfd-11e9-a72e-ce8290b78775 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 08:38:09.181: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-vhw4x" for this suite.
Mar  1 08:38:17.326: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 08:38:18.406: INFO: namespace: e2e-tests-downward-api-vhw4x, resource: bindings, ignored listing per whitelist
Mar  1 08:38:18.802: INFO: namespace e2e-tests-downward-api-vhw4x deletion completed in 9.584216565s

• [SLOW TEST:15.580 seconds]
[sig-storage] Downward API volume
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should set mode on item file [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 08:38:18.803: INFO: >>> kubeConfig: /tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-545jc
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-5e2a4d1d-3bfd-11e9-a72e-ce8290b78775
STEP: Creating a pod to test consume secrets
Mar  1 08:38:20.484: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-5e2fbb88-3bfd-11e9-a72e-ce8290b78775" in namespace "e2e-tests-projected-545jc" to be "success or failure"
Mar  1 08:38:20.520: INFO: Pod "pod-projected-secrets-5e2fbb88-3bfd-11e9-a72e-ce8290b78775": Phase="Pending", Reason="", readiness=false. Elapsed: 35.348941ms
Mar  1 08:38:22.557: INFO: Pod "pod-projected-secrets-5e2fbb88-3bfd-11e9-a72e-ce8290b78775": Phase="Pending", Reason="", readiness=false. Elapsed: 2.072714838s
Mar  1 08:38:24.593: INFO: Pod "pod-projected-secrets-5e2fbb88-3bfd-11e9-a72e-ce8290b78775": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.108665403s
STEP: Saw pod success
Mar  1 08:38:24.593: INFO: Pod "pod-projected-secrets-5e2fbb88-3bfd-11e9-a72e-ce8290b78775" satisfied condition "success or failure"
Mar  1 08:38:24.630: INFO: Trying to get logs from node shoot--it--pub-az-nl4q9-cpu-worker-7dd9bbfd9c-7fp9l pod pod-projected-secrets-5e2fbb88-3bfd-11e9-a72e-ce8290b78775 container projected-secret-volume-test: <nil>
STEP: delete the pod
Mar  1 08:38:24.721: INFO: Waiting for pod pod-projected-secrets-5e2fbb88-3bfd-11e9-a72e-ce8290b78775 to disappear
Mar  1 08:38:24.757: INFO: Pod pod-projected-secrets-5e2fbb88-3bfd-11e9-a72e-ce8290b78775 no longer exists
[AfterEach] [sig-storage] Projected
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 08:38:24.757: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-545jc" for this suite.
Mar  1 08:38:30.902: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 08:38:31.930: INFO: namespace: e2e-tests-projected-545jc, resource: bindings, ignored listing per whitelist
Mar  1 08:38:32.245: INFO: namespace e2e-tests-projected-545jc deletion completed in 7.452226374s

• [SLOW TEST:13.443 seconds]
[sig-storage] Projected
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[k8s.io] KubeletManagedEtcHosts 
  should test kubelet managed /etc/hosts file [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] KubeletManagedEtcHosts
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 08:38:32.246: INFO: >>> kubeConfig: /tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename e2e-kubelet-etc-hosts
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-e2e-kubelet-etc-hosts-gflj2
STEP: Waiting for a default service account to be provisioned in namespace
[It] should test kubelet managed /etc/hosts file [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Setting up the test
STEP: Creating hostNetwork=false pod
STEP: Creating hostNetwork=true pod
STEP: Running the test
STEP: Verifying /etc/hosts of container is kubelet-managed for pod with hostNetwork=false
Mar  1 08:38:42.108: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-gflj2 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar  1 08:38:42.108: INFO: >>> kubeConfig: /tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
Mar  1 08:38:42.779: INFO: Exec stderr: ""
Mar  1 08:38:42.779: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-gflj2 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar  1 08:38:42.779: INFO: >>> kubeConfig: /tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
Mar  1 08:38:43.364: INFO: Exec stderr: ""
Mar  1 08:38:43.364: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-gflj2 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar  1 08:38:43.364: INFO: >>> kubeConfig: /tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
Mar  1 08:38:43.989: INFO: Exec stderr: ""
Mar  1 08:38:43.989: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-gflj2 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar  1 08:38:43.989: INFO: >>> kubeConfig: /tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
Mar  1 08:38:44.501: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts of container is not kubelet-managed since container specifies /etc/hosts mount
Mar  1 08:38:44.501: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-gflj2 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar  1 08:38:44.501: INFO: >>> kubeConfig: /tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
Mar  1 08:38:45.083: INFO: Exec stderr: ""
Mar  1 08:38:45.083: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-gflj2 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar  1 08:38:45.083: INFO: >>> kubeConfig: /tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
Mar  1 08:38:45.690: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts content of container is not kubelet-managed for pod with hostNetwork=true
Mar  1 08:38:45.690: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-gflj2 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar  1 08:38:45.690: INFO: >>> kubeConfig: /tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
Mar  1 08:38:46.264: INFO: Exec stderr: ""
Mar  1 08:38:46.264: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-gflj2 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar  1 08:38:46.264: INFO: >>> kubeConfig: /tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
Mar  1 08:38:46.800: INFO: Exec stderr: ""
Mar  1 08:38:46.800: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-gflj2 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar  1 08:38:46.800: INFO: >>> kubeConfig: /tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
Mar  1 08:38:47.465: INFO: Exec stderr: ""
Mar  1 08:38:47.465: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-gflj2 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar  1 08:38:47.465: INFO: >>> kubeConfig: /tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
Mar  1 08:38:48.088: INFO: Exec stderr: ""
[AfterEach] [k8s.io] KubeletManagedEtcHosts
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 08:38:48.088: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-e2e-kubelet-etc-hosts-gflj2" for this suite.
Mar  1 08:39:38.233: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 08:39:39.215: INFO: namespace: e2e-tests-e2e-kubelet-etc-hosts-gflj2, resource: bindings, ignored listing per whitelist
Mar  1 08:39:39.650: INFO: namespace e2e-tests-e2e-kubelet-etc-hosts-gflj2 deletion completed in 51.525391357s

• [SLOW TEST:67.405 seconds]
[k8s.io] KubeletManagedEtcHosts
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should test kubelet managed /etc/hosts file [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,default) [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 08:39:39.650: INFO: >>> kubeConfig: /tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-gw5q8
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,default) [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0644 on node default medium
Mar  1 08:39:41.315: INFO: Waiting up to 5m0s for pod "pod-8e5d4d62-3bfd-11e9-a72e-ce8290b78775" in namespace "e2e-tests-emptydir-gw5q8" to be "success or failure"
Mar  1 08:39:41.395: INFO: Pod "pod-8e5d4d62-3bfd-11e9-a72e-ce8290b78775": Phase="Pending", Reason="", readiness=false. Elapsed: 80.182522ms
Mar  1 08:39:43.432: INFO: Pod "pod-8e5d4d62-3bfd-11e9-a72e-ce8290b78775": Phase="Pending", Reason="", readiness=false. Elapsed: 2.117342987s
Mar  1 08:39:45.469: INFO: Pod "pod-8e5d4d62-3bfd-11e9-a72e-ce8290b78775": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.154248494s
STEP: Saw pod success
Mar  1 08:39:45.469: INFO: Pod "pod-8e5d4d62-3bfd-11e9-a72e-ce8290b78775" satisfied condition "success or failure"
Mar  1 08:39:45.504: INFO: Trying to get logs from node shoot--it--pub-az-nl4q9-cpu-worker-7dd9bbfd9c-7fp9l pod pod-8e5d4d62-3bfd-11e9-a72e-ce8290b78775 container test-container: <nil>
STEP: delete the pod
Mar  1 08:39:45.597: INFO: Waiting for pod pod-8e5d4d62-3bfd-11e9-a72e-ce8290b78775 to disappear
Mar  1 08:39:45.635: INFO: Pod pod-8e5d4d62-3bfd-11e9-a72e-ce8290b78775 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 08:39:45.635: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-gw5q8" for this suite.
Mar  1 08:39:53.780: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 08:39:54.028: INFO: namespace: e2e-tests-emptydir-gw5q8, resource: bindings, ignored listing per whitelist
Mar  1 08:39:55.211: INFO: namespace e2e-tests-emptydir-gw5q8 deletion completed in 9.540130866s

• [SLOW TEST:15.561 seconds]
[sig-storage] EmptyDir volumes
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0644,default) [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 08:39:55.212: INFO: >>> kubeConfig: /tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename init-container
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-init-container-p2zsp
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
Mar  1 08:39:56.778: INFO: PodSpec: initContainers in spec.initContainers
Mar  1 08:40:44.084: INFO: init container has failed twice: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-init-979aec0d-3bfd-11e9-a72e-ce8290b78775", GenerateName:"", Namespace:"e2e-tests-init-container-p2zsp", SelfLink:"/api/v1/namespaces/e2e-tests-init-container-p2zsp/pods/pod-init-979aec0d-3bfd-11e9-a72e-ce8290b78775", UID:"979e0929-3bfd-11e9-b4e8-fa9e8069966e", ResourceVersion:"13882", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63687026396, loc:(*time.Location)(0x78fbda0)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"778809053"}, Annotations:map[string]string{"cni.projectcalico.org/podIP":"100.96.1.117/32", "kubernetes.io/psp":"e2e-test-privileged-psp"}, OwnerReferences:[]v1.OwnerReference(nil), Initializers:(*v1.Initializers)(nil), Finalizers:[]string(nil), ClusterName:""}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"default-token-j2xnd", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(0xc001f7d440), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil)}}}, InitContainers:[]v1.Container{v1.Container{Name:"init1", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/false"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-j2xnd", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}, v1.Container{Name:"init2", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/true"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-j2xnd", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, Containers:[]v1.Container{v1.Container{Name:"run1", Image:"k8s.gcr.io/pause:3.1", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}, Requests:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-j2xnd", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc001b57f18), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"shoot--it--pub-az-nl4q9-cpu-worker-7dd9bbfd9c-7fp9l", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc001ab9ce0), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc001b57f90)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc001b57fb0)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc001b57fb8), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil)}, Status:v1.PodStatus{Phase:"Pending", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63687026396, loc:(*time.Location)(0x78fbda0)}}, Reason:"ContainersNotInitialized", Message:"containers with incomplete status: [init1 init2]"}, v1.PodCondition{Type:"Ready", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63687026396, loc:(*time.Location)(0x78fbda0)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"ContainersReady", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63687026396, loc:(*time.Location)(0x78fbda0)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63687026396, loc:(*time.Location)(0x78fbda0)}}, Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"10.250.0.4", PodIP:"100.96.1.117", StartTime:(*v1.Time)(0xc00178db00), InitContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"init1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc001009d50)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc001009dc0)}, Ready:false, RestartCount:3, Image:"busybox:1.29", ImageID:"docker-pullable://busybox@sha256:8ccbac733d19c0dd4d70b4f0c1e12245b5fa3ad24758a11035ee505c629c0796", ContainerID:"docker://4b501828a7f749432264392e26462b934c735ebf397002328f5061f92ecc1407"}, v1.ContainerStatus{Name:"init2", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc00178db60), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"docker.io/library/busybox:1.29", ImageID:"", ContainerID:""}}, ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"run1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc00178db20), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"k8s.gcr.io/pause:3.1", ImageID:"", ContainerID:""}}, QOSClass:"Guaranteed"}}
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 08:40:44.084: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-init-container-p2zsp" for this suite.
Mar  1 08:41:06.247: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 08:41:06.822: INFO: namespace: e2e-tests-init-container-p2zsp, resource: bindings, ignored listing per whitelist
Mar  1 08:41:07.660: INFO: namespace e2e-tests-init-container-p2zsp deletion completed in 23.54026789s

• [SLOW TEST:72.448 seconds]
[k8s.io] InitContainer [NodeConformance]
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-api-machinery] Downward API 
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Downward API
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 08:41:07.661: INFO: >>> kubeConfig: /tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-nnzwl
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Mar  1 08:41:09.336: INFO: Waiting up to 5m0s for pod "downward-api-c2d44068-3bfd-11e9-a72e-ce8290b78775" in namespace "e2e-tests-downward-api-nnzwl" to be "success or failure"
Mar  1 08:41:09.383: INFO: Pod "downward-api-c2d44068-3bfd-11e9-a72e-ce8290b78775": Phase="Pending", Reason="", readiness=false. Elapsed: 46.447062ms
Mar  1 08:41:11.422: INFO: Pod "downward-api-c2d44068-3bfd-11e9-a72e-ce8290b78775": Phase="Pending", Reason="", readiness=false. Elapsed: 2.085782225s
Mar  1 08:41:13.459: INFO: Pod "downward-api-c2d44068-3bfd-11e9-a72e-ce8290b78775": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.122267461s
STEP: Saw pod success
Mar  1 08:41:13.459: INFO: Pod "downward-api-c2d44068-3bfd-11e9-a72e-ce8290b78775" satisfied condition "success or failure"
Mar  1 08:41:13.497: INFO: Trying to get logs from node shoot--it--pub-az-nl4q9-cpu-worker-7dd9bbfd9c-7fp9l pod downward-api-c2d44068-3bfd-11e9-a72e-ce8290b78775 container dapi-container: <nil>
STEP: delete the pod
Mar  1 08:41:13.589: INFO: Waiting for pod downward-api-c2d44068-3bfd-11e9-a72e-ce8290b78775 to disappear
Mar  1 08:41:13.636: INFO: Pod downward-api-c2d44068-3bfd-11e9-a72e-ce8290b78775 no longer exists
[AfterEach] [sig-api-machinery] Downward API
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 08:41:13.636: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-nnzwl" for this suite.
Mar  1 08:41:19.783: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 08:41:20.647: INFO: namespace: e2e-tests-downward-api-nnzwl, resource: bindings, ignored listing per whitelist
Mar  1 08:41:21.176: INFO: namespace e2e-tests-downward-api-nnzwl deletion completed in 7.501177349s

• [SLOW TEST:13.515 seconds]
[sig-api-machinery] Downward API
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 08:41:21.176: INFO: >>> kubeConfig: /tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-dtkd7
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-cade5721-3bfd-11e9-a72e-ce8290b78775
STEP: Creating a pod to test consume configMaps
Mar  1 08:41:22.860: INFO: Waiting up to 5m0s for pod "pod-configmaps-cae3d636-3bfd-11e9-a72e-ce8290b78775" in namespace "e2e-tests-configmap-dtkd7" to be "success or failure"
Mar  1 08:41:22.911: INFO: Pod "pod-configmaps-cae3d636-3bfd-11e9-a72e-ce8290b78775": Phase="Pending", Reason="", readiness=false. Elapsed: 51.011131ms
Mar  1 08:41:24.947: INFO: Pod "pod-configmaps-cae3d636-3bfd-11e9-a72e-ce8290b78775": Phase="Pending", Reason="", readiness=false. Elapsed: 2.087228288s
Mar  1 08:41:26.984: INFO: Pod "pod-configmaps-cae3d636-3bfd-11e9-a72e-ce8290b78775": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.124325034s
STEP: Saw pod success
Mar  1 08:41:26.984: INFO: Pod "pod-configmaps-cae3d636-3bfd-11e9-a72e-ce8290b78775" satisfied condition "success or failure"
Mar  1 08:41:27.020: INFO: Trying to get logs from node shoot--it--pub-az-nl4q9-cpu-worker-7dd9bbfd9c-7fp9l pod pod-configmaps-cae3d636-3bfd-11e9-a72e-ce8290b78775 container configmap-volume-test: <nil>
STEP: delete the pod
Mar  1 08:41:27.103: INFO: Waiting for pod pod-configmaps-cae3d636-3bfd-11e9-a72e-ce8290b78775 to disappear
Mar  1 08:41:27.138: INFO: Pod pod-configmaps-cae3d636-3bfd-11e9-a72e-ce8290b78775 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 08:41:27.139: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-dtkd7" for this suite.
Mar  1 08:41:35.283: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 08:41:35.672: INFO: namespace: e2e-tests-configmap-dtkd7, resource: bindings, ignored listing per whitelist
Mar  1 08:41:36.681: INFO: namespace e2e-tests-configmap-dtkd7 deletion completed in 9.50584554s

• [SLOW TEST:15.505 seconds]
[sig-storage] ConfigMap
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu request [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 08:41:36.681: INFO: >>> kubeConfig: /tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-7twrh
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Mar  1 08:41:38.344: INFO: Waiting up to 5m0s for pod "downwardapi-volume-d41ea4fb-3bfd-11e9-a72e-ce8290b78775" in namespace "e2e-tests-downward-api-7twrh" to be "success or failure"
Mar  1 08:41:38.393: INFO: Pod "downwardapi-volume-d41ea4fb-3bfd-11e9-a72e-ce8290b78775": Phase="Pending", Reason="", readiness=false. Elapsed: 48.768513ms
Mar  1 08:41:40.430: INFO: Pod "downwardapi-volume-d41ea4fb-3bfd-11e9-a72e-ce8290b78775": Phase="Pending", Reason="", readiness=false. Elapsed: 2.085509722s
Mar  1 08:41:42.467: INFO: Pod "downwardapi-volume-d41ea4fb-3bfd-11e9-a72e-ce8290b78775": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.122508517s
STEP: Saw pod success
Mar  1 08:41:42.467: INFO: Pod "downwardapi-volume-d41ea4fb-3bfd-11e9-a72e-ce8290b78775" satisfied condition "success or failure"
Mar  1 08:41:42.503: INFO: Trying to get logs from node shoot--it--pub-az-nl4q9-cpu-worker-7dd9bbfd9c-7fp9l pod downwardapi-volume-d41ea4fb-3bfd-11e9-a72e-ce8290b78775 container client-container: <nil>
STEP: delete the pod
Mar  1 08:41:42.588: INFO: Waiting for pod downwardapi-volume-d41ea4fb-3bfd-11e9-a72e-ce8290b78775 to disappear
Mar  1 08:41:42.634: INFO: Pod downwardapi-volume-d41ea4fb-3bfd-11e9-a72e-ce8290b78775 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 08:41:42.634: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-7twrh" for this suite.
Mar  1 08:41:48.782: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 08:41:49.777: INFO: namespace: e2e-tests-downward-api-7twrh, resource: bindings, ignored listing per whitelist
Mar  1 08:41:50.211: INFO: namespace e2e-tests-downward-api-7twrh deletion completed in 7.541966962s

• [SLOW TEST:13.531 seconds]
[sig-storage] Downward API volume
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's cpu request [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Projected 
  should update annotations on modification [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 08:41:50.211: INFO: >>> kubeConfig: /tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-xjq82
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should update annotations on modification [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating the pod
Mar  1 08:41:56.586: INFO: Successfully updated pod "annotationupdatedc282521-3bfd-11e9-a72e-ce8290b78775"
[AfterEach] [sig-storage] Projected
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 08:41:58.681: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-xjq82" for this suite.
Mar  1 08:42:22.830: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 08:42:23.376: INFO: namespace: e2e-tests-projected-xjq82, resource: bindings, ignored listing per whitelist
Mar  1 08:42:24.247: INFO: namespace e2e-tests-projected-xjq82 deletion completed in 25.530397952s

• [SLOW TEST:34.036 seconds]
[sig-storage] Projected
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should update annotations on modification [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl expose 
  should create services for rc  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 08:42:24.248: INFO: >>> kubeConfig: /tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-ffsrr
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should create services for rc  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating Redis RC
Mar  1 08:42:25.897: INFO: namespace e2e-tests-kubectl-ffsrr
Mar  1 08:42:25.897: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-az-nl4q9.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml create -f - --namespace=e2e-tests-kubectl-ffsrr'
Mar  1 08:42:26.803: INFO: stderr: ""
Mar  1 08:42:26.803: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
Mar  1 08:42:27.840: INFO: Selector matched 1 pods for map[app:redis]
Mar  1 08:42:27.840: INFO: Found 0 / 1
Mar  1 08:42:28.840: INFO: Selector matched 1 pods for map[app:redis]
Mar  1 08:42:28.840: INFO: Found 0 / 1
Mar  1 08:42:29.856: INFO: Selector matched 1 pods for map[app:redis]
Mar  1 08:42:29.856: INFO: Found 1 / 1
Mar  1 08:42:29.856: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Mar  1 08:42:29.892: INFO: Selector matched 1 pods for map[app:redis]
Mar  1 08:42:29.892: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Mar  1 08:42:29.892: INFO: wait on redis-master startup in e2e-tests-kubectl-ffsrr 
Mar  1 08:42:29.892: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-az-nl4q9.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml logs redis-master-nxqp5 redis-master --namespace=e2e-tests-kubectl-ffsrr'
Mar  1 08:42:30.163: INFO: stderr: ""
Mar  1 08:42:30.163: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 01 Mar 08:42:28.698 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 01 Mar 08:42:28.698 # Server started, Redis version 3.2.12\n1:M 01 Mar 08:42:28.698 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 01 Mar 08:42:28.698 * The server is now ready to accept connections on port 6379\n"
STEP: exposing RC
Mar  1 08:42:30.163: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-az-nl4q9.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml expose rc redis-master --name=rm2 --port=1234 --target-port=6379 --namespace=e2e-tests-kubectl-ffsrr'
Mar  1 08:42:30.479: INFO: stderr: ""
Mar  1 08:42:30.479: INFO: stdout: "service/rm2 exposed\n"
Mar  1 08:42:30.527: INFO: Service rm2 in namespace e2e-tests-kubectl-ffsrr found.
STEP: exposing service
Mar  1 08:42:32.598: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-az-nl4q9.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml expose service rm2 --name=rm3 --port=2345 --target-port=6379 --namespace=e2e-tests-kubectl-ffsrr'
Mar  1 08:42:33.011: INFO: stderr: ""
Mar  1 08:42:33.011: INFO: stdout: "service/rm3 exposed\n"
Mar  1 08:42:33.047: INFO: Service rm3 in namespace e2e-tests-kubectl-ffsrr found.
[AfterEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 08:42:35.119: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-ffsrr" for this suite.
Mar  1 08:42:59.262: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 08:43:00.293: INFO: namespace: e2e-tests-kubectl-ffsrr, resource: bindings, ignored listing per whitelist
Mar  1 08:43:00.622: INFO: namespace e2e-tests-kubectl-ffsrr deletion completed in 25.468203262s

• [SLOW TEST:36.375 seconds]
[sig-cli] Kubectl client
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl expose
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create services for rc  [Conformance]
    /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 08:43:00.623: INFO: >>> kubeConfig: /tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-6pc7d
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-0632a06b-3bfe-11e9-a72e-ce8290b78775
STEP: Creating a pod to test consume secrets
Mar  1 08:43:02.397: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-063817cb-3bfe-11e9-a72e-ce8290b78775" in namespace "e2e-tests-projected-6pc7d" to be "success or failure"
Mar  1 08:43:02.432: INFO: Pod "pod-projected-secrets-063817cb-3bfe-11e9-a72e-ce8290b78775": Phase="Pending", Reason="", readiness=false. Elapsed: 35.121077ms
Mar  1 08:43:04.469: INFO: Pod "pod-projected-secrets-063817cb-3bfe-11e9-a72e-ce8290b78775": Phase="Pending", Reason="", readiness=false. Elapsed: 2.07233421s
Mar  1 08:43:06.505: INFO: Pod "pod-projected-secrets-063817cb-3bfe-11e9-a72e-ce8290b78775": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.108214218s
STEP: Saw pod success
Mar  1 08:43:06.505: INFO: Pod "pod-projected-secrets-063817cb-3bfe-11e9-a72e-ce8290b78775" satisfied condition "success or failure"
Mar  1 08:43:06.541: INFO: Trying to get logs from node shoot--it--pub-az-nl4q9-cpu-worker-7dd9bbfd9c-7fp9l pod pod-projected-secrets-063817cb-3bfe-11e9-a72e-ce8290b78775 container projected-secret-volume-test: <nil>
STEP: delete the pod
Mar  1 08:43:06.624: INFO: Waiting for pod pod-projected-secrets-063817cb-3bfe-11e9-a72e-ce8290b78775 to disappear
Mar  1 08:43:06.692: INFO: Pod pod-projected-secrets-063817cb-3bfe-11e9-a72e-ce8290b78775 no longer exists
[AfterEach] [sig-storage] Projected
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 08:43:06.692: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-6pc7d" for this suite.
Mar  1 08:43:12.836: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 08:43:13.220: INFO: namespace: e2e-tests-projected-6pc7d, resource: bindings, ignored listing per whitelist
Mar  1 08:43:14.266: INFO: namespace e2e-tests-projected-6pc7d deletion completed in 7.537391924s

• [SLOW TEST:13.643 seconds]
[sig-storage] Projected
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] Projected 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 08:43:14.266: INFO: >>> kubeConfig: /tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-w45sz
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Mar  1 08:43:15.921: INFO: Waiting up to 5m0s for pod "downwardapi-volume-0e479877-3bfe-11e9-a72e-ce8290b78775" in namespace "e2e-tests-projected-w45sz" to be "success or failure"
Mar  1 08:43:15.957: INFO: Pod "downwardapi-volume-0e479877-3bfe-11e9-a72e-ce8290b78775": Phase="Pending", Reason="", readiness=false. Elapsed: 35.637306ms
Mar  1 08:43:17.993: INFO: Pod "downwardapi-volume-0e479877-3bfe-11e9-a72e-ce8290b78775": Phase="Pending", Reason="", readiness=false. Elapsed: 2.072173431s
Mar  1 08:43:20.029: INFO: Pod "downwardapi-volume-0e479877-3bfe-11e9-a72e-ce8290b78775": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.108424659s
STEP: Saw pod success
Mar  1 08:43:20.030: INFO: Pod "downwardapi-volume-0e479877-3bfe-11e9-a72e-ce8290b78775" satisfied condition "success or failure"
Mar  1 08:43:20.065: INFO: Trying to get logs from node shoot--it--pub-az-nl4q9-cpu-worker-7dd9bbfd9c-7fp9l pod downwardapi-volume-0e479877-3bfe-11e9-a72e-ce8290b78775 container client-container: <nil>
STEP: delete the pod
Mar  1 08:43:20.159: INFO: Waiting for pod downwardapi-volume-0e479877-3bfe-11e9-a72e-ce8290b78775 to disappear
Mar  1 08:43:20.195: INFO: Pod downwardapi-volume-0e479877-3bfe-11e9-a72e-ce8290b78775 no longer exists
[AfterEach] [sig-storage] Projected
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 08:43:20.195: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-w45sz" for this suite.
Mar  1 08:43:26.400: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 08:43:26.865: INFO: namespace: e2e-tests-projected-w45sz, resource: bindings, ignored listing per whitelist
Mar  1 08:43:27.803: INFO: namespace e2e-tests-projected-w45sz deletion completed in 7.572836873s

• [SLOW TEST:13.537 seconds]
[sig-storage] Projected
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should provide container's cpu limit [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[k8s.io] Probing container 
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 08:43:27.803: INFO: >>> kubeConfig: /tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-container-probe-nrcdp
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-http in namespace e2e-tests-container-probe-nrcdp
Mar  1 08:43:33.612: INFO: Started pod liveness-http in namespace e2e-tests-container-probe-nrcdp
STEP: checking the pod's current state and verifying that restartCount is present
Mar  1 08:43:33.652: INFO: Initial restart count of pod liveness-http is 0
Mar  1 08:43:52.015: INFO: Restart count of pod e2e-tests-container-probe-nrcdp/liveness-http is now 1 (18.363156332s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 08:43:52.056: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-nrcdp" for this suite.
Mar  1 08:43:58.199: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 08:43:58.551: INFO: namespace: e2e-tests-container-probe-nrcdp, resource: bindings, ignored listing per whitelist
Mar  1 08:43:59.552: INFO: namespace e2e-tests-container-probe-nrcdp deletion completed in 7.459967496s

• [SLOW TEST:31.748 seconds]
[k8s.io] Probing container
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on default medium should have the correct mode [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 08:43:59.552: INFO: >>> kubeConfig: /tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-jgw7f
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on default medium should have the correct mode [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir volume type on node default medium
Mar  1 08:44:01.127: INFO: Waiting up to 5m0s for pod "pod-293973f3-3bfe-11e9-a72e-ce8290b78775" in namespace "e2e-tests-emptydir-jgw7f" to be "success or failure"
Mar  1 08:44:01.170: INFO: Pod "pod-293973f3-3bfe-11e9-a72e-ce8290b78775": Phase="Pending", Reason="", readiness=false. Elapsed: 43.043176ms
Mar  1 08:44:03.208: INFO: Pod "pod-293973f3-3bfe-11e9-a72e-ce8290b78775": Phase="Pending", Reason="", readiness=false. Elapsed: 2.081616134s
Mar  1 08:44:05.244: INFO: Pod "pod-293973f3-3bfe-11e9-a72e-ce8290b78775": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.117449815s
STEP: Saw pod success
Mar  1 08:44:05.244: INFO: Pod "pod-293973f3-3bfe-11e9-a72e-ce8290b78775" satisfied condition "success or failure"
Mar  1 08:44:05.279: INFO: Trying to get logs from node shoot--it--pub-az-nl4q9-cpu-worker-7dd9bbfd9c-7fp9l pod pod-293973f3-3bfe-11e9-a72e-ce8290b78775 container test-container: <nil>
STEP: delete the pod
Mar  1 08:44:05.393: INFO: Waiting for pod pod-293973f3-3bfe-11e9-a72e-ce8290b78775 to disappear
Mar  1 08:44:05.428: INFO: Pod pod-293973f3-3bfe-11e9-a72e-ce8290b78775 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 08:44:05.428: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-jgw7f" for this suite.
Mar  1 08:44:11.578: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 08:44:12.347: INFO: namespace: e2e-tests-emptydir-jgw7f, resource: bindings, ignored listing per whitelist
Mar  1 08:44:12.988: INFO: namespace e2e-tests-emptydir-jgw7f deletion completed in 7.523695947s

• [SLOW TEST:13.436 seconds]
[sig-storage] EmptyDir volumes
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  volume on default medium should have the correct mode [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 08:44:12.988: INFO: >>> kubeConfig: /tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-container-probe-97pln
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-http in namespace e2e-tests-container-probe-97pln
Mar  1 08:44:18.736: INFO: Started pod liveness-http in namespace e2e-tests-container-probe-97pln
STEP: checking the pod's current state and verifying that restartCount is present
Mar  1 08:44:18.772: INFO: Initial restart count of pod liveness-http is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 08:48:19.286: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-97pln" for this suite.
Mar  1 08:48:25.430: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 08:48:26.140: INFO: namespace: e2e-tests-container-probe-97pln, resource: bindings, ignored listing per whitelist
Mar  1 08:48:26.805: INFO: namespace e2e-tests-container-probe-97pln deletion completed in 7.482392748s

• [SLOW TEST:253.817 seconds]
[k8s.io] Probing container
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[k8s.io] Pods 
  should be updated [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 08:48:26.805: INFO: >>> kubeConfig: /tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-pods-jwm47
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should be updated [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Mar  1 08:48:33.180: INFO: Successfully updated pod "pod-update-c88daea8-3bfe-11e9-a72e-ce8290b78775"
STEP: verifying the updated pod is in kubernetes
Mar  1 08:48:33.258: INFO: Pod update OK
[AfterEach] [k8s.io] Pods
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 08:48:33.258: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-jwm47" for this suite.
Mar  1 08:48:55.435: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 08:48:56.082: INFO: namespace: e2e-tests-pods-jwm47, resource: bindings, ignored listing per whitelist
Mar  1 08:48:56.844: INFO: namespace e2e-tests-pods-jwm47 deletion completed in 23.549548714s

• [SLOW TEST:30.039 seconds]
[k8s.io] Pods
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be updated [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan pods created by rc if delete options say so [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 08:48:56.844: INFO: >>> kubeConfig: /tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-gc-pblht
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan pods created by rc if delete options say so [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the pods
STEP: Gathering metrics
W0301 08:49:38.728458   31889 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Mar  1 08:49:38.728: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 08:49:38.728: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-pblht" for this suite.
Mar  1 08:49:46.897: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 08:49:48.296: INFO: namespace: e2e-tests-gc-pblht, resource: bindings, ignored listing per whitelist
Mar  1 08:49:48.367: INFO: namespace e2e-tests-gc-pblht deletion completed in 9.602792371s

• [SLOW TEST:51.523 seconds]
[sig-api-machinery] Garbage collector
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should orphan pods created by rc if delete options say so [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Should recreate evicted statefulset [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 08:49:48.367: INFO: >>> kubeConfig: /tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-statefulset-9bk6w
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-9bk6w
[It] Should recreate evicted statefulset [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Looking for a node to schedule stateful set and pod
STEP: Creating pod with conflicting port in namespace e2e-tests-statefulset-9bk6w
STEP: Creating statefulset with conflicting port in namespace e2e-tests-statefulset-9bk6w
STEP: Waiting until pod test-pod will start running in namespace e2e-tests-statefulset-9bk6w
STEP: Waiting until stateful pod ss-0 will be recreated and deleted at least once in namespace e2e-tests-statefulset-9bk6w
Mar  1 08:49:54.254: INFO: Observed stateful pod in namespace: e2e-tests-statefulset-9bk6w, name: ss-0, uid: fa045bdf-3bfe-11e9-b4e8-fa9e8069966e, status phase: Pending. Waiting for statefulset controller to delete.
Mar  1 08:50:01.192: INFO: Observed stateful pod in namespace: e2e-tests-statefulset-9bk6w, name: ss-0, uid: fa045bdf-3bfe-11e9-b4e8-fa9e8069966e, status phase: Failed. Waiting for statefulset controller to delete.
Mar  1 08:50:01.200: INFO: Observed stateful pod in namespace: e2e-tests-statefulset-9bk6w, name: ss-0, uid: fa045bdf-3bfe-11e9-b4e8-fa9e8069966e, status phase: Failed. Waiting for statefulset controller to delete.
Mar  1 08:50:01.204: INFO: Observed delete event for stateful pod ss-0 in namespace e2e-tests-statefulset-9bk6w
STEP: Removing pod with conflicting port in namespace e2e-tests-statefulset-9bk6w
STEP: Waiting when stateful pod ss-0 will be recreated in namespace e2e-tests-statefulset-9bk6w and will be in running state
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Mar  1 08:50:05.379: INFO: Deleting all statefulset in ns e2e-tests-statefulset-9bk6w
Mar  1 08:50:05.414: INFO: Scaling statefulset ss to 0
Mar  1 08:50:15.564: INFO: Waiting for statefulset status.replicas updated to 0
Mar  1 08:50:15.600: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 08:50:15.729: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-9bk6w" for this suite.
Mar  1 08:50:21.873: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 08:50:22.663: INFO: namespace: e2e-tests-statefulset-9bk6w, resource: bindings, ignored listing per whitelist
Mar  1 08:50:23.274: INFO: namespace e2e-tests-statefulset-9bk6w deletion completed in 7.509244261s

• [SLOW TEST:34.907 seconds]
[sig-apps] StatefulSet
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    Should recreate evicted statefulset [Conformance]
    /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should serve a basic image on each replica with a public image  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] ReplicationController
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 08:50:23.274: INFO: >>> kubeConfig: /tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename replication-controller
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-replication-controller-m4fhh
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating replication controller my-hostname-basic-0dfc90f4-3bff-11e9-a72e-ce8290b78775
Mar  1 08:50:24.960: INFO: Pod name my-hostname-basic-0dfc90f4-3bff-11e9-a72e-ce8290b78775: Found 1 pods out of 1
Mar  1 08:50:24.960: INFO: Ensuring all pods for ReplicationController "my-hostname-basic-0dfc90f4-3bff-11e9-a72e-ce8290b78775" are running
Mar  1 08:50:29.033: INFO: Pod "my-hostname-basic-0dfc90f4-3bff-11e9-a72e-ce8290b78775-q8m8l" is running (conditions: [{Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-03-01 08:50:24 +0000 UTC Reason: Message:}])
Mar  1 08:50:29.033: INFO: Trying to dial the pod
Mar  1 08:50:34.229: INFO: Controller my-hostname-basic-0dfc90f4-3bff-11e9-a72e-ce8290b78775: Got expected result from replica 1 [my-hostname-basic-0dfc90f4-3bff-11e9-a72e-ce8290b78775-q8m8l]: "my-hostname-basic-0dfc90f4-3bff-11e9-a72e-ce8290b78775-q8m8l", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicationController
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 08:50:34.229: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-replication-controller-m4fhh" for this suite.
Mar  1 08:50:40.374: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 08:50:40.694: INFO: namespace: e2e-tests-replication-controller-m4fhh, resource: bindings, ignored listing per whitelist
Mar  1 08:50:41.822: INFO: namespace e2e-tests-replication-controller-m4fhh deletion completed in 7.557361272s

• [SLOW TEST:18.548 seconds]
[sig-apps] ReplicationController
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should serve a basic image on each replica with a public image  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should retry creating failed daemon pods [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 08:50:41.823: INFO: >>> kubeConfig: /tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-daemonsets-pplkv
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should retry creating failed daemon pods [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Mar  1 08:50:43.733: INFO: Number of nodes with available pods: 0
Mar  1 08:50:43.733: INFO: Node shoot--it--pub-az-nl4q9-cpu-worker-7dd9bbfd9c-7fp9l is running more than one daemon pod
Mar  1 08:50:44.805: INFO: Number of nodes with available pods: 0
Mar  1 08:50:44.805: INFO: Node shoot--it--pub-az-nl4q9-cpu-worker-7dd9bbfd9c-7fp9l is running more than one daemon pod
Mar  1 08:50:45.809: INFO: Number of nodes with available pods: 2
Mar  1 08:50:45.809: INFO: Number of running nodes: 2, number of available pods: 2
STEP: Set a daemon pod's phase to 'Failed', check that the daemon pod is revived.
Mar  1 08:50:45.997: INFO: Number of nodes with available pods: 1
Mar  1 08:50:45.997: INFO: Node shoot--it--pub-az-nl4q9-cpu-worker-7dd9bbfd9c-gwjjt is running more than one daemon pod
Mar  1 08:50:47.071: INFO: Number of nodes with available pods: 1
Mar  1 08:50:47.071: INFO: Node shoot--it--pub-az-nl4q9-cpu-worker-7dd9bbfd9c-gwjjt is running more than one daemon pod
Mar  1 08:50:48.070: INFO: Number of nodes with available pods: 1
Mar  1 08:50:48.070: INFO: Node shoot--it--pub-az-nl4q9-cpu-worker-7dd9bbfd9c-gwjjt is running more than one daemon pod
Mar  1 08:50:49.069: INFO: Number of nodes with available pods: 2
Mar  1 08:50:49.069: INFO: Number of running nodes: 2, number of available pods: 2
STEP: Wait for the failed daemon pod to be completely deleted.
[AfterEach] [sig-apps] Daemon set [Serial]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting {extensions DaemonSet} daemon-set in namespace e2e-tests-daemonsets-pplkv, will wait for the garbage collector to delete the pods
Mar  1 08:50:49.300: INFO: Deleting {extensions DaemonSet} daemon-set took: 45.504153ms
Mar  1 08:50:49.400: INFO: Terminating {extensions DaemonSet} daemon-set pods took: 100.229224ms
Mar  1 08:51:31.237: INFO: Number of nodes with available pods: 0
Mar  1 08:51:31.237: INFO: Number of running nodes: 0, number of available pods: 0
Mar  1 08:51:31.282: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-pplkv/daemonsets","resourceVersion":"15651"},"items":null}

Mar  1 08:51:31.317: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-pplkv/pods","resourceVersion":"15651"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 08:51:31.445: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-pplkv" for this suite.
Mar  1 08:51:37.600: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 08:51:37.831: INFO: namespace: e2e-tests-daemonsets-pplkv, resource: bindings, ignored listing per whitelist
Mar  1 08:51:39.062: INFO: namespace e2e-tests-daemonsets-pplkv deletion completed in 7.578887765s

• [SLOW TEST:57.239 seconds]
[sig-apps] Daemon set [Serial]
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should retry creating failed daemon pods [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,default) [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 08:51:39.062: INFO: >>> kubeConfig: /tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-4kddp
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,default) [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0666 on node default medium
Mar  1 08:51:40.766: INFO: Waiting up to 5m0s for pod "pod-3b30eb5f-3bff-11e9-a72e-ce8290b78775" in namespace "e2e-tests-emptydir-4kddp" to be "success or failure"
Mar  1 08:51:40.805: INFO: Pod "pod-3b30eb5f-3bff-11e9-a72e-ce8290b78775": Phase="Pending", Reason="", readiness=false. Elapsed: 39.166686ms
Mar  1 08:51:42.843: INFO: Pod "pod-3b30eb5f-3bff-11e9-a72e-ce8290b78775": Phase="Pending", Reason="", readiness=false. Elapsed: 2.076750124s
Mar  1 08:51:44.883: INFO: Pod "pod-3b30eb5f-3bff-11e9-a72e-ce8290b78775": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.116748889s
STEP: Saw pod success
Mar  1 08:51:44.883: INFO: Pod "pod-3b30eb5f-3bff-11e9-a72e-ce8290b78775" satisfied condition "success or failure"
Mar  1 08:51:44.922: INFO: Trying to get logs from node shoot--it--pub-az-nl4q9-cpu-worker-7dd9bbfd9c-7fp9l pod pod-3b30eb5f-3bff-11e9-a72e-ce8290b78775 container test-container: <nil>
STEP: delete the pod
Mar  1 08:51:45.020: INFO: Waiting for pod pod-3b30eb5f-3bff-11e9-a72e-ce8290b78775 to disappear
Mar  1 08:51:45.056: INFO: Pod pod-3b30eb5f-3bff-11e9-a72e-ce8290b78775 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 08:51:45.056: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-4kddp" for this suite.
Mar  1 08:51:53.204: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 08:51:54.472: INFO: namespace: e2e-tests-emptydir-4kddp, resource: bindings, ignored listing per whitelist
Mar  1 08:51:54.648: INFO: namespace e2e-tests-emptydir-4kddp deletion completed in 9.555691594s

• [SLOW TEST:15.586 seconds]
[sig-storage] EmptyDir volumes
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0666,default) [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,default) [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 08:51:54.648: INFO: >>> kubeConfig: /tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-hlrpf
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,default) [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0777 on node default medium
Mar  1 08:51:56.413: INFO: Waiting up to 5m0s for pod "pod-44845e41-3bff-11e9-a72e-ce8290b78775" in namespace "e2e-tests-emptydir-hlrpf" to be "success or failure"
Mar  1 08:51:56.451: INFO: Pod "pod-44845e41-3bff-11e9-a72e-ce8290b78775": Phase="Pending", Reason="", readiness=false. Elapsed: 38.102051ms
Mar  1 08:51:58.491: INFO: Pod "pod-44845e41-3bff-11e9-a72e-ce8290b78775": Phase="Pending", Reason="", readiness=false. Elapsed: 2.07795873s
Mar  1 08:52:00.527: INFO: Pod "pod-44845e41-3bff-11e9-a72e-ce8290b78775": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.114253943s
STEP: Saw pod success
Mar  1 08:52:00.527: INFO: Pod "pod-44845e41-3bff-11e9-a72e-ce8290b78775" satisfied condition "success or failure"
Mar  1 08:52:00.562: INFO: Trying to get logs from node shoot--it--pub-az-nl4q9-cpu-worker-7dd9bbfd9c-7fp9l pod pod-44845e41-3bff-11e9-a72e-ce8290b78775 container test-container: <nil>
STEP: delete the pod
Mar  1 08:52:00.646: INFO: Waiting for pod pod-44845e41-3bff-11e9-a72e-ce8290b78775 to disappear
Mar  1 08:52:00.682: INFO: Pod pod-44845e41-3bff-11e9-a72e-ce8290b78775 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 08:52:00.682: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-hlrpf" for this suite.
Mar  1 08:52:06.842: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 08:52:07.639: INFO: namespace: e2e-tests-emptydir-hlrpf, resource: bindings, ignored listing per whitelist
Mar  1 08:52:08.298: INFO: namespace e2e-tests-emptydir-hlrpf deletion completed in 7.574903324s

• [SLOW TEST:13.650 seconds]
[sig-storage] EmptyDir volumes
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0777,default) [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[k8s.io] Docker Containers 
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Docker Containers
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 08:52:08.298: INFO: >>> kubeConfig: /tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename containers
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-containers-7kvcs
STEP: Waiting for a default service account to be provisioned in namespace
[It] should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test use defaults
Mar  1 08:52:10.026: INFO: Waiting up to 5m0s for pod "client-containers-4ca19723-3bff-11e9-a72e-ce8290b78775" in namespace "e2e-tests-containers-7kvcs" to be "success or failure"
Mar  1 08:52:10.084: INFO: Pod "client-containers-4ca19723-3bff-11e9-a72e-ce8290b78775": Phase="Pending", Reason="", readiness=false. Elapsed: 57.777891ms
Mar  1 08:52:12.121: INFO: Pod "client-containers-4ca19723-3bff-11e9-a72e-ce8290b78775": Phase="Pending", Reason="", readiness=false. Elapsed: 2.09528715s
Mar  1 08:52:14.158: INFO: Pod "client-containers-4ca19723-3bff-11e9-a72e-ce8290b78775": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.131669919s
STEP: Saw pod success
Mar  1 08:52:14.158: INFO: Pod "client-containers-4ca19723-3bff-11e9-a72e-ce8290b78775" satisfied condition "success or failure"
Mar  1 08:52:14.194: INFO: Trying to get logs from node shoot--it--pub-az-nl4q9-cpu-worker-7dd9bbfd9c-7fp9l pod client-containers-4ca19723-3bff-11e9-a72e-ce8290b78775 container test-container: <nil>
STEP: delete the pod
Mar  1 08:52:14.353: INFO: Waiting for pod client-containers-4ca19723-3bff-11e9-a72e-ce8290b78775 to disappear
Mar  1 08:52:14.389: INFO: Pod client-containers-4ca19723-3bff-11e9-a72e-ce8290b78775 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 08:52:14.389: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-7kvcs" for this suite.
Mar  1 08:52:20.533: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 08:52:21.920: INFO: namespace: e2e-tests-containers-7kvcs, resource: bindings, ignored listing per whitelist
Mar  1 08:52:21.955: INFO: namespace e2e-tests-containers-7kvcs deletion completed in 7.530575932s

• [SLOW TEST:13.657 seconds]
[k8s.io] Docker Containers
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run job 
  should create a job from an image when restart is OnFailure  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 08:52:21.956: INFO: >>> kubeConfig: /tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-dmw6s
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Kubectl run job
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1402
[It] should create a job from an image when restart is OnFailure  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Mar  1 08:52:23.484: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-az-nl4q9.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml run e2e-test-nginx-job --restart=OnFailure --generator=job/v1 --image=docker.io/library/nginx:1.14-alpine --namespace=e2e-tests-kubectl-dmw6s'
Mar  1 08:52:25.341: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl create instead.\n"
Mar  1 08:52:25.341: INFO: stdout: "job.batch/e2e-test-nginx-job created\n"
STEP: verifying the job e2e-test-nginx-job was created
[AfterEach] [k8s.io] Kubectl run job
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1407
Mar  1 08:52:25.376: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-az-nl4q9.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml delete jobs e2e-test-nginx-job --namespace=e2e-tests-kubectl-dmw6s'
Mar  1 08:52:25.657: INFO: stderr: ""
Mar  1 08:52:25.657: INFO: stdout: "job.batch \"e2e-test-nginx-job\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 08:52:25.657: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-dmw6s" for this suite.
Mar  1 08:52:31.814: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 08:52:33.280: INFO: namespace: e2e-tests-kubectl-dmw6s, resource: bindings, ignored listing per whitelist
Mar  1 08:52:33.280: INFO: namespace e2e-tests-kubectl-dmw6s deletion completed in 7.58673723s

• [SLOW TEST:11.325 seconds]
[sig-cli] Kubectl client
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run job
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create a job from an image when restart is OnFailure  [Conformance]
    /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-apps] Deployment 
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 08:52:33.280: INFO: >>> kubeConfig: /tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-deployment-p5dhw
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Mar  1 08:52:34.995: INFO: Creating replica set "test-rolling-update-controller" (going to be adopted)
Mar  1 08:52:35.067: INFO: Pod name sample-pod: Found 0 pods out of 1
Mar  1 08:52:40.105: INFO: Pod name sample-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Mar  1 08:52:40.105: INFO: Creating deployment "test-rolling-update-deployment"
Mar  1 08:52:40.141: INFO: Ensuring deployment "test-rolling-update-deployment" gets the next revision from the one the adopted replica set "test-rolling-update-controller" has
Mar  1 08:52:40.237: INFO: Ensuring status for deployment "test-rolling-update-deployment" is the expected
Mar  1 08:52:40.273: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:2, UpdatedReplicas:1, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63687027160, loc:(*time.Location)(0x78fbda0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63687027160, loc:(*time.Location)(0x78fbda0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63687027160, loc:(*time.Location)(0x78fbda0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63687027160, loc:(*time.Location)(0x78fbda0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rolling-update-deployment-65b7695dcf\" is progressing."}}, CollisionCount:(*int32)(nil)}
Mar  1 08:52:42.311: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:2, UpdatedReplicas:1, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63687027160, loc:(*time.Location)(0x78fbda0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63687027160, loc:(*time.Location)(0x78fbda0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63687027160, loc:(*time.Location)(0x78fbda0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63687027160, loc:(*time.Location)(0x78fbda0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rolling-update-deployment-65b7695dcf\" is progressing."}}, CollisionCount:(*int32)(nil)}
Mar  1 08:52:44.310: INFO: Ensuring deployment "test-rolling-update-deployment" has one old replica set (the one it adopted)
[AfterEach] [sig-apps] Deployment
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Mar  1 08:52:44.421: INFO: Deployment "test-rolling-update-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment,GenerateName:,Namespace:e2e-tests-deployment-p5dhw,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-p5dhw/deployments/test-rolling-update-deployment,UID:5e981727-3bff-11e9-b4e8-fa9e8069966e,ResourceVersion:15912,Generation:1,CreationTimestamp:2019-03-01 08:52:40 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,},Annotations:map[string]string{deployment.kubernetes.io/revision: 3546343826724305833,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[{Available True 2019-03-01 08:52:40 +0000 UTC 2019-03-01 08:52:40 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2019-03-01 08:52:42 +0000 UTC 2019-03-01 08:52:40 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-rolling-update-deployment-65b7695dcf" has successfully progressed.}],ReadyReplicas:1,CollisionCount:nil,},}

Mar  1 08:52:44.470: INFO: New ReplicaSet "test-rolling-update-deployment-65b7695dcf" of Deployment "test-rolling-update-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment-65b7695dcf,GenerateName:,Namespace:e2e-tests-deployment-p5dhw,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-p5dhw/replicasets/test-rolling-update-deployment-65b7695dcf,UID:5e9b6aa0-3bff-11e9-b4e8-fa9e8069966e,ResourceVersion:15905,Generation:1,CreationTimestamp:2019-03-01 08:52:40 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 65b7695dcf,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 3546343826724305833,},OwnerReferences:[{apps/v1 Deployment test-rolling-update-deployment 5e981727-3bff-11e9-b4e8-fa9e8069966e 0xc002191027 0xc002191028}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod-template-hash: 65b7695dcf,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 65b7695dcf,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Mar  1 08:52:44.470: INFO: All old ReplicaSets of Deployment "test-rolling-update-deployment":
Mar  1 08:52:44.470: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-controller,GenerateName:,Namespace:e2e-tests-deployment-p5dhw,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-p5dhw/replicasets/test-rolling-update-controller,UID:5b8c5ae2-3bff-11e9-b4e8-fa9e8069966e,ResourceVersion:15911,Generation:2,CreationTimestamp:2019-03-01 08:52:35 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod: nginx,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 3546343826724305832,},OwnerReferences:[{apps/v1 Deployment test-rolling-update-deployment 5e981727-3bff-11e9-b4e8-fa9e8069966e 0xc002190f67 0xc002190f68}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Mar  1 08:52:44.507: INFO: Pod "test-rolling-update-deployment-65b7695dcf-799qc" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment-65b7695dcf-799qc,GenerateName:test-rolling-update-deployment-65b7695dcf-,Namespace:e2e-tests-deployment-p5dhw,SelfLink:/api/v1/namespaces/e2e-tests-deployment-p5dhw/pods/test-rolling-update-deployment-65b7695dcf-799qc,UID:5e9c5e6f-3bff-11e9-b4e8-fa9e8069966e,ResourceVersion:15904,Generation:0,CreationTimestamp:2019-03-01 08:52:40 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 65b7695dcf,},Annotations:map[string]string{cni.projectcalico.org/podIP: 100.96.1.146/32,kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet test-rolling-update-deployment-65b7695dcf 5e9b6aa0-3bff-11e9-b4e8-fa9e8069966e 0xc0021918d7 0xc0021918d8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-9l7cj {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-9l7cj,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-9l7cj true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--pub-az-nl4q9-cpu-worker-7dd9bbfd9c-7fp9l,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002191940} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002191960}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 08:52:40 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 08:52:42 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 08:52:42 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 08:52:40 +0000 UTC  }],Message:,Reason:,HostIP:10.250.0.4,PodIP:100.96.1.146,StartTime:2019-03-01 08:52:40 +0000 UTC,ContainerStatuses:[{redis {nil ContainerStateRunning{StartedAt:2019-03-01 08:52:42 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/redis:1.0 docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830 docker://8e4a59b61bd71db26834a5cc8ba88c74a0cef7137fd939bbc7ffeb7d434e49ea}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 08:52:44.507: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-p5dhw" for this suite.
Mar  1 08:52:52.652: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 08:52:53.400: INFO: namespace: e2e-tests-deployment-p5dhw, resource: bindings, ignored listing per whitelist
Mar  1 08:52:54.011: INFO: namespace e2e-tests-deployment-p5dhw deletion completed in 9.468354276s

• [SLOW TEST:20.731 seconds]
[sig-apps] Deployment
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 08:52:54.012: INFO: >>> kubeConfig: /tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-subpath-qpvgl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with configmap pod [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-configmap-qxxv
STEP: Creating a pod to test atomic-volume-subpath
Mar  1 08:52:55.738: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-qxxv" in namespace "e2e-tests-subpath-qpvgl" to be "success or failure"
Mar  1 08:52:55.776: INFO: Pod "pod-subpath-test-configmap-qxxv": Phase="Pending", Reason="", readiness=false. Elapsed: 37.765892ms
Mar  1 08:52:57.812: INFO: Pod "pod-subpath-test-configmap-qxxv": Phase="Pending", Reason="", readiness=false. Elapsed: 2.073869033s
Mar  1 08:52:59.849: INFO: Pod "pod-subpath-test-configmap-qxxv": Phase="Pending", Reason="", readiness=false. Elapsed: 4.110374278s
Mar  1 08:53:01.887: INFO: Pod "pod-subpath-test-configmap-qxxv": Phase="Running", Reason="", readiness=false. Elapsed: 6.149125724s
Mar  1 08:53:03.925: INFO: Pod "pod-subpath-test-configmap-qxxv": Phase="Running", Reason="", readiness=false. Elapsed: 8.186495291s
Mar  1 08:53:05.962: INFO: Pod "pod-subpath-test-configmap-qxxv": Phase="Running", Reason="", readiness=false. Elapsed: 10.224169543s
Mar  1 08:53:07.999: INFO: Pod "pod-subpath-test-configmap-qxxv": Phase="Running", Reason="", readiness=false. Elapsed: 12.261054519s
Mar  1 08:53:10.036: INFO: Pod "pod-subpath-test-configmap-qxxv": Phase="Running", Reason="", readiness=false. Elapsed: 14.297256384s
Mar  1 08:53:12.077: INFO: Pod "pod-subpath-test-configmap-qxxv": Phase="Running", Reason="", readiness=false. Elapsed: 16.338202566s
Mar  1 08:53:14.113: INFO: Pod "pod-subpath-test-configmap-qxxv": Phase="Running", Reason="", readiness=false. Elapsed: 18.37474342s
Mar  1 08:53:16.150: INFO: Pod "pod-subpath-test-configmap-qxxv": Phase="Running", Reason="", readiness=false. Elapsed: 20.411272257s
Mar  1 08:53:18.186: INFO: Pod "pod-subpath-test-configmap-qxxv": Phase="Running", Reason="", readiness=false. Elapsed: 22.447918019s
Mar  1 08:53:20.222: INFO: Pod "pod-subpath-test-configmap-qxxv": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.483705535s
STEP: Saw pod success
Mar  1 08:53:20.222: INFO: Pod "pod-subpath-test-configmap-qxxv" satisfied condition "success or failure"
Mar  1 08:53:20.257: INFO: Trying to get logs from node shoot--it--pub-az-nl4q9-cpu-worker-7dd9bbfd9c-7fp9l pod pod-subpath-test-configmap-qxxv container test-container-subpath-configmap-qxxv: <nil>
STEP: delete the pod
Mar  1 08:53:20.349: INFO: Waiting for pod pod-subpath-test-configmap-qxxv to disappear
Mar  1 08:53:20.414: INFO: Pod pod-subpath-test-configmap-qxxv no longer exists
STEP: Deleting pod pod-subpath-test-configmap-qxxv
Mar  1 08:53:20.414: INFO: Deleting pod "pod-subpath-test-configmap-qxxv" in namespace "e2e-tests-subpath-qpvgl"
[AfterEach] [sig-storage] Subpath
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 08:53:20.449: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-qpvgl" for this suite.
Mar  1 08:53:26.594: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 08:53:27.909: INFO: namespace: e2e-tests-subpath-qpvgl, resource: bindings, ignored listing per whitelist
Mar  1 08:53:27.944: INFO: namespace e2e-tests-subpath-qpvgl deletion completed in 7.459086569s

• [SLOW TEST:33.932 seconds]
[sig-storage] Subpath
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with configmap pod [Conformance]
    /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-api-machinery] Downward API 
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Downward API
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 08:53:27.944: INFO: >>> kubeConfig: /tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-t75gs
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod UID as env vars [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Mar  1 08:53:29.705: INFO: Waiting up to 5m0s for pod "downward-api-7c1fbb80-3bff-11e9-a72e-ce8290b78775" in namespace "e2e-tests-downward-api-t75gs" to be "success or failure"
Mar  1 08:53:29.741: INFO: Pod "downward-api-7c1fbb80-3bff-11e9-a72e-ce8290b78775": Phase="Pending", Reason="", readiness=false. Elapsed: 36.00294ms
Mar  1 08:53:31.779: INFO: Pod "downward-api-7c1fbb80-3bff-11e9-a72e-ce8290b78775": Phase="Pending", Reason="", readiness=false. Elapsed: 2.073357309s
Mar  1 08:53:33.815: INFO: Pod "downward-api-7c1fbb80-3bff-11e9-a72e-ce8290b78775": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.109416354s
STEP: Saw pod success
Mar  1 08:53:33.815: INFO: Pod "downward-api-7c1fbb80-3bff-11e9-a72e-ce8290b78775" satisfied condition "success or failure"
Mar  1 08:53:33.861: INFO: Trying to get logs from node shoot--it--pub-az-nl4q9-cpu-worker-7dd9bbfd9c-7fp9l pod downward-api-7c1fbb80-3bff-11e9-a72e-ce8290b78775 container dapi-container: <nil>
STEP: delete the pod
Mar  1 08:53:33.957: INFO: Waiting for pod downward-api-7c1fbb80-3bff-11e9-a72e-ce8290b78775 to disappear
Mar  1 08:53:33.992: INFO: Pod downward-api-7c1fbb80-3bff-11e9-a72e-ce8290b78775 no longer exists
[AfterEach] [sig-api-machinery] Downward API
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 08:53:33.992: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-t75gs" for this suite.
Mar  1 08:53:40.145: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 08:53:40.256: INFO: namespace: e2e-tests-downward-api-t75gs, resource: bindings, ignored listing per whitelist
Mar  1 08:53:41.522: INFO: namespace e2e-tests-downward-api-t75gs deletion completed in 7.493455306s

• [SLOW TEST:13.578 seconds]
[sig-api-machinery] Downward API
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform canary updates and phased rolling updates of template modifications [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 08:53:41.523: INFO: >>> kubeConfig: /tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-statefulset-dld8p
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-dld8p
[It] should perform canary updates and phased rolling updates of template modifications [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a new StaefulSet
Mar  1 08:53:43.211: INFO: Found 0 stateful pods, waiting for 3
Mar  1 08:53:53.250: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Mar  1 08:53:53.250: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Mar  1 08:53:53.250: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Updating stateful set template: update image from docker.io/library/nginx:1.14-alpine to docker.io/library/nginx:1.15-alpine
Mar  1 08:53:53.444: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Not applying an update when the partition is greater than the number of replicas
STEP: Performing a canary update
Mar  1 08:53:53.600: INFO: Updating stateful set ss2
Mar  1 08:53:53.676: INFO: Waiting for Pod e2e-tests-statefulset-dld8p/ss2-2 to have revision ss2-c79899b9 update revision ss2-787997d666
STEP: Restoring Pods to the correct revision when they are deleted
Mar  1 08:54:03.905: INFO: Found 2 stateful pods, waiting for 3
Mar  1 08:54:13.942: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Mar  1 08:54:13.942: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Mar  1 08:54:13.942: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Performing a phased rolling update
Mar  1 08:54:14.096: INFO: Updating stateful set ss2
Mar  1 08:54:14.170: INFO: Waiting for Pod e2e-tests-statefulset-dld8p/ss2-1 to have revision ss2-c79899b9 update revision ss2-787997d666
Mar  1 08:54:24.242: INFO: Waiting for Pod e2e-tests-statefulset-dld8p/ss2-1 to have revision ss2-c79899b9 update revision ss2-787997d666
Mar  1 08:54:34.325: INFO: Updating stateful set ss2
Mar  1 08:54:34.398: INFO: Waiting for StatefulSet e2e-tests-statefulset-dld8p/ss2 to complete update
Mar  1 08:54:34.398: INFO: Waiting for Pod e2e-tests-statefulset-dld8p/ss2-0 to have revision ss2-c79899b9 update revision ss2-787997d666
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Mar  1 08:54:44.521: INFO: Deleting all statefulset in ns e2e-tests-statefulset-dld8p
Mar  1 08:54:44.557: INFO: Scaling statefulset ss2 to 0
Mar  1 08:55:14.718: INFO: Waiting for statefulset status.replicas updated to 0
Mar  1 08:55:14.757: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 08:55:14.877: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-dld8p" for this suite.
Mar  1 08:55:23.026: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 08:55:23.941: INFO: namespace: e2e-tests-statefulset-dld8p, resource: bindings, ignored listing per whitelist
Mar  1 08:55:24.473: INFO: namespace e2e-tests-statefulset-dld8p deletion completed in 9.5580684s

• [SLOW TEST:102.950 seconds]
[sig-apps] StatefulSet
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should perform canary updates and phased rolling updates of template modifications [Conformance]
    /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart http hook properly [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 08:55:24.473: INFO: >>> kubeConfig: /tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-container-lifecycle-hook-v6c2p
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart http hook properly [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Mar  1 08:55:34.577: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Mar  1 08:55:34.614: INFO: Pod pod-with-poststart-http-hook still exists
Mar  1 08:55:36.614: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Mar  1 08:55:36.650: INFO: Pod pod-with-poststart-http-hook still exists
Mar  1 08:55:38.614: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Mar  1 08:55:38.651: INFO: Pod pod-with-poststart-http-hook still exists
Mar  1 08:55:40.614: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Mar  1 08:55:40.652: INFO: Pod pod-with-poststart-http-hook still exists
Mar  1 08:55:42.614: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Mar  1 08:55:42.651: INFO: Pod pod-with-poststart-http-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 08:55:42.651: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-lifecycle-hook-v6c2p" for this suite.
Mar  1 08:56:06.799: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 08:56:07.949: INFO: namespace: e2e-tests-container-lifecycle-hook-v6c2p, resource: bindings, ignored listing per whitelist
Mar  1 08:56:08.201: INFO: namespace e2e-tests-container-lifecycle-hook-v6c2p deletion completed in 25.512737906s

• [SLOW TEST:43.728 seconds]
[k8s.io] Container Lifecycle Hook
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when create a pod with lifecycle hook
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute poststart http hook properly [NodeConformance] [Conformance]
    /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 08:56:08.201: INFO: >>> kubeConfig: /tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename namespaces
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-namespaces-gg9zh
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all pods are removed when a namespace is deleted [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a test namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-nsdeletetest-gf5vr
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a pod in the namespace
STEP: Waiting for the pod to have running status
STEP: Creating an uninitialized pod in the namespace
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
Mar  1 08:56:21.520: INFO: error from create uninitialized namespace: Internal error occurred: object deleted while waiting for creation
STEP: Recreating the namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-nsdeletetest-bmfth
STEP: Verifying there are no pods in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 08:56:39.927: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-namespaces-gg9zh" for this suite.
Mar  1 08:56:46.090: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 08:56:47.102: INFO: namespace: e2e-tests-namespaces-gg9zh, resource: bindings, ignored listing per whitelist
Mar  1 08:56:47.529: INFO: namespace e2e-tests-namespaces-gg9zh deletion completed in 7.561308404s
STEP: Destroying namespace "e2e-tests-nsdeletetest-gf5vr" for this suite.
Mar  1 08:56:47.566: INFO: Namespace e2e-tests-nsdeletetest-gf5vr was already deleted
STEP: Destroying namespace "e2e-tests-nsdeletetest-bmfth" for this suite.
Mar  1 08:56:53.675: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 08:56:54.184: INFO: namespace: e2e-tests-nsdeletetest-bmfth, resource: bindings, ignored listing per whitelist
Mar  1 08:56:55.086: INFO: namespace e2e-tests-nsdeletetest-bmfth deletion completed in 7.519594139s

• [SLOW TEST:46.884 seconds]
[sig-api-machinery] Namespaces [Serial]
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] [sig-node] Pods Extended [k8s.io] Pods Set QOS Class 
  should be submitted and removed  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] [sig-node] Pods Extended
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 08:56:55.086: INFO: >>> kubeConfig: /tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-pods-h7tw2
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods Set QOS Class
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/node/pods.go:204
[It] should be submitted and removed  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying QOS class is set on the pod
[AfterEach] [k8s.io] [sig-node] Pods Extended
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 08:56:56.754: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-h7tw2" for this suite.
Mar  1 08:57:18.936: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 08:57:19.046: INFO: namespace: e2e-tests-pods-h7tw2, resource: bindings, ignored listing per whitelist
Mar  1 08:57:20.310: INFO: namespace e2e-tests-pods-h7tw2 deletion completed in 23.519575467s

• [SLOW TEST:25.224 seconds]
[k8s.io] [sig-node] Pods Extended
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  [k8s.io] Pods Set QOS Class
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should be submitted and removed  [Conformance]
    /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-api-machinery] ConfigMap 
  should be consumable via the environment [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] ConfigMap
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 08:57:20.310: INFO: >>> kubeConfig: /tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-f8pkm
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap e2e-tests-configmap-f8pkm/configmap-test-06b574f6-3c00-11e9-a72e-ce8290b78775
STEP: Creating a pod to test consume configMaps
Mar  1 08:57:22.247: INFO: Waiting up to 5m0s for pod "pod-configmaps-06baec29-3c00-11e9-a72e-ce8290b78775" in namespace "e2e-tests-configmap-f8pkm" to be "success or failure"
Mar  1 08:57:22.291: INFO: Pod "pod-configmaps-06baec29-3c00-11e9-a72e-ce8290b78775": Phase="Pending", Reason="", readiness=false. Elapsed: 44.462377ms
Mar  1 08:57:24.328: INFO: Pod "pod-configmaps-06baec29-3c00-11e9-a72e-ce8290b78775": Phase="Pending", Reason="", readiness=false. Elapsed: 2.080875788s
Mar  1 08:57:26.364: INFO: Pod "pod-configmaps-06baec29-3c00-11e9-a72e-ce8290b78775": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.117395351s
STEP: Saw pod success
Mar  1 08:57:26.364: INFO: Pod "pod-configmaps-06baec29-3c00-11e9-a72e-ce8290b78775" satisfied condition "success or failure"
Mar  1 08:57:26.400: INFO: Trying to get logs from node shoot--it--pub-az-nl4q9-cpu-worker-7dd9bbfd9c-7fp9l pod pod-configmaps-06baec29-3c00-11e9-a72e-ce8290b78775 container env-test: <nil>
STEP: delete the pod
Mar  1 08:57:26.495: INFO: Waiting for pod pod-configmaps-06baec29-3c00-11e9-a72e-ce8290b78775 to disappear
Mar  1 08:57:26.532: INFO: Pod pod-configmaps-06baec29-3c00-11e9-a72e-ce8290b78775 no longer exists
[AfterEach] [sig-api-machinery] ConfigMap
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 08:57:26.532: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-f8pkm" for this suite.
Mar  1 08:57:34.680: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 08:57:35.625: INFO: namespace: e2e-tests-configmap-f8pkm, resource: bindings, ignored listing per whitelist
Mar  1 08:57:36.196: INFO: namespace e2e-tests-configmap-f8pkm deletion completed in 9.629052389s

• [SLOW TEST:15.886 seconds]
[sig-api-machinery] ConfigMap
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:30
  should be consumable via the environment [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl replace 
  should update a single-container pod's image  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 08:57:36.196: INFO: >>> kubeConfig: /tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-tk9hm
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Kubectl replace
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1511
[It] should update a single-container pod's image  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Mar  1 08:57:37.780: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-az-nl4q9.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml run e2e-test-nginx-pod --generator=run-pod/v1 --image=docker.io/library/nginx:1.14-alpine --labels=run=e2e-test-nginx-pod --namespace=e2e-tests-kubectl-tk9hm'
Mar  1 08:57:38.177: INFO: stderr: ""
Mar  1 08:57:38.177: INFO: stdout: "pod/e2e-test-nginx-pod created\n"
STEP: verifying the pod e2e-test-nginx-pod is running
STEP: verifying the pod e2e-test-nginx-pod was created
Mar  1 08:57:43.230: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-az-nl4q9.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml get pod e2e-test-nginx-pod --namespace=e2e-tests-kubectl-tk9hm -o json'
Mar  1 08:57:43.521: INFO: stderr: ""
Mar  1 08:57:43.521: INFO: stdout: "{\n    \"apiVersion\": \"v1\",\n    \"kind\": \"Pod\",\n    \"metadata\": {\n        \"annotations\": {\n            \"cni.projectcalico.org/podIP\": \"100.96.1.161/32\",\n            \"kubernetes.io/psp\": \"e2e-test-privileged-psp\"\n        },\n        \"creationTimestamp\": \"2019-03-01T08:57:38Z\",\n        \"labels\": {\n            \"run\": \"e2e-test-nginx-pod\"\n        },\n        \"name\": \"e2e-test-nginx-pod\",\n        \"namespace\": \"e2e-tests-kubectl-tk9hm\",\n        \"resourceVersion\": \"16841\",\n        \"selfLink\": \"/api/v1/namespaces/e2e-tests-kubectl-tk9hm/pods/e2e-test-nginx-pod\",\n        \"uid\": \"103b11a9-3c00-11e9-b4e8-fa9e8069966e\"\n    },\n    \"spec\": {\n        \"containers\": [\n            {\n                \"image\": \"docker.io/library/nginx:1.14-alpine\",\n                \"imagePullPolicy\": \"IfNotPresent\",\n                \"name\": \"e2e-test-nginx-pod\",\n                \"resources\": {},\n                \"terminationMessagePath\": \"/dev/termination-log\",\n                \"terminationMessagePolicy\": \"File\",\n                \"volumeMounts\": [\n                    {\n                        \"mountPath\": \"/var/run/secrets/kubernetes.io/serviceaccount\",\n                        \"name\": \"default-token-j72l8\",\n                        \"readOnly\": true\n                    }\n                ]\n            }\n        ],\n        \"dnsPolicy\": \"ClusterFirst\",\n        \"nodeName\": \"shoot--it--pub-az-nl4q9-cpu-worker-7dd9bbfd9c-7fp9l\",\n        \"priority\": 0,\n        \"restartPolicy\": \"Always\",\n        \"schedulerName\": \"default-scheduler\",\n        \"securityContext\": {},\n        \"serviceAccount\": \"default\",\n        \"serviceAccountName\": \"default\",\n        \"terminationGracePeriodSeconds\": 30,\n        \"tolerations\": [\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/not-ready\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            },\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/unreachable\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            }\n        ],\n        \"volumes\": [\n            {\n                \"name\": \"default-token-j72l8\",\n                \"secret\": {\n                    \"defaultMode\": 420,\n                    \"secretName\": \"default-token-j72l8\"\n                }\n            }\n        ]\n    },\n    \"status\": {\n        \"conditions\": [\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-03-01T08:57:38Z\",\n                \"status\": \"True\",\n                \"type\": \"Initialized\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-03-01T08:57:40Z\",\n                \"status\": \"True\",\n                \"type\": \"Ready\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-03-01T08:57:40Z\",\n                \"status\": \"True\",\n                \"type\": \"ContainersReady\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-03-01T08:57:38Z\",\n                \"status\": \"True\",\n                \"type\": \"PodScheduled\"\n            }\n        ],\n        \"containerStatuses\": [\n            {\n                \"containerID\": \"docker://49dc29bd5105d8df1004fcd4a008ca4b418d533efd353682a9ba599ad26a0717\",\n                \"image\": \"nginx:1.14-alpine\",\n                \"imageID\": \"docker-pullable://nginx@sha256:b96aeeb1687703c49096f4969358d44f8520b671da94848309a3ba5be5b4c632\",\n                \"lastState\": {},\n                \"name\": \"e2e-test-nginx-pod\",\n                \"ready\": true,\n                \"restartCount\": 0,\n                \"state\": {\n                    \"running\": {\n                        \"startedAt\": \"2019-03-01T08:57:40Z\"\n                    }\n                }\n            }\n        ],\n        \"hostIP\": \"10.250.0.4\",\n        \"phase\": \"Running\",\n        \"podIP\": \"100.96.1.161\",\n        \"qosClass\": \"BestEffort\",\n        \"startTime\": \"2019-03-01T08:57:38Z\"\n    }\n}\n"
STEP: replace the image in the pod
Mar  1 08:57:43.521: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-az-nl4q9.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml replace -f - --namespace=e2e-tests-kubectl-tk9hm'
Mar  1 08:57:43.983: INFO: stderr: ""
Mar  1 08:57:43.983: INFO: stdout: "pod/e2e-test-nginx-pod replaced\n"
STEP: verifying the pod e2e-test-nginx-pod has the right image docker.io/library/busybox:1.29
[AfterEach] [k8s.io] Kubectl replace
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1516
Mar  1 08:57:44.024: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-az-nl4q9.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml delete pods e2e-test-nginx-pod --namespace=e2e-tests-kubectl-tk9hm'
Mar  1 08:57:51.220: INFO: stderr: ""
Mar  1 08:57:51.220: INFO: stdout: "pod \"e2e-test-nginx-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 08:57:51.220: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-tk9hm" for this suite.
Mar  1 08:57:59.364: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 08:58:00.160: INFO: namespace: e2e-tests-kubectl-tk9hm, resource: bindings, ignored listing per whitelist
Mar  1 08:58:00.729: INFO: namespace e2e-tests-kubectl-tk9hm deletion completed in 9.472896889s

• [SLOW TEST:24.533 seconds]
[sig-cli] Kubectl client
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl replace
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should update a single-container pod's image  [Conformance]
    /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 08:58:00.730: INFO: >>> kubeConfig: /tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-fqp7v
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Mar  1 08:58:02.335: INFO: Waiting up to 5m0s for pod "downwardapi-volume-1e9fce2c-3c00-11e9-a72e-ce8290b78775" in namespace "e2e-tests-downward-api-fqp7v" to be "success or failure"
Mar  1 08:58:02.370: INFO: Pod "downwardapi-volume-1e9fce2c-3c00-11e9-a72e-ce8290b78775": Phase="Pending", Reason="", readiness=false. Elapsed: 35.092673ms
Mar  1 08:58:04.407: INFO: Pod "downwardapi-volume-1e9fce2c-3c00-11e9-a72e-ce8290b78775": Phase="Pending", Reason="", readiness=false. Elapsed: 2.071548309s
Mar  1 08:58:06.444: INFO: Pod "downwardapi-volume-1e9fce2c-3c00-11e9-a72e-ce8290b78775": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.108337299s
STEP: Saw pod success
Mar  1 08:58:06.444: INFO: Pod "downwardapi-volume-1e9fce2c-3c00-11e9-a72e-ce8290b78775" satisfied condition "success or failure"
Mar  1 08:58:06.479: INFO: Trying to get logs from node shoot--it--pub-az-nl4q9-cpu-worker-7dd9bbfd9c-7fp9l pod downwardapi-volume-1e9fce2c-3c00-11e9-a72e-ce8290b78775 container client-container: <nil>
STEP: delete the pod
Mar  1 08:58:06.569: INFO: Waiting for pod downwardapi-volume-1e9fce2c-3c00-11e9-a72e-ce8290b78775 to disappear
Mar  1 08:58:06.606: INFO: Pod downwardapi-volume-1e9fce2c-3c00-11e9-a72e-ce8290b78775 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 08:58:06.607: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-fqp7v" for this suite.
Mar  1 08:58:12.759: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 08:58:12.867: INFO: namespace: e2e-tests-downward-api-fqp7v, resource: bindings, ignored listing per whitelist
Mar  1 08:58:14.142: INFO: namespace e2e-tests-downward-api-fqp7v deletion completed in 7.497550881s

• [SLOW TEST:13.412 seconds]
[sig-storage] Downward API volume
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's cpu limit [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] ConfigMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 08:58:14.142: INFO: >>> kubeConfig: /tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-ngnc8
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name cm-test-opt-del-26bdc80f-3c00-11e9-a72e-ce8290b78775
STEP: Creating configMap with name cm-test-opt-upd-26bdc867-3c00-11e9-a72e-ce8290b78775
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-26bdc80f-3c00-11e9-a72e-ce8290b78775
STEP: Updating configmap cm-test-opt-upd-26bdc867-3c00-11e9-a72e-ce8290b78775
STEP: Creating configMap with name cm-test-opt-create-26bdc8c7-3c00-11e9-a72e-ce8290b78775
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 08:59:48.785: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-ngnc8" for this suite.
Mar  1 09:00:10.939: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 09:00:11.677: INFO: namespace: e2e-tests-configmap-ngnc8, resource: bindings, ignored listing per whitelist
Mar  1 09:00:12.415: INFO: namespace e2e-tests-configmap-ngnc8 deletion completed in 23.594248159s

• [SLOW TEST:118.273 seconds]
[sig-storage] ConfigMap
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl api-versions 
  should check if v1 is in available api versions  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 09:00:12.416: INFO: >>> kubeConfig: /tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-kgbrg
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should check if v1 is in available api versions  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: validating api versions
Mar  1 09:00:13.985: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-az-nl4q9.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml api-versions'
Mar  1 09:00:14.459: INFO: stderr: ""
Mar  1 09:00:14.459: INFO: stdout: "admissionregistration.k8s.io/v1alpha1\nadmissionregistration.k8s.io/v1beta1\napiextensions.k8s.io/v1beta1\napiregistration.k8s.io/v1\napiregistration.k8s.io/v1beta1\napps/v1\napps/v1beta1\napps/v1beta2\nauthentication.k8s.io/v1\nauthentication.k8s.io/v1beta1\nauthorization.k8s.io/v1\nauthorization.k8s.io/v1beta1\nautoscaling/v1\nautoscaling/v2beta1\nautoscaling/v2beta2\nbatch/v1\nbatch/v1beta1\ncertificates.k8s.io/v1beta1\ncoordination.k8s.io/v1beta1\ncrd.projectcalico.org/v1\nevents.k8s.io/v1beta1\nextensions/v1beta1\nmetrics.k8s.io/v1beta1\nnetworking.k8s.io/v1\npolicy/v1beta1\nrbac.authorization.k8s.io/v1\nrbac.authorization.k8s.io/v1beta1\nscheduling.k8s.io/v1beta1\nstorage.k8s.io/v1\nstorage.k8s.io/v1beta1\nv1\n"
[AfterEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 09:00:14.459: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-kgbrg" for this suite.
Mar  1 09:00:20.609: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 09:00:21.228: INFO: namespace: e2e-tests-kubectl-kgbrg, resource: bindings, ignored listing per whitelist
Mar  1 09:00:22.018: INFO: namespace e2e-tests-kubectl-kgbrg deletion completed in 7.521609064s

• [SLOW TEST:9.602 seconds]
[sig-cli] Kubectl client
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl api-versions
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should check if v1 is in available api versions  [Conformance]
    /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should update labels on modification [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 09:00:22.018: INFO: >>> kubeConfig: /tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-rr7gr
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should update labels on modification [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating the pod
Mar  1 09:00:28.391: INFO: Successfully updated pod "labelsupdate72dcbfbd-3c00-11e9-a72e-ce8290b78775"
[AfterEach] [sig-storage] Downward API volume
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 09:00:32.542: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-rr7gr" for this suite.
Mar  1 09:00:54.686: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 09:00:55.492: INFO: namespace: e2e-tests-downward-api-rr7gr, resource: bindings, ignored listing per whitelist
Mar  1 09:00:56.169: INFO: namespace e2e-tests-downward-api-rr7gr deletion completed in 23.591910917s

• [SLOW TEST:34.151 seconds]
[sig-storage] Downward API volume
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should update labels on modification [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-apps] Deployment 
  deployment should support proportional scaling [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 09:00:56.170: INFO: >>> kubeConfig: /tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-deployment-5z82f
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should support proportional scaling [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Mar  1 09:00:57.803: INFO: Creating deployment "nginx-deployment"
Mar  1 09:00:57.843: INFO: Waiting for observed generation 1
Mar  1 09:00:57.890: INFO: Waiting for all required pods to come up
Mar  1 09:00:57.950: INFO: Pod name nginx: Found 10 pods out of 10
STEP: ensuring each pod is running
Mar  1 09:01:14.035: INFO: Waiting for deployment "nginx-deployment" to complete
Mar  1 09:01:14.124: INFO: Updating deployment "nginx-deployment" with a non-existent image
Mar  1 09:01:14.196: INFO: Updating deployment nginx-deployment
Mar  1 09:01:14.196: INFO: Waiting for observed generation 2
Mar  1 09:01:16.300: INFO: Waiting for the first rollout's replicaset to have .status.availableReplicas = 8
Mar  1 09:01:16.338: INFO: Waiting for the first rollout's replicaset to have .spec.replicas = 8
Mar  1 09:01:16.374: INFO: Waiting for the first rollout's replicaset of deployment "nginx-deployment" to have desired number of replicas
Mar  1 09:01:16.528: INFO: Verifying that the second rollout's replicaset has .status.availableReplicas = 0
Mar  1 09:01:16.528: INFO: Waiting for the second rollout's replicaset to have .spec.replicas = 5
Mar  1 09:01:16.564: INFO: Waiting for the second rollout's replicaset of deployment "nginx-deployment" to have desired number of replicas
Mar  1 09:01:16.636: INFO: Verifying that deployment "nginx-deployment" has minimum required number of available replicas
Mar  1 09:01:16.636: INFO: Scaling up the deployment "nginx-deployment" from 10 to 30
Mar  1 09:01:16.709: INFO: Updating deployment nginx-deployment
Mar  1 09:01:16.709: INFO: Waiting for the replicasets of deployment "nginx-deployment" to have desired number of replicas
Mar  1 09:01:16.810: INFO: Verifying that first rollout's replicaset has .spec.replicas = 20
Mar  1 09:01:18.894: INFO: Verifying that second rollout's replicaset has .spec.replicas = 13
[AfterEach] [sig-apps] Deployment
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Mar  1 09:01:18.970: INFO: Deployment "nginx-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment,GenerateName:,Namespace:e2e-tests-deployment-5z82f,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-5z82f/deployments/nginx-deployment,UID:873ea3df-3c00-11e9-b4e8-fa9e8069966e,ResourceVersion:17534,Generation:3,CreationTimestamp:2019-03-01 09:00:57 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*30,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:2,MaxSurge:3,},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:3,Replicas:33,UpdatedReplicas:13,AvailableReplicas:8,UnavailableReplicas:25,Conditions:[{Available False 2019-03-01 09:01:16 +0000 UTC 2019-03-01 09:01:16 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.} {Progressing True 2019-03-01 09:01:17 +0000 UTC 2019-03-01 09:00:57 +0000 UTC ReplicaSetUpdated ReplicaSet "nginx-deployment-7dc8f79789" is progressing.}],ReadyReplicas:8,CollisionCount:nil,},}

Mar  1 09:01:19.006: INFO: New ReplicaSet "nginx-deployment-7dc8f79789" of Deployment "nginx-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789,GenerateName:,Namespace:e2e-tests-deployment-5z82f,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-5z82f/replicasets/nginx-deployment-7dc8f79789,UID:90fefe92-3c00-11e9-b4e8-fa9e8069966e,ResourceVersion:17533,Generation:3,CreationTimestamp:2019-03-01 09:01:14 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 30,deployment.kubernetes.io/max-replicas: 33,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment nginx-deployment 873ea3df-3c00-11e9-b4e8-fa9e8069966e 0xc001c5dd57 0xc001c5dd58}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*13,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:13,FullyLabeledReplicas:13,ObservedGeneration:3,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Mar  1 09:01:19.006: INFO: All old ReplicaSets of Deployment "nginx-deployment":
Mar  1 09:01:19.006: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b,GenerateName:,Namespace:e2e-tests-deployment-5z82f,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-5z82f/replicasets/nginx-deployment-7f9675fb8b,UID:873fe46e-3c00-11e9-b4e8-fa9e8069966e,ResourceVersion:17531,Generation:3,CreationTimestamp:2019-03-01 09:00:57 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 30,deployment.kubernetes.io/max-replicas: 33,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment nginx-deployment 873ea3df-3c00-11e9-b4e8-fa9e8069966e 0xc001364477 0xc001364478}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*20,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:20,FullyLabeledReplicas:20,ObservedGeneration:3,ReadyReplicas:8,AvailableReplicas:8,Conditions:[],},}
Mar  1 09:01:19.047: INFO: Pod "nginx-deployment-7dc8f79789-7xnd5" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-7xnd5,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-5z82f,SelfLink:/api/v1/namespaces/e2e-tests-deployment-5z82f/pods/nginx-deployment-7dc8f79789-7xnd5,UID:92865208-3c00-11e9-b4e8-fa9e8069966e,ResourceVersion:17505,Generation:0,CreationTimestamp:2019-03-01 09:01:16 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 90fefe92-3c00-11e9-b4e8-fa9e8069966e 0xc00123cb97 0xc00123cb98}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-4867m {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-4867m,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-4867m true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--pub-az-nl4q9-cpu-worker-7dd9bbfd9c-gwjjt,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00123cc30} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00123cc50}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 09:01:16 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-01 09:01:16 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-01 09:01:16 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 09:01:16 +0000 UTC  }],Message:,Reason:,HostIP:10.250.0.5,PodIP:,StartTime:2019-03-01 09:01:16 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar  1 09:01:19.048: INFO: Pod "nginx-deployment-7dc8f79789-bm79q" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-bm79q,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-5z82f,SelfLink:/api/v1/namespaces/e2e-tests-deployment-5z82f/pods/nginx-deployment-7dc8f79789-bm79q,UID:92885e26-3c00-11e9-b4e8-fa9e8069966e,ResourceVersion:17520,Generation:0,CreationTimestamp:2019-03-01 09:01:16 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 90fefe92-3c00-11e9-b4e8-fa9e8069966e 0xc00123ce40 0xc00123ce41}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-4867m {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-4867m,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-4867m true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--pub-az-nl4q9-cpu-worker-7dd9bbfd9c-gwjjt,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00123cf20} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00123cf40}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 09:01:16 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-01 09:01:16 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-01 09:01:16 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 09:01:16 +0000 UTC  }],Message:,Reason:,HostIP:10.250.0.5,PodIP:,StartTime:2019-03-01 09:01:16 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar  1 09:01:19.048: INFO: Pod "nginx-deployment-7dc8f79789-cw5cc" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-cw5cc,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-5z82f,SelfLink:/api/v1/namespaces/e2e-tests-deployment-5z82f/pods/nginx-deployment-7dc8f79789-cw5cc,UID:9295aeba-3c00-11e9-b4e8-fa9e8069966e,ResourceVersion:17515,Generation:0,CreationTimestamp:2019-03-01 09:01:16 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 90fefe92-3c00-11e9-b4e8-fa9e8069966e 0xc00123d050 0xc00123d051}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-4867m {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-4867m,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-4867m true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--pub-az-nl4q9-cpu-worker-7dd9bbfd9c-7fp9l,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00123d290} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00123d2c0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 09:01:16 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar  1 09:01:19.048: INFO: Pod "nginx-deployment-7dc8f79789-f6cmq" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-f6cmq,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-5z82f,SelfLink:/api/v1/namespaces/e2e-tests-deployment-5z82f/pods/nginx-deployment-7dc8f79789-f6cmq,UID:9130ce78-3c00-11e9-b4e8-fa9e8069966e,ResourceVersion:17462,Generation:0,CreationTimestamp:2019-03-01 09:01:14 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 90fefe92-3c00-11e9-b4e8-fa9e8069966e 0xc00123d380 0xc00123d381}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-4867m {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-4867m,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-4867m true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--pub-az-nl4q9-cpu-worker-7dd9bbfd9c-7fp9l,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00123d4f0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00123d510}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 09:01:15 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-01 09:01:15 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-01 09:01:15 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 09:01:14 +0000 UTC  }],Message:,Reason:,HostIP:10.250.0.4,PodIP:,StartTime:2019-03-01 09:01:15 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar  1 09:01:19.048: INFO: Pod "nginx-deployment-7dc8f79789-kgzz2" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-kgzz2,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-5z82f,SelfLink:/api/v1/namespaces/e2e-tests-deployment-5z82f/pods/nginx-deployment-7dc8f79789-kgzz2,UID:9101524d-3c00-11e9-b4e8-fa9e8069966e,ResourceVersion:17537,Generation:0,CreationTimestamp:2019-03-01 09:01:14 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{cni.projectcalico.org/podIP: 100.96.0.43/32,kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 90fefe92-3c00-11e9-b4e8-fa9e8069966e 0xc00123d6d0 0xc00123d6d1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-4867m {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-4867m,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-4867m true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--pub-az-nl4q9-cpu-worker-7dd9bbfd9c-gwjjt,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00123d7e0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00123d840}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 09:01:14 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-01 09:01:14 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-01 09:01:14 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 09:01:14 +0000 UTC  }],Message:,Reason:,HostIP:10.250.0.5,PodIP:100.96.0.43,StartTime:2019-03-01 09:01:14 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = Error response from daemon: manifest for nginx:404 not found,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar  1 09:01:19.048: INFO: Pod "nginx-deployment-7dc8f79789-khnln" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-khnln,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-5z82f,SelfLink:/api/v1/namespaces/e2e-tests-deployment-5z82f/pods/nginx-deployment-7dc8f79789-khnln,UID:9129b207-3c00-11e9-b4e8-fa9e8069966e,ResourceVersion:17467,Generation:0,CreationTimestamp:2019-03-01 09:01:14 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{cni.projectcalico.org/podIP: 100.96.0.44/32,kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 90fefe92-3c00-11e9-b4e8-fa9e8069966e 0xc00123da50 0xc00123da51}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-4867m {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-4867m,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-4867m true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--pub-az-nl4q9-cpu-worker-7dd9bbfd9c-gwjjt,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00123db40} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00123db60}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 09:01:14 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-01 09:01:14 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-01 09:01:14 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 09:01:14 +0000 UTC  }],Message:,Reason:,HostIP:10.250.0.5,PodIP:,StartTime:2019-03-01 09:01:14 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar  1 09:01:19.048: INFO: Pod "nginx-deployment-7dc8f79789-l8lb4" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-l8lb4,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-5z82f,SelfLink:/api/v1/namespaces/e2e-tests-deployment-5z82f/pods/nginx-deployment-7dc8f79789-l8lb4,UID:92864853-3c00-11e9-b4e8-fa9e8069966e,ResourceVersion:17525,Generation:0,CreationTimestamp:2019-03-01 09:01:16 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 90fefe92-3c00-11e9-b4e8-fa9e8069966e 0xc00123dd90 0xc00123dd91}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-4867m {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-4867m,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-4867m true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--pub-az-nl4q9-cpu-worker-7dd9bbfd9c-7fp9l,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00123deb0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00123ded0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 09:01:16 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-01 09:01:16 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-01 09:01:16 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 09:01:16 +0000 UTC  }],Message:,Reason:,HostIP:10.250.0.4,PodIP:,StartTime:2019-03-01 09:01:16 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar  1 09:01:19.049: INFO: Pod "nginx-deployment-7dc8f79789-nhsk5" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-nhsk5,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-5z82f,SelfLink:/api/v1/namespaces/e2e-tests-deployment-5z82f/pods/nginx-deployment-7dc8f79789-nhsk5,UID:92884bc2-3c00-11e9-b4e8-fa9e8069966e,ResourceVersion:17540,Generation:0,CreationTimestamp:2019-03-01 09:01:16 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 90fefe92-3c00-11e9-b4e8-fa9e8069966e 0xc00123df90 0xc00123df91}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-4867m {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-4867m,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-4867m true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--pub-az-nl4q9-cpu-worker-7dd9bbfd9c-7fp9l,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001916000} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001916160}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 09:01:18 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-01 09:01:18 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-01 09:01:18 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 09:01:16 +0000 UTC  }],Message:,Reason:,HostIP:10.250.0.4,PodIP:,StartTime:2019-03-01 09:01:18 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar  1 09:01:19.049: INFO: Pod "nginx-deployment-7dc8f79789-phlrb" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-phlrb,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-5z82f,SelfLink:/api/v1/namespaces/e2e-tests-deployment-5z82f/pods/nginx-deployment-7dc8f79789-phlrb,UID:92884da1-3c00-11e9-b4e8-fa9e8069966e,ResourceVersion:17522,Generation:0,CreationTimestamp:2019-03-01 09:01:16 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 90fefe92-3c00-11e9-b4e8-fa9e8069966e 0xc001916230 0xc001916231}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-4867m {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-4867m,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-4867m true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--pub-az-nl4q9-cpu-worker-7dd9bbfd9c-gwjjt,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001916400} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001916420}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 09:01:16 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-01 09:01:16 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-01 09:01:16 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 09:01:16 +0000 UTC  }],Message:,Reason:,HostIP:10.250.0.5,PodIP:,StartTime:2019-03-01 09:01:16 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar  1 09:01:19.049: INFO: Pod "nginx-deployment-7dc8f79789-qczfs" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-qczfs,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-5z82f,SelfLink:/api/v1/namespaces/e2e-tests-deployment-5z82f/pods/nginx-deployment-7dc8f79789-qczfs,UID:910151aa-3c00-11e9-b4e8-fa9e8069966e,ResourceVersion:17461,Generation:0,CreationTimestamp:2019-03-01 09:01:14 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 90fefe92-3c00-11e9-b4e8-fa9e8069966e 0xc001916590 0xc001916591}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-4867m {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-4867m,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-4867m true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--pub-az-nl4q9-cpu-worker-7dd9bbfd9c-7fp9l,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0019167c0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0019167e0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 09:01:15 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-01 09:01:15 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-01 09:01:15 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 09:01:14 +0000 UTC  }],Message:,Reason:,HostIP:10.250.0.4,PodIP:,StartTime:2019-03-01 09:01:15 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar  1 09:01:19.049: INFO: Pod "nginx-deployment-7dc8f79789-sz48w" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-sz48w,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-5z82f,SelfLink:/api/v1/namespaces/e2e-tests-deployment-5z82f/pods/nginx-deployment-7dc8f79789-sz48w,UID:927fe6f8-3c00-11e9-b4e8-fa9e8069966e,ResourceVersion:17503,Generation:0,CreationTimestamp:2019-03-01 09:01:16 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 90fefe92-3c00-11e9-b4e8-fa9e8069966e 0xc001916ae0 0xc001916ae1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-4867m {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-4867m,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-4867m true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--pub-az-nl4q9-cpu-worker-7dd9bbfd9c-gwjjt,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001916d00} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001916d20}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 09:01:16 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-01 09:01:16 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-01 09:01:16 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 09:01:16 +0000 UTC  }],Message:,Reason:,HostIP:10.250.0.5,PodIP:,StartTime:2019-03-01 09:01:16 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar  1 09:01:19.050: INFO: Pod "nginx-deployment-7dc8f79789-vb7gd" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-vb7gd,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-5z82f,SelfLink:/api/v1/namespaces/e2e-tests-deployment-5z82f/pods/nginx-deployment-7dc8f79789-vb7gd,UID:90ffa23e-3c00-11e9-b4e8-fa9e8069966e,ResourceVersion:17446,Generation:0,CreationTimestamp:2019-03-01 09:01:14 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 90fefe92-3c00-11e9-b4e8-fa9e8069966e 0xc001916f10 0xc001916f11}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-4867m {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-4867m,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-4867m true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--pub-az-nl4q9-cpu-worker-7dd9bbfd9c-7fp9l,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001916f80} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001916fa0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 09:01:14 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-01 09:01:14 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-01 09:01:14 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 09:01:14 +0000 UTC  }],Message:,Reason:,HostIP:10.250.0.4,PodIP:,StartTime:2019-03-01 09:01:14 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar  1 09:01:19.050: INFO: Pod "nginx-deployment-7dc8f79789-zf6d4" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-zf6d4,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-5z82f,SelfLink:/api/v1/namespaces/e2e-tests-deployment-5z82f/pods/nginx-deployment-7dc8f79789-zf6d4,UID:92885cf0-3c00-11e9-b4e8-fa9e8069966e,ResourceVersion:17501,Generation:0,CreationTimestamp:2019-03-01 09:01:16 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 90fefe92-3c00-11e9-b4e8-fa9e8069966e 0xc001917120 0xc001917121}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-4867m {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-4867m,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-4867m true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--pub-az-nl4q9-cpu-worker-7dd9bbfd9c-7fp9l,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001917190} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0019171b0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 09:01:16 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar  1 09:01:19.050: INFO: Pod "nginx-deployment-7f9675fb8b-5jz2x" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-5jz2x,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-5z82f,SelfLink:/api/v1/namespaces/e2e-tests-deployment-5z82f/pods/nginx-deployment-7f9675fb8b-5jz2x,UID:9295a125-3c00-11e9-b4e8-fa9e8069966e,ResourceVersion:17514,Generation:0,CreationTimestamp:2019-03-01 09:01:16 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 873fe46e-3c00-11e9-b4e8-fa9e8069966e 0xc001917220 0xc001917221}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-4867m {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-4867m,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-4867m true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--pub-az-nl4q9-cpu-worker-7dd9bbfd9c-7fp9l,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001917360} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001917380}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 09:01:16 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar  1 09:01:19.051: INFO: Pod "nginx-deployment-7f9675fb8b-6wdss" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-6wdss,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-5z82f,SelfLink:/api/v1/namespaces/e2e-tests-deployment-5z82f/pods/nginx-deployment-7f9675fb8b-6wdss,UID:92883f21-3c00-11e9-b4e8-fa9e8069966e,ResourceVersion:17519,Generation:0,CreationTimestamp:2019-03-01 09:01:16 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 873fe46e-3c00-11e9-b4e8-fa9e8069966e 0xc001917470 0xc001917471}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-4867m {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-4867m,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-4867m true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--pub-az-nl4q9-cpu-worker-7dd9bbfd9c-gwjjt,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0019174d0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0019174f0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 09:01:16 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-01 09:01:16 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-01 09:01:16 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 09:01:16 +0000 UTC  }],Message:,Reason:,HostIP:10.250.0.5,PodIP:,StartTime:2019-03-01 09:01:16 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar  1 09:01:19.051: INFO: Pod "nginx-deployment-7f9675fb8b-8cks2" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-8cks2,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-5z82f,SelfLink:/api/v1/namespaces/e2e-tests-deployment-5z82f/pods/nginx-deployment-7f9675fb8b-8cks2,UID:92959f87-3c00-11e9-b4e8-fa9e8069966e,ResourceVersion:17523,Generation:0,CreationTimestamp:2019-03-01 09:01:16 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 873fe46e-3c00-11e9-b4e8-fa9e8069966e 0xc001cb2040 0xc001cb2041}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-4867m {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-4867m,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-4867m true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--pub-az-nl4q9-cpu-worker-7dd9bbfd9c-gwjjt,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001cb2260} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001cb2280}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 09:01:16 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-01 09:01:16 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-01 09:01:16 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 09:01:16 +0000 UTC  }],Message:,Reason:,HostIP:10.250.0.5,PodIP:,StartTime:2019-03-01 09:01:16 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar  1 09:01:19.051: INFO: Pod "nginx-deployment-7f9675fb8b-8qlfp" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-8qlfp,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-5z82f,SelfLink:/api/v1/namespaces/e2e-tests-deployment-5z82f/pods/nginx-deployment-7f9675fb8b-8qlfp,UID:927fdffc-3c00-11e9-b4e8-fa9e8069966e,ResourceVersion:17504,Generation:0,CreationTimestamp:2019-03-01 09:01:16 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 873fe46e-3c00-11e9-b4e8-fa9e8069966e 0xc001cb2330 0xc001cb2331}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-4867m {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-4867m,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-4867m true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--pub-az-nl4q9-cpu-worker-7dd9bbfd9c-gwjjt,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001cb2390} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001cb23b0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 09:01:16 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-01 09:01:16 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-01 09:01:16 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 09:01:16 +0000 UTC  }],Message:,Reason:,HostIP:10.250.0.5,PodIP:,StartTime:2019-03-01 09:01:16 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar  1 09:01:19.052: INFO: Pod "nginx-deployment-7f9675fb8b-9jnrd" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-9jnrd,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-5z82f,SelfLink:/api/v1/namespaces/e2e-tests-deployment-5z82f/pods/nginx-deployment-7f9675fb8b-9jnrd,UID:8744efe8-3c00-11e9-b4e8-fa9e8069966e,ResourceVersion:17375,Generation:0,CreationTimestamp:2019-03-01 09:00:57 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{cni.projectcalico.org/podIP: 100.96.0.42/32,kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 873fe46e-3c00-11e9-b4e8-fa9e8069966e 0xc001cb2520 0xc001cb2521}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-4867m {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-4867m,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-4867m true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--pub-az-nl4q9-cpu-worker-7dd9bbfd9c-gwjjt,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001cb2580} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001cb25a0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 09:00:57 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 09:01:02 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 09:01:02 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 09:00:57 +0000 UTC  }],Message:,Reason:,HostIP:10.250.0.5,PodIP:100.96.0.42,StartTime:2019-03-01 09:00:57 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-03-01 09:01:01 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:b96aeeb1687703c49096f4969358d44f8520b671da94848309a3ba5be5b4c632 docker://ffb8747cd25acc12ce750f427f7ce063b9e8bf19c0334cb11ffa862070e3843d}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar  1 09:01:19.052: INFO: Pod "nginx-deployment-7f9675fb8b-fb6sk" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-fb6sk,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-5z82f,SelfLink:/api/v1/namespaces/e2e-tests-deployment-5z82f/pods/nginx-deployment-7f9675fb8b-fb6sk,UID:92863d66-3c00-11e9-b4e8-fa9e8069966e,ResourceVersion:17521,Generation:0,CreationTimestamp:2019-03-01 09:01:16 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 873fe46e-3c00-11e9-b4e8-fa9e8069966e 0xc001cb2660 0xc001cb2661}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-4867m {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-4867m,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-4867m true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--pub-az-nl4q9-cpu-worker-7dd9bbfd9c-7fp9l,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001cb27e0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001cb2800}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 09:01:16 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-01 09:01:16 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-01 09:01:16 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 09:01:16 +0000 UTC  }],Message:,Reason:,HostIP:10.250.0.4,PodIP:,StartTime:2019-03-01 09:01:16 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar  1 09:01:19.052: INFO: Pod "nginx-deployment-7f9675fb8b-fcqxs" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-fcqxs,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-5z82f,SelfLink:/api/v1/namespaces/e2e-tests-deployment-5z82f/pods/nginx-deployment-7f9675fb8b-fcqxs,UID:8744f027-3c00-11e9-b4e8-fa9e8069966e,ResourceVersion:17418,Generation:0,CreationTimestamp:2019-03-01 09:00:57 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{cni.projectcalico.org/podIP: 100.96.1.167/32,kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 873fe46e-3c00-11e9-b4e8-fa9e8069966e 0xc001cb2b20 0xc001cb2b21}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-4867m {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-4867m,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-4867m true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--pub-az-nl4q9-cpu-worker-7dd9bbfd9c-7fp9l,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001cb2b80} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001cb2ba0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 09:00:59 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 09:01:11 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 09:01:11 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 09:00:57 +0000 UTC  }],Message:,Reason:,HostIP:10.250.0.4,PodIP:100.96.1.167,StartTime:2019-03-01 09:00:59 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-03-01 09:01:09 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:b96aeeb1687703c49096f4969358d44f8520b671da94848309a3ba5be5b4c632 docker://54094ad020d9bc3942da6a04435f7d0f589486b73d728477c33a8209a4d74280}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar  1 09:01:19.053: INFO: Pod "nginx-deployment-7f9675fb8b-gr7vg" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-gr7vg,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-5z82f,SelfLink:/api/v1/namespaces/e2e-tests-deployment-5z82f/pods/nginx-deployment-7f9675fb8b-gr7vg,UID:927f1673-3c00-11e9-b4e8-fa9e8069966e,ResourceVersion:17506,Generation:0,CreationTimestamp:2019-03-01 09:01:16 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 873fe46e-3c00-11e9-b4e8-fa9e8069966e 0xc001cb2c60 0xc001cb2c61}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-4867m {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-4867m,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-4867m true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--pub-az-nl4q9-cpu-worker-7dd9bbfd9c-7fp9l,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001cb2cc0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001cb2ce0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 09:01:16 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-01 09:01:16 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-01 09:01:16 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 09:01:16 +0000 UTC  }],Message:,Reason:,HostIP:10.250.0.4,PodIP:,StartTime:2019-03-01 09:01:16 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar  1 09:01:19.053: INFO: Pod "nginx-deployment-7f9675fb8b-hcmm5" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-hcmm5,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-5z82f,SelfLink:/api/v1/namespaces/e2e-tests-deployment-5z82f/pods/nginx-deployment-7f9675fb8b-hcmm5,UID:8744e99d-3c00-11e9-b4e8-fa9e8069966e,ResourceVersion:17409,Generation:0,CreationTimestamp:2019-03-01 09:00:57 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{cni.projectcalico.org/podIP: 100.96.1.166/32,kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 873fe46e-3c00-11e9-b4e8-fa9e8069966e 0xc001cb2fb0 0xc001cb2fb1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-4867m {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-4867m,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-4867m true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--pub-az-nl4q9-cpu-worker-7dd9bbfd9c-7fp9l,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001cb3050} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001cb3070}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 09:00:59 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 09:01:11 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 09:01:11 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 09:00:57 +0000 UTC  }],Message:,Reason:,HostIP:10.250.0.4,PodIP:100.96.1.166,StartTime:2019-03-01 09:00:59 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-03-01 09:01:09 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:b96aeeb1687703c49096f4969358d44f8520b671da94848309a3ba5be5b4c632 docker://b7d350df9a2a0689ccda9e66f9e1836c3828db5d07eee3bc95f7049b65572bdf}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar  1 09:01:19.053: INFO: Pod "nginx-deployment-7f9675fb8b-j5ddx" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-j5ddx,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-5z82f,SelfLink:/api/v1/namespaces/e2e-tests-deployment-5z82f/pods/nginx-deployment-7f9675fb8b-j5ddx,UID:92884668-3c00-11e9-b4e8-fa9e8069966e,ResourceVersion:17538,Generation:0,CreationTimestamp:2019-03-01 09:01:16 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 873fe46e-3c00-11e9-b4e8-fa9e8069966e 0xc001cb35b0 0xc001cb35b1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-4867m {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-4867m,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-4867m true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--pub-az-nl4q9-cpu-worker-7dd9bbfd9c-7fp9l,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001cb3610} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001cb3630}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 09:01:17 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-01 09:01:17 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-01 09:01:17 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 09:01:16 +0000 UTC  }],Message:,Reason:,HostIP:10.250.0.4,PodIP:,StartTime:2019-03-01 09:01:17 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar  1 09:01:19.053: INFO: Pod "nginx-deployment-7f9675fb8b-m6n6w" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-m6n6w,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-5z82f,SelfLink:/api/v1/namespaces/e2e-tests-deployment-5z82f/pods/nginx-deployment-7f9675fb8b-m6n6w,UID:87433586-3c00-11e9-b4e8-fa9e8069966e,ResourceVersion:17406,Generation:0,CreationTimestamp:2019-03-01 09:00:57 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{cni.projectcalico.org/podIP: 100.96.1.165/32,kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 873fe46e-3c00-11e9-b4e8-fa9e8069966e 0xc001cb3710 0xc001cb3711}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-4867m {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-4867m,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-4867m true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--pub-az-nl4q9-cpu-worker-7dd9bbfd9c-7fp9l,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001cb37e0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001cb3800}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 09:00:58 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 09:01:11 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 09:01:11 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 09:00:57 +0000 UTC  }],Message:,Reason:,HostIP:10.250.0.4,PodIP:100.96.1.165,StartTime:2019-03-01 09:00:58 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-03-01 09:01:09 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:b96aeeb1687703c49096f4969358d44f8520b671da94848309a3ba5be5b4c632 docker://8af37c705a99c99b4afb5d192aafa829dbb94f18fdf25adbb1b17a21dfec630a}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar  1 09:01:19.053: INFO: Pod "nginx-deployment-7f9675fb8b-m8lzb" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-m8lzb,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-5z82f,SelfLink:/api/v1/namespaces/e2e-tests-deployment-5z82f/pods/nginx-deployment-7f9675fb8b-m8lzb,UID:92885eb0-3c00-11e9-b4e8-fa9e8069966e,ResourceVersion:17499,Generation:0,CreationTimestamp:2019-03-01 09:01:16 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 873fe46e-3c00-11e9-b4e8-fa9e8069966e 0xc001cb3a40 0xc001cb3a41}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-4867m {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-4867m,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-4867m true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--pub-az-nl4q9-cpu-worker-7dd9bbfd9c-7fp9l,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001cb3aa0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001cb3ac0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 09:01:16 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar  1 09:01:19.053: INFO: Pod "nginx-deployment-7f9675fb8b-n2kxg" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-n2kxg,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-5z82f,SelfLink:/api/v1/namespaces/e2e-tests-deployment-5z82f/pods/nginx-deployment-7f9675fb8b-n2kxg,UID:87468005-3c00-11e9-b4e8-fa9e8069966e,ResourceVersion:17415,Generation:0,CreationTimestamp:2019-03-01 09:00:57 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{cni.projectcalico.org/podIP: 100.96.1.169/32,kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 873fe46e-3c00-11e9-b4e8-fa9e8069966e 0xc001cb3b70 0xc001cb3b71}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-4867m {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-4867m,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-4867m true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--pub-az-nl4q9-cpu-worker-7dd9bbfd9c-7fp9l,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001cb3cd0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001cb3cf0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 09:01:00 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 09:01:11 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 09:01:11 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 09:00:57 +0000 UTC  }],Message:,Reason:,HostIP:10.250.0.4,PodIP:100.96.1.169,StartTime:2019-03-01 09:01:00 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-03-01 09:01:11 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:b96aeeb1687703c49096f4969358d44f8520b671da94848309a3ba5be5b4c632 docker://ba642e7703307133db3bc02912a39a8c14cbf298a5e5c6fdcd81ae9687923cbe}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar  1 09:01:19.054: INFO: Pod "nginx-deployment-7f9675fb8b-ptwdj" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-ptwdj,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-5z82f,SelfLink:/api/v1/namespaces/e2e-tests-deployment-5z82f/pods/nginx-deployment-7f9675fb8b-ptwdj,UID:9295ac1b-3c00-11e9-b4e8-fa9e8069966e,ResourceVersion:17524,Generation:0,CreationTimestamp:2019-03-01 09:01:16 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 873fe46e-3c00-11e9-b4e8-fa9e8069966e 0xc001cb3e00 0xc001cb3e01}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-4867m {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-4867m,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-4867m true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--pub-az-nl4q9-cpu-worker-7dd9bbfd9c-gwjjt,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001cb3f80} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001c3e040}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 09:01:16 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-01 09:01:16 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-01 09:01:16 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 09:01:16 +0000 UTC  }],Message:,Reason:,HostIP:10.250.0.5,PodIP:,StartTime:2019-03-01 09:01:16 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar  1 09:01:19.054: INFO: Pod "nginx-deployment-7f9675fb8b-qj4zw" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-qj4zw,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-5z82f,SelfLink:/api/v1/namespaces/e2e-tests-deployment-5z82f/pods/nginx-deployment-7f9675fb8b-qj4zw,UID:92885568-3c00-11e9-b4e8-fa9e8069966e,ResourceVersion:17541,Generation:0,CreationTimestamp:2019-03-01 09:01:16 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 873fe46e-3c00-11e9-b4e8-fa9e8069966e 0xc001c3ebd0 0xc001c3ebd1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-4867m {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-4867m,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-4867m true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--pub-az-nl4q9-cpu-worker-7dd9bbfd9c-7fp9l,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001c3ec30} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001c3edb0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 09:01:18 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-01 09:01:18 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-01 09:01:18 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 09:01:16 +0000 UTC  }],Message:,Reason:,HostIP:10.250.0.4,PodIP:,StartTime:2019-03-01 09:01:18 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar  1 09:01:19.054: INFO: Pod "nginx-deployment-7f9675fb8b-qmfj6" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-qmfj6,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-5z82f,SelfLink:/api/v1/namespaces/e2e-tests-deployment-5z82f/pods/nginx-deployment-7f9675fb8b-qmfj6,UID:8744f305-3c00-11e9-b4e8-fa9e8069966e,ResourceVersion:17379,Generation:0,CreationTimestamp:2019-03-01 09:00:57 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{cni.projectcalico.org/podIP: 100.96.0.41/32,kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 873fe46e-3c00-11e9-b4e8-fa9e8069966e 0xc001c3f040 0xc001c3f041}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-4867m {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-4867m,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-4867m true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--pub-az-nl4q9-cpu-worker-7dd9bbfd9c-gwjjt,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001c3f260} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001c3f280}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 09:00:57 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 09:01:02 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 09:01:02 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 09:00:57 +0000 UTC  }],Message:,Reason:,HostIP:10.250.0.5,PodIP:100.96.0.41,StartTime:2019-03-01 09:00:57 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-03-01 09:01:01 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:b96aeeb1687703c49096f4969358d44f8520b671da94848309a3ba5be5b4c632 docker://3f30b9667ee4cb4e5d737cda80610c8679ee3ce33d946bb42620f743e8164f27}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar  1 09:01:19.054: INFO: Pod "nginx-deployment-7f9675fb8b-tfqbh" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-tfqbh,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-5z82f,SelfLink:/api/v1/namespaces/e2e-tests-deployment-5z82f/pods/nginx-deployment-7f9675fb8b-tfqbh,UID:9295a5af-3c00-11e9-b4e8-fa9e8069966e,ResourceVersion:17528,Generation:0,CreationTimestamp:2019-03-01 09:01:16 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 873fe46e-3c00-11e9-b4e8-fa9e8069966e 0xc001c3f340 0xc001c3f341}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-4867m {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-4867m,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-4867m true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--pub-az-nl4q9-cpu-worker-7dd9bbfd9c-gwjjt,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001c3f3a0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001c3f3e0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 09:01:16 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-01 09:01:16 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-01 09:01:16 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 09:01:16 +0000 UTC  }],Message:,Reason:,HostIP:10.250.0.5,PodIP:,StartTime:2019-03-01 09:01:16 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar  1 09:01:19.054: INFO: Pod "nginx-deployment-7f9675fb8b-wwk8r" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-wwk8r,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-5z82f,SelfLink:/api/v1/namespaces/e2e-tests-deployment-5z82f/pods/nginx-deployment-7f9675fb8b-wwk8r,UID:87467c0f-3c00-11e9-b4e8-fa9e8069966e,ResourceVersion:17370,Generation:0,CreationTimestamp:2019-03-01 09:00:57 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{cni.projectcalico.org/podIP: 100.96.0.40/32,kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 873fe46e-3c00-11e9-b4e8-fa9e8069966e 0xc001c3f4f0 0xc001c3f4f1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-4867m {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-4867m,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-4867m true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--pub-az-nl4q9-cpu-worker-7dd9bbfd9c-gwjjt,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001c3f550} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001c3f570}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 09:00:57 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 09:01:01 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 09:01:01 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 09:00:57 +0000 UTC  }],Message:,Reason:,HostIP:10.250.0.5,PodIP:100.96.0.40,StartTime:2019-03-01 09:00:57 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-03-01 09:01:01 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:b96aeeb1687703c49096f4969358d44f8520b671da94848309a3ba5be5b4c632 docker://6d34f22fa4b78c7f748be87fc266838e0422a616452ba4c221e15b07dcafb689}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar  1 09:01:19.055: INFO: Pod "nginx-deployment-7f9675fb8b-wzfzq" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-wzfzq,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-5z82f,SelfLink:/api/v1/namespaces/e2e-tests-deployment-5z82f/pods/nginx-deployment-7f9675fb8b-wzfzq,UID:8744291d-3c00-11e9-b4e8-fa9e8069966e,ResourceVersion:17367,Generation:0,CreationTimestamp:2019-03-01 09:00:57 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{cni.projectcalico.org/podIP: 100.96.0.39/32,kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 873fe46e-3c00-11e9-b4e8-fa9e8069966e 0xc001c3f640 0xc001c3f641}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-4867m {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-4867m,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-4867m true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--pub-az-nl4q9-cpu-worker-7dd9bbfd9c-gwjjt,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001c3f7d0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001c3f7f0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 09:00:57 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 09:01:00 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 09:01:00 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 09:00:57 +0000 UTC  }],Message:,Reason:,HostIP:10.250.0.5,PodIP:100.96.0.39,StartTime:2019-03-01 09:00:57 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-03-01 09:01:00 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:b96aeeb1687703c49096f4969358d44f8520b671da94848309a3ba5be5b4c632 docker://7a4748641e1f13f23d5a0d60b4de5b760e1b1be46a714dfd0b6aec8b991effdc}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar  1 09:01:19.055: INFO: Pod "nginx-deployment-7f9675fb8b-x8rvd" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-x8rvd,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-5z82f,SelfLink:/api/v1/namespaces/e2e-tests-deployment-5z82f/pods/nginx-deployment-7f9675fb8b-x8rvd,UID:9295a32c-3c00-11e9-b4e8-fa9e8069966e,ResourceVersion:17530,Generation:0,CreationTimestamp:2019-03-01 09:01:16 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 873fe46e-3c00-11e9-b4e8-fa9e8069966e 0xc001c3f8b0 0xc001c3f8b1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-4867m {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-4867m,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-4867m true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--pub-az-nl4q9-cpu-worker-7dd9bbfd9c-gwjjt,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001c3f910} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001c3f930}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 09:01:16 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-01 09:01:16 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-01 09:01:16 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 09:01:16 +0000 UTC  }],Message:,Reason:,HostIP:10.250.0.5,PodIP:,StartTime:2019-03-01 09:01:16 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 09:01:19.055: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-5z82f" for this suite.
Mar  1 09:01:27.208: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 09:01:28.443: INFO: namespace: e2e-tests-deployment-5z82f, resource: bindings, ignored listing per whitelist
Mar  1 09:01:28.622: INFO: namespace e2e-tests-deployment-5z82f deletion completed in 9.529875911s

• [SLOW TEST:32.452 seconds]
[sig-apps] Deployment
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  deployment should support proportional scaling [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 09:01:28.622: INFO: >>> kubeConfig: /tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-tdnc8
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Mar  1 09:01:30.230: INFO: Waiting up to 5m0s for pod "downwardapi-volume-9a8a0ec3-3c00-11e9-a72e-ce8290b78775" in namespace "e2e-tests-downward-api-tdnc8" to be "success or failure"
Mar  1 09:01:30.265: INFO: Pod "downwardapi-volume-9a8a0ec3-3c00-11e9-a72e-ce8290b78775": Phase="Pending", Reason="", readiness=false. Elapsed: 35.04253ms
Mar  1 09:01:32.303: INFO: Pod "downwardapi-volume-9a8a0ec3-3c00-11e9-a72e-ce8290b78775": Phase="Pending", Reason="", readiness=false. Elapsed: 2.072690981s
Mar  1 09:01:34.341: INFO: Pod "downwardapi-volume-9a8a0ec3-3c00-11e9-a72e-ce8290b78775": Phase="Pending", Reason="", readiness=false. Elapsed: 4.111148225s
Mar  1 09:01:36.379: INFO: Pod "downwardapi-volume-9a8a0ec3-3c00-11e9-a72e-ce8290b78775": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.148712588s
STEP: Saw pod success
Mar  1 09:01:36.379: INFO: Pod "downwardapi-volume-9a8a0ec3-3c00-11e9-a72e-ce8290b78775" satisfied condition "success or failure"
Mar  1 09:01:36.414: INFO: Trying to get logs from node shoot--it--pub-az-nl4q9-cpu-worker-7dd9bbfd9c-7fp9l pod downwardapi-volume-9a8a0ec3-3c00-11e9-a72e-ce8290b78775 container client-container: <nil>
STEP: delete the pod
Mar  1 09:01:36.502: INFO: Waiting for pod downwardapi-volume-9a8a0ec3-3c00-11e9-a72e-ce8290b78775 to disappear
Mar  1 09:01:36.541: INFO: Pod downwardapi-volume-9a8a0ec3-3c00-11e9-a72e-ce8290b78775 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 09:01:36.541: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-tdnc8" for this suite.
Mar  1 09:01:42.689: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 09:01:43.950: INFO: namespace: e2e-tests-downward-api-tdnc8, resource: bindings, ignored listing per whitelist
Mar  1 09:01:44.092: INFO: namespace e2e-tests-downward-api-tdnc8 deletion completed in 7.515043012s

• [SLOW TEST:15.470 seconds]
[sig-storage] Downward API volume
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,default) [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 09:01:44.092: INFO: >>> kubeConfig: /tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-cgbht
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,default) [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0777 on node default medium
Mar  1 09:01:45.759: INFO: Waiting up to 5m0s for pod "pod-a3cb73ef-3c00-11e9-a72e-ce8290b78775" in namespace "e2e-tests-emptydir-cgbht" to be "success or failure"
Mar  1 09:01:45.807: INFO: Pod "pod-a3cb73ef-3c00-11e9-a72e-ce8290b78775": Phase="Pending", Reason="", readiness=false. Elapsed: 48.266881ms
Mar  1 09:01:47.844: INFO: Pod "pod-a3cb73ef-3c00-11e9-a72e-ce8290b78775": Phase="Pending", Reason="", readiness=false. Elapsed: 2.084879746s
Mar  1 09:01:49.883: INFO: Pod "pod-a3cb73ef-3c00-11e9-a72e-ce8290b78775": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.123650883s
STEP: Saw pod success
Mar  1 09:01:49.883: INFO: Pod "pod-a3cb73ef-3c00-11e9-a72e-ce8290b78775" satisfied condition "success or failure"
Mar  1 09:01:49.919: INFO: Trying to get logs from node shoot--it--pub-az-nl4q9-cpu-worker-7dd9bbfd9c-7fp9l pod pod-a3cb73ef-3c00-11e9-a72e-ce8290b78775 container test-container: <nil>
STEP: delete the pod
Mar  1 09:01:50.015: INFO: Waiting for pod pod-a3cb73ef-3c00-11e9-a72e-ce8290b78775 to disappear
Mar  1 09:01:50.052: INFO: Pod pod-a3cb73ef-3c00-11e9-a72e-ce8290b78775 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 09:01:50.053: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-cgbht" for this suite.
Mar  1 09:01:56.267: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 09:01:57.435: INFO: namespace: e2e-tests-emptydir-cgbht, resource: bindings, ignored listing per whitelist
Mar  1 09:01:57.687: INFO: namespace e2e-tests-emptydir-cgbht deletion completed in 7.595879774s

• [SLOW TEST:13.595 seconds]
[sig-storage] EmptyDir volumes
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0777,default) [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run default 
  should create an rc or deployment from an image  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 09:01:57.687: INFO: >>> kubeConfig: /tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-vlfvz
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Kubectl run default
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1210
[It] should create an rc or deployment from an image  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Mar  1 09:01:59.388: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-az-nl4q9.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml run e2e-test-nginx-deployment --image=docker.io/library/nginx:1.14-alpine --namespace=e2e-tests-kubectl-vlfvz'
Mar  1 09:01:59.817: INFO: stderr: "kubectl run --generator=deployment/apps.v1beta1 is DEPRECATED and will be removed in a future version. Use kubectl create instead.\n"
Mar  1 09:01:59.817: INFO: stdout: "deployment.apps/e2e-test-nginx-deployment created\n"
STEP: verifying the pod controlled by e2e-test-nginx-deployment gets created
[AfterEach] [k8s.io] Kubectl run default
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1216
Mar  1 09:01:59.880: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-az-nl4q9.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml delete deployment e2e-test-nginx-deployment --namespace=e2e-tests-kubectl-vlfvz'
Mar  1 09:02:00.281: INFO: stderr: ""
Mar  1 09:02:00.281: INFO: stdout: "deployment.extensions \"e2e-test-nginx-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 09:02:00.281: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-vlfvz" for this suite.
Mar  1 09:02:06.429: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 09:02:07.511: INFO: namespace: e2e-tests-kubectl-vlfvz, resource: bindings, ignored listing per whitelist
Mar  1 09:02:07.882: INFO: namespace e2e-tests-kubectl-vlfvz deletion completed in 7.563790142s

• [SLOW TEST:10.195 seconds]
[sig-cli] Kubectl client
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run default
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create an rc or deployment from an image  [Conformance]
    /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 09:02:07.882: INFO: >>> kubeConfig: /tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-secrets-k85db
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-map-b1f75b34-3c00-11e9-a72e-ce8290b78775
STEP: Creating a pod to test consume secrets
Mar  1 09:02:09.576: INFO: Waiting up to 5m0s for pod "pod-secrets-b1fcd62b-3c00-11e9-a72e-ce8290b78775" in namespace "e2e-tests-secrets-k85db" to be "success or failure"
Mar  1 09:02:09.623: INFO: Pod "pod-secrets-b1fcd62b-3c00-11e9-a72e-ce8290b78775": Phase="Pending", Reason="", readiness=false. Elapsed: 46.95943ms
Mar  1 09:02:11.660: INFO: Pod "pod-secrets-b1fcd62b-3c00-11e9-a72e-ce8290b78775": Phase="Pending", Reason="", readiness=false. Elapsed: 2.084473358s
Mar  1 09:02:13.700: INFO: Pod "pod-secrets-b1fcd62b-3c00-11e9-a72e-ce8290b78775": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.123932957s
STEP: Saw pod success
Mar  1 09:02:13.700: INFO: Pod "pod-secrets-b1fcd62b-3c00-11e9-a72e-ce8290b78775" satisfied condition "success or failure"
Mar  1 09:02:13.736: INFO: Trying to get logs from node shoot--it--pub-az-nl4q9-cpu-worker-7dd9bbfd9c-7fp9l pod pod-secrets-b1fcd62b-3c00-11e9-a72e-ce8290b78775 container secret-volume-test: <nil>
STEP: delete the pod
Mar  1 09:02:13.859: INFO: Waiting for pod pod-secrets-b1fcd62b-3c00-11e9-a72e-ce8290b78775 to disappear
Mar  1 09:02:13.896: INFO: Pod pod-secrets-b1fcd62b-3c00-11e9-a72e-ce8290b78775 no longer exists
[AfterEach] [sig-storage] Secrets
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 09:02:13.896: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-k85db" for this suite.
Mar  1 09:02:20.043: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 09:02:20.765: INFO: namespace: e2e-tests-secrets-k85db, resource: bindings, ignored listing per whitelist
Mar  1 09:02:21.411: INFO: namespace e2e-tests-secrets-k85db deletion completed in 7.478262551s

• [SLOW TEST:13.529 seconds]
[sig-storage] Secrets
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Guestbook application 
  should create and stop a working application  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 09:02:21.411: INFO: >>> kubeConfig: /tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-w77k8
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should create and stop a working application  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating all guestbook components
Mar  1 09:02:23.099: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-slave
  labels:
    app: redis
    role: slave
    tier: backend
spec:
  ports:
  - port: 6379
  selector:
    app: redis
    role: slave
    tier: backend

Mar  1 09:02:23.099: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-az-nl4q9.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml create -f - --namespace=e2e-tests-kubectl-w77k8'
Mar  1 09:02:23.552: INFO: stderr: ""
Mar  1 09:02:23.553: INFO: stdout: "service/redis-slave created\n"
Mar  1 09:02:23.553: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-master
  labels:
    app: redis
    role: master
    tier: backend
spec:
  ports:
  - port: 6379
    targetPort: 6379
  selector:
    app: redis
    role: master
    tier: backend

Mar  1 09:02:23.553: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-az-nl4q9.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml create -f - --namespace=e2e-tests-kubectl-w77k8'
Mar  1 09:02:23.928: INFO: stderr: ""
Mar  1 09:02:23.928: INFO: stdout: "service/redis-master created\n"
Mar  1 09:02:23.928: INFO: apiVersion: v1
kind: Service
metadata:
  name: frontend
  labels:
    app: guestbook
    tier: frontend
spec:
  # if your cluster supports it, uncomment the following to automatically create
  # an external load-balanced IP for the frontend service.
  # type: LoadBalancer
  ports:
  - port: 80
  selector:
    app: guestbook
    tier: frontend

Mar  1 09:02:23.928: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-az-nl4q9.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml create -f - --namespace=e2e-tests-kubectl-w77k8'
Mar  1 09:02:25.983: INFO: stderr: ""
Mar  1 09:02:25.983: INFO: stdout: "service/frontend created\n"
Mar  1 09:02:25.986: INFO: apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: frontend
spec:
  replicas: 3
  template:
    metadata:
      labels:
        app: guestbook
        tier: frontend
    spec:
      containers:
      - name: php-redis
        image: gcr.io/google-samples/gb-frontend:v6
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access environment variables to find service host
          # info, comment out the 'value: dns' line above, and uncomment the
          # line below:
          # value: env
        ports:
        - containerPort: 80

Mar  1 09:02:25.986: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-az-nl4q9.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml create -f - --namespace=e2e-tests-kubectl-w77k8'
Mar  1 09:02:26.390: INFO: stderr: ""
Mar  1 09:02:26.390: INFO: stdout: "deployment.extensions/frontend created\n"
Mar  1 09:02:26.390: INFO: apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: redis-master
spec:
  replicas: 1
  template:
    metadata:
      labels:
        app: redis
        role: master
        tier: backend
    spec:
      containers:
      - name: master
        image: gcr.io/kubernetes-e2e-test-images/redis:1.0
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        ports:
        - containerPort: 6379

Mar  1 09:02:26.390: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-az-nl4q9.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml create -f - --namespace=e2e-tests-kubectl-w77k8'
Mar  1 09:02:26.860: INFO: stderr: ""
Mar  1 09:02:26.860: INFO: stdout: "deployment.extensions/redis-master created\n"
Mar  1 09:02:26.860: INFO: apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: redis-slave
spec:
  replicas: 2
  template:
    metadata:
      labels:
        app: redis
        role: slave
        tier: backend
    spec:
      containers:
      - name: slave
        image: gcr.io/google-samples/gb-redisslave:v3
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access an environment variable to find the master
          # service's host, comment out the 'value: dns' line above, and
          # uncomment the line below:
          # value: env
        ports:
        - containerPort: 6379

Mar  1 09:02:26.860: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-az-nl4q9.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml create -f - --namespace=e2e-tests-kubectl-w77k8'
Mar  1 09:02:27.316: INFO: stderr: ""
Mar  1 09:02:27.316: INFO: stdout: "deployment.extensions/redis-slave created\n"
STEP: validating guestbook app
Mar  1 09:02:27.316: INFO: Waiting for all frontend pods to be Running.
Mar  1 09:03:02.370: INFO: Waiting for frontend to serve content.
Mar  1 09:03:02.494: INFO: Trying to add a new entry to the guestbook.
Mar  1 09:03:02.620: INFO: Verifying that added entry can be retrieved.
STEP: using delete to clean up resources
Mar  1 09:03:02.746: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-az-nl4q9.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-w77k8'
Mar  1 09:03:03.196: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Mar  1 09:03:03.197: INFO: stdout: "service \"redis-slave\" force deleted\n"
STEP: using delete to clean up resources
Mar  1 09:03:03.197: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-az-nl4q9.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-w77k8'
Mar  1 09:03:03.502: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Mar  1 09:03:03.502: INFO: stdout: "service \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
Mar  1 09:03:03.502: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-az-nl4q9.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-w77k8'
Mar  1 09:03:03.807: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Mar  1 09:03:03.807: INFO: stdout: "service \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Mar  1 09:03:03.808: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-az-nl4q9.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-w77k8'
Mar  1 09:03:04.207: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Mar  1 09:03:04.207: INFO: stdout: "deployment.extensions \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Mar  1 09:03:04.207: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-az-nl4q9.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-w77k8'
Mar  1 09:03:04.630: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Mar  1 09:03:04.630: INFO: stdout: "deployment.extensions \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
Mar  1 09:03:04.630: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-az-nl4q9.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-w77k8'
Mar  1 09:03:04.955: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Mar  1 09:03:04.955: INFO: stdout: "deployment.extensions \"redis-slave\" force deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 09:03:04.955: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-w77k8" for this suite.
Mar  1 09:03:49.103: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 09:03:49.425: INFO: namespace: e2e-tests-kubectl-w77k8, resource: bindings, ignored listing per whitelist
Mar  1 09:03:50.489: INFO: namespace e2e-tests-kubectl-w77k8 deletion completed in 45.495927611s

• [SLOW TEST:89.078 seconds]
[sig-cli] Kubectl client
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Guestbook application
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create and stop a working application  [Conformance]
    /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 09:03:50.490: INFO: >>> kubeConfig: /tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-secrets-x6z42
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-ef1f381d-3c00-11e9-a72e-ce8290b78775
STEP: Creating a pod to test consume secrets
Mar  1 09:03:52.172: INFO: Waiting up to 5m0s for pod "pod-secrets-ef24a3a9-3c00-11e9-a72e-ce8290b78775" in namespace "e2e-tests-secrets-x6z42" to be "success or failure"
Mar  1 09:03:52.207: INFO: Pod "pod-secrets-ef24a3a9-3c00-11e9-a72e-ce8290b78775": Phase="Pending", Reason="", readiness=false. Elapsed: 35.532348ms
Mar  1 09:03:54.243: INFO: Pod "pod-secrets-ef24a3a9-3c00-11e9-a72e-ce8290b78775": Phase="Pending", Reason="", readiness=false. Elapsed: 2.071604485s
Mar  1 09:03:56.280: INFO: Pod "pod-secrets-ef24a3a9-3c00-11e9-a72e-ce8290b78775": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.108461655s
STEP: Saw pod success
Mar  1 09:03:56.280: INFO: Pod "pod-secrets-ef24a3a9-3c00-11e9-a72e-ce8290b78775" satisfied condition "success or failure"
Mar  1 09:03:56.316: INFO: Trying to get logs from node shoot--it--pub-az-nl4q9-cpu-worker-7dd9bbfd9c-7fp9l pod pod-secrets-ef24a3a9-3c00-11e9-a72e-ce8290b78775 container secret-volume-test: <nil>
STEP: delete the pod
Mar  1 09:03:56.417: INFO: Waiting for pod pod-secrets-ef24a3a9-3c00-11e9-a72e-ce8290b78775 to disappear
Mar  1 09:03:56.452: INFO: Pod pod-secrets-ef24a3a9-3c00-11e9-a72e-ce8290b78775 no longer exists
[AfterEach] [sig-storage] Secrets
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 09:03:56.452: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-x6z42" for this suite.
Mar  1 09:04:02.596: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 09:04:03.446: INFO: namespace: e2e-tests-secrets-x6z42, resource: bindings, ignored listing per whitelist
Mar  1 09:04:03.966: INFO: namespace e2e-tests-secrets-x6z42 deletion completed in 7.478049307s

• [SLOW TEST:13.476 seconds]
[sig-storage] Secrets
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop simple daemon [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 09:04:03.966: INFO: >>> kubeConfig: /tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-daemonsets-jb8xt
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should run and stop simple daemon [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Mar  1 09:04:05.919: INFO: Number of nodes with available pods: 0
Mar  1 09:04:05.919: INFO: Node shoot--it--pub-az-nl4q9-cpu-worker-7dd9bbfd9c-7fp9l is running more than one daemon pod
Mar  1 09:04:06.999: INFO: Number of nodes with available pods: 0
Mar  1 09:04:06.999: INFO: Node shoot--it--pub-az-nl4q9-cpu-worker-7dd9bbfd9c-7fp9l is running more than one daemon pod
Mar  1 09:04:07.996: INFO: Number of nodes with available pods: 0
Mar  1 09:04:07.996: INFO: Node shoot--it--pub-az-nl4q9-cpu-worker-7dd9bbfd9c-7fp9l is running more than one daemon pod
Mar  1 09:04:08.995: INFO: Number of nodes with available pods: 2
Mar  1 09:04:08.995: INFO: Number of running nodes: 2, number of available pods: 2
STEP: Stop a daemon pod, check that the daemon pod is revived.
Mar  1 09:04:09.178: INFO: Number of nodes with available pods: 1
Mar  1 09:04:09.178: INFO: Node shoot--it--pub-az-nl4q9-cpu-worker-7dd9bbfd9c-7fp9l is running more than one daemon pod
Mar  1 09:04:10.250: INFO: Number of nodes with available pods: 1
Mar  1 09:04:10.250: INFO: Node shoot--it--pub-az-nl4q9-cpu-worker-7dd9bbfd9c-7fp9l is running more than one daemon pod
Mar  1 09:04:11.252: INFO: Number of nodes with available pods: 1
Mar  1 09:04:11.252: INFO: Node shoot--it--pub-az-nl4q9-cpu-worker-7dd9bbfd9c-7fp9l is running more than one daemon pod
Mar  1 09:04:12.250: INFO: Number of nodes with available pods: 1
Mar  1 09:04:12.250: INFO: Node shoot--it--pub-az-nl4q9-cpu-worker-7dd9bbfd9c-7fp9l is running more than one daemon pod
Mar  1 09:04:13.257: INFO: Number of nodes with available pods: 1
Mar  1 09:04:13.257: INFO: Node shoot--it--pub-az-nl4q9-cpu-worker-7dd9bbfd9c-7fp9l is running more than one daemon pod
Mar  1 09:04:14.251: INFO: Number of nodes with available pods: 1
Mar  1 09:04:14.251: INFO: Node shoot--it--pub-az-nl4q9-cpu-worker-7dd9bbfd9c-7fp9l is running more than one daemon pod
Mar  1 09:04:15.255: INFO: Number of nodes with available pods: 1
Mar  1 09:04:15.255: INFO: Node shoot--it--pub-az-nl4q9-cpu-worker-7dd9bbfd9c-7fp9l is running more than one daemon pod
Mar  1 09:04:16.251: INFO: Number of nodes with available pods: 1
Mar  1 09:04:16.251: INFO: Node shoot--it--pub-az-nl4q9-cpu-worker-7dd9bbfd9c-7fp9l is running more than one daemon pod
Mar  1 09:04:17.251: INFO: Number of nodes with available pods: 1
Mar  1 09:04:17.251: INFO: Node shoot--it--pub-az-nl4q9-cpu-worker-7dd9bbfd9c-7fp9l is running more than one daemon pod
Mar  1 09:04:18.254: INFO: Number of nodes with available pods: 1
Mar  1 09:04:18.254: INFO: Node shoot--it--pub-az-nl4q9-cpu-worker-7dd9bbfd9c-7fp9l is running more than one daemon pod
Mar  1 09:04:19.251: INFO: Number of nodes with available pods: 1
Mar  1 09:04:19.251: INFO: Node shoot--it--pub-az-nl4q9-cpu-worker-7dd9bbfd9c-7fp9l is running more than one daemon pod
Mar  1 09:04:20.260: INFO: Number of nodes with available pods: 1
Mar  1 09:04:20.260: INFO: Node shoot--it--pub-az-nl4q9-cpu-worker-7dd9bbfd9c-7fp9l is running more than one daemon pod
Mar  1 09:04:21.268: INFO: Number of nodes with available pods: 1
Mar  1 09:04:21.268: INFO: Node shoot--it--pub-az-nl4q9-cpu-worker-7dd9bbfd9c-7fp9l is running more than one daemon pod
Mar  1 09:04:22.257: INFO: Number of nodes with available pods: 1
Mar  1 09:04:22.257: INFO: Node shoot--it--pub-az-nl4q9-cpu-worker-7dd9bbfd9c-7fp9l is running more than one daemon pod
Mar  1 09:04:23.250: INFO: Number of nodes with available pods: 1
Mar  1 09:04:23.250: INFO: Node shoot--it--pub-az-nl4q9-cpu-worker-7dd9bbfd9c-7fp9l is running more than one daemon pod
Mar  1 09:04:24.250: INFO: Number of nodes with available pods: 1
Mar  1 09:04:24.250: INFO: Node shoot--it--pub-az-nl4q9-cpu-worker-7dd9bbfd9c-7fp9l is running more than one daemon pod
Mar  1 09:04:25.253: INFO: Number of nodes with available pods: 1
Mar  1 09:04:25.253: INFO: Node shoot--it--pub-az-nl4q9-cpu-worker-7dd9bbfd9c-7fp9l is running more than one daemon pod
Mar  1 09:04:26.253: INFO: Number of nodes with available pods: 1
Mar  1 09:04:26.255: INFO: Node shoot--it--pub-az-nl4q9-cpu-worker-7dd9bbfd9c-7fp9l is running more than one daemon pod
Mar  1 09:04:27.252: INFO: Number of nodes with available pods: 1
Mar  1 09:04:27.252: INFO: Node shoot--it--pub-az-nl4q9-cpu-worker-7dd9bbfd9c-7fp9l is running more than one daemon pod
Mar  1 09:04:28.257: INFO: Number of nodes with available pods: 1
Mar  1 09:04:28.258: INFO: Node shoot--it--pub-az-nl4q9-cpu-worker-7dd9bbfd9c-7fp9l is running more than one daemon pod
Mar  1 09:04:29.278: INFO: Number of nodes with available pods: 1
Mar  1 09:04:29.279: INFO: Node shoot--it--pub-az-nl4q9-cpu-worker-7dd9bbfd9c-7fp9l is running more than one daemon pod
Mar  1 09:04:30.252: INFO: Number of nodes with available pods: 1
Mar  1 09:04:30.252: INFO: Node shoot--it--pub-az-nl4q9-cpu-worker-7dd9bbfd9c-7fp9l is running more than one daemon pod
Mar  1 09:04:31.250: INFO: Number of nodes with available pods: 1
Mar  1 09:04:31.250: INFO: Node shoot--it--pub-az-nl4q9-cpu-worker-7dd9bbfd9c-7fp9l is running more than one daemon pod
Mar  1 09:04:32.250: INFO: Number of nodes with available pods: 1
Mar  1 09:04:32.250: INFO: Node shoot--it--pub-az-nl4q9-cpu-worker-7dd9bbfd9c-7fp9l is running more than one daemon pod
Mar  1 09:04:33.251: INFO: Number of nodes with available pods: 1
Mar  1 09:04:33.251: INFO: Node shoot--it--pub-az-nl4q9-cpu-worker-7dd9bbfd9c-7fp9l is running more than one daemon pod
Mar  1 09:04:34.259: INFO: Number of nodes with available pods: 1
Mar  1 09:04:34.259: INFO: Node shoot--it--pub-az-nl4q9-cpu-worker-7dd9bbfd9c-7fp9l is running more than one daemon pod
Mar  1 09:04:35.251: INFO: Number of nodes with available pods: 1
Mar  1 09:04:35.251: INFO: Node shoot--it--pub-az-nl4q9-cpu-worker-7dd9bbfd9c-7fp9l is running more than one daemon pod
Mar  1 09:04:36.251: INFO: Number of nodes with available pods: 1
Mar  1 09:04:36.251: INFO: Node shoot--it--pub-az-nl4q9-cpu-worker-7dd9bbfd9c-7fp9l is running more than one daemon pod
Mar  1 09:04:37.250: INFO: Number of nodes with available pods: 1
Mar  1 09:04:37.250: INFO: Node shoot--it--pub-az-nl4q9-cpu-worker-7dd9bbfd9c-7fp9l is running more than one daemon pod
Mar  1 09:04:38.250: INFO: Number of nodes with available pods: 1
Mar  1 09:04:38.250: INFO: Node shoot--it--pub-az-nl4q9-cpu-worker-7dd9bbfd9c-7fp9l is running more than one daemon pod
Mar  1 09:04:39.253: INFO: Number of nodes with available pods: 1
Mar  1 09:04:39.253: INFO: Node shoot--it--pub-az-nl4q9-cpu-worker-7dd9bbfd9c-7fp9l is running more than one daemon pod
Mar  1 09:04:40.266: INFO: Number of nodes with available pods: 1
Mar  1 09:04:40.266: INFO: Node shoot--it--pub-az-nl4q9-cpu-worker-7dd9bbfd9c-7fp9l is running more than one daemon pod
Mar  1 09:04:41.250: INFO: Number of nodes with available pods: 1
Mar  1 09:04:41.251: INFO: Node shoot--it--pub-az-nl4q9-cpu-worker-7dd9bbfd9c-7fp9l is running more than one daemon pod
Mar  1 09:04:42.254: INFO: Number of nodes with available pods: 1
Mar  1 09:04:42.254: INFO: Node shoot--it--pub-az-nl4q9-cpu-worker-7dd9bbfd9c-7fp9l is running more than one daemon pod
Mar  1 09:04:43.251: INFO: Number of nodes with available pods: 1
Mar  1 09:04:43.251: INFO: Node shoot--it--pub-az-nl4q9-cpu-worker-7dd9bbfd9c-7fp9l is running more than one daemon pod
Mar  1 09:04:44.255: INFO: Number of nodes with available pods: 1
Mar  1 09:04:44.255: INFO: Node shoot--it--pub-az-nl4q9-cpu-worker-7dd9bbfd9c-7fp9l is running more than one daemon pod
Mar  1 09:04:45.252: INFO: Number of nodes with available pods: 1
Mar  1 09:04:45.252: INFO: Node shoot--it--pub-az-nl4q9-cpu-worker-7dd9bbfd9c-7fp9l is running more than one daemon pod
Mar  1 09:04:46.251: INFO: Number of nodes with available pods: 1
Mar  1 09:04:46.251: INFO: Node shoot--it--pub-az-nl4q9-cpu-worker-7dd9bbfd9c-7fp9l is running more than one daemon pod
Mar  1 09:04:47.251: INFO: Number of nodes with available pods: 1
Mar  1 09:04:47.251: INFO: Node shoot--it--pub-az-nl4q9-cpu-worker-7dd9bbfd9c-7fp9l is running more than one daemon pod
Mar  1 09:04:48.251: INFO: Number of nodes with available pods: 1
Mar  1 09:04:48.251: INFO: Node shoot--it--pub-az-nl4q9-cpu-worker-7dd9bbfd9c-7fp9l is running more than one daemon pod
Mar  1 09:04:49.251: INFO: Number of nodes with available pods: 1
Mar  1 09:04:49.251: INFO: Node shoot--it--pub-az-nl4q9-cpu-worker-7dd9bbfd9c-7fp9l is running more than one daemon pod
Mar  1 09:04:50.251: INFO: Number of nodes with available pods: 1
Mar  1 09:04:50.251: INFO: Node shoot--it--pub-az-nl4q9-cpu-worker-7dd9bbfd9c-7fp9l is running more than one daemon pod
Mar  1 09:04:51.273: INFO: Number of nodes with available pods: 1
Mar  1 09:04:51.273: INFO: Node shoot--it--pub-az-nl4q9-cpu-worker-7dd9bbfd9c-7fp9l is running more than one daemon pod
Mar  1 09:04:52.251: INFO: Number of nodes with available pods: 1
Mar  1 09:04:52.251: INFO: Node shoot--it--pub-az-nl4q9-cpu-worker-7dd9bbfd9c-7fp9l is running more than one daemon pod
Mar  1 09:04:53.254: INFO: Number of nodes with available pods: 1
Mar  1 09:04:53.254: INFO: Node shoot--it--pub-az-nl4q9-cpu-worker-7dd9bbfd9c-7fp9l is running more than one daemon pod
Mar  1 09:04:54.254: INFO: Number of nodes with available pods: 2
Mar  1 09:04:54.254: INFO: Number of running nodes: 2, number of available pods: 2
[AfterEach] [sig-apps] Daemon set [Serial]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting {extensions DaemonSet} daemon-set in namespace e2e-tests-daemonsets-jb8xt, will wait for the garbage collector to delete the pods
Mar  1 09:04:54.414: INFO: Deleting {extensions DaemonSet} daemon-set took: 37.830675ms
Mar  1 09:04:54.514: INFO: Terminating {extensions DaemonSet} daemon-set pods took: 100.239947ms
Mar  1 09:05:36.650: INFO: Number of nodes with available pods: 0
Mar  1 09:05:36.650: INFO: Number of running nodes: 0, number of available pods: 0
Mar  1 09:05:36.685: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-jb8xt/daemonsets","resourceVersion":"18438"},"items":null}

Mar  1 09:05:36.721: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-jb8xt/pods","resourceVersion":"18438"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 09:05:36.828: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-jb8xt" for this suite.
Mar  1 09:05:42.972: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 09:05:43.799: INFO: namespace: e2e-tests-daemonsets-jb8xt, resource: bindings, ignored listing per whitelist
Mar  1 09:05:44.371: INFO: namespace e2e-tests-daemonsets-jb8xt deletion completed in 7.50745851s

• [SLOW TEST:100.404 seconds]
[sig-apps] Daemon set [Serial]
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should run and stop simple daemon [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 09:05:44.371: INFO: >>> kubeConfig: /tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-8f5nt
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-330045e1-3c01-11e9-a72e-ce8290b78775
STEP: Creating a pod to test consume configMaps
Mar  1 09:05:46.056: INFO: Waiting up to 5m0s for pod "pod-configmaps-3305d906-3c01-11e9-a72e-ce8290b78775" in namespace "e2e-tests-configmap-8f5nt" to be "success or failure"
Mar  1 09:05:46.111: INFO: Pod "pod-configmaps-3305d906-3c01-11e9-a72e-ce8290b78775": Phase="Pending", Reason="", readiness=false. Elapsed: 54.95276ms
Mar  1 09:05:48.148: INFO: Pod "pod-configmaps-3305d906-3c01-11e9-a72e-ce8290b78775": Phase="Pending", Reason="", readiness=false. Elapsed: 2.091908489s
Mar  1 09:05:50.185: INFO: Pod "pod-configmaps-3305d906-3c01-11e9-a72e-ce8290b78775": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.128274497s
STEP: Saw pod success
Mar  1 09:05:50.185: INFO: Pod "pod-configmaps-3305d906-3c01-11e9-a72e-ce8290b78775" satisfied condition "success or failure"
Mar  1 09:05:50.220: INFO: Trying to get logs from node shoot--it--pub-az-nl4q9-cpu-worker-7dd9bbfd9c-7fp9l pod pod-configmaps-3305d906-3c01-11e9-a72e-ce8290b78775 container configmap-volume-test: <nil>
STEP: delete the pod
Mar  1 09:05:50.305: INFO: Waiting for pod pod-configmaps-3305d906-3c01-11e9-a72e-ce8290b78775 to disappear
Mar  1 09:05:50.340: INFO: Pod pod-configmaps-3305d906-3c01-11e9-a72e-ce8290b78775 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 09:05:50.340: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-8f5nt" for this suite.
Mar  1 09:05:56.508: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 09:05:56.613: INFO: namespace: e2e-tests-configmap-8f5nt, resource: bindings, ignored listing per whitelist
Mar  1 09:05:57.936: INFO: namespace e2e-tests-configmap-8f5nt deletion completed in 7.560979905s

• [SLOW TEST:13.566 seconds]
[sig-storage] ConfigMap
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-api-machinery] Watchers 
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Watchers
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 09:05:57.937: INFO: >>> kubeConfig: /tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-watch-4h5n9
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a watch on configmaps with a certain label
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: changing the label value of the configmap
STEP: Expecting to observe a delete notification for the watched object
Mar  1 09:05:59.790: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-4h5n9,SelfLink:/api/v1/namespaces/e2e-tests-watch-4h5n9/configmaps/e2e-watch-test-label-changed,UID:3b22f404-3c01-11e9-b4e8-fa9e8069966e,ResourceVersion:18513,Generation:0,CreationTimestamp:2019-03-01 09:05:59 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Mar  1 09:05:59.790: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-4h5n9,SelfLink:/api/v1/namespaces/e2e-tests-watch-4h5n9/configmaps/e2e-watch-test-label-changed,UID:3b22f404-3c01-11e9-b4e8-fa9e8069966e,ResourceVersion:18514,Generation:0,CreationTimestamp:2019-03-01 09:05:59 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Mar  1 09:05:59.790: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-4h5n9,SelfLink:/api/v1/namespaces/e2e-tests-watch-4h5n9/configmaps/e2e-watch-test-label-changed,UID:3b22f404-3c01-11e9-b4e8-fa9e8069966e,ResourceVersion:18515,Generation:0,CreationTimestamp:2019-03-01 09:05:59 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time
STEP: Expecting not to observe a notification because the object no longer meets the selector's requirements
STEP: changing the label value of the configmap back
STEP: modifying the configmap a third time
STEP: deleting the configmap
STEP: Expecting to observe an add notification for the watched object when the label value was restored
Mar  1 09:06:10.052: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-4h5n9,SelfLink:/api/v1/namespaces/e2e-tests-watch-4h5n9/configmaps/e2e-watch-test-label-changed,UID:3b22f404-3c01-11e9-b4e8-fa9e8069966e,ResourceVersion:18539,Generation:0,CreationTimestamp:2019-03-01 09:05:59 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Mar  1 09:06:10.052: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-4h5n9,SelfLink:/api/v1/namespaces/e2e-tests-watch-4h5n9/configmaps/e2e-watch-test-label-changed,UID:3b22f404-3c01-11e9-b4e8-fa9e8069966e,ResourceVersion:18540,Generation:0,CreationTimestamp:2019-03-01 09:05:59 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
Mar  1 09:06:10.067: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-4h5n9,SelfLink:/api/v1/namespaces/e2e-tests-watch-4h5n9/configmaps/e2e-watch-test-label-changed,UID:3b22f404-3c01-11e9-b4e8-fa9e8069966e,ResourceVersion:18541,Generation:0,CreationTimestamp:2019-03-01 09:05:59 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 09:06:10.067: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-4h5n9" for this suite.
Mar  1 09:06:16.223: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 09:06:17.056: INFO: namespace: e2e-tests-watch-4h5n9, resource: bindings, ignored listing per whitelist
Mar  1 09:06:17.632: INFO: namespace e2e-tests-watch-4h5n9 deletion completed in 7.52866216s

• [SLOW TEST:19.695 seconds]
[sig-api-machinery] Watchers
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-api-machinery] Secrets 
  should be consumable via the environment [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Secrets
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 09:06:17.632: INFO: >>> kubeConfig: /tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-secrets-d75z5
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating secret e2e-tests-secrets-d75z5/secret-test-46ebd0d2-3c01-11e9-a72e-ce8290b78775
STEP: Creating a pod to test consume secrets
Mar  1 09:06:19.475: INFO: Waiting up to 5m0s for pod "pod-configmaps-46f138c8-3c01-11e9-a72e-ce8290b78775" in namespace "e2e-tests-secrets-d75z5" to be "success or failure"
Mar  1 09:06:19.511: INFO: Pod "pod-configmaps-46f138c8-3c01-11e9-a72e-ce8290b78775": Phase="Pending", Reason="", readiness=false. Elapsed: 36.127388ms
Mar  1 09:06:21.547: INFO: Pod "pod-configmaps-46f138c8-3c01-11e9-a72e-ce8290b78775": Phase="Pending", Reason="", readiness=false. Elapsed: 2.072644253s
Mar  1 09:06:23.584: INFO: Pod "pod-configmaps-46f138c8-3c01-11e9-a72e-ce8290b78775": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.109168485s
STEP: Saw pod success
Mar  1 09:06:23.584: INFO: Pod "pod-configmaps-46f138c8-3c01-11e9-a72e-ce8290b78775" satisfied condition "success or failure"
Mar  1 09:06:23.619: INFO: Trying to get logs from node shoot--it--pub-az-nl4q9-cpu-worker-7dd9bbfd9c-7fp9l pod pod-configmaps-46f138c8-3c01-11e9-a72e-ce8290b78775 container env-test: <nil>
STEP: delete the pod
Mar  1 09:06:23.709: INFO: Waiting for pod pod-configmaps-46f138c8-3c01-11e9-a72e-ce8290b78775 to disappear
Mar  1 09:06:23.744: INFO: Pod pod-configmaps-46f138c8-3c01-11e9-a72e-ce8290b78775 no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 09:06:23.744: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-d75z5" for this suite.
Mar  1 09:06:29.892: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 09:06:30.163: INFO: namespace: e2e-tests-secrets-d75z5, resource: bindings, ignored listing per whitelist
Mar  1 09:06:31.297: INFO: namespace e2e-tests-secrets-d75z5 deletion completed in 7.514780133s

• [SLOW TEST:13.665 seconds]
[sig-api-machinery] Secrets
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:31
  should be consumable via the environment [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 09:06:31.297: INFO: >>> kubeConfig: /tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-7h8w4
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-4ef73dd4-3c01-11e9-a72e-ce8290b78775
STEP: Creating a pod to test consume configMaps
Mar  1 09:06:32.972: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-4efcd037-3c01-11e9-a72e-ce8290b78775" in namespace "e2e-tests-projected-7h8w4" to be "success or failure"
Mar  1 09:06:33.009: INFO: Pod "pod-projected-configmaps-4efcd037-3c01-11e9-a72e-ce8290b78775": Phase="Pending", Reason="", readiness=false. Elapsed: 36.404175ms
Mar  1 09:06:35.046: INFO: Pod "pod-projected-configmaps-4efcd037-3c01-11e9-a72e-ce8290b78775": Phase="Pending", Reason="", readiness=false. Elapsed: 2.074135606s
Mar  1 09:06:37.083: INFO: Pod "pod-projected-configmaps-4efcd037-3c01-11e9-a72e-ce8290b78775": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.110882031s
STEP: Saw pod success
Mar  1 09:06:37.084: INFO: Pod "pod-projected-configmaps-4efcd037-3c01-11e9-a72e-ce8290b78775" satisfied condition "success or failure"
Mar  1 09:06:37.119: INFO: Trying to get logs from node shoot--it--pub-az-nl4q9-cpu-worker-7dd9bbfd9c-7fp9l pod pod-projected-configmaps-4efcd037-3c01-11e9-a72e-ce8290b78775 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Mar  1 09:06:37.326: INFO: Waiting for pod pod-projected-configmaps-4efcd037-3c01-11e9-a72e-ce8290b78775 to disappear
Mar  1 09:06:37.361: INFO: Pod pod-projected-configmaps-4efcd037-3c01-11e9-a72e-ce8290b78775 no longer exists
[AfterEach] [sig-storage] Projected
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 09:06:37.361: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-7h8w4" for this suite.
Mar  1 09:06:43.509: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 09:06:43.949: INFO: namespace: e2e-tests-projected-7h8w4, resource: bindings, ignored listing per whitelist
Mar  1 09:06:44.978: INFO: namespace e2e-tests-projected-7h8w4 deletion completed in 7.578896692s

• [SLOW TEST:13.681 seconds]
[sig-storage] Projected
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory request [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 09:06:44.978: INFO: >>> kubeConfig: /tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-5h4wd
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's memory request [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Mar  1 09:06:46.645: INFO: Waiting up to 5m0s for pod "downwardapi-volume-572308e9-3c01-11e9-a72e-ce8290b78775" in namespace "e2e-tests-downward-api-5h4wd" to be "success or failure"
Mar  1 09:06:46.681: INFO: Pod "downwardapi-volume-572308e9-3c01-11e9-a72e-ce8290b78775": Phase="Pending", Reason="", readiness=false. Elapsed: 36.039888ms
Mar  1 09:06:48.719: INFO: Pod "downwardapi-volume-572308e9-3c01-11e9-a72e-ce8290b78775": Phase="Pending", Reason="", readiness=false. Elapsed: 2.073826791s
Mar  1 09:06:50.755: INFO: Pod "downwardapi-volume-572308e9-3c01-11e9-a72e-ce8290b78775": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.110354404s
STEP: Saw pod success
Mar  1 09:06:50.755: INFO: Pod "downwardapi-volume-572308e9-3c01-11e9-a72e-ce8290b78775" satisfied condition "success or failure"
Mar  1 09:06:50.791: INFO: Trying to get logs from node shoot--it--pub-az-nl4q9-cpu-worker-7dd9bbfd9c-7fp9l pod downwardapi-volume-572308e9-3c01-11e9-a72e-ce8290b78775 container client-container: <nil>
STEP: delete the pod
Mar  1 09:06:50.931: INFO: Waiting for pod downwardapi-volume-572308e9-3c01-11e9-a72e-ce8290b78775 to disappear
Mar  1 09:06:50.968: INFO: Pod downwardapi-volume-572308e9-3c01-11e9-a72e-ce8290b78775 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 09:06:50.968: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-5h4wd" for this suite.
Mar  1 09:06:57.112: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 09:06:57.688: INFO: namespace: e2e-tests-downward-api-5h4wd, resource: bindings, ignored listing per whitelist
Mar  1 09:06:58.485: INFO: namespace e2e-tests-downward-api-5h4wd deletion completed in 7.481124782s

• [SLOW TEST:13.507 seconds]
[sig-storage] Downward API volume
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's memory request [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-apps] Deployment 
  deployment should delete old replica sets [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 09:06:58.485: INFO: >>> kubeConfig: /tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-deployment-zn4k2
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should delete old replica sets [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Mar  1 09:07:00.186: INFO: Pod name cleanup-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Mar  1 09:07:04.261: INFO: Creating deployment test-cleanup-deployment
STEP: Waiting for deployment test-cleanup-deployment history to be cleaned up
[AfterEach] [sig-apps] Deployment
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Mar  1 09:07:08.578: INFO: Deployment "test-cleanup-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-deployment,GenerateName:,Namespace:e2e-tests-deployment-zn4k2,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-zn4k2/deployments/test-cleanup-deployment,UID:61b64e88-3c01-11e9-b4e8-fa9e8069966e,ResourceVersion:18749,Generation:1,CreationTimestamp:2019-03-01 09:07:04 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,},Annotations:map[string]string{deployment.kubernetes.io/revision: 1,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*0,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[{Available True 2019-03-01 09:07:04 +0000 UTC 2019-03-01 09:07:04 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2019-03-01 09:07:06 +0000 UTC 2019-03-01 09:07:04 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-cleanup-deployment-755f6b95cc" has successfully progressed.}],ReadyReplicas:1,CollisionCount:nil,},}

Mar  1 09:07:08.614: INFO: New ReplicaSet "test-cleanup-deployment-755f6b95cc" of Deployment "test-cleanup-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-deployment-755f6b95cc,GenerateName:,Namespace:e2e-tests-deployment-zn4k2,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-zn4k2/replicasets/test-cleanup-deployment-755f6b95cc,UID:61b892ed-3c01-11e9-b4e8-fa9e8069966e,ResourceVersion:18742,Generation:1,CreationTimestamp:2019-03-01 09:07:04 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod-template-hash: 755f6b95cc,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-cleanup-deployment 61b64e88-3c01-11e9-b4e8-fa9e8069966e 0xc00273a3d7 0xc00273a3d8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,pod-template-hash: 755f6b95cc,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod-template-hash: 755f6b95cc,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Mar  1 09:07:08.651: INFO: Pod "test-cleanup-deployment-755f6b95cc-kbhhg" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-deployment-755f6b95cc-kbhhg,GenerateName:test-cleanup-deployment-755f6b95cc-,Namespace:e2e-tests-deployment-zn4k2,SelfLink:/api/v1/namespaces/e2e-tests-deployment-zn4k2/pods/test-cleanup-deployment-755f6b95cc-kbhhg,UID:61b91324-3c01-11e9-b4e8-fa9e8069966e,ResourceVersion:18741,Generation:0,CreationTimestamp:2019-03-01 09:07:04 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod-template-hash: 755f6b95cc,},Annotations:map[string]string{cni.projectcalico.org/podIP: 100.96.1.193/32,kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet test-cleanup-deployment-755f6b95cc 61b892ed-3c01-11e9-b4e8-fa9e8069966e 0xc001912917 0xc001912918}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-2q8nz {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-2q8nz,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-2q8nz true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--pub-az-nl4q9-cpu-worker-7dd9bbfd9c-7fp9l,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001912f20} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001912f40}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 09:07:04 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 09:07:06 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 09:07:06 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 09:07:04 +0000 UTC  }],Message:,Reason:,HostIP:10.250.0.4,PodIP:100.96.1.193,StartTime:2019-03-01 09:07:04 +0000 UTC,ContainerStatuses:[{redis {nil ContainerStateRunning{StartedAt:2019-03-01 09:07:06 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/redis:1.0 docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830 docker://9cd5b04c5235d45e1fb9ce021872ffc08ca52a8cf061751c64610a0778cb6564}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 09:07:08.651: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-zn4k2" for this suite.
Mar  1 09:07:14.796: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 09:07:15.776: INFO: namespace: e2e-tests-deployment-zn4k2, resource: bindings, ignored listing per whitelist
Mar  1 09:07:16.241: INFO: namespace e2e-tests-deployment-zn4k2 deletion completed in 7.553822361s

• [SLOW TEST:17.756 seconds]
[sig-apps] Deployment
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  deployment should delete old replica sets [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Variable Expansion
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 09:07:16.241: INFO: >>> kubeConfig: /tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename var-expansion
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-var-expansion-96j6p
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's args [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test substitution in container's args
Mar  1 09:07:17.825: INFO: Waiting up to 5m0s for pod "var-expansion-69b8d3b8-3c01-11e9-a72e-ce8290b78775" in namespace "e2e-tests-var-expansion-96j6p" to be "success or failure"
Mar  1 09:07:17.860: INFO: Pod "var-expansion-69b8d3b8-3c01-11e9-a72e-ce8290b78775": Phase="Pending", Reason="", readiness=false. Elapsed: 35.175995ms
Mar  1 09:07:19.897: INFO: Pod "var-expansion-69b8d3b8-3c01-11e9-a72e-ce8290b78775": Phase="Pending", Reason="", readiness=false. Elapsed: 2.071558171s
Mar  1 09:07:21.933: INFO: Pod "var-expansion-69b8d3b8-3c01-11e9-a72e-ce8290b78775": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.107996707s
STEP: Saw pod success
Mar  1 09:07:21.933: INFO: Pod "var-expansion-69b8d3b8-3c01-11e9-a72e-ce8290b78775" satisfied condition "success or failure"
Mar  1 09:07:21.968: INFO: Trying to get logs from node shoot--it--pub-az-nl4q9-cpu-worker-7dd9bbfd9c-7fp9l pod var-expansion-69b8d3b8-3c01-11e9-a72e-ce8290b78775 container dapi-container: <nil>
STEP: delete the pod
Mar  1 09:07:22.052: INFO: Waiting for pod var-expansion-69b8d3b8-3c01-11e9-a72e-ce8290b78775 to disappear
Mar  1 09:07:22.088: INFO: Pod var-expansion-69b8d3b8-3c01-11e9-a72e-ce8290b78775 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 09:07:22.088: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-var-expansion-96j6p" for this suite.
Mar  1 09:07:28.241: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 09:07:29.152: INFO: namespace: e2e-tests-var-expansion-96j6p, resource: bindings, ignored listing per whitelist
Mar  1 09:07:29.772: INFO: namespace e2e-tests-var-expansion-96j6p deletion completed in 7.647919817s

• [SLOW TEST:13.531 seconds]
[k8s.io] Variable Expansion
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 09:07:29.772: INFO: >>> kubeConfig: /tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-secrets-2lrgg
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-71f34292-3c01-11e9-a72e-ce8290b78775
STEP: Creating a pod to test consume secrets
Mar  1 09:07:31.666: INFO: Waiting up to 5m0s for pod "pod-secrets-71f8d391-3c01-11e9-a72e-ce8290b78775" in namespace "e2e-tests-secrets-2lrgg" to be "success or failure"
Mar  1 09:07:31.702: INFO: Pod "pod-secrets-71f8d391-3c01-11e9-a72e-ce8290b78775": Phase="Pending", Reason="", readiness=false. Elapsed: 35.23641ms
Mar  1 09:07:33.738: INFO: Pod "pod-secrets-71f8d391-3c01-11e9-a72e-ce8290b78775": Phase="Pending", Reason="", readiness=false. Elapsed: 2.071972852s
Mar  1 09:07:35.775: INFO: Pod "pod-secrets-71f8d391-3c01-11e9-a72e-ce8290b78775": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.108646538s
STEP: Saw pod success
Mar  1 09:07:35.775: INFO: Pod "pod-secrets-71f8d391-3c01-11e9-a72e-ce8290b78775" satisfied condition "success or failure"
Mar  1 09:07:35.811: INFO: Trying to get logs from node shoot--it--pub-az-nl4q9-cpu-worker-7dd9bbfd9c-7fp9l pod pod-secrets-71f8d391-3c01-11e9-a72e-ce8290b78775 container secret-volume-test: <nil>
STEP: delete the pod
Mar  1 09:07:35.896: INFO: Waiting for pod pod-secrets-71f8d391-3c01-11e9-a72e-ce8290b78775 to disappear
Mar  1 09:07:35.934: INFO: Pod pod-secrets-71f8d391-3c01-11e9-a72e-ce8290b78775 no longer exists
[AfterEach] [sig-storage] Secrets
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 09:07:35.935: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-2lrgg" for this suite.
Mar  1 09:07:42.083: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 09:07:42.769: INFO: namespace: e2e-tests-secrets-2lrgg, resource: bindings, ignored listing per whitelist
Mar  1 09:07:43.490: INFO: namespace e2e-tests-secrets-2lrgg deletion completed in 7.519564683s

• [SLOW TEST:13.718 seconds]
[sig-storage] Secrets
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should create and stop a replication controller  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 09:07:43.491: INFO: >>> kubeConfig: /tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-dw72q
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Update Demo
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:293
[It] should create and stop a replication controller  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a replication controller
Mar  1 09:07:45.093: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-az-nl4q9.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml create -f - --namespace=e2e-tests-kubectl-dw72q'
Mar  1 09:07:45.782: INFO: stderr: ""
Mar  1 09:07:45.782: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Mar  1 09:07:45.782: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-az-nl4q9.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-dw72q'
Mar  1 09:07:46.022: INFO: stderr: ""
Mar  1 09:07:46.023: INFO: stdout: "update-demo-nautilus-tdrj4 update-demo-nautilus-xk25l "
Mar  1 09:07:46.023: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-az-nl4q9.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml get pods update-demo-nautilus-tdrj4 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-dw72q'
Mar  1 09:07:46.252: INFO: stderr: ""
Mar  1 09:07:46.252: INFO: stdout: ""
Mar  1 09:07:46.252: INFO: update-demo-nautilus-tdrj4 is created but not running
Mar  1 09:07:51.253: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-az-nl4q9.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-dw72q'
Mar  1 09:07:51.573: INFO: stderr: ""
Mar  1 09:07:51.573: INFO: stdout: "update-demo-nautilus-tdrj4 update-demo-nautilus-xk25l "
Mar  1 09:07:51.573: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-az-nl4q9.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml get pods update-demo-nautilus-tdrj4 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-dw72q'
Mar  1 09:07:51.904: INFO: stderr: ""
Mar  1 09:07:51.904: INFO: stdout: "true"
Mar  1 09:07:51.904: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-az-nl4q9.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml get pods update-demo-nautilus-tdrj4 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-dw72q'
Mar  1 09:07:52.177: INFO: stderr: ""
Mar  1 09:07:52.177: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Mar  1 09:07:52.177: INFO: validating pod update-demo-nautilus-tdrj4
Mar  1 09:07:52.298: INFO: got data: {
  "image": "nautilus.jpg"
}

Mar  1 09:07:52.298: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Mar  1 09:07:52.298: INFO: update-demo-nautilus-tdrj4 is verified up and running
Mar  1 09:07:52.298: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-az-nl4q9.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml get pods update-demo-nautilus-xk25l -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-dw72q'
Mar  1 09:07:52.579: INFO: stderr: ""
Mar  1 09:07:52.579: INFO: stdout: "true"
Mar  1 09:07:52.579: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-az-nl4q9.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml get pods update-demo-nautilus-xk25l -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-dw72q'
Mar  1 09:07:52.806: INFO: stderr: ""
Mar  1 09:07:52.806: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Mar  1 09:07:52.806: INFO: validating pod update-demo-nautilus-xk25l
Mar  1 09:07:52.926: INFO: got data: {
  "image": "nautilus.jpg"
}

Mar  1 09:07:52.926: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Mar  1 09:07:52.926: INFO: update-demo-nautilus-xk25l is verified up and running
STEP: using delete to clean up resources
Mar  1 09:07:52.926: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-az-nl4q9.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-dw72q'
Mar  1 09:07:53.210: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Mar  1 09:07:53.210: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Mar  1 09:07:53.210: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-az-nl4q9.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml get rc,svc -l name=update-demo --no-headers --namespace=e2e-tests-kubectl-dw72q'
Mar  1 09:07:53.526: INFO: stderr: "No resources found.\n"
Mar  1 09:07:53.526: INFO: stdout: ""
Mar  1 09:07:53.526: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-az-nl4q9.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml get pods -l name=update-demo --namespace=e2e-tests-kubectl-dw72q -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Mar  1 09:07:53.782: INFO: stderr: ""
Mar  1 09:07:53.782: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 09:07:53.782: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-dw72q" for this suite.
Mar  1 09:08:17.927: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 09:08:18.834: INFO: namespace: e2e-tests-kubectl-dw72q, resource: bindings, ignored listing per whitelist
Mar  1 09:08:19.336: INFO: namespace e2e-tests-kubectl-dw72q deletion completed in 25.517423254s

• [SLOW TEST:35.845 seconds]
[sig-cli] Kubectl client
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Update Demo
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create and stop a replication controller  [Conformance]
    /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,tmpfs) [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 09:08:19.336: INFO: >>> kubeConfig: /tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-wsh9k
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,tmpfs) [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0777 on tmpfs
Mar  1 09:08:21.088: INFO: Waiting up to 5m0s for pod "pod-8f6dff29-3c01-11e9-a72e-ce8290b78775" in namespace "e2e-tests-emptydir-wsh9k" to be "success or failure"
Mar  1 09:08:21.123: INFO: Pod "pod-8f6dff29-3c01-11e9-a72e-ce8290b78775": Phase="Pending", Reason="", readiness=false. Elapsed: 35.061683ms
Mar  1 09:08:23.159: INFO: Pod "pod-8f6dff29-3c01-11e9-a72e-ce8290b78775": Phase="Pending", Reason="", readiness=false. Elapsed: 2.070740381s
Mar  1 09:08:25.195: INFO: Pod "pod-8f6dff29-3c01-11e9-a72e-ce8290b78775": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.106986888s
STEP: Saw pod success
Mar  1 09:08:25.195: INFO: Pod "pod-8f6dff29-3c01-11e9-a72e-ce8290b78775" satisfied condition "success or failure"
Mar  1 09:08:25.232: INFO: Trying to get logs from node shoot--it--pub-az-nl4q9-cpu-worker-7dd9bbfd9c-7fp9l pod pod-8f6dff29-3c01-11e9-a72e-ce8290b78775 container test-container: <nil>
STEP: delete the pod
Mar  1 09:08:25.323: INFO: Waiting for pod pod-8f6dff29-3c01-11e9-a72e-ce8290b78775 to disappear
Mar  1 09:08:25.359: INFO: Pod pod-8f6dff29-3c01-11e9-a72e-ce8290b78775 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 09:08:25.359: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-wsh9k" for this suite.
Mar  1 09:08:31.544: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 09:08:32.612: INFO: namespace: e2e-tests-emptydir-wsh9k, resource: bindings, ignored listing per whitelist
Mar  1 09:08:32.897: INFO: namespace e2e-tests-emptydir-wsh9k deletion completed in 7.460780705s

• [SLOW TEST:13.561 seconds]
[sig-storage] EmptyDir volumes
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0777,tmpfs) [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with secret pod [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 09:08:32.897: INFO: >>> kubeConfig: /tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-subpath-w4r87
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with secret pod [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-secret-c8q5
STEP: Creating a pod to test atomic-volume-subpath
Mar  1 09:08:34.606: INFO: Waiting up to 5m0s for pod "pod-subpath-test-secret-c8q5" in namespace "e2e-tests-subpath-w4r87" to be "success or failure"
Mar  1 09:08:34.643: INFO: Pod "pod-subpath-test-secret-c8q5": Phase="Pending", Reason="", readiness=false. Elapsed: 37.441176ms
Mar  1 09:08:36.682: INFO: Pod "pod-subpath-test-secret-c8q5": Phase="Pending", Reason="", readiness=false. Elapsed: 2.076456438s
Mar  1 09:08:38.720: INFO: Pod "pod-subpath-test-secret-c8q5": Phase="Pending", Reason="", readiness=false. Elapsed: 4.113678767s
Mar  1 09:08:40.757: INFO: Pod "pod-subpath-test-secret-c8q5": Phase="Running", Reason="", readiness=false. Elapsed: 6.150940593s
Mar  1 09:08:42.794: INFO: Pod "pod-subpath-test-secret-c8q5": Phase="Running", Reason="", readiness=false. Elapsed: 8.188545873s
Mar  1 09:08:44.831: INFO: Pod "pod-subpath-test-secret-c8q5": Phase="Running", Reason="", readiness=false. Elapsed: 10.22514752s
Mar  1 09:08:46.868: INFO: Pod "pod-subpath-test-secret-c8q5": Phase="Running", Reason="", readiness=false. Elapsed: 12.261670141s
Mar  1 09:08:48.904: INFO: Pod "pod-subpath-test-secret-c8q5": Phase="Running", Reason="", readiness=false. Elapsed: 14.297861591s
Mar  1 09:08:50.941: INFO: Pod "pod-subpath-test-secret-c8q5": Phase="Running", Reason="", readiness=false. Elapsed: 16.334687462s
Mar  1 09:08:52.978: INFO: Pod "pod-subpath-test-secret-c8q5": Phase="Running", Reason="", readiness=false. Elapsed: 18.371660238s
Mar  1 09:08:55.014: INFO: Pod "pod-subpath-test-secret-c8q5": Phase="Running", Reason="", readiness=false. Elapsed: 20.408197975s
Mar  1 09:08:57.050: INFO: Pod "pod-subpath-test-secret-c8q5": Phase="Running", Reason="", readiness=false. Elapsed: 22.444276142s
Mar  1 09:08:59.087: INFO: Pod "pod-subpath-test-secret-c8q5": Phase="Running", Reason="", readiness=false. Elapsed: 24.480905806s
Mar  1 09:09:01.125: INFO: Pod "pod-subpath-test-secret-c8q5": Phase="Succeeded", Reason="", readiness=false. Elapsed: 26.519103295s
STEP: Saw pod success
Mar  1 09:09:01.125: INFO: Pod "pod-subpath-test-secret-c8q5" satisfied condition "success or failure"
Mar  1 09:09:01.161: INFO: Trying to get logs from node shoot--it--pub-az-nl4q9-cpu-worker-7dd9bbfd9c-7fp9l pod pod-subpath-test-secret-c8q5 container test-container-subpath-secret-c8q5: <nil>
STEP: delete the pod
Mar  1 09:09:01.256: INFO: Waiting for pod pod-subpath-test-secret-c8q5 to disappear
Mar  1 09:09:01.291: INFO: Pod pod-subpath-test-secret-c8q5 no longer exists
STEP: Deleting pod pod-subpath-test-secret-c8q5
Mar  1 09:09:01.291: INFO: Deleting pod "pod-subpath-test-secret-c8q5" in namespace "e2e-tests-subpath-w4r87"
[AfterEach] [sig-storage] Subpath
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 09:09:01.326: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-w4r87" for this suite.
Mar  1 09:09:07.475: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 09:09:08.446: INFO: namespace: e2e-tests-subpath-w4r87, resource: bindings, ignored listing per whitelist
Mar  1 09:09:08.843: INFO: namespace e2e-tests-subpath-w4r87 deletion completed in 7.477112371s

• [SLOW TEST:35.946 seconds]
[sig-storage] Subpath
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with secret pod [Conformance]
    /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] Projected 
  should provide container's memory request [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 09:09:08.843: INFO: >>> kubeConfig: /tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-9xjcb
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should provide container's memory request [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Mar  1 09:09:10.540: INFO: Waiting up to 5m0s for pod "downwardapi-volume-ace78089-3c01-11e9-a72e-ce8290b78775" in namespace "e2e-tests-projected-9xjcb" to be "success or failure"
Mar  1 09:09:10.581: INFO: Pod "downwardapi-volume-ace78089-3c01-11e9-a72e-ce8290b78775": Phase="Pending", Reason="", readiness=false. Elapsed: 41.253523ms
Mar  1 09:09:12.619: INFO: Pod "downwardapi-volume-ace78089-3c01-11e9-a72e-ce8290b78775": Phase="Pending", Reason="", readiness=false. Elapsed: 2.079259436s
Mar  1 09:09:14.656: INFO: Pod "downwardapi-volume-ace78089-3c01-11e9-a72e-ce8290b78775": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.116221088s
STEP: Saw pod success
Mar  1 09:09:14.656: INFO: Pod "downwardapi-volume-ace78089-3c01-11e9-a72e-ce8290b78775" satisfied condition "success or failure"
Mar  1 09:09:14.694: INFO: Trying to get logs from node shoot--it--pub-az-nl4q9-cpu-worker-7dd9bbfd9c-7fp9l pod downwardapi-volume-ace78089-3c01-11e9-a72e-ce8290b78775 container client-container: <nil>
STEP: delete the pod
Mar  1 09:09:14.786: INFO: Waiting for pod downwardapi-volume-ace78089-3c01-11e9-a72e-ce8290b78775 to disappear
Mar  1 09:09:14.823: INFO: Pod downwardapi-volume-ace78089-3c01-11e9-a72e-ce8290b78775 no longer exists
[AfterEach] [sig-storage] Projected
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 09:09:14.823: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-9xjcb" for this suite.
Mar  1 09:09:20.983: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 09:09:22.104: INFO: namespace: e2e-tests-projected-9xjcb, resource: bindings, ignored listing per whitelist
Mar  1 09:09:22.351: INFO: namespace e2e-tests-projected-9xjcb deletion completed in 7.481158419s

• [SLOW TEST:13.508 seconds]
[sig-storage] Projected
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should provide container's memory request [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: udp [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Networking
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 09:09:22.352: INFO: >>> kubeConfig: /tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename pod-network-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-pod-network-test-r5c9r
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: udp [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-r5c9r
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Mar  1 09:09:24.002: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Mar  1 09:09:44.622: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://100.96.1.201:8080/dial?request=hostName&protocol=udp&host=100.96.1.200&port=8081&tries=1'] Namespace:e2e-tests-pod-network-test-r5c9r PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar  1 09:09:44.622: INFO: >>> kubeConfig: /tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
Mar  1 09:09:45.316: INFO: Waiting for endpoints: map[]
Mar  1 09:09:45.367: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://100.96.1.201:8080/dial?request=hostName&protocol=udp&host=100.96.0.59&port=8081&tries=1'] Namespace:e2e-tests-pod-network-test-r5c9r PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar  1 09:09:45.367: INFO: >>> kubeConfig: /tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
Mar  1 09:09:45.938: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 09:09:45.938: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-r5c9r" for this suite.
Mar  1 09:10:10.085: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 09:10:10.877: INFO: namespace: e2e-tests-pod-network-test-r5c9r, resource: bindings, ignored listing per whitelist
Mar  1 09:10:11.531: INFO: namespace e2e-tests-pod-network-test-r5c9r deletion completed in 25.556495538s

• [SLOW TEST:49.180 seconds]
[sig-network] Networking
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: udp [NodeConformance] [Conformance]
    /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 09:10:11.531: INFO: >>> kubeConfig: /tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename namespaces
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-namespaces-kqbzm
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all services are removed when a namespace is deleted [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a test namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-nsdeletetest-l7dr5
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a service in the namespace
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-nsdeletetest-fmd77
STEP: Verifying there is no service in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 09:10:20.193: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-namespaces-kqbzm" for this suite.
Mar  1 09:10:26.337: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 09:10:27.498: INFO: namespace: e2e-tests-namespaces-kqbzm, resource: bindings, ignored listing per whitelist
Mar  1 09:10:27.818: INFO: namespace e2e-tests-namespaces-kqbzm deletion completed in 7.589077221s
STEP: Destroying namespace "e2e-tests-nsdeletetest-l7dr5" for this suite.
Mar  1 09:10:27.854: INFO: Namespace e2e-tests-nsdeletetest-l7dr5 was already deleted
STEP: Destroying namespace "e2e-tests-nsdeletetest-fmd77" for this suite.
Mar  1 09:10:33.966: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 09:10:34.532: INFO: namespace: e2e-tests-nsdeletetest-fmd77, resource: bindings, ignored listing per whitelist
Mar  1 09:10:35.356: INFO: namespace e2e-tests-nsdeletetest-fmd77 deletion completed in 7.502119479s

• [SLOW TEST:23.825 seconds]
[sig-api-machinery] Namespaces [Serial]
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] version v1
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 09:10:35.357: INFO: >>> kubeConfig: /tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename proxy
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-proxy-blsls
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Mar  1 09:10:37.393: INFO: (0) /api/v1/nodes/shoot--it--pub-az-nl4q9-cpu-worker-7dd9bbfd9c-7fp9l:10250/proxy/logs/: <pre>
<a href="azure/">azure/</a>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<... (200; 268.192982ms)
Mar  1 09:10:37.783: INFO: (1) /api/v1/nodes/shoot--it--pub-az-nl4q9-cpu-worker-7dd9bbfd9c-7fp9l:10250/proxy/logs/: <pre>
<a href="azure/">azure/</a>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<... (200; 389.562007ms)
Mar  1 09:10:37.824: INFO: (2) /api/v1/nodes/shoot--it--pub-az-nl4q9-cpu-worker-7dd9bbfd9c-7fp9l:10250/proxy/logs/: <pre>
<a href="azure/">azure/</a>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<... (200; 41.156608ms)
Mar  1 09:10:37.867: INFO: (3) /api/v1/nodes/shoot--it--pub-az-nl4q9-cpu-worker-7dd9bbfd9c-7fp9l:10250/proxy/logs/: <pre>
<a href="azure/">azure/</a>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<... (200; 43.107793ms)
Mar  1 09:10:37.906: INFO: (4) /api/v1/nodes/shoot--it--pub-az-nl4q9-cpu-worker-7dd9bbfd9c-7fp9l:10250/proxy/logs/: <pre>
<a href="azure/">azure/</a>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<... (200; 38.450282ms)
Mar  1 09:10:37.944: INFO: (5) /api/v1/nodes/shoot--it--pub-az-nl4q9-cpu-worker-7dd9bbfd9c-7fp9l:10250/proxy/logs/: <pre>
<a href="azure/">azure/</a>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<... (200; 38.379034ms)
Mar  1 09:10:37.983: INFO: (6) /api/v1/nodes/shoot--it--pub-az-nl4q9-cpu-worker-7dd9bbfd9c-7fp9l:10250/proxy/logs/: <pre>
<a href="azure/">azure/</a>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<... (200; 38.631765ms)
Mar  1 09:10:38.021: INFO: (7) /api/v1/nodes/shoot--it--pub-az-nl4q9-cpu-worker-7dd9bbfd9c-7fp9l:10250/proxy/logs/: <pre>
<a href="azure/">azure/</a>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<... (200; 37.541847ms)
Mar  1 09:10:38.058: INFO: (8) /api/v1/nodes/shoot--it--pub-az-nl4q9-cpu-worker-7dd9bbfd9c-7fp9l:10250/proxy/logs/: <pre>
<a href="azure/">azure/</a>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<... (200; 37.353302ms)
Mar  1 09:10:38.098: INFO: (9) /api/v1/nodes/shoot--it--pub-az-nl4q9-cpu-worker-7dd9bbfd9c-7fp9l:10250/proxy/logs/: <pre>
<a href="azure/">azure/</a>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<... (200; 39.888979ms)
Mar  1 09:10:38.140: INFO: (10) /api/v1/nodes/shoot--it--pub-az-nl4q9-cpu-worker-7dd9bbfd9c-7fp9l:10250/proxy/logs/: <pre>
<a href="azure/">azure/</a>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<... (200; 41.899013ms)
Mar  1 09:10:38.179: INFO: (11) /api/v1/nodes/shoot--it--pub-az-nl4q9-cpu-worker-7dd9bbfd9c-7fp9l:10250/proxy/logs/: <pre>
<a href="azure/">azure/</a>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<... (200; 38.780651ms)
Mar  1 09:10:38.216: INFO: (12) /api/v1/nodes/shoot--it--pub-az-nl4q9-cpu-worker-7dd9bbfd9c-7fp9l:10250/proxy/logs/: <pre>
<a href="azure/">azure/</a>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<... (200; 37.328345ms)
Mar  1 09:10:38.255: INFO: (13) /api/v1/nodes/shoot--it--pub-az-nl4q9-cpu-worker-7dd9bbfd9c-7fp9l:10250/proxy/logs/: <pre>
<a href="azure/">azure/</a>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<... (200; 38.369641ms)
Mar  1 09:10:38.293: INFO: (14) /api/v1/nodes/shoot--it--pub-az-nl4q9-cpu-worker-7dd9bbfd9c-7fp9l:10250/proxy/logs/: <pre>
<a href="azure/">azure/</a>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<... (200; 37.874435ms)
Mar  1 09:10:38.331: INFO: (15) /api/v1/nodes/shoot--it--pub-az-nl4q9-cpu-worker-7dd9bbfd9c-7fp9l:10250/proxy/logs/: <pre>
<a href="azure/">azure/</a>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<... (200; 38.129885ms)
Mar  1 09:10:38.369: INFO: (16) /api/v1/nodes/shoot--it--pub-az-nl4q9-cpu-worker-7dd9bbfd9c-7fp9l:10250/proxy/logs/: <pre>
<a href="azure/">azure/</a>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<... (200; 37.960899ms)
Mar  1 09:10:38.408: INFO: (17) /api/v1/nodes/shoot--it--pub-az-nl4q9-cpu-worker-7dd9bbfd9c-7fp9l:10250/proxy/logs/: <pre>
<a href="azure/">azure/</a>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<... (200; 38.961216ms)
Mar  1 09:10:38.446: INFO: (18) /api/v1/nodes/shoot--it--pub-az-nl4q9-cpu-worker-7dd9bbfd9c-7fp9l:10250/proxy/logs/: <pre>
<a href="azure/">azure/</a>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<... (200; 37.64735ms)
Mar  1 09:10:38.483: INFO: (19) /api/v1/nodes/shoot--it--pub-az-nl4q9-cpu-worker-7dd9bbfd9c-7fp9l:10250/proxy/logs/: <pre>
<a href="azure/">azure/</a>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<... (200; 37.83291ms)
[AfterEach] version v1
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 09:10:38.484: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-proxy-blsls" for this suite.
Mar  1 09:10:44.629: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 09:10:45.554: INFO: namespace: e2e-tests-proxy-blsls, resource: bindings, ignored listing per whitelist
Mar  1 09:10:45.981: INFO: namespace e2e-tests-proxy-blsls deletion completed in 7.461008988s

• [SLOW TEST:10.624 seconds]
[sig-network] Proxy
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
    /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Downward API volume 
  should update annotations on modification [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 09:10:45.981: INFO: >>> kubeConfig: /tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-hmkqv
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should update annotations on modification [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating the pod
Mar  1 09:10:52.435: INFO: Successfully updated pod "annotationupdatee6c58cef-3c01-11e9-a72e-ce8290b78775"
[AfterEach] [sig-storage] Downward API volume
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 09:10:54.521: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-hmkqv" for this suite.
Mar  1 09:11:16.683: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 09:11:17.246: INFO: namespace: e2e-tests-downward-api-hmkqv, resource: bindings, ignored listing per whitelist
Mar  1 09:11:18.069: INFO: namespace e2e-tests-downward-api-hmkqv deletion completed in 23.50697595s

• [SLOW TEST:32.087 seconds]
[sig-storage] Downward API volume
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should update annotations on modification [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 09:11:18.069: INFO: >>> kubeConfig: /tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-7zz6b
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-map-f9f52f33-3c01-11e9-a72e-ce8290b78775
STEP: Creating a pod to test consume secrets
Mar  1 09:11:19.864: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-f9fb107f-3c01-11e9-a72e-ce8290b78775" in namespace "e2e-tests-projected-7zz6b" to be "success or failure"
Mar  1 09:11:19.899: INFO: Pod "pod-projected-secrets-f9fb107f-3c01-11e9-a72e-ce8290b78775": Phase="Pending", Reason="", readiness=false. Elapsed: 35.348266ms
Mar  1 09:11:21.935: INFO: Pod "pod-projected-secrets-f9fb107f-3c01-11e9-a72e-ce8290b78775": Phase="Pending", Reason="", readiness=false. Elapsed: 2.07165995s
Mar  1 09:11:23.972: INFO: Pod "pod-projected-secrets-f9fb107f-3c01-11e9-a72e-ce8290b78775": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.108415305s
STEP: Saw pod success
Mar  1 09:11:23.972: INFO: Pod "pod-projected-secrets-f9fb107f-3c01-11e9-a72e-ce8290b78775" satisfied condition "success or failure"
Mar  1 09:11:24.008: INFO: Trying to get logs from node shoot--it--pub-az-nl4q9-cpu-worker-7dd9bbfd9c-7fp9l pod pod-projected-secrets-f9fb107f-3c01-11e9-a72e-ce8290b78775 container projected-secret-volume-test: <nil>
STEP: delete the pod
Mar  1 09:11:24.095: INFO: Waiting for pod pod-projected-secrets-f9fb107f-3c01-11e9-a72e-ce8290b78775 to disappear
Mar  1 09:11:24.130: INFO: Pod pod-projected-secrets-f9fb107f-3c01-11e9-a72e-ce8290b78775 no longer exists
[AfterEach] [sig-storage] Projected
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 09:11:24.130: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-7zz6b" for this suite.
Mar  1 09:11:30.295: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 09:11:31.305: INFO: namespace: e2e-tests-projected-7zz6b, resource: bindings, ignored listing per whitelist
Mar  1 09:11:31.711: INFO: namespace e2e-tests-projected-7zz6b deletion completed in 7.525084642s

• [SLOW TEST:13.642 seconds]
[sig-storage] Projected
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should be able to start watching from a specific resource version [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Watchers
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 09:11:31.711: INFO: >>> kubeConfig: /tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-watch-f2mtq
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to start watching from a specific resource version [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: modifying the configmap a second time
STEP: deleting the configmap
STEP: creating a watch on configmaps from the resource version returned by the first update
STEP: Expecting to observe notifications for all changes to the configmap after the first update
Mar  1 09:11:33.539: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-resource-version,GenerateName:,Namespace:e2e-tests-watch-f2mtq,SelfLink:/api/v1/namespaces/e2e-tests-watch-f2mtq/configmaps/e2e-watch-test-resource-version,UID:0205b1ae-3c02-11e9-b4e8-fa9e8069966e,ResourceVersion:19551,Generation:0,CreationTimestamp:2019-03-01 09:11:33 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: from-resource-version,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Mar  1 09:11:33.539: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-resource-version,GenerateName:,Namespace:e2e-tests-watch-f2mtq,SelfLink:/api/v1/namespaces/e2e-tests-watch-f2mtq/configmaps/e2e-watch-test-resource-version,UID:0205b1ae-3c02-11e9-b4e8-fa9e8069966e,ResourceVersion:19552,Generation:0,CreationTimestamp:2019-03-01 09:11:33 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: from-resource-version,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 09:11:33.539: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-f2mtq" for this suite.
Mar  1 09:11:39.697: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 09:11:40.796: INFO: namespace: e2e-tests-watch-f2mtq, resource: bindings, ignored listing per whitelist
Mar  1 09:11:41.142: INFO: namespace e2e-tests-watch-f2mtq deletion completed in 7.562673598s

• [SLOW TEST:9.431 seconds]
[sig-api-machinery] Watchers
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should be able to start watching from a specific resource version [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should have monotonically increasing restart count [Slow][NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 09:11:41.143: INFO: >>> kubeConfig: /tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-container-probe-qvxmj
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should have monotonically increasing restart count [Slow][NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-http in namespace e2e-tests-container-probe-qvxmj
Mar  1 09:11:46.807: INFO: Started pod liveness-http in namespace e2e-tests-container-probe-qvxmj
STEP: checking the pod's current state and verifying that restartCount is present
Mar  1 09:11:46.842: INFO: Initial restart count of pod liveness-http is 0
Mar  1 09:12:05.210: INFO: Restart count of pod e2e-tests-container-probe-qvxmj/liveness-http is now 1 (18.367571466s elapsed)
Mar  1 09:12:25.586: INFO: Restart count of pod e2e-tests-container-probe-qvxmj/liveness-http is now 2 (38.743150538s elapsed)
Mar  1 09:12:45.952: INFO: Restart count of pod e2e-tests-container-probe-qvxmj/liveness-http is now 3 (59.10999499s elapsed)
Mar  1 09:13:06.317: INFO: Restart count of pod e2e-tests-container-probe-qvxmj/liveness-http is now 4 (1m19.474729935s elapsed)
Mar  1 09:14:15.610: INFO: Restart count of pod e2e-tests-container-probe-qvxmj/liveness-http is now 5 (2m28.767298581s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 09:14:15.659: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-qvxmj" for this suite.
Mar  1 09:14:21.841: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 09:14:22.990: INFO: namespace: e2e-tests-container-probe-qvxmj, resource: bindings, ignored listing per whitelist
Mar  1 09:14:23.240: INFO: namespace e2e-tests-container-probe-qvxmj deletion completed in 7.544612422s

• [SLOW TEST:162.097 seconds]
[k8s.io] Probing container
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should have monotonically increasing restart count [Slow][NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ConfigMap 
  should be consumable via environment variable [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] ConfigMap
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 09:14:23.240: INFO: >>> kubeConfig: /tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-2xsjl
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via environment variable [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap e2e-tests-configmap-2xsjl/configmap-test-683bb0ae-3c02-11e9-a72e-ce8290b78775
STEP: Creating a pod to test consume configMaps
Mar  1 09:14:24.860: INFO: Waiting up to 5m0s for pod "pod-configmaps-68412d92-3c02-11e9-a72e-ce8290b78775" in namespace "e2e-tests-configmap-2xsjl" to be "success or failure"
Mar  1 09:14:24.898: INFO: Pod "pod-configmaps-68412d92-3c02-11e9-a72e-ce8290b78775": Phase="Pending", Reason="", readiness=false. Elapsed: 38.083144ms
Mar  1 09:14:26.935: INFO: Pod "pod-configmaps-68412d92-3c02-11e9-a72e-ce8290b78775": Phase="Pending", Reason="", readiness=false. Elapsed: 2.075099471s
Mar  1 09:14:28.972: INFO: Pod "pod-configmaps-68412d92-3c02-11e9-a72e-ce8290b78775": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.111656693s
STEP: Saw pod success
Mar  1 09:14:28.972: INFO: Pod "pod-configmaps-68412d92-3c02-11e9-a72e-ce8290b78775" satisfied condition "success or failure"
Mar  1 09:14:29.007: INFO: Trying to get logs from node shoot--it--pub-az-nl4q9-cpu-worker-7dd9bbfd9c-7fp9l pod pod-configmaps-68412d92-3c02-11e9-a72e-ce8290b78775 container env-test: <nil>
STEP: delete the pod
Mar  1 09:14:29.093: INFO: Waiting for pod pod-configmaps-68412d92-3c02-11e9-a72e-ce8290b78775 to disappear
Mar  1 09:14:29.132: INFO: Pod pod-configmaps-68412d92-3c02-11e9-a72e-ce8290b78775 no longer exists
[AfterEach] [sig-api-machinery] ConfigMap
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 09:14:29.132: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-2xsjl" for this suite.
Mar  1 09:14:35.276: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 09:14:35.672: INFO: namespace: e2e-tests-configmap-2xsjl, resource: bindings, ignored listing per whitelist
Mar  1 09:14:36.703: INFO: namespace e2e-tests-configmap-2xsjl deletion completed in 7.53443046s

• [SLOW TEST:13.463 seconds]
[sig-api-machinery] ConfigMap
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:30
  should be consumable via environment variable [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[k8s.io] [sig-node] Events 
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] [sig-node] Events
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 09:14:36.703: INFO: >>> kubeConfig: /tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename events
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-events-q5zvt
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: retrieving the pod
Mar  1 09:14:42.583: INFO: &Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:send-events-7056250f-3c02-11e9-a72e-ce8290b78775,GenerateName:,Namespace:e2e-tests-events-q5zvt,SelfLink:/api/v1/namespaces/e2e-tests-events-q5zvt/pods/send-events-7056250f-3c02-11e9-a72e-ce8290b78775,UID:70590455-3c02-11e9-b4e8-fa9e8069966e,ResourceVersion:19976,Generation:0,CreationTimestamp:2019-03-01 09:14:38 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: foo,time: 380575773,},Annotations:map[string]string{cni.projectcalico.org/podIP: 100.96.1.206/32,kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-7r47k {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-7r47k,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{p gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1 [] []  [{ 0 80 TCP }] [] [] {map[] map[]} [{default-token-7r47k true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*30,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--pub-az-nl4q9-cpu-worker-7dd9bbfd9c-7fp9l,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001fcd5d0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001fcd5f0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 09:14:38 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 09:14:40 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 09:14:40 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 09:14:38 +0000 UTC  }],Message:,Reason:,HostIP:10.250.0.4,PodIP:100.96.1.206,StartTime:2019-03-01 09:14:38 +0000 UTC,ContainerStatuses:[{p {nil ContainerStateRunning{StartedAt:2019-03-01 09:14:40 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1 docker-pullable://gcr.io/kubernetes-e2e-test-images/serve-hostname@sha256:bab70473a6d8ef65a22625dc9a1b0f0452e811530fdbe77e4408523460177ff1 docker://e8144b4bf87469f0e4f48602aefbf55e8aec679eac56ec0fea7af4e7d30edfa4}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}

STEP: checking for scheduler event about the pod
Mar  1 09:14:44.619: INFO: Saw scheduler event for our pod.
STEP: checking for kubelet event about the pod
Mar  1 09:14:46.656: INFO: Saw kubelet event for our pod.
STEP: deleting the pod
[AfterEach] [k8s.io] [sig-node] Events
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 09:14:46.694: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-events-q5zvt" for this suite.
Mar  1 09:15:26.840: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 09:15:28.061: INFO: namespace: e2e-tests-events-q5zvt, resource: bindings, ignored listing per whitelist
Mar  1 09:15:28.239: INFO: namespace e2e-tests-events-q5zvt deletion completed in 41.507446043s

• [SLOW TEST:51.536 seconds]
[k8s.io] [sig-node] Events
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 09:15:28.239: INFO: >>> kubeConfig: /tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-wtrh4
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-map-8f082f36-3c02-11e9-a72e-ce8290b78775
STEP: Creating a pod to test consume configMaps
Mar  1 09:15:29.953: INFO: Waiting up to 5m0s for pod "pod-configmaps-8f0da61f-3c02-11e9-a72e-ce8290b78775" in namespace "e2e-tests-configmap-wtrh4" to be "success or failure"
Mar  1 09:15:29.988: INFO: Pod "pod-configmaps-8f0da61f-3c02-11e9-a72e-ce8290b78775": Phase="Pending", Reason="", readiness=false. Elapsed: 35.569987ms
Mar  1 09:15:32.025: INFO: Pod "pod-configmaps-8f0da61f-3c02-11e9-a72e-ce8290b78775": Phase="Pending", Reason="", readiness=false. Elapsed: 2.072377182s
Mar  1 09:15:34.062: INFO: Pod "pod-configmaps-8f0da61f-3c02-11e9-a72e-ce8290b78775": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.109539732s
STEP: Saw pod success
Mar  1 09:15:34.063: INFO: Pod "pod-configmaps-8f0da61f-3c02-11e9-a72e-ce8290b78775" satisfied condition "success or failure"
Mar  1 09:15:34.099: INFO: Trying to get logs from node shoot--it--pub-az-nl4q9-cpu-worker-7dd9bbfd9c-7fp9l pod pod-configmaps-8f0da61f-3c02-11e9-a72e-ce8290b78775 container configmap-volume-test: <nil>
STEP: delete the pod
Mar  1 09:15:34.211: INFO: Waiting for pod pod-configmaps-8f0da61f-3c02-11e9-a72e-ce8290b78775 to disappear
Mar  1 09:15:34.247: INFO: Pod pod-configmaps-8f0da61f-3c02-11e9-a72e-ce8290b78775 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 09:15:34.247: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-wtrh4" for this suite.
Mar  1 09:15:40.399: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 09:15:41.638: INFO: namespace: e2e-tests-configmap-wtrh4, resource: bindings, ignored listing per whitelist
Mar  1 09:15:41.817: INFO: namespace e2e-tests-configmap-wtrh4 deletion completed in 7.532644457s

• [SLOW TEST:13.578 seconds]
[sig-storage] ConfigMap
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 09:15:41.817: INFO: >>> kubeConfig: /tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-deployment-j9tbd
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] RecreateDeployment should delete old pods and create new ones [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Mar  1 09:15:43.482: INFO: Creating deployment "test-recreate-deployment"
Mar  1 09:15:43.519: INFO: Waiting deployment "test-recreate-deployment" to be updated to revision 1
Mar  1 09:15:43.593: INFO: Waiting deployment "test-recreate-deployment" to complete
Mar  1 09:15:43.629: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63687028543, loc:(*time.Location)(0x78fbda0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63687028543, loc:(*time.Location)(0x78fbda0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63687028543, loc:(*time.Location)(0x78fbda0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63687028543, loc:(*time.Location)(0x78fbda0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-recreate-deployment-79f694ff59\" is progressing."}}, CollisionCount:(*int32)(nil)}
Mar  1 09:15:45.666: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63687028543, loc:(*time.Location)(0x78fbda0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63687028543, loc:(*time.Location)(0x78fbda0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63687028543, loc:(*time.Location)(0x78fbda0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63687028543, loc:(*time.Location)(0x78fbda0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-recreate-deployment-79f694ff59\" is progressing."}}, CollisionCount:(*int32)(nil)}
Mar  1 09:15:47.665: INFO: Triggering a new rollout for deployment "test-recreate-deployment"
Mar  1 09:15:47.736: INFO: Updating deployment test-recreate-deployment
Mar  1 09:15:47.736: INFO: Watching deployment "test-recreate-deployment" to verify that new pods will not run with olds pods
[AfterEach] [sig-apps] Deployment
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Mar  1 09:15:48.002: INFO: Deployment "test-recreate-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment,GenerateName:,Namespace:e2e-tests-deployment-j9tbd,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-j9tbd/deployments/test-recreate-deployment,UID:97266ba4-3c02-11e9-b4e8-fa9e8069966e,ResourceVersion:20168,Generation:2,CreationTimestamp:2019-03-01 09:15:43 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},Strategy:DeploymentStrategy{Type:Recreate,RollingUpdate:nil,},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:0,UnavailableReplicas:1,Conditions:[{Available False 2019-03-01 09:15:47 +0000 UTC 2019-03-01 09:15:47 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.} {Progressing True 2019-03-01 09:15:47 +0000 UTC 2019-03-01 09:15:43 +0000 UTC ReplicaSetUpdated ReplicaSet "test-recreate-deployment-7cf749666b" is progressing.}],ReadyReplicas:0,CollisionCount:nil,},}

Mar  1 09:15:48.039: INFO: New ReplicaSet "test-recreate-deployment-7cf749666b" of Deployment "test-recreate-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-7cf749666b,GenerateName:,Namespace:e2e-tests-deployment-j9tbd,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-j9tbd/replicasets/test-recreate-deployment-7cf749666b,UID:99b3c6a7-3c02-11e9-b4e8-fa9e8069966e,ResourceVersion:20167,Generation:1,CreationTimestamp:2019-03-01 09:15:47 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 7cf749666b,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 1,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment test-recreate-deployment 97266ba4-3c02-11e9-b4e8-fa9e8069966e 0xc00297c027 0xc00297c028}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 7cf749666b,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 7cf749666b,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Mar  1 09:15:48.039: INFO: All old ReplicaSets of Deployment "test-recreate-deployment":
Mar  1 09:15:48.039: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-79f694ff59,GenerateName:,Namespace:e2e-tests-deployment-j9tbd,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-j9tbd/replicasets/test-recreate-deployment-79f694ff59,UID:972798db-3c02-11e9-b4e8-fa9e8069966e,ResourceVersion:20160,Generation:2,CreationTimestamp:2019-03-01 09:15:43 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 79f694ff59,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 1,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-recreate-deployment 97266ba4-3c02-11e9-b4e8-fa9e8069966e 0xc001fe1e77 0xc001fe1e78}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 79f694ff59,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 79f694ff59,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Mar  1 09:15:48.076: INFO: Pod "test-recreate-deployment-7cf749666b-6wq94" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-7cf749666b-6wq94,GenerateName:test-recreate-deployment-7cf749666b-,Namespace:e2e-tests-deployment-j9tbd,SelfLink:/api/v1/namespaces/e2e-tests-deployment-j9tbd/pods/test-recreate-deployment-7cf749666b-6wq94,UID:99bd94c1-3c02-11e9-b4e8-fa9e8069966e,ResourceVersion:20166,Generation:0,CreationTimestamp:2019-03-01 09:15:47 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 7cf749666b,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet test-recreate-deployment-7cf749666b 99b3c6a7-3c02-11e9-b4e8-fa9e8069966e 0xc000d32437 0xc000d32438}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-scd4k {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-scd4k,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-scd4k true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--pub-az-nl4q9-cpu-worker-7dd9bbfd9c-7fp9l,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc000d32550} {node.kubernetes.io/unreachable Exists  NoExecute 0xc000d32570}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 09:15:47 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 09:15:48.076: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-j9tbd" for this suite.
Mar  1 09:15:54.225: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 09:15:55.186: INFO: namespace: e2e-tests-deployment-j9tbd, resource: bindings, ignored listing per whitelist
Mar  1 09:15:55.665: INFO: namespace e2e-tests-deployment-j9tbd deletion completed in 7.552245459s

• [SLOW TEST:13.848 seconds]
[sig-apps] Deployment
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,tmpfs) [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 09:15:55.665: INFO: >>> kubeConfig: /tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-64tm8
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,tmpfs) [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0666 on tmpfs
Mar  1 09:15:57.223: INFO: Waiting up to 5m0s for pod "pod-9f4eb296-3c02-11e9-a72e-ce8290b78775" in namespace "e2e-tests-emptydir-64tm8" to be "success or failure"
Mar  1 09:15:57.271: INFO: Pod "pod-9f4eb296-3c02-11e9-a72e-ce8290b78775": Phase="Pending", Reason="", readiness=false. Elapsed: 48.534804ms
Mar  1 09:15:59.308: INFO: Pod "pod-9f4eb296-3c02-11e9-a72e-ce8290b78775": Phase="Pending", Reason="", readiness=false. Elapsed: 2.084904522s
Mar  1 09:16:01.347: INFO: Pod "pod-9f4eb296-3c02-11e9-a72e-ce8290b78775": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.12434368s
STEP: Saw pod success
Mar  1 09:16:01.347: INFO: Pod "pod-9f4eb296-3c02-11e9-a72e-ce8290b78775" satisfied condition "success or failure"
Mar  1 09:16:01.383: INFO: Trying to get logs from node shoot--it--pub-az-nl4q9-cpu-worker-7dd9bbfd9c-7fp9l pod pod-9f4eb296-3c02-11e9-a72e-ce8290b78775 container test-container: <nil>
STEP: delete the pod
Mar  1 09:16:01.466: INFO: Waiting for pod pod-9f4eb296-3c02-11e9-a72e-ce8290b78775 to disappear
Mar  1 09:16:01.527: INFO: Pod pod-9f4eb296-3c02-11e9-a72e-ce8290b78775 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 09:16:01.527: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-64tm8" for this suite.
Mar  1 09:16:07.675: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 09:16:08.994: INFO: namespace: e2e-tests-emptydir-64tm8, resource: bindings, ignored listing per whitelist
Mar  1 09:16:09.065: INFO: namespace e2e-tests-emptydir-64tm8 deletion completed in 7.502942401s

• [SLOW TEST:13.400 seconds]
[sig-storage] EmptyDir volumes
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0666,tmpfs) [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Projected 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 09:16:09.065: INFO: >>> kubeConfig: /tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-rnvsb
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Mar  1 09:16:10.711: INFO: Waiting up to 5m0s for pod "downwardapi-volume-a758cef5-3c02-11e9-a72e-ce8290b78775" in namespace "e2e-tests-projected-rnvsb" to be "success or failure"
Mar  1 09:16:10.746: INFO: Pod "downwardapi-volume-a758cef5-3c02-11e9-a72e-ce8290b78775": Phase="Pending", Reason="", readiness=false. Elapsed: 35.304875ms
Mar  1 09:16:12.784: INFO: Pod "downwardapi-volume-a758cef5-3c02-11e9-a72e-ce8290b78775": Phase="Pending", Reason="", readiness=false. Elapsed: 2.072939443s
Mar  1 09:16:14.823: INFO: Pod "downwardapi-volume-a758cef5-3c02-11e9-a72e-ce8290b78775": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.112436432s
STEP: Saw pod success
Mar  1 09:16:14.823: INFO: Pod "downwardapi-volume-a758cef5-3c02-11e9-a72e-ce8290b78775" satisfied condition "success or failure"
Mar  1 09:16:14.860: INFO: Trying to get logs from node shoot--it--pub-az-nl4q9-cpu-worker-7dd9bbfd9c-7fp9l pod downwardapi-volume-a758cef5-3c02-11e9-a72e-ce8290b78775 container client-container: <nil>
STEP: delete the pod
Mar  1 09:16:14.976: INFO: Waiting for pod downwardapi-volume-a758cef5-3c02-11e9-a72e-ce8290b78775 to disappear
Mar  1 09:16:15.013: INFO: Pod downwardapi-volume-a758cef5-3c02-11e9-a72e-ce8290b78775 no longer exists
[AfterEach] [sig-storage] Projected
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 09:16:15.013: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-rnvsb" for this suite.
Mar  1 09:16:21.160: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 09:16:21.484: INFO: namespace: e2e-tests-projected-rnvsb, resource: bindings, ignored listing per whitelist
Mar  1 09:16:22.547: INFO: namespace e2e-tests-projected-rnvsb deletion completed in 7.494301468s

• [SLOW TEST:13.482 seconds]
[sig-storage] Projected
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 09:16:22.547: INFO: >>> kubeConfig: /tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename init-container
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-init-container-22wct
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
Mar  1 09:16:24.082: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 09:16:28.963: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-init-container-22wct" for this suite.
Mar  1 09:16:35.114: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 09:16:35.401: INFO: namespace: e2e-tests-init-container-22wct, resource: bindings, ignored listing per whitelist
Mar  1 09:16:36.522: INFO: namespace e2e-tests-init-container-22wct deletion completed in 7.517563938s

• [SLOW TEST:13.975 seconds]
[k8s.io] InitContainer [NodeConformance]
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 09:16:36.522: INFO: >>> kubeConfig: /tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-kcdpk
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-map-b7afd5b1-3c02-11e9-a72e-ce8290b78775
STEP: Creating a pod to test consume configMaps
Mar  1 09:16:38.163: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-b7b55959-3c02-11e9-a72e-ce8290b78775" in namespace "e2e-tests-projected-kcdpk" to be "success or failure"
Mar  1 09:16:38.215: INFO: Pod "pod-projected-configmaps-b7b55959-3c02-11e9-a72e-ce8290b78775": Phase="Pending", Reason="", readiness=false. Elapsed: 52.468574ms
Mar  1 09:16:40.253: INFO: Pod "pod-projected-configmaps-b7b55959-3c02-11e9-a72e-ce8290b78775": Phase="Pending", Reason="", readiness=false. Elapsed: 2.090236831s
Mar  1 09:16:42.290: INFO: Pod "pod-projected-configmaps-b7b55959-3c02-11e9-a72e-ce8290b78775": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.127467912s
STEP: Saw pod success
Mar  1 09:16:42.290: INFO: Pod "pod-projected-configmaps-b7b55959-3c02-11e9-a72e-ce8290b78775" satisfied condition "success or failure"
Mar  1 09:16:42.327: INFO: Trying to get logs from node shoot--it--pub-az-nl4q9-cpu-worker-7dd9bbfd9c-7fp9l pod pod-projected-configmaps-b7b55959-3c02-11e9-a72e-ce8290b78775 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Mar  1 09:16:42.427: INFO: Waiting for pod pod-projected-configmaps-b7b55959-3c02-11e9-a72e-ce8290b78775 to disappear
Mar  1 09:16:42.463: INFO: Pod pod-projected-configmaps-b7b55959-3c02-11e9-a72e-ce8290b78775 no longer exists
[AfterEach] [sig-storage] Projected
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 09:16:42.463: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-kcdpk" for this suite.
Mar  1 09:16:50.611: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 09:16:51.949: INFO: namespace: e2e-tests-projected-kcdpk, resource: bindings, ignored listing per whitelist
Mar  1 09:16:52.020: INFO: namespace e2e-tests-projected-kcdpk deletion completed in 9.519125815s

• [SLOW TEST:15.498 seconds]
[sig-storage] Projected
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should set DefaultMode on files [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 09:16:52.021: INFO: >>> kubeConfig: /tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-k9qhm
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should set DefaultMode on files [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Mar  1 09:16:53.720: INFO: Waiting up to 5m0s for pod "downwardapi-volume-c0fb7e08-3c02-11e9-a72e-ce8290b78775" in namespace "e2e-tests-downward-api-k9qhm" to be "success or failure"
Mar  1 09:16:53.763: INFO: Pod "downwardapi-volume-c0fb7e08-3c02-11e9-a72e-ce8290b78775": Phase="Pending", Reason="", readiness=false. Elapsed: 42.592173ms
Mar  1 09:16:55.799: INFO: Pod "downwardapi-volume-c0fb7e08-3c02-11e9-a72e-ce8290b78775": Phase="Pending", Reason="", readiness=false. Elapsed: 2.078804703s
Mar  1 09:16:57.836: INFO: Pod "downwardapi-volume-c0fb7e08-3c02-11e9-a72e-ce8290b78775": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.115663333s
STEP: Saw pod success
Mar  1 09:16:57.836: INFO: Pod "downwardapi-volume-c0fb7e08-3c02-11e9-a72e-ce8290b78775" satisfied condition "success or failure"
Mar  1 09:16:57.872: INFO: Trying to get logs from node shoot--it--pub-az-nl4q9-cpu-worker-7dd9bbfd9c-7fp9l pod downwardapi-volume-c0fb7e08-3c02-11e9-a72e-ce8290b78775 container client-container: <nil>
STEP: delete the pod
Mar  1 09:16:57.959: INFO: Waiting for pod downwardapi-volume-c0fb7e08-3c02-11e9-a72e-ce8290b78775 to disappear
Mar  1 09:16:57.994: INFO: Pod downwardapi-volume-c0fb7e08-3c02-11e9-a72e-ce8290b78775 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 09:16:57.995: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-k9qhm" for this suite.
Mar  1 09:17:04.144: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 09:17:04.826: INFO: namespace: e2e-tests-downward-api-k9qhm, resource: bindings, ignored listing per whitelist
Mar  1 09:17:05.533: INFO: namespace e2e-tests-downward-api-k9qhm deletion completed in 7.500080274s

• [SLOW TEST:13.513 seconds]
[sig-storage] Downward API volume
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should set DefaultMode on files [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-network] DNS 
  should provide DNS for services  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] DNS
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 09:17:05.534: INFO: >>> kubeConfig: /tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-dns-s869d
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for services  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(dig +notcp +noall +answer +search dns-test-service A)" && echo OK > /results/wheezy_udp@dns-test-service;test -n "$$(dig +tcp +noall +answer +search dns-test-service A)" && echo OK > /results/wheezy_tcp@dns-test-service;test -n "$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-s869d A)" && echo OK > /results/wheezy_udp@dns-test-service.e2e-tests-dns-s869d;test -n "$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-s869d A)" && echo OK > /results/wheezy_tcp@dns-test-service.e2e-tests-dns-s869d;test -n "$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-s869d.svc A)" && echo OK > /results/wheezy_udp@dns-test-service.e2e-tests-dns-s869d.svc;test -n "$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-s869d.svc A)" && echo OK > /results/wheezy_tcp@dns-test-service.e2e-tests-dns-s869d.svc;test -n "$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-s869d.svc SRV)" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.e2e-tests-dns-s869d.svc;test -n "$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-s869d.svc SRV)" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.e2e-tests-dns-s869d.svc;test -n "$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-s869d.svc SRV)" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.e2e-tests-dns-s869d.svc;test -n "$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-s869d.svc SRV)" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.e2e-tests-dns-s869d.svc;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-s869d.pod.cluster.local"}');test -n "$$(dig +notcp +noall +answer +search $${podARec} A)" && echo OK > /results/wheezy_udp@PodARecord;test -n "$$(dig +tcp +noall +answer +search $${podARec} A)" && echo OK > /results/wheezy_tcp@PodARecord;test -n "$$(dig +notcp +noall +answer +search 208.40.68.100.in-addr.arpa. PTR)" && echo OK > /results/100.68.40.208_udp@PTR;test -n "$$(dig +tcp +noall +answer +search 208.40.68.100.in-addr.arpa. PTR)" && echo OK > /results/100.68.40.208_tcp@PTR;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(dig +notcp +noall +answer +search dns-test-service A)" && echo OK > /results/jessie_udp@dns-test-service;test -n "$$(dig +tcp +noall +answer +search dns-test-service A)" && echo OK > /results/jessie_tcp@dns-test-service;test -n "$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-s869d A)" && echo OK > /results/jessie_udp@dns-test-service.e2e-tests-dns-s869d;test -n "$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-s869d A)" && echo OK > /results/jessie_tcp@dns-test-service.e2e-tests-dns-s869d;test -n "$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-s869d.svc A)" && echo OK > /results/jessie_udp@dns-test-service.e2e-tests-dns-s869d.svc;test -n "$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-s869d.svc A)" && echo OK > /results/jessie_tcp@dns-test-service.e2e-tests-dns-s869d.svc;test -n "$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-s869d.svc SRV)" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-s869d.svc;test -n "$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-s869d.svc SRV)" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-s869d.svc;test -n "$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-s869d.svc SRV)" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.e2e-tests-dns-s869d.svc;test -n "$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-s869d.svc SRV)" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.e2e-tests-dns-s869d.svc;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-s869d.pod.cluster.local"}');test -n "$$(dig +notcp +noall +answer +search $${podARec} A)" && echo OK > /results/jessie_udp@PodARecord;test -n "$$(dig +tcp +noall +answer +search $${podARec} A)" && echo OK > /results/jessie_tcp@PodARecord;test -n "$$(dig +notcp +noall +answer +search 208.40.68.100.in-addr.arpa. PTR)" && echo OK > /results/100.68.40.208_udp@PTR;test -n "$$(dig +tcp +noall +answer +search 208.40.68.100.in-addr.arpa. PTR)" && echo OK > /results/100.68.40.208_tcp@PTR;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Mar  1 09:17:37.595: INFO: Unable to read wheezy_udp@dns-test-service from pod e2e-tests-dns-s869d/dns-test-c91c3fb6-3c02-11e9-a72e-ce8290b78775: the server could not find the requested resource (get pods dns-test-c91c3fb6-3c02-11e9-a72e-ce8290b78775)
Mar  1 09:17:37.639: INFO: Unable to read wheezy_tcp@dns-test-service from pod e2e-tests-dns-s869d/dns-test-c91c3fb6-3c02-11e9-a72e-ce8290b78775: the server could not find the requested resource (get pods dns-test-c91c3fb6-3c02-11e9-a72e-ce8290b78775)
Mar  1 09:17:37.676: INFO: Unable to read wheezy_udp@dns-test-service.e2e-tests-dns-s869d from pod e2e-tests-dns-s869d/dns-test-c91c3fb6-3c02-11e9-a72e-ce8290b78775: the server could not find the requested resource (get pods dns-test-c91c3fb6-3c02-11e9-a72e-ce8290b78775)
Mar  1 09:17:37.714: INFO: Unable to read wheezy_tcp@dns-test-service.e2e-tests-dns-s869d from pod e2e-tests-dns-s869d/dns-test-c91c3fb6-3c02-11e9-a72e-ce8290b78775: the server could not find the requested resource (get pods dns-test-c91c3fb6-3c02-11e9-a72e-ce8290b78775)
Mar  1 09:17:37.753: INFO: Unable to read wheezy_udp@dns-test-service.e2e-tests-dns-s869d.svc from pod e2e-tests-dns-s869d/dns-test-c91c3fb6-3c02-11e9-a72e-ce8290b78775: the server could not find the requested resource (get pods dns-test-c91c3fb6-3c02-11e9-a72e-ce8290b78775)
Mar  1 09:17:37.791: INFO: Unable to read wheezy_tcp@dns-test-service.e2e-tests-dns-s869d.svc from pod e2e-tests-dns-s869d/dns-test-c91c3fb6-3c02-11e9-a72e-ce8290b78775: the server could not find the requested resource (get pods dns-test-c91c3fb6-3c02-11e9-a72e-ce8290b78775)
Mar  1 09:17:37.830: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.e2e-tests-dns-s869d.svc from pod e2e-tests-dns-s869d/dns-test-c91c3fb6-3c02-11e9-a72e-ce8290b78775: the server could not find the requested resource (get pods dns-test-c91c3fb6-3c02-11e9-a72e-ce8290b78775)
Mar  1 09:17:37.868: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.e2e-tests-dns-s869d.svc from pod e2e-tests-dns-s869d/dns-test-c91c3fb6-3c02-11e9-a72e-ce8290b78775: the server could not find the requested resource (get pods dns-test-c91c3fb6-3c02-11e9-a72e-ce8290b78775)
Mar  1 09:17:38.290: INFO: Unable to read jessie_udp@dns-test-service from pod e2e-tests-dns-s869d/dns-test-c91c3fb6-3c02-11e9-a72e-ce8290b78775: the server could not find the requested resource (get pods dns-test-c91c3fb6-3c02-11e9-a72e-ce8290b78775)
Mar  1 09:17:38.327: INFO: Unable to read jessie_tcp@dns-test-service from pod e2e-tests-dns-s869d/dns-test-c91c3fb6-3c02-11e9-a72e-ce8290b78775: the server could not find the requested resource (get pods dns-test-c91c3fb6-3c02-11e9-a72e-ce8290b78775)
Mar  1 09:17:38.365: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-s869d from pod e2e-tests-dns-s869d/dns-test-c91c3fb6-3c02-11e9-a72e-ce8290b78775: the server could not find the requested resource (get pods dns-test-c91c3fb6-3c02-11e9-a72e-ce8290b78775)
Mar  1 09:17:38.406: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-s869d from pod e2e-tests-dns-s869d/dns-test-c91c3fb6-3c02-11e9-a72e-ce8290b78775: the server could not find the requested resource (get pods dns-test-c91c3fb6-3c02-11e9-a72e-ce8290b78775)
Mar  1 09:17:38.443: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-s869d.svc from pod e2e-tests-dns-s869d/dns-test-c91c3fb6-3c02-11e9-a72e-ce8290b78775: the server could not find the requested resource (get pods dns-test-c91c3fb6-3c02-11e9-a72e-ce8290b78775)
Mar  1 09:17:38.480: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-s869d.svc from pod e2e-tests-dns-s869d/dns-test-c91c3fb6-3c02-11e9-a72e-ce8290b78775: the server could not find the requested resource (get pods dns-test-c91c3fb6-3c02-11e9-a72e-ce8290b78775)
Mar  1 09:17:38.518: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-s869d.svc from pod e2e-tests-dns-s869d/dns-test-c91c3fb6-3c02-11e9-a72e-ce8290b78775: the server could not find the requested resource (get pods dns-test-c91c3fb6-3c02-11e9-a72e-ce8290b78775)
Mar  1 09:17:38.555: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-s869d.svc from pod e2e-tests-dns-s869d/dns-test-c91c3fb6-3c02-11e9-a72e-ce8290b78775: the server could not find the requested resource (get pods dns-test-c91c3fb6-3c02-11e9-a72e-ce8290b78775)
Mar  1 09:17:38.936: INFO: Lookups using e2e-tests-dns-s869d/dns-test-c91c3fb6-3c02-11e9-a72e-ce8290b78775 failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.e2e-tests-dns-s869d wheezy_tcp@dns-test-service.e2e-tests-dns-s869d wheezy_udp@dns-test-service.e2e-tests-dns-s869d.svc wheezy_tcp@dns-test-service.e2e-tests-dns-s869d.svc wheezy_udp@_http._tcp.dns-test-service.e2e-tests-dns-s869d.svc wheezy_tcp@_http._tcp.dns-test-service.e2e-tests-dns-s869d.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.e2e-tests-dns-s869d jessie_tcp@dns-test-service.e2e-tests-dns-s869d jessie_udp@dns-test-service.e2e-tests-dns-s869d.svc jessie_tcp@dns-test-service.e2e-tests-dns-s869d.svc jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-s869d.svc jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-s869d.svc]

Mar  1 09:17:49.334: INFO: DNS probes using e2e-tests-dns-s869d/dns-test-c91c3fb6-3c02-11e9-a72e-ce8290b78775 succeeded

STEP: deleting the pod
STEP: deleting the test service
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 09:17:49.516: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-dns-s869d" for this suite.
Mar  1 09:17:55.703: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 09:17:56.957: INFO: namespace: e2e-tests-dns-s869d, resource: bindings, ignored listing per whitelist
Mar  1 09:17:57.102: INFO: namespace e2e-tests-dns-s869d deletion completed in 7.549073129s

• [SLOW TEST:51.568 seconds]
[sig-network] DNS
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide DNS for services  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartAlways pod [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 09:17:57.102: INFO: >>> kubeConfig: /tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename init-container
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-init-container-w7vtc
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should invoke init containers on a RestartAlways pod [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
Mar  1 09:17:58.785: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 09:18:03.507: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-init-container-w7vtc" for this suite.
Mar  1 09:18:25.658: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 09:18:26.695: INFO: namespace: e2e-tests-init-container-w7vtc, resource: bindings, ignored listing per whitelist
Mar  1 09:18:27.015: INFO: namespace e2e-tests-init-container-w7vtc deletion completed in 23.472436618s

• [SLOW TEST:29.913 seconds]
[k8s.io] InitContainer [NodeConformance]
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should invoke init containers on a RestartAlways pod [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 09:18:27.016: INFO: >>> kubeConfig: /tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-secrets-q5d6s
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-f9aa62f7-3c02-11e9-a72e-ce8290b78775
STEP: Creating a pod to test consume secrets
Mar  1 09:18:28.855: INFO: Waiting up to 5m0s for pod "pod-secrets-f9afe1b4-3c02-11e9-a72e-ce8290b78775" in namespace "e2e-tests-secrets-q5d6s" to be "success or failure"
Mar  1 09:18:28.897: INFO: Pod "pod-secrets-f9afe1b4-3c02-11e9-a72e-ce8290b78775": Phase="Pending", Reason="", readiness=false. Elapsed: 41.20691ms
Mar  1 09:18:30.934: INFO: Pod "pod-secrets-f9afe1b4-3c02-11e9-a72e-ce8290b78775": Phase="Pending", Reason="", readiness=false. Elapsed: 2.078119338s
Mar  1 09:18:32.970: INFO: Pod "pod-secrets-f9afe1b4-3c02-11e9-a72e-ce8290b78775": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.11444705s
STEP: Saw pod success
Mar  1 09:18:32.970: INFO: Pod "pod-secrets-f9afe1b4-3c02-11e9-a72e-ce8290b78775" satisfied condition "success or failure"
Mar  1 09:18:33.006: INFO: Trying to get logs from node shoot--it--pub-az-nl4q9-cpu-worker-7dd9bbfd9c-7fp9l pod pod-secrets-f9afe1b4-3c02-11e9-a72e-ce8290b78775 container secret-volume-test: <nil>
STEP: delete the pod
Mar  1 09:18:33.145: INFO: Waiting for pod pod-secrets-f9afe1b4-3c02-11e9-a72e-ce8290b78775 to disappear
Mar  1 09:18:33.180: INFO: Pod pod-secrets-f9afe1b4-3c02-11e9-a72e-ce8290b78775 no longer exists
[AfterEach] [sig-storage] Secrets
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 09:18:33.180: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-q5d6s" for this suite.
Mar  1 09:18:39.335: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 09:18:40.630: INFO: namespace: e2e-tests-secrets-q5d6s, resource: bindings, ignored listing per whitelist
Mar  1 09:18:40.810: INFO: namespace e2e-tests-secrets-q5d6s deletion completed in 7.593722076s

• [SLOW TEST:13.794 seconds]
[sig-storage] Secrets
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 09:18:40.810: INFO: >>> kubeConfig: /tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-lg6gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-map-01d54091-3c03-11e9-a72e-ce8290b78775
STEP: Creating a pod to test consume configMaps
Mar  1 09:18:42.557: INFO: Waiting up to 5m0s for pod "pod-configmaps-01dab080-3c03-11e9-a72e-ce8290b78775" in namespace "e2e-tests-configmap-lg6gc" to be "success or failure"
Mar  1 09:18:42.602: INFO: Pod "pod-configmaps-01dab080-3c03-11e9-a72e-ce8290b78775": Phase="Pending", Reason="", readiness=false. Elapsed: 44.860702ms
Mar  1 09:18:44.638: INFO: Pod "pod-configmaps-01dab080-3c03-11e9-a72e-ce8290b78775": Phase="Pending", Reason="", readiness=false. Elapsed: 2.081034426s
Mar  1 09:18:46.674: INFO: Pod "pod-configmaps-01dab080-3c03-11e9-a72e-ce8290b78775": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.117540769s
STEP: Saw pod success
Mar  1 09:18:46.674: INFO: Pod "pod-configmaps-01dab080-3c03-11e9-a72e-ce8290b78775" satisfied condition "success or failure"
Mar  1 09:18:46.754: INFO: Trying to get logs from node shoot--it--pub-az-nl4q9-cpu-worker-7dd9bbfd9c-7fp9l pod pod-configmaps-01dab080-3c03-11e9-a72e-ce8290b78775 container configmap-volume-test: <nil>
STEP: delete the pod
Mar  1 09:18:46.848: INFO: Waiting for pod pod-configmaps-01dab080-3c03-11e9-a72e-ce8290b78775 to disappear
Mar  1 09:18:46.891: INFO: Pod pod-configmaps-01dab080-3c03-11e9-a72e-ce8290b78775 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 09:18:46.892: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-lg6gc" for this suite.
Mar  1 09:18:53.042: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 09:18:53.922: INFO: namespace: e2e-tests-configmap-lg6gc, resource: bindings, ignored listing per whitelist
Mar  1 09:18:54.473: INFO: namespace e2e-tests-configmap-lg6gc deletion completed in 7.545571032s

• [SLOW TEST:13.663 seconds]
[sig-storage] ConfigMap
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run rc 
  should create an rc from an image  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 09:18:54.474: INFO: >>> kubeConfig: /tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-fx2k8
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Kubectl run rc
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1246
[It] should create an rc from an image  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Mar  1 09:18:56.079: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-az-nl4q9.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml run e2e-test-nginx-rc --image=docker.io/library/nginx:1.14-alpine --generator=run/v1 --namespace=e2e-tests-kubectl-fx2k8'
Mar  1 09:18:58.618: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl create instead.\n"
Mar  1 09:18:58.618: INFO: stdout: "replicationcontroller/e2e-test-nginx-rc created\n"
STEP: verifying the rc e2e-test-nginx-rc was created
STEP: verifying the pod controlled by rc e2e-test-nginx-rc was created
STEP: confirm that you can get logs from an rc
Mar  1 09:18:58.694: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [e2e-test-nginx-rc-4dgzj]
Mar  1 09:18:58.694: INFO: Waiting up to 5m0s for pod "e2e-test-nginx-rc-4dgzj" in namespace "e2e-tests-kubectl-fx2k8" to be "running and ready"
Mar  1 09:18:58.730: INFO: Pod "e2e-test-nginx-rc-4dgzj": Phase="Pending", Reason="", readiness=false. Elapsed: 35.681888ms
Mar  1 09:19:00.765: INFO: Pod "e2e-test-nginx-rc-4dgzj": Phase="Pending", Reason="", readiness=false. Elapsed: 2.071305292s
Mar  1 09:19:02.801: INFO: Pod "e2e-test-nginx-rc-4dgzj": Phase="Running", Reason="", readiness=true. Elapsed: 4.10735198s
Mar  1 09:19:02.801: INFO: Pod "e2e-test-nginx-rc-4dgzj" satisfied condition "running and ready"
Mar  1 09:19:02.801: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [e2e-test-nginx-rc-4dgzj]
Mar  1 09:19:02.801: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-az-nl4q9.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml logs rc/e2e-test-nginx-rc --namespace=e2e-tests-kubectl-fx2k8'
Mar  1 09:19:03.178: INFO: stderr: ""
Mar  1 09:19:03.178: INFO: stdout: ""
[AfterEach] [k8s.io] Kubectl run rc
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1251
Mar  1 09:19:03.178: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-az-nl4q9.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml delete rc e2e-test-nginx-rc --namespace=e2e-tests-kubectl-fx2k8'
Mar  1 09:19:03.508: INFO: stderr: ""
Mar  1 09:19:03.508: INFO: stdout: "replicationcontroller \"e2e-test-nginx-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 09:19:03.508: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-fx2k8" for this suite.
Mar  1 09:19:09.664: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 09:19:09.990: INFO: namespace: e2e-tests-kubectl-fx2k8, resource: bindings, ignored listing per whitelist
Mar  1 09:19:11.070: INFO: namespace e2e-tests-kubectl-fx2k8 deletion completed in 7.517161286s

• [SLOW TEST:16.597 seconds]
[sig-cli] Kubectl client
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run rc
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create an rc from an image  [Conformance]
    /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 09:19:11.070: INFO: >>> kubeConfig: /tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-secrets-g4bqs
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-13d64e47-3c03-11e9-a72e-ce8290b78775
STEP: Creating a pod to test consume secrets
Mar  1 09:19:12.766: INFO: Waiting up to 5m0s for pod "pod-secrets-13dbf471-3c03-11e9-a72e-ce8290b78775" in namespace "e2e-tests-secrets-g4bqs" to be "success or failure"
Mar  1 09:19:12.802: INFO: Pod "pod-secrets-13dbf471-3c03-11e9-a72e-ce8290b78775": Phase="Pending", Reason="", readiness=false. Elapsed: 35.862575ms
Mar  1 09:19:14.838: INFO: Pod "pod-secrets-13dbf471-3c03-11e9-a72e-ce8290b78775": Phase="Pending", Reason="", readiness=false. Elapsed: 2.071647714s
Mar  1 09:19:16.875: INFO: Pod "pod-secrets-13dbf471-3c03-11e9-a72e-ce8290b78775": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.10856431s
STEP: Saw pod success
Mar  1 09:19:16.875: INFO: Pod "pod-secrets-13dbf471-3c03-11e9-a72e-ce8290b78775" satisfied condition "success or failure"
Mar  1 09:19:16.912: INFO: Trying to get logs from node shoot--it--pub-az-nl4q9-cpu-worker-7dd9bbfd9c-7fp9l pod pod-secrets-13dbf471-3c03-11e9-a72e-ce8290b78775 container secret-volume-test: <nil>
STEP: delete the pod
Mar  1 09:19:17.003: INFO: Waiting for pod pod-secrets-13dbf471-3c03-11e9-a72e-ce8290b78775 to disappear
Mar  1 09:19:17.038: INFO: Pod pod-secrets-13dbf471-3c03-11e9-a72e-ce8290b78775 no longer exists
[AfterEach] [sig-storage] Secrets
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 09:19:17.039: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-g4bqs" for this suite.
Mar  1 09:19:23.189: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 09:19:23.365: INFO: namespace: e2e-tests-secrets-g4bqs, resource: bindings, ignored listing per whitelist
Mar  1 09:19:24.605: INFO: namespace e2e-tests-secrets-g4bqs deletion completed in 7.523742078s

• [SLOW TEST:13.535 seconds]
[sig-storage] Secrets
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl describe 
  should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 09:19:24.605: INFO: >>> kubeConfig: /tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-bblw5
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Mar  1 09:19:26.271: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-az-nl4q9.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml version --client'
Mar  1 09:19:26.363: INFO: stderr: ""
Mar  1 09:19:26.363: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"12\", GitVersion:\"v1.12.5\", GitCommit:\"51dd616cdd25d6ee22c83a858773b607328a18ec\", GitTreeState:\"archive\", BuildDate:\"2019-03-01T07:45:25Z\", GoVersion:\"go1.11.4\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
Mar  1 09:19:26.398: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-az-nl4q9.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml create -f - --namespace=e2e-tests-kubectl-bblw5'
Mar  1 09:19:26.955: INFO: stderr: ""
Mar  1 09:19:26.955: INFO: stdout: "replicationcontroller/redis-master created\n"
Mar  1 09:19:26.955: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-az-nl4q9.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml create -f - --namespace=e2e-tests-kubectl-bblw5'
Mar  1 09:19:27.356: INFO: stderr: ""
Mar  1 09:19:27.356: INFO: stdout: "service/redis-master created\n"
STEP: Waiting for Redis master to start.
Mar  1 09:19:28.393: INFO: Selector matched 1 pods for map[app:redis]
Mar  1 09:19:28.393: INFO: Found 0 / 1
Mar  1 09:19:29.393: INFO: Selector matched 1 pods for map[app:redis]
Mar  1 09:19:29.394: INFO: Found 1 / 1
Mar  1 09:19:29.394: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Mar  1 09:19:29.429: INFO: Selector matched 1 pods for map[app:redis]
Mar  1 09:19:29.429: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Mar  1 09:19:29.429: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-az-nl4q9.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml describe pod redis-master-bsk8c --namespace=e2e-tests-kubectl-bblw5'
Mar  1 09:19:29.781: INFO: stderr: ""
Mar  1 09:19:29.781: INFO: stdout: "Name:               redis-master-bsk8c\nNamespace:          e2e-tests-kubectl-bblw5\nPriority:           0\nPriorityClassName:  <none>\nNode:               shoot--it--pub-az-nl4q9-cpu-worker-7dd9bbfd9c-7fp9l/10.250.0.4\nStart Time:         Fri, 01 Mar 2019 09:19:26 +0000\nLabels:             app=redis\n                    role=master\nAnnotations:        cni.projectcalico.org/podIP: 100.96.1.221/32\n                    kubernetes.io/psp: e2e-test-privileged-psp\nStatus:             Running\nIP:                 100.96.1.221\nControlled By:      ReplicationController/redis-master\nContainers:\n  redis-master:\n    Container ID:   docker://966ae8b80b3be6da54fc7b5ab82af2c710ab390cd611a7fdc1ccd696d8c0359d\n    Image:          gcr.io/kubernetes-e2e-test-images/redis:1.0\n    Image ID:       docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830\n    Port:           6379/TCP\n    Host Port:      0/TCP\n    State:          Running\n      Started:      Fri, 01 Mar 2019 09:19:28 +0000\n    Ready:          True\n    Restart Count:  0\n    Environment:    <none>\n    Mounts:\n      /var/run/secrets/kubernetes.io/serviceaccount from default-token-dw9tq (ro)\nConditions:\n  Type              Status\n  Initialized       True \n  Ready             True \n  ContainersReady   True \n  PodScheduled      True \nVolumes:\n  default-token-dw9tq:\n    Type:        Secret (a volume populated by a Secret)\n    SecretName:  default-token-dw9tq\n    Optional:    false\nQoS Class:       BestEffort\nNode-Selectors:  <none>\nTolerations:     node.kubernetes.io/not-ready:NoExecute for 300s\n                 node.kubernetes.io/unreachable:NoExecute for 300s\nEvents:\n  Type    Reason     Age   From                                                          Message\n  ----    ------     ----  ----                                                          -------\n  Normal  Scheduled  3s    default-scheduler                                             Successfully assigned e2e-tests-kubectl-bblw5/redis-master-bsk8c to shoot--it--pub-az-nl4q9-cpu-worker-7dd9bbfd9c-7fp9l\n  Normal  Pulled     1s    kubelet, shoot--it--pub-az-nl4q9-cpu-worker-7dd9bbfd9c-7fp9l  Container image \"gcr.io/kubernetes-e2e-test-images/redis:1.0\" already present on machine\n  Normal  Created    1s    kubelet, shoot--it--pub-az-nl4q9-cpu-worker-7dd9bbfd9c-7fp9l  Created container\n  Normal  Started    1s    kubelet, shoot--it--pub-az-nl4q9-cpu-worker-7dd9bbfd9c-7fp9l  Started container\n"
Mar  1 09:19:29.781: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-az-nl4q9.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml describe rc redis-master --namespace=e2e-tests-kubectl-bblw5'
Mar  1 09:19:30.159: INFO: stderr: ""
Mar  1 09:19:30.159: INFO: stdout: "Name:         redis-master\nNamespace:    e2e-tests-kubectl-bblw5\nSelector:     app=redis,role=master\nLabels:       app=redis\n              role=master\nAnnotations:  <none>\nReplicas:     1 current / 1 desired\nPods Status:  1 Running / 0 Waiting / 0 Succeeded / 0 Failed\nPod Template:\n  Labels:  app=redis\n           role=master\n  Containers:\n   redis-master:\n    Image:        gcr.io/kubernetes-e2e-test-images/redis:1.0\n    Port:         6379/TCP\n    Host Port:    0/TCP\n    Environment:  <none>\n    Mounts:       <none>\n  Volumes:        <none>\nEvents:\n  Type    Reason            Age   From                    Message\n  ----    ------            ----  ----                    -------\n  Normal  SuccessfulCreate  4s    replication-controller  Created pod: redis-master-bsk8c\n"
Mar  1 09:19:30.159: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-az-nl4q9.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml describe service redis-master --namespace=e2e-tests-kubectl-bblw5'
Mar  1 09:19:30.515: INFO: stderr: ""
Mar  1 09:19:30.515: INFO: stdout: "Name:              redis-master\nNamespace:         e2e-tests-kubectl-bblw5\nLabels:            app=redis\n                   role=master\nAnnotations:       <none>\nSelector:          app=redis,role=master\nType:              ClusterIP\nIP:                100.67.2.244\nPort:              <unset>  6379/TCP\nTargetPort:        redis-server/TCP\nEndpoints:         100.96.1.221:6379\nSession Affinity:  None\nEvents:            <none>\n"
Mar  1 09:19:30.551: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-az-nl4q9.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml describe node shoot--it--pub-az-nl4q9-cpu-worker-7dd9bbfd9c-7fp9l'
Mar  1 09:19:30.930: INFO: stderr: ""
Mar  1 09:19:30.930: INFO: stdout: "Name:               shoot--it--pub-az-nl4q9-cpu-worker-7dd9bbfd9c-7fp9l\nRoles:              node\nLabels:             beta.kubernetes.io/arch=amd64\n                    beta.kubernetes.io/instance-type=Standard_DS2_v2\n                    beta.kubernetes.io/os=linux\n                    failure-domain.beta.kubernetes.io/region=westeurope\n                    failure-domain.beta.kubernetes.io/zone=0\n                    kubernetes.io/hostname=shoot--it--pub-az-nl4q9-cpu-worker-7dd9bbfd9c-7fp9l\n                    kubernetes.io/role=node\n                    node-role.kubernetes.io/node=\n                    worker.garden.sapcloud.io/group=cpu-worker\nAnnotations:        node.alpha.kubernetes.io/ttl: 0\n                    projectcalico.org/IPv4Address: 10.250.0.4/19\n                    volumes.kubernetes.io/controller-managed-attach-detach: true\nCreationTimestamp:  Fri, 01 Mar 2019 07:21:56 +0000\nTaints:             <none>\nUnschedulable:      false\nConditions:\n  Type                 Status  LastHeartbeatTime                 LastTransitionTime                Reason                       Message\n  ----                 ------  -----------------                 ------------------                ------                       -------\n  NetworkUnavailable   False   Fri, 01 Mar 2019 07:22:44 +0000   Fri, 01 Mar 2019 07:22:44 +0000   RouteCreated                 RouteController created a route\n  OutOfDisk            False   Fri, 01 Mar 2019 09:19:25 +0000   Fri, 01 Mar 2019 07:21:56 +0000   KubeletHasSufficientDisk     kubelet has sufficient disk space available\n  MemoryPressure       False   Fri, 01 Mar 2019 09:19:25 +0000   Fri, 01 Mar 2019 07:21:56 +0000   KubeletHasSufficientMemory   kubelet has sufficient memory available\n  DiskPressure         False   Fri, 01 Mar 2019 09:19:25 +0000   Fri, 01 Mar 2019 07:21:56 +0000   KubeletHasNoDiskPressure     kubelet has no disk pressure\n  PIDPressure          False   Fri, 01 Mar 2019 09:19:25 +0000   Fri, 01 Mar 2019 07:21:56 +0000   KubeletHasSufficientPID      kubelet has sufficient PID available\n  Ready                True    Fri, 01 Mar 2019 09:19:25 +0000   Fri, 01 Mar 2019 07:22:16 +0000   KubeletReady                 kubelet is posting ready status\nAddresses:\n  InternalIP:  10.250.0.4\n  Hostname:    shoot--it--pub-az-nl4q9-cpu-worker-7dd9bbfd9c-7fp9l\nCapacity:\n attachable-volumes-azure-disk:  8\n cpu:                            2\n ephemeral-storage:              33136428Ki\n hugepages-1Gi:                  0\n hugepages-2Mi:                  0\n memory:                         7115804Ki\n pods:                           110\nAllocatable:\n attachable-volumes-azure-disk:  8\n cpu:                            1920m\n ephemeral-storage:              32235117134\n hugepages-1Gi:                  0\n hugepages-2Mi:                  0\n memory:                         5848512302\n pods:                           110\nSystem Info:\n Machine ID:                 fdbd2cde4fef4cf1979f42783aa2ad50\n System UUID:                8C1371DF-3B6F-0C4C-8358-D2C4FF80F597\n Boot ID:                    b7ed57f7-248c-428d-8495-360f3f7ca5bd\n Kernel Version:             4.14.96-coreos\n OS Image:                   Container Linux by CoreOS 1967.5.0 (Rhyolite)\n Operating System:           linux\n Architecture:               amd64\n Container Runtime Version:  docker://18.6.1\n Kubelet Version:            v1.12.5\n Kube-Proxy Version:         v1.12.5\nPodCIDR:                     100.96.1.0/24\nProviderID:                  azure:///subscriptions/00d2caa5-cd29-46f7-845a-2f8ee0360ef5/resourceGroups/shoot--it--pub-az-nl4q9/providers/Microsoft.Compute/virtualMachines/shoot--it--pub-az-nl4q9-cpu-worker-7dd9bbfd9c-7fp9l\nNon-terminated Pods:         (4 in total)\n  Namespace                  Name                   CPU Requests  CPU Limits  Memory Requests  Memory Limits\n  ---------                  ----                   ------------  ----------  ---------------  -------------\n  e2e-tests-kubectl-bblw5    redis-master-bsk8c     0 (0%)        0 (0%)      0 (0%)           0 (0%)\n  kube-system                calico-node-mdbnz      100m (5%)     500m (26%)  100Mi (1%)       700Mi (12%)\n  kube-system                kube-proxy-cq7cz       20m (1%)      900m (46%)  64Mi (1%)        200Mi (3%)\n  kube-system                node-exporter-h6r77    5m (0%)       15m (0%)    10Mi (0%)        50Mi (0%)\nAllocated resources:\n  (Total limits may be over 100 percent, i.e., overcommitted.)\n  Resource                       Requests    Limits\n  --------                       --------    ------\n  cpu                            125m (6%)   1415m (73%)\n  memory                         174Mi (3%)  950Mi (17%)\n  attachable-volumes-azure-disk  0           0\nEvents:                          <none>\n"
Mar  1 09:19:30.930: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-az-nl4q9.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml describe namespace e2e-tests-kubectl-bblw5'
Mar  1 09:19:31.281: INFO: stderr: ""
Mar  1 09:19:31.281: INFO: stdout: "Name:         e2e-tests-kubectl-bblw5\nLabels:       e2e-framework=kubectl\n              e2e-run=43d7ac57-3bf6-11e9-a72e-ce8290b78775\nAnnotations:  <none>\nStatus:       Active\n\nNo resource quota.\n\nNo resource limits.\n"
[AfterEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 09:19:31.281: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-bblw5" for this suite.
Mar  1 09:19:55.426: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 09:19:55.811: INFO: namespace: e2e-tests-kubectl-bblw5, resource: bindings, ignored listing per whitelist
Mar  1 09:19:56.873: INFO: namespace e2e-tests-kubectl-bblw5 deletion completed in 25.555418882s

• [SLOW TEST:32.268 seconds]
[sig-cli] Kubectl client
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl describe
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should check if kubectl describe prints relevant information for rc and pods  [Conformance]
    /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Watchers
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 09:19:56.874: INFO: >>> kubeConfig: /tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-watch-gst7z
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe add, update, and delete watch notifications on configmaps [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a watch on configmaps with label A
STEP: creating a watch on configmaps with label B
STEP: creating a watch on configmaps with label A or B
STEP: creating a configmap with label A and ensuring the correct watchers observe the notification
Mar  1 09:19:58.708: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-gst7z,SelfLink:/api/v1/namespaces/e2e-tests-watch-gst7z/configmaps/e2e-watch-test-configmap-a,UID:2f41502e-3c03-11e9-b4e8-fa9e8069966e,ResourceVersion:20950,Generation:0,CreationTimestamp:2019-03-01 09:19:58 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Mar  1 09:19:58.709: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-gst7z,SelfLink:/api/v1/namespaces/e2e-tests-watch-gst7z/configmaps/e2e-watch-test-configmap-a,UID:2f41502e-3c03-11e9-b4e8-fa9e8069966e,ResourceVersion:20950,Generation:0,CreationTimestamp:2019-03-01 09:19:58 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: modifying configmap A and ensuring the correct watchers observe the notification
Mar  1 09:20:08.782: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-gst7z,SelfLink:/api/v1/namespaces/e2e-tests-watch-gst7z/configmaps/e2e-watch-test-configmap-a,UID:2f41502e-3c03-11e9-b4e8-fa9e8069966e,ResourceVersion:20970,Generation:0,CreationTimestamp:2019-03-01 09:19:58 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Mar  1 09:20:08.782: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-gst7z,SelfLink:/api/v1/namespaces/e2e-tests-watch-gst7z/configmaps/e2e-watch-test-configmap-a,UID:2f41502e-3c03-11e9-b4e8-fa9e8069966e,ResourceVersion:20970,Generation:0,CreationTimestamp:2019-03-01 09:19:58 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying configmap A again and ensuring the correct watchers observe the notification
Mar  1 09:20:18.855: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-gst7z,SelfLink:/api/v1/namespaces/e2e-tests-watch-gst7z/configmaps/e2e-watch-test-configmap-a,UID:2f41502e-3c03-11e9-b4e8-fa9e8069966e,ResourceVersion:20991,Generation:0,CreationTimestamp:2019-03-01 09:19:58 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Mar  1 09:20:18.855: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-gst7z,SelfLink:/api/v1/namespaces/e2e-tests-watch-gst7z/configmaps/e2e-watch-test-configmap-a,UID:2f41502e-3c03-11e9-b4e8-fa9e8069966e,ResourceVersion:20991,Generation:0,CreationTimestamp:2019-03-01 09:19:58 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: deleting configmap A and ensuring the correct watchers observe the notification
Mar  1 09:20:28.900: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-gst7z,SelfLink:/api/v1/namespaces/e2e-tests-watch-gst7z/configmaps/e2e-watch-test-configmap-a,UID:2f41502e-3c03-11e9-b4e8-fa9e8069966e,ResourceVersion:21011,Generation:0,CreationTimestamp:2019-03-01 09:19:58 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Mar  1 09:20:28.900: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-gst7z,SelfLink:/api/v1/namespaces/e2e-tests-watch-gst7z/configmaps/e2e-watch-test-configmap-a,UID:2f41502e-3c03-11e9-b4e8-fa9e8069966e,ResourceVersion:21011,Generation:0,CreationTimestamp:2019-03-01 09:19:58 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: creating a configmap with label B and ensuring the correct watchers observe the notification
Mar  1 09:20:38.939: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-gst7z,SelfLink:/api/v1/namespaces/e2e-tests-watch-gst7z/configmaps/e2e-watch-test-configmap-b,UID:473bbbe9-3c03-11e9-b4e8-fa9e8069966e,ResourceVersion:21031,Generation:0,CreationTimestamp:2019-03-01 09:20:38 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Mar  1 09:20:38.939: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-gst7z,SelfLink:/api/v1/namespaces/e2e-tests-watch-gst7z/configmaps/e2e-watch-test-configmap-b,UID:473bbbe9-3c03-11e9-b4e8-fa9e8069966e,ResourceVersion:21031,Generation:0,CreationTimestamp:2019-03-01 09:20:38 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: deleting configmap B and ensuring the correct watchers observe the notification
Mar  1 09:20:48.978: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-gst7z,SelfLink:/api/v1/namespaces/e2e-tests-watch-gst7z/configmaps/e2e-watch-test-configmap-b,UID:473bbbe9-3c03-11e9-b4e8-fa9e8069966e,ResourceVersion:21052,Generation:0,CreationTimestamp:2019-03-01 09:20:38 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Mar  1 09:20:48.978: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-gst7z,SelfLink:/api/v1/namespaces/e2e-tests-watch-gst7z/configmaps/e2e-watch-test-configmap-b,UID:473bbbe9-3c03-11e9-b4e8-fa9e8069966e,ResourceVersion:21052,Generation:0,CreationTimestamp:2019-03-01 09:20:38 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 09:20:58.978: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-gst7z" for this suite.
Mar  1 09:21:05.155: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 09:21:05.870: INFO: namespace: e2e-tests-watch-gst7z, resource: bindings, ignored listing per whitelist
Mar  1 09:21:06.523: INFO: namespace e2e-tests-watch-gst7z deletion completed in 7.506224243s

• [SLOW TEST:69.650 seconds]
[sig-api-machinery] Watchers
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Docker Containers
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 09:21:06.523: INFO: >>> kubeConfig: /tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename containers
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-containers-s6n79
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test override arguments
Mar  1 09:21:08.214: INFO: Waiting up to 5m0s for pod "client-containers-58ac37da-3c03-11e9-a72e-ce8290b78775" in namespace "e2e-tests-containers-s6n79" to be "success or failure"
Mar  1 09:21:08.268: INFO: Pod "client-containers-58ac37da-3c03-11e9-a72e-ce8290b78775": Phase="Pending", Reason="", readiness=false. Elapsed: 53.891606ms
Mar  1 09:21:10.304: INFO: Pod "client-containers-58ac37da-3c03-11e9-a72e-ce8290b78775": Phase="Pending", Reason="", readiness=false. Elapsed: 2.089721529s
Mar  1 09:21:12.342: INFO: Pod "client-containers-58ac37da-3c03-11e9-a72e-ce8290b78775": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.127920113s
STEP: Saw pod success
Mar  1 09:21:12.342: INFO: Pod "client-containers-58ac37da-3c03-11e9-a72e-ce8290b78775" satisfied condition "success or failure"
Mar  1 09:21:12.381: INFO: Trying to get logs from node shoot--it--pub-az-nl4q9-cpu-worker-7dd9bbfd9c-7fp9l pod client-containers-58ac37da-3c03-11e9-a72e-ce8290b78775 container test-container: <nil>
STEP: delete the pod
Mar  1 09:21:12.485: INFO: Waiting for pod client-containers-58ac37da-3c03-11e9-a72e-ce8290b78775 to disappear
Mar  1 09:21:12.527: INFO: Pod client-containers-58ac37da-3c03-11e9-a72e-ce8290b78775 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 09:21:12.527: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-s6n79" for this suite.
Mar  1 09:21:18.673: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 09:21:19.550: INFO: namespace: e2e-tests-containers-s6n79, resource: bindings, ignored listing per whitelist
Mar  1 09:21:20.049: INFO: namespace e2e-tests-containers-s6n79 deletion completed in 7.485632547s

• [SLOW TEST:13.525 seconds]
[k8s.io] Docker Containers
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop exec hook properly [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 09:21:20.056: INFO: >>> kubeConfig: /tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-container-lifecycle-hook-lftrr
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop exec hook properly [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Mar  1 09:21:30.207: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Mar  1 09:21:30.242: INFO: Pod pod-with-prestop-exec-hook still exists
Mar  1 09:21:32.243: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Mar  1 09:21:32.280: INFO: Pod pod-with-prestop-exec-hook still exists
Mar  1 09:21:34.242: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Mar  1 09:21:34.279: INFO: Pod pod-with-prestop-exec-hook still exists
Mar  1 09:21:36.243: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Mar  1 09:21:36.282: INFO: Pod pod-with-prestop-exec-hook still exists
Mar  1 09:21:38.242: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Mar  1 09:21:38.279: INFO: Pod pod-with-prestop-exec-hook still exists
Mar  1 09:21:40.242: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Mar  1 09:21:40.279: INFO: Pod pod-with-prestop-exec-hook still exists
Mar  1 09:21:42.242: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Mar  1 09:21:42.279: INFO: Pod pod-with-prestop-exec-hook still exists
Mar  1 09:21:44.242: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Mar  1 09:21:44.279: INFO: Pod pod-with-prestop-exec-hook still exists
Mar  1 09:21:46.243: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Mar  1 09:21:46.279: INFO: Pod pod-with-prestop-exec-hook still exists
Mar  1 09:21:48.242: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Mar  1 09:21:48.279: INFO: Pod pod-with-prestop-exec-hook still exists
Mar  1 09:21:50.242: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Mar  1 09:21:50.279: INFO: Pod pod-with-prestop-exec-hook still exists
Mar  1 09:21:52.243: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Mar  1 09:21:52.322: INFO: Pod pod-with-prestop-exec-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 09:21:52.365: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-lifecycle-hook-lftrr" for this suite.
Mar  1 09:22:14.508: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 09:22:15.307: INFO: namespace: e2e-tests-container-lifecycle-hook-lftrr, resource: bindings, ignored listing per whitelist
Mar  1 09:22:15.877: INFO: namespace e2e-tests-container-lifecycle-hook-lftrr deletion completed in 23.476718368s

• [SLOW TEST:55.822 seconds]
[k8s.io] Container Lifecycle Hook
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when create a pod with lifecycle hook
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute prestop exec hook properly [NodeConformance] [Conformance]
    /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-cli] Kubectl client [k8s.io] Proxy server 
  should support --unix-socket=/path  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 09:22:15.878: INFO: >>> kubeConfig: /tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-dhgf9
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should support --unix-socket=/path  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Starting the proxy
Mar  1 09:22:17.606: INFO: Asynchronously running '/go/src/k8s.io/kubernetes/_output/bin/kubectl kubectl --server=https://api.pub-az-nl4q9.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml proxy --unix-socket=/tmp/kubectl-proxy-unix285110803/test'
STEP: retrieving proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 09:22:17.727: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-dhgf9" for this suite.
Mar  1 09:22:23.873: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 09:22:24.405: INFO: namespace: e2e-tests-kubectl-dhgf9, resource: bindings, ignored listing per whitelist
Mar  1 09:22:25.248: INFO: namespace e2e-tests-kubectl-dhgf9 deletion completed in 7.483244722s

• [SLOW TEST:9.370 seconds]
[sig-cli] Kubectl client
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Proxy server
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should support --unix-socket=/path  [Conformance]
    /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-network] Services 
  should serve multiport endpoints from pods  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Services
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 09:22:25.248: INFO: >>> kubeConfig: /tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-services-8267l
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/network/service.go:84
[It] should serve multiport endpoints from pods  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating service multi-endpoint-test in namespace e2e-tests-services-8267l
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-8267l to expose endpoints map[]
Mar  1 09:22:26.979: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-8267l exposes endpoints map[] (47.203047ms elapsed)
STEP: Creating pod pod1 in namespace e2e-tests-services-8267l
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-8267l to expose endpoints map[pod1:[100]]
Mar  1 09:22:30.304: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-8267l exposes endpoints map[pod1:[100]] (3.2858074s elapsed)
STEP: Creating pod pod2 in namespace e2e-tests-services-8267l
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-8267l to expose endpoints map[pod1:[100] pod2:[101]]
Mar  1 09:22:32.681: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-8267l exposes endpoints map[pod1:[100] pod2:[101]] (2.32254509s elapsed)
STEP: Deleting pod pod1 in namespace e2e-tests-services-8267l
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-8267l to expose endpoints map[pod2:[101]]
Mar  1 09:22:32.790: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-8267l exposes endpoints map[pod2:[101]] (71.505523ms elapsed)
STEP: Deleting pod pod2 in namespace e2e-tests-services-8267l
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-8267l to expose endpoints map[]
Mar  1 09:22:32.862: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-8267l exposes endpoints map[] (35.36028ms elapsed)
[AfterEach] [sig-network] Services
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 09:22:32.915: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-services-8267l" for this suite.
Mar  1 09:22:57.077: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 09:22:57.401: INFO: namespace: e2e-tests-services-8267l, resource: bindings, ignored listing per whitelist
Mar  1 09:22:58.465: INFO: namespace e2e-tests-services-8267l deletion completed in 25.49679913s
[AfterEach] [sig-network] Services
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/network/service.go:89

• [SLOW TEST:33.217 seconds]
[sig-network] Services
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should serve multiport endpoints from pods  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run deployment 
  should create a deployment from an image  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 09:22:58.465: INFO: >>> kubeConfig: /tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-2xc2f
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Kubectl run deployment
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1347
[It] should create a deployment from an image  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Mar  1 09:23:00.084: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-az-nl4q9.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml run e2e-test-nginx-deployment --image=docker.io/library/nginx:1.14-alpine --generator=deployment/v1beta1 --namespace=e2e-tests-kubectl-2xc2f'
Mar  1 09:23:00.444: INFO: stderr: "kubectl run --generator=deployment/v1beta1 is DEPRECATED and will be removed in a future version. Use kubectl create instead.\n"
Mar  1 09:23:00.444: INFO: stdout: "deployment.extensions/e2e-test-nginx-deployment created\n"
STEP: verifying the deployment e2e-test-nginx-deployment was created
STEP: verifying the pod controlled by deployment e2e-test-nginx-deployment was created
[AfterEach] [k8s.io] Kubectl run deployment
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1352
Mar  1 09:23:02.541: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-az-nl4q9.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml delete deployment e2e-test-nginx-deployment --namespace=e2e-tests-kubectl-2xc2f'
Mar  1 09:23:02.885: INFO: stderr: ""
Mar  1 09:23:02.885: INFO: stdout: "deployment.extensions \"e2e-test-nginx-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 09:23:02.885: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-2xc2f" for this suite.
Mar  1 09:23:25.029: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 09:23:26.160: INFO: namespace: e2e-tests-kubectl-2xc2f, resource: bindings, ignored listing per whitelist
Mar  1 09:23:26.385: INFO: namespace e2e-tests-kubectl-2xc2f deletion completed in 23.46410467s

• [SLOW TEST:27.920 seconds]
[sig-cli] Kubectl client
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run deployment
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create a deployment from an image  [Conformance]
    /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: udp [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Networking
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 09:23:26.386: INFO: >>> kubeConfig: /tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename pod-network-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-pod-network-test-gx29m
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: udp [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-gx29m
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Mar  1 09:23:27.987: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Mar  1 09:23:52.644: INFO: ExecWithOptions {Command:[/bin/sh -c echo 'hostName' | timeout -t 2 nc -w 1 -u 100.96.1.227 8081 | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-gx29m PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar  1 09:23:52.644: INFO: >>> kubeConfig: /tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
Mar  1 09:23:54.366: INFO: Found all expected endpoints: [netserver-0]
Mar  1 09:23:54.402: INFO: ExecWithOptions {Command:[/bin/sh -c echo 'hostName' | timeout -t 2 nc -w 1 -u 100.96.0.61 8081 | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-gx29m PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar  1 09:23:54.402: INFO: >>> kubeConfig: /tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
Mar  1 09:23:56.015: INFO: Found all expected endpoints: [netserver-1]
[AfterEach] [sig-network] Networking
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 09:23:56.015: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-gx29m" for this suite.
Mar  1 09:24:18.160: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 09:24:18.371: INFO: namespace: e2e-tests-pod-network-test-gx29m, resource: bindings, ignored listing per whitelist
Mar  1 09:24:19.530: INFO: namespace e2e-tests-pod-network-test-gx29m deletion completed in 23.477920191s

• [SLOW TEST:53.144 seconds]
[sig-network] Networking
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: udp [NodeConformance] [Conformance]
    /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for the cluster  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] DNS
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 09:24:19.531: INFO: >>> kubeConfig: /tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-dns-q8zlw
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for the cluster  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(dig +notcp +noall +answer +search kubernetes.default A)" && echo OK > /results/wheezy_udp@kubernetes.default;test -n "$$(dig +tcp +noall +answer +search kubernetes.default A)" && echo OK > /results/wheezy_tcp@kubernetes.default;test -n "$$(dig +notcp +noall +answer +search kubernetes.default.svc A)" && echo OK > /results/wheezy_udp@kubernetes.default.svc;test -n "$$(dig +tcp +noall +answer +search kubernetes.default.svc A)" && echo OK > /results/wheezy_tcp@kubernetes.default.svc;test -n "$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && echo OK > /results/wheezy_udp@kubernetes.default.svc.cluster.local;test -n "$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && echo OK > /results/wheezy_tcp@kubernetes.default.svc.cluster.local;test -n "$$(getent hosts dns-querier-1.dns-test-service.e2e-tests-dns-q8zlw.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-1.dns-test-service.e2e-tests-dns-q8zlw.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/wheezy_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-q8zlw.pod.cluster.local"}');test -n "$$(dig +notcp +noall +answer +search $${podARec} A)" && echo OK > /results/wheezy_udp@PodARecord;test -n "$$(dig +tcp +noall +answer +search $${podARec} A)" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(dig +notcp +noall +answer +search kubernetes.default A)" && echo OK > /results/jessie_udp@kubernetes.default;test -n "$$(dig +tcp +noall +answer +search kubernetes.default A)" && echo OK > /results/jessie_tcp@kubernetes.default;test -n "$$(dig +notcp +noall +answer +search kubernetes.default.svc A)" && echo OK > /results/jessie_udp@kubernetes.default.svc;test -n "$$(dig +tcp +noall +answer +search kubernetes.default.svc A)" && echo OK > /results/jessie_tcp@kubernetes.default.svc;test -n "$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && echo OK > /results/jessie_udp@kubernetes.default.svc.cluster.local;test -n "$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && echo OK > /results/jessie_tcp@kubernetes.default.svc.cluster.local;test -n "$$(getent hosts dns-querier-1.dns-test-service.e2e-tests-dns-q8zlw.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-1.dns-test-service.e2e-tests-dns-q8zlw.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/jessie_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-q8zlw.pod.cluster.local"}');test -n "$$(dig +notcp +noall +answer +search $${podARec} A)" && echo OK > /results/jessie_udp@PodARecord;test -n "$$(dig +tcp +noall +answer +search $${podARec} A)" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Mar  1 09:24:39.243: INFO: DNS probes using e2e-tests-dns-q8zlw/dns-test-cba9948c-3c03-11e9-a72e-ce8290b78775 succeeded

STEP: deleting the pod
[AfterEach] [sig-network] DNS
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 09:24:39.292: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-dns-q8zlw" for this suite.
Mar  1 09:24:45.438: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 09:24:46.285: INFO: namespace: e2e-tests-dns-q8zlw, resource: bindings, ignored listing per whitelist
Mar  1 09:24:46.824: INFO: namespace e2e-tests-dns-q8zlw deletion completed in 7.495862855s

• [SLOW TEST:27.293 seconds]
[sig-network] DNS
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide DNS for the cluster  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 09:24:46.824: INFO: >>> kubeConfig: /tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-gc-kg92m
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the rc1
STEP: create the rc2
STEP: set half of pods created by rc simpletest-rc-to-be-deleted to have rc simpletest-rc-to-stay as owner as well
STEP: delete the rc simpletest-rc-to-be-deleted
STEP: wait for the rc to be deleted
STEP: Gathering metrics
W0301 09:24:59.137889   31889 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Mar  1 09:24:59.137: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 09:24:59.138: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-kg92m" for this suite.
Mar  1 09:25:05.282: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 09:25:06.334: INFO: namespace: e2e-tests-gc-kg92m, resource: bindings, ignored listing per whitelist
Mar  1 09:25:06.685: INFO: namespace e2e-tests-gc-kg92m deletion completed in 7.511469861s

• [SLOW TEST:19.861 seconds]
[sig-api-machinery] Garbage collector
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl label 
  should update the label on a resource  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 09:25:06.686: INFO: >>> kubeConfig: /tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-trh49
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Kubectl label
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1042
STEP: creating the pod
Mar  1 09:25:08.286: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-az-nl4q9.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml create -f - --namespace=e2e-tests-kubectl-trh49'
Mar  1 09:25:08.890: INFO: stderr: ""
Mar  1 09:25:08.890: INFO: stdout: "pod/pause created\n"
Mar  1 09:25:08.891: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [pause]
Mar  1 09:25:08.891: INFO: Waiting up to 5m0s for pod "pause" in namespace "e2e-tests-kubectl-trh49" to be "running and ready"
Mar  1 09:25:08.936: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 45.274373ms
Mar  1 09:25:10.973: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 2.082439745s
Mar  1 09:25:13.010: INFO: Pod "pause": Phase="Running", Reason="", readiness=true. Elapsed: 4.119125264s
Mar  1 09:25:13.010: INFO: Pod "pause" satisfied condition "running and ready"
Mar  1 09:25:13.010: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [pause]
[It] should update the label on a resource  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: adding the label testing-label with value testing-label-value to a pod
Mar  1 09:25:13.010: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-az-nl4q9.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml label pods pause testing-label=testing-label-value --namespace=e2e-tests-kubectl-trh49'
Mar  1 09:25:13.361: INFO: stderr: ""
Mar  1 09:25:13.361: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod has the label testing-label with the value testing-label-value
Mar  1 09:25:13.361: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-az-nl4q9.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml get pod pause -L testing-label --namespace=e2e-tests-kubectl-trh49'
Mar  1 09:25:13.662: INFO: stderr: ""
Mar  1 09:25:13.662: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          5s    testing-label-value\n"
STEP: removing the label testing-label of a pod
Mar  1 09:25:13.662: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-az-nl4q9.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml label pods pause testing-label- --namespace=e2e-tests-kubectl-trh49'
Mar  1 09:25:14.061: INFO: stderr: ""
Mar  1 09:25:14.061: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod doesn't have the label testing-label
Mar  1 09:25:14.061: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-az-nl4q9.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml get pod pause -L testing-label --namespace=e2e-tests-kubectl-trh49'
Mar  1 09:25:14.363: INFO: stderr: ""
Mar  1 09:25:14.363: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          6s    \n"
[AfterEach] [k8s.io] Kubectl label
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1048
STEP: using delete to clean up resources
Mar  1 09:25:14.363: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-az-nl4q9.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-trh49'
Mar  1 09:25:14.733: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Mar  1 09:25:14.733: INFO: stdout: "pod \"pause\" force deleted\n"
Mar  1 09:25:14.733: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-az-nl4q9.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml get rc,svc -l name=pause --no-headers --namespace=e2e-tests-kubectl-trh49'
Mar  1 09:25:15.166: INFO: stderr: "No resources found.\n"
Mar  1 09:25:15.166: INFO: stdout: ""
Mar  1 09:25:15.166: INFO: Running '/go/src/k8s.io/kubernetes/_output/bin/kubectl --server=https://api.pub-az-nl4q9.it.shoot.dev.k8s-hana.ondemand.com --kubeconfig=/tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml get pods -l name=pause --namespace=e2e-tests-kubectl-trh49 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Mar  1 09:25:15.521: INFO: stderr: ""
Mar  1 09:25:15.521: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 09:25:15.521: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-trh49" for this suite.
Mar  1 09:25:21.673: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 09:25:22.253: INFO: namespace: e2e-tests-kubectl-trh49, resource: bindings, ignored listing per whitelist
Mar  1 09:25:23.060: INFO: namespace e2e-tests-kubectl-trh49 deletion completed in 7.500984521s

• [SLOW TEST:16.375 seconds]
[sig-cli] Kubectl client
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl label
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should update the label on a resource  [Conformance]
    /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-api-machinery] Garbage collector 
  should delete RS created by deployment when not orphaning [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 09:25:23.061: INFO: >>> kubeConfig: /tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-gc-nw67v
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete RS created by deployment when not orphaning [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for all rs to be garbage collected
STEP: Gathering metrics
W0301 09:25:24.993704   31889 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Mar  1 09:25:24.993: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 09:25:24.993: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-nw67v" for this suite.
Mar  1 09:25:31.144: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 09:25:32.307: INFO: namespace: e2e-tests-gc-nw67v, resource: bindings, ignored listing per whitelist
Mar  1 09:25:32.553: INFO: namespace e2e-tests-gc-nw67v deletion completed in 7.52167996s

• [SLOW TEST:9.493 seconds]
[sig-api-machinery] Garbage collector
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should delete RS created by deployment when not orphaning [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,default) [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 09:25:32.553: INFO: >>> kubeConfig: /tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-z5wqt
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,default) [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0644 on node default medium
Mar  1 09:25:34.215: INFO: Waiting up to 5m0s for pod "pod-f738a5d7-3c03-11e9-a72e-ce8290b78775" in namespace "e2e-tests-emptydir-z5wqt" to be "success or failure"
Mar  1 09:25:34.257: INFO: Pod "pod-f738a5d7-3c03-11e9-a72e-ce8290b78775": Phase="Pending", Reason="", readiness=false. Elapsed: 41.794231ms
Mar  1 09:25:36.293: INFO: Pod "pod-f738a5d7-3c03-11e9-a72e-ce8290b78775": Phase="Pending", Reason="", readiness=false. Elapsed: 2.077787945s
Mar  1 09:25:38.329: INFO: Pod "pod-f738a5d7-3c03-11e9-a72e-ce8290b78775": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.114066974s
STEP: Saw pod success
Mar  1 09:25:38.329: INFO: Pod "pod-f738a5d7-3c03-11e9-a72e-ce8290b78775" satisfied condition "success or failure"
Mar  1 09:25:38.366: INFO: Trying to get logs from node shoot--it--pub-az-nl4q9-cpu-worker-7dd9bbfd9c-7fp9l pod pod-f738a5d7-3c03-11e9-a72e-ce8290b78775 container test-container: <nil>
STEP: delete the pod
Mar  1 09:25:38.482: INFO: Waiting for pod pod-f738a5d7-3c03-11e9-a72e-ce8290b78775 to disappear
Mar  1 09:25:38.518: INFO: Pod pod-f738a5d7-3c03-11e9-a72e-ce8290b78775 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 09:25:38.518: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-z5wqt" for this suite.
Mar  1 09:25:44.680: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 09:25:45.372: INFO: namespace: e2e-tests-emptydir-z5wqt, resource: bindings, ignored listing per whitelist
Mar  1 09:25:46.101: INFO: namespace e2e-tests-emptydir-z5wqt deletion completed in 7.546404656s

• [SLOW TEST:13.548 seconds]
[sig-storage] EmptyDir volumes
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0644,default) [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-auth] ServiceAccounts 
  should mount an API token into pods  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-auth] ServiceAccounts
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 09:25:46.102: INFO: >>> kubeConfig: /tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename svcaccounts
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-svcaccounts-bt4dd
STEP: Waiting for a default service account to be provisioned in namespace
[It] should mount an API token into pods  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: getting the auto-created API token
STEP: Creating a pod to test consume service account token
Mar  1 09:25:48.492: INFO: Waiting up to 5m0s for pod "pod-service-account-ffbafe9a-3c03-11e9-a72e-ce8290b78775-k28q2" in namespace "e2e-tests-svcaccounts-bt4dd" to be "success or failure"
Mar  1 09:25:48.528: INFO: Pod "pod-service-account-ffbafe9a-3c03-11e9-a72e-ce8290b78775-k28q2": Phase="Pending", Reason="", readiness=false. Elapsed: 36.185068ms
Mar  1 09:25:50.564: INFO: Pod "pod-service-account-ffbafe9a-3c03-11e9-a72e-ce8290b78775-k28q2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.072599849s
Mar  1 09:25:52.601: INFO: Pod "pod-service-account-ffbafe9a-3c03-11e9-a72e-ce8290b78775-k28q2": Phase="Pending", Reason="", readiness=false. Elapsed: 4.10926323s
Mar  1 09:25:54.639: INFO: Pod "pod-service-account-ffbafe9a-3c03-11e9-a72e-ce8290b78775-k28q2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.147477637s
STEP: Saw pod success
Mar  1 09:25:54.639: INFO: Pod "pod-service-account-ffbafe9a-3c03-11e9-a72e-ce8290b78775-k28q2" satisfied condition "success or failure"
Mar  1 09:25:54.675: INFO: Trying to get logs from node shoot--it--pub-az-nl4q9-cpu-worker-7dd9bbfd9c-7fp9l pod pod-service-account-ffbafe9a-3c03-11e9-a72e-ce8290b78775-k28q2 container token-test: <nil>
STEP: delete the pod
Mar  1 09:25:54.783: INFO: Waiting for pod pod-service-account-ffbafe9a-3c03-11e9-a72e-ce8290b78775-k28q2 to disappear
Mar  1 09:25:54.818: INFO: Pod pod-service-account-ffbafe9a-3c03-11e9-a72e-ce8290b78775-k28q2 no longer exists
STEP: Creating a pod to test consume service account root CA
Mar  1 09:25:54.855: INFO: Waiting up to 5m0s for pod "pod-service-account-ffbafe9a-3c03-11e9-a72e-ce8290b78775-b6cw2" in namespace "e2e-tests-svcaccounts-bt4dd" to be "success or failure"
Mar  1 09:25:54.893: INFO: Pod "pod-service-account-ffbafe9a-3c03-11e9-a72e-ce8290b78775-b6cw2": Phase="Pending", Reason="", readiness=false. Elapsed: 38.844853ms
Mar  1 09:25:56.931: INFO: Pod "pod-service-account-ffbafe9a-3c03-11e9-a72e-ce8290b78775-b6cw2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.076490531s
Mar  1 09:25:58.968: INFO: Pod "pod-service-account-ffbafe9a-3c03-11e9-a72e-ce8290b78775-b6cw2": Phase="Pending", Reason="", readiness=false. Elapsed: 4.113386728s
Mar  1 09:26:01.006: INFO: Pod "pod-service-account-ffbafe9a-3c03-11e9-a72e-ce8290b78775-b6cw2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.150966183s
STEP: Saw pod success
Mar  1 09:26:01.006: INFO: Pod "pod-service-account-ffbafe9a-3c03-11e9-a72e-ce8290b78775-b6cw2" satisfied condition "success or failure"
Mar  1 09:26:01.042: INFO: Trying to get logs from node shoot--it--pub-az-nl4q9-cpu-worker-7dd9bbfd9c-7fp9l pod pod-service-account-ffbafe9a-3c03-11e9-a72e-ce8290b78775-b6cw2 container root-ca-test: <nil>
STEP: delete the pod
Mar  1 09:26:01.189: INFO: Waiting for pod pod-service-account-ffbafe9a-3c03-11e9-a72e-ce8290b78775-b6cw2 to disappear
Mar  1 09:26:01.227: INFO: Pod pod-service-account-ffbafe9a-3c03-11e9-a72e-ce8290b78775-b6cw2 no longer exists
STEP: Creating a pod to test consume service account namespace
Mar  1 09:26:01.265: INFO: Waiting up to 5m0s for pod "pod-service-account-ffbafe9a-3c03-11e9-a72e-ce8290b78775-9crgp" in namespace "e2e-tests-svcaccounts-bt4dd" to be "success or failure"
Mar  1 09:26:01.300: INFO: Pod "pod-service-account-ffbafe9a-3c03-11e9-a72e-ce8290b78775-9crgp": Phase="Pending", Reason="", readiness=false. Elapsed: 35.279034ms
Mar  1 09:26:03.337: INFO: Pod "pod-service-account-ffbafe9a-3c03-11e9-a72e-ce8290b78775-9crgp": Phase="Pending", Reason="", readiness=false. Elapsed: 2.071877767s
Mar  1 09:26:05.373: INFO: Pod "pod-service-account-ffbafe9a-3c03-11e9-a72e-ce8290b78775-9crgp": Phase="Pending", Reason="", readiness=false. Elapsed: 4.108025702s
Mar  1 09:26:07.409: INFO: Pod "pod-service-account-ffbafe9a-3c03-11e9-a72e-ce8290b78775-9crgp": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.144173054s
STEP: Saw pod success
Mar  1 09:26:07.409: INFO: Pod "pod-service-account-ffbafe9a-3c03-11e9-a72e-ce8290b78775-9crgp" satisfied condition "success or failure"
Mar  1 09:26:07.445: INFO: Trying to get logs from node shoot--it--pub-az-nl4q9-cpu-worker-7dd9bbfd9c-7fp9l pod pod-service-account-ffbafe9a-3c03-11e9-a72e-ce8290b78775-9crgp container namespace-test: <nil>
STEP: delete the pod
Mar  1 09:26:07.547: INFO: Waiting for pod pod-service-account-ffbafe9a-3c03-11e9-a72e-ce8290b78775-9crgp to disappear
Mar  1 09:26:07.583: INFO: Pod pod-service-account-ffbafe9a-3c03-11e9-a72e-ce8290b78775-9crgp no longer exists
[AfterEach] [sig-auth] ServiceAccounts
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 09:26:07.583: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-svcaccounts-bt4dd" for this suite.
Mar  1 09:26:13.728: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 09:26:14.394: INFO: namespace: e2e-tests-svcaccounts-bt4dd, resource: bindings, ignored listing per whitelist
Mar  1 09:26:15.131: INFO: namespace e2e-tests-svcaccounts-bt4dd deletion completed in 7.512832532s

• [SLOW TEST:29.030 seconds]
[sig-auth] ServiceAccounts
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:22
  should mount an API token into pods  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,tmpfs) [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 09:26:15.132: INFO: >>> kubeConfig: /tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-s7h5n
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,tmpfs) [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0666 on tmpfs
Mar  1 09:26:16.722: INFO: Waiting up to 5m0s for pod "pod-108ea875-3c04-11e9-a72e-ce8290b78775" in namespace "e2e-tests-emptydir-s7h5n" to be "success or failure"
Mar  1 09:26:16.757: INFO: Pod "pod-108ea875-3c04-11e9-a72e-ce8290b78775": Phase="Pending", Reason="", readiness=false. Elapsed: 35.316639ms
Mar  1 09:26:18.793: INFO: Pod "pod-108ea875-3c04-11e9-a72e-ce8290b78775": Phase="Pending", Reason="", readiness=false. Elapsed: 2.071461907s
Mar  1 09:26:20.831: INFO: Pod "pod-108ea875-3c04-11e9-a72e-ce8290b78775": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.108927045s
STEP: Saw pod success
Mar  1 09:26:20.831: INFO: Pod "pod-108ea875-3c04-11e9-a72e-ce8290b78775" satisfied condition "success or failure"
Mar  1 09:26:20.867: INFO: Trying to get logs from node shoot--it--pub-az-nl4q9-cpu-worker-7dd9bbfd9c-7fp9l pod pod-108ea875-3c04-11e9-a72e-ce8290b78775 container test-container: <nil>
STEP: delete the pod
Mar  1 09:26:20.975: INFO: Waiting for pod pod-108ea875-3c04-11e9-a72e-ce8290b78775 to disappear
Mar  1 09:26:21.019: INFO: Pod pod-108ea875-3c04-11e9-a72e-ce8290b78775 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 09:26:21.019: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-s7h5n" for this suite.
Mar  1 09:26:27.166: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 09:26:27.892: INFO: namespace: e2e-tests-emptydir-s7h5n, resource: bindings, ignored listing per whitelist
Mar  1 09:26:28.580: INFO: namespace e2e-tests-emptydir-s7h5n deletion completed in 7.525414093s

• [SLOW TEST:13.449 seconds]
[sig-storage] EmptyDir volumes
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0666,tmpfs) [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 09:26:28.580: INFO: >>> kubeConfig: /tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-secrets-ts5n9
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-map-18a875a2-3c04-11e9-a72e-ce8290b78775
STEP: Creating a pod to test consume secrets
Mar  1 09:26:30.348: INFO: Waiting up to 5m0s for pod "pod-secrets-18adf2bf-3c04-11e9-a72e-ce8290b78775" in namespace "e2e-tests-secrets-ts5n9" to be "success or failure"
Mar  1 09:26:30.390: INFO: Pod "pod-secrets-18adf2bf-3c04-11e9-a72e-ce8290b78775": Phase="Pending", Reason="", readiness=false. Elapsed: 41.268942ms
Mar  1 09:26:32.426: INFO: Pod "pod-secrets-18adf2bf-3c04-11e9-a72e-ce8290b78775": Phase="Pending", Reason="", readiness=false. Elapsed: 2.077515783s
Mar  1 09:26:34.462: INFO: Pod "pod-secrets-18adf2bf-3c04-11e9-a72e-ce8290b78775": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.114065288s
STEP: Saw pod success
Mar  1 09:26:34.463: INFO: Pod "pod-secrets-18adf2bf-3c04-11e9-a72e-ce8290b78775" satisfied condition "success or failure"
Mar  1 09:26:34.498: INFO: Trying to get logs from node shoot--it--pub-az-nl4q9-cpu-worker-7dd9bbfd9c-7fp9l pod pod-secrets-18adf2bf-3c04-11e9-a72e-ce8290b78775 container secret-volume-test: <nil>
STEP: delete the pod
Mar  1 09:26:34.587: INFO: Waiting for pod pod-secrets-18adf2bf-3c04-11e9-a72e-ce8290b78775 to disappear
Mar  1 09:26:34.623: INFO: Pod pod-secrets-18adf2bf-3c04-11e9-a72e-ce8290b78775 no longer exists
[AfterEach] [sig-storage] Secrets
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 09:26:34.623: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-ts5n9" for this suite.
Mar  1 09:26:40.785: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 09:26:41.392: INFO: namespace: e2e-tests-secrets-ts5n9, resource: bindings, ignored listing per whitelist
Mar  1 09:26:42.284: INFO: namespace e2e-tests-secrets-ts5n9 deletion completed in 7.618300964s

• [SLOW TEST:13.704 seconds]
[sig-storage] Secrets
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 09:26:42.285: INFO: >>> kubeConfig: /tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-gc-vm5hg
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the rs
STEP: Gathering metrics
W0301 09:27:14.284911   31889 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Mar  1 09:27:14.284: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 09:27:14.285: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-vm5hg" for this suite.
Mar  1 09:27:20.434: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 09:27:20.683: INFO: namespace: e2e-tests-gc-vm5hg, resource: bindings, ignored listing per whitelist
Mar  1 09:27:21.799: INFO: namespace e2e-tests-gc-vm5hg deletion completed in 7.475613505s

• [SLOW TEST:39.514 seconds]
[sig-api-machinery] Garbage collector
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,tmpfs) [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 09:27:21.799: INFO: >>> kubeConfig: /tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-mlt7h
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,tmpfs) [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0644 on tmpfs
Mar  1 09:27:23.426: INFO: Waiting up to 5m0s for pod "pod-3850ef41-3c04-11e9-a72e-ce8290b78775" in namespace "e2e-tests-emptydir-mlt7h" to be "success or failure"
Mar  1 09:27:23.463: INFO: Pod "pod-3850ef41-3c04-11e9-a72e-ce8290b78775": Phase="Pending", Reason="", readiness=false. Elapsed: 37.000581ms
Mar  1 09:27:25.515: INFO: Pod "pod-3850ef41-3c04-11e9-a72e-ce8290b78775": Phase="Pending", Reason="", readiness=false. Elapsed: 2.088798848s
Mar  1 09:27:27.553: INFO: Pod "pod-3850ef41-3c04-11e9-a72e-ce8290b78775": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.126685322s
STEP: Saw pod success
Mar  1 09:27:27.553: INFO: Pod "pod-3850ef41-3c04-11e9-a72e-ce8290b78775" satisfied condition "success or failure"
Mar  1 09:27:27.590: INFO: Trying to get logs from node shoot--it--pub-az-nl4q9-cpu-worker-7dd9bbfd9c-7fp9l pod pod-3850ef41-3c04-11e9-a72e-ce8290b78775 container test-container: <nil>
STEP: delete the pod
Mar  1 09:27:27.677: INFO: Waiting for pod pod-3850ef41-3c04-11e9-a72e-ce8290b78775 to disappear
Mar  1 09:27:27.721: INFO: Pod pod-3850ef41-3c04-11e9-a72e-ce8290b78775 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 09:27:27.721: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-mlt7h" for this suite.
Mar  1 09:27:33.867: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 09:27:34.650: INFO: namespace: e2e-tests-emptydir-mlt7h, resource: bindings, ignored listing per whitelist
Mar  1 09:27:35.227: INFO: namespace e2e-tests-emptydir-mlt7h deletion completed in 7.469217736s

• [SLOW TEST:13.428 seconds]
[sig-storage] EmptyDir volumes
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0644,tmpfs) [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartNever pod [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 09:27:35.228: INFO: >>> kubeConfig: /tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename init-container
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-init-container-l497t
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should invoke init containers on a RestartNever pod [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
Mar  1 09:27:36.786: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 09:27:42.173: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-init-container-l497t" for this suite.
Mar  1 09:27:48.321: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 09:27:48.713: INFO: namespace: e2e-tests-init-container-l497t, resource: bindings, ignored listing per whitelist
Mar  1 09:27:49.673: INFO: namespace e2e-tests-init-container-l497t deletion completed in 7.460371585s

• [SLOW TEST:14.445 seconds]
[k8s.io] InitContainer [NodeConformance]
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should invoke init containers on a RestartNever pod [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Secrets 
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 09:27:49.673: INFO: >>> kubeConfig: /tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-secrets-jtvfz
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-secret-namespace-lcrsx
STEP: Creating secret with name secret-test-48f50158-3c04-11e9-a72e-ce8290b78775
STEP: Creating a pod to test consume secrets
Mar  1 09:27:51.852: INFO: Waiting up to 5m0s for pod "pod-secrets-49427524-3c04-11e9-a72e-ce8290b78775" in namespace "e2e-tests-secrets-jtvfz" to be "success or failure"
Mar  1 09:27:51.888: INFO: Pod "pod-secrets-49427524-3c04-11e9-a72e-ce8290b78775": Phase="Pending", Reason="", readiness=false. Elapsed: 35.216411ms
Mar  1 09:27:53.925: INFO: Pod "pod-secrets-49427524-3c04-11e9-a72e-ce8290b78775": Phase="Pending", Reason="", readiness=false. Elapsed: 2.072564847s
Mar  1 09:27:55.961: INFO: Pod "pod-secrets-49427524-3c04-11e9-a72e-ce8290b78775": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.1084941s
STEP: Saw pod success
Mar  1 09:27:55.961: INFO: Pod "pod-secrets-49427524-3c04-11e9-a72e-ce8290b78775" satisfied condition "success or failure"
Mar  1 09:27:55.996: INFO: Trying to get logs from node shoot--it--pub-az-nl4q9-cpu-worker-7dd9bbfd9c-7fp9l pod pod-secrets-49427524-3c04-11e9-a72e-ce8290b78775 container secret-volume-test: <nil>
STEP: delete the pod
Mar  1 09:27:56.079: INFO: Waiting for pod pod-secrets-49427524-3c04-11e9-a72e-ce8290b78775 to disappear
Mar  1 09:27:56.121: INFO: Pod pod-secrets-49427524-3c04-11e9-a72e-ce8290b78775 no longer exists
[AfterEach] [sig-storage] Secrets
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 09:27:56.121: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-jtvfz" for this suite.
Mar  1 09:28:02.272: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 09:28:03.027: INFO: namespace: e2e-tests-secrets-jtvfz, resource: bindings, ignored listing per whitelist
Mar  1 09:28:03.704: INFO: namespace e2e-tests-secrets-jtvfz deletion completed in 7.539849308s
STEP: Destroying namespace "e2e-tests-secret-namespace-lcrsx" for this suite.
Mar  1 09:28:09.813: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 09:28:11.099: INFO: namespace: e2e-tests-secret-namespace-lcrsx, resource: bindings, ignored listing per whitelist
Mar  1 09:28:11.209: INFO: namespace e2e-tests-secret-namespace-lcrsx deletion completed in 7.504827678s

• [SLOW TEST:21.537 seconds]
[sig-storage] Secrets
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 09:28:11.210: INFO: >>> kubeConfig: /tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-7jgp4
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-55c2ac43-3c04-11e9-a72e-ce8290b78775
STEP: Creating a pod to test consume configMaps
Mar  1 09:28:12.861: INFO: Waiting up to 5m0s for pod "pod-configmaps-55c81a0a-3c04-11e9-a72e-ce8290b78775" in namespace "e2e-tests-configmap-7jgp4" to be "success or failure"
Mar  1 09:28:12.897: INFO: Pod "pod-configmaps-55c81a0a-3c04-11e9-a72e-ce8290b78775": Phase="Pending", Reason="", readiness=false. Elapsed: 35.491838ms
Mar  1 09:28:14.934: INFO: Pod "pod-configmaps-55c81a0a-3c04-11e9-a72e-ce8290b78775": Phase="Pending", Reason="", readiness=false. Elapsed: 2.071998493s
Mar  1 09:28:16.972: INFO: Pod "pod-configmaps-55c81a0a-3c04-11e9-a72e-ce8290b78775": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.110748919s
STEP: Saw pod success
Mar  1 09:28:16.972: INFO: Pod "pod-configmaps-55c81a0a-3c04-11e9-a72e-ce8290b78775" satisfied condition "success or failure"
Mar  1 09:28:17.008: INFO: Trying to get logs from node shoot--it--pub-az-nl4q9-cpu-worker-7dd9bbfd9c-7fp9l pod pod-configmaps-55c81a0a-3c04-11e9-a72e-ce8290b78775 container configmap-volume-test: <nil>
STEP: delete the pod
Mar  1 09:28:17.122: INFO: Waiting for pod pod-configmaps-55c81a0a-3c04-11e9-a72e-ce8290b78775 to disappear
Mar  1 09:28:17.158: INFO: Pod pod-configmaps-55c81a0a-3c04-11e9-a72e-ce8290b78775 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 09:28:17.158: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-7jgp4" for this suite.
Mar  1 09:28:23.309: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 09:28:24.096: INFO: namespace: e2e-tests-configmap-7jgp4, resource: bindings, ignored listing per whitelist
Mar  1 09:28:24.713: INFO: namespace e2e-tests-configmap-7jgp4 deletion completed in 7.5129714s

• [SLOW TEST:13.504 seconds]
[sig-storage] ConfigMap
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-network] Services 
  should provide secure master service  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Services
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 09:28:24.714: INFO: >>> kubeConfig: /tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-services-xpln9
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/network/service.go:84
[It] should provide secure master service  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [sig-network] Services
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 09:28:26.330: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-services-xpln9" for this suite.
Mar  1 09:28:32.472: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 09:28:32.726: INFO: namespace: e2e-tests-services-xpln9, resource: bindings, ignored listing per whitelist
Mar  1 09:28:33.875: INFO: namespace e2e-tests-services-xpln9 deletion completed in 7.509324571s
[AfterEach] [sig-network] Services
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/network/service.go:89

• [SLOW TEST:9.161 seconds]
[sig-network] Services
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide secure master service  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 09:28:33.875: INFO: >>> kubeConfig: /tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-d4pjm
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-map-634c52f3-3c04-11e9-a72e-ce8290b78775
STEP: Creating a pod to test consume secrets
Mar  1 09:28:35.574: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-6351e581-3c04-11e9-a72e-ce8290b78775" in namespace "e2e-tests-projected-d4pjm" to be "success or failure"
Mar  1 09:28:35.637: INFO: Pod "pod-projected-secrets-6351e581-3c04-11e9-a72e-ce8290b78775": Phase="Pending", Reason="", readiness=false. Elapsed: 62.562121ms
Mar  1 09:28:37.673: INFO: Pod "pod-projected-secrets-6351e581-3c04-11e9-a72e-ce8290b78775": Phase="Pending", Reason="", readiness=false. Elapsed: 2.098431624s
Mar  1 09:28:39.713: INFO: Pod "pod-projected-secrets-6351e581-3c04-11e9-a72e-ce8290b78775": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.138512234s
STEP: Saw pod success
Mar  1 09:28:39.713: INFO: Pod "pod-projected-secrets-6351e581-3c04-11e9-a72e-ce8290b78775" satisfied condition "success or failure"
Mar  1 09:28:39.748: INFO: Trying to get logs from node shoot--it--pub-az-nl4q9-cpu-worker-7dd9bbfd9c-7fp9l pod pod-projected-secrets-6351e581-3c04-11e9-a72e-ce8290b78775 container projected-secret-volume-test: <nil>
STEP: delete the pod
Mar  1 09:28:39.841: INFO: Waiting for pod pod-projected-secrets-6351e581-3c04-11e9-a72e-ce8290b78775 to disappear
Mar  1 09:28:39.878: INFO: Pod pod-projected-secrets-6351e581-3c04-11e9-a72e-ce8290b78775 no longer exists
[AfterEach] [sig-storage] Projected
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 09:28:39.878: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-d4pjm" for this suite.
Mar  1 09:28:46.028: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 09:28:47.047: INFO: namespace: e2e-tests-projected-d4pjm, resource: bindings, ignored listing per whitelist
Mar  1 09:28:47.399: INFO: namespace e2e-tests-projected-d4pjm deletion completed in 7.484240636s

• [SLOW TEST:13.524 seconds]
[sig-storage] Projected
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should not be blocked by dependency circle [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 09:28:47.400: INFO: >>> kubeConfig: /tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-gc-jlqrr
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be blocked by dependency circle [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Mar  1 09:28:49.139: INFO: pod1.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod3", UID:"6b65083b-3c04-11e9-b4e8-fa9e8069966e", Controller:(*bool)(0xc000958dde), BlockOwnerDeletion:(*bool)(0xc000958ddf)}}
Mar  1 09:28:49.175: INFO: pod2.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod1", UID:"6b58ace3-3c04-11e9-b4e8-fa9e8069966e", Controller:(*bool)(0xc00078c22e), BlockOwnerDeletion:(*bool)(0xc00078c22f)}}
Mar  1 09:28:49.212: INFO: pod3.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod2", UID:"6b5e4394-3c04-11e9-b4e8-fa9e8069966e", Controller:(*bool)(0xc00095969e), BlockOwnerDeletion:(*bool)(0xc00095969f)}}
[AfterEach] [sig-api-machinery] Garbage collector
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 09:28:54.288: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-jlqrr" for this suite.
Mar  1 09:29:00.434: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 09:29:01.755: INFO: namespace: e2e-tests-gc-jlqrr, resource: bindings, ignored listing per whitelist
Mar  1 09:29:01.792: INFO: namespace e2e-tests-gc-jlqrr deletion completed in 7.46778122s

• [SLOW TEST:14.392 seconds]
[sig-api-machinery] Garbage collector
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should not be blocked by dependency circle [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 09:29:01.792: INFO: >>> kubeConfig: /tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-s76qt
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name cm-test-opt-del-73f0bb43-3c04-11e9-a72e-ce8290b78775
STEP: Creating configMap with name cm-test-opt-upd-73f0bb8c-3c04-11e9-a72e-ce8290b78775
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-73f0bb43-3c04-11e9-a72e-ce8290b78775
STEP: Updating configmap cm-test-opt-upd-73f0bb8c-3c04-11e9-a72e-ce8290b78775
STEP: Creating configMap with name cm-test-opt-create-73f0bba4-3c04-11e9-a72e-ce8290b78775
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 09:30:36.473: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-s76qt" for this suite.
Mar  1 09:31:00.618: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 09:31:01.889: INFO: namespace: e2e-tests-projected-s76qt, resource: bindings, ignored listing per whitelist
Mar  1 09:31:01.961: INFO: namespace e2e-tests-projected-s76qt deletion completed in 25.452874531s

• [SLOW TEST:120.169 seconds]
[sig-storage] Projected
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[k8s.io] [sig-node] PreStop 
  should call prestop when killing a pod  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] [sig-node] PreStop
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 09:31:01.961: INFO: >>> kubeConfig: /tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename prestop
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-prestop-fnm4d
STEP: Waiting for a default service account to be provisioned in namespace
[It] should call prestop when killing a pod  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating server pod server in namespace e2e-tests-prestop-fnm4d
STEP: Waiting for pods to come up.
STEP: Creating tester pod tester in namespace e2e-tests-prestop-fnm4d
STEP: Deleting pre-stop pod
Mar  1 09:31:19.011: INFO: Saw: {
	"Hostname": "server",
	"Sent": null,
	"Received": {
		"prestop": 1
	},
	"Errors": null,
	"Log": [
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up."
	],
	"StillContactingPeers": true
}
STEP: Deleting the server pod
[AfterEach] [k8s.io] [sig-node] PreStop
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 09:31:19.048: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-prestop-fnm4d" for this suite.
Mar  1 09:31:59.193: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 09:31:59.691: INFO: namespace: e2e-tests-prestop-fnm4d, resource: bindings, ignored listing per whitelist
Mar  1 09:32:00.673: INFO: namespace e2e-tests-prestop-fnm4d deletion completed in 41.587858816s

• [SLOW TEST:58.712 seconds]
[k8s.io] [sig-node] PreStop
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should call prestop when killing a pod  [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should rollback without unnecessary restarts [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 09:32:00.674: INFO: >>> kubeConfig: /tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-daemonsets-8pj92
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should rollback without unnecessary restarts [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Mar  1 09:32:02.462: INFO: Requires at least 2 nodes (not -1)
[AfterEach] [sig-apps] Daemon set [Serial]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
Mar  1 09:32:02.534: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-8pj92/daemonsets","resourceVersion":"23068"},"items":null}

Mar  1 09:32:02.570: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-8pj92/pods","resourceVersion":"23068"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 09:32:02.676: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-8pj92" for this suite.
Mar  1 09:32:08.824: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 09:32:09.221: INFO: namespace: e2e-tests-daemonsets-8pj92, resource: bindings, ignored listing per whitelist
Mar  1 09:32:10.245: INFO: namespace e2e-tests-daemonsets-8pj92 deletion completed in 7.532113277s

S [SKIPPING] [9.571 seconds]
[sig-apps] Daemon set [Serial]
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should rollback without unnecessary restarts [Conformance] [It]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699

  Mar  1 09:32:02.462: Requires at least 2 nodes (not -1)

  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/util.go:292
------------------------------
SS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: http [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Networking
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 09:32:10.245: INFO: >>> kubeConfig: /tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename pod-network-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-pod-network-test-4zxrl
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: http [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-4zxrl
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Mar  1 09:32:11.781: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Mar  1 09:32:36.412: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://100.96.1.2:8080/dial?request=hostName&protocol=http&host=100.96.0.67&port=8080&tries=1'] Namespace:e2e-tests-pod-network-test-4zxrl PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar  1 09:32:36.412: INFO: >>> kubeConfig: /tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
Mar  1 09:32:37.260: INFO: Waiting for endpoints: map[]
Mar  1 09:32:37.296: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://100.96.1.2:8080/dial?request=hostName&protocol=http&host=100.96.1.254&port=8080&tries=1'] Namespace:e2e-tests-pod-network-test-4zxrl PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar  1 09:32:37.296: INFO: >>> kubeConfig: /tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
Mar  1 09:32:37.938: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 09:32:37.938: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-4zxrl" for this suite.
Mar  1 09:33:00.092: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 09:33:00.948: INFO: namespace: e2e-tests-pod-network-test-4zxrl, resource: bindings, ignored listing per whitelist
Mar  1 09:33:01.444: INFO: namespace e2e-tests-pod-network-test-4zxrl deletion completed in 23.468729416s

• [SLOW TEST:51.199 seconds]
[sig-network] Networking
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: http [NodeConformance] [Conformance]
    /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory limit [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 09:33:01.444: INFO: >>> kubeConfig: /tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-c9rfl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Mar  1 09:33:03.136: INFO: Waiting up to 5m0s for pod "downwardapi-volume-02cc2c65-3c05-11e9-a72e-ce8290b78775" in namespace "e2e-tests-downward-api-c9rfl" to be "success or failure"
Mar  1 09:33:03.171: INFO: Pod "downwardapi-volume-02cc2c65-3c05-11e9-a72e-ce8290b78775": Phase="Pending", Reason="", readiness=false. Elapsed: 34.815567ms
Mar  1 09:33:05.207: INFO: Pod "downwardapi-volume-02cc2c65-3c05-11e9-a72e-ce8290b78775": Phase="Pending", Reason="", readiness=false. Elapsed: 2.07059111s
Mar  1 09:33:07.243: INFO: Pod "downwardapi-volume-02cc2c65-3c05-11e9-a72e-ce8290b78775": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.106374117s
STEP: Saw pod success
Mar  1 09:33:07.243: INFO: Pod "downwardapi-volume-02cc2c65-3c05-11e9-a72e-ce8290b78775" satisfied condition "success or failure"
Mar  1 09:33:07.279: INFO: Trying to get logs from node shoot--it--pub-az-nl4q9-cpu-worker-7dd9bbfd9c-7fp9l pod downwardapi-volume-02cc2c65-3c05-11e9-a72e-ce8290b78775 container client-container: <nil>
STEP: delete the pod
Mar  1 09:33:07.365: INFO: Waiting for pod downwardapi-volume-02cc2c65-3c05-11e9-a72e-ce8290b78775 to disappear
Mar  1 09:33:07.445: INFO: Pod downwardapi-volume-02cc2c65-3c05-11e9-a72e-ce8290b78775 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 09:33:07.445: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-c9rfl" for this suite.
Mar  1 09:33:13.602: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 09:33:14.613: INFO: namespace: e2e-tests-downward-api-c9rfl, resource: bindings, ignored listing per whitelist
Mar  1 09:33:14.978: INFO: namespace e2e-tests-downward-api-c9rfl deletion completed in 7.493734682s

• [SLOW TEST:13.534 seconds]
[sig-storage] Downward API volume
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's memory limit [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete pods created by rc when not orphaning [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 09:33:14.978: INFO: >>> kubeConfig: /tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-gc-5b66z
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete pods created by rc when not orphaning [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the rc
STEP: delete the rc
STEP: wait for all pods to be garbage collected
STEP: Gathering metrics
W0301 09:33:26.808287   31889 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Mar  1 09:33:26.808: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 09:33:26.808: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-5b66z" for this suite.
Mar  1 09:33:32.954: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 09:33:33.804: INFO: namespace: e2e-tests-gc-5b66z, resource: bindings, ignored listing per whitelist
Mar  1 09:33:34.384: INFO: namespace e2e-tests-gc-5b66z deletion completed in 7.538498905s

• [SLOW TEST:19.405 seconds]
[sig-api-machinery] Garbage collector
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should delete pods created by rc when not orphaning [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-api-machinery] Downward API 
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Downward API
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 09:33:34.384: INFO: >>> kubeConfig: /tmp/build/7d7241ef/git-kubernetes_publish_conf_test_results-master_master/scripts/azure_kubeconfig.yaml
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-hht7b
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Mar  1 09:33:36.029: INFO: Waiting up to 5m0s for pod "downward-api-166793b9-3c05-11e9-a72e-ce8290b78775" in namespace "e2e-tests-downward-api-hht7b" to be "success or failure"
Mar  1 09:33:36.088: INFO: Pod "downward-api-166793b9-3c05-11e9-a72e-ce8290b78775": Phase="Pending", Reason="", readiness=false. Elapsed: 58.382694ms
Mar  1 09:33:38.135: INFO: Pod "downward-api-166793b9-3c05-11e9-a72e-ce8290b78775": Phase="Pending", Reason="", readiness=false. Elapsed: 2.105572023s
Mar  1 09:33:40.176: INFO: Pod "downward-api-166793b9-3c05-11e9-a72e-ce8290b78775": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.146528229s
STEP: Saw pod success
Mar  1 09:33:40.176: INFO: Pod "downward-api-166793b9-3c05-11e9-a72e-ce8290b78775" satisfied condition "success or failure"
Mar  1 09:33:40.211: INFO: Trying to get logs from node shoot--it--pub-az-nl4q9-cpu-worker-7dd9bbfd9c-7fp9l pod downward-api-166793b9-3c05-11e9-a72e-ce8290b78775 container dapi-container: <nil>
STEP: delete the pod
Mar  1 09:33:40.637: INFO: Waiting for pod downward-api-166793b9-3c05-11e9-a72e-ce8290b78775 to disappear
Mar  1 09:33:40.680: INFO: Pod downward-api-166793b9-3c05-11e9-a72e-ce8290b78775 no longer exists
[AfterEach] [sig-api-machinery] Downward API
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 09:33:40.680: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-hht7b" for this suite.
Mar  1 09:33:46.892: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 09:33:47.851: INFO: namespace: e2e-tests-downward-api-hht7b, resource: bindings, ignored listing per whitelist
Mar  1 09:33:48.312: INFO: namespace e2e-tests-downward-api-hht7b deletion completed in 7.592467597s

• [SLOW TEST:13.928 seconds]
[sig-api-machinery] Downward API
/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSMar  1 09:33:48.312: INFO: Running AfterSuite actions on all node
Mar  1 09:33:48.312: INFO: Running AfterSuite actions on node 1
Mar  1 09:33:48.312: INFO: Skipping dumping logs from cluster

Ran 187 of 2011 Specs in 6377.463 seconds
SUCCESS! -- 187 Passed | 0 Failed | 0 Flaked | 0 Pending | 1824 Skipped PASS

Ginkgo ran 1 suite in 1h46m18.826046545s
Test Suite Passed
