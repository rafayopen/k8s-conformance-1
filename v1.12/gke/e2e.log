Mar  1 13:26:22.329: INFO: Overriding default scale value of zero to 1
Mar  1 13:26:22.329: INFO: Overriding default milliseconds value of zero to 5000
I0301 13:26:22.853047      19 test_context.go:385] Using a temporary kubeconfig file from in-cluster config : /tmp/kubeconfig-210205575
I0301 13:26:22.853179      19 e2e.go:304] Starting e2e run "9aef9de6-3c25-11e9-a154-0a580a280202" on Ginkgo node 1
Running Suite: Kubernetes e2e suite
===================================
Random Seed: 1551446782 - Will randomize all specs
Will run 188 of 1814 specs

Mar  1 13:26:23.027: INFO: >>> kubeConfig: /tmp/kubeconfig-210205575
Mar  1 13:26:23.030: INFO: Waiting up to 30m0s for all (but 0) nodes to be schedulable
Mar  1 13:26:23.042: INFO: Waiting up to 10m0s for all pods (need at least 0) in namespace 'kube-system' to be running and ready
Mar  1 13:26:23.085: INFO: 23 / 23 pods in namespace 'kube-system' are running and ready (0 seconds elapsed)
Mar  1 13:26:23.085: INFO: expected 8 pod replicas in namespace 'kube-system', 8 are Running and Ready.
Mar  1 13:26:23.085: INFO: Waiting up to 5m0s for all daemonsets in namespace 'kube-system' to start
Mar  1 13:26:23.094: INFO: 5 / 5 pods ready in namespace 'kube-system' in daemonset 'fluentd-gcp-v3.2.0' (0 seconds elapsed)
Mar  1 13:26:23.094: INFO: 0 / 0 pods ready in namespace 'kube-system' in daemonset 'metadata-proxy-v0.1' (0 seconds elapsed)
Mar  1 13:26:23.094: INFO: 0 / 0 pods ready in namespace 'kube-system' in daemonset 'nvidia-gpu-device-plugin' (0 seconds elapsed)
Mar  1 13:26:23.094: INFO: 5 / 5 pods ready in namespace 'kube-system' in daemonset 'prometheus-to-sd' (0 seconds elapsed)
Mar  1 13:26:23.094: INFO: e2e test version: v1.12.1
Mar  1 13:26:23.095: INFO: kube-apiserver version: v1.12.5-gke.7
SS
------------------------------
[sig-apps] ReplicationController 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 13:26:23.095: INFO: >>> kubeConfig: /tmp/kubeconfig-210205575
STEP: Building a namespace api object, basename replication-controller
Mar  1 13:26:23.213: INFO: No PodSecurityPolicies found; assuming PodSecurityPolicy is disabled.
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating replication controller my-hostname-basic-9b850bd6-3c25-11e9-a154-0a580a280202
Mar  1 13:26:23.228: INFO: Pod name my-hostname-basic-9b850bd6-3c25-11e9-a154-0a580a280202: Found 0 pods out of 1
Mar  1 13:26:28.232: INFO: Pod name my-hostname-basic-9b850bd6-3c25-11e9-a154-0a580a280202: Found 1 pods out of 1
Mar  1 13:26:28.232: INFO: Ensuring all pods for ReplicationController "my-hostname-basic-9b850bd6-3c25-11e9-a154-0a580a280202" are running
Mar  1 13:26:28.235: INFO: Pod "my-hostname-basic-9b850bd6-3c25-11e9-a154-0a580a280202-wqvxt" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-03-01 13:26:23 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-03-01 13:26:26 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-03-01 13:26:26 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-03-01 13:26:23 +0000 UTC Reason: Message:}])
Mar  1 13:26:28.235: INFO: Trying to dial the pod
Mar  1 13:26:33.248: INFO: Controller my-hostname-basic-9b850bd6-3c25-11e9-a154-0a580a280202: Got expected result from replica 1 [my-hostname-basic-9b850bd6-3c25-11e9-a154-0a580a280202-wqvxt]: "my-hostname-basic-9b850bd6-3c25-11e9-a154-0a580a280202-wqvxt", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 13:26:33.248: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-replication-controller-t2jwb" for this suite.
Mar  1 13:26:39.264: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 13:26:39.299: INFO: namespace: e2e-tests-replication-controller-t2jwb, resource: bindings, ignored listing per whitelist
Mar  1 13:26:39.384: INFO: namespace e2e-tests-replication-controller-t2jwb deletion completed in 6.131656246s

• [SLOW TEST:16.288 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Projected 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 13:26:39.384: INFO: >>> kubeConfig: /tmp/kubeconfig-210205575
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name cm-test-opt-del-a5374fd9-3c25-11e9-a154-0a580a280202
STEP: Creating configMap with name cm-test-opt-upd-a5375008-3c25-11e9-a154-0a580a280202
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-a5374fd9-3c25-11e9-a154-0a580a280202
STEP: Updating configmap cm-test-opt-upd-a5375008-3c25-11e9-a154-0a580a280202
STEP: Creating configMap with name cm-test-opt-create-a5375019-3c25-11e9-a154-0a580a280202
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 13:26:43.627: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-qzxph" for this suite.
Mar  1 13:27:05.644: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 13:27:05.736: INFO: namespace: e2e-tests-projected-qzxph, resource: bindings, ignored listing per whitelist
Mar  1 13:27:05.796: INFO: namespace e2e-tests-projected-qzxph deletion completed in 22.163380073s

• [SLOW TEST:26.412 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 13:27:05.796: INFO: >>> kubeConfig: /tmp/kubeconfig-210205575
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-map-b50ee186-3c25-11e9-a154-0a580a280202
STEP: Creating a pod to test consume secrets
Mar  1 13:27:06.095: INFO: Waiting up to 5m0s for pod "pod-secrets-b50fa7a4-3c25-11e9-a154-0a580a280202" in namespace "e2e-tests-secrets-gsjlg" to be "success or failure"
Mar  1 13:27:06.107: INFO: Pod "pod-secrets-b50fa7a4-3c25-11e9-a154-0a580a280202": Phase="Pending", Reason="", readiness=false. Elapsed: 11.878499ms
Mar  1 13:27:08.112: INFO: Pod "pod-secrets-b50fa7a4-3c25-11e9-a154-0a580a280202": Phase="Pending", Reason="", readiness=false. Elapsed: 2.016926496s
Mar  1 13:27:10.116: INFO: Pod "pod-secrets-b50fa7a4-3c25-11e9-a154-0a580a280202": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.021519172s
STEP: Saw pod success
Mar  1 13:27:10.117: INFO: Pod "pod-secrets-b50fa7a4-3c25-11e9-a154-0a580a280202" satisfied condition "success or failure"
Mar  1 13:27:10.120: INFO: Trying to get logs from node gke-conformance-default-pool-eca581b0-sqmc pod pod-secrets-b50fa7a4-3c25-11e9-a154-0a580a280202 container secret-volume-test: <nil>
STEP: delete the pod
Mar  1 13:27:10.152: INFO: Waiting for pod pod-secrets-b50fa7a4-3c25-11e9-a154-0a580a280202 to disappear
Mar  1 13:27:10.156: INFO: Pod pod-secrets-b50fa7a4-3c25-11e9-a154-0a580a280202 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 13:27:10.156: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-gsjlg" for this suite.
Mar  1 13:27:16.172: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 13:27:16.415: INFO: namespace: e2e-tests-secrets-gsjlg, resource: bindings, ignored listing per whitelist
Mar  1 13:27:16.461: INFO: namespace e2e-tests-secrets-gsjlg deletion completed in 6.302068985s

• [SLOW TEST:10.665 seconds]
[sig-storage] Secrets
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Projected 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 13:27:16.461: INFO: >>> kubeConfig: /tmp/kubeconfig-210205575
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Mar  1 13:27:16.577: INFO: Waiting up to 5m0s for pod "downwardapi-volume-bb522003-3c25-11e9-a154-0a580a280202" in namespace "e2e-tests-projected-t8d6l" to be "success or failure"
Mar  1 13:27:16.584: INFO: Pod "downwardapi-volume-bb522003-3c25-11e9-a154-0a580a280202": Phase="Pending", Reason="", readiness=false. Elapsed: 7.361437ms
Mar  1 13:27:18.588: INFO: Pod "downwardapi-volume-bb522003-3c25-11e9-a154-0a580a280202": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.011349894s
STEP: Saw pod success
Mar  1 13:27:18.588: INFO: Pod "downwardapi-volume-bb522003-3c25-11e9-a154-0a580a280202" satisfied condition "success or failure"
Mar  1 13:27:18.591: INFO: Trying to get logs from node gke-conformance-default-pool-eca581b0-czl4 pod downwardapi-volume-bb522003-3c25-11e9-a154-0a580a280202 container client-container: <nil>
STEP: delete the pod
Mar  1 13:27:18.626: INFO: Waiting for pod downwardapi-volume-bb522003-3c25-11e9-a154-0a580a280202 to disappear
Mar  1 13:27:18.643: INFO: Pod downwardapi-volume-bb522003-3c25-11e9-a154-0a580a280202 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 13:27:18.643: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-t8d6l" for this suite.
Mar  1 13:27:24.687: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 13:27:24.845: INFO: namespace: e2e-tests-projected-t8d6l, resource: bindings, ignored listing per whitelist
Mar  1 13:27:24.878: INFO: namespace e2e-tests-projected-t8d6l deletion completed in 6.223006718s

• [SLOW TEST:8.417 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 13:27:24.878: INFO: >>> kubeConfig: /tmp/kubeconfig-210205575
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a watch on configmaps with label A
STEP: creating a watch on configmaps with label B
STEP: creating a watch on configmaps with label A or B
STEP: creating a configmap with label A and ensuring the correct watchers observe the notification
Mar  1 13:27:25.005: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-zbzxt,SelfLink:/api/v1/namespaces/e2e-tests-watch-zbzxt/configmaps/e2e-watch-test-configmap-a,UID:c05826e2-3c25-11e9-83c3-42010a800094,ResourceVersion:1550,Generation:0,CreationTimestamp:2019-03-01 13:27:24 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Mar  1 13:27:25.005: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-zbzxt,SelfLink:/api/v1/namespaces/e2e-tests-watch-zbzxt/configmaps/e2e-watch-test-configmap-a,UID:c05826e2-3c25-11e9-83c3-42010a800094,ResourceVersion:1550,Generation:0,CreationTimestamp:2019-03-01 13:27:24 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: modifying configmap A and ensuring the correct watchers observe the notification
Mar  1 13:27:35.012: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-zbzxt,SelfLink:/api/v1/namespaces/e2e-tests-watch-zbzxt/configmaps/e2e-watch-test-configmap-a,UID:c05826e2-3c25-11e9-83c3-42010a800094,ResourceVersion:1586,Generation:0,CreationTimestamp:2019-03-01 13:27:24 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Mar  1 13:27:35.012: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-zbzxt,SelfLink:/api/v1/namespaces/e2e-tests-watch-zbzxt/configmaps/e2e-watch-test-configmap-a,UID:c05826e2-3c25-11e9-83c3-42010a800094,ResourceVersion:1586,Generation:0,CreationTimestamp:2019-03-01 13:27:24 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying configmap A again and ensuring the correct watchers observe the notification
Mar  1 13:27:45.029: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-zbzxt,SelfLink:/api/v1/namespaces/e2e-tests-watch-zbzxt/configmaps/e2e-watch-test-configmap-a,UID:c05826e2-3c25-11e9-83c3-42010a800094,ResourceVersion:1619,Generation:0,CreationTimestamp:2019-03-01 13:27:24 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Mar  1 13:27:45.029: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-zbzxt,SelfLink:/api/v1/namespaces/e2e-tests-watch-zbzxt/configmaps/e2e-watch-test-configmap-a,UID:c05826e2-3c25-11e9-83c3-42010a800094,ResourceVersion:1619,Generation:0,CreationTimestamp:2019-03-01 13:27:24 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: deleting configmap A and ensuring the correct watchers observe the notification
Mar  1 13:27:55.040: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-zbzxt,SelfLink:/api/v1/namespaces/e2e-tests-watch-zbzxt/configmaps/e2e-watch-test-configmap-a,UID:c05826e2-3c25-11e9-83c3-42010a800094,ResourceVersion:1647,Generation:0,CreationTimestamp:2019-03-01 13:27:24 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Mar  1 13:27:55.040: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-zbzxt,SelfLink:/api/v1/namespaces/e2e-tests-watch-zbzxt/configmaps/e2e-watch-test-configmap-a,UID:c05826e2-3c25-11e9-83c3-42010a800094,ResourceVersion:1647,Generation:0,CreationTimestamp:2019-03-01 13:27:24 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: creating a configmap with label B and ensuring the correct watchers observe the notification
Mar  1 13:28:05.108: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-zbzxt,SelfLink:/api/v1/namespaces/e2e-tests-watch-zbzxt/configmaps/e2e-watch-test-configmap-b,UID:d83a3dfb-3c25-11e9-83c3-42010a800094,ResourceVersion:1673,Generation:0,CreationTimestamp:2019-03-01 13:28:05 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Mar  1 13:28:05.108: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-zbzxt,SelfLink:/api/v1/namespaces/e2e-tests-watch-zbzxt/configmaps/e2e-watch-test-configmap-b,UID:d83a3dfb-3c25-11e9-83c3-42010a800094,ResourceVersion:1673,Generation:0,CreationTimestamp:2019-03-01 13:28:05 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: deleting configmap B and ensuring the correct watchers observe the notification
Mar  1 13:28:15.124: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-zbzxt,SelfLink:/api/v1/namespaces/e2e-tests-watch-zbzxt/configmaps/e2e-watch-test-configmap-b,UID:d83a3dfb-3c25-11e9-83c3-42010a800094,ResourceVersion:1700,Generation:0,CreationTimestamp:2019-03-01 13:28:05 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Mar  1 13:28:15.124: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-zbzxt,SelfLink:/api/v1/namespaces/e2e-tests-watch-zbzxt/configmaps/e2e-watch-test-configmap-b,UID:d83a3dfb-3c25-11e9-83c3-42010a800094,ResourceVersion:1700,Generation:0,CreationTimestamp:2019-03-01 13:28:05 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 13:28:25.124: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-zbzxt" for this suite.
Mar  1 13:28:31.143: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 13:28:31.222: INFO: namespace: e2e-tests-watch-zbzxt, resource: bindings, ignored listing per whitelist
Mar  1 13:28:31.269: INFO: namespace e2e-tests-watch-zbzxt deletion completed in 6.14112313s

• [SLOW TEST:66.391 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Downward API volume 
  should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 13:28:31.269: INFO: >>> kubeConfig: /tmp/kubeconfig-210205575
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Mar  1 13:28:31.374: INFO: Waiting up to 5m0s for pod "downwardapi-volume-e7e7146b-3c25-11e9-a154-0a580a280202" in namespace "e2e-tests-downward-api-446mf" to be "success or failure"
Mar  1 13:28:31.377: INFO: Pod "downwardapi-volume-e7e7146b-3c25-11e9-a154-0a580a280202": Phase="Pending", Reason="", readiness=false. Elapsed: 2.579463ms
Mar  1 13:28:33.380: INFO: Pod "downwardapi-volume-e7e7146b-3c25-11e9-a154-0a580a280202": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006168538s
Mar  1 13:28:35.384: INFO: Pod "downwardapi-volume-e7e7146b-3c25-11e9-a154-0a580a280202": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.010036472s
STEP: Saw pod success
Mar  1 13:28:35.384: INFO: Pod "downwardapi-volume-e7e7146b-3c25-11e9-a154-0a580a280202" satisfied condition "success or failure"
Mar  1 13:28:35.387: INFO: Trying to get logs from node gke-conformance-default-pool-eca581b0-sww9 pod downwardapi-volume-e7e7146b-3c25-11e9-a154-0a580a280202 container client-container: <nil>
STEP: delete the pod
Mar  1 13:28:35.423: INFO: Waiting for pod downwardapi-volume-e7e7146b-3c25-11e9-a154-0a580a280202 to disappear
Mar  1 13:28:35.427: INFO: Pod downwardapi-volume-e7e7146b-3c25-11e9-a154-0a580a280202 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 13:28:35.427: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-446mf" for this suite.
Mar  1 13:28:41.445: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 13:28:41.519: INFO: namespace: e2e-tests-downward-api-446mf, resource: bindings, ignored listing per whitelist
Mar  1 13:28:41.576: INFO: namespace e2e-tests-downward-api-446mf deletion completed in 6.143928274s

• [SLOW TEST:10.306 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 13:28:41.576: INFO: >>> kubeConfig: /tmp/kubeconfig-210205575
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Mar  1 13:28:41.701: INFO: Waiting up to 5m0s for pod "downwardapi-volume-ee0ed0cb-3c25-11e9-a154-0a580a280202" in namespace "e2e-tests-downward-api-tpjdr" to be "success or failure"
Mar  1 13:28:41.720: INFO: Pod "downwardapi-volume-ee0ed0cb-3c25-11e9-a154-0a580a280202": Phase="Pending", Reason="", readiness=false. Elapsed: 18.977186ms
Mar  1 13:28:43.724: INFO: Pod "downwardapi-volume-ee0ed0cb-3c25-11e9-a154-0a580a280202": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.023189328s
STEP: Saw pod success
Mar  1 13:28:43.724: INFO: Pod "downwardapi-volume-ee0ed0cb-3c25-11e9-a154-0a580a280202" satisfied condition "success or failure"
Mar  1 13:28:43.727: INFO: Trying to get logs from node gke-conformance-default-pool-eca581b0-sqmc pod downwardapi-volume-ee0ed0cb-3c25-11e9-a154-0a580a280202 container client-container: <nil>
STEP: delete the pod
Mar  1 13:28:43.750: INFO: Waiting for pod downwardapi-volume-ee0ed0cb-3c25-11e9-a154-0a580a280202 to disappear
Mar  1 13:28:43.754: INFO: Pod downwardapi-volume-ee0ed0cb-3c25-11e9-a154-0a580a280202 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 13:28:43.754: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-tpjdr" for this suite.
Mar  1 13:28:49.773: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 13:28:49.833: INFO: namespace: e2e-tests-downward-api-tpjdr, resource: bindings, ignored listing per whitelist
Mar  1 13:28:49.915: INFO: namespace e2e-tests-downward-api-tpjdr deletion completed in 6.154887274s

• [SLOW TEST:8.339 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Proxy server 
  should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 13:28:49.915: INFO: >>> kubeConfig: /tmp/kubeconfig-210205575
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Starting the proxy
Mar  1 13:28:50.013: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-210205575 proxy --unix-socket=/tmp/kubectl-proxy-unix311896378/test'
STEP: retrieving proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 13:28:50.080: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-d99nl" for this suite.
Mar  1 13:28:56.097: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 13:28:56.282: INFO: namespace: e2e-tests-kubectl-d99nl, resource: bindings, ignored listing per whitelist
Mar  1 13:28:56.305: INFO: namespace e2e-tests-kubectl-d99nl deletion completed in 6.219844929s

• [SLOW TEST:6.390 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Proxy server
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should support --unix-socket=/path  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 13:28:56.306: INFO: >>> kubeConfig: /tmp/kubeconfig-210205575
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0644 on node default medium
Mar  1 13:28:56.405: INFO: Waiting up to 5m0s for pod "pod-f6d2d6b1-3c25-11e9-a154-0a580a280202" in namespace "e2e-tests-emptydir-jwnrw" to be "success or failure"
Mar  1 13:28:56.412: INFO: Pod "pod-f6d2d6b1-3c25-11e9-a154-0a580a280202": Phase="Pending", Reason="", readiness=false. Elapsed: 6.323847ms
Mar  1 13:28:58.415: INFO: Pod "pod-f6d2d6b1-3c25-11e9-a154-0a580a280202": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010228659s
STEP: Saw pod success
Mar  1 13:28:58.416: INFO: Pod "pod-f6d2d6b1-3c25-11e9-a154-0a580a280202" satisfied condition "success or failure"
Mar  1 13:28:58.418: INFO: Trying to get logs from node gke-conformance-default-pool-eca581b0-czl4 pod pod-f6d2d6b1-3c25-11e9-a154-0a580a280202 container test-container: <nil>
STEP: delete the pod
Mar  1 13:28:58.442: INFO: Waiting for pod pod-f6d2d6b1-3c25-11e9-a154-0a580a280202 to disappear
Mar  1 13:28:58.449: INFO: Pod pod-f6d2d6b1-3c25-11e9-a154-0a580a280202 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 13:28:58.449: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-jwnrw" for this suite.
Mar  1 13:29:04.465: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 13:29:04.544: INFO: namespace: e2e-tests-emptydir-jwnrw, resource: bindings, ignored listing per whitelist
Mar  1 13:29:04.598: INFO: namespace e2e-tests-emptydir-jwnrw deletion completed in 6.145737779s

• [SLOW TEST:8.293 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 13:29:04.599: INFO: >>> kubeConfig: /tmp/kubeconfig-210205575
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0777 on node default medium
Mar  1 13:29:04.693: INFO: Waiting up to 5m0s for pod "pod-fbc34fe2-3c25-11e9-a154-0a580a280202" in namespace "e2e-tests-emptydir-vqv9r" to be "success or failure"
Mar  1 13:29:04.701: INFO: Pod "pod-fbc34fe2-3c25-11e9-a154-0a580a280202": Phase="Pending", Reason="", readiness=false. Elapsed: 7.626815ms
Mar  1 13:29:06.704: INFO: Pod "pod-fbc34fe2-3c25-11e9-a154-0a580a280202": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.01119872s
STEP: Saw pod success
Mar  1 13:29:06.704: INFO: Pod "pod-fbc34fe2-3c25-11e9-a154-0a580a280202" satisfied condition "success or failure"
Mar  1 13:29:06.707: INFO: Trying to get logs from node gke-conformance-default-pool-eca581b0-sww9 pod pod-fbc34fe2-3c25-11e9-a154-0a580a280202 container test-container: <nil>
STEP: delete the pod
Mar  1 13:29:06.730: INFO: Waiting for pod pod-fbc34fe2-3c25-11e9-a154-0a580a280202 to disappear
Mar  1 13:29:06.735: INFO: Pod pod-fbc34fe2-3c25-11e9-a154-0a580a280202 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 13:29:06.735: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-vqv9r" for this suite.
Mar  1 13:29:12.749: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 13:29:12.805: INFO: namespace: e2e-tests-emptydir-vqv9r, resource: bindings, ignored listing per whitelist
Mar  1 13:29:12.900: INFO: namespace e2e-tests-emptydir-vqv9r deletion completed in 6.162020503s

• [SLOW TEST:8.302 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 13:29:12.901: INFO: >>> kubeConfig: /tmp/kubeconfig-210205575
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: modifying the configmap a second time
STEP: deleting the configmap
STEP: creating a watch on configmaps from the resource version returned by the first update
STEP: Expecting to observe notifications for all changes to the configmap after the first update
Mar  1 13:29:13.048: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-resource-version,GenerateName:,Namespace:e2e-tests-watch-jpn4z,SelfLink:/api/v1/namespaces/e2e-tests-watch-jpn4z/configmaps/e2e-watch-test-resource-version,UID:00b9dd47-3c26-11e9-83c3-42010a800094,ResourceVersion:1960,Generation:0,CreationTimestamp:2019-03-01 13:29:13 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: from-resource-version,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Mar  1 13:29:13.049: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-resource-version,GenerateName:,Namespace:e2e-tests-watch-jpn4z,SelfLink:/api/v1/namespaces/e2e-tests-watch-jpn4z/configmaps/e2e-watch-test-resource-version,UID:00b9dd47-3c26-11e9-83c3-42010a800094,ResourceVersion:1961,Generation:0,CreationTimestamp:2019-03-01 13:29:13 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: from-resource-version,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 13:29:13.049: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-jpn4z" for this suite.
Mar  1 13:29:19.064: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 13:29:19.095: INFO: namespace: e2e-tests-watch-jpn4z, resource: bindings, ignored listing per whitelist
Mar  1 13:29:19.396: INFO: namespace e2e-tests-watch-jpn4z deletion completed in 6.342428715s

• [SLOW TEST:6.496 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 13:29:19.397: INFO: >>> kubeConfig: /tmp/kubeconfig-210205575
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Mar  1 13:29:19.494: INFO: Waiting up to 5m0s for pod "downwardapi-volume-0495bf38-3c26-11e9-a154-0a580a280202" in namespace "e2e-tests-downward-api-ndjl6" to be "success or failure"
Mar  1 13:29:19.499: INFO: Pod "downwardapi-volume-0495bf38-3c26-11e9-a154-0a580a280202": Phase="Pending", Reason="", readiness=false. Elapsed: 4.182656ms
Mar  1 13:29:21.502: INFO: Pod "downwardapi-volume-0495bf38-3c26-11e9-a154-0a580a280202": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007538005s
Mar  1 13:29:23.506: INFO: Pod "downwardapi-volume-0495bf38-3c26-11e9-a154-0a580a280202": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011347391s
STEP: Saw pod success
Mar  1 13:29:23.506: INFO: Pod "downwardapi-volume-0495bf38-3c26-11e9-a154-0a580a280202" satisfied condition "success or failure"
Mar  1 13:29:23.509: INFO: Trying to get logs from node gke-conformance-default-pool-eca581b0-sqmc pod downwardapi-volume-0495bf38-3c26-11e9-a154-0a580a280202 container client-container: <nil>
STEP: delete the pod
Mar  1 13:29:23.533: INFO: Waiting for pod downwardapi-volume-0495bf38-3c26-11e9-a154-0a580a280202 to disappear
Mar  1 13:29:23.536: INFO: Pod downwardapi-volume-0495bf38-3c26-11e9-a154-0a580a280202 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 13:29:23.536: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-ndjl6" for this suite.
Mar  1 13:29:29.552: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 13:29:29.639: INFO: namespace: e2e-tests-downward-api-ndjl6, resource: bindings, ignored listing per whitelist
Mar  1 13:29:29.680: INFO: namespace e2e-tests-downward-api-ndjl6 deletion completed in 6.138877133s

• [SLOW TEST:10.283 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 13:29:29.680: INFO: >>> kubeConfig: /tmp/kubeconfig-210205575
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:78
Mar  1 13:29:29.798: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Mar  1 13:29:29.807: INFO: Waiting for terminating namespaces to be deleted...
Mar  1 13:29:29.818: INFO: 
Logging pods the kubelet thinks is on node gke-conformance-default-pool-eca581b0-00fq before test
Mar  1 13:29:29.844: INFO: kube-proxy-gke-conformance-default-pool-eca581b0-00fq from kube-system started at <nil> (0 container statuses recorded)
Mar  1 13:29:29.844: INFO: fluentd-gcp-v3.2.0-22pm2 from kube-system started at 2019-03-01 13:23:51 +0000 UTC (2 container statuses recorded)
Mar  1 13:29:29.844: INFO: 	Container fluentd-gcp ready: true, restart count 0
Mar  1 13:29:29.844: INFO: 	Container prometheus-to-sd-exporter ready: true, restart count 0
Mar  1 13:29:29.844: INFO: prometheus-to-sd-b6mpb from kube-system started at 2019-03-01 13:23:41 +0000 UTC (1 container statuses recorded)
Mar  1 13:29:29.844: INFO: 	Container prometheus-to-sd ready: true, restart count 0
Mar  1 13:29:29.844: INFO: sonobuoy-e2e-job-48f7569bb1614ff5 from heptio-sonobuoy started at 2019-03-01 13:25:56 +0000 UTC (2 container statuses recorded)
Mar  1 13:29:29.844: INFO: 	Container e2e ready: true, restart count 0
Mar  1 13:29:29.844: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Mar  1 13:29:29.844: INFO: sonobuoy-systemd-logs-daemon-set-85467eaf90f647f9-rqg97 from heptio-sonobuoy started at 2019-03-01 13:25:56 +0000 UTC (2 container statuses recorded)
Mar  1 13:29:29.844: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 0
Mar  1 13:29:29.844: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Mar  1 13:29:29.844: INFO: 
Logging pods the kubelet thinks is on node gke-conformance-default-pool-eca581b0-40vx before test
Mar  1 13:29:30.012: INFO: fluentd-gcp-scaler-69d79984cb-v6cwh from kube-system started at 2019-03-01 13:23:39 +0000 UTC (1 container statuses recorded)
Mar  1 13:29:30.012: INFO: 	Container fluentd-gcp-scaler ready: true, restart count 0
Mar  1 13:29:30.012: INFO: prometheus-to-sd-clvb4 from kube-system started at 2019-03-01 13:23:40 +0000 UTC (1 container statuses recorded)
Mar  1 13:29:30.012: INFO: 	Container prometheus-to-sd ready: true, restart count 0
Mar  1 13:29:30.012: INFO: fluentd-gcp-v3.2.0-z4kfv from kube-system started at 2019-03-01 13:23:53 +0000 UTC (2 container statuses recorded)
Mar  1 13:29:30.012: INFO: 	Container fluentd-gcp ready: true, restart count 0
Mar  1 13:29:30.012: INFO: 	Container prometheus-to-sd-exporter ready: true, restart count 0
Mar  1 13:29:30.012: INFO: metrics-server-v0.3.1-54699c9cc8-f74r6 from kube-system started at 2019-03-01 13:23:53 +0000 UTC (2 container statuses recorded)
Mar  1 13:29:30.012: INFO: 	Container metrics-server ready: true, restart count 0
Mar  1 13:29:30.012: INFO: 	Container metrics-server-nanny ready: true, restart count 0
Mar  1 13:29:30.012: INFO: kube-dns-659bd65dfc-mpd7w from kube-system started at 2019-03-01 13:23:57 +0000 UTC (4 container statuses recorded)
Mar  1 13:29:30.012: INFO: 	Container dnsmasq ready: true, restart count 0
Mar  1 13:29:30.012: INFO: 	Container kubedns ready: true, restart count 0
Mar  1 13:29:30.012: INFO: 	Container prometheus-to-sd ready: true, restart count 0
Mar  1 13:29:30.012: INFO: 	Container sidecar ready: true, restart count 0
Mar  1 13:29:30.012: INFO: kube-proxy-gke-conformance-default-pool-eca581b0-40vx from kube-system started at <nil> (0 container statuses recorded)
Mar  1 13:29:30.012: INFO: kube-dns-659bd65dfc-q4d65 from kube-system started at 2019-03-01 13:23:39 +0000 UTC (4 container statuses recorded)
Mar  1 13:29:30.012: INFO: 	Container dnsmasq ready: true, restart count 0
Mar  1 13:29:30.012: INFO: 	Container kubedns ready: true, restart count 0
Mar  1 13:29:30.012: INFO: 	Container prometheus-to-sd ready: true, restart count 0
Mar  1 13:29:30.012: INFO: 	Container sidecar ready: true, restart count 0
Mar  1 13:29:30.012: INFO: kube-dns-autoscaler-76fcd5f658-wqrrk from kube-system started at 2019-03-01 13:23:53 +0000 UTC (1 container statuses recorded)
Mar  1 13:29:30.012: INFO: 	Container autoscaler ready: true, restart count 0
Mar  1 13:29:30.012: INFO: heapster-v1.6.0-beta.1-554b54d8fb-s9lfd from kube-system started at 2019-03-01 13:23:53 +0000 UTC (3 container statuses recorded)
Mar  1 13:29:30.012: INFO: 	Container heapster ready: true, restart count 0
Mar  1 13:29:30.012: INFO: 	Container heapster-nanny ready: true, restart count 0
Mar  1 13:29:30.012: INFO: 	Container prom-to-sd ready: true, restart count 0
Mar  1 13:29:30.012: INFO: sonobuoy-systemd-logs-daemon-set-85467eaf90f647f9-7gvps from heptio-sonobuoy started at 2019-03-01 13:25:56 +0000 UTC (2 container statuses recorded)
Mar  1 13:29:30.012: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 0
Mar  1 13:29:30.012: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Mar  1 13:29:30.012: INFO: l7-default-backend-6f8697844f-9bl6b from kube-system started at 2019-03-01 13:23:39 +0000 UTC (1 container statuses recorded)
Mar  1 13:29:30.012: INFO: 	Container default-http-backend ready: true, restart count 0
Mar  1 13:29:30.012: INFO: event-exporter-v0.2.3-f9c896d75-gm5q7 from kube-system started at 2019-03-01 13:23:40 +0000 UTC (2 container statuses recorded)
Mar  1 13:29:30.012: INFO: 	Container event-exporter ready: true, restart count 0
Mar  1 13:29:30.012: INFO: 	Container prometheus-to-sd-exporter ready: true, restart count 0
Mar  1 13:29:30.012: INFO: 
Logging pods the kubelet thinks is on node gke-conformance-default-pool-eca581b0-czl4 before test
Mar  1 13:29:30.117: INFO: fluentd-gcp-v3.2.0-557h7 from kube-system started at 2019-03-01 13:23:51 +0000 UTC (2 container statuses recorded)
Mar  1 13:29:30.117: INFO: 	Container fluentd-gcp ready: true, restart count 0
Mar  1 13:29:30.117: INFO: 	Container prometheus-to-sd-exporter ready: true, restart count 0
Mar  1 13:29:30.117: INFO: prometheus-to-sd-77kbd from kube-system started at 2019-03-01 13:23:41 +0000 UTC (1 container statuses recorded)
Mar  1 13:29:30.117: INFO: 	Container prometheus-to-sd ready: true, restart count 0
Mar  1 13:29:30.117: INFO: sonobuoy-systemd-logs-daemon-set-85467eaf90f647f9-8jn8q from heptio-sonobuoy started at 2019-03-01 13:25:56 +0000 UTC (2 container statuses recorded)
Mar  1 13:29:30.117: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 0
Mar  1 13:29:30.117: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Mar  1 13:29:30.117: INFO: kube-proxy-gke-conformance-default-pool-eca581b0-czl4 from kube-system started at <nil> (0 container statuses recorded)
Mar  1 13:29:30.117: INFO: 
Logging pods the kubelet thinks is on node gke-conformance-default-pool-eca581b0-sqmc before test
Mar  1 13:29:30.136: INFO: kube-proxy-gke-conformance-default-pool-eca581b0-sqmc from kube-system started at <nil> (0 container statuses recorded)
Mar  1 13:29:30.136: INFO: prometheus-to-sd-lj8s7 from kube-system started at 2019-03-01 13:23:41 +0000 UTC (1 container statuses recorded)
Mar  1 13:29:30.136: INFO: 	Container prometheus-to-sd ready: true, restart count 0
Mar  1 13:29:30.136: INFO: fluentd-gcp-v3.2.0-ltz26 from kube-system started at 2019-03-01 13:23:50 +0000 UTC (2 container statuses recorded)
Mar  1 13:29:30.136: INFO: 	Container fluentd-gcp ready: true, restart count 0
Mar  1 13:29:30.136: INFO: 	Container prometheus-to-sd-exporter ready: true, restart count 0
Mar  1 13:29:30.136: INFO: sonobuoy-systemd-logs-daemon-set-85467eaf90f647f9-x9t8z from heptio-sonobuoy started at 2019-03-01 13:25:56 +0000 UTC (2 container statuses recorded)
Mar  1 13:29:30.136: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 0
Mar  1 13:29:30.136: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Mar  1 13:29:30.136: INFO: 
Logging pods the kubelet thinks is on node gke-conformance-default-pool-eca581b0-sww9 before test
Mar  1 13:29:30.145: INFO: prometheus-to-sd-5qc6r from kube-system started at 2019-03-01 13:23:40 +0000 UTC (1 container statuses recorded)
Mar  1 13:29:30.145: INFO: 	Container prometheus-to-sd ready: true, restart count 0
Mar  1 13:29:30.145: INFO: sonobuoy from heptio-sonobuoy started at 2019-03-01 13:25:52 +0000 UTC (1 container statuses recorded)
Mar  1 13:29:30.145: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Mar  1 13:29:30.145: INFO: sonobuoy-systemd-logs-daemon-set-85467eaf90f647f9-fr9v9 from heptio-sonobuoy started at 2019-03-01 13:25:56 +0000 UTC (2 container statuses recorded)
Mar  1 13:29:30.145: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 0
Mar  1 13:29:30.145: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Mar  1 13:29:30.145: INFO: kube-proxy-gke-conformance-default-pool-eca581b0-sww9 from kube-system started at <nil> (0 container statuses recorded)
Mar  1 13:29:30.145: INFO: fluentd-gcp-v3.2.0-ttmft from kube-system started at 2019-03-01 13:23:51 +0000 UTC (2 container statuses recorded)
Mar  1 13:29:30.145: INFO: 	Container fluentd-gcp ready: true, restart count 0
Mar  1 13:29:30.145: INFO: 	Container prometheus-to-sd-exporter ready: true, restart count 0
[It] validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Trying to launch a pod without a label to get a node which can launch it.
STEP: Explicitly delete pod here to free the resource it takes.
STEP: Trying to apply a random label on the found node.
STEP: verifying the node has the label kubernetes.io/e2e-0c26fde4-3c26-11e9-a154-0a580a280202 42
STEP: Trying to relaunch the pod, now with labels.
STEP: removing the label kubernetes.io/e2e-0c26fde4-3c26-11e9-a154-0a580a280202 off the node gke-conformance-default-pool-eca581b0-czl4
STEP: verifying the node doesn't have the label kubernetes.io/e2e-0c26fde4-3c26-11e9-a154-0a580a280202
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 13:29:34.237: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-sched-pred-txdq5" for this suite.
Mar  1 13:29:54.252: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 13:29:54.288: INFO: namespace: e2e-tests-sched-pred-txdq5, resource: bindings, ignored listing per whitelist
Mar  1 13:29:54.363: INFO: namespace e2e-tests-sched-pred-txdq5 deletion completed in 20.121948068s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:69

• [SLOW TEST:24.683 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-cli] Kubectl client [k8s.io] Proxy server 
  should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 13:29:54.363: INFO: >>> kubeConfig: /tmp/kubeconfig-210205575
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: starting the proxy server
Mar  1 13:29:54.502: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-210205575 proxy -p 0 --disable-filter'
STEP: curling proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 13:29:54.575: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-qcl4k" for this suite.
Mar  1 13:30:00.591: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 13:30:00.758: INFO: namespace: e2e-tests-kubectl-qcl4k, resource: bindings, ignored listing per whitelist
Mar  1 13:30:00.780: INFO: namespace e2e-tests-kubectl-qcl4k deletion completed in 6.19991666s

• [SLOW TEST:6.417 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Proxy server
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should support proxy with --port 0  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[k8s.io] Probing container 
  should have monotonically increasing restart count [Slow][NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 13:30:00.780: INFO: >>> kubeConfig: /tmp/kubeconfig-210205575
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should have monotonically increasing restart count [Slow][NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-http in namespace e2e-tests-container-probe-jq7h6
Mar  1 13:30:04.916: INFO: Started pod liveness-http in namespace e2e-tests-container-probe-jq7h6
STEP: checking the pod's current state and verifying that restartCount is present
Mar  1 13:30:04.919: INFO: Initial restart count of pod liveness-http is 0
Mar  1 13:30:15.013: INFO: Restart count of pod e2e-tests-container-probe-jq7h6/liveness-http is now 1 (10.094434575s elapsed)
Mar  1 13:30:35.049: INFO: Restart count of pod e2e-tests-container-probe-jq7h6/liveness-http is now 2 (30.130002121s elapsed)
Mar  1 13:30:55.085: INFO: Restart count of pod e2e-tests-container-probe-jq7h6/liveness-http is now 3 (50.166357871s elapsed)
Mar  1 13:31:15.129: INFO: Restart count of pod e2e-tests-container-probe-jq7h6/liveness-http is now 4 (1m10.210566002s elapsed)
Mar  1 13:32:27.288: INFO: Restart count of pod e2e-tests-container-probe-jq7h6/liveness-http is now 5 (2m22.368946867s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 13:32:27.304: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-jq7h6" for this suite.
Mar  1 13:32:33.328: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 13:32:33.409: INFO: namespace: e2e-tests-container-probe-jq7h6, resource: bindings, ignored listing per whitelist
Mar  1 13:32:33.469: INFO: namespace e2e-tests-container-probe-jq7h6 deletion completed in 6.154021594s

• [SLOW TEST:152.689 seconds]
[k8s.io] Probing container
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should have monotonically increasing restart count [Slow][NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Projected 
  should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 13:32:33.470: INFO: >>> kubeConfig: /tmp/kubeconfig-210205575
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Mar  1 13:32:33.588: INFO: Waiting up to 5m0s for pod "downwardapi-volume-7845a6b1-3c26-11e9-a154-0a580a280202" in namespace "e2e-tests-projected-x7kc5" to be "success or failure"
Mar  1 13:32:33.593: INFO: Pod "downwardapi-volume-7845a6b1-3c26-11e9-a154-0a580a280202": Phase="Pending", Reason="", readiness=false. Elapsed: 4.42588ms
Mar  1 13:32:35.597: INFO: Pod "downwardapi-volume-7845a6b1-3c26-11e9-a154-0a580a280202": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008401052s
Mar  1 13:32:37.601: INFO: Pod "downwardapi-volume-7845a6b1-3c26-11e9-a154-0a580a280202": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012237753s
STEP: Saw pod success
Mar  1 13:32:37.601: INFO: Pod "downwardapi-volume-7845a6b1-3c26-11e9-a154-0a580a280202" satisfied condition "success or failure"
Mar  1 13:32:37.604: INFO: Trying to get logs from node gke-conformance-default-pool-eca581b0-sqmc pod downwardapi-volume-7845a6b1-3c26-11e9-a154-0a580a280202 container client-container: <nil>
STEP: delete the pod
Mar  1 13:32:37.632: INFO: Waiting for pod downwardapi-volume-7845a6b1-3c26-11e9-a154-0a580a280202 to disappear
Mar  1 13:32:37.640: INFO: Pod downwardapi-volume-7845a6b1-3c26-11e9-a154-0a580a280202 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 13:32:37.640: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-x7kc5" for this suite.
Mar  1 13:32:43.658: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 13:32:43.764: INFO: namespace: e2e-tests-projected-x7kc5, resource: bindings, ignored listing per whitelist
Mar  1 13:32:43.800: INFO: namespace e2e-tests-projected-x7kc5 deletion completed in 6.156866642s

• [SLOW TEST:10.331 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 13:32:43.800: INFO: >>> kubeConfig: /tmp/kubeconfig-210205575
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Mar  1 13:32:51.967: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Mar  1 13:32:51.971: INFO: Pod pod-with-poststart-http-hook still exists
Mar  1 13:32:53.971: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Mar  1 13:32:53.975: INFO: Pod pod-with-poststart-http-hook still exists
Mar  1 13:32:55.971: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Mar  1 13:32:56.050: INFO: Pod pod-with-poststart-http-hook still exists
Mar  1 13:32:57.971: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Mar  1 13:32:57.975: INFO: Pod pod-with-poststart-http-hook still exists
Mar  1 13:32:59.971: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Mar  1 13:33:00.051: INFO: Pod pod-with-poststart-http-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 13:33:00.051: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-lifecycle-hook-pjb9l" for this suite.
Mar  1 13:33:26.079: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 13:33:26.193: INFO: namespace: e2e-tests-container-lifecycle-hook-pjb9l, resource: bindings, ignored listing per whitelist
Mar  1 13:33:26.213: INFO: namespace e2e-tests-container-lifecycle-hook-pjb9l deletion completed in 26.148108958s

• [SLOW TEST:42.413 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when create a pod with lifecycle hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute poststart http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 13:33:26.213: INFO: >>> kubeConfig: /tmp/kubeconfig-210205575
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-97b347e7-3c26-11e9-a154-0a580a280202
STEP: Creating a pod to test consume secrets
Mar  1 13:33:26.324: INFO: Waiting up to 5m0s for pod "pod-secrets-97b4ba52-3c26-11e9-a154-0a580a280202" in namespace "e2e-tests-secrets-glvsc" to be "success or failure"
Mar  1 13:33:26.329: INFO: Pod "pod-secrets-97b4ba52-3c26-11e9-a154-0a580a280202": Phase="Pending", Reason="", readiness=false. Elapsed: 4.996487ms
Mar  1 13:33:28.333: INFO: Pod "pod-secrets-97b4ba52-3c26-11e9-a154-0a580a280202": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008459877s
STEP: Saw pod success
Mar  1 13:33:28.333: INFO: Pod "pod-secrets-97b4ba52-3c26-11e9-a154-0a580a280202" satisfied condition "success or failure"
Mar  1 13:33:28.336: INFO: Trying to get logs from node gke-conformance-default-pool-eca581b0-sqmc pod pod-secrets-97b4ba52-3c26-11e9-a154-0a580a280202 container secret-volume-test: <nil>
STEP: delete the pod
Mar  1 13:33:28.387: INFO: Waiting for pod pod-secrets-97b4ba52-3c26-11e9-a154-0a580a280202 to disappear
Mar  1 13:33:28.392: INFO: Pod pod-secrets-97b4ba52-3c26-11e9-a154-0a580a280202 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 13:33:28.392: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-glvsc" for this suite.
Mar  1 13:33:34.407: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 13:33:34.549: INFO: namespace: e2e-tests-secrets-glvsc, resource: bindings, ignored listing per whitelist
Mar  1 13:33:34.597: INFO: namespace e2e-tests-secrets-glvsc deletion completed in 6.200518106s

• [SLOW TEST:8.383 seconds]
[sig-storage] Secrets
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl label 
  should update the label on a resource  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 13:33:34.597: INFO: >>> kubeConfig: /tmp/kubeconfig-210205575
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Kubectl label
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1042
STEP: creating the pod
Mar  1 13:33:34.689: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-210205575 create -f - --namespace=e2e-tests-kubectl-f7h8b'
Mar  1 13:33:35.171: INFO: stderr: ""
Mar  1 13:33:35.171: INFO: stdout: "pod/pause created\n"
Mar  1 13:33:35.171: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [pause]
Mar  1 13:33:35.171: INFO: Waiting up to 5m0s for pod "pause" in namespace "e2e-tests-kubectl-f7h8b" to be "running and ready"
Mar  1 13:33:35.199: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 27.087724ms
Mar  1 13:33:37.202: INFO: Pod "pause": Phase="Running", Reason="", readiness=true. Elapsed: 2.030639244s
Mar  1 13:33:37.202: INFO: Pod "pause" satisfied condition "running and ready"
Mar  1 13:33:37.202: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [pause]
[It] should update the label on a resource  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: adding the label testing-label with value testing-label-value to a pod
Mar  1 13:33:37.202: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-210205575 label pods pause testing-label=testing-label-value --namespace=e2e-tests-kubectl-f7h8b'
Mar  1 13:33:37.295: INFO: stderr: ""
Mar  1 13:33:37.295: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod has the label testing-label with the value testing-label-value
Mar  1 13:33:37.295: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-210205575 get pod pause -L testing-label --namespace=e2e-tests-kubectl-f7h8b'
Mar  1 13:33:37.375: INFO: stderr: ""
Mar  1 13:33:37.375: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          2s    testing-label-value\n"
STEP: removing the label testing-label of a pod
Mar  1 13:33:37.375: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-210205575 label pods pause testing-label- --namespace=e2e-tests-kubectl-f7h8b'
Mar  1 13:33:37.471: INFO: stderr: ""
Mar  1 13:33:37.472: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod doesn't have the label testing-label
Mar  1 13:33:37.472: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-210205575 get pod pause -L testing-label --namespace=e2e-tests-kubectl-f7h8b'
Mar  1 13:33:37.554: INFO: stderr: ""
Mar  1 13:33:37.554: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          2s    \n"
[AfterEach] [k8s.io] Kubectl label
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1048
STEP: using delete to clean up resources
Mar  1 13:33:37.555: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-210205575 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-f7h8b'
Mar  1 13:33:37.652: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Mar  1 13:33:37.652: INFO: stdout: "pod \"pause\" force deleted\n"
Mar  1 13:33:37.652: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-210205575 get rc,svc -l name=pause --no-headers --namespace=e2e-tests-kubectl-f7h8b'
Mar  1 13:33:37.742: INFO: stderr: "No resources found.\n"
Mar  1 13:33:37.742: INFO: stdout: ""
Mar  1 13:33:37.742: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-210205575 get pods -l name=pause --namespace=e2e-tests-kubectl-f7h8b -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Mar  1 13:33:37.823: INFO: stderr: ""
Mar  1 13:33:37.823: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 13:33:37.824: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-f7h8b" for this suite.
Mar  1 13:33:43.846: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 13:33:44.000: INFO: namespace: e2e-tests-kubectl-f7h8b, resource: bindings, ignored listing per whitelist
Mar  1 13:33:44.016: INFO: namespace e2e-tests-kubectl-f7h8b deletion completed in 6.186749321s

• [SLOW TEST:9.419 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl label
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should update the label on a resource  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 13:33:44.016: INFO: >>> kubeConfig: /tmp/kubeconfig-210205575
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0666 on tmpfs
Mar  1 13:33:44.121: INFO: Waiting up to 5m0s for pod "pod-a2506ec4-3c26-11e9-a154-0a580a280202" in namespace "e2e-tests-emptydir-ld9sz" to be "success or failure"
Mar  1 13:33:44.127: INFO: Pod "pod-a2506ec4-3c26-11e9-a154-0a580a280202": Phase="Pending", Reason="", readiness=false. Elapsed: 5.907375ms
Mar  1 13:33:46.130: INFO: Pod "pod-a2506ec4-3c26-11e9-a154-0a580a280202": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009660193s
STEP: Saw pod success
Mar  1 13:33:46.130: INFO: Pod "pod-a2506ec4-3c26-11e9-a154-0a580a280202" satisfied condition "success or failure"
Mar  1 13:33:46.134: INFO: Trying to get logs from node gke-conformance-default-pool-eca581b0-sww9 pod pod-a2506ec4-3c26-11e9-a154-0a580a280202 container test-container: <nil>
STEP: delete the pod
Mar  1 13:33:46.163: INFO: Waiting for pod pod-a2506ec4-3c26-11e9-a154-0a580a280202 to disappear
Mar  1 13:33:46.167: INFO: Pod pod-a2506ec4-3c26-11e9-a154-0a580a280202 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 13:33:46.167: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-ld9sz" for this suite.
Mar  1 13:33:52.183: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 13:33:52.270: INFO: namespace: e2e-tests-emptydir-ld9sz, resource: bindings, ignored listing per whitelist
Mar  1 13:33:52.335: INFO: namespace e2e-tests-emptydir-ld9sz deletion completed in 6.164438418s

• [SLOW TEST:8.319 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[k8s.io] Pods 
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 13:33:52.335: INFO: >>> kubeConfig: /tmp/kubeconfig-210205575
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Mar  1 13:33:56.982: INFO: Successfully updated pod "pod-update-activedeadlineseconds-a746085e-3c26-11e9-a154-0a580a280202"
Mar  1 13:33:56.982: INFO: Waiting up to 5m0s for pod "pod-update-activedeadlineseconds-a746085e-3c26-11e9-a154-0a580a280202" in namespace "e2e-tests-pods-kdh4h" to be "terminated due to deadline exceeded"
Mar  1 13:33:56.985: INFO: Pod "pod-update-activedeadlineseconds-a746085e-3c26-11e9-a154-0a580a280202": Phase="Running", Reason="", readiness=true. Elapsed: 3.029682ms
Mar  1 13:33:58.988: INFO: Pod "pod-update-activedeadlineseconds-a746085e-3c26-11e9-a154-0a580a280202": Phase="Failed", Reason="DeadlineExceeded", readiness=false. Elapsed: 2.006437809s
Mar  1 13:33:58.988: INFO: Pod "pod-update-activedeadlineseconds-a746085e-3c26-11e9-a154-0a580a280202" satisfied condition "terminated due to deadline exceeded"
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 13:33:58.988: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-kdh4h" for this suite.
Mar  1 13:34:05.004: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 13:34:05.041: INFO: namespace: e2e-tests-pods-kdh4h, resource: bindings, ignored listing per whitelist
Mar  1 13:34:05.145: INFO: namespace e2e-tests-pods-kdh4h deletion completed in 6.152209032s

• [SLOW TEST:12.810 seconds]
[k8s.io] Pods
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 13:34:05.145: INFO: >>> kubeConfig: /tmp/kubeconfig-210205575
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test override command
Mar  1 13:34:05.252: INFO: Waiting up to 5m0s for pod "client-containers-aee92735-3c26-11e9-a154-0a580a280202" in namespace "e2e-tests-containers-5hklk" to be "success or failure"
Mar  1 13:34:05.258: INFO: Pod "client-containers-aee92735-3c26-11e9-a154-0a580a280202": Phase="Pending", Reason="", readiness=false. Elapsed: 5.6495ms
Mar  1 13:34:07.261: INFO: Pod "client-containers-aee92735-3c26-11e9-a154-0a580a280202": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009011749s
Mar  1 13:34:09.265: INFO: Pod "client-containers-aee92735-3c26-11e9-a154-0a580a280202": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012295635s
STEP: Saw pod success
Mar  1 13:34:09.265: INFO: Pod "client-containers-aee92735-3c26-11e9-a154-0a580a280202" satisfied condition "success or failure"
Mar  1 13:34:09.268: INFO: Trying to get logs from node gke-conformance-default-pool-eca581b0-czl4 pod client-containers-aee92735-3c26-11e9-a154-0a580a280202 container test-container: <nil>
STEP: delete the pod
Mar  1 13:34:09.289: INFO: Waiting for pod client-containers-aee92735-3c26-11e9-a154-0a580a280202 to disappear
Mar  1 13:34:09.293: INFO: Pod client-containers-aee92735-3c26-11e9-a154-0a580a280202 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 13:34:09.293: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-5hklk" for this suite.
Mar  1 13:34:15.308: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 13:34:15.343: INFO: namespace: e2e-tests-containers-5hklk, resource: bindings, ignored listing per whitelist
Mar  1 13:34:15.464: INFO: namespace e2e-tests-containers-5hklk deletion completed in 6.167111915s

• [SLOW TEST:10.319 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[k8s.io] Pods 
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 13:34:15.464: INFO: >>> kubeConfig: /tmp/kubeconfig-210205575
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Mar  1 13:34:20.108: INFO: Successfully updated pod "pod-update-b5107766-3c26-11e9-a154-0a580a280202"
STEP: verifying the updated pod is in kubernetes
Mar  1 13:34:20.118: INFO: Pod update OK
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 13:34:20.118: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-9cwfs" for this suite.
Mar  1 13:34:42.141: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 13:34:42.245: INFO: namespace: e2e-tests-pods-9cwfs, resource: bindings, ignored listing per whitelist
Mar  1 13:34:42.279: INFO: namespace e2e-tests-pods-9cwfs deletion completed in 22.151318908s

• [SLOW TEST:26.815 seconds]
[k8s.io] Pods
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 13:34:42.279: INFO: >>> kubeConfig: /tmp/kubeconfig-210205575
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
Mar  1 13:34:42.406: INFO: PodSpec: initContainers in spec.initContainers
Mar  1 13:35:24.694: INFO: init container has failed twice: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-init-c50f7dc8-3c26-11e9-a154-0a580a280202", GenerateName:"", Namespace:"e2e-tests-init-container-8bpg7", SelfLink:"/api/v1/namespaces/e2e-tests-init-container-8bpg7/pods/pod-init-c50f7dc8-3c26-11e9-a154-0a580a280202", UID:"c512d890-3c26-11e9-83c3-42010a800094", ResourceVersion:"3238", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63687044082, loc:(*time.Location)(0x6c43b60)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"406142146"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Initializers:(*v1.Initializers)(nil), Finalizers:[]string(nil), ClusterName:""}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"default-token-hmqhf", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(0xc421de2280), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil)}}}, InitContainers:[]v1.Container{v1.Container{Name:"init1", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/false"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-hmqhf", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}, v1.Container{Name:"init2", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/true"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-hmqhf", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, Containers:[]v1.Container{v1.Container{Name:"run1", Image:"k8s.gcr.io/pause:3.1", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}, Requests:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-hmqhf", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc421919388), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"gke-conformance-default-pool-eca581b0-sqmc", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc420c3a5a0), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc421919400)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc421919430)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc421919438), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil)}, Status:v1.PodStatus{Phase:"Pending", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63687044082, loc:(*time.Location)(0x6c43b60)}}, Reason:"ContainersNotInitialized", Message:"containers with incomplete status: [init1 init2]"}, v1.PodCondition{Type:"Ready", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63687044082, loc:(*time.Location)(0x6c43b60)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"ContainersReady", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63687044082, loc:(*time.Location)(0x6c43b60)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63687044082, loc:(*time.Location)(0x6c43b60)}}, Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"10.128.0.17", PodIP:"10.40.3.11", StartTime:(*v1.Time)(0xc4210dadc0), InitContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"init1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc420ad7f10)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc420ad7f80)}, Ready:false, RestartCount:3, Image:"busybox:1.29", ImageID:"docker-pullable://busybox@sha256:e004c2cc521c95383aebb1fb5893719aa7a8eae2e7a71f316a4410784edb00a9", ContainerID:"docker://80502b44642b8d2f8ae40acb1b70a30ea739dcdf0cb56c4e4effbf745292aa4c"}, v1.ContainerStatus{Name:"init2", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc4210dae00), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"docker.io/library/busybox:1.29", ImageID:"", ContainerID:""}}, ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"run1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc4210dade0), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"k8s.gcr.io/pause:3.1", ImageID:"", ContainerID:""}}, QOSClass:"Guaranteed"}}
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 13:35:24.694: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-init-container-8bpg7" for this suite.
Mar  1 13:35:46.713: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 13:35:46.913: INFO: namespace: e2e-tests-init-container-8bpg7, resource: bindings, ignored listing per whitelist
Mar  1 13:35:46.915: INFO: namespace e2e-tests-init-container-8bpg7 deletion completed in 22.212836574s

• [SLOW TEST:64.636 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 13:35:46.916: INFO: >>> kubeConfig: /tmp/kubeconfig-210205575
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-eb90435f-3c26-11e9-a154-0a580a280202
STEP: Creating a pod to test consume secrets
Mar  1 13:35:47.017: INFO: Waiting up to 5m0s for pod "pod-secrets-eb90e4f7-3c26-11e9-a154-0a580a280202" in namespace "e2e-tests-secrets-g6xg6" to be "success or failure"
Mar  1 13:35:47.022: INFO: Pod "pod-secrets-eb90e4f7-3c26-11e9-a154-0a580a280202": Phase="Pending", Reason="", readiness=false. Elapsed: 4.509132ms
Mar  1 13:35:49.026: INFO: Pod "pod-secrets-eb90e4f7-3c26-11e9-a154-0a580a280202": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00867132s
STEP: Saw pod success
Mar  1 13:35:49.026: INFO: Pod "pod-secrets-eb90e4f7-3c26-11e9-a154-0a580a280202" satisfied condition "success or failure"
Mar  1 13:35:49.029: INFO: Trying to get logs from node gke-conformance-default-pool-eca581b0-czl4 pod pod-secrets-eb90e4f7-3c26-11e9-a154-0a580a280202 container secret-volume-test: <nil>
STEP: delete the pod
Mar  1 13:35:49.055: INFO: Waiting for pod pod-secrets-eb90e4f7-3c26-11e9-a154-0a580a280202 to disappear
Mar  1 13:35:49.062: INFO: Pod pod-secrets-eb90e4f7-3c26-11e9-a154-0a580a280202 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 13:35:49.062: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-g6xg6" for this suite.
Mar  1 13:35:55.080: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 13:35:55.178: INFO: namespace: e2e-tests-secrets-g6xg6, resource: bindings, ignored listing per whitelist
Mar  1 13:35:55.241: INFO: namespace e2e-tests-secrets-g6xg6 deletion completed in 6.17425825s

• [SLOW TEST:8.325 seconds]
[sig-storage] Secrets
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Downward API 
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 13:35:55.241: INFO: >>> kubeConfig: /tmp/kubeconfig-210205575
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Mar  1 13:35:55.366: INFO: Waiting up to 5m0s for pod "downward-api-f088e768-3c26-11e9-a154-0a580a280202" in namespace "e2e-tests-downward-api-bvwv7" to be "success or failure"
Mar  1 13:35:55.371: INFO: Pod "downward-api-f088e768-3c26-11e9-a154-0a580a280202": Phase="Pending", Reason="", readiness=false. Elapsed: 5.521694ms
Mar  1 13:35:57.377: INFO: Pod "downward-api-f088e768-3c26-11e9-a154-0a580a280202": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.011793948s
STEP: Saw pod success
Mar  1 13:35:57.378: INFO: Pod "downward-api-f088e768-3c26-11e9-a154-0a580a280202" satisfied condition "success or failure"
Mar  1 13:35:57.386: INFO: Trying to get logs from node gke-conformance-default-pool-eca581b0-sww9 pod downward-api-f088e768-3c26-11e9-a154-0a580a280202 container dapi-container: <nil>
STEP: delete the pod
Mar  1 13:35:57.415: INFO: Waiting for pod downward-api-f088e768-3c26-11e9-a154-0a580a280202 to disappear
Mar  1 13:35:57.418: INFO: Pod downward-api-f088e768-3c26-11e9-a154-0a580a280202 no longer exists
[AfterEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 13:35:57.418: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-bvwv7" for this suite.
Mar  1 13:36:03.434: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 13:36:03.492: INFO: namespace: e2e-tests-downward-api-bvwv7, resource: bindings, ignored listing per whitelist
Mar  1 13:36:03.589: INFO: namespace e2e-tests-downward-api-bvwv7 deletion completed in 6.166459597s

• [SLOW TEST:8.348 seconds]
[sig-api-machinery] Downward API
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] HostPath 
  should give a volume the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 13:36:03.589: INFO: >>> kubeConfig: /tmp/kubeconfig-210205575
STEP: Building a namespace api object, basename hostpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:37
[It] should give a volume the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test hostPath mode
Mar  1 13:36:03.699: INFO: Waiting up to 5m0s for pod "pod-host-path-test" in namespace "e2e-tests-hostpath-mgjqm" to be "success or failure"
Mar  1 13:36:03.705: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 5.998592ms
Mar  1 13:36:05.708: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009708135s
Mar  1 13:36:07.713: INFO: Pod "pod-host-path-test": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014093814s
STEP: Saw pod success
Mar  1 13:36:07.713: INFO: Pod "pod-host-path-test" satisfied condition "success or failure"
Mar  1 13:36:07.719: INFO: Trying to get logs from node gke-conformance-default-pool-eca581b0-czl4 pod pod-host-path-test container test-container-1: <nil>
STEP: delete the pod
Mar  1 13:36:07.746: INFO: Waiting for pod pod-host-path-test to disappear
Mar  1 13:36:07.754: INFO: Pod pod-host-path-test no longer exists
[AfterEach] [sig-storage] HostPath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 13:36:07.754: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-hostpath-mgjqm" for this suite.
Mar  1 13:36:13.775: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 13:36:13.863: INFO: namespace: e2e-tests-hostpath-mgjqm, resource: bindings, ignored listing per whitelist
Mar  1 13:36:13.972: INFO: namespace e2e-tests-hostpath-mgjqm deletion completed in 6.212595203s

• [SLOW TEST:10.383 seconds]
[sig-storage] HostPath
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:34
  should give a volume the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-api-machinery] Garbage collector 
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 13:36:13.972: INFO: >>> kubeConfig: /tmp/kubeconfig-210205575
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the rc1
STEP: create the rc2
STEP: set half of pods created by rc simpletest-rc-to-be-deleted to have rc simpletest-rc-to-stay as owner as well
STEP: delete the rc simpletest-rc-to-be-deleted
STEP: wait for the rc to be deleted
STEP: Gathering metrics
W0301 13:36:24.305345      19 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Mar  1 13:36:24.305: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 13:36:24.305: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-tw7q2" for this suite.
Mar  1 13:36:32.321: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 13:36:32.434: INFO: namespace: e2e-tests-gc-tw7q2, resource: bindings, ignored listing per whitelist
Mar  1 13:36:32.466: INFO: namespace e2e-tests-gc-tw7q2 deletion completed in 8.157907638s

• [SLOW TEST:18.494 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 13:36:32.466: INFO: >>> kubeConfig: /tmp/kubeconfig-210205575
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0777 on node default medium
Mar  1 13:36:32.569: INFO: Waiting up to 5m0s for pod "pod-06b70997-3c27-11e9-a154-0a580a280202" in namespace "e2e-tests-emptydir-r6qrl" to be "success or failure"
Mar  1 13:36:32.585: INFO: Pod "pod-06b70997-3c27-11e9-a154-0a580a280202": Phase="Pending", Reason="", readiness=false. Elapsed: 16.320435ms
Mar  1 13:36:34.588: INFO: Pod "pod-06b70997-3c27-11e9-a154-0a580a280202": Phase="Pending", Reason="", readiness=false. Elapsed: 2.019544832s
Mar  1 13:36:36.593: INFO: Pod "pod-06b70997-3c27-11e9-a154-0a580a280202": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.023700532s
STEP: Saw pod success
Mar  1 13:36:36.593: INFO: Pod "pod-06b70997-3c27-11e9-a154-0a580a280202" satisfied condition "success or failure"
Mar  1 13:36:36.596: INFO: Trying to get logs from node gke-conformance-default-pool-eca581b0-sww9 pod pod-06b70997-3c27-11e9-a154-0a580a280202 container test-container: <nil>
STEP: delete the pod
Mar  1 13:36:36.617: INFO: Waiting for pod pod-06b70997-3c27-11e9-a154-0a580a280202 to disappear
Mar  1 13:36:36.622: INFO: Pod pod-06b70997-3c27-11e9-a154-0a580a280202 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 13:36:36.622: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-r6qrl" for this suite.
Mar  1 13:36:42.634: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 13:36:42.812: INFO: namespace: e2e-tests-emptydir-r6qrl, resource: bindings, ignored listing per whitelist
Mar  1 13:36:42.862: INFO: namespace e2e-tests-emptydir-r6qrl deletion completed in 6.236779987s

• [SLOW TEST:10.395 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl expose 
  should create services for rc  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 13:36:42.862: INFO: >>> kubeConfig: /tmp/kubeconfig-210205575
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should create services for rc  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating Redis RC
Mar  1 13:36:42.960: INFO: namespace e2e-tests-kubectl-xfqrr
Mar  1 13:36:42.960: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-210205575 create -f - --namespace=e2e-tests-kubectl-xfqrr'
Mar  1 13:36:43.137: INFO: stderr: ""
Mar  1 13:36:43.137: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
Mar  1 13:36:44.141: INFO: Selector matched 1 pods for map[app:redis]
Mar  1 13:36:44.141: INFO: Found 0 / 1
Mar  1 13:36:45.143: INFO: Selector matched 1 pods for map[app:redis]
Mar  1 13:36:45.143: INFO: Found 0 / 1
Mar  1 13:36:46.144: INFO: Selector matched 1 pods for map[app:redis]
Mar  1 13:36:46.144: INFO: Found 0 / 1
Mar  1 13:36:47.141: INFO: Selector matched 1 pods for map[app:redis]
Mar  1 13:36:47.141: INFO: Found 1 / 1
Mar  1 13:36:47.141: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Mar  1 13:36:47.144: INFO: Selector matched 1 pods for map[app:redis]
Mar  1 13:36:47.144: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Mar  1 13:36:47.144: INFO: wait on redis-master startup in e2e-tests-kubectl-xfqrr 
Mar  1 13:36:47.145: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-210205575 logs redis-master-9nx5k redis-master --namespace=e2e-tests-kubectl-xfqrr'
Mar  1 13:36:47.243: INFO: stderr: ""
Mar  1 13:36:47.243: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 01 Mar 13:36:46.234 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 01 Mar 13:36:46.235 # Server started, Redis version 3.2.12\n1:M 01 Mar 13:36:46.235 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 01 Mar 13:36:46.235 * The server is now ready to accept connections on port 6379\n"
STEP: exposing RC
Mar  1 13:36:47.243: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-210205575 expose rc redis-master --name=rm2 --port=1234 --target-port=6379 --namespace=e2e-tests-kubectl-xfqrr'
Mar  1 13:36:47.353: INFO: stderr: ""
Mar  1 13:36:47.353: INFO: stdout: "service/rm2 exposed\n"
Mar  1 13:36:47.358: INFO: Service rm2 in namespace e2e-tests-kubectl-xfqrr found.
STEP: exposing service
Mar  1 13:36:49.366: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-210205575 expose service rm2 --name=rm3 --port=2345 --target-port=6379 --namespace=e2e-tests-kubectl-xfqrr'
Mar  1 13:36:49.470: INFO: stderr: ""
Mar  1 13:36:49.470: INFO: stdout: "service/rm3 exposed\n"
Mar  1 13:36:49.478: INFO: Service rm3 in namespace e2e-tests-kubectl-xfqrr found.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 13:36:51.485: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-xfqrr" for this suite.
Mar  1 13:37:13.502: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 13:37:13.649: INFO: namespace: e2e-tests-kubectl-xfqrr, resource: bindings, ignored listing per whitelist
Mar  1 13:37:13.711: INFO: namespace e2e-tests-kubectl-xfqrr deletion completed in 22.222382704s

• [SLOW TEST:30.850 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl expose
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create services for rc  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 13:37:13.711: INFO: >>> kubeConfig: /tmp/kubeconfig-210205575
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0777 on tmpfs
Mar  1 13:37:13.833: INFO: Waiting up to 5m0s for pod "pod-1f4f8a5f-3c27-11e9-a154-0a580a280202" in namespace "e2e-tests-emptydir-r8mnj" to be "success or failure"
Mar  1 13:37:13.847: INFO: Pod "pod-1f4f8a5f-3c27-11e9-a154-0a580a280202": Phase="Pending", Reason="", readiness=false. Elapsed: 14.612248ms
Mar  1 13:37:15.851: INFO: Pod "pod-1f4f8a5f-3c27-11e9-a154-0a580a280202": Phase="Pending", Reason="", readiness=false. Elapsed: 2.018784506s
Mar  1 13:37:17.858: INFO: Pod "pod-1f4f8a5f-3c27-11e9-a154-0a580a280202": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.025080379s
STEP: Saw pod success
Mar  1 13:37:17.858: INFO: Pod "pod-1f4f8a5f-3c27-11e9-a154-0a580a280202" satisfied condition "success or failure"
Mar  1 13:37:17.863: INFO: Trying to get logs from node gke-conformance-default-pool-eca581b0-czl4 pod pod-1f4f8a5f-3c27-11e9-a154-0a580a280202 container test-container: <nil>
STEP: delete the pod
Mar  1 13:37:17.901: INFO: Waiting for pod pod-1f4f8a5f-3c27-11e9-a154-0a580a280202 to disappear
Mar  1 13:37:17.913: INFO: Pod pod-1f4f8a5f-3c27-11e9-a154-0a580a280202 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 13:37:17.913: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-r8mnj" for this suite.
Mar  1 13:37:23.940: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 13:37:23.994: INFO: namespace: e2e-tests-emptydir-r8mnj, resource: bindings, ignored listing per whitelist
Mar  1 13:37:24.073: INFO: namespace e2e-tests-emptydir-r8mnj deletion completed in 6.154338161s

• [SLOW TEST:10.362 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 13:37:24.074: INFO: >>> kubeConfig: /tmp/kubeconfig-210205575
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-257a2801-3c27-11e9-a154-0a580a280202
STEP: Creating a pod to test consume secrets
Mar  1 13:37:24.180: INFO: Waiting up to 5m0s for pod "pod-secrets-257ae5cb-3c27-11e9-a154-0a580a280202" in namespace "e2e-tests-secrets-zzhm2" to be "success or failure"
Mar  1 13:37:24.187: INFO: Pod "pod-secrets-257ae5cb-3c27-11e9-a154-0a580a280202": Phase="Pending", Reason="", readiness=false. Elapsed: 6.678909ms
Mar  1 13:37:26.191: INFO: Pod "pod-secrets-257ae5cb-3c27-11e9-a154-0a580a280202": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010711145s
Mar  1 13:37:28.194: INFO: Pod "pod-secrets-257ae5cb-3c27-11e9-a154-0a580a280202": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014145546s
STEP: Saw pod success
Mar  1 13:37:28.194: INFO: Pod "pod-secrets-257ae5cb-3c27-11e9-a154-0a580a280202" satisfied condition "success or failure"
Mar  1 13:37:28.198: INFO: Trying to get logs from node gke-conformance-default-pool-eca581b0-sww9 pod pod-secrets-257ae5cb-3c27-11e9-a154-0a580a280202 container secret-volume-test: <nil>
STEP: delete the pod
Mar  1 13:37:28.219: INFO: Waiting for pod pod-secrets-257ae5cb-3c27-11e9-a154-0a580a280202 to disappear
Mar  1 13:37:28.223: INFO: Pod pod-secrets-257ae5cb-3c27-11e9-a154-0a580a280202 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 13:37:28.223: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-zzhm2" for this suite.
Mar  1 13:37:34.240: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 13:37:34.298: INFO: namespace: e2e-tests-secrets-zzhm2, resource: bindings, ignored listing per whitelist
Mar  1 13:37:34.363: INFO: namespace e2e-tests-secrets-zzhm2 deletion completed in 6.134391105s

• [SLOW TEST:10.289 seconds]
[sig-storage] Secrets
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 13:37:34.363: INFO: >>> kubeConfig: /tmp/kubeconfig-210205575
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-2b9cc63a-3c27-11e9-a154-0a580a280202
STEP: Creating a pod to test consume configMaps
Mar  1 13:37:34.472: INFO: Waiting up to 5m0s for pod "pod-configmaps-2b9d7c1f-3c27-11e9-a154-0a580a280202" in namespace "e2e-tests-configmap-wgjs9" to be "success or failure"
Mar  1 13:37:34.477: INFO: Pod "pod-configmaps-2b9d7c1f-3c27-11e9-a154-0a580a280202": Phase="Pending", Reason="", readiness=false. Elapsed: 4.922082ms
Mar  1 13:37:36.482: INFO: Pod "pod-configmaps-2b9d7c1f-3c27-11e9-a154-0a580a280202": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010015089s
Mar  1 13:37:38.486: INFO: Pod "pod-configmaps-2b9d7c1f-3c27-11e9-a154-0a580a280202": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014238041s
STEP: Saw pod success
Mar  1 13:37:38.486: INFO: Pod "pod-configmaps-2b9d7c1f-3c27-11e9-a154-0a580a280202" satisfied condition "success or failure"
Mar  1 13:37:38.489: INFO: Trying to get logs from node gke-conformance-default-pool-eca581b0-sqmc pod pod-configmaps-2b9d7c1f-3c27-11e9-a154-0a580a280202 container configmap-volume-test: <nil>
STEP: delete the pod
Mar  1 13:37:38.516: INFO: Waiting for pod pod-configmaps-2b9d7c1f-3c27-11e9-a154-0a580a280202 to disappear
Mar  1 13:37:38.520: INFO: Pod pod-configmaps-2b9d7c1f-3c27-11e9-a154-0a580a280202 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 13:37:38.520: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-wgjs9" for this suite.
Mar  1 13:37:44.536: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 13:37:44.611: INFO: namespace: e2e-tests-configmap-wgjs9, resource: bindings, ignored listing per whitelist
Mar  1 13:37:44.676: INFO: namespace e2e-tests-configmap-wgjs9 deletion completed in 6.151306468s

• [SLOW TEST:10.313 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-api-machinery] ConfigMap 
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 13:37:44.676: INFO: >>> kubeConfig: /tmp/kubeconfig-210205575
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap e2e-tests-configmap-nx8xs/configmap-test-31c21aaf-3c27-11e9-a154-0a580a280202
STEP: Creating a pod to test consume configMaps
Mar  1 13:37:44.789: INFO: Waiting up to 5m0s for pod "pod-configmaps-31c2c773-3c27-11e9-a154-0a580a280202" in namespace "e2e-tests-configmap-nx8xs" to be "success or failure"
Mar  1 13:37:44.797: INFO: Pod "pod-configmaps-31c2c773-3c27-11e9-a154-0a580a280202": Phase="Pending", Reason="", readiness=false. Elapsed: 7.986918ms
Mar  1 13:37:46.800: INFO: Pod "pod-configmaps-31c2c773-3c27-11e9-a154-0a580a280202": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011220527s
Mar  1 13:37:48.804: INFO: Pod "pod-configmaps-31c2c773-3c27-11e9-a154-0a580a280202": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.015095089s
STEP: Saw pod success
Mar  1 13:37:48.804: INFO: Pod "pod-configmaps-31c2c773-3c27-11e9-a154-0a580a280202" satisfied condition "success or failure"
Mar  1 13:37:48.807: INFO: Trying to get logs from node gke-conformance-default-pool-eca581b0-czl4 pod pod-configmaps-31c2c773-3c27-11e9-a154-0a580a280202 container env-test: <nil>
STEP: delete the pod
Mar  1 13:37:48.830: INFO: Waiting for pod pod-configmaps-31c2c773-3c27-11e9-a154-0a580a280202 to disappear
Mar  1 13:37:48.835: INFO: Pod pod-configmaps-31c2c773-3c27-11e9-a154-0a580a280202 no longer exists
[AfterEach] [sig-api-machinery] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 13:37:48.835: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-nx8xs" for this suite.
Mar  1 13:37:54.849: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 13:37:54.944: INFO: namespace: e2e-tests-configmap-nx8xs, resource: bindings, ignored listing per whitelist
Mar  1 13:37:54.958: INFO: namespace e2e-tests-configmap-nx8xs deletion completed in 6.119063666s

• [SLOW TEST:10.283 seconds]
[sig-api-machinery] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:30
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 13:37:54.959: INFO: >>> kubeConfig: /tmp/kubeconfig-210205575
STEP: Building a namespace api object, basename replicaset
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Mar  1 13:37:55.052: INFO: Creating ReplicaSet my-hostname-basic-37e305a4-3c27-11e9-a154-0a580a280202
Mar  1 13:37:55.064: INFO: Pod name my-hostname-basic-37e305a4-3c27-11e9-a154-0a580a280202: Found 0 pods out of 1
Mar  1 13:38:00.090: INFO: Pod name my-hostname-basic-37e305a4-3c27-11e9-a154-0a580a280202: Found 1 pods out of 1
Mar  1 13:38:00.090: INFO: Ensuring a pod for ReplicaSet "my-hostname-basic-37e305a4-3c27-11e9-a154-0a580a280202" is running
Mar  1 13:38:00.096: INFO: Pod "my-hostname-basic-37e305a4-3c27-11e9-a154-0a580a280202-8l5dv" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-03-01 13:37:55 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-03-01 13:37:56 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-03-01 13:37:56 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-03-01 13:37:55 +0000 UTC Reason: Message:}])
Mar  1 13:38:00.096: INFO: Trying to dial the pod
Mar  1 13:38:05.397: INFO: Controller my-hostname-basic-37e305a4-3c27-11e9-a154-0a580a280202: Got expected result from replica 1 [my-hostname-basic-37e305a4-3c27-11e9-a154-0a580a280202-8l5dv]: "my-hostname-basic-37e305a4-3c27-11e9-a154-0a580a280202-8l5dv", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 13:38:05.397: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-replicaset-h6zn5" for this suite.
Mar  1 13:38:11.705: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 13:38:11.758: INFO: namespace: e2e-tests-replicaset-h6zn5, resource: bindings, ignored listing per whitelist
Mar  1 13:38:11.829: INFO: namespace e2e-tests-replicaset-h6zn5 deletion completed in 6.331086951s

• [SLOW TEST:16.870 seconds]
[sig-apps] ReplicaSet
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] Projected 
  should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 13:38:11.829: INFO: >>> kubeConfig: /tmp/kubeconfig-210205575
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Mar  1 13:38:11.932: INFO: Waiting up to 5m0s for pod "downwardapi-volume-41f129a7-3c27-11e9-a154-0a580a280202" in namespace "e2e-tests-projected-hsc4q" to be "success or failure"
Mar  1 13:38:11.939: INFO: Pod "downwardapi-volume-41f129a7-3c27-11e9-a154-0a580a280202": Phase="Pending", Reason="", readiness=false. Elapsed: 6.537791ms
Mar  1 13:38:13.943: INFO: Pod "downwardapi-volume-41f129a7-3c27-11e9-a154-0a580a280202": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.01057624s
STEP: Saw pod success
Mar  1 13:38:13.943: INFO: Pod "downwardapi-volume-41f129a7-3c27-11e9-a154-0a580a280202" satisfied condition "success or failure"
Mar  1 13:38:13.946: INFO: Trying to get logs from node gke-conformance-default-pool-eca581b0-sqmc pod downwardapi-volume-41f129a7-3c27-11e9-a154-0a580a280202 container client-container: <nil>
STEP: delete the pod
Mar  1 13:38:13.970: INFO: Waiting for pod downwardapi-volume-41f129a7-3c27-11e9-a154-0a580a280202 to disappear
Mar  1 13:38:13.975: INFO: Pod downwardapi-volume-41f129a7-3c27-11e9-a154-0a580a280202 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 13:38:13.975: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-hsc4q" for this suite.
Mar  1 13:38:19.989: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 13:38:20.095: INFO: namespace: e2e-tests-projected-hsc4q, resource: bindings, ignored listing per whitelist
Mar  1 13:38:20.123: INFO: namespace e2e-tests-projected-hsc4q deletion completed in 6.144394046s

• [SLOW TEST:8.294 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 13:38:20.123: INFO: >>> kubeConfig: /tmp/kubeconfig-210205575
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-map-46e338b0-3c27-11e9-a154-0a580a280202
STEP: Creating a pod to test consume configMaps
Mar  1 13:38:20.231: INFO: Waiting up to 5m0s for pod "pod-configmaps-46e3dfdd-3c27-11e9-a154-0a580a280202" in namespace "e2e-tests-configmap-mxvx5" to be "success or failure"
Mar  1 13:38:20.237: INFO: Pod "pod-configmaps-46e3dfdd-3c27-11e9-a154-0a580a280202": Phase="Pending", Reason="", readiness=false. Elapsed: 5.087565ms
Mar  1 13:38:22.240: INFO: Pod "pod-configmaps-46e3dfdd-3c27-11e9-a154-0a580a280202": Phase="Running", Reason="", readiness=true. Elapsed: 2.008688855s
Mar  1 13:38:24.245: INFO: Pod "pod-configmaps-46e3dfdd-3c27-11e9-a154-0a580a280202": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013023414s
STEP: Saw pod success
Mar  1 13:38:24.245: INFO: Pod "pod-configmaps-46e3dfdd-3c27-11e9-a154-0a580a280202" satisfied condition "success or failure"
Mar  1 13:38:24.248: INFO: Trying to get logs from node gke-conformance-default-pool-eca581b0-czl4 pod pod-configmaps-46e3dfdd-3c27-11e9-a154-0a580a280202 container configmap-volume-test: <nil>
STEP: delete the pod
Mar  1 13:38:24.272: INFO: Waiting for pod pod-configmaps-46e3dfdd-3c27-11e9-a154-0a580a280202 to disappear
Mar  1 13:38:24.277: INFO: Pod pod-configmaps-46e3dfdd-3c27-11e9-a154-0a580a280202 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 13:38:24.277: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-mxvx5" for this suite.
Mar  1 13:38:30.293: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 13:38:30.352: INFO: namespace: e2e-tests-configmap-mxvx5, resource: bindings, ignored listing per whitelist
Mar  1 13:38:30.407: INFO: namespace e2e-tests-configmap-mxvx5 deletion completed in 6.126302482s

• [SLOW TEST:10.284 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 13:38:30.407: INFO: >>> kubeConfig: /tmp/kubeconfig-210205575
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Mar  1 13:38:30.530: INFO: Waiting up to 5m0s for pod "downwardapi-volume-4d0620a4-3c27-11e9-a154-0a580a280202" in namespace "e2e-tests-projected-dkg4b" to be "success or failure"
Mar  1 13:38:30.541: INFO: Pod "downwardapi-volume-4d0620a4-3c27-11e9-a154-0a580a280202": Phase="Pending", Reason="", readiness=false. Elapsed: 11.278759ms
Mar  1 13:38:32.546: INFO: Pod "downwardapi-volume-4d0620a4-3c27-11e9-a154-0a580a280202": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015567305s
Mar  1 13:38:34.550: INFO: Pod "downwardapi-volume-4d0620a4-3c27-11e9-a154-0a580a280202": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.019433548s
STEP: Saw pod success
Mar  1 13:38:34.550: INFO: Pod "downwardapi-volume-4d0620a4-3c27-11e9-a154-0a580a280202" satisfied condition "success or failure"
Mar  1 13:38:34.553: INFO: Trying to get logs from node gke-conformance-default-pool-eca581b0-czl4 pod downwardapi-volume-4d0620a4-3c27-11e9-a154-0a580a280202 container client-container: <nil>
STEP: delete the pod
Mar  1 13:38:34.580: INFO: Waiting for pod downwardapi-volume-4d0620a4-3c27-11e9-a154-0a580a280202 to disappear
Mar  1 13:38:34.583: INFO: Pod downwardapi-volume-4d0620a4-3c27-11e9-a154-0a580a280202 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 13:38:34.583: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-dkg4b" for this suite.
Mar  1 13:38:40.597: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 13:38:40.729: INFO: namespace: e2e-tests-projected-dkg4b, resource: bindings, ignored listing per whitelist
Mar  1 13:38:40.825: INFO: namespace e2e-tests-projected-dkg4b deletion completed in 6.237858816s

• [SLOW TEST:10.418 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl describe 
  should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 13:38:40.825: INFO: >>> kubeConfig: /tmp/kubeconfig-210205575
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Mar  1 13:38:40.910: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-210205575 version --client'
Mar  1 13:38:40.978: INFO: stderr: ""
Mar  1 13:38:40.978: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"12\", GitVersion:\"v1.12.1\", GitCommit:\"4ed3216f3ec431b140b1d899130a69fc671678f4\", GitTreeState:\"clean\", BuildDate:\"2018-10-05T16:46:06Z\", GoVersion:\"go1.10.4\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
Mar  1 13:38:40.982: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-210205575 create -f - --namespace=e2e-tests-kubectl-86n92'
Mar  1 13:38:41.228: INFO: stderr: ""
Mar  1 13:38:41.228: INFO: stdout: "replicationcontroller/redis-master created\n"
Mar  1 13:38:41.228: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-210205575 create -f - --namespace=e2e-tests-kubectl-86n92'
Mar  1 13:38:41.435: INFO: stderr: ""
Mar  1 13:38:41.435: INFO: stdout: "service/redis-master created\n"
STEP: Waiting for Redis master to start.
Mar  1 13:38:42.439: INFO: Selector matched 1 pods for map[app:redis]
Mar  1 13:38:42.439: INFO: Found 0 / 1
Mar  1 13:38:43.439: INFO: Selector matched 1 pods for map[app:redis]
Mar  1 13:38:43.439: INFO: Found 1 / 1
Mar  1 13:38:43.439: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Mar  1 13:38:43.443: INFO: Selector matched 1 pods for map[app:redis]
Mar  1 13:38:43.443: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Mar  1 13:38:43.443: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-210205575 describe pod redis-master-8gp7n --namespace=e2e-tests-kubectl-86n92'
Mar  1 13:38:43.540: INFO: stderr: ""
Mar  1 13:38:43.540: INFO: stdout: "Name:               redis-master-8gp7n\nNamespace:          e2e-tests-kubectl-86n92\nPriority:           0\nPriorityClassName:  <none>\nNode:               gke-conformance-default-pool-eca581b0-sqmc/10.128.0.17\nStart Time:         Fri, 01 Mar 2019 13:38:41 +0000\nLabels:             app=redis\n                    role=master\nAnnotations:        <none>\nStatus:             Running\nIP:                 10.40.3.18\nControlled By:      ReplicationController/redis-master\nContainers:\n  redis-master:\n    Container ID:   docker://b6f20eb3a7e7b52b778038a2641a0a6384197dcb7cbce3637b3f3819c9e96d01\n    Image:          gcr.io/kubernetes-e2e-test-images/redis:1.0\n    Image ID:       docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830\n    Port:           6379/TCP\n    Host Port:      0/TCP\n    State:          Running\n      Started:      Fri, 01 Mar 2019 13:38:42 +0000\n    Ready:          True\n    Restart Count:  0\n    Environment:    <none>\n    Mounts:\n      /var/run/secrets/kubernetes.io/serviceaccount from default-token-h7skl (ro)\nConditions:\n  Type              Status\n  Initialized       True \n  Ready             True \n  ContainersReady   True \n  PodScheduled      True \nVolumes:\n  default-token-h7skl:\n    Type:        Secret (a volume populated by a Secret)\n    SecretName:  default-token-h7skl\n    Optional:    false\nQoS Class:       BestEffort\nNode-Selectors:  <none>\nTolerations:     node.kubernetes.io/not-ready:NoExecute for 300s\n                 node.kubernetes.io/unreachable:NoExecute for 300s\nEvents:\n  Type    Reason     Age   From                                                 Message\n  ----    ------     ----  ----                                                 -------\n  Normal  Scheduled  2s    default-scheduler                                    Successfully assigned e2e-tests-kubectl-86n92/redis-master-8gp7n to gke-conformance-default-pool-eca581b0-sqmc\n  Normal  Pulled     1s    kubelet, gke-conformance-default-pool-eca581b0-sqmc  Container image \"gcr.io/kubernetes-e2e-test-images/redis:1.0\" already present on machine\n  Normal  Created    1s    kubelet, gke-conformance-default-pool-eca581b0-sqmc  Created container\n  Normal  Started    1s    kubelet, gke-conformance-default-pool-eca581b0-sqmc  Started container\n"
Mar  1 13:38:43.540: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-210205575 describe rc redis-master --namespace=e2e-tests-kubectl-86n92'
Mar  1 13:38:43.643: INFO: stderr: ""
Mar  1 13:38:43.643: INFO: stdout: "Name:         redis-master\nNamespace:    e2e-tests-kubectl-86n92\nSelector:     app=redis,role=master\nLabels:       app=redis\n              role=master\nAnnotations:  <none>\nReplicas:     1 current / 1 desired\nPods Status:  1 Running / 0 Waiting / 0 Succeeded / 0 Failed\nPod Template:\n  Labels:  app=redis\n           role=master\n  Containers:\n   redis-master:\n    Image:        gcr.io/kubernetes-e2e-test-images/redis:1.0\n    Port:         6379/TCP\n    Host Port:    0/TCP\n    Environment:  <none>\n    Mounts:       <none>\n  Volumes:        <none>\nEvents:\n  Type    Reason            Age   From                    Message\n  ----    ------            ----  ----                    -------\n  Normal  SuccessfulCreate  2s    replication-controller  Created pod: redis-master-8gp7n\n"
Mar  1 13:38:43.643: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-210205575 describe service redis-master --namespace=e2e-tests-kubectl-86n92'
Mar  1 13:38:43.742: INFO: stderr: ""
Mar  1 13:38:43.742: INFO: stdout: "Name:              redis-master\nNamespace:         e2e-tests-kubectl-86n92\nLabels:            app=redis\n                   role=master\nAnnotations:       <none>\nSelector:          app=redis,role=master\nType:              ClusterIP\nIP:                10.43.252.248\nPort:              <unset>  6379/TCP\nTargetPort:        redis-server/TCP\nEndpoints:         10.40.3.18:6379\nSession Affinity:  None\nEvents:            <none>\n"
Mar  1 13:38:43.747: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-210205575 describe node gke-conformance-default-pool-eca581b0-00fq'
Mar  1 13:38:43.891: INFO: stderr: ""
Mar  1 13:38:43.891: INFO: stdout: "Name:               gke-conformance-default-pool-eca581b0-00fq\nRoles:              <none>\nLabels:             beta.kubernetes.io/arch=amd64\n                    beta.kubernetes.io/fluentd-ds-ready=true\n                    beta.kubernetes.io/instance-type=n1-standard-4\n                    beta.kubernetes.io/os=linux\n                    cloud.google.com/gke-nodepool=default-pool\n                    cloud.google.com/gke-os-distribution=cos\n                    failure-domain.beta.kubernetes.io/region=us-central1\n                    failure-domain.beta.kubernetes.io/zone=us-central1-a\n                    kubernetes.io/hostname=gke-conformance-default-pool-eca581b0-00fq\nAnnotations:        container.googleapis.com/instance_id: 1085430094359727895\n                    node.alpha.kubernetes.io/ttl: 0\n                    volumes.kubernetes.io/controller-managed-attach-detach: true\nCreationTimestamp:  Fri, 01 Mar 2019 13:23:40 +0000\nTaints:             <none>\nUnschedulable:      false\nConditions:\n  Type                          Status  LastHeartbeatTime                 LastTransitionTime                Reason                       Message\n  ----                          ------  -----------------                 ------------------                ------                       -------\n  FrequentDockerRestart         False   Fri, 01 Mar 2019 13:38:42 +0000   Fri, 01 Mar 2019 13:27:33 +0000   FrequentDockerRestart        docker is functioning properly\n  FrequentContainerdRestart     False   Fri, 01 Mar 2019 13:38:42 +0000   Fri, 01 Mar 2019 13:27:34 +0000   FrequentContainerdRestart    containerd is functioning properly\n  CorruptDockerOverlay2         False   Fri, 01 Mar 2019 13:38:42 +0000   Fri, 01 Mar 2019 13:27:32 +0000   CorruptDockerOverlay2        docker overlay2 is functioning properly\n  KernelDeadlock                False   Fri, 01 Mar 2019 13:38:42 +0000   Fri, 01 Mar 2019 13:22:31 +0000   KernelHasNoDeadlock          kernel has no deadlock\n  ReadonlyFilesystem            False   Fri, 01 Mar 2019 13:38:42 +0000   Fri, 01 Mar 2019 13:22:31 +0000   FilesystemIsNotReadOnly      Filesystem is not read-only\n  FrequentUnregisterNetDevice   False   Fri, 01 Mar 2019 13:38:42 +0000   Fri, 01 Mar 2019 13:27:32 +0000   UnregisterNetDevice          node is functioning properly\n  FrequentKubeletRestart        False   Fri, 01 Mar 2019 13:38:42 +0000   Fri, 01 Mar 2019 13:27:32 +0000   FrequentKubeletRestart       kubelet is functioning properly\n  NetworkUnavailable            False   Fri, 01 Mar 2019 13:24:02 +0000   Fri, 01 Mar 2019 13:24:02 +0000   RouteCreated                 RouteController created a route\n  OutOfDisk                     False   Fri, 01 Mar 2019 13:38:42 +0000   Fri, 01 Mar 2019 13:23:40 +0000   KubeletHasSufficientDisk     kubelet has sufficient disk space available\n  MemoryPressure                False   Fri, 01 Mar 2019 13:38:42 +0000   Fri, 01 Mar 2019 13:23:40 +0000   KubeletHasSufficientMemory   kubelet has sufficient memory available\n  DiskPressure                  False   Fri, 01 Mar 2019 13:38:42 +0000   Fri, 01 Mar 2019 13:23:40 +0000   KubeletHasNoDiskPressure     kubelet has no disk pressure\n  PIDPressure                   False   Fri, 01 Mar 2019 13:38:42 +0000   Fri, 01 Mar 2019 13:23:40 +0000   KubeletHasSufficientPID      kubelet has sufficient PID available\n  Ready                         True    Fri, 01 Mar 2019 13:38:42 +0000   Fri, 01 Mar 2019 13:23:40 +0000   KubeletReady                 kubelet is posting ready status. AppArmor enabled\nAddresses:\n  InternalIP:   10.128.0.16\n  ExternalIP:   35.193.149.55\n  InternalDNS:  gke-conformance-default-pool-eca581b0-00fq.c.yaseenh-gke-dev.internal\n  Hostname:     gke-conformance-default-pool-eca581b0-00fq.c.yaseenh-gke-dev.internal\nCapacity:\n attachable-volumes-gce-pd:  64\n cpu:                        4\n ephemeral-storage:          47259264Ki\n hugepages-2Mi:              0\n memory:                     15399296Ki\n pods:                       110\nAllocatable:\n attachable-volumes-gce-pd:  64\n cpu:                        3920m\n ephemeral-storage:          18858075679\n hugepages-2Mi:              0\n memory:                     12700032Ki\n pods:                       110\nSystem Info:\n Machine ID:                 31082f9297be7f9f2b7417d5e51578ff\n System UUID:                31082F92-97BE-7F9F-2B74-17D5E51578FF\n Boot ID:                    e2fb1159-51cb-45c9-81ea-2a8496ef2763\n Kernel Version:             4.14.91+\n OS Image:                   Container-Optimized OS from Google\n Operating System:           linux\n Architecture:               amd64\n Container Runtime Version:  docker://17.3.2\n Kubelet Version:            v1.12.5-gke.7\n Kube-Proxy Version:         v1.12.5-gke.7\nPodCIDR:                     10.40.2.0/24\nProviderID:                  gce://yaseenh-gke-dev/us-central1-a/gke-conformance-default-pool-eca581b0-00fq\nNon-terminated Pods:         (5 in total)\n  Namespace                  Name                                                       CPU Requests  CPU Limits  Memory Requests  Memory Limits\n  ---------                  ----                                                       ------------  ----------  ---------------  -------------\n  heptio-sonobuoy            sonobuoy-e2e-job-48f7569bb1614ff5                          0 (0%)        0 (0%)      0 (0%)           0 (0%)\n  heptio-sonobuoy            sonobuoy-systemd-logs-daemon-set-85467eaf90f647f9-rqg97    0 (0%)        0 (0%)      0 (0%)           0 (0%)\n  kube-system                fluentd-gcp-v3.2.0-22pm2                                   100m (2%)     1 (25%)     200Mi (1%)       500Mi (4%)\n  kube-system                kube-proxy-gke-conformance-default-pool-eca581b0-00fq      100m (2%)     0 (0%)      0 (0%)           0 (0%)\n  kube-system                prometheus-to-sd-b6mpb                                     1m (0%)       3m (0%)     20Mi (0%)        20Mi (0%)\nAllocated resources:\n  (Total limits may be over 100 percent, i.e., overcommitted.)\n  Resource                   Requests    Limits\n  --------                   --------    ------\n  cpu                        201m (5%)   1003m (25%)\n  memory                     220Mi (1%)  520Mi (4%)\n  attachable-volumes-gce-pd  0           0\nEvents:\n  Type    Reason                     Age                From                                                         Message\n  ----    ------                     ----               ----                                                         -------\n  Normal  NodeReady                  15m                kubelet, gke-conformance-default-pool-eca581b0-00fq          Node gke-conformance-default-pool-eca581b0-00fq status is now: NodeReady\n  Normal  NodeHasSufficientDisk      15m (x2 over 15m)  kubelet, gke-conformance-default-pool-eca581b0-00fq          Node gke-conformance-default-pool-eca581b0-00fq status is now: NodeHasSufficientDisk\n  Normal  NodeHasSufficientMemory    15m (x2 over 15m)  kubelet, gke-conformance-default-pool-eca581b0-00fq          Node gke-conformance-default-pool-eca581b0-00fq status is now: NodeHasSufficientMemory\n  Normal  NodeHasNoDiskPressure      15m (x2 over 15m)  kubelet, gke-conformance-default-pool-eca581b0-00fq          Node gke-conformance-default-pool-eca581b0-00fq status is now: NodeHasNoDiskPressure\n  Normal  NodeHasSufficientPID       15m (x2 over 15m)  kubelet, gke-conformance-default-pool-eca581b0-00fq          Node gke-conformance-default-pool-eca581b0-00fq status is now: NodeHasSufficientPID\n  Normal  NodeAllocatableEnforced    15m                kubelet, gke-conformance-default-pool-eca581b0-00fq          Updated Node Allocatable limit across pods\n  Normal  Starting                   15m                kubelet, gke-conformance-default-pool-eca581b0-00fq          Starting kubelet.\n  Normal  Starting                   15m                kube-proxy, gke-conformance-default-pool-eca581b0-00fq       Starting kube-proxy.\n  Normal  FrequentKubeletRestart     11m                systemd-monitor, gke-conformance-default-pool-eca581b0-00fq  Node condition FrequentKubeletRestart is now: False, reason: FrequentKubeletRestart\n  Normal  CorruptDockerOverlay2      11m                docker-monitor, gke-conformance-default-pool-eca581b0-00fq   Node condition CorruptDockerOverlay2 is now: False, reason: CorruptDockerOverlay2\n  Normal  UnregisterNetDevice        11m                kernel-monitor, gke-conformance-default-pool-eca581b0-00fq   Node condition FrequentUnregisterNetDevice is now: False, reason: UnregisterNetDevice\n  Normal  FrequentDockerRestart      11m                systemd-monitor, gke-conformance-default-pool-eca581b0-00fq  Node condition FrequentDockerRestart is now: False, reason: FrequentDockerRestart\n  Normal  FrequentContainerdRestart  11m                systemd-monitor, gke-conformance-default-pool-eca581b0-00fq  Node condition FrequentContainerdRestart is now: False, reason: FrequentContainerdRestart\n"
Mar  1 13:38:43.892: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-210205575 describe namespace e2e-tests-kubectl-86n92'
Mar  1 13:38:43.987: INFO: stderr: ""
Mar  1 13:38:43.987: INFO: stdout: "Name:         e2e-tests-kubectl-86n92\nLabels:       e2e-framework=kubectl\n              e2e-run=9aef9de6-3c25-11e9-a154-0a580a280202\nAnnotations:  <none>\nStatus:       Active\n\nResource Quotas\n Name:                       gke-resource-quotas\n Resource                    Used  Hard\n --------                    ---   ---\n count/ingresses.extensions  0     1G\n count/jobs.batch            0     1G\n pods                        1     1G\n services                    1     1G\n\nNo resource limits.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 13:38:43.987: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-86n92" for this suite.
Mar  1 13:39:06.003: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 13:39:06.149: INFO: namespace: e2e-tests-kubectl-86n92, resource: bindings, ignored listing per whitelist
Mar  1 13:39:06.174: INFO: namespace e2e-tests-kubectl-86n92 deletion completed in 22.182590569s

• [SLOW TEST:25.349 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl describe
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should check if kubectl describe prints relevant information for rc and pods  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 13:39:06.174: INFO: >>> kubeConfig: /tmp/kubeconfig-210205575
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-625714d7-3c27-11e9-a154-0a580a280202
STEP: Creating a pod to test consume configMaps
Mar  1 13:39:06.296: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-62581d62-3c27-11e9-a154-0a580a280202" in namespace "e2e-tests-projected-klk6x" to be "success or failure"
Mar  1 13:39:06.300: INFO: Pod "pod-projected-configmaps-62581d62-3c27-11e9-a154-0a580a280202": Phase="Pending", Reason="", readiness=false. Elapsed: 4.474449ms
Mar  1 13:39:08.304: INFO: Pod "pod-projected-configmaps-62581d62-3c27-11e9-a154-0a580a280202": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008553834s
STEP: Saw pod success
Mar  1 13:39:08.304: INFO: Pod "pod-projected-configmaps-62581d62-3c27-11e9-a154-0a580a280202" satisfied condition "success or failure"
Mar  1 13:39:08.307: INFO: Trying to get logs from node gke-conformance-default-pool-eca581b0-czl4 pod pod-projected-configmaps-62581d62-3c27-11e9-a154-0a580a280202 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Mar  1 13:39:08.329: INFO: Waiting for pod pod-projected-configmaps-62581d62-3c27-11e9-a154-0a580a280202 to disappear
Mar  1 13:39:08.337: INFO: Pod pod-projected-configmaps-62581d62-3c27-11e9-a154-0a580a280202 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 13:39:08.337: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-klk6x" for this suite.
Mar  1 13:39:14.353: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 13:39:14.537: INFO: namespace: e2e-tests-projected-klk6x, resource: bindings, ignored listing per whitelist
Mar  1 13:39:15.101: INFO: namespace e2e-tests-projected-klk6x deletion completed in 6.760063684s

• [SLOW TEST:8.927 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl replace 
  should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 13:39:15.101: INFO: >>> kubeConfig: /tmp/kubeconfig-210205575
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Kubectl replace
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1511
[It] should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Mar  1 13:39:15.196: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-210205575 run e2e-test-nginx-pod --generator=run-pod/v1 --image=docker.io/library/nginx:1.14-alpine --labels=run=e2e-test-nginx-pod --namespace=e2e-tests-kubectl-5q68j'
Mar  1 13:39:15.292: INFO: stderr: ""
Mar  1 13:39:15.292: INFO: stdout: "pod/e2e-test-nginx-pod created\n"
STEP: verifying the pod e2e-test-nginx-pod is running
STEP: verifying the pod e2e-test-nginx-pod was created
Mar  1 13:39:20.343: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-210205575 get pod e2e-test-nginx-pod --namespace=e2e-tests-kubectl-5q68j -o json'
Mar  1 13:39:20.425: INFO: stderr: ""
Mar  1 13:39:20.425: INFO: stdout: "{\n    \"apiVersion\": \"v1\",\n    \"kind\": \"Pod\",\n    \"metadata\": {\n        \"creationTimestamp\": \"2019-03-01T13:39:15Z\",\n        \"labels\": {\n            \"run\": \"e2e-test-nginx-pod\"\n        },\n        \"name\": \"e2e-test-nginx-pod\",\n        \"namespace\": \"e2e-tests-kubectl-5q68j\",\n        \"resourceVersion\": \"4345\",\n        \"selfLink\": \"/api/v1/namespaces/e2e-tests-kubectl-5q68j/pods/e2e-test-nginx-pod\",\n        \"uid\": \"67b5b078-3c27-11e9-83c3-42010a800094\"\n    },\n    \"spec\": {\n        \"containers\": [\n            {\n                \"image\": \"docker.io/library/nginx:1.14-alpine\",\n                \"imagePullPolicy\": \"IfNotPresent\",\n                \"name\": \"e2e-test-nginx-pod\",\n                \"resources\": {},\n                \"terminationMessagePath\": \"/dev/termination-log\",\n                \"terminationMessagePolicy\": \"File\",\n                \"volumeMounts\": [\n                    {\n                        \"mountPath\": \"/var/run/secrets/kubernetes.io/serviceaccount\",\n                        \"name\": \"default-token-fsqm5\",\n                        \"readOnly\": true\n                    }\n                ]\n            }\n        ],\n        \"dnsPolicy\": \"ClusterFirst\",\n        \"nodeName\": \"gke-conformance-default-pool-eca581b0-sww9\",\n        \"priority\": 0,\n        \"restartPolicy\": \"Always\",\n        \"schedulerName\": \"default-scheduler\",\n        \"securityContext\": {},\n        \"serviceAccount\": \"default\",\n        \"serviceAccountName\": \"default\",\n        \"terminationGracePeriodSeconds\": 30,\n        \"tolerations\": [\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/not-ready\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            },\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/unreachable\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            }\n        ],\n        \"volumes\": [\n            {\n                \"name\": \"default-token-fsqm5\",\n                \"secret\": {\n                    \"defaultMode\": 420,\n                    \"secretName\": \"default-token-fsqm5\"\n                }\n            }\n        ]\n    },\n    \"status\": {\n        \"conditions\": [\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-03-01T13:39:15Z\",\n                \"status\": \"True\",\n                \"type\": \"Initialized\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-03-01T13:39:17Z\",\n                \"status\": \"True\",\n                \"type\": \"Ready\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-03-01T13:39:17Z\",\n                \"status\": \"True\",\n                \"type\": \"ContainersReady\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-03-01T13:39:15Z\",\n                \"status\": \"True\",\n                \"type\": \"PodScheduled\"\n            }\n        ],\n        \"containerStatuses\": [\n            {\n                \"containerID\": \"docker://b0ced61f2fce594bcad380bc00728754c19414a244bd0456b190fc39c9a6db1f\",\n                \"image\": \"nginx:1.14-alpine\",\n                \"imageID\": \"docker-pullable://nginx@sha256:b9734546761e49b453efce35ee523bbcaff1052d281516f133d41b090e26c0df\",\n                \"lastState\": {},\n                \"name\": \"e2e-test-nginx-pod\",\n                \"ready\": true,\n                \"restartCount\": 0,\n                \"state\": {\n                    \"running\": {\n                        \"startedAt\": \"2019-03-01T13:39:16Z\"\n                    }\n                }\n            }\n        ],\n        \"hostIP\": \"10.128.0.18\",\n        \"phase\": \"Running\",\n        \"podIP\": \"10.40.1.21\",\n        \"qosClass\": \"BestEffort\",\n        \"startTime\": \"2019-03-01T13:39:15Z\"\n    }\n}\n"
STEP: replace the image in the pod
Mar  1 13:39:20.425: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-210205575 replace -f - --namespace=e2e-tests-kubectl-5q68j'
Mar  1 13:39:20.608: INFO: stderr: ""
Mar  1 13:39:20.609: INFO: stdout: "pod/e2e-test-nginx-pod replaced\n"
STEP: verifying the pod e2e-test-nginx-pod has the right image docker.io/library/busybox:1.29
[AfterEach] [k8s.io] Kubectl replace
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1516
Mar  1 13:39:20.612: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-210205575 delete pods e2e-test-nginx-pod --namespace=e2e-tests-kubectl-5q68j'
Mar  1 13:39:29.699: INFO: stderr: ""
Mar  1 13:39:29.699: INFO: stdout: "pod \"e2e-test-nginx-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 13:39:29.699: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-5q68j" for this suite.
Mar  1 13:39:35.714: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 13:39:35.816: INFO: namespace: e2e-tests-kubectl-5q68j, resource: bindings, ignored listing per whitelist
Mar  1 13:39:35.855: INFO: namespace e2e-tests-kubectl-5q68j deletion completed in 6.151636309s

• [SLOW TEST:20.754 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl replace
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should update a single-container pod's image  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-apps] Deployment 
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 13:39:35.855: INFO: >>> kubeConfig: /tmp/kubeconfig-210205575
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Mar  1 13:39:35.987: INFO: Creating deployment "test-recreate-deployment"
Mar  1 13:39:35.994: INFO: Waiting deployment "test-recreate-deployment" to be updated to revision 1
Mar  1 13:39:36.003: INFO: new replicaset for deployment "test-recreate-deployment" is yet to be created
Mar  1 13:39:38.009: INFO: Waiting deployment "test-recreate-deployment" to complete
Mar  1 13:39:38.012: INFO: Triggering a new rollout for deployment "test-recreate-deployment"
Mar  1 13:39:38.021: INFO: Updating deployment test-recreate-deployment
Mar  1 13:39:38.021: INFO: Watching deployment "test-recreate-deployment" to verify that new pods will not run with olds pods
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Mar  1 13:39:38.189: INFO: Deployment "test-recreate-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment,GenerateName:,Namespace:e2e-tests-deployment-8gbl9,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-8gbl9/deployments/test-recreate-deployment,UID:740ede9b-3c27-11e9-83c3-42010a800094,ResourceVersion:4450,Generation:2,CreationTimestamp:2019-03-01 13:39:36 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},Strategy:DeploymentStrategy{Type:Recreate,RollingUpdate:nil,},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:0,UnavailableReplicas:1,Conditions:[{Available False 2019-03-01 13:39:38 +0000 UTC 2019-03-01 13:39:38 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.} {Progressing True 2019-03-01 13:39:38 +0000 UTC 2019-03-01 13:39:36 +0000 UTC ReplicaSetUpdated ReplicaSet "test-recreate-deployment-7cf749666b" is progressing.}],ReadyReplicas:0,CollisionCount:nil,},}

Mar  1 13:39:38.192: INFO: New ReplicaSet "test-recreate-deployment-7cf749666b" of Deployment "test-recreate-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-7cf749666b,GenerateName:,Namespace:e2e-tests-deployment-8gbl9,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-8gbl9/replicasets/test-recreate-deployment-7cf749666b,UID:754e4111-3c27-11e9-83c3-42010a800094,ResourceVersion:4449,Generation:1,CreationTimestamp:2019-03-01 13:39:38 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 7cf749666b,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 1,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment test-recreate-deployment 740ede9b-3c27-11e9-83c3-42010a800094 0xc4225722d7 0xc4225722d8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 7cf749666b,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 7cf749666b,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Mar  1 13:39:38.192: INFO: All old ReplicaSets of Deployment "test-recreate-deployment":
Mar  1 13:39:38.192: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-79f694ff59,GenerateName:,Namespace:e2e-tests-deployment-8gbl9,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-8gbl9/replicasets/test-recreate-deployment-79f694ff59,UID:74112fe1-3c27-11e9-83c3-42010a800094,ResourceVersion:4440,Generation:2,CreationTimestamp:2019-03-01 13:39:36 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 79f694ff59,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 1,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-recreate-deployment 740ede9b-3c27-11e9-83c3-42010a800094 0xc422457f97 0xc422457f98}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 79f694ff59,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 79f694ff59,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Mar  1 13:39:38.209: INFO: Pod "test-recreate-deployment-7cf749666b-pf9ms" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-7cf749666b-pf9ms,GenerateName:test-recreate-deployment-7cf749666b-,Namespace:e2e-tests-deployment-8gbl9,SelfLink:/api/v1/namespaces/e2e-tests-deployment-8gbl9/pods/test-recreate-deployment-7cf749666b-pf9ms,UID:754f48d5-3c27-11e9-83c3-42010a800094,ResourceVersion:4448,Generation:0,CreationTimestamp:2019-03-01 13:39:38 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 7cf749666b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet test-recreate-deployment-7cf749666b 754e4111-3c27-11e9-83c3-42010a800094 0xc422572ab7 0xc422572ab8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-rxgmp {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-rxgmp,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-rxgmp true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:gke-conformance-default-pool-eca581b0-czl4,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc422572b20} {node.kubernetes.io/unreachable Exists  NoExecute 0xc422572b40}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 13:39:38 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-01 13:39:38 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-01 13:39:38 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 13:39:38 +0000 UTC  }],Message:,Reason:,HostIP:10.128.0.14,PodIP:,StartTime:2019-03-01 13:39:38 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 13:39:38.209: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-8gbl9" for this suite.
Mar  1 13:39:44.236: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 13:39:44.421: INFO: namespace: e2e-tests-deployment-8gbl9, resource: bindings, ignored listing per whitelist
Mar  1 13:39:44.428: INFO: namespace e2e-tests-deployment-8gbl9 deletion completed in 6.213718516s

• [SLOW TEST:8.573 seconds]
[sig-apps] Deployment
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-apps] Deployment 
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 13:39:44.428: INFO: >>> kubeConfig: /tmp/kubeconfig-210205575
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Mar  1 13:39:44.598: INFO: Pod name cleanup-pod: Found 0 pods out of 1
Mar  1 13:39:49.604: INFO: Pod name cleanup-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Mar  1 13:39:49.604: INFO: Creating deployment test-cleanup-deployment
STEP: Waiting for deployment test-cleanup-deployment history to be cleaned up
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Mar  1 13:39:49.653: INFO: Deployment "test-cleanup-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-deployment,GenerateName:,Namespace:e2e-tests-deployment-7wkq6,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-7wkq6/deployments/test-cleanup-deployment,UID:7c2d986e-3c27-11e9-83c3-42010a800094,ResourceVersion:4513,Generation:1,CreationTimestamp:2019-03-01 13:39:49 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*0,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:0,Replicas:0,UpdatedReplicas:0,AvailableReplicas:0,UnavailableReplicas:0,Conditions:[],ReadyReplicas:0,CollisionCount:nil,},}

Mar  1 13:39:49.657: INFO: New ReplicaSet of Deployment "test-cleanup-deployment" is nil.
Mar  1 13:39:49.657: INFO: All old ReplicaSets of Deployment "test-cleanup-deployment":
Mar  1 13:39:49.657: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-controller,GenerateName:,Namespace:e2e-tests-deployment-7wkq6,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-7wkq6/replicasets/test-cleanup-controller,UID:792ed822-3c27-11e9-83c3-42010a800094,ResourceVersion:4514,Generation:1,CreationTimestamp:2019-03-01 13:39:44 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 Deployment test-cleanup-deployment 7c2d986e-3c27-11e9-83c3-42010a800094 0xc4221b1e8f 0xc4221b1ea0}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Mar  1 13:39:49.662: INFO: Pod "test-cleanup-controller-vqgmh" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-controller-vqgmh,GenerateName:test-cleanup-controller-,Namespace:e2e-tests-deployment-7wkq6,SelfLink:/api/v1/namespaces/e2e-tests-deployment-7wkq6/pods/test-cleanup-controller-vqgmh,UID:7930937c-3c27-11e9-83c3-42010a800094,ResourceVersion:4501,Generation:0,CreationTimestamp:2019-03-01 13:39:44 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet test-cleanup-controller 792ed822-3c27-11e9-83c3-42010a800094 0xc42214afaf 0xc42214afc0}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-tkk2w {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-tkk2w,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-tkk2w true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:gke-conformance-default-pool-eca581b0-sww9,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc42214b020} {node.kubernetes.io/unreachable Exists  NoExecute 0xc42214b040}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 13:39:44 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 13:39:45 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 13:39:45 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 13:39:44 +0000 UTC  }],Message:,Reason:,HostIP:10.128.0.18,PodIP:10.40.1.22,StartTime:2019-03-01 13:39:44 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-03-01 13:39:45 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:b9734546761e49b453efce35ee523bbcaff1052d281516f133d41b090e26c0df docker://41bf2ca013054512f4b3db574b4a300e5618850be8a0f578623d46bfdd941425}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 13:39:49.662: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-7wkq6" for this suite.
Mar  1 13:39:55.708: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 13:39:55.907: INFO: namespace: e2e-tests-deployment-7wkq6, resource: bindings, ignored listing per whitelist
Mar  1 13:39:55.907: INFO: namespace e2e-tests-deployment-7wkq6 deletion completed in 6.232736296s

• [SLOW TEST:11.479 seconds]
[sig-apps] Deployment
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-storage] ConfigMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 13:39:55.907: INFO: >>> kubeConfig: /tmp/kubeconfig-210205575
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-upd-7ffc502a-3c27-11e9-a154-0a580a280202
STEP: Creating the pod
STEP: Updating configmap configmap-test-upd-7ffc502a-3c27-11e9-a154-0a580a280202
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 13:41:30.719: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-wl2f6" for this suite.
Mar  1 13:41:52.740: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 13:41:52.878: INFO: namespace: e2e-tests-configmap-wl2f6, resource: bindings, ignored listing per whitelist
Mar  1 13:41:52.930: INFO: namespace e2e-tests-configmap-wl2f6 deletion completed in 22.204635201s

• [SLOW TEST:117.023 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl version 
  should check is all data is printed  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 13:41:52.930: INFO: >>> kubeConfig: /tmp/kubeconfig-210205575
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should check is all data is printed  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Mar  1 13:41:53.027: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-210205575 version'
Mar  1 13:41:53.134: INFO: stderr: ""
Mar  1 13:41:53.134: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"12\", GitVersion:\"v1.12.1\", GitCommit:\"4ed3216f3ec431b140b1d899130a69fc671678f4\", GitTreeState:\"clean\", BuildDate:\"2018-10-05T16:46:06Z\", GoVersion:\"go1.10.4\", Compiler:\"gc\", Platform:\"linux/amd64\"}\nServer Version: version.Info{Major:\"1\", Minor:\"12+\", GitVersion:\"v1.12.5-gke.7\", GitCommit:\"62b95928b91e1c129ddc4a779939eb8cd5b6c870\", GitTreeState:\"clean\", BuildDate:\"2019-02-11T23:20:39Z\", GoVersion:\"go1.10.8b4\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 13:41:53.134: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-cf6bg" for this suite.
Mar  1 13:41:59.152: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 13:41:59.207: INFO: namespace: e2e-tests-kubectl-cf6bg, resource: bindings, ignored listing per whitelist
Mar  1 13:41:59.258: INFO: namespace e2e-tests-kubectl-cf6bg deletion completed in 6.118739992s

• [SLOW TEST:6.328 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl version
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should check is all data is printed  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 13:41:59.259: INFO: >>> kubeConfig: /tmp/kubeconfig-210205575
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name s-test-opt-del-c97f4593-3c27-11e9-a154-0a580a280202
STEP: Creating secret with name s-test-opt-upd-c97f45de-3c27-11e9-a154-0a580a280202
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-c97f4593-3c27-11e9-a154-0a580a280202
STEP: Updating secret s-test-opt-upd-c97f45de-3c27-11e9-a154-0a580a280202
STEP: Creating secret with name s-test-opt-create-c97f45f2-3c27-11e9-a154-0a580a280202
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 13:42:05.465: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-bw5vc" for this suite.
Mar  1 13:42:29.481: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 13:42:29.547: INFO: namespace: e2e-tests-secrets-bw5vc, resource: bindings, ignored listing per whitelist
Mar  1 13:42:29.713: INFO: namespace e2e-tests-secrets-bw5vc deletion completed in 24.244556079s

• [SLOW TEST:30.455 seconds]
[sig-storage] Secrets
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] version v1
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 13:42:29.714: INFO: >>> kubeConfig: /tmp/kubeconfig-210205575
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Mar  1 13:42:30.304: INFO: (0) /api/v1/nodes/gke-conformance-default-pool-eca581b0-00fq/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="cloud-init.log">cloud-init.log</a>
<a href="containers/">c... (200; 10.508821ms)
Mar  1 13:42:30.310: INFO: (1) /api/v1/nodes/gke-conformance-default-pool-eca581b0-00fq/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="cloud-init.log">cloud-init.log</a>
<a href="containers/">c... (200; 5.726827ms)
Mar  1 13:42:30.322: INFO: (2) /api/v1/nodes/gke-conformance-default-pool-eca581b0-00fq/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="cloud-init.log">cloud-init.log</a>
<a href="containers/">c... (200; 11.74758ms)
Mar  1 13:42:30.328: INFO: (3) /api/v1/nodes/gke-conformance-default-pool-eca581b0-00fq/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="cloud-init.log">cloud-init.log</a>
<a href="containers/">c... (200; 6.3019ms)
Mar  1 13:42:30.335: INFO: (4) /api/v1/nodes/gke-conformance-default-pool-eca581b0-00fq/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="cloud-init.log">cloud-init.log</a>
<a href="containers/">c... (200; 6.164887ms)
Mar  1 13:42:30.340: INFO: (5) /api/v1/nodes/gke-conformance-default-pool-eca581b0-00fq/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="cloud-init.log">cloud-init.log</a>
<a href="containers/">c... (200; 5.095082ms)
Mar  1 13:42:30.350: INFO: (6) /api/v1/nodes/gke-conformance-default-pool-eca581b0-00fq/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="cloud-init.log">cloud-init.log</a>
<a href="containers/">c... (200; 9.939064ms)
Mar  1 13:42:30.359: INFO: (7) /api/v1/nodes/gke-conformance-default-pool-eca581b0-00fq/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="cloud-init.log">cloud-init.log</a>
<a href="containers/">c... (200; 9.379607ms)
Mar  1 13:42:30.365: INFO: (8) /api/v1/nodes/gke-conformance-default-pool-eca581b0-00fq/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="cloud-init.log">cloud-init.log</a>
<a href="containers/">c... (200; 6.237541ms)
Mar  1 13:42:30.371: INFO: (9) /api/v1/nodes/gke-conformance-default-pool-eca581b0-00fq/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="cloud-init.log">cloud-init.log</a>
<a href="containers/">c... (200; 5.787343ms)
Mar  1 13:42:30.380: INFO: (10) /api/v1/nodes/gke-conformance-default-pool-eca581b0-00fq/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="cloud-init.log">cloud-init.log</a>
<a href="containers/">c... (200; 8.984168ms)
Mar  1 13:42:30.386: INFO: (11) /api/v1/nodes/gke-conformance-default-pool-eca581b0-00fq/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="cloud-init.log">cloud-init.log</a>
<a href="containers/">c... (200; 5.224841ms)
Mar  1 13:42:30.391: INFO: (12) /api/v1/nodes/gke-conformance-default-pool-eca581b0-00fq/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="cloud-init.log">cloud-init.log</a>
<a href="containers/">c... (200; 5.79266ms)
Mar  1 13:42:30.403: INFO: (13) /api/v1/nodes/gke-conformance-default-pool-eca581b0-00fq/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="cloud-init.log">cloud-init.log</a>
<a href="containers/">c... (200; 11.672066ms)
Mar  1 13:42:30.419: INFO: (14) /api/v1/nodes/gke-conformance-default-pool-eca581b0-00fq/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="cloud-init.log">cloud-init.log</a>
<a href="containers/">c... (200; 15.459731ms)
Mar  1 13:42:30.432: INFO: (15) /api/v1/nodes/gke-conformance-default-pool-eca581b0-00fq/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="cloud-init.log">cloud-init.log</a>
<a href="containers/">c... (200; 12.950238ms)
Mar  1 13:42:30.440: INFO: (16) /api/v1/nodes/gke-conformance-default-pool-eca581b0-00fq/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="cloud-init.log">cloud-init.log</a>
<a href="containers/">c... (200; 8.351166ms)
Mar  1 13:42:30.446: INFO: (17) /api/v1/nodes/gke-conformance-default-pool-eca581b0-00fq/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="cloud-init.log">cloud-init.log</a>
<a href="containers/">c... (200; 5.817715ms)
Mar  1 13:42:30.452: INFO: (18) /api/v1/nodes/gke-conformance-default-pool-eca581b0-00fq/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="cloud-init.log">cloud-init.log</a>
<a href="containers/">c... (200; 6.129774ms)
Mar  1 13:42:30.457: INFO: (19) /api/v1/nodes/gke-conformance-default-pool-eca581b0-00fq/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="cloud-init.log">cloud-init.log</a>
<a href="containers/">c... (200; 4.944637ms)
[AfterEach] version v1
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 13:42:30.457: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-proxy-hb2mr" for this suite.
Mar  1 13:42:36.475: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 13:42:36.531: INFO: namespace: e2e-tests-proxy-hb2mr, resource: bindings, ignored listing per whitelist
Mar  1 13:42:36.632: INFO: namespace e2e-tests-proxy-hb2mr deletion completed in 6.170312043s

• [SLOW TEST:6.919 seconds]
[sig-network] Proxy
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy logs on node using proxy subresource  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 13:42:36.633: INFO: >>> kubeConfig: /tmp/kubeconfig-210205575
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-dfcbf492-3c27-11e9-a154-0a580a280202
STEP: Creating a pod to test consume secrets
Mar  1 13:42:36.774: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-dfccb9b1-3c27-11e9-a154-0a580a280202" in namespace "e2e-tests-projected-9f4b9" to be "success or failure"
Mar  1 13:42:36.791: INFO: Pod "pod-projected-secrets-dfccb9b1-3c27-11e9-a154-0a580a280202": Phase="Pending", Reason="", readiness=false. Elapsed: 17.082202ms
Mar  1 13:42:38.794: INFO: Pod "pod-projected-secrets-dfccb9b1-3c27-11e9-a154-0a580a280202": Phase="Running", Reason="", readiness=true. Elapsed: 2.020342471s
Mar  1 13:42:40.798: INFO: Pod "pod-projected-secrets-dfccb9b1-3c27-11e9-a154-0a580a280202": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.024035671s
STEP: Saw pod success
Mar  1 13:42:40.798: INFO: Pod "pod-projected-secrets-dfccb9b1-3c27-11e9-a154-0a580a280202" satisfied condition "success or failure"
Mar  1 13:42:40.801: INFO: Trying to get logs from node gke-conformance-default-pool-eca581b0-sww9 pod pod-projected-secrets-dfccb9b1-3c27-11e9-a154-0a580a280202 container projected-secret-volume-test: <nil>
STEP: delete the pod
Mar  1 13:42:40.834: INFO: Waiting for pod pod-projected-secrets-dfccb9b1-3c27-11e9-a154-0a580a280202 to disappear
Mar  1 13:42:40.839: INFO: Pod pod-projected-secrets-dfccb9b1-3c27-11e9-a154-0a580a280202 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 13:42:40.840: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-9f4b9" for this suite.
Mar  1 13:42:46.854: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 13:42:46.875: INFO: namespace: e2e-tests-projected-9f4b9, resource: bindings, ignored listing per whitelist
Mar  1 13:42:46.975: INFO: namespace e2e-tests-projected-9f4b9 deletion completed in 6.130862206s

• [SLOW TEST:10.342 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run pod 
  should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 13:42:46.975: INFO: >>> kubeConfig: /tmp/kubeconfig-210205575
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Kubectl run pod
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1475
[It] should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Mar  1 13:42:47.084: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-210205575 run e2e-test-nginx-pod --restart=Never --generator=run-pod/v1 --image=docker.io/library/nginx:1.14-alpine --namespace=e2e-tests-kubectl-8pcjm'
Mar  1 13:42:47.187: INFO: stderr: ""
Mar  1 13:42:47.187: INFO: stdout: "pod/e2e-test-nginx-pod created\n"
STEP: verifying the pod e2e-test-nginx-pod was created
[AfterEach] [k8s.io] Kubectl run pod
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1480
Mar  1 13:42:47.198: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-210205575 delete pods e2e-test-nginx-pod --namespace=e2e-tests-kubectl-8pcjm'
Mar  1 13:42:50.322: INFO: stderr: ""
Mar  1 13:42:50.322: INFO: stdout: "pod \"e2e-test-nginx-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 13:42:50.322: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-8pcjm" for this suite.
Mar  1 13:42:56.339: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 13:42:56.458: INFO: namespace: e2e-tests-kubectl-8pcjm, resource: bindings, ignored listing per whitelist
Mar  1 13:42:56.458: INFO: namespace e2e-tests-kubectl-8pcjm deletion completed in 6.128200477s

• [SLOW TEST:9.483 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run pod
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create a pod from an image when restart is Never  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 13:42:56.458: INFO: >>> kubeConfig: /tmp/kubeconfig-210205575
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Mar  1 13:42:56.559: INFO: Waiting up to 5m0s for pod "downwardapi-volume-eb979e68-3c27-11e9-a154-0a580a280202" in namespace "e2e-tests-downward-api-hn5sw" to be "success or failure"
Mar  1 13:42:56.595: INFO: Pod "downwardapi-volume-eb979e68-3c27-11e9-a154-0a580a280202": Phase="Pending", Reason="", readiness=false. Elapsed: 36.290871ms
Mar  1 13:42:58.608: INFO: Pod "downwardapi-volume-eb979e68-3c27-11e9-a154-0a580a280202": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.049576073s
STEP: Saw pod success
Mar  1 13:42:58.608: INFO: Pod "downwardapi-volume-eb979e68-3c27-11e9-a154-0a580a280202" satisfied condition "success or failure"
Mar  1 13:42:58.612: INFO: Trying to get logs from node gke-conformance-default-pool-eca581b0-sqmc pod downwardapi-volume-eb979e68-3c27-11e9-a154-0a580a280202 container client-container: <nil>
STEP: delete the pod
Mar  1 13:42:58.656: INFO: Waiting for pod downwardapi-volume-eb979e68-3c27-11e9-a154-0a580a280202 to disappear
Mar  1 13:42:58.665: INFO: Pod downwardapi-volume-eb979e68-3c27-11e9-a154-0a580a280202 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 13:42:58.665: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-hn5sw" for this suite.
Mar  1 13:43:08.689: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 13:43:08.733: INFO: namespace: e2e-tests-downward-api-hn5sw, resource: bindings, ignored listing per whitelist
Mar  1 13:43:08.827: INFO: namespace e2e-tests-downward-api-hn5sw deletion completed in 10.155823408s

• [SLOW TEST:12.369 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 13:43:08.827: INFO: >>> kubeConfig: /tmp/kubeconfig-210205575
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Mar  1 13:43:08.952: INFO: Waiting up to 5m0s for pod "downwardapi-volume-f2facedc-3c27-11e9-a154-0a580a280202" in namespace "e2e-tests-downward-api-rpbw5" to be "success or failure"
Mar  1 13:43:08.966: INFO: Pod "downwardapi-volume-f2facedc-3c27-11e9-a154-0a580a280202": Phase="Pending", Reason="", readiness=false. Elapsed: 14.013703ms
Mar  1 13:43:10.969: INFO: Pod "downwardapi-volume-f2facedc-3c27-11e9-a154-0a580a280202": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.017256045s
STEP: Saw pod success
Mar  1 13:43:10.969: INFO: Pod "downwardapi-volume-f2facedc-3c27-11e9-a154-0a580a280202" satisfied condition "success or failure"
Mar  1 13:43:10.972: INFO: Trying to get logs from node gke-conformance-default-pool-eca581b0-czl4 pod downwardapi-volume-f2facedc-3c27-11e9-a154-0a580a280202 container client-container: <nil>
STEP: delete the pod
Mar  1 13:43:10.997: INFO: Waiting for pod downwardapi-volume-f2facedc-3c27-11e9-a154-0a580a280202 to disappear
Mar  1 13:43:11.001: INFO: Pod downwardapi-volume-f2facedc-3c27-11e9-a154-0a580a280202 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 13:43:11.001: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-rpbw5" for this suite.
Mar  1 13:43:17.018: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 13:43:17.077: INFO: namespace: e2e-tests-downward-api-rpbw5, resource: bindings, ignored listing per whitelist
Mar  1 13:43:17.141: INFO: namespace e2e-tests-downward-api-rpbw5 deletion completed in 6.132821203s

• [SLOW TEST:8.314 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 13:43:17.141: INFO: >>> kubeConfig: /tmp/kubeconfig-210205575
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-f7f2a637-3c27-11e9-a154-0a580a280202
STEP: Creating a pod to test consume secrets
Mar  1 13:43:17.293: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-f7f34a20-3c27-11e9-a154-0a580a280202" in namespace "e2e-tests-projected-rcs2g" to be "success or failure"
Mar  1 13:43:17.297: INFO: Pod "pod-projected-secrets-f7f34a20-3c27-11e9-a154-0a580a280202": Phase="Pending", Reason="", readiness=false. Elapsed: 3.777534ms
Mar  1 13:43:19.300: INFO: Pod "pod-projected-secrets-f7f34a20-3c27-11e9-a154-0a580a280202": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007627193s
STEP: Saw pod success
Mar  1 13:43:19.301: INFO: Pod "pod-projected-secrets-f7f34a20-3c27-11e9-a154-0a580a280202" satisfied condition "success or failure"
Mar  1 13:43:19.304: INFO: Trying to get logs from node gke-conformance-default-pool-eca581b0-sqmc pod pod-projected-secrets-f7f34a20-3c27-11e9-a154-0a580a280202 container projected-secret-volume-test: <nil>
STEP: delete the pod
Mar  1 13:43:19.327: INFO: Waiting for pod pod-projected-secrets-f7f34a20-3c27-11e9-a154-0a580a280202 to disappear
Mar  1 13:43:19.333: INFO: Pod pod-projected-secrets-f7f34a20-3c27-11e9-a154-0a580a280202 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 13:43:19.333: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-rcs2g" for this suite.
Mar  1 13:43:25.356: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 13:43:25.466: INFO: namespace: e2e-tests-projected-rcs2g, resource: bindings, ignored listing per whitelist
Mar  1 13:43:25.485: INFO: namespace e2e-tests-projected-rcs2g deletion completed in 6.142894225s

• [SLOW TEST:8.344 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] Projected 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 13:43:25.486: INFO: >>> kubeConfig: /tmp/kubeconfig-210205575
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name projected-secret-test-fce59998-3c27-11e9-a154-0a580a280202
STEP: Creating a pod to test consume secrets
Mar  1 13:43:25.593: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-fce634b9-3c27-11e9-a154-0a580a280202" in namespace "e2e-tests-projected-trx82" to be "success or failure"
Mar  1 13:43:25.596: INFO: Pod "pod-projected-secrets-fce634b9-3c27-11e9-a154-0a580a280202": Phase="Pending", Reason="", readiness=false. Elapsed: 3.115624ms
Mar  1 13:43:27.600: INFO: Pod "pod-projected-secrets-fce634b9-3c27-11e9-a154-0a580a280202": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007013388s
Mar  1 13:43:29.604: INFO: Pod "pod-projected-secrets-fce634b9-3c27-11e9-a154-0a580a280202": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011011163s
STEP: Saw pod success
Mar  1 13:43:29.604: INFO: Pod "pod-projected-secrets-fce634b9-3c27-11e9-a154-0a580a280202" satisfied condition "success or failure"
Mar  1 13:43:29.606: INFO: Trying to get logs from node gke-conformance-default-pool-eca581b0-czl4 pod pod-projected-secrets-fce634b9-3c27-11e9-a154-0a580a280202 container secret-volume-test: <nil>
STEP: delete the pod
Mar  1 13:43:29.634: INFO: Waiting for pod pod-projected-secrets-fce634b9-3c27-11e9-a154-0a580a280202 to disappear
Mar  1 13:43:29.638: INFO: Pod pod-projected-secrets-fce634b9-3c27-11e9-a154-0a580a280202 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 13:43:29.638: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-trx82" for this suite.
Mar  1 13:43:35.653: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 13:43:35.784: INFO: namespace: e2e-tests-projected-trx82, resource: bindings, ignored listing per whitelist
Mar  1 13:43:35.809: INFO: namespace e2e-tests-projected-trx82 deletion completed in 6.167572488s

• [SLOW TEST:10.323 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] ConfigMap 
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 13:43:35.809: INFO: >>> kubeConfig: /tmp/kubeconfig-210205575
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-upd-030f327c-3c28-11e9-a154-0a580a280202
STEP: Creating the pod
STEP: Waiting for pod with text data
STEP: Waiting for pod with binary data
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 13:43:39.967: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-kn288" for this suite.
Mar  1 13:44:01.989: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 13:44:02.107: INFO: namespace: e2e-tests-configmap-kn288, resource: bindings, ignored listing per whitelist
Mar  1 13:44:02.151: INFO: namespace e2e-tests-configmap-kn288 deletion completed in 22.177744335s

• [SLOW TEST:26.342 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-network] Proxy version v1 
  should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] version v1
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 13:44:02.151: INFO: >>> kubeConfig: /tmp/kubeconfig-210205575
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: starting an echo server on multiple ports
STEP: creating replication controller proxy-service-7c86j in namespace e2e-tests-proxy-94thk
I0301 13:44:02.283325      19 runners.go:180] Created replication controller with name: proxy-service-7c86j, namespace: e2e-tests-proxy-94thk, replica count: 1
I0301 13:44:03.333972      19 runners.go:180] proxy-service-7c86j Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0301 13:44:04.334268      19 runners.go:180] proxy-service-7c86j Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0301 13:44:05.334561      19 runners.go:180] proxy-service-7c86j Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0301 13:44:06.334880      19 runners.go:180] proxy-service-7c86j Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0301 13:44:07.335208      19 runners.go:180] proxy-service-7c86j Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0301 13:44:08.335523      19 runners.go:180] proxy-service-7c86j Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0301 13:44:09.335825      19 runners.go:180] proxy-service-7c86j Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0301 13:44:10.336141      19 runners.go:180] proxy-service-7c86j Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Mar  1 13:44:10.340: INFO: setup took 8.083125113s, starting test cases
STEP: running 16 cases, 20 attempts per case, 320 total attempts
Mar  1 13:44:10.365: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-94thk/pods/http:proxy-service-7c86j-xsqtb:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-94thk/pods/http:proxy-service-7c86j-xsqtb:1080/proxy/... (200; 24.573633ms)
Mar  1 13:44:10.366: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-94thk/pods/proxy-service-7c86j-xsqtb/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-94thk/pods/proxy-service-7c86j-xsqtb/proxy/rewriteme"... (200; 25.076107ms)
Mar  1 13:44:10.366: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-94thk/services/proxy-service-7c86j:portname2/proxy/: bar (200; 25.547847ms)
Mar  1 13:44:10.369: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-94thk/services/http:proxy-service-7c86j:portname2/proxy/: bar (200; 29.042995ms)
Mar  1 13:44:10.370: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-94thk/pods/http:proxy-service-7c86j-xsqtb:160/proxy/: foo (200; 29.61239ms)
Mar  1 13:44:10.370: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-94thk/pods/proxy-service-7c86j-xsqtb:162/proxy/: bar (200; 29.533945ms)
Mar  1 13:44:10.370: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-94thk/services/proxy-service-7c86j:portname1/proxy/: foo (200; 29.275159ms)
Mar  1 13:44:10.370: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-94thk/pods/http:proxy-service-7c86j-xsqtb:162/proxy/: bar (200; 29.5349ms)
Mar  1 13:44:10.374: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-94thk/services/http:proxy-service-7c86j:portname1/proxy/: foo (200; 33.042831ms)
Mar  1 13:44:10.374: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-94thk/pods/https:proxy-service-7c86j-xsqtb:460/proxy/: tls baz (200; 33.238545ms)
Mar  1 13:44:10.374: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-94thk/pods/proxy-service-7c86j-xsqtb:160/proxy/: foo (200; 33.567917ms)
Mar  1 13:44:10.374: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-94thk/pods/proxy-service-7c86j-xsqtb:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-94thk/pods/proxy-service-7c86j-xsqtb:1080/proxy/rewri... (200; 33.80426ms)
Mar  1 13:44:10.375: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-94thk/services/https:proxy-service-7c86j:tlsportname1/proxy/: tls baz (200; 34.77007ms)
Mar  1 13:44:10.376: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-94thk/services/https:proxy-service-7c86j:tlsportname2/proxy/: tls qux (200; 35.317022ms)
Mar  1 13:44:10.376: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-94thk/pods/https:proxy-service-7c86j-xsqtb:462/proxy/: tls qux (200; 35.264337ms)
Mar  1 13:44:10.420: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-94thk/pods/https:proxy-service-7c86j-xsqtb:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-94thk/pods/https:proxy-service-7c86j-xsqtb:443/proxy/... (200; 79.675173ms)
Mar  1 13:44:10.439: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-94thk/pods/https:proxy-service-7c86j-xsqtb:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-94thk/pods/https:proxy-service-7c86j-xsqtb:443/proxy/... (200; 18.703702ms)
Mar  1 13:44:10.443: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-94thk/pods/http:proxy-service-7c86j-xsqtb:160/proxy/: foo (200; 22.503086ms)
Mar  1 13:44:10.444: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-94thk/pods/https:proxy-service-7c86j-xsqtb:460/proxy/: tls baz (200; 24.183263ms)
Mar  1 13:44:10.445: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-94thk/pods/https:proxy-service-7c86j-xsqtb:462/proxy/: tls qux (200; 24.430874ms)
Mar  1 13:44:10.445: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-94thk/pods/proxy-service-7c86j-xsqtb:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-94thk/pods/proxy-service-7c86j-xsqtb:1080/proxy/rewri... (200; 24.378481ms)
Mar  1 13:44:10.446: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-94thk/pods/proxy-service-7c86j-xsqtb/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-94thk/pods/proxy-service-7c86j-xsqtb/proxy/rewriteme"... (200; 25.855745ms)
Mar  1 13:44:10.446: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-94thk/pods/http:proxy-service-7c86j-xsqtb:162/proxy/: bar (200; 25.956656ms)
Mar  1 13:44:10.446: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-94thk/pods/proxy-service-7c86j-xsqtb:160/proxy/: foo (200; 26.051838ms)
Mar  1 13:44:10.447: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-94thk/pods/proxy-service-7c86j-xsqtb:162/proxy/: bar (200; 26.364191ms)
Mar  1 13:44:10.447: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-94thk/services/https:proxy-service-7c86j:tlsportname2/proxy/: tls qux (200; 26.348457ms)
Mar  1 13:44:10.449: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-94thk/pods/http:proxy-service-7c86j-xsqtb:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-94thk/pods/http:proxy-service-7c86j-xsqtb:1080/proxy/... (200; 28.442569ms)
Mar  1 13:44:10.449: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-94thk/services/https:proxy-service-7c86j:tlsportname1/proxy/: tls baz (200; 28.654861ms)
Mar  1 13:44:10.449: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-94thk/services/http:proxy-service-7c86j:portname1/proxy/: foo (200; 28.518963ms)
Mar  1 13:44:10.449: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-94thk/services/proxy-service-7c86j:portname1/proxy/: foo (200; 28.756038ms)
Mar  1 13:44:10.451: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-94thk/services/proxy-service-7c86j:portname2/proxy/: bar (200; 31.349318ms)
Mar  1 13:44:10.452: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-94thk/services/http:proxy-service-7c86j:portname2/proxy/: bar (200; 31.465604ms)
Mar  1 13:44:10.471: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-94thk/pods/https:proxy-service-7c86j-xsqtb:462/proxy/: tls qux (200; 18.871806ms)
Mar  1 13:44:10.475: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-94thk/pods/http:proxy-service-7c86j-xsqtb:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-94thk/pods/http:proxy-service-7c86j-xsqtb:1080/proxy/... (200; 23.687341ms)
Mar  1 13:44:10.475: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-94thk/pods/proxy-service-7c86j-xsqtb/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-94thk/pods/proxy-service-7c86j-xsqtb/proxy/rewriteme"... (200; 23.670212ms)
Mar  1 13:44:10.478: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-94thk/pods/proxy-service-7c86j-xsqtb:160/proxy/: foo (200; 26.27476ms)
Mar  1 13:44:10.480: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-94thk/pods/proxy-service-7c86j-xsqtb:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-94thk/pods/proxy-service-7c86j-xsqtb:1080/proxy/rewri... (200; 28.031525ms)
Mar  1 13:44:10.482: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-94thk/pods/https:proxy-service-7c86j-xsqtb:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-94thk/pods/https:proxy-service-7c86j-xsqtb:443/proxy/... (200; 29.793425ms)
Mar  1 13:44:10.482: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-94thk/pods/http:proxy-service-7c86j-xsqtb:162/proxy/: bar (200; 30.132044ms)
Mar  1 13:44:10.482: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-94thk/services/http:proxy-service-7c86j:portname1/proxy/: foo (200; 30.156145ms)
Mar  1 13:44:10.482: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-94thk/pods/https:proxy-service-7c86j-xsqtb:460/proxy/: tls baz (200; 30.032231ms)
Mar  1 13:44:10.482: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-94thk/pods/proxy-service-7c86j-xsqtb:162/proxy/: bar (200; 30.071992ms)
Mar  1 13:44:10.482: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-94thk/pods/http:proxy-service-7c86j-xsqtb:160/proxy/: foo (200; 30.101192ms)
Mar  1 13:44:10.484: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-94thk/services/proxy-service-7c86j:portname2/proxy/: bar (200; 32.689285ms)
Mar  1 13:44:10.485: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-94thk/services/https:proxy-service-7c86j:tlsportname2/proxy/: tls qux (200; 33.036078ms)
Mar  1 13:44:10.485: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-94thk/services/proxy-service-7c86j:portname1/proxy/: foo (200; 33.307045ms)
Mar  1 13:44:10.485: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-94thk/services/https:proxy-service-7c86j:tlsportname1/proxy/: tls baz (200; 33.568237ms)
Mar  1 13:44:10.485: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-94thk/services/http:proxy-service-7c86j:portname2/proxy/: bar (200; 33.646791ms)
Mar  1 13:44:10.507: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-94thk/pods/http:proxy-service-7c86j-xsqtb:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-94thk/pods/http:proxy-service-7c86j-xsqtb:1080/proxy/... (200; 21.382216ms)
Mar  1 13:44:10.507: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-94thk/pods/https:proxy-service-7c86j-xsqtb:460/proxy/: tls baz (200; 21.380362ms)
Mar  1 13:44:10.509: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-94thk/pods/https:proxy-service-7c86j-xsqtb:462/proxy/: tls qux (200; 23.197907ms)
Mar  1 13:44:10.512: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-94thk/pods/http:proxy-service-7c86j-xsqtb:162/proxy/: bar (200; 26.759596ms)
Mar  1 13:44:10.512: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-94thk/pods/proxy-service-7c86j-xsqtb/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-94thk/pods/proxy-service-7c86j-xsqtb/proxy/rewriteme"... (200; 26.907031ms)
Mar  1 13:44:10.516: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-94thk/pods/https:proxy-service-7c86j-xsqtb:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-94thk/pods/https:proxy-service-7c86j-xsqtb:443/proxy/... (200; 31.093867ms)
Mar  1 13:44:10.517: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-94thk/pods/http:proxy-service-7c86j-xsqtb:160/proxy/: foo (200; 31.67492ms)
Mar  1 13:44:10.518: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-94thk/pods/proxy-service-7c86j-xsqtb:162/proxy/: bar (200; 32.768588ms)
Mar  1 13:44:10.518: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-94thk/services/http:proxy-service-7c86j:portname1/proxy/: foo (200; 32.752523ms)
Mar  1 13:44:10.518: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-94thk/services/http:proxy-service-7c86j:portname2/proxy/: bar (200; 32.905031ms)
Mar  1 13:44:10.519: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-94thk/pods/proxy-service-7c86j-xsqtb:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-94thk/pods/proxy-service-7c86j-xsqtb:1080/proxy/rewri... (200; 33.71307ms)
Mar  1 13:44:10.520: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-94thk/services/https:proxy-service-7c86j:tlsportname2/proxy/: tls qux (200; 34.103238ms)
Mar  1 13:44:10.520: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-94thk/services/proxy-service-7c86j:portname1/proxy/: foo (200; 34.128181ms)
Mar  1 13:44:10.520: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-94thk/services/https:proxy-service-7c86j:tlsportname1/proxy/: tls baz (200; 34.271195ms)
Mar  1 13:44:10.520: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-94thk/pods/proxy-service-7c86j-xsqtb:160/proxy/: foo (200; 34.06392ms)
Mar  1 13:44:10.520: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-94thk/services/proxy-service-7c86j:portname2/proxy/: bar (200; 34.990885ms)
Mar  1 13:44:10.535: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-94thk/pods/proxy-service-7c86j-xsqtb/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-94thk/pods/proxy-service-7c86j-xsqtb/proxy/rewriteme"... (200; 14.1985ms)
Mar  1 13:44:10.543: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-94thk/pods/proxy-service-7c86j-xsqtb:162/proxy/: bar (200; 22.017692ms)
Mar  1 13:44:10.543: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-94thk/services/proxy-service-7c86j:portname1/proxy/: foo (200; 22.631331ms)
Mar  1 13:44:10.544: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-94thk/pods/proxy-service-7c86j-xsqtb:160/proxy/: foo (200; 22.661719ms)
Mar  1 13:44:10.544: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-94thk/services/https:proxy-service-7c86j:tlsportname1/proxy/: tls baz (200; 22.930829ms)
Mar  1 13:44:10.546: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-94thk/pods/https:proxy-service-7c86j-xsqtb:462/proxy/: tls qux (200; 24.005372ms)
Mar  1 13:44:10.546: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-94thk/pods/proxy-service-7c86j-xsqtb:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-94thk/pods/proxy-service-7c86j-xsqtb:1080/proxy/rewri... (200; 24.679301ms)
Mar  1 13:44:10.549: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-94thk/pods/https:proxy-service-7c86j-xsqtb:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-94thk/pods/https:proxy-service-7c86j-xsqtb:443/proxy/... (200; 27.452571ms)
Mar  1 13:44:10.549: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-94thk/pods/https:proxy-service-7c86j-xsqtb:460/proxy/: tls baz (200; 27.117142ms)
Mar  1 13:44:10.552: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-94thk/pods/http:proxy-service-7c86j-xsqtb:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-94thk/pods/http:proxy-service-7c86j-xsqtb:1080/proxy/... (200; 30.668025ms)
Mar  1 13:44:10.552: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-94thk/services/http:proxy-service-7c86j:portname2/proxy/: bar (200; 31.61353ms)
Mar  1 13:44:10.552: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-94thk/pods/http:proxy-service-7c86j-xsqtb:162/proxy/: bar (200; 30.84885ms)
Mar  1 13:44:10.552: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-94thk/pods/http:proxy-service-7c86j-xsqtb:160/proxy/: foo (200; 31.077457ms)
Mar  1 13:44:10.554: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-94thk/services/https:proxy-service-7c86j:tlsportname2/proxy/: tls qux (200; 33.152721ms)
Mar  1 13:44:10.554: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-94thk/services/http:proxy-service-7c86j:portname1/proxy/: foo (200; 33.292725ms)
Mar  1 13:44:10.554: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-94thk/services/proxy-service-7c86j:portname2/proxy/: bar (200; 33.144567ms)
Mar  1 13:44:10.577: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-94thk/pods/https:proxy-service-7c86j-xsqtb:462/proxy/: tls qux (200; 21.479602ms)
Mar  1 13:44:10.582: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-94thk/pods/https:proxy-service-7c86j-xsqtb:460/proxy/: tls baz (200; 26.965758ms)
Mar  1 13:44:10.582: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-94thk/pods/http:proxy-service-7c86j-xsqtb:162/proxy/: bar (200; 27.051ms)
Mar  1 13:44:10.582: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-94thk/pods/https:proxy-service-7c86j-xsqtb:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-94thk/pods/https:proxy-service-7c86j-xsqtb:443/proxy/... (200; 27.242089ms)
Mar  1 13:44:10.582: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-94thk/pods/http:proxy-service-7c86j-xsqtb:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-94thk/pods/http:proxy-service-7c86j-xsqtb:1080/proxy/... (200; 27.148282ms)
Mar  1 13:44:10.582: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-94thk/pods/http:proxy-service-7c86j-xsqtb:160/proxy/: foo (200; 27.347614ms)
Mar  1 13:44:10.582: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-94thk/pods/proxy-service-7c86j-xsqtb:162/proxy/: bar (200; 27.336611ms)
Mar  1 13:44:10.583: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-94thk/services/https:proxy-service-7c86j:tlsportname2/proxy/: tls qux (200; 27.81783ms)
Mar  1 13:44:10.586: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-94thk/services/https:proxy-service-7c86j:tlsportname1/proxy/: tls baz (200; 30.675353ms)
Mar  1 13:44:10.586: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-94thk/services/proxy-service-7c86j:portname1/proxy/: foo (200; 31.525552ms)
Mar  1 13:44:10.588: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-94thk/services/http:proxy-service-7c86j:portname2/proxy/: bar (200; 32.498252ms)
Mar  1 13:44:10.588: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-94thk/services/proxy-service-7c86j:portname2/proxy/: bar (200; 32.790936ms)
Mar  1 13:44:10.589: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-94thk/services/http:proxy-service-7c86j:portname1/proxy/: foo (200; 34.121604ms)
Mar  1 13:44:10.618: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-94thk/pods/proxy-service-7c86j-xsqtb:160/proxy/: foo (200; 63.817592ms)
Mar  1 13:44:10.619: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-94thk/pods/proxy-service-7c86j-xsqtb:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-94thk/pods/proxy-service-7c86j-xsqtb:1080/proxy/rewri... (200; 63.900178ms)
Mar  1 13:44:10.618: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-94thk/pods/proxy-service-7c86j-xsqtb/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-94thk/pods/proxy-service-7c86j-xsqtb/proxy/rewriteme"... (200; 63.957012ms)
Mar  1 13:44:10.647: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-94thk/services/https:proxy-service-7c86j:tlsportname2/proxy/: tls qux (200; 28.522628ms)
Mar  1 13:44:10.648: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-94thk/pods/https:proxy-service-7c86j-xsqtb:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-94thk/pods/https:proxy-service-7c86j-xsqtb:443/proxy/... (200; 29.903319ms)
Mar  1 13:44:10.651: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-94thk/pods/http:proxy-service-7c86j-xsqtb:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-94thk/pods/http:proxy-service-7c86j-xsqtb:1080/proxy/... (200; 31.715795ms)
Mar  1 13:44:10.651: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-94thk/pods/https:proxy-service-7c86j-xsqtb:462/proxy/: tls qux (200; 32.032926ms)
Mar  1 13:44:10.651: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-94thk/pods/https:proxy-service-7c86j-xsqtb:460/proxy/: tls baz (200; 32.24051ms)
Mar  1 13:44:10.652: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-94thk/pods/http:proxy-service-7c86j-xsqtb:160/proxy/: foo (200; 33.052678ms)
Mar  1 13:44:10.652: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-94thk/pods/http:proxy-service-7c86j-xsqtb:162/proxy/: bar (200; 33.052856ms)
Mar  1 13:44:10.652: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-94thk/pods/proxy-service-7c86j-xsqtb:160/proxy/: foo (200; 33.252908ms)
Mar  1 13:44:10.652: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-94thk/pods/proxy-service-7c86j-xsqtb:162/proxy/: bar (200; 33.054099ms)
Mar  1 13:44:10.653: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-94thk/pods/proxy-service-7c86j-xsqtb:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-94thk/pods/proxy-service-7c86j-xsqtb:1080/proxy/rewri... (200; 34.470345ms)
Mar  1 13:44:10.654: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-94thk/pods/proxy-service-7c86j-xsqtb/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-94thk/pods/proxy-service-7c86j-xsqtb/proxy/rewriteme"... (200; 35.120699ms)
Mar  1 13:44:10.655: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-94thk/services/proxy-service-7c86j:portname2/proxy/: bar (200; 36.038735ms)
Mar  1 13:44:10.655: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-94thk/services/http:proxy-service-7c86j:portname2/proxy/: bar (200; 36.156478ms)
Mar  1 13:44:10.655: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-94thk/services/https:proxy-service-7c86j:tlsportname1/proxy/: tls baz (200; 36.165976ms)
Mar  1 13:44:10.655: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-94thk/services/proxy-service-7c86j:portname1/proxy/: foo (200; 36.811558ms)
Mar  1 13:44:10.656: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-94thk/services/http:proxy-service-7c86j:portname1/proxy/: foo (200; 36.765795ms)
Mar  1 13:44:10.674: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-94thk/pods/proxy-service-7c86j-xsqtb:162/proxy/: bar (200; 17.92523ms)
Mar  1 13:44:10.677: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-94thk/pods/proxy-service-7c86j-xsqtb:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-94thk/pods/proxy-service-7c86j-xsqtb:1080/proxy/rewri... (200; 20.937062ms)
Mar  1 13:44:10.682: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-94thk/pods/http:proxy-service-7c86j-xsqtb:160/proxy/: foo (200; 26.161449ms)
Mar  1 13:44:10.685: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-94thk/pods/https:proxy-service-7c86j-xsqtb:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-94thk/pods/https:proxy-service-7c86j-xsqtb:443/proxy/... (200; 29.547005ms)
Mar  1 13:44:10.685: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-94thk/pods/https:proxy-service-7c86j-xsqtb:460/proxy/: tls baz (200; 29.678882ms)
Mar  1 13:44:10.685: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-94thk/pods/http:proxy-service-7c86j-xsqtb:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-94thk/pods/http:proxy-service-7c86j-xsqtb:1080/proxy/... (200; 29.56683ms)
Mar  1 13:44:10.685: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-94thk/pods/http:proxy-service-7c86j-xsqtb:162/proxy/: bar (200; 29.826ms)
Mar  1 13:44:10.685: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-94thk/pods/proxy-service-7c86j-xsqtb:160/proxy/: foo (200; 29.690216ms)
Mar  1 13:44:10.686: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-94thk/services/proxy-service-7c86j:portname1/proxy/: foo (200; 30.059803ms)
Mar  1 13:44:10.686: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-94thk/services/https:proxy-service-7c86j:tlsportname1/proxy/: tls baz (200; 30.514534ms)
Mar  1 13:44:10.686: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-94thk/pods/https:proxy-service-7c86j-xsqtb:462/proxy/: tls qux (200; 30.566676ms)
Mar  1 13:44:10.686: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-94thk/services/proxy-service-7c86j:portname2/proxy/: bar (200; 30.53434ms)
Mar  1 13:44:10.687: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-94thk/pods/proxy-service-7c86j-xsqtb/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-94thk/pods/proxy-service-7c86j-xsqtb/proxy/rewriteme"... (200; 30.95453ms)
Mar  1 13:44:10.687: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-94thk/services/http:proxy-service-7c86j:portname2/proxy/: bar (200; 31.261769ms)
Mar  1 13:44:10.687: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-94thk/services/http:proxy-service-7c86j:portname1/proxy/: foo (200; 31.465337ms)
Mar  1 13:44:10.687: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-94thk/services/https:proxy-service-7c86j:tlsportname2/proxy/: tls qux (200; 31.501016ms)
Mar  1 13:44:10.710: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-94thk/pods/https:proxy-service-7c86j-xsqtb:460/proxy/: tls baz (200; 22.068604ms)
Mar  1 13:44:10.710: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-94thk/pods/proxy-service-7c86j-xsqtb:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-94thk/pods/proxy-service-7c86j-xsqtb:1080/proxy/rewri... (200; 22.23445ms)
Mar  1 13:44:10.710: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-94thk/pods/https:proxy-service-7c86j-xsqtb:462/proxy/: tls qux (200; 22.13493ms)
Mar  1 13:44:10.712: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-94thk/pods/https:proxy-service-7c86j-xsqtb:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-94thk/pods/https:proxy-service-7c86j-xsqtb:443/proxy/... (200; 24.021964ms)
Mar  1 13:44:10.712: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-94thk/pods/proxy-service-7c86j-xsqtb:160/proxy/: foo (200; 24.222795ms)
Mar  1 13:44:10.717: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-94thk/pods/proxy-service-7c86j-xsqtb/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-94thk/pods/proxy-service-7c86j-xsqtb/proxy/rewriteme"... (200; 29.514124ms)
Mar  1 13:44:10.717: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-94thk/pods/http:proxy-service-7c86j-xsqtb:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-94thk/pods/http:proxy-service-7c86j-xsqtb:1080/proxy/... (200; 29.454712ms)
Mar  1 13:44:10.718: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-94thk/pods/http:proxy-service-7c86j-xsqtb:162/proxy/: bar (200; 30.041377ms)
Mar  1 13:44:10.718: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-94thk/pods/http:proxy-service-7c86j-xsqtb:160/proxy/: foo (200; 30.019639ms)
Mar  1 13:44:10.728: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-94thk/services/https:proxy-service-7c86j:tlsportname1/proxy/: tls baz (200; 39.669687ms)
Mar  1 13:44:10.728: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-94thk/services/https:proxy-service-7c86j:tlsportname2/proxy/: tls qux (200; 40.017288ms)
Mar  1 13:44:10.728: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-94thk/services/http:proxy-service-7c86j:portname1/proxy/: foo (200; 40.06839ms)
Mar  1 13:44:10.728: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-94thk/services/proxy-service-7c86j:portname1/proxy/: foo (200; 40.343036ms)
Mar  1 13:44:10.728: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-94thk/pods/proxy-service-7c86j-xsqtb:162/proxy/: bar (200; 39.858293ms)
Mar  1 13:44:10.729: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-94thk/services/http:proxy-service-7c86j:portname2/proxy/: bar (200; 41.393042ms)
Mar  1 13:44:10.729: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-94thk/services/proxy-service-7c86j:portname2/proxy/: bar (200; 41.621372ms)
Mar  1 13:44:10.759: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-94thk/pods/https:proxy-service-7c86j-xsqtb:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-94thk/pods/https:proxy-service-7c86j-xsqtb:443/proxy/... (200; 29.752454ms)
Mar  1 13:44:10.762: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-94thk/pods/http:proxy-service-7c86j-xsqtb:160/proxy/: foo (200; 32.868287ms)
Mar  1 13:44:10.763: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-94thk/services/https:proxy-service-7c86j:tlsportname2/proxy/: tls qux (200; 33.760173ms)
Mar  1 13:44:10.765: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-94thk/pods/https:proxy-service-7c86j-xsqtb:460/proxy/: tls baz (200; 35.640245ms)
Mar  1 13:44:10.765: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-94thk/pods/https:proxy-service-7c86j-xsqtb:462/proxy/: tls qux (200; 35.643523ms)
Mar  1 13:44:10.765: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-94thk/pods/http:proxy-service-7c86j-xsqtb:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-94thk/pods/http:proxy-service-7c86j-xsqtb:1080/proxy/... (200; 35.664898ms)
Mar  1 13:44:10.765: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-94thk/pods/proxy-service-7c86j-xsqtb:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-94thk/pods/proxy-service-7c86j-xsqtb:1080/proxy/rewri... (200; 35.552018ms)
Mar  1 13:44:10.765: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-94thk/pods/proxy-service-7c86j-xsqtb:162/proxy/: bar (200; 35.69307ms)
Mar  1 13:44:10.765: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-94thk/pods/proxy-service-7c86j-xsqtb/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-94thk/pods/proxy-service-7c86j-xsqtb/proxy/rewriteme"... (200; 35.622882ms)
Mar  1 13:44:10.769: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-94thk/pods/http:proxy-service-7c86j-xsqtb:162/proxy/: bar (200; 39.308218ms)
Mar  1 13:44:10.769: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-94thk/pods/proxy-service-7c86j-xsqtb:160/proxy/: foo (200; 39.229205ms)
Mar  1 13:44:10.771: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-94thk/services/http:proxy-service-7c86j:portname2/proxy/: bar (200; 41.513642ms)
Mar  1 13:44:10.771: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-94thk/services/proxy-service-7c86j:portname2/proxy/: bar (200; 41.514856ms)
Mar  1 13:44:10.771: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-94thk/services/http:proxy-service-7c86j:portname1/proxy/: foo (200; 41.617608ms)
Mar  1 13:44:10.771: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-94thk/services/https:proxy-service-7c86j:tlsportname1/proxy/: tls baz (200; 41.586033ms)
Mar  1 13:44:10.774: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-94thk/services/proxy-service-7c86j:portname1/proxy/: foo (200; 44.029508ms)
Mar  1 13:44:10.817: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-94thk/pods/proxy-service-7c86j-xsqtb:160/proxy/: foo (200; 43.687937ms)
Mar  1 13:44:10.818: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-94thk/pods/https:proxy-service-7c86j-xsqtb:462/proxy/: tls qux (200; 43.851681ms)
Mar  1 13:44:10.822: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-94thk/services/https:proxy-service-7c86j:tlsportname2/proxy/: tls qux (200; 48.156603ms)
Mar  1 13:44:10.822: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-94thk/pods/http:proxy-service-7c86j-xsqtb:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-94thk/pods/http:proxy-service-7c86j-xsqtb:1080/proxy/... (200; 48.268189ms)
Mar  1 13:44:10.824: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-94thk/pods/proxy-service-7c86j-xsqtb:162/proxy/: bar (200; 49.827749ms)
Mar  1 13:44:10.824: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-94thk/pods/https:proxy-service-7c86j-xsqtb:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-94thk/pods/https:proxy-service-7c86j-xsqtb:443/proxy/... (200; 49.70913ms)
Mar  1 13:44:10.824: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-94thk/pods/https:proxy-service-7c86j-xsqtb:460/proxy/: tls baz (200; 49.823953ms)
Mar  1 13:44:10.824: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-94thk/pods/proxy-service-7c86j-xsqtb/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-94thk/pods/proxy-service-7c86j-xsqtb/proxy/rewriteme"... (200; 49.786837ms)
Mar  1 13:44:10.824: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-94thk/pods/proxy-service-7c86j-xsqtb:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-94thk/pods/proxy-service-7c86j-xsqtb:1080/proxy/rewri... (200; 50.015059ms)
Mar  1 13:44:10.825: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-94thk/pods/http:proxy-service-7c86j-xsqtb:162/proxy/: bar (200; 51.210922ms)
Mar  1 13:44:10.825: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-94thk/pods/http:proxy-service-7c86j-xsqtb:160/proxy/: foo (200; 51.295691ms)
Mar  1 13:44:10.826: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-94thk/services/https:proxy-service-7c86j:tlsportname1/proxy/: tls baz (200; 52.169109ms)
Mar  1 13:44:10.826: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-94thk/services/proxy-service-7c86j:portname2/proxy/: bar (200; 51.921426ms)
Mar  1 13:44:10.826: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-94thk/services/http:proxy-service-7c86j:portname2/proxy/: bar (200; 52.426829ms)
Mar  1 13:44:10.830: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-94thk/services/proxy-service-7c86j:portname1/proxy/: foo (200; 55.91542ms)
Mar  1 13:44:10.863: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-94thk/services/http:proxy-service-7c86j:portname1/proxy/: foo (200; 88.972149ms)
Mar  1 13:44:10.887: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-94thk/pods/http:proxy-service-7c86j-xsqtb:160/proxy/: foo (200; 23.55062ms)
Mar  1 13:44:10.888: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-94thk/pods/https:proxy-service-7c86j-xsqtb:460/proxy/: tls baz (200; 24.987834ms)
Mar  1 13:44:10.889: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-94thk/pods/proxy-service-7c86j-xsqtb/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-94thk/pods/proxy-service-7c86j-xsqtb/proxy/rewriteme"... (200; 25.535792ms)
Mar  1 13:44:10.890: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-94thk/pods/http:proxy-service-7c86j-xsqtb:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-94thk/pods/http:proxy-service-7c86j-xsqtb:1080/proxy/... (200; 26.527156ms)
Mar  1 13:44:10.890: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-94thk/pods/proxy-service-7c86j-xsqtb:162/proxy/: bar (200; 26.689754ms)
Mar  1 13:44:10.890: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-94thk/pods/proxy-service-7c86j-xsqtb:160/proxy/: foo (200; 26.959431ms)
Mar  1 13:44:10.890: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-94thk/pods/https:proxy-service-7c86j-xsqtb:462/proxy/: tls qux (200; 27.120408ms)
Mar  1 13:44:10.892: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-94thk/pods/https:proxy-service-7c86j-xsqtb:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-94thk/pods/https:proxy-service-7c86j-xsqtb:443/proxy/... (200; 28.391781ms)
Mar  1 13:44:10.892: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-94thk/pods/http:proxy-service-7c86j-xsqtb:162/proxy/: bar (200; 28.475496ms)
Mar  1 13:44:10.892: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-94thk/pods/proxy-service-7c86j-xsqtb:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-94thk/pods/proxy-service-7c86j-xsqtb:1080/proxy/rewri... (200; 28.380613ms)
Mar  1 13:44:10.892: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-94thk/services/http:proxy-service-7c86j:portname1/proxy/: foo (200; 28.630211ms)
Mar  1 13:44:10.892: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-94thk/services/proxy-service-7c86j:portname1/proxy/: foo (200; 28.718207ms)
Mar  1 13:44:10.893: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-94thk/services/http:proxy-service-7c86j:portname2/proxy/: bar (200; 29.622878ms)
Mar  1 13:44:10.893: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-94thk/services/https:proxy-service-7c86j:tlsportname2/proxy/: tls qux (200; 29.35795ms)
Mar  1 13:44:10.893: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-94thk/services/proxy-service-7c86j:portname2/proxy/: bar (200; 29.54058ms)
Mar  1 13:44:10.896: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-94thk/services/https:proxy-service-7c86j:tlsportname1/proxy/: tls baz (200; 32.649526ms)
Mar  1 13:44:10.920: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-94thk/pods/proxy-service-7c86j-xsqtb:162/proxy/: bar (200; 24.281508ms)
Mar  1 13:44:10.921: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-94thk/services/proxy-service-7c86j:portname1/proxy/: foo (200; 25.693988ms)
Mar  1 13:44:10.927: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-94thk/services/https:proxy-service-7c86j:tlsportname1/proxy/: tls baz (200; 31.357192ms)
Mar  1 13:44:10.928: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-94thk/services/https:proxy-service-7c86j:tlsportname2/proxy/: tls qux (200; 32.561823ms)
Mar  1 13:44:10.929: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-94thk/pods/https:proxy-service-7c86j-xsqtb:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-94thk/pods/https:proxy-service-7c86j-xsqtb:443/proxy/... (200; 32.953636ms)
Mar  1 13:44:10.929: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-94thk/pods/proxy-service-7c86j-xsqtb/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-94thk/pods/proxy-service-7c86j-xsqtb/proxy/rewriteme"... (200; 33.288445ms)
Mar  1 13:44:10.929: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-94thk/pods/https:proxy-service-7c86j-xsqtb:462/proxy/: tls qux (200; 33.380693ms)
Mar  1 13:44:10.929: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-94thk/pods/http:proxy-service-7c86j-xsqtb:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-94thk/pods/http:proxy-service-7c86j-xsqtb:1080/proxy/... (200; 33.392299ms)
Mar  1 13:44:10.929: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-94thk/pods/http:proxy-service-7c86j-xsqtb:162/proxy/: bar (200; 33.55832ms)
Mar  1 13:44:10.929: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-94thk/pods/proxy-service-7c86j-xsqtb:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-94thk/pods/proxy-service-7c86j-xsqtb:1080/proxy/rewri... (200; 33.738609ms)
Mar  1 13:44:10.929: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-94thk/services/http:proxy-service-7c86j:portname2/proxy/: bar (200; 33.642182ms)
Mar  1 13:44:10.929: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-94thk/services/http:proxy-service-7c86j:portname1/proxy/: foo (200; 33.722264ms)
Mar  1 13:44:10.930: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-94thk/services/proxy-service-7c86j:portname2/proxy/: bar (200; 33.899361ms)
Mar  1 13:44:10.930: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-94thk/pods/https:proxy-service-7c86j-xsqtb:460/proxy/: tls baz (200; 34.200628ms)
Mar  1 13:44:10.931: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-94thk/pods/http:proxy-service-7c86j-xsqtb:160/proxy/: foo (200; 35.408404ms)
Mar  1 13:44:10.931: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-94thk/pods/proxy-service-7c86j-xsqtb:160/proxy/: foo (200; 35.788015ms)
Mar  1 13:44:10.963: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-94thk/pods/http:proxy-service-7c86j-xsqtb:162/proxy/: bar (200; 31.207591ms)
Mar  1 13:44:10.967: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-94thk/pods/proxy-service-7c86j-xsqtb:160/proxy/: foo (200; 35.048241ms)
Mar  1 13:44:10.967: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-94thk/pods/https:proxy-service-7c86j-xsqtb:462/proxy/: tls qux (200; 34.845397ms)
Mar  1 13:44:10.970: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-94thk/pods/http:proxy-service-7c86j-xsqtb:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-94thk/pods/http:proxy-service-7c86j-xsqtb:1080/proxy/... (200; 38.015585ms)
Mar  1 13:44:10.971: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-94thk/pods/proxy-service-7c86j-xsqtb:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-94thk/pods/proxy-service-7c86j-xsqtb:1080/proxy/rewri... (200; 38.627091ms)
Mar  1 13:44:10.972: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-94thk/pods/proxy-service-7c86j-xsqtb:162/proxy/: bar (200; 39.890633ms)
Mar  1 13:44:10.972: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-94thk/pods/https:proxy-service-7c86j-xsqtb:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-94thk/pods/https:proxy-service-7c86j-xsqtb:443/proxy/... (200; 40.164244ms)
Mar  1 13:44:10.972: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-94thk/services/http:proxy-service-7c86j:portname1/proxy/: foo (200; 40.475136ms)
Mar  1 13:44:10.972: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-94thk/pods/https:proxy-service-7c86j-xsqtb:460/proxy/: tls baz (200; 40.173721ms)
Mar  1 13:44:10.973: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-94thk/pods/proxy-service-7c86j-xsqtb/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-94thk/pods/proxy-service-7c86j-xsqtb/proxy/rewriteme"... (200; 40.646824ms)
Mar  1 13:44:10.975: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-94thk/services/https:proxy-service-7c86j:tlsportname2/proxy/: tls qux (200; 42.609835ms)
Mar  1 13:44:10.975: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-94thk/services/https:proxy-service-7c86j:tlsportname1/proxy/: tls baz (200; 43.420873ms)
Mar  1 13:44:10.976: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-94thk/services/proxy-service-7c86j:portname1/proxy/: foo (200; 43.86761ms)
Mar  1 13:44:10.976: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-94thk/services/http:proxy-service-7c86j:portname2/proxy/: bar (200; 43.393468ms)
Mar  1 13:44:10.976: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-94thk/pods/http:proxy-service-7c86j-xsqtb:160/proxy/: foo (200; 43.30313ms)
Mar  1 13:44:10.976: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-94thk/services/proxy-service-7c86j:portname2/proxy/: bar (200; 43.622428ms)
Mar  1 13:44:11.000: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-94thk/pods/http:proxy-service-7c86j-xsqtb:160/proxy/: foo (200; 23.36368ms)
Mar  1 13:44:11.003: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-94thk/pods/https:proxy-service-7c86j-xsqtb:462/proxy/: tls qux (200; 26.498642ms)
Mar  1 13:44:11.003: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-94thk/pods/proxy-service-7c86j-xsqtb:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-94thk/pods/proxy-service-7c86j-xsqtb:1080/proxy/rewri... (200; 27.007579ms)
Mar  1 13:44:11.006: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-94thk/pods/proxy-service-7c86j-xsqtb:160/proxy/: foo (200; 30.376119ms)
Mar  1 13:44:11.006: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-94thk/pods/proxy-service-7c86j-xsqtb:162/proxy/: bar (200; 30.094898ms)
Mar  1 13:44:11.007: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-94thk/pods/proxy-service-7c86j-xsqtb/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-94thk/pods/proxy-service-7c86j-xsqtb/proxy/rewriteme"... (200; 30.599899ms)
Mar  1 13:44:11.009: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-94thk/pods/http:proxy-service-7c86j-xsqtb:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-94thk/pods/http:proxy-service-7c86j-xsqtb:1080/proxy/... (200; 32.252405ms)
Mar  1 13:44:11.009: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-94thk/pods/http:proxy-service-7c86j-xsqtb:162/proxy/: bar (200; 32.501002ms)
Mar  1 13:44:11.009: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-94thk/pods/https:proxy-service-7c86j-xsqtb:460/proxy/: tls baz (200; 32.535288ms)
Mar  1 13:44:11.009: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-94thk/pods/https:proxy-service-7c86j-xsqtb:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-94thk/pods/https:proxy-service-7c86j-xsqtb:443/proxy/... (200; 32.803689ms)
Mar  1 13:44:11.015: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-94thk/services/https:proxy-service-7c86j:tlsportname2/proxy/: tls qux (200; 38.817643ms)
Mar  1 13:44:11.019: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-94thk/services/proxy-service-7c86j:portname2/proxy/: bar (200; 42.444899ms)
Mar  1 13:44:11.019: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-94thk/services/http:proxy-service-7c86j:portname1/proxy/: foo (200; 42.574345ms)
Mar  1 13:44:11.019: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-94thk/services/proxy-service-7c86j:portname1/proxy/: foo (200; 42.230604ms)
Mar  1 13:44:11.019: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-94thk/services/https:proxy-service-7c86j:tlsportname1/proxy/: tls baz (200; 42.852159ms)
Mar  1 13:44:11.019: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-94thk/services/http:proxy-service-7c86j:portname2/proxy/: bar (200; 42.208961ms)
Mar  1 13:44:11.043: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-94thk/pods/https:proxy-service-7c86j-xsqtb:462/proxy/: tls qux (200; 23.608541ms)
Mar  1 13:44:11.046: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-94thk/pods/proxy-service-7c86j-xsqtb:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-94thk/pods/proxy-service-7c86j-xsqtb:1080/proxy/rewri... (200; 26.131348ms)
Mar  1 13:44:11.046: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-94thk/pods/http:proxy-service-7c86j-xsqtb:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-94thk/pods/http:proxy-service-7c86j-xsqtb:1080/proxy/... (200; 26.454818ms)
Mar  1 13:44:11.046: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-94thk/pods/https:proxy-service-7c86j-xsqtb:460/proxy/: tls baz (200; 26.600283ms)
Mar  1 13:44:11.048: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-94thk/pods/http:proxy-service-7c86j-xsqtb:162/proxy/: bar (200; 29.061227ms)
Mar  1 13:44:11.049: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-94thk/pods/proxy-service-7c86j-xsqtb/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-94thk/pods/proxy-service-7c86j-xsqtb/proxy/rewriteme"... (200; 30.040166ms)
Mar  1 13:44:11.050: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-94thk/pods/proxy-service-7c86j-xsqtb:160/proxy/: foo (200; 30.247839ms)
Mar  1 13:44:11.050: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-94thk/pods/proxy-service-7c86j-xsqtb:162/proxy/: bar (200; 30.564438ms)
Mar  1 13:44:11.050: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-94thk/services/https:proxy-service-7c86j:tlsportname2/proxy/: tls qux (200; 30.905056ms)
Mar  1 13:44:11.051: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-94thk/pods/http:proxy-service-7c86j-xsqtb:160/proxy/: foo (200; 31.633545ms)
Mar  1 13:44:11.051: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-94thk/pods/https:proxy-service-7c86j-xsqtb:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-94thk/pods/https:proxy-service-7c86j-xsqtb:443/proxy/... (200; 32.042924ms)
Mar  1 13:44:11.052: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-94thk/services/https:proxy-service-7c86j:tlsportname1/proxy/: tls baz (200; 33.098219ms)
Mar  1 13:44:11.052: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-94thk/services/http:proxy-service-7c86j:portname2/proxy/: bar (200; 33.345928ms)
Mar  1 13:44:11.056: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-94thk/services/proxy-service-7c86j:portname1/proxy/: foo (200; 36.346712ms)
Mar  1 13:44:11.056: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-94thk/services/http:proxy-service-7c86j:portname1/proxy/: foo (200; 36.296518ms)
Mar  1 13:44:11.056: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-94thk/services/proxy-service-7c86j:portname2/proxy/: bar (200; 36.093574ms)
Mar  1 13:44:11.081: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-94thk/pods/https:proxy-service-7c86j-xsqtb:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-94thk/pods/https:proxy-service-7c86j-xsqtb:443/proxy/... (200; 24.84898ms)
Mar  1 13:44:11.082: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-94thk/pods/https:proxy-service-7c86j-xsqtb:460/proxy/: tls baz (200; 26.403511ms)
Mar  1 13:44:11.084: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-94thk/pods/http:proxy-service-7c86j-xsqtb:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-94thk/pods/http:proxy-service-7c86j-xsqtb:1080/proxy/... (200; 28.208656ms)
Mar  1 13:44:11.084: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-94thk/pods/proxy-service-7c86j-xsqtb/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-94thk/pods/proxy-service-7c86j-xsqtb/proxy/rewriteme"... (200; 28.403214ms)
Mar  1 13:44:11.085: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-94thk/pods/https:proxy-service-7c86j-xsqtb:462/proxy/: tls qux (200; 28.674072ms)
Mar  1 13:44:11.086: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-94thk/pods/http:proxy-service-7c86j-xsqtb:162/proxy/: bar (200; 30.374388ms)
Mar  1 13:44:11.086: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-94thk/pods/proxy-service-7c86j-xsqtb:160/proxy/: foo (200; 30.403074ms)
Mar  1 13:44:11.086: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-94thk/pods/proxy-service-7c86j-xsqtb:162/proxy/: bar (200; 30.487638ms)
Mar  1 13:44:11.086: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-94thk/pods/http:proxy-service-7c86j-xsqtb:160/proxy/: foo (200; 30.320298ms)
Mar  1 13:44:11.088: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-94thk/services/https:proxy-service-7c86j:tlsportname2/proxy/: tls qux (200; 32.259792ms)
Mar  1 13:44:11.088: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-94thk/services/http:proxy-service-7c86j:portname2/proxy/: bar (200; 32.506275ms)
Mar  1 13:44:11.088: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-94thk/pods/proxy-service-7c86j-xsqtb:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-94thk/pods/proxy-service-7c86j-xsqtb:1080/proxy/rewri... (200; 32.357099ms)
Mar  1 13:44:11.089: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-94thk/services/http:proxy-service-7c86j:portname1/proxy/: foo (200; 32.742084ms)
Mar  1 13:44:11.089: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-94thk/services/proxy-service-7c86j:portname2/proxy/: bar (200; 32.907211ms)
Mar  1 13:44:11.089: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-94thk/services/proxy-service-7c86j:portname1/proxy/: foo (200; 32.873935ms)
Mar  1 13:44:11.125: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-94thk/services/https:proxy-service-7c86j:tlsportname1/proxy/: tls baz (200; 69.084166ms)
Mar  1 13:44:11.149: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-94thk/pods/https:proxy-service-7c86j-xsqtb:462/proxy/: tls qux (200; 23.766094ms)
Mar  1 13:44:11.153: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-94thk/pods/proxy-service-7c86j-xsqtb/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-94thk/pods/proxy-service-7c86j-xsqtb/proxy/rewriteme"... (200; 27.765246ms)
Mar  1 13:44:11.157: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-94thk/pods/proxy-service-7c86j-xsqtb:160/proxy/: foo (200; 31.673998ms)
Mar  1 13:44:11.158: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-94thk/services/https:proxy-service-7c86j:tlsportname1/proxy/: tls baz (200; 33.044033ms)
Mar  1 13:44:11.161: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-94thk/services/proxy-service-7c86j:portname2/proxy/: bar (200; 36.200538ms)
Mar  1 13:44:11.161: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-94thk/services/http:proxy-service-7c86j:portname2/proxy/: bar (200; 36.515821ms)
Mar  1 13:44:11.162: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-94thk/pods/http:proxy-service-7c86j-xsqtb:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-94thk/pods/http:proxy-service-7c86j-xsqtb:1080/proxy/... (200; 36.500646ms)
Mar  1 13:44:11.161: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-94thk/pods/proxy-service-7c86j-xsqtb:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-94thk/pods/proxy-service-7c86j-xsqtb:1080/proxy/rewri... (200; 36.328146ms)
Mar  1 13:44:11.162: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-94thk/services/https:proxy-service-7c86j:tlsportname2/proxy/: tls qux (200; 37.007678ms)
Mar  1 13:44:11.163: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-94thk/pods/https:proxy-service-7c86j-xsqtb:460/proxy/: tls baz (200; 37.391748ms)
Mar  1 13:44:11.163: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-94thk/pods/https:proxy-service-7c86j-xsqtb:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-94thk/pods/https:proxy-service-7c86j-xsqtb:443/proxy/... (200; 37.870137ms)
Mar  1 13:44:11.163: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-94thk/pods/http:proxy-service-7c86j-xsqtb:160/proxy/: foo (200; 38.180059ms)
Mar  1 13:44:11.163: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-94thk/pods/proxy-service-7c86j-xsqtb:162/proxy/: bar (200; 38.05224ms)
Mar  1 13:44:11.163: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-94thk/pods/http:proxy-service-7c86j-xsqtb:162/proxy/: bar (200; 38.034615ms)
Mar  1 13:44:11.164: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-94thk/services/http:proxy-service-7c86j:portname1/proxy/: foo (200; 38.308127ms)
Mar  1 13:44:11.165: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-94thk/services/proxy-service-7c86j:portname1/proxy/: foo (200; 40.353298ms)
Mar  1 13:44:11.184: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-94thk/pods/https:proxy-service-7c86j-xsqtb:462/proxy/: tls qux (200; 18.540814ms)
Mar  1 13:44:11.186: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-94thk/pods/https:proxy-service-7c86j-xsqtb:460/proxy/: tls baz (200; 20.525973ms)
Mar  1 13:44:11.186: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-94thk/pods/https:proxy-service-7c86j-xsqtb:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-94thk/pods/https:proxy-service-7c86j-xsqtb:443/proxy/... (200; 20.750308ms)
Mar  1 13:44:11.188: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-94thk/pods/proxy-service-7c86j-xsqtb:162/proxy/: bar (200; 22.308028ms)
Mar  1 13:44:11.194: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-94thk/pods/proxy-service-7c86j-xsqtb:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-94thk/pods/proxy-service-7c86j-xsqtb:1080/proxy/rewri... (200; 28.518351ms)
Mar  1 13:44:11.195: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-94thk/services/https:proxy-service-7c86j:tlsportname1/proxy/: tls baz (200; 29.268265ms)
Mar  1 13:44:11.195: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-94thk/pods/http:proxy-service-7c86j-xsqtb:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-94thk/pods/http:proxy-service-7c86j-xsqtb:1080/proxy/... (200; 28.949267ms)
Mar  1 13:44:11.195: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-94thk/pods/proxy-service-7c86j-xsqtb/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-94thk/pods/proxy-service-7c86j-xsqtb/proxy/rewriteme"... (200; 28.999132ms)
Mar  1 13:44:11.195: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-94thk/pods/http:proxy-service-7c86j-xsqtb:160/proxy/: foo (200; 28.937009ms)
Mar  1 13:44:11.195: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-94thk/pods/http:proxy-service-7c86j-xsqtb:162/proxy/: bar (200; 29.298302ms)
Mar  1 13:44:11.195: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-94thk/pods/proxy-service-7c86j-xsqtb:160/proxy/: foo (200; 29.239224ms)
Mar  1 13:44:11.195: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-94thk/services/http:proxy-service-7c86j:portname2/proxy/: bar (200; 29.659554ms)
Mar  1 13:44:11.198: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-94thk/services/http:proxy-service-7c86j:portname1/proxy/: foo (200; 32.409042ms)
Mar  1 13:44:11.198: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-94thk/services/proxy-service-7c86j:portname2/proxy/: bar (200; 32.307845ms)
Mar  1 13:44:11.198: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-94thk/services/proxy-service-7c86j:portname1/proxy/: foo (200; 32.491589ms)
Mar  1 13:44:11.232: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-94thk/services/https:proxy-service-7c86j:tlsportname2/proxy/: tls qux (200; 65.784097ms)
Mar  1 13:44:11.256: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-94thk/pods/https:proxy-service-7c86j-xsqtb:460/proxy/: tls baz (200; 23.606757ms)
Mar  1 13:44:11.261: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-94thk/pods/proxy-service-7c86j-xsqtb:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-94thk/pods/proxy-service-7c86j-xsqtb:1080/proxy/rewri... (200; 28.552422ms)
Mar  1 13:44:11.261: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-94thk/services/https:proxy-service-7c86j:tlsportname1/proxy/: tls baz (200; 28.670238ms)
Mar  1 13:44:11.261: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-94thk/pods/proxy-service-7c86j-xsqtb/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-94thk/pods/proxy-service-7c86j-xsqtb/proxy/rewriteme"... (200; 28.739105ms)
Mar  1 13:44:11.261: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-94thk/pods/proxy-service-7c86j-xsqtb:162/proxy/: bar (200; 28.670479ms)
Mar  1 13:44:11.262: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-94thk/pods/https:proxy-service-7c86j-xsqtb:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-94thk/pods/https:proxy-service-7c86j-xsqtb:443/proxy/... (200; 30.243146ms)
Mar  1 13:44:11.267: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-94thk/pods/proxy-service-7c86j-xsqtb:160/proxy/: foo (200; 34.91139ms)
Mar  1 13:44:11.267: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-94thk/services/https:proxy-service-7c86j:tlsportname2/proxy/: tls qux (200; 35.047698ms)
Mar  1 13:44:11.267: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-94thk/pods/https:proxy-service-7c86j-xsqtb:462/proxy/: tls qux (200; 35.265308ms)
Mar  1 13:44:11.267: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-94thk/pods/http:proxy-service-7c86j-xsqtb:160/proxy/: foo (200; 35.095116ms)
Mar  1 13:44:11.267: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-94thk/pods/http:proxy-service-7c86j-xsqtb:162/proxy/: bar (200; 35.110608ms)
Mar  1 13:44:11.270: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-94thk/services/proxy-service-7c86j:portname2/proxy/: bar (200; 37.911563ms)
Mar  1 13:44:11.270: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-94thk/pods/http:proxy-service-7c86j-xsqtb:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-94thk/pods/http:proxy-service-7c86j-xsqtb:1080/proxy/... (200; 37.87722ms)
Mar  1 13:44:11.270: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-94thk/services/http:proxy-service-7c86j:portname2/proxy/: bar (200; 38.001402ms)
Mar  1 13:44:11.270: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-94thk/services/http:proxy-service-7c86j:portname1/proxy/: foo (200; 38.346546ms)
Mar  1 13:44:11.271: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-94thk/services/proxy-service-7c86j:portname1/proxy/: foo (200; 38.73608ms)
STEP: deleting { ReplicationController} proxy-service-7c86j in namespace e2e-tests-proxy-94thk, will wait for the garbage collector to delete the pods
Mar  1 13:44:11.333: INFO: Deleting { ReplicationController} proxy-service-7c86j took: 7.777386ms
Mar  1 13:44:11.433: INFO: Terminating { ReplicationController} proxy-service-7c86j pods took: 100.334977ms
[AfterEach] version v1
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 13:44:12.833: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-proxy-94thk" for this suite.
Mar  1 13:44:18.851: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 13:44:18.985: INFO: namespace: e2e-tests-proxy-94thk, resource: bindings, ignored listing per whitelist
Mar  1 13:44:19.004: INFO: namespace e2e-tests-proxy-94thk deletion completed in 6.164889482s

• [SLOW TEST:16.853 seconds]
[sig-network] Proxy
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy through a service and a pod  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 13:44:19.004: INFO: >>> kubeConfig: /tmp/kubeconfig-210205575
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:98
[It] should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Mar  1 13:44:19.249: INFO: Creating simple daemon set daemon-set
STEP: Check that daemon pods launch on every node of the cluster.
Mar  1 13:44:19.293: INFO: Number of nodes with available pods: 0
Mar  1 13:44:19.293: INFO: Node gke-conformance-default-pool-eca581b0-00fq is running more than one daemon pod
Mar  1 13:44:20.305: INFO: Number of nodes with available pods: 0
Mar  1 13:44:20.305: INFO: Node gke-conformance-default-pool-eca581b0-00fq is running more than one daemon pod
Mar  1 13:44:21.301: INFO: Number of nodes with available pods: 1
Mar  1 13:44:21.301: INFO: Node gke-conformance-default-pool-eca581b0-00fq is running more than one daemon pod
Mar  1 13:44:22.311: INFO: Number of nodes with available pods: 4
Mar  1 13:44:22.311: INFO: Node gke-conformance-default-pool-eca581b0-40vx is running more than one daemon pod
Mar  1 13:44:23.314: INFO: Number of nodes with available pods: 5
Mar  1 13:44:23.314: INFO: Number of running nodes: 5, number of available pods: 5
STEP: Update daemon pods image.
STEP: Check that daemon pods images are updated.
Mar  1 13:44:23.411: INFO: Wrong image for pod: daemon-set-r6ktj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:44:23.411: INFO: Wrong image for pod: daemon-set-smq4n. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:44:23.411: INFO: Wrong image for pod: daemon-set-snhsp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:44:23.411: INFO: Wrong image for pod: daemon-set-t7bnk. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:44:23.411: INFO: Wrong image for pod: daemon-set-vl87b. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:44:24.437: INFO: Wrong image for pod: daemon-set-r6ktj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:44:24.437: INFO: Wrong image for pod: daemon-set-smq4n. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:44:24.437: INFO: Wrong image for pod: daemon-set-snhsp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:44:24.437: INFO: Wrong image for pod: daemon-set-t7bnk. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:44:24.437: INFO: Wrong image for pod: daemon-set-vl87b. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:44:25.438: INFO: Wrong image for pod: daemon-set-r6ktj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:44:25.438: INFO: Wrong image for pod: daemon-set-smq4n. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:44:25.438: INFO: Wrong image for pod: daemon-set-snhsp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:44:25.438: INFO: Wrong image for pod: daemon-set-t7bnk. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:44:25.438: INFO: Wrong image for pod: daemon-set-vl87b. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:44:26.437: INFO: Wrong image for pod: daemon-set-r6ktj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:44:26.437: INFO: Wrong image for pod: daemon-set-smq4n. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:44:26.437: INFO: Wrong image for pod: daemon-set-snhsp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:44:26.437: INFO: Wrong image for pod: daemon-set-t7bnk. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:44:26.437: INFO: Wrong image for pod: daemon-set-vl87b. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:44:27.437: INFO: Wrong image for pod: daemon-set-r6ktj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:44:27.437: INFO: Wrong image for pod: daemon-set-smq4n. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:44:27.437: INFO: Wrong image for pod: daemon-set-snhsp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:44:27.437: INFO: Wrong image for pod: daemon-set-t7bnk. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:44:27.437: INFO: Wrong image for pod: daemon-set-vl87b. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:44:28.437: INFO: Wrong image for pod: daemon-set-r6ktj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:44:28.437: INFO: Wrong image for pod: daemon-set-smq4n. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:44:28.437: INFO: Wrong image for pod: daemon-set-snhsp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:44:28.437: INFO: Wrong image for pod: daemon-set-t7bnk. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:44:28.437: INFO: Wrong image for pod: daemon-set-vl87b. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:44:29.436: INFO: Wrong image for pod: daemon-set-r6ktj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:44:29.436: INFO: Wrong image for pod: daemon-set-smq4n. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:44:29.436: INFO: Wrong image for pod: daemon-set-snhsp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:44:29.436: INFO: Wrong image for pod: daemon-set-t7bnk. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:44:29.436: INFO: Wrong image for pod: daemon-set-vl87b. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:44:30.437: INFO: Wrong image for pod: daemon-set-r6ktj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:44:30.437: INFO: Wrong image for pod: daemon-set-smq4n. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:44:30.437: INFO: Wrong image for pod: daemon-set-snhsp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:44:30.437: INFO: Wrong image for pod: daemon-set-t7bnk. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:44:30.437: INFO: Wrong image for pod: daemon-set-vl87b. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:44:31.447: INFO: Wrong image for pod: daemon-set-r6ktj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:44:31.447: INFO: Wrong image for pod: daemon-set-smq4n. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:44:31.447: INFO: Wrong image for pod: daemon-set-snhsp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:44:31.447: INFO: Wrong image for pod: daemon-set-t7bnk. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:44:31.447: INFO: Wrong image for pod: daemon-set-vl87b. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:44:32.437: INFO: Wrong image for pod: daemon-set-r6ktj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:44:32.437: INFO: Wrong image for pod: daemon-set-smq4n. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:44:32.437: INFO: Wrong image for pod: daemon-set-snhsp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:44:32.437: INFO: Wrong image for pod: daemon-set-t7bnk. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:44:32.437: INFO: Wrong image for pod: daemon-set-vl87b. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:44:33.437: INFO: Wrong image for pod: daemon-set-r6ktj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:44:33.437: INFO: Wrong image for pod: daemon-set-smq4n. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:44:33.437: INFO: Wrong image for pod: daemon-set-snhsp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:44:33.437: INFO: Wrong image for pod: daemon-set-t7bnk. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:44:33.437: INFO: Wrong image for pod: daemon-set-vl87b. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:44:34.437: INFO: Wrong image for pod: daemon-set-r6ktj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:44:34.437: INFO: Wrong image for pod: daemon-set-smq4n. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:44:34.437: INFO: Wrong image for pod: daemon-set-snhsp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:44:34.437: INFO: Wrong image for pod: daemon-set-t7bnk. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:44:34.437: INFO: Wrong image for pod: daemon-set-vl87b. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:44:35.436: INFO: Wrong image for pod: daemon-set-r6ktj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:44:35.437: INFO: Wrong image for pod: daemon-set-smq4n. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:44:35.437: INFO: Wrong image for pod: daemon-set-snhsp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:44:35.437: INFO: Wrong image for pod: daemon-set-t7bnk. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:44:35.437: INFO: Wrong image for pod: daemon-set-vl87b. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:44:36.437: INFO: Wrong image for pod: daemon-set-r6ktj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:44:36.437: INFO: Wrong image for pod: daemon-set-smq4n. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:44:36.437: INFO: Wrong image for pod: daemon-set-snhsp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:44:36.437: INFO: Wrong image for pod: daemon-set-t7bnk. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:44:36.437: INFO: Wrong image for pod: daemon-set-vl87b. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:44:37.437: INFO: Wrong image for pod: daemon-set-r6ktj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:44:37.437: INFO: Wrong image for pod: daemon-set-smq4n. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:44:37.437: INFO: Wrong image for pod: daemon-set-snhsp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:44:37.437: INFO: Wrong image for pod: daemon-set-t7bnk. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:44:37.437: INFO: Wrong image for pod: daemon-set-vl87b. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:44:38.437: INFO: Wrong image for pod: daemon-set-r6ktj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:44:38.437: INFO: Wrong image for pod: daemon-set-smq4n. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:44:38.437: INFO: Wrong image for pod: daemon-set-snhsp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:44:38.437: INFO: Wrong image for pod: daemon-set-t7bnk. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:44:38.437: INFO: Wrong image for pod: daemon-set-vl87b. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:44:39.437: INFO: Wrong image for pod: daemon-set-r6ktj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:44:39.437: INFO: Wrong image for pod: daemon-set-smq4n. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:44:39.437: INFO: Wrong image for pod: daemon-set-snhsp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:44:39.437: INFO: Wrong image for pod: daemon-set-t7bnk. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:44:39.437: INFO: Wrong image for pod: daemon-set-vl87b. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:44:40.437: INFO: Wrong image for pod: daemon-set-r6ktj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:44:40.437: INFO: Wrong image for pod: daemon-set-smq4n. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:44:40.437: INFO: Wrong image for pod: daemon-set-snhsp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:44:40.437: INFO: Wrong image for pod: daemon-set-t7bnk. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:44:40.437: INFO: Wrong image for pod: daemon-set-vl87b. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:44:41.437: INFO: Wrong image for pod: daemon-set-r6ktj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:44:41.437: INFO: Wrong image for pod: daemon-set-smq4n. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:44:41.437: INFO: Wrong image for pod: daemon-set-snhsp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:44:41.437: INFO: Wrong image for pod: daemon-set-t7bnk. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:44:41.437: INFO: Wrong image for pod: daemon-set-vl87b. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:44:42.438: INFO: Wrong image for pod: daemon-set-r6ktj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:44:42.438: INFO: Wrong image for pod: daemon-set-smq4n. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:44:42.438: INFO: Wrong image for pod: daemon-set-snhsp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:44:42.438: INFO: Wrong image for pod: daemon-set-t7bnk. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:44:42.438: INFO: Wrong image for pod: daemon-set-vl87b. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:44:43.437: INFO: Wrong image for pod: daemon-set-r6ktj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:44:43.437: INFO: Wrong image for pod: daemon-set-smq4n. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:44:43.437: INFO: Wrong image for pod: daemon-set-snhsp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:44:43.437: INFO: Wrong image for pod: daemon-set-t7bnk. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:44:43.437: INFO: Wrong image for pod: daemon-set-vl87b. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:44:44.436: INFO: Wrong image for pod: daemon-set-r6ktj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:44:44.436: INFO: Wrong image for pod: daemon-set-smq4n. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:44:44.436: INFO: Wrong image for pod: daemon-set-snhsp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:44:44.436: INFO: Wrong image for pod: daemon-set-t7bnk. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:44:44.436: INFO: Wrong image for pod: daemon-set-vl87b. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:44:45.437: INFO: Wrong image for pod: daemon-set-r6ktj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:44:45.437: INFO: Wrong image for pod: daemon-set-smq4n. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:44:45.437: INFO: Wrong image for pod: daemon-set-snhsp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:44:45.437: INFO: Wrong image for pod: daemon-set-t7bnk. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:44:45.437: INFO: Wrong image for pod: daemon-set-vl87b. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:44:46.437: INFO: Wrong image for pod: daemon-set-r6ktj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:44:46.437: INFO: Wrong image for pod: daemon-set-smq4n. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:44:46.437: INFO: Wrong image for pod: daemon-set-snhsp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:44:46.437: INFO: Wrong image for pod: daemon-set-t7bnk. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:44:46.437: INFO: Wrong image for pod: daemon-set-vl87b. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:44:47.437: INFO: Wrong image for pod: daemon-set-r6ktj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:44:47.437: INFO: Wrong image for pod: daemon-set-smq4n. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:44:47.437: INFO: Wrong image for pod: daemon-set-snhsp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:44:47.437: INFO: Wrong image for pod: daemon-set-t7bnk. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:44:47.437: INFO: Wrong image for pod: daemon-set-vl87b. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:44:48.437: INFO: Wrong image for pod: daemon-set-r6ktj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:44:48.437: INFO: Wrong image for pod: daemon-set-smq4n. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:44:48.437: INFO: Wrong image for pod: daemon-set-snhsp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:44:48.437: INFO: Wrong image for pod: daemon-set-t7bnk. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:44:48.437: INFO: Wrong image for pod: daemon-set-vl87b. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:44:49.437: INFO: Wrong image for pod: daemon-set-r6ktj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:44:49.437: INFO: Wrong image for pod: daemon-set-smq4n. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:44:49.437: INFO: Wrong image for pod: daemon-set-snhsp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:44:49.437: INFO: Wrong image for pod: daemon-set-t7bnk. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:44:49.437: INFO: Wrong image for pod: daemon-set-vl87b. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:44:50.437: INFO: Wrong image for pod: daemon-set-r6ktj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:44:50.437: INFO: Wrong image for pod: daemon-set-smq4n. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:44:50.437: INFO: Wrong image for pod: daemon-set-snhsp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:44:50.437: INFO: Wrong image for pod: daemon-set-t7bnk. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:44:50.437: INFO: Wrong image for pod: daemon-set-vl87b. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:44:51.437: INFO: Wrong image for pod: daemon-set-r6ktj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:44:51.437: INFO: Wrong image for pod: daemon-set-smq4n. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:44:51.437: INFO: Wrong image for pod: daemon-set-snhsp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:44:51.437: INFO: Wrong image for pod: daemon-set-t7bnk. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:44:51.437: INFO: Wrong image for pod: daemon-set-vl87b. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:44:52.437: INFO: Wrong image for pod: daemon-set-r6ktj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:44:52.437: INFO: Wrong image for pod: daemon-set-smq4n. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:44:52.437: INFO: Wrong image for pod: daemon-set-snhsp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:44:52.437: INFO: Wrong image for pod: daemon-set-t7bnk. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:44:52.437: INFO: Wrong image for pod: daemon-set-vl87b. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:44:53.437: INFO: Wrong image for pod: daemon-set-r6ktj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:44:53.437: INFO: Wrong image for pod: daemon-set-smq4n. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:44:53.437: INFO: Wrong image for pod: daemon-set-snhsp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:44:53.437: INFO: Wrong image for pod: daemon-set-t7bnk. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:44:53.437: INFO: Wrong image for pod: daemon-set-vl87b. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:44:54.437: INFO: Wrong image for pod: daemon-set-r6ktj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:44:54.437: INFO: Wrong image for pod: daemon-set-smq4n. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:44:54.437: INFO: Wrong image for pod: daemon-set-snhsp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:44:54.437: INFO: Wrong image for pod: daemon-set-t7bnk. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:44:54.437: INFO: Wrong image for pod: daemon-set-vl87b. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:44:55.437: INFO: Wrong image for pod: daemon-set-r6ktj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:44:55.437: INFO: Wrong image for pod: daemon-set-smq4n. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:44:55.437: INFO: Wrong image for pod: daemon-set-snhsp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:44:55.437: INFO: Wrong image for pod: daemon-set-t7bnk. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:44:55.437: INFO: Pod daemon-set-t7bnk is not available
Mar  1 13:44:55.437: INFO: Wrong image for pod: daemon-set-vl87b. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:44:56.439: INFO: Pod daemon-set-m27r5 is not available
Mar  1 13:44:56.439: INFO: Wrong image for pod: daemon-set-r6ktj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:44:56.439: INFO: Wrong image for pod: daemon-set-smq4n. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:44:56.439: INFO: Wrong image for pod: daemon-set-snhsp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:44:56.439: INFO: Wrong image for pod: daemon-set-vl87b. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:44:57.442: INFO: Pod daemon-set-m27r5 is not available
Mar  1 13:44:57.442: INFO: Wrong image for pod: daemon-set-r6ktj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:44:57.442: INFO: Wrong image for pod: daemon-set-smq4n. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:44:57.442: INFO: Wrong image for pod: daemon-set-snhsp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:44:57.442: INFO: Wrong image for pod: daemon-set-vl87b. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:44:58.440: INFO: Wrong image for pod: daemon-set-r6ktj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:44:58.440: INFO: Wrong image for pod: daemon-set-smq4n. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:44:58.440: INFO: Wrong image for pod: daemon-set-snhsp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:44:58.440: INFO: Wrong image for pod: daemon-set-vl87b. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:44:59.437: INFO: Wrong image for pod: daemon-set-r6ktj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:44:59.437: INFO: Wrong image for pod: daemon-set-smq4n. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:44:59.437: INFO: Wrong image for pod: daemon-set-snhsp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:44:59.437: INFO: Wrong image for pod: daemon-set-vl87b. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:45:00.437: INFO: Wrong image for pod: daemon-set-r6ktj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:45:00.437: INFO: Wrong image for pod: daemon-set-smq4n. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:45:00.437: INFO: Wrong image for pod: daemon-set-snhsp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:45:00.437: INFO: Wrong image for pod: daemon-set-vl87b. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:45:01.437: INFO: Wrong image for pod: daemon-set-r6ktj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:45:01.437: INFO: Wrong image for pod: daemon-set-smq4n. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:45:01.437: INFO: Wrong image for pod: daemon-set-snhsp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:45:01.437: INFO: Wrong image for pod: daemon-set-vl87b. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:45:02.437: INFO: Wrong image for pod: daemon-set-r6ktj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:45:02.437: INFO: Wrong image for pod: daemon-set-smq4n. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:45:02.437: INFO: Wrong image for pod: daemon-set-snhsp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:45:02.437: INFO: Wrong image for pod: daemon-set-vl87b. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:45:03.436: INFO: Wrong image for pod: daemon-set-r6ktj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:45:03.436: INFO: Wrong image for pod: daemon-set-smq4n. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:45:03.436: INFO: Wrong image for pod: daemon-set-snhsp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:45:03.436: INFO: Wrong image for pod: daemon-set-vl87b. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:45:04.437: INFO: Wrong image for pod: daemon-set-r6ktj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:45:04.437: INFO: Wrong image for pod: daemon-set-smq4n. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:45:04.437: INFO: Wrong image for pod: daemon-set-snhsp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:45:04.437: INFO: Wrong image for pod: daemon-set-vl87b. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:45:05.437: INFO: Wrong image for pod: daemon-set-r6ktj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:45:05.437: INFO: Wrong image for pod: daemon-set-smq4n. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:45:05.437: INFO: Wrong image for pod: daemon-set-snhsp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:45:05.437: INFO: Wrong image for pod: daemon-set-vl87b. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:45:06.437: INFO: Wrong image for pod: daemon-set-r6ktj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:45:06.438: INFO: Wrong image for pod: daemon-set-smq4n. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:45:06.438: INFO: Wrong image for pod: daemon-set-snhsp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:45:06.438: INFO: Wrong image for pod: daemon-set-vl87b. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:45:07.438: INFO: Wrong image for pod: daemon-set-r6ktj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:45:07.438: INFO: Wrong image for pod: daemon-set-smq4n. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:45:07.438: INFO: Wrong image for pod: daemon-set-snhsp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:45:07.438: INFO: Wrong image for pod: daemon-set-vl87b. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:45:08.437: INFO: Wrong image for pod: daemon-set-r6ktj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:45:08.437: INFO: Wrong image for pod: daemon-set-smq4n. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:45:08.437: INFO: Wrong image for pod: daemon-set-snhsp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:45:08.437: INFO: Wrong image for pod: daemon-set-vl87b. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:45:09.437: INFO: Wrong image for pod: daemon-set-r6ktj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:45:09.437: INFO: Wrong image for pod: daemon-set-smq4n. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:45:09.437: INFO: Wrong image for pod: daemon-set-snhsp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:45:09.437: INFO: Wrong image for pod: daemon-set-vl87b. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:45:10.437: INFO: Wrong image for pod: daemon-set-r6ktj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:45:10.437: INFO: Wrong image for pod: daemon-set-smq4n. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:45:10.437: INFO: Wrong image for pod: daemon-set-snhsp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:45:10.437: INFO: Wrong image for pod: daemon-set-vl87b. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:45:11.438: INFO: Wrong image for pod: daemon-set-r6ktj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:45:11.438: INFO: Wrong image for pod: daemon-set-smq4n. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:45:11.438: INFO: Wrong image for pod: daemon-set-snhsp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:45:11.438: INFO: Wrong image for pod: daemon-set-vl87b. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:45:12.437: INFO: Wrong image for pod: daemon-set-r6ktj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:45:12.437: INFO: Wrong image for pod: daemon-set-smq4n. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:45:12.437: INFO: Wrong image for pod: daemon-set-snhsp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:45:12.437: INFO: Wrong image for pod: daemon-set-vl87b. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:45:13.437: INFO: Wrong image for pod: daemon-set-r6ktj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:45:13.437: INFO: Wrong image for pod: daemon-set-smq4n. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:45:13.437: INFO: Wrong image for pod: daemon-set-snhsp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:45:13.437: INFO: Wrong image for pod: daemon-set-vl87b. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:45:14.437: INFO: Wrong image for pod: daemon-set-r6ktj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:45:14.437: INFO: Wrong image for pod: daemon-set-smq4n. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:45:14.437: INFO: Wrong image for pod: daemon-set-snhsp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:45:14.437: INFO: Wrong image for pod: daemon-set-vl87b. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:45:15.437: INFO: Wrong image for pod: daemon-set-r6ktj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:45:15.437: INFO: Wrong image for pod: daemon-set-smq4n. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:45:15.437: INFO: Wrong image for pod: daemon-set-snhsp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:45:15.437: INFO: Wrong image for pod: daemon-set-vl87b. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:45:16.438: INFO: Wrong image for pod: daemon-set-r6ktj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:45:16.438: INFO: Wrong image for pod: daemon-set-smq4n. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:45:16.438: INFO: Wrong image for pod: daemon-set-snhsp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:45:16.438: INFO: Wrong image for pod: daemon-set-vl87b. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:45:17.437: INFO: Wrong image for pod: daemon-set-r6ktj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:45:17.437: INFO: Wrong image for pod: daemon-set-smq4n. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:45:17.437: INFO: Wrong image for pod: daemon-set-snhsp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:45:17.437: INFO: Wrong image for pod: daemon-set-vl87b. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:45:18.437: INFO: Wrong image for pod: daemon-set-r6ktj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:45:18.437: INFO: Wrong image for pod: daemon-set-smq4n. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:45:18.437: INFO: Wrong image for pod: daemon-set-snhsp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:45:18.437: INFO: Wrong image for pod: daemon-set-vl87b. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:45:19.437: INFO: Wrong image for pod: daemon-set-r6ktj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:45:19.437: INFO: Wrong image for pod: daemon-set-smq4n. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:45:19.437: INFO: Wrong image for pod: daemon-set-snhsp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:45:19.437: INFO: Wrong image for pod: daemon-set-vl87b. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:45:20.437: INFO: Wrong image for pod: daemon-set-r6ktj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:45:20.437: INFO: Wrong image for pod: daemon-set-smq4n. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:45:20.437: INFO: Wrong image for pod: daemon-set-snhsp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:45:20.437: INFO: Wrong image for pod: daemon-set-vl87b. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:45:21.451: INFO: Wrong image for pod: daemon-set-r6ktj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:45:21.451: INFO: Wrong image for pod: daemon-set-smq4n. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:45:21.451: INFO: Wrong image for pod: daemon-set-snhsp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:45:21.451: INFO: Wrong image for pod: daemon-set-vl87b. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:45:22.437: INFO: Wrong image for pod: daemon-set-r6ktj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:45:22.437: INFO: Wrong image for pod: daemon-set-smq4n. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:45:22.437: INFO: Wrong image for pod: daemon-set-snhsp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:45:22.437: INFO: Wrong image for pod: daemon-set-vl87b. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:45:23.437: INFO: Wrong image for pod: daemon-set-r6ktj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:45:23.437: INFO: Wrong image for pod: daemon-set-smq4n. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:45:23.437: INFO: Wrong image for pod: daemon-set-snhsp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:45:23.437: INFO: Wrong image for pod: daemon-set-vl87b. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:45:24.436: INFO: Wrong image for pod: daemon-set-r6ktj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:45:24.436: INFO: Wrong image for pod: daemon-set-smq4n. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:45:24.436: INFO: Wrong image for pod: daemon-set-snhsp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:45:24.436: INFO: Wrong image for pod: daemon-set-vl87b. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:45:25.436: INFO: Wrong image for pod: daemon-set-r6ktj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:45:25.436: INFO: Wrong image for pod: daemon-set-smq4n. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:45:25.436: INFO: Wrong image for pod: daemon-set-snhsp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:45:25.436: INFO: Wrong image for pod: daemon-set-vl87b. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:45:26.436: INFO: Wrong image for pod: daemon-set-r6ktj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:45:26.436: INFO: Wrong image for pod: daemon-set-smq4n. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:45:26.436: INFO: Wrong image for pod: daemon-set-snhsp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:45:26.436: INFO: Wrong image for pod: daemon-set-vl87b. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:45:27.437: INFO: Wrong image for pod: daemon-set-r6ktj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:45:27.437: INFO: Wrong image for pod: daemon-set-smq4n. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:45:27.437: INFO: Wrong image for pod: daemon-set-snhsp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:45:27.437: INFO: Wrong image for pod: daemon-set-vl87b. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:45:28.438: INFO: Wrong image for pod: daemon-set-r6ktj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:45:28.438: INFO: Wrong image for pod: daemon-set-smq4n. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:45:28.438: INFO: Wrong image for pod: daemon-set-snhsp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:45:28.438: INFO: Wrong image for pod: daemon-set-vl87b. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:45:29.437: INFO: Wrong image for pod: daemon-set-r6ktj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:45:29.437: INFO: Wrong image for pod: daemon-set-smq4n. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:45:29.437: INFO: Wrong image for pod: daemon-set-snhsp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:45:29.437: INFO: Wrong image for pod: daemon-set-vl87b. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:45:30.437: INFO: Wrong image for pod: daemon-set-r6ktj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:45:30.437: INFO: Wrong image for pod: daemon-set-smq4n. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:45:30.437: INFO: Wrong image for pod: daemon-set-snhsp. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:45:30.437: INFO: Pod daemon-set-snhsp is not available
Mar  1 13:45:30.437: INFO: Wrong image for pod: daemon-set-vl87b. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:45:31.437: INFO: Wrong image for pod: daemon-set-r6ktj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:45:31.437: INFO: Pod daemon-set-rlclq is not available
Mar  1 13:45:31.437: INFO: Wrong image for pod: daemon-set-smq4n. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:45:31.437: INFO: Wrong image for pod: daemon-set-vl87b. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:45:32.437: INFO: Wrong image for pod: daemon-set-r6ktj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:45:32.437: INFO: Pod daemon-set-rlclq is not available
Mar  1 13:45:32.437: INFO: Wrong image for pod: daemon-set-smq4n. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:45:32.437: INFO: Wrong image for pod: daemon-set-vl87b. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:45:33.437: INFO: Wrong image for pod: daemon-set-r6ktj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:45:33.437: INFO: Wrong image for pod: daemon-set-smq4n. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:45:33.437: INFO: Wrong image for pod: daemon-set-vl87b. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:45:34.437: INFO: Wrong image for pod: daemon-set-r6ktj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:45:34.437: INFO: Wrong image for pod: daemon-set-smq4n. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:45:34.437: INFO: Wrong image for pod: daemon-set-vl87b. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:45:35.436: INFO: Wrong image for pod: daemon-set-r6ktj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:45:35.436: INFO: Wrong image for pod: daemon-set-smq4n. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:45:35.436: INFO: Wrong image for pod: daemon-set-vl87b. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:45:36.437: INFO: Wrong image for pod: daemon-set-r6ktj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:45:36.437: INFO: Wrong image for pod: daemon-set-smq4n. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:45:36.437: INFO: Wrong image for pod: daemon-set-vl87b. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:45:37.436: INFO: Wrong image for pod: daemon-set-r6ktj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:45:37.436: INFO: Wrong image for pod: daemon-set-smq4n. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:45:37.436: INFO: Wrong image for pod: daemon-set-vl87b. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:45:38.437: INFO: Wrong image for pod: daemon-set-r6ktj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:45:38.437: INFO: Wrong image for pod: daemon-set-smq4n. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:45:38.437: INFO: Wrong image for pod: daemon-set-vl87b. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:45:39.438: INFO: Wrong image for pod: daemon-set-r6ktj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:45:39.438: INFO: Wrong image for pod: daemon-set-smq4n. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:45:39.438: INFO: Wrong image for pod: daemon-set-vl87b. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:45:40.437: INFO: Wrong image for pod: daemon-set-r6ktj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:45:40.437: INFO: Wrong image for pod: daemon-set-smq4n. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:45:40.437: INFO: Wrong image for pod: daemon-set-vl87b. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:45:41.437: INFO: Wrong image for pod: daemon-set-r6ktj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:45:41.437: INFO: Wrong image for pod: daemon-set-smq4n. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:45:41.437: INFO: Wrong image for pod: daemon-set-vl87b. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:45:42.437: INFO: Wrong image for pod: daemon-set-r6ktj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:45:42.437: INFO: Wrong image for pod: daemon-set-smq4n. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:45:42.437: INFO: Wrong image for pod: daemon-set-vl87b. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:45:43.437: INFO: Wrong image for pod: daemon-set-r6ktj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:45:43.437: INFO: Wrong image for pod: daemon-set-smq4n. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:45:43.437: INFO: Wrong image for pod: daemon-set-vl87b. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:45:44.437: INFO: Wrong image for pod: daemon-set-r6ktj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:45:44.437: INFO: Wrong image for pod: daemon-set-smq4n. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:45:44.437: INFO: Wrong image for pod: daemon-set-vl87b. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:45:45.437: INFO: Wrong image for pod: daemon-set-r6ktj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:45:45.437: INFO: Wrong image for pod: daemon-set-smq4n. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:45:45.437: INFO: Wrong image for pod: daemon-set-vl87b. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:45:46.437: INFO: Wrong image for pod: daemon-set-r6ktj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:45:46.437: INFO: Wrong image for pod: daemon-set-smq4n. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:45:46.437: INFO: Wrong image for pod: daemon-set-vl87b. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:45:47.437: INFO: Wrong image for pod: daemon-set-r6ktj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:45:47.437: INFO: Wrong image for pod: daemon-set-smq4n. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:45:47.437: INFO: Wrong image for pod: daemon-set-vl87b. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:45:48.437: INFO: Wrong image for pod: daemon-set-r6ktj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:45:48.437: INFO: Wrong image for pod: daemon-set-smq4n. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:45:48.437: INFO: Wrong image for pod: daemon-set-vl87b. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:45:49.437: INFO: Wrong image for pod: daemon-set-r6ktj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:45:49.437: INFO: Wrong image for pod: daemon-set-smq4n. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:45:49.437: INFO: Wrong image for pod: daemon-set-vl87b. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:45:50.437: INFO: Wrong image for pod: daemon-set-r6ktj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:45:50.437: INFO: Wrong image for pod: daemon-set-smq4n. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:45:50.437: INFO: Wrong image for pod: daemon-set-vl87b. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:45:51.437: INFO: Wrong image for pod: daemon-set-r6ktj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:45:51.437: INFO: Wrong image for pod: daemon-set-smq4n. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:45:51.437: INFO: Wrong image for pod: daemon-set-vl87b. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:45:52.437: INFO: Wrong image for pod: daemon-set-r6ktj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:45:52.437: INFO: Wrong image for pod: daemon-set-smq4n. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:45:52.437: INFO: Wrong image for pod: daemon-set-vl87b. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:45:53.437: INFO: Wrong image for pod: daemon-set-r6ktj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:45:53.437: INFO: Wrong image for pod: daemon-set-smq4n. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:45:53.437: INFO: Wrong image for pod: daemon-set-vl87b. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:45:54.438: INFO: Wrong image for pod: daemon-set-r6ktj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:45:54.438: INFO: Wrong image for pod: daemon-set-smq4n. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:45:54.438: INFO: Wrong image for pod: daemon-set-vl87b. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:45:55.437: INFO: Wrong image for pod: daemon-set-r6ktj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:45:55.437: INFO: Wrong image for pod: daemon-set-smq4n. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:45:55.437: INFO: Wrong image for pod: daemon-set-vl87b. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:45:56.438: INFO: Wrong image for pod: daemon-set-r6ktj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:45:56.438: INFO: Wrong image for pod: daemon-set-smq4n. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:45:56.438: INFO: Wrong image for pod: daemon-set-vl87b. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:45:57.437: INFO: Wrong image for pod: daemon-set-r6ktj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:45:57.437: INFO: Wrong image for pod: daemon-set-smq4n. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:45:57.437: INFO: Wrong image for pod: daemon-set-vl87b. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:45:58.437: INFO: Wrong image for pod: daemon-set-r6ktj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:45:58.437: INFO: Wrong image for pod: daemon-set-smq4n. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:45:58.437: INFO: Wrong image for pod: daemon-set-vl87b. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:45:59.437: INFO: Wrong image for pod: daemon-set-r6ktj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:45:59.437: INFO: Wrong image for pod: daemon-set-smq4n. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:45:59.437: INFO: Wrong image for pod: daemon-set-vl87b. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:46:00.437: INFO: Wrong image for pod: daemon-set-r6ktj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:46:00.437: INFO: Wrong image for pod: daemon-set-smq4n. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:46:00.437: INFO: Wrong image for pod: daemon-set-vl87b. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:46:01.437: INFO: Wrong image for pod: daemon-set-r6ktj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:46:01.437: INFO: Wrong image for pod: daemon-set-smq4n. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:46:01.437: INFO: Wrong image for pod: daemon-set-vl87b. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:46:02.438: INFO: Wrong image for pod: daemon-set-r6ktj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:46:02.438: INFO: Wrong image for pod: daemon-set-smq4n. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:46:02.438: INFO: Wrong image for pod: daemon-set-vl87b. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:46:03.449: INFO: Wrong image for pod: daemon-set-r6ktj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:46:03.449: INFO: Wrong image for pod: daemon-set-smq4n. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:46:03.449: INFO: Pod daemon-set-smq4n is not available
Mar  1 13:46:03.449: INFO: Wrong image for pod: daemon-set-vl87b. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:46:04.437: INFO: Wrong image for pod: daemon-set-r6ktj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:46:04.437: INFO: Wrong image for pod: daemon-set-smq4n. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:46:04.437: INFO: Pod daemon-set-smq4n is not available
Mar  1 13:46:04.437: INFO: Wrong image for pod: daemon-set-vl87b. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:46:05.436: INFO: Wrong image for pod: daemon-set-r6ktj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:46:05.436: INFO: Wrong image for pod: daemon-set-smq4n. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:46:05.436: INFO: Pod daemon-set-smq4n is not available
Mar  1 13:46:05.436: INFO: Wrong image for pod: daemon-set-vl87b. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:46:06.438: INFO: Wrong image for pod: daemon-set-r6ktj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:46:06.438: INFO: Wrong image for pod: daemon-set-smq4n. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:46:06.438: INFO: Pod daemon-set-smq4n is not available
Mar  1 13:46:06.438: INFO: Wrong image for pod: daemon-set-vl87b. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:46:07.437: INFO: Wrong image for pod: daemon-set-r6ktj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:46:07.437: INFO: Wrong image for pod: daemon-set-smq4n. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:46:07.437: INFO: Pod daemon-set-smq4n is not available
Mar  1 13:46:07.437: INFO: Wrong image for pod: daemon-set-vl87b. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:46:08.437: INFO: Wrong image for pod: daemon-set-r6ktj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:46:08.437: INFO: Wrong image for pod: daemon-set-smq4n. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:46:08.437: INFO: Pod daemon-set-smq4n is not available
Mar  1 13:46:08.437: INFO: Wrong image for pod: daemon-set-vl87b. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:46:09.439: INFO: Wrong image for pod: daemon-set-r6ktj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:46:09.439: INFO: Wrong image for pod: daemon-set-smq4n. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:46:09.439: INFO: Pod daemon-set-smq4n is not available
Mar  1 13:46:09.439: INFO: Wrong image for pod: daemon-set-vl87b. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:46:10.437: INFO: Pod daemon-set-dvkrb is not available
Mar  1 13:46:10.437: INFO: Wrong image for pod: daemon-set-r6ktj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:46:10.437: INFO: Wrong image for pod: daemon-set-vl87b. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:46:11.437: INFO: Pod daemon-set-dvkrb is not available
Mar  1 13:46:11.437: INFO: Wrong image for pod: daemon-set-r6ktj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:46:11.437: INFO: Wrong image for pod: daemon-set-vl87b. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:46:12.437: INFO: Pod daemon-set-dvkrb is not available
Mar  1 13:46:12.437: INFO: Wrong image for pod: daemon-set-r6ktj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:46:12.437: INFO: Wrong image for pod: daemon-set-vl87b. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:46:13.437: INFO: Wrong image for pod: daemon-set-r6ktj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:46:13.437: INFO: Wrong image for pod: daemon-set-vl87b. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:46:14.437: INFO: Wrong image for pod: daemon-set-r6ktj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:46:14.437: INFO: Wrong image for pod: daemon-set-vl87b. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:46:15.438: INFO: Wrong image for pod: daemon-set-r6ktj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:46:15.438: INFO: Wrong image for pod: daemon-set-vl87b. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:46:16.437: INFO: Wrong image for pod: daemon-set-r6ktj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:46:16.437: INFO: Wrong image for pod: daemon-set-vl87b. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:46:17.437: INFO: Wrong image for pod: daemon-set-r6ktj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:46:17.437: INFO: Wrong image for pod: daemon-set-vl87b. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:46:18.437: INFO: Wrong image for pod: daemon-set-r6ktj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:46:18.437: INFO: Wrong image for pod: daemon-set-vl87b. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:46:19.437: INFO: Wrong image for pod: daemon-set-r6ktj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:46:19.437: INFO: Wrong image for pod: daemon-set-vl87b. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:46:20.437: INFO: Wrong image for pod: daemon-set-r6ktj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:46:20.437: INFO: Wrong image for pod: daemon-set-vl87b. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:46:21.437: INFO: Wrong image for pod: daemon-set-r6ktj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:46:21.437: INFO: Wrong image for pod: daemon-set-vl87b. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:46:22.437: INFO: Wrong image for pod: daemon-set-r6ktj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:46:22.437: INFO: Wrong image for pod: daemon-set-vl87b. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:46:23.437: INFO: Wrong image for pod: daemon-set-r6ktj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:46:23.437: INFO: Wrong image for pod: daemon-set-vl87b. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:46:24.437: INFO: Wrong image for pod: daemon-set-r6ktj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:46:24.437: INFO: Wrong image for pod: daemon-set-vl87b. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:46:25.438: INFO: Wrong image for pod: daemon-set-r6ktj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:46:25.438: INFO: Wrong image for pod: daemon-set-vl87b. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:46:26.437: INFO: Wrong image for pod: daemon-set-r6ktj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:46:26.437: INFO: Wrong image for pod: daemon-set-vl87b. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:46:27.437: INFO: Wrong image for pod: daemon-set-r6ktj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:46:27.437: INFO: Wrong image for pod: daemon-set-vl87b. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:46:28.437: INFO: Wrong image for pod: daemon-set-r6ktj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:46:28.437: INFO: Wrong image for pod: daemon-set-vl87b. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:46:29.436: INFO: Wrong image for pod: daemon-set-r6ktj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:46:29.436: INFO: Wrong image for pod: daemon-set-vl87b. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:46:30.437: INFO: Wrong image for pod: daemon-set-r6ktj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:46:30.437: INFO: Wrong image for pod: daemon-set-vl87b. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:46:31.437: INFO: Wrong image for pod: daemon-set-r6ktj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:46:31.437: INFO: Wrong image for pod: daemon-set-vl87b. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:46:32.437: INFO: Wrong image for pod: daemon-set-r6ktj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:46:32.437: INFO: Wrong image for pod: daemon-set-vl87b. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:46:33.437: INFO: Wrong image for pod: daemon-set-r6ktj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:46:33.437: INFO: Wrong image for pod: daemon-set-vl87b. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:46:34.437: INFO: Wrong image for pod: daemon-set-r6ktj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:46:34.437: INFO: Wrong image for pod: daemon-set-vl87b. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:46:35.438: INFO: Wrong image for pod: daemon-set-r6ktj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:46:35.438: INFO: Wrong image for pod: daemon-set-vl87b. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:46:36.438: INFO: Wrong image for pod: daemon-set-r6ktj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:46:36.438: INFO: Wrong image for pod: daemon-set-vl87b. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:46:37.437: INFO: Wrong image for pod: daemon-set-r6ktj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:46:37.437: INFO: Wrong image for pod: daemon-set-vl87b. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:46:38.437: INFO: Wrong image for pod: daemon-set-r6ktj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:46:38.437: INFO: Wrong image for pod: daemon-set-vl87b. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:46:39.437: INFO: Wrong image for pod: daemon-set-r6ktj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:46:39.437: INFO: Wrong image for pod: daemon-set-vl87b. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:46:40.437: INFO: Wrong image for pod: daemon-set-r6ktj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:46:40.437: INFO: Wrong image for pod: daemon-set-vl87b. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:46:41.437: INFO: Wrong image for pod: daemon-set-r6ktj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:46:41.437: INFO: Wrong image for pod: daemon-set-vl87b. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:46:42.437: INFO: Wrong image for pod: daemon-set-r6ktj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:46:42.437: INFO: Wrong image for pod: daemon-set-vl87b. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:46:43.437: INFO: Wrong image for pod: daemon-set-r6ktj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:46:43.437: INFO: Wrong image for pod: daemon-set-vl87b. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:46:43.437: INFO: Pod daemon-set-vl87b is not available
Mar  1 13:46:44.446: INFO: Pod daemon-set-c6vxq is not available
Mar  1 13:46:44.446: INFO: Wrong image for pod: daemon-set-r6ktj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:46:45.436: INFO: Pod daemon-set-c6vxq is not available
Mar  1 13:46:45.436: INFO: Wrong image for pod: daemon-set-r6ktj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:46:46.437: INFO: Wrong image for pod: daemon-set-r6ktj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:46:47.437: INFO: Wrong image for pod: daemon-set-r6ktj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:46:48.437: INFO: Wrong image for pod: daemon-set-r6ktj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:46:49.437: INFO: Wrong image for pod: daemon-set-r6ktj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:46:50.438: INFO: Wrong image for pod: daemon-set-r6ktj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:46:51.437: INFO: Wrong image for pod: daemon-set-r6ktj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:46:52.437: INFO: Wrong image for pod: daemon-set-r6ktj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:46:53.437: INFO: Wrong image for pod: daemon-set-r6ktj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:46:54.437: INFO: Wrong image for pod: daemon-set-r6ktj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:46:55.437: INFO: Wrong image for pod: daemon-set-r6ktj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:46:56.437: INFO: Wrong image for pod: daemon-set-r6ktj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:46:57.436: INFO: Wrong image for pod: daemon-set-r6ktj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:46:58.437: INFO: Wrong image for pod: daemon-set-r6ktj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:46:59.437: INFO: Wrong image for pod: daemon-set-r6ktj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:47:00.438: INFO: Wrong image for pod: daemon-set-r6ktj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:47:01.437: INFO: Wrong image for pod: daemon-set-r6ktj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:47:02.438: INFO: Wrong image for pod: daemon-set-r6ktj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:47:03.439: INFO: Wrong image for pod: daemon-set-r6ktj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:47:04.446: INFO: Wrong image for pod: daemon-set-r6ktj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:47:05.437: INFO: Wrong image for pod: daemon-set-r6ktj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:47:06.437: INFO: Wrong image for pod: daemon-set-r6ktj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:47:07.438: INFO: Wrong image for pod: daemon-set-r6ktj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:47:08.437: INFO: Wrong image for pod: daemon-set-r6ktj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:47:09.437: INFO: Wrong image for pod: daemon-set-r6ktj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:47:10.437: INFO: Wrong image for pod: daemon-set-r6ktj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:47:11.439: INFO: Wrong image for pod: daemon-set-r6ktj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:47:12.437: INFO: Wrong image for pod: daemon-set-r6ktj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:47:13.437: INFO: Wrong image for pod: daemon-set-r6ktj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:47:14.437: INFO: Wrong image for pod: daemon-set-r6ktj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:47:15.438: INFO: Wrong image for pod: daemon-set-r6ktj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:47:16.436: INFO: Wrong image for pod: daemon-set-r6ktj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:47:17.437: INFO: Wrong image for pod: daemon-set-r6ktj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:47:17.437: INFO: Pod daemon-set-r6ktj is not available
Mar  1 13:47:18.437: INFO: Wrong image for pod: daemon-set-r6ktj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:47:18.437: INFO: Pod daemon-set-r6ktj is not available
Mar  1 13:47:19.437: INFO: Wrong image for pod: daemon-set-r6ktj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Mar  1 13:47:19.437: INFO: Pod daemon-set-r6ktj is not available
Mar  1 13:47:20.437: INFO: Pod daemon-set-225hr is not available
STEP: Check that daemon pods are still running on every node of the cluster.
Mar  1 13:47:20.447: INFO: Number of nodes with available pods: 4
Mar  1 13:47:20.447: INFO: Node gke-conformance-default-pool-eca581b0-sqmc is running more than one daemon pod
Mar  1 13:47:21.456: INFO: Number of nodes with available pods: 4
Mar  1 13:47:21.456: INFO: Node gke-conformance-default-pool-eca581b0-sqmc is running more than one daemon pod
Mar  1 13:47:22.456: INFO: Number of nodes with available pods: 5
Mar  1 13:47:22.456: INFO: Number of running nodes: 5, number of available pods: 5
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:64
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting {extensions DaemonSet} daemon-set in namespace e2e-tests-daemonsets-8ql4t, will wait for the garbage collector to delete the pods
Mar  1 13:47:22.539: INFO: Deleting {extensions DaemonSet} daemon-set took: 16.221906ms
Mar  1 13:47:22.640: INFO: Terminating {extensions DaemonSet} daemon-set pods took: 100.371769ms
Mar  1 13:47:31.550: INFO: Number of nodes with available pods: 0
Mar  1 13:47:31.550: INFO: Number of running nodes: 0, number of available pods: 0
Mar  1 13:47:31.555: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-8ql4t/daemonsets","resourceVersion":"6165"},"items":null}

Mar  1 13:47:31.558: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-8ql4t/pods","resourceVersion":"6165"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 13:47:31.586: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-8ql4t" for this suite.
Mar  1 13:47:37.608: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 13:47:37.705: INFO: namespace: e2e-tests-daemonsets-8ql4t, resource: bindings, ignored listing per whitelist
Mar  1 13:47:37.809: INFO: namespace e2e-tests-daemonsets-8ql4t deletion completed in 6.218189287s

• [SLOW TEST:198.805 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 13:47:37.809: INFO: >>> kubeConfig: /tmp/kubeconfig-210205575
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:98
[It] should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Mar  1 13:47:37.977: INFO: Number of nodes with available pods: 0
Mar  1 13:47:37.977: INFO: Node gke-conformance-default-pool-eca581b0-00fq is running more than one daemon pod
Mar  1 13:47:38.986: INFO: Number of nodes with available pods: 0
Mar  1 13:47:38.986: INFO: Node gke-conformance-default-pool-eca581b0-00fq is running more than one daemon pod
Mar  1 13:47:39.986: INFO: Number of nodes with available pods: 4
Mar  1 13:47:39.986: INFO: Node gke-conformance-default-pool-eca581b0-czl4 is running more than one daemon pod
Mar  1 13:47:40.986: INFO: Number of nodes with available pods: 5
Mar  1 13:47:40.986: INFO: Number of running nodes: 5, number of available pods: 5
STEP: Set a daemon pod's phase to 'Failed', check that the daemon pod is revived.
Mar  1 13:47:41.027: INFO: Number of nodes with available pods: 4
Mar  1 13:47:41.027: INFO: Node gke-conformance-default-pool-eca581b0-40vx is running more than one daemon pod
Mar  1 13:47:42.035: INFO: Number of nodes with available pods: 4
Mar  1 13:47:42.035: INFO: Node gke-conformance-default-pool-eca581b0-40vx is running more than one daemon pod
Mar  1 13:47:43.037: INFO: Number of nodes with available pods: 4
Mar  1 13:47:43.037: INFO: Node gke-conformance-default-pool-eca581b0-40vx is running more than one daemon pod
Mar  1 13:47:44.042: INFO: Number of nodes with available pods: 5
Mar  1 13:47:44.042: INFO: Number of running nodes: 5, number of available pods: 5
STEP: Wait for the failed daemon pod to be completely deleted.
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:64
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting {extensions DaemonSet} daemon-set in namespace e2e-tests-daemonsets-76hl4, will wait for the garbage collector to delete the pods
Mar  1 13:47:44.114: INFO: Deleting {extensions DaemonSet} daemon-set took: 13.94115ms
Mar  1 13:47:44.314: INFO: Terminating {extensions DaemonSet} daemon-set pods took: 200.357734ms
Mar  1 13:48:20.418: INFO: Number of nodes with available pods: 0
Mar  1 13:48:20.418: INFO: Number of running nodes: 0, number of available pods: 0
Mar  1 13:48:20.420: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-76hl4/daemonsets","resourceVersion":"6384"},"items":null}

Mar  1 13:48:20.423: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-76hl4/pods","resourceVersion":"6384"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 13:48:20.444: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-76hl4" for this suite.
Mar  1 13:48:26.464: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 13:48:26.582: INFO: namespace: e2e-tests-daemonsets-76hl4, resource: bindings, ignored listing per whitelist
Mar  1 13:48:26.603: INFO: namespace e2e-tests-daemonsets-76hl4 deletion completed in 6.153605381s

• [SLOW TEST:48.794 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 13:48:26.603: INFO: >>> kubeConfig: /tmp/kubeconfig-210205575
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0644 on node default medium
Mar  1 13:48:26.719: INFO: Waiting up to 5m0s for pod "pod-b0612312-3c28-11e9-a154-0a580a280202" in namespace "e2e-tests-emptydir-qtwmk" to be "success or failure"
Mar  1 13:48:26.723: INFO: Pod "pod-b0612312-3c28-11e9-a154-0a580a280202": Phase="Pending", Reason="", readiness=false. Elapsed: 4.251735ms
Mar  1 13:48:28.733: INFO: Pod "pod-b0612312-3c28-11e9-a154-0a580a280202": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014482357s
Mar  1 13:48:30.737: INFO: Pod "pod-b0612312-3c28-11e9-a154-0a580a280202": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.017908359s
STEP: Saw pod success
Mar  1 13:48:30.737: INFO: Pod "pod-b0612312-3c28-11e9-a154-0a580a280202" satisfied condition "success or failure"
Mar  1 13:48:30.740: INFO: Trying to get logs from node gke-conformance-default-pool-eca581b0-czl4 pod pod-b0612312-3c28-11e9-a154-0a580a280202 container test-container: <nil>
STEP: delete the pod
Mar  1 13:48:30.771: INFO: Waiting for pod pod-b0612312-3c28-11e9-a154-0a580a280202 to disappear
Mar  1 13:48:30.774: INFO: Pod pod-b0612312-3c28-11e9-a154-0a580a280202 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 13:48:30.774: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-qtwmk" for this suite.
Mar  1 13:48:36.787: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 13:48:36.968: INFO: namespace: e2e-tests-emptydir-qtwmk, resource: bindings, ignored listing per whitelist
Mar  1 13:48:36.974: INFO: namespace e2e-tests-emptydir-qtwmk deletion completed in 6.196100121s

• [SLOW TEST:10.371 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 13:48:36.974: INFO: >>> kubeConfig: /tmp/kubeconfig-210205575
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-n4g4t
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Mar  1 13:48:37.084: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Mar  1 13:48:59.296: INFO: ExecWithOptions {Command:[/bin/sh -c timeout -t 15 curl -g -q -s --connect-timeout 1 http://10.40.3.29:8080/hostName | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-n4g4t PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar  1 13:48:59.296: INFO: >>> kubeConfig: /tmp/kubeconfig-210205575
Mar  1 13:48:59.376: INFO: Found all expected endpoints: [netserver-0]
Mar  1 13:48:59.380: INFO: ExecWithOptions {Command:[/bin/sh -c timeout -t 15 curl -g -q -s --connect-timeout 1 http://10.40.0.17:8080/hostName | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-n4g4t PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar  1 13:48:59.380: INFO: >>> kubeConfig: /tmp/kubeconfig-210205575
Mar  1 13:48:59.461: INFO: Found all expected endpoints: [netserver-1]
Mar  1 13:48:59.465: INFO: ExecWithOptions {Command:[/bin/sh -c timeout -t 15 curl -g -q -s --connect-timeout 1 http://10.40.4.36:8080/hostName | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-n4g4t PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar  1 13:48:59.465: INFO: >>> kubeConfig: /tmp/kubeconfig-210205575
Mar  1 13:48:59.537: INFO: Found all expected endpoints: [netserver-2]
Mar  1 13:48:59.541: INFO: ExecWithOptions {Command:[/bin/sh -c timeout -t 15 curl -g -q -s --connect-timeout 1 http://10.40.1.28:8080/hostName | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-n4g4t PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar  1 13:48:59.541: INFO: >>> kubeConfig: /tmp/kubeconfig-210205575
Mar  1 13:48:59.618: INFO: Found all expected endpoints: [netserver-3]
Mar  1 13:48:59.621: INFO: ExecWithOptions {Command:[/bin/sh -c timeout -t 15 curl -g -q -s --connect-timeout 1 http://10.40.2.9:8080/hostName | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-n4g4t PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar  1 13:48:59.622: INFO: >>> kubeConfig: /tmp/kubeconfig-210205575
Mar  1 13:48:59.697: INFO: Found all expected endpoints: [netserver-4]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 13:48:59.697: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-n4g4t" for this suite.
Mar  1 13:49:21.714: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 13:49:21.891: INFO: namespace: e2e-tests-pod-network-test-n4g4t, resource: bindings, ignored listing per whitelist
Mar  1 13:49:21.904: INFO: namespace e2e-tests-pod-network-test-n4g4t deletion completed in 22.203056724s

• [SLOW TEST:44.930 seconds]
[sig-network] Networking
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: http [NodeConformance] [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 13:49:21.904: INFO: >>> kubeConfig: /tmp/kubeconfig-210205575
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
Mar  1 13:49:22.006: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 13:49:26.229: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-init-container-9d922" for this suite.
Mar  1 13:49:48.249: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 13:49:48.336: INFO: namespace: e2e-tests-init-container-9d922, resource: bindings, ignored listing per whitelist
Mar  1 13:49:48.373: INFO: namespace e2e-tests-init-container-9d922 deletion completed in 22.137240723s

• [SLOW TEST:26.468 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-storage] Projected 
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 13:49:48.373: INFO: >>> kubeConfig: /tmp/kubeconfig-210205575
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-projected-all-test-volume-e11e41d4-3c28-11e9-a154-0a580a280202
STEP: Creating secret with name secret-projected-all-test-volume-e11e41c5-3c28-11e9-a154-0a580a280202
STEP: Creating a pod to test Check all projections for projected volume plugin
Mar  1 13:49:48.493: INFO: Waiting up to 5m0s for pod "projected-volume-e11e4199-3c28-11e9-a154-0a580a280202" in namespace "e2e-tests-projected-lgxhr" to be "success or failure"
Mar  1 13:49:48.506: INFO: Pod "projected-volume-e11e4199-3c28-11e9-a154-0a580a280202": Phase="Pending", Reason="", readiness=false. Elapsed: 13.41687ms
Mar  1 13:49:50.511: INFO: Pod "projected-volume-e11e4199-3c28-11e9-a154-0a580a280202": Phase="Pending", Reason="", readiness=false. Elapsed: 2.017563163s
Mar  1 13:49:52.514: INFO: Pod "projected-volume-e11e4199-3c28-11e9-a154-0a580a280202": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.021322757s
STEP: Saw pod success
Mar  1 13:49:52.514: INFO: Pod "projected-volume-e11e4199-3c28-11e9-a154-0a580a280202" satisfied condition "success or failure"
Mar  1 13:49:52.517: INFO: Trying to get logs from node gke-conformance-default-pool-eca581b0-sww9 pod projected-volume-e11e4199-3c28-11e9-a154-0a580a280202 container projected-all-volume-test: <nil>
STEP: delete the pod
Mar  1 13:49:52.542: INFO: Waiting for pod projected-volume-e11e4199-3c28-11e9-a154-0a580a280202 to disappear
Mar  1 13:49:52.545: INFO: Pod projected-volume-e11e4199-3c28-11e9-a154-0a580a280202 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 13:49:52.545: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-lgxhr" for this suite.
Mar  1 13:49:58.558: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 13:49:58.659: INFO: namespace: e2e-tests-projected-lgxhr, resource: bindings, ignored listing per whitelist
Mar  1 13:49:58.713: INFO: namespace e2e-tests-projected-lgxhr deletion completed in 6.164970488s

• [SLOW TEST:10.341 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 13:49:58.714: INFO: >>> kubeConfig: /tmp/kubeconfig-210205575
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating the pod
Mar  1 13:50:01.630: INFO: Successfully updated pod "annotationupdatee76f1936-3c28-11e9-a154-0a580a280202"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 13:50:03.652: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-wwt8n" for this suite.
Mar  1 13:50:25.670: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 13:50:25.819: INFO: namespace: e2e-tests-downward-api-wwt8n, resource: bindings, ignored listing per whitelist
Mar  1 13:50:25.831: INFO: namespace e2e-tests-downward-api-wwt8n deletion completed in 22.175578602s

• [SLOW TEST:27.118 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 13:50:25.831: INFO: >>> kubeConfig: /tmp/kubeconfig-210205575
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test substitution in container's args
Mar  1 13:50:25.937: INFO: Waiting up to 5m0s for pod "var-expansion-f771045d-3c28-11e9-a154-0a580a280202" in namespace "e2e-tests-var-expansion-9pzmd" to be "success or failure"
Mar  1 13:50:25.949: INFO: Pod "var-expansion-f771045d-3c28-11e9-a154-0a580a280202": Phase="Pending", Reason="", readiness=false. Elapsed: 12.056665ms
Mar  1 13:50:27.953: INFO: Pod "var-expansion-f771045d-3c28-11e9-a154-0a580a280202": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.015490493s
STEP: Saw pod success
Mar  1 13:50:27.953: INFO: Pod "var-expansion-f771045d-3c28-11e9-a154-0a580a280202" satisfied condition "success or failure"
Mar  1 13:50:27.956: INFO: Trying to get logs from node gke-conformance-default-pool-eca581b0-czl4 pod var-expansion-f771045d-3c28-11e9-a154-0a580a280202 container dapi-container: <nil>
STEP: delete the pod
Mar  1 13:50:28.003: INFO: Waiting for pod var-expansion-f771045d-3c28-11e9-a154-0a580a280202 to disappear
Mar  1 13:50:28.012: INFO: Pod var-expansion-f771045d-3c28-11e9-a154-0a580a280202 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 13:50:28.012: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-var-expansion-9pzmd" for this suite.
Mar  1 13:50:34.028: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 13:50:34.143: INFO: namespace: e2e-tests-var-expansion-9pzmd, resource: bindings, ignored listing per whitelist
Mar  1 13:50:34.167: INFO: namespace e2e-tests-var-expansion-9pzmd deletion completed in 6.151421952s

• [SLOW TEST:8.336 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 13:50:34.168: INFO: >>> kubeConfig: /tmp/kubeconfig-210205575
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:98
[It] should run and stop simple daemon [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Mar  1 13:50:34.302: INFO: Number of nodes with available pods: 0
Mar  1 13:50:34.302: INFO: Node gke-conformance-default-pool-eca581b0-00fq is running more than one daemon pod
Mar  1 13:50:35.313: INFO: Number of nodes with available pods: 0
Mar  1 13:50:35.313: INFO: Node gke-conformance-default-pool-eca581b0-00fq is running more than one daemon pod
Mar  1 13:50:36.312: INFO: Number of nodes with available pods: 2
Mar  1 13:50:36.312: INFO: Node gke-conformance-default-pool-eca581b0-00fq is running more than one daemon pod
Mar  1 13:50:37.312: INFO: Number of nodes with available pods: 4
Mar  1 13:50:37.312: INFO: Node gke-conformance-default-pool-eca581b0-czl4 is running more than one daemon pod
Mar  1 13:50:38.311: INFO: Number of nodes with available pods: 5
Mar  1 13:50:38.311: INFO: Number of running nodes: 5, number of available pods: 5
STEP: Stop a daemon pod, check that the daemon pod is revived.
Mar  1 13:50:38.331: INFO: Number of nodes with available pods: 4
Mar  1 13:50:38.331: INFO: Node gke-conformance-default-pool-eca581b0-czl4 is running more than one daemon pod
Mar  1 13:50:39.339: INFO: Number of nodes with available pods: 4
Mar  1 13:50:39.339: INFO: Node gke-conformance-default-pool-eca581b0-czl4 is running more than one daemon pod
Mar  1 13:50:40.340: INFO: Number of nodes with available pods: 4
Mar  1 13:50:40.340: INFO: Node gke-conformance-default-pool-eca581b0-czl4 is running more than one daemon pod
Mar  1 13:50:41.339: INFO: Number of nodes with available pods: 4
Mar  1 13:50:41.339: INFO: Node gke-conformance-default-pool-eca581b0-czl4 is running more than one daemon pod
Mar  1 13:50:42.340: INFO: Number of nodes with available pods: 4
Mar  1 13:50:42.340: INFO: Node gke-conformance-default-pool-eca581b0-czl4 is running more than one daemon pod
Mar  1 13:50:43.342: INFO: Number of nodes with available pods: 4
Mar  1 13:50:43.342: INFO: Node gke-conformance-default-pool-eca581b0-czl4 is running more than one daemon pod
Mar  1 13:50:44.340: INFO: Number of nodes with available pods: 4
Mar  1 13:50:44.340: INFO: Node gke-conformance-default-pool-eca581b0-czl4 is running more than one daemon pod
Mar  1 13:50:45.339: INFO: Number of nodes with available pods: 4
Mar  1 13:50:45.339: INFO: Node gke-conformance-default-pool-eca581b0-czl4 is running more than one daemon pod
Mar  1 13:50:46.340: INFO: Number of nodes with available pods: 4
Mar  1 13:50:46.340: INFO: Node gke-conformance-default-pool-eca581b0-czl4 is running more than one daemon pod
Mar  1 13:50:47.339: INFO: Number of nodes with available pods: 4
Mar  1 13:50:47.339: INFO: Node gke-conformance-default-pool-eca581b0-czl4 is running more than one daemon pod
Mar  1 13:50:48.340: INFO: Number of nodes with available pods: 4
Mar  1 13:50:48.340: INFO: Node gke-conformance-default-pool-eca581b0-czl4 is running more than one daemon pod
Mar  1 13:50:49.339: INFO: Number of nodes with available pods: 4
Mar  1 13:50:49.339: INFO: Node gke-conformance-default-pool-eca581b0-czl4 is running more than one daemon pod
Mar  1 13:50:50.340: INFO: Number of nodes with available pods: 4
Mar  1 13:50:50.340: INFO: Node gke-conformance-default-pool-eca581b0-czl4 is running more than one daemon pod
Mar  1 13:50:51.340: INFO: Number of nodes with available pods: 4
Mar  1 13:50:51.341: INFO: Node gke-conformance-default-pool-eca581b0-czl4 is running more than one daemon pod
Mar  1 13:50:52.346: INFO: Number of nodes with available pods: 4
Mar  1 13:50:52.346: INFO: Node gke-conformance-default-pool-eca581b0-czl4 is running more than one daemon pod
Mar  1 13:50:53.340: INFO: Number of nodes with available pods: 4
Mar  1 13:50:53.340: INFO: Node gke-conformance-default-pool-eca581b0-czl4 is running more than one daemon pod
Mar  1 13:50:54.340: INFO: Number of nodes with available pods: 4
Mar  1 13:50:54.340: INFO: Node gke-conformance-default-pool-eca581b0-czl4 is running more than one daemon pod
Mar  1 13:50:55.341: INFO: Number of nodes with available pods: 4
Mar  1 13:50:55.341: INFO: Node gke-conformance-default-pool-eca581b0-czl4 is running more than one daemon pod
Mar  1 13:50:56.339: INFO: Number of nodes with available pods: 4
Mar  1 13:50:56.339: INFO: Node gke-conformance-default-pool-eca581b0-czl4 is running more than one daemon pod
Mar  1 13:50:57.340: INFO: Number of nodes with available pods: 4
Mar  1 13:50:57.340: INFO: Node gke-conformance-default-pool-eca581b0-czl4 is running more than one daemon pod
Mar  1 13:50:58.339: INFO: Number of nodes with available pods: 4
Mar  1 13:50:58.339: INFO: Node gke-conformance-default-pool-eca581b0-czl4 is running more than one daemon pod
Mar  1 13:50:59.340: INFO: Number of nodes with available pods: 4
Mar  1 13:50:59.340: INFO: Node gke-conformance-default-pool-eca581b0-czl4 is running more than one daemon pod
Mar  1 13:51:00.340: INFO: Number of nodes with available pods: 4
Mar  1 13:51:00.340: INFO: Node gke-conformance-default-pool-eca581b0-czl4 is running more than one daemon pod
Mar  1 13:51:01.341: INFO: Number of nodes with available pods: 4
Mar  1 13:51:01.341: INFO: Node gke-conformance-default-pool-eca581b0-czl4 is running more than one daemon pod
Mar  1 13:51:02.339: INFO: Number of nodes with available pods: 4
Mar  1 13:51:02.339: INFO: Node gke-conformance-default-pool-eca581b0-czl4 is running more than one daemon pod
Mar  1 13:51:03.340: INFO: Number of nodes with available pods: 4
Mar  1 13:51:03.340: INFO: Node gke-conformance-default-pool-eca581b0-czl4 is running more than one daemon pod
Mar  1 13:51:04.339: INFO: Number of nodes with available pods: 4
Mar  1 13:51:04.339: INFO: Node gke-conformance-default-pool-eca581b0-czl4 is running more than one daemon pod
Mar  1 13:51:05.339: INFO: Number of nodes with available pods: 4
Mar  1 13:51:05.339: INFO: Node gke-conformance-default-pool-eca581b0-czl4 is running more than one daemon pod
Mar  1 13:51:06.341: INFO: Number of nodes with available pods: 4
Mar  1 13:51:06.341: INFO: Node gke-conformance-default-pool-eca581b0-czl4 is running more than one daemon pod
Mar  1 13:51:07.339: INFO: Number of nodes with available pods: 4
Mar  1 13:51:07.339: INFO: Node gke-conformance-default-pool-eca581b0-czl4 is running more than one daemon pod
Mar  1 13:51:08.340: INFO: Number of nodes with available pods: 4
Mar  1 13:51:08.340: INFO: Node gke-conformance-default-pool-eca581b0-czl4 is running more than one daemon pod
Mar  1 13:51:09.339: INFO: Number of nodes with available pods: 4
Mar  1 13:51:09.339: INFO: Node gke-conformance-default-pool-eca581b0-czl4 is running more than one daemon pod
Mar  1 13:51:10.339: INFO: Number of nodes with available pods: 4
Mar  1 13:51:10.339: INFO: Node gke-conformance-default-pool-eca581b0-czl4 is running more than one daemon pod
Mar  1 13:51:11.340: INFO: Number of nodes with available pods: 4
Mar  1 13:51:11.340: INFO: Node gke-conformance-default-pool-eca581b0-czl4 is running more than one daemon pod
Mar  1 13:51:12.340: INFO: Number of nodes with available pods: 4
Mar  1 13:51:12.340: INFO: Node gke-conformance-default-pool-eca581b0-czl4 is running more than one daemon pod
Mar  1 13:51:13.340: INFO: Number of nodes with available pods: 4
Mar  1 13:51:13.340: INFO: Node gke-conformance-default-pool-eca581b0-czl4 is running more than one daemon pod
Mar  1 13:51:14.340: INFO: Number of nodes with available pods: 4
Mar  1 13:51:14.340: INFO: Node gke-conformance-default-pool-eca581b0-czl4 is running more than one daemon pod
Mar  1 13:51:15.339: INFO: Number of nodes with available pods: 4
Mar  1 13:51:15.339: INFO: Node gke-conformance-default-pool-eca581b0-czl4 is running more than one daemon pod
Mar  1 13:51:16.347: INFO: Number of nodes with available pods: 4
Mar  1 13:51:16.347: INFO: Node gke-conformance-default-pool-eca581b0-czl4 is running more than one daemon pod
Mar  1 13:51:17.340: INFO: Number of nodes with available pods: 4
Mar  1 13:51:17.340: INFO: Node gke-conformance-default-pool-eca581b0-czl4 is running more than one daemon pod
Mar  1 13:51:18.340: INFO: Number of nodes with available pods: 4
Mar  1 13:51:18.340: INFO: Node gke-conformance-default-pool-eca581b0-czl4 is running more than one daemon pod
Mar  1 13:51:19.343: INFO: Number of nodes with available pods: 4
Mar  1 13:51:19.344: INFO: Node gke-conformance-default-pool-eca581b0-czl4 is running more than one daemon pod
Mar  1 13:51:20.339: INFO: Number of nodes with available pods: 4
Mar  1 13:51:20.339: INFO: Node gke-conformance-default-pool-eca581b0-czl4 is running more than one daemon pod
Mar  1 13:51:21.350: INFO: Number of nodes with available pods: 4
Mar  1 13:51:21.350: INFO: Node gke-conformance-default-pool-eca581b0-czl4 is running more than one daemon pod
Mar  1 13:51:22.340: INFO: Number of nodes with available pods: 4
Mar  1 13:51:22.340: INFO: Node gke-conformance-default-pool-eca581b0-czl4 is running more than one daemon pod
Mar  1 13:51:23.340: INFO: Number of nodes with available pods: 5
Mar  1 13:51:23.340: INFO: Number of running nodes: 5, number of available pods: 5
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:64
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting {extensions DaemonSet} daemon-set in namespace e2e-tests-daemonsets-rzxzs, will wait for the garbage collector to delete the pods
Mar  1 13:51:23.404: INFO: Deleting {extensions DaemonSet} daemon-set took: 8.481477ms
Mar  1 13:51:23.504: INFO: Terminating {extensions DaemonSet} daemon-set pods took: 100.275368ms
Mar  1 13:52:00.408: INFO: Number of nodes with available pods: 0
Mar  1 13:52:00.408: INFO: Number of running nodes: 0, number of available pods: 0
Mar  1 13:52:00.411: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-rzxzs/daemonsets","resourceVersion":"7231"},"items":null}

Mar  1 13:52:00.413: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-rzxzs/pods","resourceVersion":"7231"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 13:52:00.431: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-rzxzs" for this suite.
Mar  1 13:52:06.458: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 13:52:06.565: INFO: namespace: e2e-tests-daemonsets-rzxzs, resource: bindings, ignored listing per whitelist
Mar  1 13:52:06.597: INFO: namespace e2e-tests-daemonsets-rzxzs deletion completed in 6.162437179s

• [SLOW TEST:92.430 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 13:52:06.597: INFO: >>> kubeConfig: /tmp/kubeconfig-210205575
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-787sg
[It] should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a new StatefulSet
Mar  1 13:52:06.735: INFO: Found 0 stateful pods, waiting for 3
Mar  1 13:52:16.740: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Mar  1 13:52:16.740: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Mar  1 13:52:16.740: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
Mar  1 13:52:16.752: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-210205575 exec --namespace=e2e-tests-statefulset-787sg ss2-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Mar  1 13:52:16.913: INFO: stderr: ""
Mar  1 13:52:16.913: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Mar  1 13:52:16.913: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss2-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

STEP: Updating StatefulSet template: update image from docker.io/library/nginx:1.14-alpine to docker.io/library/nginx:1.15-alpine
Mar  1 13:52:26.950: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Updating Pods in reverse ordinal order
Mar  1 13:52:36.978: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-210205575 exec --namespace=e2e-tests-statefulset-787sg ss2-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar  1 13:52:37.142: INFO: stderr: ""
Mar  1 13:52:37.142: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Mar  1 13:52:37.142: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss2-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Mar  1 13:52:57.164: INFO: Waiting for StatefulSet e2e-tests-statefulset-787sg/ss2 to complete update
Mar  1 13:52:57.164: INFO: Waiting for Pod e2e-tests-statefulset-787sg/ss2-0 to have revision ss2-c79899b9 update revision ss2-787997d666
STEP: Rolling back to a previous revision
Mar  1 13:53:07.299: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-210205575 exec --namespace=e2e-tests-statefulset-787sg ss2-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Mar  1 13:53:07.776: INFO: stderr: ""
Mar  1 13:53:07.776: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Mar  1 13:53:07.776: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss2-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Mar  1 13:53:17.812: INFO: Updating stateful set ss2
STEP: Rolling back update in reverse ordinal order
Mar  1 13:53:27.864: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-210205575 exec --namespace=e2e-tests-statefulset-787sg ss2-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar  1 13:53:28.025: INFO: stderr: ""
Mar  1 13:53:28.025: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Mar  1 13:53:28.025: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss2-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Mar  1 13:53:38.056: INFO: Waiting for StatefulSet e2e-tests-statefulset-787sg/ss2 to complete update
Mar  1 13:53:38.056: INFO: Waiting for Pod e2e-tests-statefulset-787sg/ss2-0 to have revision ss2-787997d666 update revision ss2-c79899b9
Mar  1 13:53:38.056: INFO: Waiting for Pod e2e-tests-statefulset-787sg/ss2-1 to have revision ss2-787997d666 update revision ss2-c79899b9
Mar  1 13:53:38.056: INFO: Waiting for Pod e2e-tests-statefulset-787sg/ss2-2 to have revision ss2-787997d666 update revision ss2-c79899b9
Mar  1 13:53:48.068: INFO: Waiting for StatefulSet e2e-tests-statefulset-787sg/ss2 to complete update
Mar  1 13:53:48.068: INFO: Waiting for Pod e2e-tests-statefulset-787sg/ss2-0 to have revision ss2-787997d666 update revision ss2-c79899b9
Mar  1 13:53:48.068: INFO: Waiting for Pod e2e-tests-statefulset-787sg/ss2-1 to have revision ss2-787997d666 update revision ss2-c79899b9
Mar  1 13:53:58.168: INFO: Waiting for StatefulSet e2e-tests-statefulset-787sg/ss2 to complete update
Mar  1 13:53:58.168: INFO: Waiting for Pod e2e-tests-statefulset-787sg/ss2-0 to have revision ss2-787997d666 update revision ss2-c79899b9
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Mar  1 13:54:08.064: INFO: Deleting all statefulset in ns e2e-tests-statefulset-787sg
Mar  1 13:54:08.068: INFO: Scaling statefulset ss2 to 0
Mar  1 13:54:28.097: INFO: Waiting for statefulset status.replicas updated to 0
Mar  1 13:54:28.104: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 13:54:28.132: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-787sg" for this suite.
Mar  1 13:54:34.206: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 13:54:34.244: INFO: namespace: e2e-tests-statefulset-787sg, resource: bindings, ignored listing per whitelist
Mar  1 13:54:34.327: INFO: namespace e2e-tests-statefulset-787sg deletion completed in 6.170852701s

• [SLOW TEST:147.730 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should perform rolling updates and roll backs of template modifications [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run default 
  should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 13:54:34.327: INFO: >>> kubeConfig: /tmp/kubeconfig-210205575
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Kubectl run default
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1210
[It] should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Mar  1 13:54:34.458: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-210205575 run e2e-test-nginx-deployment --image=docker.io/library/nginx:1.14-alpine --namespace=e2e-tests-kubectl-bhjbl'
Mar  1 13:54:34.764: INFO: stderr: "kubectl run --generator=deployment/apps.v1beta1 is DEPRECATED and will be removed in a future version. Use kubectl create instead.\n"
Mar  1 13:54:34.764: INFO: stdout: "deployment.apps/e2e-test-nginx-deployment created\n"
STEP: verifying the pod controlled by e2e-test-nginx-deployment gets created
[AfterEach] [k8s.io] Kubectl run default
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1216
Mar  1 13:54:36.777: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-210205575 delete deployment e2e-test-nginx-deployment --namespace=e2e-tests-kubectl-bhjbl'
Mar  1 13:54:36.904: INFO: stderr: ""
Mar  1 13:54:36.904: INFO: stdout: "deployment.extensions \"e2e-test-nginx-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 13:54:36.904: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-bhjbl" for this suite.
Mar  1 13:56:00.966: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 13:56:01.036: INFO: namespace: e2e-tests-kubectl-bhjbl, resource: bindings, ignored listing per whitelist
Mar  1 13:56:01.078: INFO: namespace e2e-tests-kubectl-bhjbl deletion completed in 1m24.164767065s

• [SLOW TEST:86.751 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run default
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create an rc or deployment from an image  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 13:56:01.078: INFO: >>> kubeConfig: /tmp/kubeconfig-210205575
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:78
Mar  1 13:56:01.163: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Mar  1 13:56:01.174: INFO: Waiting for terminating namespaces to be deleted...
Mar  1 13:56:01.176: INFO: 
Logging pods the kubelet thinks is on node gke-conformance-default-pool-eca581b0-00fq before test
Mar  1 13:56:01.186: INFO: sonobuoy-systemd-logs-daemon-set-85467eaf90f647f9-rqg97 from heptio-sonobuoy started at 2019-03-01 13:25:56 +0000 UTC (2 container statuses recorded)
Mar  1 13:56:01.186: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 0
Mar  1 13:56:01.186: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Mar  1 13:56:01.186: INFO: kube-proxy-gke-conformance-default-pool-eca581b0-00fq from kube-system started at <nil> (0 container statuses recorded)
Mar  1 13:56:01.186: INFO: fluentd-gcp-v3.2.0-22pm2 from kube-system started at 2019-03-01 13:23:51 +0000 UTC (2 container statuses recorded)
Mar  1 13:56:01.186: INFO: 	Container fluentd-gcp ready: true, restart count 0
Mar  1 13:56:01.187: INFO: 	Container prometheus-to-sd-exporter ready: true, restart count 0
Mar  1 13:56:01.187: INFO: prometheus-to-sd-b6mpb from kube-system started at 2019-03-01 13:23:41 +0000 UTC (1 container statuses recorded)
Mar  1 13:56:01.187: INFO: 	Container prometheus-to-sd ready: true, restart count 0
Mar  1 13:56:01.187: INFO: sonobuoy-e2e-job-48f7569bb1614ff5 from heptio-sonobuoy started at 2019-03-01 13:25:56 +0000 UTC (2 container statuses recorded)
Mar  1 13:56:01.187: INFO: 	Container e2e ready: true, restart count 0
Mar  1 13:56:01.187: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Mar  1 13:56:01.187: INFO: 
Logging pods the kubelet thinks is on node gke-conformance-default-pool-eca581b0-40vx before test
Mar  1 13:56:01.203: INFO: heapster-v1.6.0-beta.1-554b54d8fb-s9lfd from kube-system started at 2019-03-01 13:23:53 +0000 UTC (3 container statuses recorded)
Mar  1 13:56:01.203: INFO: 	Container heapster ready: true, restart count 0
Mar  1 13:56:01.203: INFO: 	Container heapster-nanny ready: true, restart count 0
Mar  1 13:56:01.203: INFO: 	Container prom-to-sd ready: true, restart count 0
Mar  1 13:56:01.203: INFO: sonobuoy-systemd-logs-daemon-set-85467eaf90f647f9-7gvps from heptio-sonobuoy started at 2019-03-01 13:25:56 +0000 UTC (2 container statuses recorded)
Mar  1 13:56:01.203: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 0
Mar  1 13:56:01.203: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Mar  1 13:56:01.203: INFO: l7-default-backend-6f8697844f-9bl6b from kube-system started at 2019-03-01 13:23:39 +0000 UTC (1 container statuses recorded)
Mar  1 13:56:01.203: INFO: 	Container default-http-backend ready: true, restart count 0
Mar  1 13:56:01.203: INFO: event-exporter-v0.2.3-f9c896d75-gm5q7 from kube-system started at 2019-03-01 13:23:40 +0000 UTC (2 container statuses recorded)
Mar  1 13:56:01.203: INFO: 	Container event-exporter ready: true, restart count 0
Mar  1 13:56:01.203: INFO: 	Container prometheus-to-sd-exporter ready: true, restart count 0
Mar  1 13:56:01.203: INFO: kube-dns-autoscaler-76fcd5f658-wqrrk from kube-system started at 2019-03-01 13:23:53 +0000 UTC (1 container statuses recorded)
Mar  1 13:56:01.203: INFO: 	Container autoscaler ready: true, restart count 0
Mar  1 13:56:01.203: INFO: prometheus-to-sd-clvb4 from kube-system started at 2019-03-01 13:23:40 +0000 UTC (1 container statuses recorded)
Mar  1 13:56:01.203: INFO: 	Container prometheus-to-sd ready: true, restart count 0
Mar  1 13:56:01.203: INFO: fluentd-gcp-v3.2.0-z4kfv from kube-system started at 2019-03-01 13:23:53 +0000 UTC (2 container statuses recorded)
Mar  1 13:56:01.203: INFO: 	Container fluentd-gcp ready: true, restart count 0
Mar  1 13:56:01.203: INFO: 	Container prometheus-to-sd-exporter ready: true, restart count 0
Mar  1 13:56:01.203: INFO: metrics-server-v0.3.1-54699c9cc8-f74r6 from kube-system started at 2019-03-01 13:23:53 +0000 UTC (2 container statuses recorded)
Mar  1 13:56:01.203: INFO: 	Container metrics-server ready: true, restart count 0
Mar  1 13:56:01.203: INFO: 	Container metrics-server-nanny ready: true, restart count 0
Mar  1 13:56:01.203: INFO: kube-dns-659bd65dfc-mpd7w from kube-system started at 2019-03-01 13:23:57 +0000 UTC (4 container statuses recorded)
Mar  1 13:56:01.203: INFO: 	Container dnsmasq ready: true, restart count 0
Mar  1 13:56:01.203: INFO: 	Container kubedns ready: true, restart count 0
Mar  1 13:56:01.203: INFO: 	Container prometheus-to-sd ready: true, restart count 0
Mar  1 13:56:01.203: INFO: 	Container sidecar ready: true, restart count 0
Mar  1 13:56:01.203: INFO: kube-proxy-gke-conformance-default-pool-eca581b0-40vx from kube-system started at <nil> (0 container statuses recorded)
Mar  1 13:56:01.203: INFO: kube-dns-659bd65dfc-q4d65 from kube-system started at 2019-03-01 13:23:39 +0000 UTC (4 container statuses recorded)
Mar  1 13:56:01.203: INFO: 	Container dnsmasq ready: true, restart count 0
Mar  1 13:56:01.203: INFO: 	Container kubedns ready: true, restart count 0
Mar  1 13:56:01.203: INFO: 	Container prometheus-to-sd ready: true, restart count 0
Mar  1 13:56:01.203: INFO: 	Container sidecar ready: true, restart count 0
Mar  1 13:56:01.203: INFO: fluentd-gcp-scaler-69d79984cb-v6cwh from kube-system started at 2019-03-01 13:23:39 +0000 UTC (1 container statuses recorded)
Mar  1 13:56:01.203: INFO: 	Container fluentd-gcp-scaler ready: true, restart count 0
Mar  1 13:56:01.203: INFO: 
Logging pods the kubelet thinks is on node gke-conformance-default-pool-eca581b0-czl4 before test
Mar  1 13:56:01.216: INFO: sonobuoy-systemd-logs-daemon-set-85467eaf90f647f9-8jn8q from heptio-sonobuoy started at 2019-03-01 13:25:56 +0000 UTC (2 container statuses recorded)
Mar  1 13:56:01.216: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 0
Mar  1 13:56:01.216: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Mar  1 13:56:01.216: INFO: kube-proxy-gke-conformance-default-pool-eca581b0-czl4 from kube-system started at <nil> (0 container statuses recorded)
Mar  1 13:56:01.216: INFO: fluentd-gcp-v3.2.0-557h7 from kube-system started at 2019-03-01 13:23:51 +0000 UTC (2 container statuses recorded)
Mar  1 13:56:01.216: INFO: 	Container fluentd-gcp ready: true, restart count 0
Mar  1 13:56:01.216: INFO: 	Container prometheus-to-sd-exporter ready: true, restart count 0
Mar  1 13:56:01.216: INFO: prometheus-to-sd-77kbd from kube-system started at 2019-03-01 13:23:41 +0000 UTC (1 container statuses recorded)
Mar  1 13:56:01.216: INFO: 	Container prometheus-to-sd ready: true, restart count 0
Mar  1 13:56:01.216: INFO: 
Logging pods the kubelet thinks is on node gke-conformance-default-pool-eca581b0-sqmc before test
Mar  1 13:56:01.229: INFO: kube-proxy-gke-conformance-default-pool-eca581b0-sqmc from kube-system started at <nil> (0 container statuses recorded)
Mar  1 13:56:01.229: INFO: prometheus-to-sd-lj8s7 from kube-system started at 2019-03-01 13:23:41 +0000 UTC (1 container statuses recorded)
Mar  1 13:56:01.229: INFO: 	Container prometheus-to-sd ready: true, restart count 0
Mar  1 13:56:01.229: INFO: fluentd-gcp-v3.2.0-ltz26 from kube-system started at 2019-03-01 13:23:50 +0000 UTC (2 container statuses recorded)
Mar  1 13:56:01.229: INFO: 	Container fluentd-gcp ready: true, restart count 0
Mar  1 13:56:01.229: INFO: 	Container prometheus-to-sd-exporter ready: true, restart count 0
Mar  1 13:56:01.229: INFO: sonobuoy-systemd-logs-daemon-set-85467eaf90f647f9-x9t8z from heptio-sonobuoy started at 2019-03-01 13:25:56 +0000 UTC (2 container statuses recorded)
Mar  1 13:56:01.229: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 0
Mar  1 13:56:01.230: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Mar  1 13:56:01.230: INFO: 
Logging pods the kubelet thinks is on node gke-conformance-default-pool-eca581b0-sww9 before test
Mar  1 13:56:01.244: INFO: kube-proxy-gke-conformance-default-pool-eca581b0-sww9 from kube-system started at <nil> (0 container statuses recorded)
Mar  1 13:56:01.244: INFO: fluentd-gcp-v3.2.0-ttmft from kube-system started at 2019-03-01 13:23:51 +0000 UTC (2 container statuses recorded)
Mar  1 13:56:01.244: INFO: 	Container fluentd-gcp ready: true, restart count 0
Mar  1 13:56:01.244: INFO: 	Container prometheus-to-sd-exporter ready: true, restart count 0
Mar  1 13:56:01.244: INFO: prometheus-to-sd-5qc6r from kube-system started at 2019-03-01 13:23:40 +0000 UTC (1 container statuses recorded)
Mar  1 13:56:01.244: INFO: 	Container prometheus-to-sd ready: true, restart count 0
Mar  1 13:56:01.244: INFO: sonobuoy from heptio-sonobuoy started at 2019-03-01 13:25:52 +0000 UTC (1 container statuses recorded)
Mar  1 13:56:01.244: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Mar  1 13:56:01.244: INFO: sonobuoy-systemd-logs-daemon-set-85467eaf90f647f9-fr9v9 from heptio-sonobuoy started at 2019-03-01 13:25:56 +0000 UTC (2 container statuses recorded)
Mar  1 13:56:01.244: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 0
Mar  1 13:56:01.244: INFO: 	Container sonobuoy-worker ready: true, restart count 0
[It] validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: verifying the node has the label node gke-conformance-default-pool-eca581b0-00fq
STEP: verifying the node has the label node gke-conformance-default-pool-eca581b0-40vx
STEP: verifying the node has the label node gke-conformance-default-pool-eca581b0-czl4
STEP: verifying the node has the label node gke-conformance-default-pool-eca581b0-sqmc
STEP: verifying the node has the label node gke-conformance-default-pool-eca581b0-sww9
Mar  1 13:56:01.323: INFO: Pod sonobuoy requesting resource cpu=0m on Node gke-conformance-default-pool-eca581b0-sww9
Mar  1 13:56:01.323: INFO: Pod sonobuoy-e2e-job-48f7569bb1614ff5 requesting resource cpu=0m on Node gke-conformance-default-pool-eca581b0-00fq
Mar  1 13:56:01.323: INFO: Pod sonobuoy-systemd-logs-daemon-set-85467eaf90f647f9-7gvps requesting resource cpu=0m on Node gke-conformance-default-pool-eca581b0-40vx
Mar  1 13:56:01.323: INFO: Pod sonobuoy-systemd-logs-daemon-set-85467eaf90f647f9-8jn8q requesting resource cpu=0m on Node gke-conformance-default-pool-eca581b0-czl4
Mar  1 13:56:01.323: INFO: Pod sonobuoy-systemd-logs-daemon-set-85467eaf90f647f9-fr9v9 requesting resource cpu=0m on Node gke-conformance-default-pool-eca581b0-sww9
Mar  1 13:56:01.323: INFO: Pod sonobuoy-systemd-logs-daemon-set-85467eaf90f647f9-rqg97 requesting resource cpu=0m on Node gke-conformance-default-pool-eca581b0-00fq
Mar  1 13:56:01.323: INFO: Pod sonobuoy-systemd-logs-daemon-set-85467eaf90f647f9-x9t8z requesting resource cpu=0m on Node gke-conformance-default-pool-eca581b0-sqmc
Mar  1 13:56:01.323: INFO: Pod event-exporter-v0.2.3-f9c896d75-gm5q7 requesting resource cpu=0m on Node gke-conformance-default-pool-eca581b0-40vx
Mar  1 13:56:01.323: INFO: Pod fluentd-gcp-scaler-69d79984cb-v6cwh requesting resource cpu=0m on Node gke-conformance-default-pool-eca581b0-40vx
Mar  1 13:56:01.323: INFO: Pod fluentd-gcp-v3.2.0-22pm2 requesting resource cpu=100m on Node gke-conformance-default-pool-eca581b0-00fq
Mar  1 13:56:01.323: INFO: Pod fluentd-gcp-v3.2.0-557h7 requesting resource cpu=100m on Node gke-conformance-default-pool-eca581b0-czl4
Mar  1 13:56:01.323: INFO: Pod fluentd-gcp-v3.2.0-ltz26 requesting resource cpu=100m on Node gke-conformance-default-pool-eca581b0-sqmc
Mar  1 13:56:01.323: INFO: Pod fluentd-gcp-v3.2.0-ttmft requesting resource cpu=100m on Node gke-conformance-default-pool-eca581b0-sww9
Mar  1 13:56:01.323: INFO: Pod fluentd-gcp-v3.2.0-z4kfv requesting resource cpu=100m on Node gke-conformance-default-pool-eca581b0-40vx
Mar  1 13:56:01.323: INFO: Pod heapster-v1.6.0-beta.1-554b54d8fb-s9lfd requesting resource cpu=138m on Node gke-conformance-default-pool-eca581b0-40vx
Mar  1 13:56:01.323: INFO: Pod kube-dns-659bd65dfc-mpd7w requesting resource cpu=260m on Node gke-conformance-default-pool-eca581b0-40vx
Mar  1 13:56:01.323: INFO: Pod kube-dns-659bd65dfc-q4d65 requesting resource cpu=260m on Node gke-conformance-default-pool-eca581b0-40vx
Mar  1 13:56:01.323: INFO: Pod kube-dns-autoscaler-76fcd5f658-wqrrk requesting resource cpu=20m on Node gke-conformance-default-pool-eca581b0-40vx
Mar  1 13:56:01.323: INFO: Pod kube-proxy-gke-conformance-default-pool-eca581b0-00fq requesting resource cpu=100m on Node gke-conformance-default-pool-eca581b0-00fq
Mar  1 13:56:01.323: INFO: Pod kube-proxy-gke-conformance-default-pool-eca581b0-40vx requesting resource cpu=100m on Node gke-conformance-default-pool-eca581b0-40vx
Mar  1 13:56:01.323: INFO: Pod kube-proxy-gke-conformance-default-pool-eca581b0-czl4 requesting resource cpu=100m on Node gke-conformance-default-pool-eca581b0-czl4
Mar  1 13:56:01.323: INFO: Pod kube-proxy-gke-conformance-default-pool-eca581b0-sqmc requesting resource cpu=100m on Node gke-conformance-default-pool-eca581b0-sqmc
Mar  1 13:56:01.323: INFO: Pod kube-proxy-gke-conformance-default-pool-eca581b0-sww9 requesting resource cpu=100m on Node gke-conformance-default-pool-eca581b0-sww9
Mar  1 13:56:01.323: INFO: Pod l7-default-backend-6f8697844f-9bl6b requesting resource cpu=10m on Node gke-conformance-default-pool-eca581b0-40vx
Mar  1 13:56:01.323: INFO: Pod metrics-server-v0.3.1-54699c9cc8-f74r6 requesting resource cpu=53m on Node gke-conformance-default-pool-eca581b0-40vx
Mar  1 13:56:01.323: INFO: Pod prometheus-to-sd-5qc6r requesting resource cpu=1m on Node gke-conformance-default-pool-eca581b0-sww9
Mar  1 13:56:01.323: INFO: Pod prometheus-to-sd-77kbd requesting resource cpu=1m on Node gke-conformance-default-pool-eca581b0-czl4
Mar  1 13:56:01.323: INFO: Pod prometheus-to-sd-b6mpb requesting resource cpu=1m on Node gke-conformance-default-pool-eca581b0-00fq
Mar  1 13:56:01.323: INFO: Pod prometheus-to-sd-clvb4 requesting resource cpu=1m on Node gke-conformance-default-pool-eca581b0-40vx
Mar  1 13:56:01.323: INFO: Pod prometheus-to-sd-lj8s7 requesting resource cpu=1m on Node gke-conformance-default-pool-eca581b0-sqmc
STEP: Starting Pods to consume most of the cluster CPU.
STEP: Creating another pod that requires unavailable amount of CPU.
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-bf5ac0e7-3c29-11e9-a154-0a580a280202.1587da3f21d78c4b], Reason = [Scheduled], Message = [Successfully assigned e2e-tests-sched-pred-fhtvt/filler-pod-bf5ac0e7-3c29-11e9-a154-0a580a280202 to gke-conformance-default-pool-eca581b0-00fq]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-bf5ac0e7-3c29-11e9-a154-0a580a280202.1587da3f667a7d93], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-bf5ac0e7-3c29-11e9-a154-0a580a280202.1587da3f69720d95], Reason = [Created], Message = [Created container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-bf5ac0e7-3c29-11e9-a154-0a580a280202.1587da3f6d4a1895], Reason = [Started], Message = [Started container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-bf5cf998-3c29-11e9-a154-0a580a280202.1587da3f244eef9e], Reason = [Scheduled], Message = [Successfully assigned e2e-tests-sched-pred-fhtvt/filler-pod-bf5cf998-3c29-11e9-a154-0a580a280202 to gke-conformance-default-pool-eca581b0-40vx]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-bf5cf998-3c29-11e9-a154-0a580a280202.1587da3fa6475abf], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-bf5cf998-3c29-11e9-a154-0a580a280202.1587da3fa917dd53], Reason = [Created], Message = [Created container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-bf5cf998-3c29-11e9-a154-0a580a280202.1587da3fb0c4544b], Reason = [Started], Message = [Started container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-bf60f549-3c29-11e9-a154-0a580a280202.1587da3f25c01a23], Reason = [Scheduled], Message = [Successfully assigned e2e-tests-sched-pred-fhtvt/filler-pod-bf60f549-3c29-11e9-a154-0a580a280202 to gke-conformance-default-pool-eca581b0-czl4]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-bf60f549-3c29-11e9-a154-0a580a280202.1587da3f59b7a4d6], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-bf60f549-3c29-11e9-a154-0a580a280202.1587da3f5d128668], Reason = [Created], Message = [Created container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-bf60f549-3c29-11e9-a154-0a580a280202.1587da3f63daff55], Reason = [Started], Message = [Started container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-bf6497cd-3c29-11e9-a154-0a580a280202.1587da3f2885819a], Reason = [Scheduled], Message = [Successfully assigned e2e-tests-sched-pred-fhtvt/filler-pod-bf6497cd-3c29-11e9-a154-0a580a280202 to gke-conformance-default-pool-eca581b0-sqmc]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-bf6497cd-3c29-11e9-a154-0a580a280202.1587da3f73f01f5e], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-bf6497cd-3c29-11e9-a154-0a580a280202.1587da3f77214c53], Reason = [Created], Message = [Created container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-bf6497cd-3c29-11e9-a154-0a580a280202.1587da3f7c042e9e], Reason = [Started], Message = [Started container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-bf6b4e27-3c29-11e9-a154-0a580a280202.1587da3f2a134794], Reason = [Scheduled], Message = [Successfully assigned e2e-tests-sched-pred-fhtvt/filler-pod-bf6b4e27-3c29-11e9-a154-0a580a280202 to gke-conformance-default-pool-eca581b0-sww9]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-bf6b4e27-3c29-11e9-a154-0a580a280202.1587da3f733d023d], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-bf6b4e27-3c29-11e9-a154-0a580a280202.1587da3f7752459c], Reason = [Created], Message = [Created container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-bf6b4e27-3c29-11e9-a154-0a580a280202.1587da3f7e14512c], Reason = [Started], Message = [Started container]
STEP: Considering event: 
Type = [Warning], Name = [additional-pod.1587da4019aefa52], Reason = [FailedScheduling], Message = [0/5 nodes are available: 5 Insufficient cpu.]
STEP: removing the label node off the node gke-conformance-default-pool-eca581b0-00fq
STEP: verifying the node doesn't have the label node
STEP: removing the label node off the node gke-conformance-default-pool-eca581b0-40vx
STEP: verifying the node doesn't have the label node
STEP: removing the label node off the node gke-conformance-default-pool-eca581b0-czl4
STEP: verifying the node doesn't have the label node
STEP: removing the label node off the node gke-conformance-default-pool-eca581b0-sqmc
STEP: verifying the node doesn't have the label node
STEP: removing the label node off the node gke-conformance-default-pool-eca581b0-sww9
STEP: verifying the node doesn't have the label node
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 13:56:06.650: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-sched-pred-fhtvt" for this suite.
Mar  1 13:56:12.666: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 13:56:12.787: INFO: namespace: e2e-tests-sched-pred-fhtvt, resource: bindings, ignored listing per whitelist
Mar  1 13:56:12.798: INFO: namespace e2e-tests-sched-pred-fhtvt deletion completed in 6.142117961s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:69

• [SLOW TEST:11.720 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 13:56:12.799: INFO: >>> kubeConfig: /tmp/kubeconfig-210205575
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0777 on tmpfs
Mar  1 13:56:12.924: INFO: Waiting up to 5m0s for pod "pod-c643b3bc-3c29-11e9-a154-0a580a280202" in namespace "e2e-tests-emptydir-jw8x9" to be "success or failure"
Mar  1 13:56:12.927: INFO: Pod "pod-c643b3bc-3c29-11e9-a154-0a580a280202": Phase="Pending", Reason="", readiness=false. Elapsed: 2.925767ms
Mar  1 13:56:15.005: INFO: Pod "pod-c643b3bc-3c29-11e9-a154-0a580a280202": Phase="Running", Reason="", readiness=true. Elapsed: 2.081297861s
Mar  1 13:56:17.008: INFO: Pod "pod-c643b3bc-3c29-11e9-a154-0a580a280202": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.084389388s
STEP: Saw pod success
Mar  1 13:56:17.008: INFO: Pod "pod-c643b3bc-3c29-11e9-a154-0a580a280202" satisfied condition "success or failure"
Mar  1 13:56:17.011: INFO: Trying to get logs from node gke-conformance-default-pool-eca581b0-sqmc pod pod-c643b3bc-3c29-11e9-a154-0a580a280202 container test-container: <nil>
STEP: delete the pod
Mar  1 13:56:17.035: INFO: Waiting for pod pod-c643b3bc-3c29-11e9-a154-0a580a280202 to disappear
Mar  1 13:56:17.040: INFO: Pod pod-c643b3bc-3c29-11e9-a154-0a580a280202 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 13:56:17.040: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-jw8x9" for this suite.
Mar  1 13:56:23.054: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 13:56:23.135: INFO: namespace: e2e-tests-emptydir-jw8x9, resource: bindings, ignored listing per whitelist
Mar  1 13:56:23.154: INFO: namespace e2e-tests-emptydir-jw8x9 deletion completed in 6.110663739s

• [SLOW TEST:10.355 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 13:56:23.154: INFO: >>> kubeConfig: /tmp/kubeconfig-210205575
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test override arguments
Mar  1 13:56:23.252: INFO: Waiting up to 5m0s for pod "client-containers-cc6b3239-3c29-11e9-a154-0a580a280202" in namespace "e2e-tests-containers-twrpm" to be "success or failure"
Mar  1 13:56:23.260: INFO: Pod "client-containers-cc6b3239-3c29-11e9-a154-0a580a280202": Phase="Pending", Reason="", readiness=false. Elapsed: 8.373839ms
Mar  1 13:56:25.273: INFO: Pod "client-containers-cc6b3239-3c29-11e9-a154-0a580a280202": Phase="Pending", Reason="", readiness=false. Elapsed: 2.020890596s
Mar  1 13:56:27.279: INFO: Pod "client-containers-cc6b3239-3c29-11e9-a154-0a580a280202": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.027525886s
STEP: Saw pod success
Mar  1 13:56:27.279: INFO: Pod "client-containers-cc6b3239-3c29-11e9-a154-0a580a280202" satisfied condition "success or failure"
Mar  1 13:56:27.283: INFO: Trying to get logs from node gke-conformance-default-pool-eca581b0-czl4 pod client-containers-cc6b3239-3c29-11e9-a154-0a580a280202 container test-container: <nil>
STEP: delete the pod
Mar  1 13:56:27.308: INFO: Waiting for pod client-containers-cc6b3239-3c29-11e9-a154-0a580a280202 to disappear
Mar  1 13:56:27.315: INFO: Pod client-containers-cc6b3239-3c29-11e9-a154-0a580a280202 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 13:56:27.315: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-twrpm" for this suite.
Mar  1 13:56:33.331: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 13:56:33.399: INFO: namespace: e2e-tests-containers-twrpm, resource: bindings, ignored listing per whitelist
Mar  1 13:56:33.457: INFO: namespace e2e-tests-containers-twrpm deletion completed in 6.137922886s

• [SLOW TEST:10.304 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 13:56:33.458: INFO: >>> kubeConfig: /tmp/kubeconfig-210205575
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:78
Mar  1 13:56:33.566: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Mar  1 13:56:33.575: INFO: Waiting for terminating namespaces to be deleted...
Mar  1 13:56:33.579: INFO: 
Logging pods the kubelet thinks is on node gke-conformance-default-pool-eca581b0-00fq before test
Mar  1 13:56:33.587: INFO: prometheus-to-sd-b6mpb from kube-system started at 2019-03-01 13:23:41 +0000 UTC (1 container statuses recorded)
Mar  1 13:56:33.587: INFO: 	Container prometheus-to-sd ready: true, restart count 0
Mar  1 13:56:33.587: INFO: sonobuoy-e2e-job-48f7569bb1614ff5 from heptio-sonobuoy started at 2019-03-01 13:25:56 +0000 UTC (2 container statuses recorded)
Mar  1 13:56:33.587: INFO: 	Container e2e ready: true, restart count 0
Mar  1 13:56:33.587: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Mar  1 13:56:33.587: INFO: sonobuoy-systemd-logs-daemon-set-85467eaf90f647f9-rqg97 from heptio-sonobuoy started at 2019-03-01 13:25:56 +0000 UTC (2 container statuses recorded)
Mar  1 13:56:33.587: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 0
Mar  1 13:56:33.587: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Mar  1 13:56:33.587: INFO: kube-proxy-gke-conformance-default-pool-eca581b0-00fq from kube-system started at <nil> (0 container statuses recorded)
Mar  1 13:56:33.587: INFO: fluentd-gcp-v3.2.0-22pm2 from kube-system started at 2019-03-01 13:23:51 +0000 UTC (2 container statuses recorded)
Mar  1 13:56:33.587: INFO: 	Container fluentd-gcp ready: true, restart count 0
Mar  1 13:56:33.587: INFO: 	Container prometheus-to-sd-exporter ready: true, restart count 0
Mar  1 13:56:33.587: INFO: 
Logging pods the kubelet thinks is on node gke-conformance-default-pool-eca581b0-40vx before test
Mar  1 13:56:33.602: INFO: fluentd-gcp-v3.2.0-z4kfv from kube-system started at 2019-03-01 13:23:53 +0000 UTC (2 container statuses recorded)
Mar  1 13:56:33.602: INFO: 	Container fluentd-gcp ready: true, restart count 0
Mar  1 13:56:33.602: INFO: 	Container prometheus-to-sd-exporter ready: true, restart count 0
Mar  1 13:56:33.602: INFO: metrics-server-v0.3.1-54699c9cc8-f74r6 from kube-system started at 2019-03-01 13:23:53 +0000 UTC (2 container statuses recorded)
Mar  1 13:56:33.602: INFO: 	Container metrics-server ready: true, restart count 0
Mar  1 13:56:33.602: INFO: 	Container metrics-server-nanny ready: true, restart count 0
Mar  1 13:56:33.602: INFO: kube-dns-659bd65dfc-mpd7w from kube-system started at 2019-03-01 13:23:57 +0000 UTC (4 container statuses recorded)
Mar  1 13:56:33.602: INFO: 	Container dnsmasq ready: true, restart count 0
Mar  1 13:56:33.602: INFO: 	Container kubedns ready: true, restart count 0
Mar  1 13:56:33.602: INFO: 	Container prometheus-to-sd ready: true, restart count 0
Mar  1 13:56:33.602: INFO: 	Container sidecar ready: true, restart count 0
Mar  1 13:56:33.602: INFO: kube-proxy-gke-conformance-default-pool-eca581b0-40vx from kube-system started at <nil> (0 container statuses recorded)
Mar  1 13:56:33.602: INFO: kube-dns-659bd65dfc-q4d65 from kube-system started at 2019-03-01 13:23:39 +0000 UTC (4 container statuses recorded)
Mar  1 13:56:33.602: INFO: 	Container dnsmasq ready: true, restart count 0
Mar  1 13:56:33.602: INFO: 	Container kubedns ready: true, restart count 0
Mar  1 13:56:33.602: INFO: 	Container prometheus-to-sd ready: true, restart count 0
Mar  1 13:56:33.602: INFO: 	Container sidecar ready: true, restart count 0
Mar  1 13:56:33.602: INFO: fluentd-gcp-scaler-69d79984cb-v6cwh from kube-system started at 2019-03-01 13:23:39 +0000 UTC (1 container statuses recorded)
Mar  1 13:56:33.602: INFO: 	Container fluentd-gcp-scaler ready: true, restart count 0
Mar  1 13:56:33.602: INFO: prometheus-to-sd-clvb4 from kube-system started at 2019-03-01 13:23:40 +0000 UTC (1 container statuses recorded)
Mar  1 13:56:33.602: INFO: 	Container prometheus-to-sd ready: true, restart count 0
Mar  1 13:56:33.602: INFO: sonobuoy-systemd-logs-daemon-set-85467eaf90f647f9-7gvps from heptio-sonobuoy started at 2019-03-01 13:25:56 +0000 UTC (2 container statuses recorded)
Mar  1 13:56:33.602: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 0
Mar  1 13:56:33.602: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Mar  1 13:56:33.602: INFO: l7-default-backend-6f8697844f-9bl6b from kube-system started at 2019-03-01 13:23:39 +0000 UTC (1 container statuses recorded)
Mar  1 13:56:33.602: INFO: 	Container default-http-backend ready: true, restart count 0
Mar  1 13:56:33.602: INFO: event-exporter-v0.2.3-f9c896d75-gm5q7 from kube-system started at 2019-03-01 13:23:40 +0000 UTC (2 container statuses recorded)
Mar  1 13:56:33.602: INFO: 	Container event-exporter ready: true, restart count 0
Mar  1 13:56:33.602: INFO: 	Container prometheus-to-sd-exporter ready: true, restart count 0
Mar  1 13:56:33.602: INFO: kube-dns-autoscaler-76fcd5f658-wqrrk from kube-system started at 2019-03-01 13:23:53 +0000 UTC (1 container statuses recorded)
Mar  1 13:56:33.602: INFO: 	Container autoscaler ready: true, restart count 0
Mar  1 13:56:33.602: INFO: heapster-v1.6.0-beta.1-554b54d8fb-s9lfd from kube-system started at 2019-03-01 13:23:53 +0000 UTC (3 container statuses recorded)
Mar  1 13:56:33.602: INFO: 	Container heapster ready: true, restart count 0
Mar  1 13:56:33.602: INFO: 	Container heapster-nanny ready: true, restart count 0
Mar  1 13:56:33.602: INFO: 	Container prom-to-sd ready: true, restart count 0
Mar  1 13:56:33.602: INFO: 
Logging pods the kubelet thinks is on node gke-conformance-default-pool-eca581b0-czl4 before test
Mar  1 13:56:33.617: INFO: kube-proxy-gke-conformance-default-pool-eca581b0-czl4 from kube-system started at <nil> (0 container statuses recorded)
Mar  1 13:56:33.617: INFO: fluentd-gcp-v3.2.0-557h7 from kube-system started at 2019-03-01 13:23:51 +0000 UTC (2 container statuses recorded)
Mar  1 13:56:33.617: INFO: 	Container fluentd-gcp ready: true, restart count 0
Mar  1 13:56:33.617: INFO: 	Container prometheus-to-sd-exporter ready: true, restart count 0
Mar  1 13:56:33.617: INFO: prometheus-to-sd-77kbd from kube-system started at 2019-03-01 13:23:41 +0000 UTC (1 container statuses recorded)
Mar  1 13:56:33.617: INFO: 	Container prometheus-to-sd ready: true, restart count 0
Mar  1 13:56:33.617: INFO: sonobuoy-systemd-logs-daemon-set-85467eaf90f647f9-8jn8q from heptio-sonobuoy started at 2019-03-01 13:25:56 +0000 UTC (2 container statuses recorded)
Mar  1 13:56:33.617: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 0
Mar  1 13:56:33.617: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Mar  1 13:56:33.617: INFO: 
Logging pods the kubelet thinks is on node gke-conformance-default-pool-eca581b0-sqmc before test
Mar  1 13:56:33.626: INFO: sonobuoy-systemd-logs-daemon-set-85467eaf90f647f9-x9t8z from heptio-sonobuoy started at 2019-03-01 13:25:56 +0000 UTC (2 container statuses recorded)
Mar  1 13:56:33.626: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 0
Mar  1 13:56:33.626: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Mar  1 13:56:33.626: INFO: kube-proxy-gke-conformance-default-pool-eca581b0-sqmc from kube-system started at <nil> (0 container statuses recorded)
Mar  1 13:56:33.626: INFO: prometheus-to-sd-lj8s7 from kube-system started at 2019-03-01 13:23:41 +0000 UTC (1 container statuses recorded)
Mar  1 13:56:33.626: INFO: 	Container prometheus-to-sd ready: true, restart count 0
Mar  1 13:56:33.626: INFO: fluentd-gcp-v3.2.0-ltz26 from kube-system started at 2019-03-01 13:23:50 +0000 UTC (2 container statuses recorded)
Mar  1 13:56:33.626: INFO: 	Container fluentd-gcp ready: true, restart count 0
Mar  1 13:56:33.626: INFO: 	Container prometheus-to-sd-exporter ready: true, restart count 0
Mar  1 13:56:33.626: INFO: 
Logging pods the kubelet thinks is on node gke-conformance-default-pool-eca581b0-sww9 before test
Mar  1 13:56:33.638: INFO: fluentd-gcp-v3.2.0-ttmft from kube-system started at 2019-03-01 13:23:51 +0000 UTC (2 container statuses recorded)
Mar  1 13:56:33.638: INFO: 	Container fluentd-gcp ready: true, restart count 0
Mar  1 13:56:33.638: INFO: 	Container prometheus-to-sd-exporter ready: true, restart count 0
Mar  1 13:56:33.639: INFO: prometheus-to-sd-5qc6r from kube-system started at 2019-03-01 13:23:40 +0000 UTC (1 container statuses recorded)
Mar  1 13:56:33.639: INFO: 	Container prometheus-to-sd ready: true, restart count 0
Mar  1 13:56:33.639: INFO: sonobuoy from heptio-sonobuoy started at 2019-03-01 13:25:52 +0000 UTC (1 container statuses recorded)
Mar  1 13:56:33.639: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Mar  1 13:56:33.639: INFO: sonobuoy-systemd-logs-daemon-set-85467eaf90f647f9-fr9v9 from heptio-sonobuoy started at 2019-03-01 13:25:56 +0000 UTC (2 container statuses recorded)
Mar  1 13:56:33.639: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 0
Mar  1 13:56:33.639: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Mar  1 13:56:33.639: INFO: kube-proxy-gke-conformance-default-pool-eca581b0-sww9 from kube-system started at <nil> (0 container statuses recorded)
[It] validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Trying to schedule Pod with nonempty NodeSelector.
STEP: Considering event: 
Type = [Warning], Name = [restricted-pod.1587da46a845218c], Reason = [FailedScheduling], Message = [0/5 nodes are available: 5 node(s) didn't match node selector.]
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 13:56:34.672: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-sched-pred-kn29l" for this suite.
Mar  1 13:56:40.687: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 13:56:40.805: INFO: namespace: e2e-tests-sched-pred-kn29l, resource: bindings, ignored listing per whitelist
Mar  1 13:56:40.908: INFO: namespace e2e-tests-sched-pred-kn29l deletion completed in 6.232309075s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:69

• [SLOW TEST:7.450 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl rolling-update 
  should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 13:56:40.908: INFO: >>> kubeConfig: /tmp/kubeconfig-210205575
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1306
[It] should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Mar  1 13:56:41.003: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-210205575 run e2e-test-nginx-rc --image=docker.io/library/nginx:1.14-alpine --generator=run/v1 --namespace=e2e-tests-kubectl-jqqdq'
Mar  1 13:56:41.097: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl create instead.\n"
Mar  1 13:56:41.097: INFO: stdout: "replicationcontroller/e2e-test-nginx-rc created\n"
STEP: verifying the rc e2e-test-nginx-rc was created
Mar  1 13:56:41.133: INFO: Waiting for rc e2e-test-nginx-rc to stabilize, generation 1 observed generation 1 spec.replicas 1 status.replicas 0
STEP: rolling-update to same image controller
Mar  1 13:56:41.146: INFO: scanned /root for discovery docs: <nil>
Mar  1 13:56:41.146: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-210205575 rolling-update e2e-test-nginx-rc --update-period=1s --image=docker.io/library/nginx:1.14-alpine --image-pull-policy=IfNotPresent --namespace=e2e-tests-kubectl-jqqdq'
Mar  1 13:56:56.970: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Mar  1 13:56:56.970: INFO: stdout: "Created e2e-test-nginx-rc-7d5b3f09c18784a8ac7904ac2e59b50f\nScaling up e2e-test-nginx-rc-7d5b3f09c18784a8ac7904ac2e59b50f from 0 to 1, scaling down e2e-test-nginx-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-nginx-rc-7d5b3f09c18784a8ac7904ac2e59b50f up to 1\nScaling e2e-test-nginx-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-nginx-rc\nRenaming e2e-test-nginx-rc-7d5b3f09c18784a8ac7904ac2e59b50f to e2e-test-nginx-rc\nreplicationcontroller/e2e-test-nginx-rc rolling updated\n"
Mar  1 13:56:56.970: INFO: stdout: "Created e2e-test-nginx-rc-7d5b3f09c18784a8ac7904ac2e59b50f\nScaling up e2e-test-nginx-rc-7d5b3f09c18784a8ac7904ac2e59b50f from 0 to 1, scaling down e2e-test-nginx-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-nginx-rc-7d5b3f09c18784a8ac7904ac2e59b50f up to 1\nScaling e2e-test-nginx-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-nginx-rc\nRenaming e2e-test-nginx-rc-7d5b3f09c18784a8ac7904ac2e59b50f to e2e-test-nginx-rc\nreplicationcontroller/e2e-test-nginx-rc rolling updated\n"
STEP: waiting for all containers in run=e2e-test-nginx-rc pods to come up.
Mar  1 13:56:56.970: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-210205575 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l run=e2e-test-nginx-rc --namespace=e2e-tests-kubectl-jqqdq'
Mar  1 13:56:57.060: INFO: stderr: ""
Mar  1 13:56:57.060: INFO: stdout: "e2e-test-nginx-rc-7d5b3f09c18784a8ac7904ac2e59b50f-ztcrs "
Mar  1 13:56:57.060: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-210205575 get pods e2e-test-nginx-rc-7d5b3f09c18784a8ac7904ac2e59b50f-ztcrs -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "e2e-test-nginx-rc") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-jqqdq'
Mar  1 13:56:57.145: INFO: stderr: ""
Mar  1 13:56:57.145: INFO: stdout: "true"
Mar  1 13:56:57.145: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-210205575 get pods e2e-test-nginx-rc-7d5b3f09c18784a8ac7904ac2e59b50f-ztcrs -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "e2e-test-nginx-rc"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-jqqdq'
Mar  1 13:56:57.234: INFO: stderr: ""
Mar  1 13:56:57.234: INFO: stdout: "nginx:1.14-alpine"
Mar  1 13:56:57.234: INFO: e2e-test-nginx-rc-7d5b3f09c18784a8ac7904ac2e59b50f-ztcrs is verified up and running
[AfterEach] [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1312
Mar  1 13:56:57.234: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-210205575 delete rc e2e-test-nginx-rc --namespace=e2e-tests-kubectl-jqqdq'
Mar  1 13:56:57.333: INFO: stderr: ""
Mar  1 13:56:57.333: INFO: stdout: "replicationcontroller \"e2e-test-nginx-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 13:56:57.333: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-jqqdq" for this suite.
Mar  1 13:57:19.352: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 13:57:19.409: INFO: namespace: e2e-tests-kubectl-jqqdq, resource: bindings, ignored listing per whitelist
Mar  1 13:57:19.523: INFO: namespace e2e-tests-kubectl-jqqdq deletion completed in 22.182877711s

• [SLOW TEST:38.615 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should support rolling-update to same image  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 13:57:19.524: INFO: >>> kubeConfig: /tmp/kubeconfig-210205575
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0644 on tmpfs
Mar  1 13:57:19.630: INFO: Waiting up to 5m0s for pod "pod-ee06588d-3c29-11e9-a154-0a580a280202" in namespace "e2e-tests-emptydir-dbvrl" to be "success or failure"
Mar  1 13:57:19.634: INFO: Pod "pod-ee06588d-3c29-11e9-a154-0a580a280202": Phase="Pending", Reason="", readiness=false. Elapsed: 3.593383ms
Mar  1 13:57:21.637: INFO: Pod "pod-ee06588d-3c29-11e9-a154-0a580a280202": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007408287s
Mar  1 13:57:23.641: INFO: Pod "pod-ee06588d-3c29-11e9-a154-0a580a280202": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.010801778s
STEP: Saw pod success
Mar  1 13:57:23.641: INFO: Pod "pod-ee06588d-3c29-11e9-a154-0a580a280202" satisfied condition "success or failure"
Mar  1 13:57:23.643: INFO: Trying to get logs from node gke-conformance-default-pool-eca581b0-czl4 pod pod-ee06588d-3c29-11e9-a154-0a580a280202 container test-container: <nil>
STEP: delete the pod
Mar  1 13:57:23.665: INFO: Waiting for pod pod-ee06588d-3c29-11e9-a154-0a580a280202 to disappear
Mar  1 13:57:23.670: INFO: Pod pod-ee06588d-3c29-11e9-a154-0a580a280202 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 13:57:23.670: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-dbvrl" for this suite.
Mar  1 13:57:29.688: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 13:57:29.724: INFO: namespace: e2e-tests-emptydir-dbvrl, resource: bindings, ignored listing per whitelist
Mar  1 13:57:30.147: INFO: namespace e2e-tests-emptydir-dbvrl deletion completed in 6.472813184s

• [SLOW TEST:10.623 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 13:57:30.147: INFO: >>> kubeConfig: /tmp/kubeconfig-210205575
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the pods
STEP: Gathering metrics
W0301 13:58:10.300898      19 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Mar  1 13:58:10.300: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 13:58:10.300: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-jzl6h" for this suite.
Mar  1 13:58:16.316: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 13:58:16.348: INFO: namespace: e2e-tests-gc-jzl6h, resource: bindings, ignored listing per whitelist
Mar  1 13:58:16.436: INFO: namespace e2e-tests-gc-jzl6h deletion completed in 6.131859672s

• [SLOW TEST:46.289 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 13:58:16.436: INFO: >>> kubeConfig: /tmp/kubeconfig-210205575
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the rc
STEP: delete the rc
STEP: wait for all pods to be garbage collected
STEP: Gathering metrics
W0301 13:58:26.552374      19 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Mar  1 13:58:26.552: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 13:58:26.552: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-nqm9k" for this suite.
Mar  1 13:58:32.568: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 13:58:32.653: INFO: namespace: e2e-tests-gc-nqm9k, resource: bindings, ignored listing per whitelist
Mar  1 13:58:32.687: INFO: namespace e2e-tests-gc-nqm9k deletion completed in 6.131119153s

• [SLOW TEST:16.251 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 13:58:32.687: INFO: >>> kubeConfig: /tmp/kubeconfig-210205575
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-19a2f5fc-3c2a-11e9-a154-0a580a280202
STEP: Creating a pod to test consume secrets
Mar  1 13:58:32.829: INFO: Waiting up to 5m0s for pod "pod-secrets-19a38885-3c2a-11e9-a154-0a580a280202" in namespace "e2e-tests-secrets-blnl4" to be "success or failure"
Mar  1 13:58:32.859: INFO: Pod "pod-secrets-19a38885-3c2a-11e9-a154-0a580a280202": Phase="Pending", Reason="", readiness=false. Elapsed: 29.633592ms
Mar  1 13:58:34.862: INFO: Pod "pod-secrets-19a38885-3c2a-11e9-a154-0a580a280202": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.03279472s
STEP: Saw pod success
Mar  1 13:58:34.862: INFO: Pod "pod-secrets-19a38885-3c2a-11e9-a154-0a580a280202" satisfied condition "success or failure"
Mar  1 13:58:34.865: INFO: Trying to get logs from node gke-conformance-default-pool-eca581b0-sww9 pod pod-secrets-19a38885-3c2a-11e9-a154-0a580a280202 container secret-volume-test: <nil>
STEP: delete the pod
Mar  1 13:58:34.892: INFO: Waiting for pod pod-secrets-19a38885-3c2a-11e9-a154-0a580a280202 to disappear
Mar  1 13:58:34.897: INFO: Pod pod-secrets-19a38885-3c2a-11e9-a154-0a580a280202 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 13:58:34.897: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-blnl4" for this suite.
Mar  1 13:58:40.912: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 13:58:40.946: INFO: namespace: e2e-tests-secrets-blnl4, resource: bindings, ignored listing per whitelist
Mar  1 13:58:41.135: INFO: namespace e2e-tests-secrets-blnl4 deletion completed in 6.234226652s

• [SLOW TEST:8.448 seconds]
[sig-storage] Secrets
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Downward API 
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 13:58:41.135: INFO: >>> kubeConfig: /tmp/kubeconfig-210205575
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Mar  1 13:58:41.233: INFO: Waiting up to 5m0s for pod "downward-api-1ea9b03e-3c2a-11e9-a154-0a580a280202" in namespace "e2e-tests-downward-api-kjzq2" to be "success or failure"
Mar  1 13:58:41.244: INFO: Pod "downward-api-1ea9b03e-3c2a-11e9-a154-0a580a280202": Phase="Pending", Reason="", readiness=false. Elapsed: 11.191506ms
Mar  1 13:58:43.251: INFO: Pod "downward-api-1ea9b03e-3c2a-11e9-a154-0a580a280202": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.017413656s
STEP: Saw pod success
Mar  1 13:58:43.251: INFO: Pod "downward-api-1ea9b03e-3c2a-11e9-a154-0a580a280202" satisfied condition "success or failure"
Mar  1 13:58:43.254: INFO: Trying to get logs from node gke-conformance-default-pool-eca581b0-czl4 pod downward-api-1ea9b03e-3c2a-11e9-a154-0a580a280202 container dapi-container: <nil>
STEP: delete the pod
Mar  1 13:58:43.284: INFO: Waiting for pod downward-api-1ea9b03e-3c2a-11e9-a154-0a580a280202 to disappear
Mar  1 13:58:43.288: INFO: Pod downward-api-1ea9b03e-3c2a-11e9-a154-0a580a280202 no longer exists
[AfterEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 13:58:43.288: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-kjzq2" for this suite.
Mar  1 13:58:49.313: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 13:58:49.401: INFO: namespace: e2e-tests-downward-api-kjzq2, resource: bindings, ignored listing per whitelist
Mar  1 13:58:49.453: INFO: namespace e2e-tests-downward-api-kjzq2 deletion completed in 6.159062277s

• [SLOW TEST:8.317 seconds]
[sig-api-machinery] Downward API
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 13:58:49.453: INFO: >>> kubeConfig: /tmp/kubeconfig-210205575
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(dig +notcp +noall +answer +search kubernetes.default A)" && echo OK > /results/wheezy_udp@kubernetes.default;test -n "$$(dig +tcp +noall +answer +search kubernetes.default A)" && echo OK > /results/wheezy_tcp@kubernetes.default;test -n "$$(dig +notcp +noall +answer +search kubernetes.default.svc A)" && echo OK > /results/wheezy_udp@kubernetes.default.svc;test -n "$$(dig +tcp +noall +answer +search kubernetes.default.svc A)" && echo OK > /results/wheezy_tcp@kubernetes.default.svc;test -n "$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && echo OK > /results/wheezy_udp@kubernetes.default.svc.cluster.local;test -n "$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && echo OK > /results/wheezy_tcp@kubernetes.default.svc.cluster.local;test -n "$$(getent hosts dns-querier-1.dns-test-service.e2e-tests-dns-svkdp.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-1.dns-test-service.e2e-tests-dns-svkdp.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/wheezy_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-svkdp.pod.cluster.local"}');test -n "$$(dig +notcp +noall +answer +search $${podARec} A)" && echo OK > /results/wheezy_udp@PodARecord;test -n "$$(dig +tcp +noall +answer +search $${podARec} A)" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(dig +notcp +noall +answer +search kubernetes.default A)" && echo OK > /results/jessie_udp@kubernetes.default;test -n "$$(dig +tcp +noall +answer +search kubernetes.default A)" && echo OK > /results/jessie_tcp@kubernetes.default;test -n "$$(dig +notcp +noall +answer +search kubernetes.default.svc A)" && echo OK > /results/jessie_udp@kubernetes.default.svc;test -n "$$(dig +tcp +noall +answer +search kubernetes.default.svc A)" && echo OK > /results/jessie_tcp@kubernetes.default.svc;test -n "$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && echo OK > /results/jessie_udp@kubernetes.default.svc.cluster.local;test -n "$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && echo OK > /results/jessie_tcp@kubernetes.default.svc.cluster.local;test -n "$$(getent hosts dns-querier-1.dns-test-service.e2e-tests-dns-svkdp.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-1.dns-test-service.e2e-tests-dns-svkdp.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/jessie_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-svkdp.pod.cluster.local"}');test -n "$$(dig +notcp +noall +answer +search $${podARec} A)" && echo OK > /results/jessie_udp@PodARecord;test -n "$$(dig +tcp +noall +answer +search $${podARec} A)" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Mar  1 13:59:11.682: INFO: DNS probes using e2e-tests-dns-svkdp/dns-test-23a00074-3c2a-11e9-a154-0a580a280202 succeeded

STEP: deleting the pod
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 13:59:11.699: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-dns-svkdp" for this suite.
Mar  1 13:59:17.723: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 13:59:17.846: INFO: namespace: e2e-tests-dns-svkdp, resource: bindings, ignored listing per whitelist
Mar  1 13:59:17.902: INFO: namespace e2e-tests-dns-svkdp deletion completed in 6.191833614s

• [SLOW TEST:28.449 seconds]
[sig-network] DNS
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 13:59:17.902: INFO: >>> kubeConfig: /tmp/kubeconfig-210205575
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Mar  1 13:59:18.030: INFO: pod1.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod3", UID:"3495fcc6-3c2a-11e9-83c3-42010a800094", Controller:(*bool)(0xc421076b56), BlockOwnerDeletion:(*bool)(0xc421076b57)}}
Mar  1 13:59:18.042: INFO: pod2.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod1", UID:"3493d722-3c2a-11e9-83c3-42010a800094", Controller:(*bool)(0xc421076da2), BlockOwnerDeletion:(*bool)(0xc421076da3)}}
Mar  1 13:59:18.063: INFO: pod3.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod2", UID:"3494aed5-3c2a-11e9-83c3-42010a800094", Controller:(*bool)(0xc421076f56), BlockOwnerDeletion:(*bool)(0xc421076f57)}}
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 13:59:23.079: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-tqs9c" for this suite.
Mar  1 13:59:29.095: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 13:59:29.232: INFO: namespace: e2e-tests-gc-tqs9c, resource: bindings, ignored listing per whitelist
Mar  1 13:59:29.241: INFO: namespace e2e-tests-gc-tqs9c deletion completed in 6.15739085s

• [SLOW TEST:11.339 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[k8s.io] [sig-node] Pods Extended [k8s.io] Pods Set QOS Class 
  should be submitted and removed  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 13:59:29.241: INFO: >>> kubeConfig: /tmp/kubeconfig-210205575
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pods.go:204
[It] should be submitted and removed  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying QOS class is set on the pod
[AfterEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 13:59:29.449: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-kqvll" for this suite.
Mar  1 13:59:51.540: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 13:59:51.616: INFO: namespace: e2e-tests-pods-kqvll, resource: bindings, ignored listing per whitelist
Mar  1 13:59:51.656: INFO: namespace e2e-tests-pods-kqvll deletion completed in 22.142267371s

• [SLOW TEST:22.415 seconds]
[k8s.io] [sig-node] Pods Extended
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should be submitted and removed  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 13:59:51.656: INFO: >>> kubeConfig: /tmp/kubeconfig-210205575
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-map-48b30077-3c2a-11e9-a154-0a580a280202
STEP: Creating a pod to test consume configMaps
Mar  1 13:59:51.761: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-48b39328-3c2a-11e9-a154-0a580a280202" in namespace "e2e-tests-projected-cgxhw" to be "success or failure"
Mar  1 13:59:51.765: INFO: Pod "pod-projected-configmaps-48b39328-3c2a-11e9-a154-0a580a280202": Phase="Pending", Reason="", readiness=false. Elapsed: 3.993776ms
Mar  1 13:59:53.769: INFO: Pod "pod-projected-configmaps-48b39328-3c2a-11e9-a154-0a580a280202": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007785336s
STEP: Saw pod success
Mar  1 13:59:53.769: INFO: Pod "pod-projected-configmaps-48b39328-3c2a-11e9-a154-0a580a280202" satisfied condition "success or failure"
Mar  1 13:59:53.772: INFO: Trying to get logs from node gke-conformance-default-pool-eca581b0-sqmc pod pod-projected-configmaps-48b39328-3c2a-11e9-a154-0a580a280202 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Mar  1 13:59:53.796: INFO: Waiting for pod pod-projected-configmaps-48b39328-3c2a-11e9-a154-0a580a280202 to disappear
Mar  1 13:59:53.802: INFO: Pod pod-projected-configmaps-48b39328-3c2a-11e9-a154-0a580a280202 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 13:59:53.802: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-cgxhw" for this suite.
Mar  1 13:59:59.818: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 13:59:59.984: INFO: namespace: e2e-tests-projected-cgxhw, resource: bindings, ignored listing per whitelist
Mar  1 14:00:00.341: INFO: namespace e2e-tests-projected-cgxhw deletion completed in 6.534438029s

• [SLOW TEST:8.685 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 14:00:00.341: INFO: >>> kubeConfig: /tmp/kubeconfig-210205575
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:98
[It] should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Mar  1 14:00:00.463: INFO: Requires at least 2 nodes (not -1)
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:64
Mar  1 14:00:00.468: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-c2495/daemonsets","resourceVersion":"9232"},"items":null}

Mar  1 14:00:00.470: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-c2495/pods","resourceVersion":"9232"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 14:00:00.497: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-c2495" for this suite.
Mar  1 14:00:06.515: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 14:00:06.675: INFO: namespace: e2e-tests-daemonsets-c2495, resource: bindings, ignored listing per whitelist
Mar  1 14:00:06.860: INFO: namespace e2e-tests-daemonsets-c2495 deletion completed in 6.35835259s

S [SKIPPING] [6.519 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should rollback without unnecessary restarts [Conformance] [It]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699

  Mar  1 14:00:00.463: Requires at least 2 nodes (not -1)

  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/util.go:292
------------------------------
SSSS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 14:00:06.860: INFO: >>> kubeConfig: /tmp/kubeconfig-210205575
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-map-51d0cbeb-3c2a-11e9-a154-0a580a280202
STEP: Creating a pod to test consume secrets
Mar  1 14:00:07.081: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-51d443cf-3c2a-11e9-a154-0a580a280202" in namespace "e2e-tests-projected-pkmnr" to be "success or failure"
Mar  1 14:00:07.088: INFO: Pod "pod-projected-secrets-51d443cf-3c2a-11e9-a154-0a580a280202": Phase="Pending", Reason="", readiness=false. Elapsed: 7.100511ms
Mar  1 14:00:09.091: INFO: Pod "pod-projected-secrets-51d443cf-3c2a-11e9-a154-0a580a280202": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010865534s
STEP: Saw pod success
Mar  1 14:00:09.091: INFO: Pod "pod-projected-secrets-51d443cf-3c2a-11e9-a154-0a580a280202" satisfied condition "success or failure"
Mar  1 14:00:09.094: INFO: Trying to get logs from node gke-conformance-default-pool-eca581b0-czl4 pod pod-projected-secrets-51d443cf-3c2a-11e9-a154-0a580a280202 container projected-secret-volume-test: <nil>
STEP: delete the pod
Mar  1 14:00:09.118: INFO: Waiting for pod pod-projected-secrets-51d443cf-3c2a-11e9-a154-0a580a280202 to disappear
Mar  1 14:00:09.122: INFO: Pod pod-projected-secrets-51d443cf-3c2a-11e9-a154-0a580a280202 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 14:00:09.122: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-pkmnr" for this suite.
Mar  1 14:00:15.209: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 14:00:15.329: INFO: namespace: e2e-tests-projected-pkmnr, resource: bindings, ignored listing per whitelist
Mar  1 14:00:15.372: INFO: namespace e2e-tests-projected-pkmnr deletion completed in 6.245128075s

• [SLOW TEST:8.512 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 14:00:15.372: INFO: >>> kubeConfig: /tmp/kubeconfig-210205575
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-map-56d68fc4-3c2a-11e9-a154-0a580a280202
STEP: Creating a pod to test consume secrets
Mar  1 14:00:15.483: INFO: Waiting up to 5m0s for pod "pod-secrets-56d73dd4-3c2a-11e9-a154-0a580a280202" in namespace "e2e-tests-secrets-2drln" to be "success or failure"
Mar  1 14:00:15.485: INFO: Pod "pod-secrets-56d73dd4-3c2a-11e9-a154-0a580a280202": Phase="Pending", Reason="", readiness=false. Elapsed: 2.765135ms
Mar  1 14:00:17.489: INFO: Pod "pod-secrets-56d73dd4-3c2a-11e9-a154-0a580a280202": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00609775s
Mar  1 14:00:19.493: INFO: Pod "pod-secrets-56d73dd4-3c2a-11e9-a154-0a580a280202": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.010212267s
STEP: Saw pod success
Mar  1 14:00:19.493: INFO: Pod "pod-secrets-56d73dd4-3c2a-11e9-a154-0a580a280202" satisfied condition "success or failure"
Mar  1 14:00:19.496: INFO: Trying to get logs from node gke-conformance-default-pool-eca581b0-sww9 pod pod-secrets-56d73dd4-3c2a-11e9-a154-0a580a280202 container secret-volume-test: <nil>
STEP: delete the pod
Mar  1 14:00:19.530: INFO: Waiting for pod pod-secrets-56d73dd4-3c2a-11e9-a154-0a580a280202 to disappear
Mar  1 14:00:19.534: INFO: Pod pod-secrets-56d73dd4-3c2a-11e9-a154-0a580a280202 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 14:00:19.534: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-2drln" for this suite.
Mar  1 14:00:25.548: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 14:00:25.661: INFO: namespace: e2e-tests-secrets-2drln, resource: bindings, ignored listing per whitelist
Mar  1 14:00:25.665: INFO: namespace e2e-tests-secrets-2drln deletion completed in 6.127613561s

• [SLOW TEST:10.294 seconds]
[sig-storage] Secrets
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 14:00:25.665: INFO: >>> kubeConfig: /tmp/kubeconfig-210205575
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Mar  1 14:00:25.763: INFO: Waiting up to 5m0s for pod "downwardapi-volume-5cf7fd53-3c2a-11e9-a154-0a580a280202" in namespace "e2e-tests-downward-api-9gf6g" to be "success or failure"
Mar  1 14:00:25.767: INFO: Pod "downwardapi-volume-5cf7fd53-3c2a-11e9-a154-0a580a280202": Phase="Pending", Reason="", readiness=false. Elapsed: 3.183851ms
Mar  1 14:00:27.771: INFO: Pod "downwardapi-volume-5cf7fd53-3c2a-11e9-a154-0a580a280202": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007703215s
Mar  1 14:00:29.775: INFO: Pod "downwardapi-volume-5cf7fd53-3c2a-11e9-a154-0a580a280202": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011172301s
STEP: Saw pod success
Mar  1 14:00:29.775: INFO: Pod "downwardapi-volume-5cf7fd53-3c2a-11e9-a154-0a580a280202" satisfied condition "success or failure"
Mar  1 14:00:29.778: INFO: Trying to get logs from node gke-conformance-default-pool-eca581b0-sqmc pod downwardapi-volume-5cf7fd53-3c2a-11e9-a154-0a580a280202 container client-container: <nil>
STEP: delete the pod
Mar  1 14:00:29.805: INFO: Waiting for pod downwardapi-volume-5cf7fd53-3c2a-11e9-a154-0a580a280202 to disappear
Mar  1 14:00:29.810: INFO: Pod downwardapi-volume-5cf7fd53-3c2a-11e9-a154-0a580a280202 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 14:00:29.810: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-9gf6g" for this suite.
Mar  1 14:00:35.829: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 14:00:35.877: INFO: namespace: e2e-tests-downward-api-9gf6g, resource: bindings, ignored listing per whitelist
Mar  1 14:00:35.950: INFO: namespace e2e-tests-downward-api-9gf6g deletion completed in 6.134602167s

• [SLOW TEST:10.285 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-auth] ServiceAccounts 
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 14:00:35.950: INFO: >>> kubeConfig: /tmp/kubeconfig-210205575
STEP: Building a namespace api object, basename svcaccounts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should mount an API token into pods  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: getting the auto-created API token
STEP: Creating a pod to test consume service account token
Mar  1 14:00:36.595: INFO: Waiting up to 5m0s for pod "pod-service-account-636bc453-3c2a-11e9-a154-0a580a280202-klsc7" in namespace "e2e-tests-svcaccounts-g72rv" to be "success or failure"
Mar  1 14:00:36.605: INFO: Pod "pod-service-account-636bc453-3c2a-11e9-a154-0a580a280202-klsc7": Phase="Pending", Reason="", readiness=false. Elapsed: 9.967239ms
Mar  1 14:00:38.609: INFO: Pod "pod-service-account-636bc453-3c2a-11e9-a154-0a580a280202-klsc7": Phase="Running", Reason="", readiness=false. Elapsed: 2.013873912s
Mar  1 14:00:40.612: INFO: Pod "pod-service-account-636bc453-3c2a-11e9-a154-0a580a280202-klsc7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.017351428s
STEP: Saw pod success
Mar  1 14:00:40.612: INFO: Pod "pod-service-account-636bc453-3c2a-11e9-a154-0a580a280202-klsc7" satisfied condition "success or failure"
Mar  1 14:00:40.615: INFO: Trying to get logs from node gke-conformance-default-pool-eca581b0-czl4 pod pod-service-account-636bc453-3c2a-11e9-a154-0a580a280202-klsc7 container token-test: <nil>
STEP: delete the pod
Mar  1 14:00:40.640: INFO: Waiting for pod pod-service-account-636bc453-3c2a-11e9-a154-0a580a280202-klsc7 to disappear
Mar  1 14:00:40.645: INFO: Pod pod-service-account-636bc453-3c2a-11e9-a154-0a580a280202-klsc7 no longer exists
STEP: Creating a pod to test consume service account root CA
Mar  1 14:00:40.662: INFO: Waiting up to 5m0s for pod "pod-service-account-636bc453-3c2a-11e9-a154-0a580a280202-qdqfw" in namespace "e2e-tests-svcaccounts-g72rv" to be "success or failure"
Mar  1 14:00:40.672: INFO: Pod "pod-service-account-636bc453-3c2a-11e9-a154-0a580a280202-qdqfw": Phase="Pending", Reason="", readiness=false. Elapsed: 10.198991ms
Mar  1 14:00:42.676: INFO: Pod "pod-service-account-636bc453-3c2a-11e9-a154-0a580a280202-qdqfw": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01352027s
Mar  1 14:00:44.680: INFO: Pod "pod-service-account-636bc453-3c2a-11e9-a154-0a580a280202-qdqfw": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.017516757s
STEP: Saw pod success
Mar  1 14:00:44.680: INFO: Pod "pod-service-account-636bc453-3c2a-11e9-a154-0a580a280202-qdqfw" satisfied condition "success or failure"
Mar  1 14:00:44.684: INFO: Trying to get logs from node gke-conformance-default-pool-eca581b0-sww9 pod pod-service-account-636bc453-3c2a-11e9-a154-0a580a280202-qdqfw container root-ca-test: <nil>
STEP: delete the pod
Mar  1 14:00:44.708: INFO: Waiting for pod pod-service-account-636bc453-3c2a-11e9-a154-0a580a280202-qdqfw to disappear
Mar  1 14:00:44.712: INFO: Pod pod-service-account-636bc453-3c2a-11e9-a154-0a580a280202-qdqfw no longer exists
STEP: Creating a pod to test consume service account namespace
Mar  1 14:00:44.723: INFO: Waiting up to 5m0s for pod "pod-service-account-636bc453-3c2a-11e9-a154-0a580a280202-zmkp4" in namespace "e2e-tests-svcaccounts-g72rv" to be "success or failure"
Mar  1 14:00:44.732: INFO: Pod "pod-service-account-636bc453-3c2a-11e9-a154-0a580a280202-zmkp4": Phase="Pending", Reason="", readiness=false. Elapsed: 9.329093ms
Mar  1 14:00:46.736: INFO: Pod "pod-service-account-636bc453-3c2a-11e9-a154-0a580a280202-zmkp4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013071105s
Mar  1 14:00:48.740: INFO: Pod "pod-service-account-636bc453-3c2a-11e9-a154-0a580a280202-zmkp4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.016543844s
STEP: Saw pod success
Mar  1 14:00:48.740: INFO: Pod "pod-service-account-636bc453-3c2a-11e9-a154-0a580a280202-zmkp4" satisfied condition "success or failure"
Mar  1 14:00:48.743: INFO: Trying to get logs from node gke-conformance-default-pool-eca581b0-00fq pod pod-service-account-636bc453-3c2a-11e9-a154-0a580a280202-zmkp4 container namespace-test: <nil>
STEP: delete the pod
Mar  1 14:00:48.767: INFO: Waiting for pod pod-service-account-636bc453-3c2a-11e9-a154-0a580a280202-zmkp4 to disappear
Mar  1 14:00:48.773: INFO: Pod pod-service-account-636bc453-3c2a-11e9-a154-0a580a280202-zmkp4 no longer exists
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 14:00:48.773: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-svcaccounts-g72rv" for this suite.
Mar  1 14:00:54.788: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 14:00:54.948: INFO: namespace: e2e-tests-svcaccounts-g72rv, resource: bindings, ignored listing per whitelist
Mar  1 14:00:55.018: INFO: namespace e2e-tests-svcaccounts-g72rv deletion completed in 6.241570964s

• [SLOW TEST:19.068 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:22
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-api-machinery] Secrets 
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 14:00:55.018: INFO: >>> kubeConfig: /tmp/kubeconfig-210205575
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-6e789470-3c2a-11e9-a154-0a580a280202
STEP: Creating a pod to test consume secrets
Mar  1 14:00:55.133: INFO: Waiting up to 5m0s for pod "pod-secrets-6e793860-3c2a-11e9-a154-0a580a280202" in namespace "e2e-tests-secrets-l7b8d" to be "success or failure"
Mar  1 14:00:55.138: INFO: Pod "pod-secrets-6e793860-3c2a-11e9-a154-0a580a280202": Phase="Pending", Reason="", readiness=false. Elapsed: 4.696499ms
Mar  1 14:00:57.142: INFO: Pod "pod-secrets-6e793860-3c2a-11e9-a154-0a580a280202": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008336883s
STEP: Saw pod success
Mar  1 14:00:57.142: INFO: Pod "pod-secrets-6e793860-3c2a-11e9-a154-0a580a280202" satisfied condition "success or failure"
Mar  1 14:00:57.149: INFO: Trying to get logs from node gke-conformance-default-pool-eca581b0-czl4 pod pod-secrets-6e793860-3c2a-11e9-a154-0a580a280202 container secret-env-test: <nil>
STEP: delete the pod
Mar  1 14:00:57.181: INFO: Waiting for pod pod-secrets-6e793860-3c2a-11e9-a154-0a580a280202 to disappear
Mar  1 14:00:57.186: INFO: Pod pod-secrets-6e793860-3c2a-11e9-a154-0a580a280202 no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 14:00:57.186: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-l7b8d" for this suite.
Mar  1 14:01:03.204: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 14:01:03.233: INFO: namespace: e2e-tests-secrets-l7b8d, resource: bindings, ignored listing per whitelist
Mar  1 14:01:03.353: INFO: namespace e2e-tests-secrets-l7b8d deletion completed in 6.16384552s

• [SLOW TEST:8.335 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:31
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Projected 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 14:01:03.353: INFO: >>> kubeConfig: /tmp/kubeconfig-210205575
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Mar  1 14:01:03.455: INFO: Waiting up to 5m0s for pod "downwardapi-volume-736edc84-3c2a-11e9-a154-0a580a280202" in namespace "e2e-tests-projected-qx4bw" to be "success or failure"
Mar  1 14:01:03.465: INFO: Pod "downwardapi-volume-736edc84-3c2a-11e9-a154-0a580a280202": Phase="Pending", Reason="", readiness=false. Elapsed: 9.967439ms
Mar  1 14:01:05.468: INFO: Pod "downwardapi-volume-736edc84-3c2a-11e9-a154-0a580a280202": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01316053s
Mar  1 14:01:07.472: INFO: Pod "downwardapi-volume-736edc84-3c2a-11e9-a154-0a580a280202": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.016754954s
STEP: Saw pod success
Mar  1 14:01:07.472: INFO: Pod "downwardapi-volume-736edc84-3c2a-11e9-a154-0a580a280202" satisfied condition "success or failure"
Mar  1 14:01:07.475: INFO: Trying to get logs from node gke-conformance-default-pool-eca581b0-sww9 pod downwardapi-volume-736edc84-3c2a-11e9-a154-0a580a280202 container client-container: <nil>
STEP: delete the pod
Mar  1 14:01:07.501: INFO: Waiting for pod downwardapi-volume-736edc84-3c2a-11e9-a154-0a580a280202 to disappear
Mar  1 14:01:07.505: INFO: Pod downwardapi-volume-736edc84-3c2a-11e9-a154-0a580a280202 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 14:01:07.505: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-qx4bw" for this suite.
Mar  1 14:01:13.520: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 14:01:13.608: INFO: namespace: e2e-tests-projected-qx4bw, resource: bindings, ignored listing per whitelist
Mar  1 14:01:13.642: INFO: namespace e2e-tests-projected-qx4bw deletion completed in 6.132424754s

• [SLOW TEST:10.289 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-network] Service endpoints latency 
  should not be very high  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 14:01:13.642: INFO: >>> kubeConfig: /tmp/kubeconfig-210205575
STEP: Building a namespace api object, basename svc-latency
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be very high  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating replication controller svc-latency-rc in namespace e2e-tests-svc-latency-28vx9
I0301 14:01:13.742633      19 runners.go:180] Created replication controller with name: svc-latency-rc, namespace: e2e-tests-svc-latency-28vx9, replica count: 1
I0301 14:01:14.793219      19 runners.go:180] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0301 14:01:15.793436      19 runners.go:180] svc-latency-rc Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Mar  1 14:01:15.908: INFO: Created: latency-svc-q2j9z
Mar  1 14:01:15.919: INFO: Got endpoints: latency-svc-q2j9z [26.223951ms]
Mar  1 14:01:15.938: INFO: Created: latency-svc-2m5kx
Mar  1 14:01:15.942: INFO: Got endpoints: latency-svc-2m5kx [22.523839ms]
Mar  1 14:01:15.953: INFO: Created: latency-svc-88m5r
Mar  1 14:01:15.967: INFO: Created: latency-svc-zdzfz
Mar  1 14:01:15.981: INFO: Got endpoints: latency-svc-88m5r [61.159486ms]
Mar  1 14:01:15.988: INFO: Created: latency-svc-fd22c
Mar  1 14:01:15.999: INFO: Created: latency-svc-z5v85
Mar  1 14:01:16.010: INFO: Got endpoints: latency-svc-zdzfz [89.740138ms]
Mar  1 14:01:16.019: INFO: Created: latency-svc-6227f
Mar  1 14:01:16.023: INFO: Got endpoints: latency-svc-fd22c [103.754094ms]
Mar  1 14:01:16.037: INFO: Created: latency-svc-qnpzb
Mar  1 14:01:16.040: INFO: Created: latency-svc-2rrdh
Mar  1 14:01:16.041: INFO: Got endpoints: latency-svc-z5v85 [120.965821ms]
Mar  1 14:01:16.056: INFO: Created: latency-svc-tjswr
Mar  1 14:01:16.068: INFO: Got endpoints: latency-svc-6227f [148.198955ms]
Mar  1 14:01:16.093: INFO: Created: latency-svc-vd8wx
Mar  1 14:01:16.096: INFO: Got endpoints: latency-svc-qnpzb [175.961155ms]
Mar  1 14:01:16.096: INFO: Got endpoints: latency-svc-2rrdh [175.951003ms]
Mar  1 14:01:16.109: INFO: Created: latency-svc-r7htz
Mar  1 14:01:16.115: INFO: Got endpoints: latency-svc-tjswr [195.400924ms]
Mar  1 14:01:16.125: INFO: Created: latency-svc-rpgj4
Mar  1 14:01:16.129: INFO: Got endpoints: latency-svc-vd8wx [209.383315ms]
Mar  1 14:01:16.144: INFO: Created: latency-svc-wm2zk
Mar  1 14:01:16.145: INFO: Got endpoints: latency-svc-r7htz [225.340595ms]
Mar  1 14:01:16.145: INFO: Created: latency-svc-58hrr
Mar  1 14:01:16.163: INFO: Created: latency-svc-ngr2m
Mar  1 14:01:16.180: INFO: Created: latency-svc-k6zhl
Mar  1 14:01:16.188: INFO: Got endpoints: latency-svc-wm2zk [267.865357ms]
Mar  1 14:01:16.188: INFO: Got endpoints: latency-svc-rpgj4 [268.206474ms]
Mar  1 14:01:16.188: INFO: Got endpoints: latency-svc-58hrr [267.929357ms]
Mar  1 14:01:16.201: INFO: Created: latency-svc-gd8sc
Mar  1 14:01:16.206: INFO: Created: latency-svc-vxpmm
Mar  1 14:01:16.209: INFO: Got endpoints: latency-svc-ngr2m [288.726774ms]
Mar  1 14:01:16.222: INFO: Got endpoints: latency-svc-k6zhl [280.267545ms]
Mar  1 14:01:16.222: INFO: Created: latency-svc-2gdlw
Mar  1 14:01:16.223: INFO: Created: latency-svc-m6qnq
Mar  1 14:01:16.242: INFO: Got endpoints: latency-svc-gd8sc [261.369749ms]
Mar  1 14:01:16.256: INFO: Created: latency-svc-lxhrs
Mar  1 14:01:16.264: INFO: Got endpoints: latency-svc-vxpmm [254.588432ms]
Mar  1 14:01:16.275: INFO: Created: latency-svc-6lqcf
Mar  1 14:01:16.294: INFO: Got endpoints: latency-svc-lxhrs [226.39123ms]
Mar  1 14:01:16.299: INFO: Got endpoints: latency-svc-m6qnq [275.6826ms]
Mar  1 14:01:16.299: INFO: Got endpoints: latency-svc-2gdlw [258.328053ms]
Mar  1 14:01:16.302: INFO: Created: latency-svc-r6kgn
Mar  1 14:01:16.302: INFO: Created: latency-svc-6tgqg
Mar  1 14:01:16.324: INFO: Got endpoints: latency-svc-6lqcf [227.928425ms]
Mar  1 14:01:16.325: INFO: Created: latency-svc-9th2d
Mar  1 14:01:16.332: INFO: Got endpoints: latency-svc-r6kgn [216.741962ms]
Mar  1 14:01:16.335: INFO: Created: latency-svc-lvqdp
Mar  1 14:01:16.336: INFO: Created: latency-svc-qlfm9
Mar  1 14:01:16.351: INFO: Created: latency-svc-79d96
Mar  1 14:01:16.355: INFO: Got endpoints: latency-svc-6tgqg [259.5858ms]
Mar  1 14:01:16.372: INFO: Created: latency-svc-stkng
Mar  1 14:01:16.377: INFO: Got endpoints: latency-svc-9th2d [247.930684ms]
Mar  1 14:01:16.377: INFO: Got endpoints: latency-svc-lvqdp [189.577347ms]
Mar  1 14:01:16.391: INFO: Created: latency-svc-r2kbb
Mar  1 14:01:16.392: INFO: Got endpoints: latency-svc-qlfm9 [247.128531ms]
Mar  1 14:01:16.405: INFO: Created: latency-svc-vzljj
Mar  1 14:01:16.405: INFO: Got endpoints: latency-svc-79d96 [217.179821ms]
Mar  1 14:01:16.416: INFO: Created: latency-svc-92lz6
Mar  1 14:01:16.421: INFO: Got endpoints: latency-svc-stkng [233.387281ms]
Mar  1 14:01:16.429: INFO: Created: latency-svc-w8pcq
Mar  1 14:01:16.436: INFO: Got endpoints: latency-svc-r2kbb [227.159164ms]
Mar  1 14:01:16.446: INFO: Got endpoints: latency-svc-vzljj [224.047278ms]
Mar  1 14:01:16.452: INFO: Created: latency-svc-vmzcs
Mar  1 14:01:16.470: INFO: Created: latency-svc-q6f8n
Mar  1 14:01:16.471: INFO: Got endpoints: latency-svc-92lz6 [228.974804ms]
Mar  1 14:01:16.471: INFO: Got endpoints: latency-svc-w8pcq [206.996929ms]
Mar  1 14:01:16.488: INFO: Created: latency-svc-8hrlx
Mar  1 14:01:16.495: INFO: Created: latency-svc-v9ksg
Mar  1 14:01:16.496: INFO: Created: latency-svc-4crnl
Mar  1 14:01:16.498: INFO: Got endpoints: latency-svc-vmzcs [203.808641ms]
Mar  1 14:01:16.498: INFO: Got endpoints: latency-svc-q6f8n [198.934216ms]
Mar  1 14:01:16.511: INFO: Got endpoints: latency-svc-8hrlx [211.994721ms]
Mar  1 14:01:16.519: INFO: Got endpoints: latency-svc-4crnl [187.388825ms]
Mar  1 14:01:16.519: INFO: Got endpoints: latency-svc-v9ksg [195.767653ms]
Mar  1 14:01:16.555: INFO: Created: latency-svc-qmn29
Mar  1 14:01:16.582: INFO: Created: latency-svc-nclg4
Mar  1 14:01:16.614: INFO: Created: latency-svc-qtsx7
Mar  1 14:01:16.620: INFO: Got endpoints: latency-svc-qmn29 [264.801727ms]
Mar  1 14:01:16.635: INFO: Created: latency-svc-vmbcc
Mar  1 14:01:16.653: INFO: Got endpoints: latency-svc-qtsx7 [275.65595ms]
Mar  1 14:01:16.655: INFO: Created: latency-svc-266c2
Mar  1 14:01:16.656: INFO: Created: latency-svc-mt9g7
Mar  1 14:01:16.669: INFO: Got endpoints: latency-svc-nclg4 [291.453158ms]
Mar  1 14:01:16.682: INFO: Got endpoints: latency-svc-vmbcc [289.826469ms]
Mar  1 14:01:16.684: INFO: Created: latency-svc-fwq9b
Mar  1 14:01:16.702: INFO: Created: latency-svc-dflk7
Mar  1 14:01:16.703: INFO: Got endpoints: latency-svc-mt9g7 [281.776582ms]
Mar  1 14:01:16.725: INFO: Got endpoints: latency-svc-266c2 [320.237612ms]
Mar  1 14:01:16.726: INFO: Created: latency-svc-sbwqv
Mar  1 14:01:16.747: INFO: Created: latency-svc-7gtxc
Mar  1 14:01:16.756: INFO: Created: latency-svc-6zwhd
Mar  1 14:01:16.756: INFO: Got endpoints: latency-svc-fwq9b [320.377555ms]
Mar  1 14:01:16.767: INFO: Created: latency-svc-v7rsw
Mar  1 14:01:16.780: INFO: Created: latency-svc-hvbcw
Mar  1 14:01:16.780: INFO: Created: latency-svc-xcvbz
Mar  1 14:01:16.806: INFO: Created: latency-svc-9mcnf
Mar  1 14:01:16.806: INFO: Got endpoints: latency-svc-dflk7 [359.877394ms]
Mar  1 14:01:16.834: INFO: Created: latency-svc-b79vp
Mar  1 14:01:16.841: INFO: Created: latency-svc-ww6jf
Mar  1 14:01:16.842: INFO: Got endpoints: latency-svc-sbwqv [371.191801ms]
Mar  1 14:01:16.865: INFO: Created: latency-svc-p7ns8
Mar  1 14:01:16.865: INFO: Created: latency-svc-5kmpv
Mar  1 14:01:16.882: INFO: Created: latency-svc-d2z5p
Mar  1 14:01:16.907: INFO: Created: latency-svc-9qzvt
Mar  1 14:01:16.916: INFO: Got endpoints: latency-svc-7gtxc [444.306393ms]
Mar  1 14:01:16.925: INFO: Created: latency-svc-qtm2c
Mar  1 14:01:16.925: INFO: Created: latency-svc-pmkdm
Mar  1 14:01:16.930: INFO: Got endpoints: latency-svc-6zwhd [432.007747ms]
Mar  1 14:01:16.935: INFO: Created: latency-svc-k67jm
Mar  1 14:01:16.949: INFO: Created: latency-svc-gtsjz
Mar  1 14:01:16.957: INFO: Created: latency-svc-xmlfx
Mar  1 14:01:16.964: INFO: Got endpoints: latency-svc-v7rsw [465.961434ms]
Mar  1 14:01:16.982: INFO: Created: latency-svc-2z8gb
Mar  1 14:01:17.019: INFO: Got endpoints: latency-svc-hvbcw [499.855966ms]
Mar  1 14:01:17.032: INFO: Created: latency-svc-t7zdx
Mar  1 14:01:17.065: INFO: Got endpoints: latency-svc-xcvbz [554.085182ms]
Mar  1 14:01:17.084: INFO: Created: latency-svc-dr7lc
Mar  1 14:01:17.113: INFO: Got endpoints: latency-svc-9mcnf [593.921727ms]
Mar  1 14:01:17.129: INFO: Created: latency-svc-mwgsd
Mar  1 14:01:17.165: INFO: Got endpoints: latency-svc-b79vp [544.61338ms]
Mar  1 14:01:17.178: INFO: Created: latency-svc-g5qtm
Mar  1 14:01:17.213: INFO: Got endpoints: latency-svc-ww6jf [560.30873ms]
Mar  1 14:01:17.232: INFO: Created: latency-svc-pdcb8
Mar  1 14:01:17.265: INFO: Got endpoints: latency-svc-5kmpv [583.205843ms]
Mar  1 14:01:17.280: INFO: Created: latency-svc-szs49
Mar  1 14:01:17.314: INFO: Got endpoints: latency-svc-p7ns8 [645.311372ms]
Mar  1 14:01:17.330: INFO: Created: latency-svc-5d7mf
Mar  1 14:01:17.366: INFO: Got endpoints: latency-svc-d2z5p [662.629024ms]
Mar  1 14:01:17.378: INFO: Created: latency-svc-87gr8
Mar  1 14:01:17.413: INFO: Got endpoints: latency-svc-9qzvt [687.760974ms]
Mar  1 14:01:17.426: INFO: Created: latency-svc-mn4g4
Mar  1 14:01:17.463: INFO: Got endpoints: latency-svc-qtm2c [656.232078ms]
Mar  1 14:01:17.479: INFO: Created: latency-svc-h5l5f
Mar  1 14:01:17.514: INFO: Got endpoints: latency-svc-pmkdm [758.315126ms]
Mar  1 14:01:17.530: INFO: Created: latency-svc-tt4vk
Mar  1 14:01:17.564: INFO: Got endpoints: latency-svc-k67jm [721.929995ms]
Mar  1 14:01:17.577: INFO: Created: latency-svc-jxlgq
Mar  1 14:01:17.614: INFO: Got endpoints: latency-svc-gtsjz [698.756098ms]
Mar  1 14:01:17.627: INFO: Created: latency-svc-kq4f2
Mar  1 14:01:17.664: INFO: Got endpoints: latency-svc-xmlfx [734.210508ms]
Mar  1 14:01:17.680: INFO: Created: latency-svc-gcndz
Mar  1 14:01:17.713: INFO: Got endpoints: latency-svc-2z8gb [748.651006ms]
Mar  1 14:01:17.729: INFO: Created: latency-svc-kld9r
Mar  1 14:01:17.764: INFO: Got endpoints: latency-svc-t7zdx [745.044579ms]
Mar  1 14:01:17.777: INFO: Created: latency-svc-tmt2p
Mar  1 14:01:17.815: INFO: Got endpoints: latency-svc-dr7lc [749.560832ms]
Mar  1 14:01:17.828: INFO: Created: latency-svc-ld57w
Mar  1 14:01:17.866: INFO: Got endpoints: latency-svc-mwgsd [752.47155ms]
Mar  1 14:01:17.878: INFO: Created: latency-svc-s5ntq
Mar  1 14:01:17.915: INFO: Got endpoints: latency-svc-g5qtm [750.657109ms]
Mar  1 14:01:17.933: INFO: Created: latency-svc-tmvr6
Mar  1 14:01:17.966: INFO: Got endpoints: latency-svc-pdcb8 [752.66274ms]
Mar  1 14:01:17.988: INFO: Created: latency-svc-6jh9b
Mar  1 14:01:18.013: INFO: Got endpoints: latency-svc-szs49 [747.5523ms]
Mar  1 14:01:18.027: INFO: Created: latency-svc-9rw8x
Mar  1 14:01:18.065: INFO: Got endpoints: latency-svc-5d7mf [751.28419ms]
Mar  1 14:01:18.081: INFO: Created: latency-svc-9jm77
Mar  1 14:01:18.115: INFO: Got endpoints: latency-svc-87gr8 [748.947883ms]
Mar  1 14:01:18.129: INFO: Created: latency-svc-lxkl5
Mar  1 14:01:18.165: INFO: Got endpoints: latency-svc-mn4g4 [751.913593ms]
Mar  1 14:01:18.178: INFO: Created: latency-svc-mfbcv
Mar  1 14:01:18.215: INFO: Got endpoints: latency-svc-h5l5f [752.451456ms]
Mar  1 14:01:18.234: INFO: Created: latency-svc-5rblw
Mar  1 14:01:18.268: INFO: Got endpoints: latency-svc-tt4vk [753.667097ms]
Mar  1 14:01:18.285: INFO: Created: latency-svc-fm496
Mar  1 14:01:18.314: INFO: Got endpoints: latency-svc-jxlgq [749.902832ms]
Mar  1 14:01:18.331: INFO: Created: latency-svc-xkztr
Mar  1 14:01:18.365: INFO: Got endpoints: latency-svc-kq4f2 [750.220442ms]
Mar  1 14:01:18.379: INFO: Created: latency-svc-t77b9
Mar  1 14:01:18.415: INFO: Got endpoints: latency-svc-gcndz [750.874679ms]
Mar  1 14:01:18.434: INFO: Created: latency-svc-5vzkq
Mar  1 14:01:18.465: INFO: Got endpoints: latency-svc-kld9r [752.174134ms]
Mar  1 14:01:18.479: INFO: Created: latency-svc-qs6m6
Mar  1 14:01:18.514: INFO: Got endpoints: latency-svc-tmt2p [750.041379ms]
Mar  1 14:01:18.532: INFO: Created: latency-svc-kft2r
Mar  1 14:01:18.565: INFO: Got endpoints: latency-svc-ld57w [750.090492ms]
Mar  1 14:01:18.581: INFO: Created: latency-svc-nh5r6
Mar  1 14:01:18.613: INFO: Got endpoints: latency-svc-s5ntq [746.861511ms]
Mar  1 14:01:18.629: INFO: Created: latency-svc-g4q5b
Mar  1 14:01:18.672: INFO: Got endpoints: latency-svc-tmvr6 [756.86405ms]
Mar  1 14:01:18.689: INFO: Created: latency-svc-wngpr
Mar  1 14:01:18.716: INFO: Got endpoints: latency-svc-6jh9b [750.388672ms]
Mar  1 14:01:18.731: INFO: Created: latency-svc-n4zbj
Mar  1 14:01:18.763: INFO: Got endpoints: latency-svc-9rw8x [749.593764ms]
Mar  1 14:01:18.781: INFO: Created: latency-svc-k7rf6
Mar  1 14:01:18.821: INFO: Got endpoints: latency-svc-9jm77 [755.336096ms]
Mar  1 14:01:18.843: INFO: Created: latency-svc-2tjxt
Mar  1 14:01:18.864: INFO: Got endpoints: latency-svc-lxkl5 [749.624286ms]
Mar  1 14:01:18.878: INFO: Created: latency-svc-6fxzk
Mar  1 14:01:18.913: INFO: Got endpoints: latency-svc-mfbcv [747.611434ms]
Mar  1 14:01:18.934: INFO: Created: latency-svc-6vddt
Mar  1 14:01:18.965: INFO: Got endpoints: latency-svc-5rblw [749.767223ms]
Mar  1 14:01:18.978: INFO: Created: latency-svc-cnknh
Mar  1 14:01:19.015: INFO: Got endpoints: latency-svc-fm496 [747.034142ms]
Mar  1 14:01:19.037: INFO: Created: latency-svc-ghg8d
Mar  1 14:01:19.065: INFO: Got endpoints: latency-svc-xkztr [750.87097ms]
Mar  1 14:01:19.095: INFO: Created: latency-svc-8hk7q
Mar  1 14:01:19.125: INFO: Got endpoints: latency-svc-t77b9 [760.371484ms]
Mar  1 14:01:19.165: INFO: Created: latency-svc-b9htd
Mar  1 14:01:19.174: INFO: Got endpoints: latency-svc-5vzkq [758.138075ms]
Mar  1 14:01:19.214: INFO: Created: latency-svc-gwpmh
Mar  1 14:01:19.223: INFO: Got endpoints: latency-svc-qs6m6 [758.03718ms]
Mar  1 14:01:19.261: INFO: Created: latency-svc-xwtwc
Mar  1 14:01:19.278: INFO: Got endpoints: latency-svc-kft2r [763.945083ms]
Mar  1 14:01:19.325: INFO: Created: latency-svc-75ndc
Mar  1 14:01:19.334: INFO: Got endpoints: latency-svc-nh5r6 [768.995561ms]
Mar  1 14:01:19.389: INFO: Got endpoints: latency-svc-g4q5b [776.486774ms]
Mar  1 14:01:19.408: INFO: Created: latency-svc-nrj5j
Mar  1 14:01:19.438: INFO: Got endpoints: latency-svc-wngpr [765.540578ms]
Mar  1 14:01:19.469: INFO: Created: latency-svc-hw26f
Mar  1 14:01:19.481: INFO: Got endpoints: latency-svc-n4zbj [764.986266ms]
Mar  1 14:01:19.484: INFO: Created: latency-svc-8r5jw
Mar  1 14:01:19.499: INFO: Created: latency-svc-6w5gv
Mar  1 14:01:19.517: INFO: Got endpoints: latency-svc-k7rf6 [753.999068ms]
Mar  1 14:01:19.533: INFO: Created: latency-svc-8glbw
Mar  1 14:01:19.563: INFO: Got endpoints: latency-svc-2tjxt [742.521478ms]
Mar  1 14:01:19.578: INFO: Created: latency-svc-hkc8w
Mar  1 14:01:19.618: INFO: Got endpoints: latency-svc-6fxzk [753.319789ms]
Mar  1 14:01:19.633: INFO: Created: latency-svc-76xwn
Mar  1 14:01:19.664: INFO: Got endpoints: latency-svc-6vddt [750.976868ms]
Mar  1 14:01:19.688: INFO: Created: latency-svc-zqsnt
Mar  1 14:01:19.715: INFO: Got endpoints: latency-svc-cnknh [749.744218ms]
Mar  1 14:01:19.731: INFO: Created: latency-svc-cvdfk
Mar  1 14:01:19.765: INFO: Got endpoints: latency-svc-ghg8d [749.505895ms]
Mar  1 14:01:19.780: INFO: Created: latency-svc-sfdnb
Mar  1 14:01:19.813: INFO: Got endpoints: latency-svc-8hk7q [747.722318ms]
Mar  1 14:01:19.828: INFO: Created: latency-svc-5qqxl
Mar  1 14:01:19.864: INFO: Got endpoints: latency-svc-b9htd [738.77719ms]
Mar  1 14:01:19.888: INFO: Created: latency-svc-lf29l
Mar  1 14:01:19.914: INFO: Got endpoints: latency-svc-gwpmh [740.397308ms]
Mar  1 14:01:19.931: INFO: Created: latency-svc-ccmlx
Mar  1 14:01:19.970: INFO: Got endpoints: latency-svc-xwtwc [746.746518ms]
Mar  1 14:01:19.996: INFO: Created: latency-svc-64drr
Mar  1 14:01:20.012: INFO: Got endpoints: latency-svc-75ndc [733.994698ms]
Mar  1 14:01:20.028: INFO: Created: latency-svc-d5tjh
Mar  1 14:01:20.065: INFO: Got endpoints: latency-svc-nrj5j [730.556899ms]
Mar  1 14:01:20.079: INFO: Created: latency-svc-8xdm2
Mar  1 14:01:20.115: INFO: Got endpoints: latency-svc-hw26f [725.204078ms]
Mar  1 14:01:20.130: INFO: Created: latency-svc-zkk8q
Mar  1 14:01:20.165: INFO: Got endpoints: latency-svc-8r5jw [726.715578ms]
Mar  1 14:01:20.188: INFO: Created: latency-svc-d4db5
Mar  1 14:01:20.214: INFO: Got endpoints: latency-svc-6w5gv [731.984897ms]
Mar  1 14:01:20.228: INFO: Created: latency-svc-ns6vs
Mar  1 14:01:20.264: INFO: Got endpoints: latency-svc-8glbw [747.381003ms]
Mar  1 14:01:20.280: INFO: Created: latency-svc-hhgrz
Mar  1 14:01:20.315: INFO: Got endpoints: latency-svc-hkc8w [752.314969ms]
Mar  1 14:01:20.330: INFO: Created: latency-svc-8572f
Mar  1 14:01:20.363: INFO: Got endpoints: latency-svc-76xwn [744.813963ms]
Mar  1 14:01:20.385: INFO: Created: latency-svc-n5ccg
Mar  1 14:01:20.413: INFO: Got endpoints: latency-svc-zqsnt [749.591644ms]
Mar  1 14:01:20.429: INFO: Created: latency-svc-4dknf
Mar  1 14:01:20.464: INFO: Got endpoints: latency-svc-cvdfk [749.011871ms]
Mar  1 14:01:20.487: INFO: Created: latency-svc-8s942
Mar  1 14:01:20.517: INFO: Got endpoints: latency-svc-sfdnb [752.055448ms]
Mar  1 14:01:20.529: INFO: Created: latency-svc-ks85p
Mar  1 14:01:20.565: INFO: Got endpoints: latency-svc-5qqxl [752.149658ms]
Mar  1 14:01:20.581: INFO: Created: latency-svc-kv6m7
Mar  1 14:01:20.615: INFO: Got endpoints: latency-svc-lf29l [750.767824ms]
Mar  1 14:01:20.628: INFO: Created: latency-svc-w4c6w
Mar  1 14:01:20.664: INFO: Got endpoints: latency-svc-ccmlx [750.18461ms]
Mar  1 14:01:20.676: INFO: Created: latency-svc-5xmpr
Mar  1 14:01:20.714: INFO: Got endpoints: latency-svc-64drr [743.803261ms]
Mar  1 14:01:20.730: INFO: Created: latency-svc-zzkrq
Mar  1 14:01:20.764: INFO: Got endpoints: latency-svc-d5tjh [751.355257ms]
Mar  1 14:01:20.780: INFO: Created: latency-svc-4ng4v
Mar  1 14:01:20.813: INFO: Got endpoints: latency-svc-8xdm2 [748.374281ms]
Mar  1 14:01:20.827: INFO: Created: latency-svc-htq8q
Mar  1 14:01:20.864: INFO: Got endpoints: latency-svc-zkk8q [749.025386ms]
Mar  1 14:01:20.881: INFO: Created: latency-svc-4nhkw
Mar  1 14:01:20.914: INFO: Got endpoints: latency-svc-d4db5 [749.278504ms]
Mar  1 14:01:20.935: INFO: Created: latency-svc-25wjd
Mar  1 14:01:20.964: INFO: Got endpoints: latency-svc-ns6vs [750.534266ms]
Mar  1 14:01:20.977: INFO: Created: latency-svc-k4jr6
Mar  1 14:01:21.016: INFO: Got endpoints: latency-svc-hhgrz [751.734411ms]
Mar  1 14:01:21.030: INFO: Created: latency-svc-4rtvx
Mar  1 14:01:21.064: INFO: Got endpoints: latency-svc-8572f [748.587624ms]
Mar  1 14:01:21.076: INFO: Created: latency-svc-w54jg
Mar  1 14:01:21.113: INFO: Got endpoints: latency-svc-n5ccg [749.947996ms]
Mar  1 14:01:21.127: INFO: Created: latency-svc-4dllh
Mar  1 14:01:21.165: INFO: Got endpoints: latency-svc-4dknf [751.287535ms]
Mar  1 14:01:21.178: INFO: Created: latency-svc-8svq9
Mar  1 14:01:21.213: INFO: Got endpoints: latency-svc-8s942 [749.244679ms]
Mar  1 14:01:21.226: INFO: Created: latency-svc-z2wvm
Mar  1 14:01:21.265: INFO: Got endpoints: latency-svc-ks85p [747.668396ms]
Mar  1 14:01:21.277: INFO: Created: latency-svc-p2sln
Mar  1 14:01:21.312: INFO: Got endpoints: latency-svc-kv6m7 [747.058627ms]
Mar  1 14:01:21.328: INFO: Created: latency-svc-r5p48
Mar  1 14:01:21.364: INFO: Got endpoints: latency-svc-w4c6w [748.643132ms]
Mar  1 14:01:21.380: INFO: Created: latency-svc-vsrf6
Mar  1 14:01:21.414: INFO: Got endpoints: latency-svc-5xmpr [749.372393ms]
Mar  1 14:01:21.426: INFO: Created: latency-svc-fpkbd
Mar  1 14:01:21.465: INFO: Got endpoints: latency-svc-zzkrq [750.738974ms]
Mar  1 14:01:21.479: INFO: Created: latency-svc-dfqnf
Mar  1 14:01:21.513: INFO: Got endpoints: latency-svc-4ng4v [748.82097ms]
Mar  1 14:01:21.528: INFO: Created: latency-svc-rmpkn
Mar  1 14:01:21.564: INFO: Got endpoints: latency-svc-htq8q [751.181407ms]
Mar  1 14:01:21.578: INFO: Created: latency-svc-4f8fm
Mar  1 14:01:21.613: INFO: Got endpoints: latency-svc-4nhkw [749.641001ms]
Mar  1 14:01:21.626: INFO: Created: latency-svc-225qq
Mar  1 14:01:21.665: INFO: Got endpoints: latency-svc-25wjd [750.565594ms]
Mar  1 14:01:21.679: INFO: Created: latency-svc-ql2m5
Mar  1 14:01:21.715: INFO: Got endpoints: latency-svc-k4jr6 [751.022797ms]
Mar  1 14:01:21.728: INFO: Created: latency-svc-dk95g
Mar  1 14:01:21.763: INFO: Got endpoints: latency-svc-4rtvx [747.151174ms]
Mar  1 14:01:21.778: INFO: Created: latency-svc-kjpgx
Mar  1 14:01:21.815: INFO: Got endpoints: latency-svc-w54jg [750.361851ms]
Mar  1 14:01:21.827: INFO: Created: latency-svc-4z4vb
Mar  1 14:01:21.862: INFO: Got endpoints: latency-svc-4dllh [749.523456ms]
Mar  1 14:01:21.896: INFO: Created: latency-svc-r9gsq
Mar  1 14:01:21.913: INFO: Got endpoints: latency-svc-8svq9 [748.450308ms]
Mar  1 14:01:21.928: INFO: Created: latency-svc-sfrkx
Mar  1 14:01:21.965: INFO: Got endpoints: latency-svc-z2wvm [751.783422ms]
Mar  1 14:01:21.977: INFO: Created: latency-svc-l4tb7
Mar  1 14:01:22.013: INFO: Got endpoints: latency-svc-p2sln [748.520361ms]
Mar  1 14:01:22.028: INFO: Created: latency-svc-xr7k2
Mar  1 14:01:22.064: INFO: Got endpoints: latency-svc-r5p48 [751.902973ms]
Mar  1 14:01:22.075: INFO: Created: latency-svc-bj2kx
Mar  1 14:01:22.113: INFO: Got endpoints: latency-svc-vsrf6 [749.6969ms]
Mar  1 14:01:22.127: INFO: Created: latency-svc-zw45q
Mar  1 14:01:22.165: INFO: Got endpoints: latency-svc-fpkbd [751.124631ms]
Mar  1 14:01:22.178: INFO: Created: latency-svc-pz2sp
Mar  1 14:01:22.213: INFO: Got endpoints: latency-svc-dfqnf [748.237425ms]
Mar  1 14:01:22.226: INFO: Created: latency-svc-gtrsp
Mar  1 14:01:22.266: INFO: Got endpoints: latency-svc-rmpkn [752.826895ms]
Mar  1 14:01:22.277: INFO: Created: latency-svc-dvgsr
Mar  1 14:01:22.315: INFO: Got endpoints: latency-svc-4f8fm [750.179655ms]
Mar  1 14:01:22.330: INFO: Created: latency-svc-hb9dv
Mar  1 14:01:22.365: INFO: Got endpoints: latency-svc-225qq [751.487911ms]
Mar  1 14:01:22.380: INFO: Created: latency-svc-4tf2p
Mar  1 14:01:22.413: INFO: Got endpoints: latency-svc-ql2m5 [747.762117ms]
Mar  1 14:01:22.428: INFO: Created: latency-svc-r59d2
Mar  1 14:01:22.465: INFO: Got endpoints: latency-svc-dk95g [749.496683ms]
Mar  1 14:01:22.480: INFO: Created: latency-svc-dzf7p
Mar  1 14:01:22.518: INFO: Got endpoints: latency-svc-kjpgx [754.554296ms]
Mar  1 14:01:22.543: INFO: Created: latency-svc-r99w2
Mar  1 14:01:22.566: INFO: Got endpoints: latency-svc-4z4vb [751.005319ms]
Mar  1 14:01:22.583: INFO: Created: latency-svc-7tgxp
Mar  1 14:01:22.614: INFO: Got endpoints: latency-svc-r9gsq [751.844862ms]
Mar  1 14:01:22.628: INFO: Created: latency-svc-g4wdr
Mar  1 14:01:22.663: INFO: Got endpoints: latency-svc-sfrkx [749.315675ms]
Mar  1 14:01:22.678: INFO: Created: latency-svc-pvqv4
Mar  1 14:01:22.714: INFO: Got endpoints: latency-svc-l4tb7 [748.644914ms]
Mar  1 14:01:22.727: INFO: Created: latency-svc-22v4k
Mar  1 14:01:22.764: INFO: Got endpoints: latency-svc-xr7k2 [751.12161ms]
Mar  1 14:01:22.776: INFO: Created: latency-svc-4nrw5
Mar  1 14:01:22.814: INFO: Got endpoints: latency-svc-bj2kx [749.002578ms]
Mar  1 14:01:22.830: INFO: Created: latency-svc-b789n
Mar  1 14:01:22.865: INFO: Got endpoints: latency-svc-zw45q [751.291842ms]
Mar  1 14:01:22.878: INFO: Created: latency-svc-ght94
Mar  1 14:01:22.914: INFO: Got endpoints: latency-svc-pz2sp [748.62231ms]
Mar  1 14:01:22.928: INFO: Created: latency-svc-h5ttn
Mar  1 14:01:22.963: INFO: Got endpoints: latency-svc-gtrsp [750.194505ms]
Mar  1 14:01:22.979: INFO: Created: latency-svc-xlbrh
Mar  1 14:01:23.014: INFO: Got endpoints: latency-svc-dvgsr [747.854255ms]
Mar  1 14:01:23.047: INFO: Created: latency-svc-xzbsd
Mar  1 14:01:23.064: INFO: Got endpoints: latency-svc-hb9dv [749.361277ms]
Mar  1 14:01:23.081: INFO: Created: latency-svc-ghlsn
Mar  1 14:01:23.114: INFO: Got endpoints: latency-svc-4tf2p [748.615748ms]
Mar  1 14:01:23.133: INFO: Created: latency-svc-2n4b8
Mar  1 14:01:23.165: INFO: Got endpoints: latency-svc-r59d2 [752.215512ms]
Mar  1 14:01:23.177: INFO: Created: latency-svc-bbftk
Mar  1 14:01:23.214: INFO: Got endpoints: latency-svc-dzf7p [748.953383ms]
Mar  1 14:01:23.225: INFO: Created: latency-svc-xvn5c
Mar  1 14:01:23.263: INFO: Got endpoints: latency-svc-r99w2 [744.924478ms]
Mar  1 14:01:23.277: INFO: Created: latency-svc-njrcn
Mar  1 14:01:23.318: INFO: Got endpoints: latency-svc-7tgxp [751.976993ms]
Mar  1 14:01:23.331: INFO: Created: latency-svc-rz9mk
Mar  1 14:01:23.364: INFO: Got endpoints: latency-svc-g4wdr [750.150011ms]
Mar  1 14:01:23.376: INFO: Created: latency-svc-dg868
Mar  1 14:01:23.412: INFO: Got endpoints: latency-svc-pvqv4 [749.673684ms]
Mar  1 14:01:23.427: INFO: Created: latency-svc-6pj62
Mar  1 14:01:23.464: INFO: Got endpoints: latency-svc-22v4k [750.456211ms]
Mar  1 14:01:23.477: INFO: Created: latency-svc-bg77k
Mar  1 14:01:23.513: INFO: Got endpoints: latency-svc-4nrw5 [748.84653ms]
Mar  1 14:01:23.527: INFO: Created: latency-svc-kvkg8
Mar  1 14:01:23.565: INFO: Got endpoints: latency-svc-b789n [751.161286ms]
Mar  1 14:01:23.582: INFO: Created: latency-svc-f9r2p
Mar  1 14:01:23.615: INFO: Got endpoints: latency-svc-ght94 [749.89865ms]
Mar  1 14:01:23.628: INFO: Created: latency-svc-nc9vb
Mar  1 14:01:23.664: INFO: Got endpoints: latency-svc-h5ttn [750.713848ms]
Mar  1 14:01:23.677: INFO: Created: latency-svc-wpl9t
Mar  1 14:01:23.716: INFO: Got endpoints: latency-svc-xlbrh [752.506539ms]
Mar  1 14:01:23.728: INFO: Created: latency-svc-6fd5f
Mar  1 14:01:23.765: INFO: Got endpoints: latency-svc-xzbsd [751.362972ms]
Mar  1 14:01:23.813: INFO: Got endpoints: latency-svc-ghlsn [748.983143ms]
Mar  1 14:01:23.864: INFO: Got endpoints: latency-svc-2n4b8 [750.61943ms]
Mar  1 14:01:23.914: INFO: Got endpoints: latency-svc-bbftk [749.022492ms]
Mar  1 14:01:23.964: INFO: Got endpoints: latency-svc-xvn5c [750.280228ms]
Mar  1 14:01:24.014: INFO: Got endpoints: latency-svc-njrcn [751.334008ms]
Mar  1 14:01:24.066: INFO: Got endpoints: latency-svc-rz9mk [748.761686ms]
Mar  1 14:01:24.114: INFO: Got endpoints: latency-svc-dg868 [750.10323ms]
Mar  1 14:01:24.164: INFO: Got endpoints: latency-svc-6pj62 [752.065165ms]
Mar  1 14:01:24.214: INFO: Got endpoints: latency-svc-bg77k [749.857391ms]
Mar  1 14:01:24.265: INFO: Got endpoints: latency-svc-kvkg8 [751.728386ms]
Mar  1 14:01:24.317: INFO: Got endpoints: latency-svc-f9r2p [752.150912ms]
Mar  1 14:01:24.365: INFO: Got endpoints: latency-svc-nc9vb [750.549996ms]
Mar  1 14:01:24.416: INFO: Got endpoints: latency-svc-wpl9t [751.365076ms]
Mar  1 14:01:24.465: INFO: Got endpoints: latency-svc-6fd5f [748.901016ms]
Mar  1 14:01:24.465: INFO: Latencies: [22.523839ms 61.159486ms 89.740138ms 103.754094ms 120.965821ms 148.198955ms 175.951003ms 175.961155ms 187.388825ms 189.577347ms 195.400924ms 195.767653ms 198.934216ms 203.808641ms 206.996929ms 209.383315ms 211.994721ms 216.741962ms 217.179821ms 224.047278ms 225.340595ms 226.39123ms 227.159164ms 227.928425ms 228.974804ms 233.387281ms 247.128531ms 247.930684ms 254.588432ms 258.328053ms 259.5858ms 261.369749ms 264.801727ms 267.865357ms 267.929357ms 268.206474ms 275.65595ms 275.6826ms 280.267545ms 281.776582ms 288.726774ms 289.826469ms 291.453158ms 320.237612ms 320.377555ms 359.877394ms 371.191801ms 432.007747ms 444.306393ms 465.961434ms 499.855966ms 544.61338ms 554.085182ms 560.30873ms 583.205843ms 593.921727ms 645.311372ms 656.232078ms 662.629024ms 687.760974ms 698.756098ms 721.929995ms 725.204078ms 726.715578ms 730.556899ms 731.984897ms 733.994698ms 734.210508ms 738.77719ms 740.397308ms 742.521478ms 743.803261ms 744.813963ms 744.924478ms 745.044579ms 746.746518ms 746.861511ms 747.034142ms 747.058627ms 747.151174ms 747.381003ms 747.5523ms 747.611434ms 747.668396ms 747.722318ms 747.762117ms 747.854255ms 748.237425ms 748.374281ms 748.450308ms 748.520361ms 748.587624ms 748.615748ms 748.62231ms 748.643132ms 748.644914ms 748.651006ms 748.761686ms 748.82097ms 748.84653ms 748.901016ms 748.947883ms 748.953383ms 748.983143ms 749.002578ms 749.011871ms 749.022492ms 749.025386ms 749.244679ms 749.278504ms 749.315675ms 749.361277ms 749.372393ms 749.496683ms 749.505895ms 749.523456ms 749.560832ms 749.591644ms 749.593764ms 749.624286ms 749.641001ms 749.673684ms 749.6969ms 749.744218ms 749.767223ms 749.857391ms 749.89865ms 749.902832ms 749.947996ms 750.041379ms 750.090492ms 750.10323ms 750.150011ms 750.179655ms 750.18461ms 750.194505ms 750.220442ms 750.280228ms 750.361851ms 750.388672ms 750.456211ms 750.534266ms 750.549996ms 750.565594ms 750.61943ms 750.657109ms 750.713848ms 750.738974ms 750.767824ms 750.87097ms 750.874679ms 750.976868ms 751.005319ms 751.022797ms 751.12161ms 751.124631ms 751.161286ms 751.181407ms 751.28419ms 751.287535ms 751.291842ms 751.334008ms 751.355257ms 751.362972ms 751.365076ms 751.487911ms 751.728386ms 751.734411ms 751.783422ms 751.844862ms 751.902973ms 751.913593ms 751.976993ms 752.055448ms 752.065165ms 752.149658ms 752.150912ms 752.174134ms 752.215512ms 752.314969ms 752.451456ms 752.47155ms 752.506539ms 752.66274ms 752.826895ms 753.319789ms 753.667097ms 753.999068ms 754.554296ms 755.336096ms 756.86405ms 758.03718ms 758.138075ms 758.315126ms 760.371484ms 763.945083ms 764.986266ms 765.540578ms 768.995561ms 776.486774ms]
Mar  1 14:01:24.465: INFO: 50 %ile: 748.901016ms
Mar  1 14:01:24.465: INFO: 90 %ile: 752.451456ms
Mar  1 14:01:24.465: INFO: 99 %ile: 768.995561ms
Mar  1 14:01:24.465: INFO: Total sample count: 200
[AfterEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 14:01:24.465: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-svc-latency-28vx9" for this suite.
Mar  1 14:01:42.482: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 14:01:42.569: INFO: namespace: e2e-tests-svc-latency-28vx9, resource: bindings, ignored listing per whitelist
Mar  1 14:01:42.615: INFO: namespace e2e-tests-svc-latency-28vx9 deletion completed in 18.144072927s

• [SLOW TEST:28.973 seconds]
[sig-network] Service endpoints latency
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should not be very high  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with downward pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 14:01:42.615: INFO: >>> kubeConfig: /tmp/kubeconfig-210205575
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with downward pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-downwardapi-cqcr
STEP: Creating a pod to test atomic-volume-subpath
Mar  1 14:01:42.737: INFO: Waiting up to 5m0s for pod "pod-subpath-test-downwardapi-cqcr" in namespace "e2e-tests-subpath-hgnq7" to be "success or failure"
Mar  1 14:01:42.750: INFO: Pod "pod-subpath-test-downwardapi-cqcr": Phase="Pending", Reason="", readiness=false. Elapsed: 13.390004ms
Mar  1 14:01:44.754: INFO: Pod "pod-subpath-test-downwardapi-cqcr": Phase="Pending", Reason="", readiness=false. Elapsed: 2.017108111s
Mar  1 14:01:46.757: INFO: Pod "pod-subpath-test-downwardapi-cqcr": Phase="Running", Reason="", readiness=false. Elapsed: 4.020572043s
Mar  1 14:01:48.762: INFO: Pod "pod-subpath-test-downwardapi-cqcr": Phase="Running", Reason="", readiness=false. Elapsed: 6.025731977s
Mar  1 14:01:50.766: INFO: Pod "pod-subpath-test-downwardapi-cqcr": Phase="Running", Reason="", readiness=false. Elapsed: 8.029064395s
Mar  1 14:01:52.769: INFO: Pod "pod-subpath-test-downwardapi-cqcr": Phase="Running", Reason="", readiness=false. Elapsed: 10.032640492s
Mar  1 14:01:54.773: INFO: Pod "pod-subpath-test-downwardapi-cqcr": Phase="Running", Reason="", readiness=false. Elapsed: 12.03605625s
Mar  1 14:01:56.776: INFO: Pod "pod-subpath-test-downwardapi-cqcr": Phase="Running", Reason="", readiness=false. Elapsed: 14.039619652s
Mar  1 14:01:58.780: INFO: Pod "pod-subpath-test-downwardapi-cqcr": Phase="Running", Reason="", readiness=false. Elapsed: 16.043147866s
Mar  1 14:02:00.854: INFO: Pod "pod-subpath-test-downwardapi-cqcr": Phase="Running", Reason="", readiness=false. Elapsed: 18.116892337s
Mar  1 14:02:02.857: INFO: Pod "pod-subpath-test-downwardapi-cqcr": Phase="Running", Reason="", readiness=false. Elapsed: 20.120331808s
Mar  1 14:02:04.860: INFO: Pod "pod-subpath-test-downwardapi-cqcr": Phase="Running", Reason="", readiness=false. Elapsed: 22.123868488s
Mar  1 14:02:06.864: INFO: Pod "pod-subpath-test-downwardapi-cqcr": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.127207912s
STEP: Saw pod success
Mar  1 14:02:06.864: INFO: Pod "pod-subpath-test-downwardapi-cqcr" satisfied condition "success or failure"
Mar  1 14:02:06.867: INFO: Trying to get logs from node gke-conformance-default-pool-eca581b0-czl4 pod pod-subpath-test-downwardapi-cqcr container test-container-subpath-downwardapi-cqcr: <nil>
STEP: delete the pod
Mar  1 14:02:06.892: INFO: Waiting for pod pod-subpath-test-downwardapi-cqcr to disappear
Mar  1 14:02:06.897: INFO: Pod pod-subpath-test-downwardapi-cqcr no longer exists
STEP: Deleting pod pod-subpath-test-downwardapi-cqcr
Mar  1 14:02:06.897: INFO: Deleting pod "pod-subpath-test-downwardapi-cqcr" in namespace "e2e-tests-subpath-hgnq7"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 14:02:06.900: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-hgnq7" for this suite.
Mar  1 14:02:12.914: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 14:02:13.006: INFO: namespace: e2e-tests-subpath-hgnq7, resource: bindings, ignored listing per whitelist
Mar  1 14:02:13.028: INFO: namespace e2e-tests-subpath-hgnq7 deletion completed in 6.123956421s

• [SLOW TEST:30.413 seconds]
[sig-storage] Subpath
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with downward pod [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-network] Services 
  should provide secure master service  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 14:02:13.028: INFO: >>> kubeConfig: /tmp/kubeconfig-210205575
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:83
[It] should provide secure master service  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 14:02:13.133: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-services-hzqww" for this suite.
Mar  1 14:02:19.150: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 14:02:19.259: INFO: namespace: e2e-tests-services-hzqww, resource: bindings, ignored listing per whitelist
Mar  1 14:02:19.428: INFO: namespace e2e-tests-services-hzqww deletion completed in 6.289955563s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:88

• [SLOW TEST:6.400 seconds]
[sig-network] Services
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide secure master service  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on default medium should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 14:02:19.428: INFO: >>> kubeConfig: /tmp/kubeconfig-210205575
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on default medium should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir volume type on node default medium
Mar  1 14:02:19.541: INFO: Waiting up to 5m0s for pod "pod-a0c8f617-3c2a-11e9-a154-0a580a280202" in namespace "e2e-tests-emptydir-98zhq" to be "success or failure"
Mar  1 14:02:19.546: INFO: Pod "pod-a0c8f617-3c2a-11e9-a154-0a580a280202": Phase="Pending", Reason="", readiness=false. Elapsed: 5.783575ms
Mar  1 14:02:21.563: INFO: Pod "pod-a0c8f617-3c2a-11e9-a154-0a580a280202": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.022670703s
STEP: Saw pod success
Mar  1 14:02:21.563: INFO: Pod "pod-a0c8f617-3c2a-11e9-a154-0a580a280202" satisfied condition "success or failure"
Mar  1 14:02:21.567: INFO: Trying to get logs from node gke-conformance-default-pool-eca581b0-sww9 pod pod-a0c8f617-3c2a-11e9-a154-0a580a280202 container test-container: <nil>
STEP: delete the pod
Mar  1 14:02:21.598: INFO: Waiting for pod pod-a0c8f617-3c2a-11e9-a154-0a580a280202 to disappear
Mar  1 14:02:21.602: INFO: Pod pod-a0c8f617-3c2a-11e9-a154-0a580a280202 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 14:02:21.602: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-98zhq" for this suite.
Mar  1 14:02:27.620: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 14:02:27.640: INFO: namespace: e2e-tests-emptydir-98zhq, resource: bindings, ignored listing per whitelist
Mar  1 14:02:27.760: INFO: namespace e2e-tests-emptydir-98zhq deletion completed in 6.153102076s

• [SLOW TEST:8.333 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  volume on default medium should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 14:02:27.761: INFO: >>> kubeConfig: /tmp/kubeconfig-210205575
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-map-a5c1deda-3c2a-11e9-a154-0a580a280202
STEP: Creating a pod to test consume configMaps
Mar  1 14:02:27.887: INFO: Waiting up to 5m0s for pod "pod-configmaps-a5c2a378-3c2a-11e9-a154-0a580a280202" in namespace "e2e-tests-configmap-vkxqj" to be "success or failure"
Mar  1 14:02:27.891: INFO: Pod "pod-configmaps-a5c2a378-3c2a-11e9-a154-0a580a280202": Phase="Pending", Reason="", readiness=false. Elapsed: 3.821552ms
Mar  1 14:02:29.971: INFO: Pod "pod-configmaps-a5c2a378-3c2a-11e9-a154-0a580a280202": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.083570173s
STEP: Saw pod success
Mar  1 14:02:29.971: INFO: Pod "pod-configmaps-a5c2a378-3c2a-11e9-a154-0a580a280202" satisfied condition "success or failure"
Mar  1 14:02:30.051: INFO: Trying to get logs from node gke-conformance-default-pool-eca581b0-sqmc pod pod-configmaps-a5c2a378-3c2a-11e9-a154-0a580a280202 container configmap-volume-test: <nil>
STEP: delete the pod
Mar  1 14:02:30.270: INFO: Waiting for pod pod-configmaps-a5c2a378-3c2a-11e9-a154-0a580a280202 to disappear
Mar  1 14:02:30.275: INFO: Pod pod-configmaps-a5c2a378-3c2a-11e9-a154-0a580a280202 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 14:02:30.275: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-vkxqj" for this suite.
Mar  1 14:02:36.291: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 14:02:36.315: INFO: namespace: e2e-tests-configmap-vkxqj, resource: bindings, ignored listing per whitelist
Mar  1 14:02:36.412: INFO: namespace e2e-tests-configmap-vkxqj deletion completed in 6.133264659s

• [SLOW TEST:8.652 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 14:02:36.412: INFO: >>> kubeConfig: /tmp/kubeconfig-210205575
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Mar  1 14:02:40.583: INFO: Waiting up to 5m0s for pod "client-envvars-ad524a49-3c2a-11e9-a154-0a580a280202" in namespace "e2e-tests-pods-tw692" to be "success or failure"
Mar  1 14:02:40.590: INFO: Pod "client-envvars-ad524a49-3c2a-11e9-a154-0a580a280202": Phase="Pending", Reason="", readiness=false. Elapsed: 6.094897ms
Mar  1 14:02:42.593: INFO: Pod "client-envvars-ad524a49-3c2a-11e9-a154-0a580a280202": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009774258s
Mar  1 14:02:44.597: INFO: Pod "client-envvars-ad524a49-3c2a-11e9-a154-0a580a280202": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013275389s
STEP: Saw pod success
Mar  1 14:02:44.597: INFO: Pod "client-envvars-ad524a49-3c2a-11e9-a154-0a580a280202" satisfied condition "success or failure"
Mar  1 14:02:44.604: INFO: Trying to get logs from node gke-conformance-default-pool-eca581b0-sww9 pod client-envvars-ad524a49-3c2a-11e9-a154-0a580a280202 container env3cont: <nil>
STEP: delete the pod
Mar  1 14:02:44.632: INFO: Waiting for pod client-envvars-ad524a49-3c2a-11e9-a154-0a580a280202 to disappear
Mar  1 14:02:44.637: INFO: Pod client-envvars-ad524a49-3c2a-11e9-a154-0a580a280202 no longer exists
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 14:02:44.637: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-tw692" for this suite.
Mar  1 14:03:24.652: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 14:03:24.772: INFO: namespace: e2e-tests-pods-tw692, resource: bindings, ignored listing per whitelist
Mar  1 14:03:24.799: INFO: namespace e2e-tests-pods-tw692 deletion completed in 40.158020762s

• [SLOW TEST:48.387 seconds]
[k8s.io] Pods
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] KubeletManagedEtcHosts 
  should test kubelet managed /etc/hosts file [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 14:03:24.799: INFO: >>> kubeConfig: /tmp/kubeconfig-210205575
STEP: Building a namespace api object, basename e2e-kubelet-etc-hosts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should test kubelet managed /etc/hosts file [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Setting up the test
STEP: Creating hostNetwork=false pod
STEP: Creating hostNetwork=true pod
STEP: Running the test
STEP: Verifying /etc/hosts of container is kubelet-managed for pod with hostNetwork=false
Mar  1 14:03:30.969: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-mmgt6 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar  1 14:03:30.969: INFO: >>> kubeConfig: /tmp/kubeconfig-210205575
Mar  1 14:03:31.048: INFO: Exec stderr: ""
Mar  1 14:03:31.048: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-mmgt6 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar  1 14:03:31.048: INFO: >>> kubeConfig: /tmp/kubeconfig-210205575
Mar  1 14:03:31.120: INFO: Exec stderr: ""
Mar  1 14:03:31.120: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-mmgt6 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar  1 14:03:31.120: INFO: >>> kubeConfig: /tmp/kubeconfig-210205575
Mar  1 14:03:31.195: INFO: Exec stderr: ""
Mar  1 14:03:31.195: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-mmgt6 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar  1 14:03:31.195: INFO: >>> kubeConfig: /tmp/kubeconfig-210205575
Mar  1 14:03:31.269: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts of container is not kubelet-managed since container specifies /etc/hosts mount
Mar  1 14:03:31.269: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-mmgt6 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar  1 14:03:31.269: INFO: >>> kubeConfig: /tmp/kubeconfig-210205575
Mar  1 14:03:31.347: INFO: Exec stderr: ""
Mar  1 14:03:31.347: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-mmgt6 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar  1 14:03:31.347: INFO: >>> kubeConfig: /tmp/kubeconfig-210205575
Mar  1 14:03:31.424: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts content of container is not kubelet-managed for pod with hostNetwork=true
Mar  1 14:03:31.424: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-mmgt6 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar  1 14:03:31.424: INFO: >>> kubeConfig: /tmp/kubeconfig-210205575
Mar  1 14:03:31.503: INFO: Exec stderr: ""
Mar  1 14:03:31.503: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-mmgt6 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar  1 14:03:31.503: INFO: >>> kubeConfig: /tmp/kubeconfig-210205575
Mar  1 14:03:31.576: INFO: Exec stderr: ""
Mar  1 14:03:31.576: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-mmgt6 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar  1 14:03:31.576: INFO: >>> kubeConfig: /tmp/kubeconfig-210205575
Mar  1 14:03:31.650: INFO: Exec stderr: ""
Mar  1 14:03:31.650: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-mmgt6 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar  1 14:03:31.650: INFO: >>> kubeConfig: /tmp/kubeconfig-210205575
Mar  1 14:03:31.737: INFO: Exec stderr: ""
[AfterEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 14:03:31.737: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-e2e-kubelet-etc-hosts-mmgt6" for this suite.
Mar  1 14:04:23.752: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 14:04:23.824: INFO: namespace: e2e-tests-e2e-kubelet-etc-hosts-mmgt6, resource: bindings, ignored listing per whitelist
Mar  1 14:04:23.947: INFO: namespace e2e-tests-e2e-kubelet-etc-hosts-mmgt6 deletion completed in 52.205789045s

• [SLOW TEST:59.148 seconds]
[k8s.io] KubeletManagedEtcHosts
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should test kubelet managed /etc/hosts file [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 14:04:23.947: INFO: >>> kubeConfig: /tmp/kubeconfig-210205575
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-http in namespace e2e-tests-container-probe-zr6m6
Mar  1 14:04:26.069: INFO: Started pod liveness-http in namespace e2e-tests-container-probe-zr6m6
STEP: checking the pod's current state and verifying that restartCount is present
Mar  1 14:04:26.073: INFO: Initial restart count of pod liveness-http is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 14:08:26.990: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-zr6m6" for this suite.
Mar  1 14:08:33.005: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 14:08:33.124: INFO: namespace: e2e-tests-container-probe-zr6m6, resource: bindings, ignored listing per whitelist
Mar  1 14:08:33.156: INFO: namespace e2e-tests-container-probe-zr6m6 deletion completed in 6.159611323s

• [SLOW TEST:249.209 seconds]
[k8s.io] Probing container
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 14:08:33.156: INFO: >>> kubeConfig: /tmp/kubeconfig-210205575
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: setting up watch
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: verifying pod creation was observed
Mar  1 14:08:35.284: INFO: running pod: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-submit-remove-7f89beb0-3c2b-11e9-a154-0a580a280202", GenerateName:"", Namespace:"e2e-tests-pods-t4sfj", SelfLink:"/api/v1/namespaces/e2e-tests-pods-t4sfj/pods/pod-submit-remove-7f89beb0-3c2b-11e9-a154-0a580a280202", UID:"7f8ac575-3c2b-11e9-83c3-42010a800094", ResourceVersion:"12569", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63687046113, loc:(*time.Location)(0x6c43b60)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"250480429"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Initializers:(*v1.Initializers)(nil), Finalizers:[]string(nil), ClusterName:""}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"default-token-7fq62", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(0xc421b333c0), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil)}}}, InitContainers:[]v1.Container(nil), Containers:[]v1.Container{v1.Container{Name:"nginx", Image:"docker.io/library/nginx:1.14-alpine", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-7fq62", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc4226f87f8), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"gke-conformance-default-pool-eca581b0-sqmc", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc4224d74a0), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc4226f8830)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc4226f8850)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc4226f8858), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil)}, Status:v1.PodStatus{Phase:"Running", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63687046113, loc:(*time.Location)(0x6c43b60)}}, Reason:"", Message:""}, v1.PodCondition{Type:"Ready", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63687046114, loc:(*time.Location)(0x6c43b60)}}, Reason:"", Message:""}, v1.PodCondition{Type:"ContainersReady", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63687046114, loc:(*time.Location)(0x6c43b60)}}, Reason:"", Message:""}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63687046113, loc:(*time.Location)(0x6c43b60)}}, Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"10.128.0.17", PodIP:"10.40.3.50", StartTime:(*v1.Time)(0xc42189fca0), InitContainerStatuses:[]v1.ContainerStatus(nil), ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"nginx", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(0xc42189fd40), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:true, RestartCount:0, Image:"nginx:1.14-alpine", ImageID:"docker-pullable://nginx@sha256:b9734546761e49b453efce35ee523bbcaff1052d281516f133d41b090e26c0df", ContainerID:"docker://d49fdad08ad8ed7fba0cc19383ed6872da53cd5df277ab36be19b1df90403253"}}, QOSClass:"BestEffort"}}
STEP: deleting the pod gracefully
STEP: verifying the kubelet observed the termination notice
Mar  1 14:08:40.306: INFO: no pod exists with the name we were looking for, assuming the termination request was observed and completed
STEP: verifying pod deletion was observed
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 14:08:40.310: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-t4sfj" for this suite.
Mar  1 14:08:46.324: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 14:08:46.382: INFO: namespace: e2e-tests-pods-t4sfj, resource: bindings, ignored listing per whitelist
Mar  1 14:08:46.453: INFO: namespace e2e-tests-pods-t4sfj deletion completed in 6.13911568s

• [SLOW TEST:13.297 seconds]
[k8s.io] Pods
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[k8s.io] Docker Containers 
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 14:08:46.453: INFO: >>> kubeConfig: /tmp/kubeconfig-210205575
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test use defaults
Mar  1 14:08:46.565: INFO: Waiting up to 5m0s for pod "client-containers-8777f017-3c2b-11e9-a154-0a580a280202" in namespace "e2e-tests-containers-bk5sm" to be "success or failure"
Mar  1 14:08:46.571: INFO: Pod "client-containers-8777f017-3c2b-11e9-a154-0a580a280202": Phase="Pending", Reason="", readiness=false. Elapsed: 5.609207ms
Mar  1 14:08:48.575: INFO: Pod "client-containers-8777f017-3c2b-11e9-a154-0a580a280202": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00979414s
STEP: Saw pod success
Mar  1 14:08:48.575: INFO: Pod "client-containers-8777f017-3c2b-11e9-a154-0a580a280202" satisfied condition "success or failure"
Mar  1 14:08:48.578: INFO: Trying to get logs from node gke-conformance-default-pool-eca581b0-czl4 pod client-containers-8777f017-3c2b-11e9-a154-0a580a280202 container test-container: <nil>
STEP: delete the pod
Mar  1 14:08:48.607: INFO: Waiting for pod client-containers-8777f017-3c2b-11e9-a154-0a580a280202 to disappear
Mar  1 14:08:48.611: INFO: Pod client-containers-8777f017-3c2b-11e9-a154-0a580a280202 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 14:08:48.611: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-bk5sm" for this suite.
Mar  1 14:08:54.628: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 14:08:54.740: INFO: namespace: e2e-tests-containers-bk5sm, resource: bindings, ignored listing per whitelist
Mar  1 14:08:54.744: INFO: namespace e2e-tests-containers-bk5sm deletion completed in 6.129373245s

• [SLOW TEST:8.292 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-apps] Deployment 
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 14:08:54.745: INFO: >>> kubeConfig: /tmp/kubeconfig-210205575
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Mar  1 14:08:54.894: INFO: Creating deployment "nginx-deployment"
Mar  1 14:08:54.920: INFO: Waiting for observed generation 1
Mar  1 14:08:56.930: INFO: Waiting for all required pods to come up
Mar  1 14:08:56.935: INFO: Pod name nginx: Found 10 pods out of 10
STEP: ensuring each pod is running
Mar  1 14:08:58.955: INFO: Waiting for deployment "nginx-deployment" to complete
Mar  1 14:08:58.961: INFO: Updating deployment "nginx-deployment" with a non-existent image
Mar  1 14:08:58.972: INFO: Updating deployment nginx-deployment
Mar  1 14:08:58.972: INFO: Waiting for observed generation 2
Mar  1 14:09:00.981: INFO: Waiting for the first rollout's replicaset to have .status.availableReplicas = 8
Mar  1 14:09:00.985: INFO: Waiting for the first rollout's replicaset to have .spec.replicas = 8
Mar  1 14:09:00.988: INFO: Waiting for the first rollout's replicaset of deployment "nginx-deployment" to have desired number of replicas
Mar  1 14:09:00.997: INFO: Verifying that the second rollout's replicaset has .status.availableReplicas = 0
Mar  1 14:09:00.997: INFO: Waiting for the second rollout's replicaset to have .spec.replicas = 5
Mar  1 14:09:01.000: INFO: Waiting for the second rollout's replicaset of deployment "nginx-deployment" to have desired number of replicas
Mar  1 14:09:01.005: INFO: Verifying that deployment "nginx-deployment" has minimum required number of available replicas
Mar  1 14:09:01.005: INFO: Scaling up the deployment "nginx-deployment" from 10 to 30
Mar  1 14:09:01.016: INFO: Updating deployment nginx-deployment
Mar  1 14:09:01.016: INFO: Waiting for the replicasets of deployment "nginx-deployment" to have desired number of replicas
Mar  1 14:09:01.046: INFO: Verifying that first rollout's replicaset has .spec.replicas = 20
Mar  1 14:09:03.077: INFO: Verifying that second rollout's replicaset has .spec.replicas = 13
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Mar  1 14:09:03.085: INFO: Deployment "nginx-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment,GenerateName:,Namespace:e2e-tests-deployment-428rz,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-428rz/deployments/nginx-deployment,UID:8c720a99-3c2b-11e9-83c3-42010a800094,ResourceVersion:12892,Generation:3,CreationTimestamp:2019-03-01 14:08:54 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*30,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:2,MaxSurge:3,},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:3,Replicas:33,UpdatedReplicas:13,AvailableReplicas:13,UnavailableReplicas:20,Conditions:[{Available False 2019-03-01 14:09:01 +0000 UTC 2019-03-01 14:09:01 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.} {Progressing True 2019-03-01 14:09:02 +0000 UTC 2019-03-01 14:08:54 +0000 UTC ReplicaSetUpdated ReplicaSet "nginx-deployment-7dc8f79789" is progressing.}],ReadyReplicas:13,CollisionCount:nil,},}

Mar  1 14:09:03.090: INFO: New ReplicaSet "nginx-deployment-7dc8f79789" of Deployment "nginx-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789,GenerateName:,Namespace:e2e-tests-deployment-428rz,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-428rz/replicasets/nginx-deployment-7dc8f79789,UID:8ede623b-3c2b-11e9-83c3-42010a800094,ResourceVersion:12846,Generation:3,CreationTimestamp:2019-03-01 14:08:58 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 30,deployment.kubernetes.io/max-replicas: 33,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment nginx-deployment 8c720a99-3c2b-11e9-83c3-42010a800094 0xc421e37fe7 0xc421e37fe8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*13,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:13,FullyLabeledReplicas:13,ObservedGeneration:3,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Mar  1 14:09:03.090: INFO: All old ReplicaSets of Deployment "nginx-deployment":
Mar  1 14:09:03.090: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b,GenerateName:,Namespace:e2e-tests-deployment-428rz,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-428rz/replicasets/nginx-deployment-7f9675fb8b,UID:8c751322-3c2b-11e9-83c3-42010a800094,ResourceVersion:12891,Generation:3,CreationTimestamp:2019-03-01 14:08:54 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 30,deployment.kubernetes.io/max-replicas: 33,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment nginx-deployment 8c720a99-3c2b-11e9-83c3-42010a800094 0xc4223605b7 0xc4223605b8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*20,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:20,FullyLabeledReplicas:20,ObservedGeneration:3,ReadyReplicas:13,AvailableReplicas:13,Conditions:[],},}
Mar  1 14:09:03.097: INFO: Pod "nginx-deployment-7dc8f79789-5ql4v" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-5ql4v,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-428rz,SelfLink:/api/v1/namespaces/e2e-tests-deployment-428rz/pods/nginx-deployment-7dc8f79789-5ql4v,UID:8f05614a-3c2b-11e9-83c3-42010a800094,ResourceVersion:12875,Generation:0,CreationTimestamp:2019-03-01 14:08:59 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 8ede623b-3c2b-11e9-83c3-42010a800094 0xc421d63857 0xc421d63858}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-j45rz {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-j45rz,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-j45rz true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:gke-conformance-default-pool-eca581b0-40vx,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc421d638c0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421d638e0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 14:08:59 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-01 14:08:59 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-01 14:08:59 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 14:08:59 +0000 UTC  }],Message:,Reason:,HostIP:10.128.0.15,PodIP:10.40.0.20,StartTime:2019-03-01 14:08:59 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ImagePullBackOff,Message:Back-off pulling image "nginx:404",} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar  1 14:09:03.097: INFO: Pod "nginx-deployment-7dc8f79789-8bmls" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-8bmls,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-428rz,SelfLink:/api/v1/namespaces/e2e-tests-deployment-428rz/pods/nginx-deployment-7dc8f79789-8bmls,UID:902cfa7d-3c2b-11e9-83c3-42010a800094,ResourceVersion:12856,Generation:0,CreationTimestamp:2019-03-01 14:09:01 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 8ede623b-3c2b-11e9-83c3-42010a800094 0xc421d63a90 0xc421d63a91}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-j45rz {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-j45rz,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-j45rz true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:gke-conformance-default-pool-eca581b0-czl4,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc421d63b00} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421d63b20}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 14:09:01 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-01 14:09:01 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-01 14:09:01 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 14:09:01 +0000 UTC  }],Message:,Reason:,HostIP:10.128.0.14,PodIP:,StartTime:2019-03-01 14:09:01 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar  1 14:09:03.097: INFO: Pod "nginx-deployment-7dc8f79789-btj4r" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-btj4r,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-428rz,SelfLink:/api/v1/namespaces/e2e-tests-deployment-428rz/pods/nginx-deployment-7dc8f79789-btj4r,UID:8ee4dcf0-3c2b-11e9-83c3-42010a800094,ResourceVersion:12857,Generation:0,CreationTimestamp:2019-03-01 14:08:59 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 8ede623b-3c2b-11e9-83c3-42010a800094 0xc421d63c70 0xc421d63c71}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-j45rz {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-j45rz,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-j45rz true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:gke-conformance-default-pool-eca581b0-00fq,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc421d63ce0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421d63d00}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 14:08:59 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-01 14:08:59 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-01 14:08:59 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 14:08:59 +0000 UTC  }],Message:,Reason:,HostIP:10.128.0.16,PodIP:10.40.2.19,StartTime:2019-03-01 14:08:59 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = Error response from daemon: manifest for nginx:404 not found,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar  1 14:09:03.097: INFO: Pod "nginx-deployment-7dc8f79789-frxjr" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-frxjr,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-428rz,SelfLink:/api/v1/namespaces/e2e-tests-deployment-428rz/pods/nginx-deployment-7dc8f79789-frxjr,UID:8edfc4e1-3c2b-11e9-83c3-42010a800094,ResourceVersion:12873,Generation:0,CreationTimestamp:2019-03-01 14:08:58 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 8ede623b-3c2b-11e9-83c3-42010a800094 0xc421d63de0 0xc421d63de1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-j45rz {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-j45rz,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-j45rz true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:gke-conformance-default-pool-eca581b0-sqmc,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc421d63e70} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421d63e90}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 14:08:59 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-01 14:08:59 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-01 14:08:59 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 14:08:59 +0000 UTC  }],Message:,Reason:,HostIP:10.128.0.17,PodIP:,StartTime:2019-03-01 14:08:59 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = Error response from daemon: manifest for nginx:404 not found,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar  1 14:09:03.097: INFO: Pod "nginx-deployment-7dc8f79789-g6c8s" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-g6c8s,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-428rz,SelfLink:/api/v1/namespaces/e2e-tests-deployment-428rz/pods/nginx-deployment-7dc8f79789-g6c8s,UID:90235b86-3c2b-11e9-83c3-42010a800094,ResourceVersion:12826,Generation:0,CreationTimestamp:2019-03-01 14:09:01 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 8ede623b-3c2b-11e9-83c3-42010a800094 0xc421d63f60 0xc421d63f61}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-j45rz {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-j45rz,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-j45rz true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:gke-conformance-default-pool-eca581b0-00fq,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc421d63fd0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421d63ff0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 14:09:01 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-01 14:09:01 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-01 14:09:01 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 14:09:01 +0000 UTC  }],Message:,Reason:,HostIP:10.128.0.16,PodIP:,StartTime:2019-03-01 14:09:01 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar  1 14:09:03.097: INFO: Pod "nginx-deployment-7dc8f79789-hpwcw" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-hpwcw,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-428rz,SelfLink:/api/v1/namespaces/e2e-tests-deployment-428rz/pods/nginx-deployment-7dc8f79789-hpwcw,UID:8f0247e2-3c2b-11e9-83c3-42010a800094,ResourceVersion:12876,Generation:0,CreationTimestamp:2019-03-01 14:08:59 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 8ede623b-3c2b-11e9-83c3-42010a800094 0xc422428320 0xc422428321}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-j45rz {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-j45rz,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-j45rz true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:gke-conformance-default-pool-eca581b0-sww9,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc422428a10} {node.kubernetes.io/unreachable Exists  NoExecute 0xc422428a30}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 14:08:59 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-01 14:08:59 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-01 14:08:59 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 14:08:59 +0000 UTC  }],Message:,Reason:,HostIP:10.128.0.18,PodIP:,StartTime:2019-03-01 14:08:59 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = Error response from daemon: manifest for nginx:404 not found,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar  1 14:09:03.098: INFO: Pod "nginx-deployment-7dc8f79789-j6fr7" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-j6fr7,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-428rz,SelfLink:/api/v1/namespaces/e2e-tests-deployment-428rz/pods/nginx-deployment-7dc8f79789-j6fr7,UID:902381fd-3c2b-11e9-83c3-42010a800094,ResourceVersion:12827,Generation:0,CreationTimestamp:2019-03-01 14:09:01 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 8ede623b-3c2b-11e9-83c3-42010a800094 0xc422428b40 0xc422428b41}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-j45rz {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-j45rz,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-j45rz true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:gke-conformance-default-pool-eca581b0-sqmc,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc422428cc0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc422428ce0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 14:09:01 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-01 14:09:01 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-01 14:09:01 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 14:09:01 +0000 UTC  }],Message:,Reason:,HostIP:10.128.0.17,PodIP:,StartTime:2019-03-01 14:09:01 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar  1 14:09:03.098: INFO: Pod "nginx-deployment-7dc8f79789-p5vml" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-p5vml,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-428rz,SelfLink:/api/v1/namespaces/e2e-tests-deployment-428rz/pods/nginx-deployment-7dc8f79789-p5vml,UID:902d0150-3c2b-11e9-83c3-42010a800094,ResourceVersion:12851,Generation:0,CreationTimestamp:2019-03-01 14:09:01 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 8ede623b-3c2b-11e9-83c3-42010a800094 0xc422428da0 0xc422428da1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-j45rz {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-j45rz,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-j45rz true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:gke-conformance-default-pool-eca581b0-sqmc,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc422428ed0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc422428ef0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 14:09:01 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-01 14:09:01 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-01 14:09:01 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 14:09:01 +0000 UTC  }],Message:,Reason:,HostIP:10.128.0.17,PodIP:,StartTime:2019-03-01 14:09:01 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar  1 14:09:03.098: INFO: Pod "nginx-deployment-7dc8f79789-p87nc" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-p87nc,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-428rz,SelfLink:/api/v1/namespaces/e2e-tests-deployment-428rz/pods/nginx-deployment-7dc8f79789-p87nc,UID:8ee402a2-3c2b-11e9-83c3-42010a800094,ResourceVersion:12877,Generation:0,CreationTimestamp:2019-03-01 14:08:59 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 8ede623b-3c2b-11e9-83c3-42010a800094 0xc422428fc0 0xc422428fc1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-j45rz {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-j45rz,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-j45rz true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:gke-conformance-default-pool-eca581b0-czl4,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc422429150} {node.kubernetes.io/unreachable Exists  NoExecute 0xc422429170}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 14:08:59 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-01 14:08:59 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-01 14:08:59 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 14:08:59 +0000 UTC  }],Message:,Reason:,HostIP:10.128.0.14,PodIP:10.40.4.66,StartTime:2019-03-01 14:08:59 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ImagePullBackOff,Message:Back-off pulling image "nginx:404",} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar  1 14:09:03.098: INFO: Pod "nginx-deployment-7dc8f79789-qmc7w" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-qmc7w,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-428rz,SelfLink:/api/v1/namespaces/e2e-tests-deployment-428rz/pods/nginx-deployment-7dc8f79789-qmc7w,UID:902d0715-3c2b-11e9-83c3-42010a800094,ResourceVersion:12848,Generation:0,CreationTimestamp:2019-03-01 14:09:01 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 8ede623b-3c2b-11e9-83c3-42010a800094 0xc4224292d0 0xc4224292d1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-j45rz {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-j45rz,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-j45rz true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:gke-conformance-default-pool-eca581b0-sww9,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc4224294b0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc4224294d0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 14:09:01 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-01 14:09:01 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-01 14:09:01 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 14:09:01 +0000 UTC  }],Message:,Reason:,HostIP:10.128.0.18,PodIP:,StartTime:2019-03-01 14:09:01 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar  1 14:09:03.098: INFO: Pod "nginx-deployment-7dc8f79789-qttz8" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-qttz8,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-428rz,SelfLink:/api/v1/namespaces/e2e-tests-deployment-428rz/pods/nginx-deployment-7dc8f79789-qttz8,UID:903d6b6e-3c2b-11e9-83c3-42010a800094,ResourceVersion:12865,Generation:0,CreationTimestamp:2019-03-01 14:09:01 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 8ede623b-3c2b-11e9-83c3-42010a800094 0xc422429610 0xc422429611}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-j45rz {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-j45rz,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-j45rz true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:gke-conformance-default-pool-eca581b0-00fq,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc4224296f0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc422429720}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 14:09:01 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-01 14:09:01 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-01 14:09:01 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 14:09:01 +0000 UTC  }],Message:,Reason:,HostIP:10.128.0.16,PodIP:,StartTime:2019-03-01 14:09:01 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar  1 14:09:03.098: INFO: Pod "nginx-deployment-7dc8f79789-rx5xw" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-rx5xw,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-428rz,SelfLink:/api/v1/namespaces/e2e-tests-deployment-428rz/pods/nginx-deployment-7dc8f79789-rx5xw,UID:902bf6ba-3c2b-11e9-83c3-42010a800094,ResourceVersion:12831,Generation:0,CreationTimestamp:2019-03-01 14:09:01 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 8ede623b-3c2b-11e9-83c3-42010a800094 0xc4224298a0 0xc4224298a1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-j45rz {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-j45rz,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-j45rz true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:gke-conformance-default-pool-eca581b0-sww9,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc422429aa0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc422429ac0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 14:09:01 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-01 14:09:01 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-01 14:09:01 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 14:09:01 +0000 UTC  }],Message:,Reason:,HostIP:10.128.0.18,PodIP:,StartTime:2019-03-01 14:09:01 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar  1 14:09:03.098: INFO: Pod "nginx-deployment-7dc8f79789-v7lgl" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-v7lgl,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-428rz,SelfLink:/api/v1/namespaces/e2e-tests-deployment-428rz/pods/nginx-deployment-7dc8f79789-v7lgl,UID:901a2f42-3c2b-11e9-83c3-42010a800094,ResourceVersion:12810,Generation:0,CreationTimestamp:2019-03-01 14:09:01 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 8ede623b-3c2b-11e9-83c3-42010a800094 0xc422429b80 0xc422429b81}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-j45rz {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-j45rz,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-j45rz true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:gke-conformance-default-pool-eca581b0-czl4,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc422429c90} {node.kubernetes.io/unreachable Exists  NoExecute 0xc422429cb0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 14:09:01 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-01 14:09:01 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-01 14:09:01 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 14:09:01 +0000 UTC  }],Message:,Reason:,HostIP:10.128.0.14,PodIP:,StartTime:2019-03-01 14:09:01 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar  1 14:09:03.099: INFO: Pod "nginx-deployment-7f9675fb8b-8pls7" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-8pls7,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-428rz,SelfLink:/api/v1/namespaces/e2e-tests-deployment-428rz/pods/nginx-deployment-7f9675fb8b-8pls7,UID:903f96a7-3c2b-11e9-83c3-42010a800094,ResourceVersion:12867,Generation:0,CreationTimestamp:2019-03-01 14:09:01 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 8c751322-3c2b-11e9-83c3-42010a800094 0xc422429d70 0xc422429d71}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-j45rz {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-j45rz,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-j45rz true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:gke-conformance-default-pool-eca581b0-sww9,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc422429e60} {node.kubernetes.io/unreachable Exists  NoExecute 0xc422429e80}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 14:09:01 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-01 14:09:01 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-01 14:09:01 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 14:09:01 +0000 UTC  }],Message:,Reason:,HostIP:10.128.0.18,PodIP:,StartTime:2019-03-01 14:09:01 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar  1 14:09:03.099: INFO: Pod "nginx-deployment-7f9675fb8b-9g8pv" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-9g8pv,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-428rz,SelfLink:/api/v1/namespaces/e2e-tests-deployment-428rz/pods/nginx-deployment-7f9675fb8b-9g8pv,UID:8c8982a0-3c2b-11e9-83c3-42010a800094,ResourceVersion:12715,Generation:0,CreationTimestamp:2019-03-01 14:08:55 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 8c751322-3c2b-11e9-83c3-42010a800094 0xc422429f30 0xc422429f31}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-j45rz {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-j45rz,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-j45rz true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:gke-conformance-default-pool-eca581b0-00fq,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc4224c8470} {node.kubernetes.io/unreachable Exists  NoExecute 0xc4224c8490}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 14:08:55 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 14:08:57 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 14:08:57 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 14:08:55 +0000 UTC  }],Message:,Reason:,HostIP:10.128.0.16,PodIP:10.40.2.18,StartTime:2019-03-01 14:08:55 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-03-01 14:08:57 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:b9734546761e49b453efce35ee523bbcaff1052d281516f133d41b090e26c0df docker://726a1ea0aba4e603dcbd7ced73c21b3b90870fe687ea834e980037a72ff0815d}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar  1 14:09:03.099: INFO: Pod "nginx-deployment-7f9675fb8b-9zvgm" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-9zvgm,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-428rz,SelfLink:/api/v1/namespaces/e2e-tests-deployment-428rz/pods/nginx-deployment-7f9675fb8b-9zvgm,UID:901da021-3c2b-11e9-83c3-42010a800094,ResourceVersion:12890,Generation:0,CreationTimestamp:2019-03-01 14:09:01 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 8c751322-3c2b-11e9-83c3-42010a800094 0xc4224c8550 0xc4224c8551}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-j45rz {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-j45rz,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-j45rz true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:gke-conformance-default-pool-eca581b0-sqmc,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc4224c85f0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc4224c8610}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 14:09:01 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 14:09:02 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 14:09:02 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 14:09:01 +0000 UTC  }],Message:,Reason:,HostIP:10.128.0.17,PodIP:10.40.3.54,StartTime:2019-03-01 14:09:01 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-03-01 14:09:02 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:b9734546761e49b453efce35ee523bbcaff1052d281516f133d41b090e26c0df docker://2e83366db044c9632a29df9d33737a68d1db6c1cbd0542754f30c187175b5131}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar  1 14:09:03.099: INFO: Pod "nginx-deployment-7f9675fb8b-cn4zj" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-cn4zj,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-428rz,SelfLink:/api/v1/namespaces/e2e-tests-deployment-428rz/pods/nginx-deployment-7f9675fb8b-cn4zj,UID:8c819335-3c2b-11e9-83c3-42010a800094,ResourceVersion:12718,Generation:0,CreationTimestamp:2019-03-01 14:08:55 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 8c751322-3c2b-11e9-83c3-42010a800094 0xc4224c8b40 0xc4224c8b41}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-j45rz {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-j45rz,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-j45rz true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:gke-conformance-default-pool-eca581b0-00fq,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc4224c8ba0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc4224c8bc0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 14:08:55 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 14:08:57 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 14:08:57 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 14:08:55 +0000 UTC  }],Message:,Reason:,HostIP:10.128.0.16,PodIP:10.40.2.16,StartTime:2019-03-01 14:08:55 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-03-01 14:08:57 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:b9734546761e49b453efce35ee523bbcaff1052d281516f133d41b090e26c0df docker://8aa4c4fb557e4955aa13c2f8fd551052c1b325757af7c4355e767ee2f4a61908}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar  1 14:09:03.099: INFO: Pod "nginx-deployment-7f9675fb8b-cth6c" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-cth6c,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-428rz,SelfLink:/api/v1/namespaces/e2e-tests-deployment-428rz/pods/nginx-deployment-7f9675fb8b-cth6c,UID:902ca572-3c2b-11e9-83c3-42010a800094,ResourceVersion:12884,Generation:0,CreationTimestamp:2019-03-01 14:09:01 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 8c751322-3c2b-11e9-83c3-42010a800094 0xc4224c8d60 0xc4224c8d61}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-j45rz {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-j45rz,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-j45rz true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:gke-conformance-default-pool-eca581b0-sqmc,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc4224c8dc0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc4224c8df0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 14:09:01 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 14:09:02 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 14:09:02 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 14:09:01 +0000 UTC  }],Message:,Reason:,HostIP:10.128.0.17,PodIP:10.40.3.56,StartTime:2019-03-01 14:09:01 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-03-01 14:09:02 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:b9734546761e49b453efce35ee523bbcaff1052d281516f133d41b090e26c0df docker://cf8e86eeac31ab0110101c1fe4ae81163633ed4cefb103530dca7c5d208f7364}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar  1 14:09:03.099: INFO: Pod "nginx-deployment-7f9675fb8b-cthwc" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-cthwc,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-428rz,SelfLink:/api/v1/namespaces/e2e-tests-deployment-428rz/pods/nginx-deployment-7f9675fb8b-cthwc,UID:903f8f85-3c2b-11e9-83c3-42010a800094,ResourceVersion:12881,Generation:0,CreationTimestamp:2019-03-01 14:09:01 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 8c751322-3c2b-11e9-83c3-42010a800094 0xc4224c8f70 0xc4224c8f71}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-j45rz {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-j45rz,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-j45rz true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:gke-conformance-default-pool-eca581b0-00fq,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc4224c9060} {node.kubernetes.io/unreachable Exists  NoExecute 0xc4224c9080}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 14:09:01 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 14:09:02 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 14:09:02 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 14:09:01 +0000 UTC  }],Message:,Reason:,HostIP:10.128.0.16,PodIP:10.40.2.23,StartTime:2019-03-01 14:09:01 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-03-01 14:09:02 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:b9734546761e49b453efce35ee523bbcaff1052d281516f133d41b090e26c0df docker://577d0ce2ed43062f2ed891a91ed63c2f64eb104a2836505a5d4a98cdb1c65011}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar  1 14:09:03.099: INFO: Pod "nginx-deployment-7f9675fb8b-fhlcq" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-fhlcq,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-428rz,SelfLink:/api/v1/namespaces/e2e-tests-deployment-428rz/pods/nginx-deployment-7f9675fb8b-fhlcq,UID:903f9e57-3c2b-11e9-83c3-42010a800094,ResourceVersion:12874,Generation:0,CreationTimestamp:2019-03-01 14:09:01 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 8c751322-3c2b-11e9-83c3-42010a800094 0xc4224c91f0 0xc4224c91f1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-j45rz {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-j45rz,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-j45rz true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:gke-conformance-default-pool-eca581b0-czl4,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc4224c9280} {node.kubernetes.io/unreachable Exists  NoExecute 0xc4224c92a0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 14:09:02 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-01 14:09:02 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-01 14:09:02 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 14:09:01 +0000 UTC  }],Message:,Reason:,HostIP:10.128.0.14,PodIP:,StartTime:2019-03-01 14:09:02 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar  1 14:09:03.099: INFO: Pod "nginx-deployment-7f9675fb8b-gcp9s" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-gcp9s,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-428rz,SelfLink:/api/v1/namespaces/e2e-tests-deployment-428rz/pods/nginx-deployment-7f9675fb8b-gcp9s,UID:903f4eb7-3c2b-11e9-83c3-42010a800094,ResourceVersion:12886,Generation:0,CreationTimestamp:2019-03-01 14:09:01 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 8c751322-3c2b-11e9-83c3-42010a800094 0xc4224c9350 0xc4224c9351}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-j45rz {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-j45rz,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-j45rz true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:gke-conformance-default-pool-eca581b0-sqmc,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc4224c94b0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc4224c94d0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 14:09:01 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 14:09:02 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 14:09:02 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 14:09:01 +0000 UTC  }],Message:,Reason:,HostIP:10.128.0.17,PodIP:10.40.3.59,StartTime:2019-03-01 14:09:01 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-03-01 14:09:02 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:b9734546761e49b453efce35ee523bbcaff1052d281516f133d41b090e26c0df docker://43f07bc5446e606781dc8c93bdee55367d4cd13b3219a66e0986dfa69a9b4526}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar  1 14:09:03.099: INFO: Pod "nginx-deployment-7f9675fb8b-gwnbv" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-gwnbv,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-428rz,SelfLink:/api/v1/namespaces/e2e-tests-deployment-428rz/pods/nginx-deployment-7f9675fb8b-gwnbv,UID:8c89426b-3c2b-11e9-83c3-42010a800094,ResourceVersion:12730,Generation:0,CreationTimestamp:2019-03-01 14:08:55 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 8c751322-3c2b-11e9-83c3-42010a800094 0xc4224c95a0 0xc4224c95a1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-j45rz {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-j45rz,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-j45rz true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:gke-conformance-default-pool-eca581b0-sww9,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc4224c9740} {node.kubernetes.io/unreachable Exists  NoExecute 0xc4224c9760}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 14:08:55 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 14:08:57 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 14:08:57 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 14:08:55 +0000 UTC  }],Message:,Reason:,HostIP:10.128.0.18,PodIP:10.40.1.55,StartTime:2019-03-01 14:08:55 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-03-01 14:08:57 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:b9734546761e49b453efce35ee523bbcaff1052d281516f133d41b090e26c0df docker://e3cfcfb954e2a44a7a8002bfcee350436cb2542fa8a9d848c3d259ec3bd4aa09}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar  1 14:09:03.100: INFO: Pod "nginx-deployment-7f9675fb8b-jdm9g" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-jdm9g,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-428rz,SelfLink:/api/v1/namespaces/e2e-tests-deployment-428rz/pods/nginx-deployment-7f9675fb8b-jdm9g,UID:9017ab64-3c2b-11e9-83c3-42010a800094,ResourceVersion:12805,Generation:0,CreationTimestamp:2019-03-01 14:09:01 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 8c751322-3c2b-11e9-83c3-42010a800094 0xc4224c9860 0xc4224c9861}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-j45rz {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-j45rz,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-j45rz true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:gke-conformance-default-pool-eca581b0-czl4,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc4224c99c0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc4224c99e0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 14:09:01 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-01 14:09:01 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-01 14:09:01 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 14:09:01 +0000 UTC  }],Message:,Reason:,HostIP:10.128.0.14,PodIP:,StartTime:2019-03-01 14:09:01 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar  1 14:09:03.100: INFO: Pod "nginx-deployment-7f9675fb8b-jv4fg" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-jv4fg,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-428rz,SelfLink:/api/v1/namespaces/e2e-tests-deployment-428rz/pods/nginx-deployment-7f9675fb8b-jv4fg,UID:903f7c2a-3c2b-11e9-83c3-42010a800094,ResourceVersion:12872,Generation:0,CreationTimestamp:2019-03-01 14:09:01 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 8c751322-3c2b-11e9-83c3-42010a800094 0xc4224c9cc0 0xc4224c9cc1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-j45rz {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-j45rz,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-j45rz true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:gke-conformance-default-pool-eca581b0-00fq,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc4224c9d90} {node.kubernetes.io/unreachable Exists  NoExecute 0xc4224c9db0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 14:09:01 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-01 14:09:01 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-01 14:09:01 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 14:09:01 +0000 UTC  }],Message:,Reason:,HostIP:10.128.0.16,PodIP:,StartTime:2019-03-01 14:09:01 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar  1 14:09:03.100: INFO: Pod "nginx-deployment-7f9675fb8b-km8mp" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-km8mp,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-428rz,SelfLink:/api/v1/namespaces/e2e-tests-deployment-428rz/pods/nginx-deployment-7f9675fb8b-km8mp,UID:8c812c6d-3c2b-11e9-83c3-42010a800094,ResourceVersion:12709,Generation:0,CreationTimestamp:2019-03-01 14:08:55 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 8c751322-3c2b-11e9-83c3-42010a800094 0xc4224c9ef0 0xc4224c9ef1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-j45rz {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-j45rz,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-j45rz true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:gke-conformance-default-pool-eca581b0-sww9,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc4224c9f50} {node.kubernetes.io/unreachable Exists  NoExecute 0xc4224c9f70}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 14:08:55 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 14:08:56 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 14:08:56 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 14:08:55 +0000 UTC  }],Message:,Reason:,HostIP:10.128.0.18,PodIP:10.40.1.53,StartTime:2019-03-01 14:08:55 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-03-01 14:08:56 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:b9734546761e49b453efce35ee523bbcaff1052d281516f133d41b090e26c0df docker://1db67b19ce125840fddef2978ff4a51b8ca5e0eb59019c510d1e7c23593f985a}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar  1 14:09:03.100: INFO: Pod "nginx-deployment-7f9675fb8b-kzbm5" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-kzbm5,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-428rz,SelfLink:/api/v1/namespaces/e2e-tests-deployment-428rz/pods/nginx-deployment-7f9675fb8b-kzbm5,UID:902d118b-3c2b-11e9-83c3-42010a800094,ResourceVersion:12878,Generation:0,CreationTimestamp:2019-03-01 14:09:01 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 8c751322-3c2b-11e9-83c3-42010a800094 0xc4224f4350 0xc4224f4351}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-j45rz {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-j45rz,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-j45rz true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:gke-conformance-default-pool-eca581b0-00fq,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc4224f43b0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc4224f43d0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 14:09:01 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 14:09:02 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 14:09:02 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 14:09:01 +0000 UTC  }],Message:,Reason:,HostIP:10.128.0.16,PodIP:10.40.2.21,StartTime:2019-03-01 14:09:01 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-03-01 14:09:02 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:b9734546761e49b453efce35ee523bbcaff1052d281516f133d41b090e26c0df docker://b2e37ff6545d6e47bb627d968f1d1571e1d7fb6e905398441894ef9ced84c45c}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar  1 14:09:03.100: INFO: Pod "nginx-deployment-7f9675fb8b-lrgg5" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-lrgg5,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-428rz,SelfLink:/api/v1/namespaces/e2e-tests-deployment-428rz/pods/nginx-deployment-7f9675fb8b-lrgg5,UID:902cf056-3c2b-11e9-83c3-42010a800094,ResourceVersion:12863,Generation:0,CreationTimestamp:2019-03-01 14:09:01 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 8c751322-3c2b-11e9-83c3-42010a800094 0xc4224f4eb0 0xc4224f4eb1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-j45rz {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-j45rz,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-j45rz true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:gke-conformance-default-pool-eca581b0-40vx,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc4224f4f10} {node.kubernetes.io/unreachable Exists  NoExecute 0xc4224f4f30}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 14:09:01 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-01 14:09:01 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-01 14:09:01 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 14:09:01 +0000 UTC  }],Message:,Reason:,HostIP:10.128.0.15,PodIP:,StartTime:2019-03-01 14:09:01 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar  1 14:09:03.100: INFO: Pod "nginx-deployment-7f9675fb8b-m49wz" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-m49wz,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-428rz,SelfLink:/api/v1/namespaces/e2e-tests-deployment-428rz/pods/nginx-deployment-7f9675fb8b-m49wz,UID:8c7cae2f-3c2b-11e9-83c3-42010a800094,ResourceVersion:12706,Generation:0,CreationTimestamp:2019-03-01 14:08:54 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 8c751322-3c2b-11e9-83c3-42010a800094 0xc4224f5930 0xc4224f5931}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-j45rz {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-j45rz,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-j45rz true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:gke-conformance-default-pool-eca581b0-sqmc,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc4224f5990} {node.kubernetes.io/unreachable Exists  NoExecute 0xc4224f59b0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 14:08:55 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 14:08:56 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 14:08:56 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 14:08:54 +0000 UTC  }],Message:,Reason:,HostIP:10.128.0.17,PodIP:10.40.3.51,StartTime:2019-03-01 14:08:55 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-03-01 14:08:56 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:b9734546761e49b453efce35ee523bbcaff1052d281516f133d41b090e26c0df docker://6e773f494f59ad62c96746914b62fe217baf87374afc58317210e9180d74e142}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar  1 14:09:03.100: INFO: Pod "nginx-deployment-7f9675fb8b-n7jd6" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-n7jd6,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-428rz,SelfLink:/api/v1/namespaces/e2e-tests-deployment-428rz/pods/nginx-deployment-7f9675fb8b-n7jd6,UID:902d0bde-3c2b-11e9-83c3-42010a800094,ResourceVersion:12839,Generation:0,CreationTimestamp:2019-03-01 14:09:01 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 8c751322-3c2b-11e9-83c3-42010a800094 0xc4224f5e60 0xc4224f5e61}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-j45rz {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-j45rz,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-j45rz true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:gke-conformance-default-pool-eca581b0-czl4,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc422456040} {node.kubernetes.io/unreachable Exists  NoExecute 0xc422456060}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 14:09:01 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-01 14:09:01 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-01 14:09:01 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 14:09:01 +0000 UTC  }],Message:,Reason:,HostIP:10.128.0.14,PodIP:,StartTime:2019-03-01 14:09:01 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar  1 14:09:03.100: INFO: Pod "nginx-deployment-7f9675fb8b-pd5bd" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-pd5bd,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-428rz,SelfLink:/api/v1/namespaces/e2e-tests-deployment-428rz/pods/nginx-deployment-7f9675fb8b-pd5bd,UID:8c7b4036-3c2b-11e9-83c3-42010a800094,ResourceVersion:12727,Generation:0,CreationTimestamp:2019-03-01 14:08:54 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 8c751322-3c2b-11e9-83c3-42010a800094 0xc422456110 0xc422456111}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-j45rz {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-j45rz,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-j45rz true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:gke-conformance-default-pool-eca581b0-sww9,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc422456170} {node.kubernetes.io/unreachable Exists  NoExecute 0xc422456190}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 14:08:55 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 14:08:57 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 14:08:57 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 14:08:54 +0000 UTC  }],Message:,Reason:,HostIP:10.128.0.18,PodIP:10.40.1.54,StartTime:2019-03-01 14:08:55 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-03-01 14:08:57 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:b9734546761e49b453efce35ee523bbcaff1052d281516f133d41b090e26c0df docker://998ce0d04bd3b971d5a874b31fff2f33e7ea51e302689d4e04451659218d8c06}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar  1 14:09:03.101: INFO: Pod "nginx-deployment-7f9675fb8b-rrzd8" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-rrzd8,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-428rz,SelfLink:/api/v1/namespaces/e2e-tests-deployment-428rz/pods/nginx-deployment-7f9675fb8b-rrzd8,UID:901dcd2f-3c2b-11e9-83c3-42010a800094,ResourceVersion:12819,Generation:0,CreationTimestamp:2019-03-01 14:09:01 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 8c751322-3c2b-11e9-83c3-42010a800094 0xc422456250 0xc422456251}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-j45rz {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-j45rz,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-j45rz true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:gke-conformance-default-pool-eca581b0-czl4,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc4224562b0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc4224562d0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 14:09:01 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-01 14:09:01 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-01 14:09:01 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 14:09:01 +0000 UTC  }],Message:,Reason:,HostIP:10.128.0.14,PodIP:,StartTime:2019-03-01 14:09:01 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar  1 14:09:03.101: INFO: Pod "nginx-deployment-7f9675fb8b-wvc9m" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-wvc9m,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-428rz,SelfLink:/api/v1/namespaces/e2e-tests-deployment-428rz/pods/nginx-deployment-7f9675fb8b-wvc9m,UID:8c7d0217-3c2b-11e9-83c3-42010a800094,ResourceVersion:12721,Generation:0,CreationTimestamp:2019-03-01 14:08:54 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 8c751322-3c2b-11e9-83c3-42010a800094 0xc422456380 0xc422456381}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-j45rz {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-j45rz,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-j45rz true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:gke-conformance-default-pool-eca581b0-czl4,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc4224563e0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc422456400}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 14:08:55 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 14:08:57 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 14:08:57 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 14:08:55 +0000 UTC  }],Message:,Reason:,HostIP:10.128.0.14,PodIP:10.40.4.62,StartTime:2019-03-01 14:08:55 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-03-01 14:08:56 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:b9734546761e49b453efce35ee523bbcaff1052d281516f133d41b090e26c0df docker://8b4f9d532bcc227c5a887d357b5ba023b8df364d6ec9ba73f1171b9ae54cc94d}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Mar  1 14:09:03.101: INFO: Pod "nginx-deployment-7f9675fb8b-zjs76" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-zjs76,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-428rz,SelfLink:/api/v1/namespaces/e2e-tests-deployment-428rz/pods/nginx-deployment-7f9675fb8b-zjs76,UID:8c819d37-3c2b-11e9-83c3-42010a800094,ResourceVersion:12703,Generation:0,CreationTimestamp:2019-03-01 14:08:55 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 8c751322-3c2b-11e9-83c3-42010a800094 0xc4224564c0 0xc4224564c1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-j45rz {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-j45rz,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-j45rz true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:gke-conformance-default-pool-eca581b0-sqmc,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc422456520} {node.kubernetes.io/unreachable Exists  NoExecute 0xc422456540}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 14:08:55 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 14:08:56 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 14:08:56 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 14:08:55 +0000 UTC  }],Message:,Reason:,HostIP:10.128.0.17,PodIP:10.40.3.52,StartTime:2019-03-01 14:08:55 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-03-01 14:08:56 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:b9734546761e49b453efce35ee523bbcaff1052d281516f133d41b090e26c0df docker://207cea197123ab20c56853838fa6680603a661806c0ff34deca37b647feae125}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 14:09:03.101: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-428rz" for this suite.
Mar  1 14:09:11.145: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 14:09:11.249: INFO: namespace: e2e-tests-deployment-428rz, resource: bindings, ignored listing per whitelist
Mar  1 14:09:11.276: INFO: namespace e2e-tests-deployment-428rz deletion completed in 8.161021756s

• [SLOW TEST:16.532 seconds]
[sig-apps] Deployment
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 14:09:11.277: INFO: >>> kubeConfig: /tmp/kubeconfig-210205575
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0666 on node default medium
Mar  1 14:09:11.391: INFO: Waiting up to 5m0s for pod "pod-964417aa-3c2b-11e9-a154-0a580a280202" in namespace "e2e-tests-emptydir-tb8kj" to be "success or failure"
Mar  1 14:09:11.394: INFO: Pod "pod-964417aa-3c2b-11e9-a154-0a580a280202": Phase="Pending", Reason="", readiness=false. Elapsed: 3.104577ms
Mar  1 14:09:13.398: INFO: Pod "pod-964417aa-3c2b-11e9-a154-0a580a280202": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006587832s
Mar  1 14:09:15.404: INFO: Pod "pod-964417aa-3c2b-11e9-a154-0a580a280202": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.01265188s
STEP: Saw pod success
Mar  1 14:09:15.404: INFO: Pod "pod-964417aa-3c2b-11e9-a154-0a580a280202" satisfied condition "success or failure"
Mar  1 14:09:15.407: INFO: Trying to get logs from node gke-conformance-default-pool-eca581b0-czl4 pod pod-964417aa-3c2b-11e9-a154-0a580a280202 container test-container: <nil>
STEP: delete the pod
Mar  1 14:09:15.432: INFO: Waiting for pod pod-964417aa-3c2b-11e9-a154-0a580a280202 to disappear
Mar  1 14:09:15.438: INFO: Pod pod-964417aa-3c2b-11e9-a154-0a580a280202 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 14:09:15.438: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-tb8kj" for this suite.
Mar  1 14:09:21.461: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 14:09:21.500: INFO: namespace: e2e-tests-emptydir-tb8kj, resource: bindings, ignored listing per whitelist
Mar  1 14:09:21.583: INFO: namespace e2e-tests-emptydir-tb8kj deletion completed in 6.141245934s

• [SLOW TEST:10.306 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[k8s.io] Probing container 
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 14:09:21.583: INFO: >>> kubeConfig: /tmp/kubeconfig-210205575
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-http in namespace e2e-tests-container-probe-pj7lc
Mar  1 14:09:23.707: INFO: Started pod liveness-http in namespace e2e-tests-container-probe-pj7lc
STEP: checking the pod's current state and verifying that restartCount is present
Mar  1 14:09:23.710: INFO: Initial restart count of pod liveness-http is 0
Mar  1 14:09:43.752: INFO: Restart count of pod e2e-tests-container-probe-pj7lc/liveness-http is now 1 (20.041901961s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 14:09:43.767: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-pj7lc" for this suite.
Mar  1 14:09:49.798: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 14:09:49.880: INFO: namespace: e2e-tests-container-probe-pj7lc, resource: bindings, ignored listing per whitelist
Mar  1 14:09:49.932: INFO: namespace e2e-tests-container-probe-pj7lc deletion completed in 6.157868773s

• [SLOW TEST:28.349 seconds]
[k8s.io] Probing container
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources Simple CustomResourceDefinition 
  creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 14:09:49.932: INFO: >>> kubeConfig: /tmp/kubeconfig-210205575
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Waiting for a default service account to be provisioned in namespace
[It] creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Mar  1 14:09:50.026: INFO: >>> kubeConfig: /tmp/kubeconfig-210205575
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 14:09:51.089: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-custom-resource-definition-s8jf4" for this suite.
Mar  1 14:09:57.106: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 14:09:57.161: INFO: namespace: e2e-tests-custom-resource-definition-s8jf4, resource: bindings, ignored listing per whitelist
Mar  1 14:09:57.257: INFO: namespace e2e-tests-custom-resource-definition-s8jf4 deletion completed in 6.162964553s

• [SLOW TEST:7.325 seconds]
[sig-api-machinery] CustomResourceDefinition resources
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  Simple CustomResourceDefinition
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/custom_resource_definition.go:35
    creating/deleting custom resource definition objects works  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 14:09:57.257: INFO: >>> kubeConfig: /tmp/kubeconfig-210205575
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0644 on tmpfs
Mar  1 14:09:57.353: INFO: Waiting up to 5m0s for pod "pod-b1a928ed-3c2b-11e9-a154-0a580a280202" in namespace "e2e-tests-emptydir-gvfzj" to be "success or failure"
Mar  1 14:09:57.364: INFO: Pod "pod-b1a928ed-3c2b-11e9-a154-0a580a280202": Phase="Pending", Reason="", readiness=false. Elapsed: 11.242491ms
Mar  1 14:09:59.368: INFO: Pod "pod-b1a928ed-3c2b-11e9-a154-0a580a280202": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015583096s
Mar  1 14:10:01.371: INFO: Pod "pod-b1a928ed-3c2b-11e9-a154-0a580a280202": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.018903636s
STEP: Saw pod success
Mar  1 14:10:01.372: INFO: Pod "pod-b1a928ed-3c2b-11e9-a154-0a580a280202" satisfied condition "success or failure"
Mar  1 14:10:01.374: INFO: Trying to get logs from node gke-conformance-default-pool-eca581b0-sqmc pod pod-b1a928ed-3c2b-11e9-a154-0a580a280202 container test-container: <nil>
STEP: delete the pod
Mar  1 14:10:01.399: INFO: Waiting for pod pod-b1a928ed-3c2b-11e9-a154-0a580a280202 to disappear
Mar  1 14:10:01.401: INFO: Pod pod-b1a928ed-3c2b-11e9-a154-0a580a280202 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 14:10:01.401: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-gvfzj" for this suite.
Mar  1 14:10:07.421: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 14:10:07.521: INFO: namespace: e2e-tests-emptydir-gvfzj, resource: bindings, ignored listing per whitelist
Mar  1 14:10:07.590: INFO: namespace e2e-tests-emptydir-gvfzj deletion completed in 6.183830265s

• [SLOW TEST:10.333 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 14:10:07.590: INFO: >>> kubeConfig: /tmp/kubeconfig-210205575
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a watch on configmaps
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: closing the watch once it receives two notifications
Mar  1 14:10:07.704: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-8nfht,SelfLink:/api/v1/namespaces/e2e-tests-watch-8nfht/configmaps/e2e-watch-test-watch-closed,UID:b7d4159a-3c2b-11e9-83c3-42010a800094,ResourceVersion:13265,Generation:0,CreationTimestamp:2019-03-01 14:10:07 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Mar  1 14:10:07.704: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-8nfht,SelfLink:/api/v1/namespaces/e2e-tests-watch-8nfht/configmaps/e2e-watch-test-watch-closed,UID:b7d4159a-3c2b-11e9-83c3-42010a800094,ResourceVersion:13266,Generation:0,CreationTimestamp:2019-03-01 14:10:07 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time, while the watch is closed
STEP: creating a new watch on configmaps from the last resource version observed by the first watch
STEP: deleting the configmap
STEP: Expecting to observe notifications for all changes to the configmap since the first watch closed
Mar  1 14:10:07.722: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-8nfht,SelfLink:/api/v1/namespaces/e2e-tests-watch-8nfht/configmaps/e2e-watch-test-watch-closed,UID:b7d4159a-3c2b-11e9-83c3-42010a800094,ResourceVersion:13267,Generation:0,CreationTimestamp:2019-03-01 14:10:07 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Mar  1 14:10:07.722: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-8nfht,SelfLink:/api/v1/namespaces/e2e-tests-watch-8nfht/configmaps/e2e-watch-test-watch-closed,UID:b7d4159a-3c2b-11e9-83c3-42010a800094,ResourceVersion:13268,Generation:0,CreationTimestamp:2019-03-01 14:10:07 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 14:10:07.722: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-8nfht" for this suite.
Mar  1 14:10:13.738: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 14:10:13.788: INFO: namespace: e2e-tests-watch-8nfht, resource: bindings, ignored listing per whitelist
Mar  1 14:10:13.867: INFO: namespace e2e-tests-watch-8nfht deletion completed in 6.139640038s

• [SLOW TEST:6.278 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Projected 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 14:10:13.867: INFO: >>> kubeConfig: /tmp/kubeconfig-210205575
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Mar  1 14:10:13.964: INFO: Waiting up to 5m0s for pod "downwardapi-volume-bb8feff0-3c2b-11e9-a154-0a580a280202" in namespace "e2e-tests-projected-jqp4p" to be "success or failure"
Mar  1 14:10:13.974: INFO: Pod "downwardapi-volume-bb8feff0-3c2b-11e9-a154-0a580a280202": Phase="Pending", Reason="", readiness=false. Elapsed: 10.037127ms
Mar  1 14:10:15.979: INFO: Pod "downwardapi-volume-bb8feff0-3c2b-11e9-a154-0a580a280202": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.015001424s
STEP: Saw pod success
Mar  1 14:10:15.979: INFO: Pod "downwardapi-volume-bb8feff0-3c2b-11e9-a154-0a580a280202" satisfied condition "success or failure"
Mar  1 14:10:15.983: INFO: Trying to get logs from node gke-conformance-default-pool-eca581b0-czl4 pod downwardapi-volume-bb8feff0-3c2b-11e9-a154-0a580a280202 container client-container: <nil>
STEP: delete the pod
Mar  1 14:10:16.008: INFO: Waiting for pod downwardapi-volume-bb8feff0-3c2b-11e9-a154-0a580a280202 to disappear
Mar  1 14:10:16.013: INFO: Pod downwardapi-volume-bb8feff0-3c2b-11e9-a154-0a580a280202 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 14:10:16.013: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-jqp4p" for this suite.
Mar  1 14:10:22.031: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 14:10:22.084: INFO: namespace: e2e-tests-projected-jqp4p, resource: bindings, ignored listing per whitelist
Mar  1 14:10:22.155: INFO: namespace e2e-tests-projected-jqp4p deletion completed in 6.136145883s

• [SLOW TEST:8.288 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 14:10:22.155: INFO: >>> kubeConfig: /tmp/kubeconfig-210205575
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Mar  1 14:10:28.303: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Mar  1 14:10:28.306: INFO: Pod pod-with-prestop-http-hook still exists
Mar  1 14:10:30.306: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Mar  1 14:10:30.309: INFO: Pod pod-with-prestop-http-hook still exists
Mar  1 14:10:32.306: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Mar  1 14:10:32.310: INFO: Pod pod-with-prestop-http-hook still exists
Mar  1 14:10:34.306: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Mar  1 14:10:34.310: INFO: Pod pod-with-prestop-http-hook still exists
Mar  1 14:10:36.306: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Mar  1 14:10:36.309: INFO: Pod pod-with-prestop-http-hook still exists
Mar  1 14:10:38.306: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Mar  1 14:10:38.310: INFO: Pod pod-with-prestop-http-hook still exists
Mar  1 14:10:40.306: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Mar  1 14:10:40.310: INFO: Pod pod-with-prestop-http-hook still exists
Mar  1 14:10:42.306: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Mar  1 14:10:42.310: INFO: Pod pod-with-prestop-http-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 14:10:42.323: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-lifecycle-hook-7m977" for this suite.
Mar  1 14:11:04.338: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 14:11:04.456: INFO: namespace: e2e-tests-container-lifecycle-hook-7m977, resource: bindings, ignored listing per whitelist
Mar  1 14:11:04.521: INFO: namespace e2e-tests-container-lifecycle-hook-7m977 deletion completed in 22.193424389s

• [SLOW TEST:42.366 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when create a pod with lifecycle hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute prestop http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 14:11:04.521: INFO: >>> kubeConfig: /tmp/kubeconfig-210205575
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-d9c28551-3c2b-11e9-a154-0a580a280202
STEP: Creating a pod to test consume configMaps
Mar  1 14:11:04.628: INFO: Waiting up to 5m0s for pod "pod-configmaps-d9c32e52-3c2b-11e9-a154-0a580a280202" in namespace "e2e-tests-configmap-44tvb" to be "success or failure"
Mar  1 14:11:04.632: INFO: Pod "pod-configmaps-d9c32e52-3c2b-11e9-a154-0a580a280202": Phase="Pending", Reason="", readiness=false. Elapsed: 3.786507ms
Mar  1 14:11:06.637: INFO: Pod "pod-configmaps-d9c32e52-3c2b-11e9-a154-0a580a280202": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008437248s
STEP: Saw pod success
Mar  1 14:11:06.637: INFO: Pod "pod-configmaps-d9c32e52-3c2b-11e9-a154-0a580a280202" satisfied condition "success or failure"
Mar  1 14:11:06.641: INFO: Trying to get logs from node gke-conformance-default-pool-eca581b0-czl4 pod pod-configmaps-d9c32e52-3c2b-11e9-a154-0a580a280202 container configmap-volume-test: <nil>
STEP: delete the pod
Mar  1 14:11:06.689: INFO: Waiting for pod pod-configmaps-d9c32e52-3c2b-11e9-a154-0a580a280202 to disappear
Mar  1 14:11:06.694: INFO: Pod pod-configmaps-d9c32e52-3c2b-11e9-a154-0a580a280202 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 14:11:06.694: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-44tvb" for this suite.
Mar  1 14:11:12.707: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 14:11:12.774: INFO: namespace: e2e-tests-configmap-44tvb, resource: bindings, ignored listing per whitelist
Mar  1 14:11:12.856: INFO: namespace e2e-tests-configmap-44tvb deletion completed in 6.158927896s

• [SLOW TEST:8.335 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[k8s.io] Probing container 
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 14:11:12.856: INFO: >>> kubeConfig: /tmp/kubeconfig-210205575
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-exec in namespace e2e-tests-container-probe-7rx6f
Mar  1 14:11:16.988: INFO: Started pod liveness-exec in namespace e2e-tests-container-probe-7rx6f
STEP: checking the pod's current state and verifying that restartCount is present
Mar  1 14:11:16.992: INFO: Initial restart count of pod liveness-exec is 0
Mar  1 14:12:03.078: INFO: Restart count of pod e2e-tests-container-probe-7rx6f/liveness-exec is now 1 (46.086744889s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 14:12:03.096: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-7rx6f" for this suite.
Mar  1 14:12:09.112: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 14:12:09.199: INFO: namespace: e2e-tests-container-probe-7rx6f, resource: bindings, ignored listing per whitelist
Mar  1 14:12:09.226: INFO: namespace e2e-tests-container-probe-7rx6f deletion completed in 6.124288568s

• [SLOW TEST:56.369 seconds]
[k8s.io] Probing container
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-api-machinery] ConfigMap 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 14:12:09.226: INFO: >>> kubeConfig: /tmp/kubeconfig-210205575
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap e2e-tests-configmap-rvzgn/configmap-test-0053933e-3c2c-11e9-a154-0a580a280202
STEP: Creating a pod to test consume configMaps
Mar  1 14:12:09.336: INFO: Waiting up to 5m0s for pod "pod-configmaps-00544e28-3c2c-11e9-a154-0a580a280202" in namespace "e2e-tests-configmap-rvzgn" to be "success or failure"
Mar  1 14:12:09.350: INFO: Pod "pod-configmaps-00544e28-3c2c-11e9-a154-0a580a280202": Phase="Pending", Reason="", readiness=false. Elapsed: 13.986821ms
Mar  1 14:12:11.355: INFO: Pod "pod-configmaps-00544e28-3c2c-11e9-a154-0a580a280202": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.018383318s
STEP: Saw pod success
Mar  1 14:12:11.355: INFO: Pod "pod-configmaps-00544e28-3c2c-11e9-a154-0a580a280202" satisfied condition "success or failure"
Mar  1 14:12:11.357: INFO: Trying to get logs from node gke-conformance-default-pool-eca581b0-sqmc pod pod-configmaps-00544e28-3c2c-11e9-a154-0a580a280202 container env-test: <nil>
STEP: delete the pod
Mar  1 14:12:11.387: INFO: Waiting for pod pod-configmaps-00544e28-3c2c-11e9-a154-0a580a280202 to disappear
Mar  1 14:12:11.393: INFO: Pod pod-configmaps-00544e28-3c2c-11e9-a154-0a580a280202 no longer exists
[AfterEach] [sig-api-machinery] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 14:12:11.393: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-rvzgn" for this suite.
Mar  1 14:12:17.411: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 14:12:17.485: INFO: namespace: e2e-tests-configmap-rvzgn, resource: bindings, ignored listing per whitelist
Mar  1 14:12:17.543: INFO: namespace e2e-tests-configmap-rvzgn deletion completed in 6.145714458s

• [SLOW TEST:8.318 seconds]
[sig-api-machinery] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:30
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run deployment 
  should create a deployment from an image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 14:12:17.544: INFO: >>> kubeConfig: /tmp/kubeconfig-210205575
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Kubectl run deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1347
[It] should create a deployment from an image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Mar  1 14:12:17.641: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-210205575 run e2e-test-nginx-deployment --image=docker.io/library/nginx:1.14-alpine --generator=deployment/v1beta1 --namespace=e2e-tests-kubectl-qcmsj'
Mar  1 14:12:17.940: INFO: stderr: "kubectl run --generator=deployment/v1beta1 is DEPRECATED and will be removed in a future version. Use kubectl create instead.\n"
Mar  1 14:12:17.940: INFO: stdout: "deployment.extensions/e2e-test-nginx-deployment created\n"
STEP: verifying the deployment e2e-test-nginx-deployment was created
STEP: verifying the pod controlled by deployment e2e-test-nginx-deployment was created
[AfterEach] [k8s.io] Kubectl run deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1352
Mar  1 14:12:21.963: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-210205575 delete deployment e2e-test-nginx-deployment --namespace=e2e-tests-kubectl-qcmsj'
Mar  1 14:12:22.051: INFO: stderr: ""
Mar  1 14:12:22.051: INFO: stdout: "deployment.extensions \"e2e-test-nginx-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 14:12:22.051: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-qcmsj" for this suite.
Mar  1 14:12:28.078: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 14:12:28.119: INFO: namespace: e2e-tests-kubectl-qcmsj, resource: bindings, ignored listing per whitelist
Mar  1 14:12:28.198: INFO: namespace e2e-tests-kubectl-qcmsj deletion completed in 6.141756302s

• [SLOW TEST:10.655 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create a deployment from an image  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 14:12:28.199: INFO: >>> kubeConfig: /tmp/kubeconfig-210205575
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with configmap pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-configmap-44ht
STEP: Creating a pod to test atomic-volume-subpath
Mar  1 14:12:28.346: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-44ht" in namespace "e2e-tests-subpath-76kxz" to be "success or failure"
Mar  1 14:12:28.369: INFO: Pod "pod-subpath-test-configmap-44ht": Phase="Pending", Reason="", readiness=false. Elapsed: 22.707044ms
Mar  1 14:12:30.372: INFO: Pod "pod-subpath-test-configmap-44ht": Phase="Pending", Reason="", readiness=false. Elapsed: 2.026624947s
Mar  1 14:12:32.376: INFO: Pod "pod-subpath-test-configmap-44ht": Phase="Running", Reason="", readiness=false. Elapsed: 4.030345833s
Mar  1 14:12:34.385: INFO: Pod "pod-subpath-test-configmap-44ht": Phase="Running", Reason="", readiness=false. Elapsed: 6.039000605s
Mar  1 14:12:36.389: INFO: Pod "pod-subpath-test-configmap-44ht": Phase="Running", Reason="", readiness=false. Elapsed: 8.042761417s
Mar  1 14:12:38.392: INFO: Pod "pod-subpath-test-configmap-44ht": Phase="Running", Reason="", readiness=false. Elapsed: 10.046592084s
Mar  1 14:12:40.396: INFO: Pod "pod-subpath-test-configmap-44ht": Phase="Running", Reason="", readiness=false. Elapsed: 12.050270439s
Mar  1 14:12:42.400: INFO: Pod "pod-subpath-test-configmap-44ht": Phase="Running", Reason="", readiness=false. Elapsed: 14.053926299s
Mar  1 14:12:44.403: INFO: Pod "pod-subpath-test-configmap-44ht": Phase="Running", Reason="", readiness=false. Elapsed: 16.057515337s
Mar  1 14:12:46.407: INFO: Pod "pod-subpath-test-configmap-44ht": Phase="Running", Reason="", readiness=false. Elapsed: 18.061503135s
Mar  1 14:12:48.412: INFO: Pod "pod-subpath-test-configmap-44ht": Phase="Running", Reason="", readiness=false. Elapsed: 20.065732779s
Mar  1 14:12:50.416: INFO: Pod "pod-subpath-test-configmap-44ht": Phase="Running", Reason="", readiness=false. Elapsed: 22.069901267s
Mar  1 14:12:52.420: INFO: Pod "pod-subpath-test-configmap-44ht": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.073791667s
STEP: Saw pod success
Mar  1 14:12:52.420: INFO: Pod "pod-subpath-test-configmap-44ht" satisfied condition "success or failure"
Mar  1 14:12:52.423: INFO: Trying to get logs from node gke-conformance-default-pool-eca581b0-sqmc pod pod-subpath-test-configmap-44ht container test-container-subpath-configmap-44ht: <nil>
STEP: delete the pod
Mar  1 14:12:52.452: INFO: Waiting for pod pod-subpath-test-configmap-44ht to disappear
Mar  1 14:12:52.457: INFO: Pod pod-subpath-test-configmap-44ht no longer exists
STEP: Deleting pod pod-subpath-test-configmap-44ht
Mar  1 14:12:52.457: INFO: Deleting pod "pod-subpath-test-configmap-44ht" in namespace "e2e-tests-subpath-76kxz"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 14:12:52.460: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-76kxz" for this suite.
Mar  1 14:12:58.485: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 14:12:58.535: INFO: namespace: e2e-tests-subpath-76kxz, resource: bindings, ignored listing per whitelist
Mar  1 14:12:58.604: INFO: namespace e2e-tests-subpath-76kxz deletion completed in 6.139684031s

• [SLOW TEST:30.406 seconds]
[sig-storage] Subpath
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with configmap pod [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl cluster-info 
  should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 14:12:58.604: INFO: >>> kubeConfig: /tmp/kubeconfig-210205575
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: validating cluster-info
Mar  1 14:12:58.745: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-210205575 cluster-info'
Mar  1 14:12:58.843: INFO: stderr: ""
Mar  1 14:12:58.843: INFO: stdout: "\x1b[0;32mKubernetes master\x1b[0m is running at \x1b[0;33mhttps://10.43.240.1:443\x1b[0m\n\x1b[0;32mGLBCDefaultBackend\x1b[0m is running at \x1b[0;33mhttps://10.43.240.1:443/api/v1/namespaces/kube-system/services/default-http-backend:http/proxy\x1b[0m\n\x1b[0;32mHeapster\x1b[0m is running at \x1b[0;33mhttps://10.43.240.1:443/api/v1/namespaces/kube-system/services/heapster/proxy\x1b[0m\n\x1b[0;32mKubeDNS\x1b[0m is running at \x1b[0;33mhttps://10.43.240.1:443/api/v1/namespaces/kube-system/services/kube-dns:dns/proxy\x1b[0m\n\x1b[0;32mMetrics-server\x1b[0m is running at \x1b[0;33mhttps://10.43.240.1:443/api/v1/namespaces/kube-system/services/https:metrics-server:/proxy\x1b[0m\n\nTo further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 14:12:58.843: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-dnz7c" for this suite.
Mar  1 14:13:08.863: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 14:13:08.919: INFO: namespace: e2e-tests-kubectl-dnz7c, resource: bindings, ignored listing per whitelist
Mar  1 14:13:09.017: INFO: namespace e2e-tests-kubectl-dnz7c deletion completed in 10.166867529s

• [SLOW TEST:10.413 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl cluster-info
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should check if Kubernetes master services is included in cluster-info  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 14:13:09.017: INFO: >>> kubeConfig: /tmp/kubeconfig-210205575
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:98
[It] should run and stop complex daemon [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Mar  1 14:13:09.151: INFO: Creating daemon "daemon-set" with a node selector
STEP: Initially, daemon pods should not be running on any nodes.
Mar  1 14:13:09.172: INFO: Number of nodes with available pods: 0
Mar  1 14:13:09.173: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Change node label to blue, check that daemon pod is launched.
Mar  1 14:13:09.260: INFO: Number of nodes with available pods: 0
Mar  1 14:13:09.260: INFO: Node gke-conformance-default-pool-eca581b0-00fq is running more than one daemon pod
Mar  1 14:13:10.268: INFO: Number of nodes with available pods: 0
Mar  1 14:13:10.268: INFO: Node gke-conformance-default-pool-eca581b0-00fq is running more than one daemon pod
Mar  1 14:13:11.264: INFO: Number of nodes with available pods: 1
Mar  1 14:13:11.264: INFO: Number of running nodes: 1, number of available pods: 1
STEP: Update the node label to green, and wait for daemons to be unscheduled
Mar  1 14:13:11.288: INFO: Number of nodes with available pods: 1
Mar  1 14:13:11.288: INFO: Number of running nodes: 0, number of available pods: 1
Mar  1 14:13:12.291: INFO: Number of nodes with available pods: 0
Mar  1 14:13:12.291: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Update DaemonSet node selector to green, and change its update strategy to RollingUpdate
Mar  1 14:13:12.305: INFO: Number of nodes with available pods: 0
Mar  1 14:13:12.305: INFO: Node gke-conformance-default-pool-eca581b0-00fq is running more than one daemon pod
Mar  1 14:13:13.312: INFO: Number of nodes with available pods: 0
Mar  1 14:13:13.312: INFO: Node gke-conformance-default-pool-eca581b0-00fq is running more than one daemon pod
Mar  1 14:13:14.308: INFO: Number of nodes with available pods: 0
Mar  1 14:13:14.308: INFO: Node gke-conformance-default-pool-eca581b0-00fq is running more than one daemon pod
Mar  1 14:13:15.309: INFO: Number of nodes with available pods: 0
Mar  1 14:13:15.309: INFO: Node gke-conformance-default-pool-eca581b0-00fq is running more than one daemon pod
Mar  1 14:13:16.308: INFO: Number of nodes with available pods: 0
Mar  1 14:13:16.308: INFO: Node gke-conformance-default-pool-eca581b0-00fq is running more than one daemon pod
Mar  1 14:13:17.308: INFO: Number of nodes with available pods: 0
Mar  1 14:13:17.308: INFO: Node gke-conformance-default-pool-eca581b0-00fq is running more than one daemon pod
Mar  1 14:13:18.310: INFO: Number of nodes with available pods: 0
Mar  1 14:13:18.310: INFO: Node gke-conformance-default-pool-eca581b0-00fq is running more than one daemon pod
Mar  1 14:13:19.309: INFO: Number of nodes with available pods: 0
Mar  1 14:13:19.309: INFO: Node gke-conformance-default-pool-eca581b0-00fq is running more than one daemon pod
Mar  1 14:13:20.308: INFO: Number of nodes with available pods: 0
Mar  1 14:13:20.308: INFO: Node gke-conformance-default-pool-eca581b0-00fq is running more than one daemon pod
Mar  1 14:13:21.308: INFO: Number of nodes with available pods: 0
Mar  1 14:13:21.308: INFO: Node gke-conformance-default-pool-eca581b0-00fq is running more than one daemon pod
Mar  1 14:13:22.308: INFO: Number of nodes with available pods: 0
Mar  1 14:13:22.308: INFO: Node gke-conformance-default-pool-eca581b0-00fq is running more than one daemon pod
Mar  1 14:13:23.309: INFO: Number of nodes with available pods: 0
Mar  1 14:13:23.309: INFO: Node gke-conformance-default-pool-eca581b0-00fq is running more than one daemon pod
Mar  1 14:13:24.311: INFO: Number of nodes with available pods: 0
Mar  1 14:13:24.311: INFO: Node gke-conformance-default-pool-eca581b0-00fq is running more than one daemon pod
Mar  1 14:13:25.309: INFO: Number of nodes with available pods: 0
Mar  1 14:13:25.309: INFO: Node gke-conformance-default-pool-eca581b0-00fq is running more than one daemon pod
Mar  1 14:13:26.308: INFO: Number of nodes with available pods: 0
Mar  1 14:13:26.308: INFO: Node gke-conformance-default-pool-eca581b0-00fq is running more than one daemon pod
Mar  1 14:13:27.310: INFO: Number of nodes with available pods: 0
Mar  1 14:13:27.310: INFO: Node gke-conformance-default-pool-eca581b0-00fq is running more than one daemon pod
Mar  1 14:13:28.309: INFO: Number of nodes with available pods: 0
Mar  1 14:13:28.309: INFO: Node gke-conformance-default-pool-eca581b0-00fq is running more than one daemon pod
Mar  1 14:13:29.309: INFO: Number of nodes with available pods: 0
Mar  1 14:13:29.309: INFO: Node gke-conformance-default-pool-eca581b0-00fq is running more than one daemon pod
Mar  1 14:13:30.308: INFO: Number of nodes with available pods: 0
Mar  1 14:13:30.308: INFO: Node gke-conformance-default-pool-eca581b0-00fq is running more than one daemon pod
Mar  1 14:13:31.308: INFO: Number of nodes with available pods: 0
Mar  1 14:13:31.308: INFO: Node gke-conformance-default-pool-eca581b0-00fq is running more than one daemon pod
Mar  1 14:13:32.309: INFO: Number of nodes with available pods: 0
Mar  1 14:13:32.309: INFO: Node gke-conformance-default-pool-eca581b0-00fq is running more than one daemon pod
Mar  1 14:13:33.308: INFO: Number of nodes with available pods: 0
Mar  1 14:13:33.308: INFO: Node gke-conformance-default-pool-eca581b0-00fq is running more than one daemon pod
Mar  1 14:13:34.309: INFO: Number of nodes with available pods: 0
Mar  1 14:13:34.309: INFO: Node gke-conformance-default-pool-eca581b0-00fq is running more than one daemon pod
Mar  1 14:13:35.309: INFO: Number of nodes with available pods: 0
Mar  1 14:13:35.309: INFO: Node gke-conformance-default-pool-eca581b0-00fq is running more than one daemon pod
Mar  1 14:13:36.309: INFO: Number of nodes with available pods: 0
Mar  1 14:13:36.309: INFO: Node gke-conformance-default-pool-eca581b0-00fq is running more than one daemon pod
Mar  1 14:13:37.308: INFO: Number of nodes with available pods: 0
Mar  1 14:13:37.308: INFO: Node gke-conformance-default-pool-eca581b0-00fq is running more than one daemon pod
Mar  1 14:13:38.309: INFO: Number of nodes with available pods: 0
Mar  1 14:13:38.309: INFO: Node gke-conformance-default-pool-eca581b0-00fq is running more than one daemon pod
Mar  1 14:13:39.308: INFO: Number of nodes with available pods: 0
Mar  1 14:13:39.308: INFO: Node gke-conformance-default-pool-eca581b0-00fq is running more than one daemon pod
Mar  1 14:13:40.308: INFO: Number of nodes with available pods: 0
Mar  1 14:13:40.308: INFO: Node gke-conformance-default-pool-eca581b0-00fq is running more than one daemon pod
Mar  1 14:13:41.310: INFO: Number of nodes with available pods: 0
Mar  1 14:13:41.310: INFO: Node gke-conformance-default-pool-eca581b0-00fq is running more than one daemon pod
Mar  1 14:13:42.308: INFO: Number of nodes with available pods: 0
Mar  1 14:13:42.308: INFO: Node gke-conformance-default-pool-eca581b0-00fq is running more than one daemon pod
Mar  1 14:13:43.309: INFO: Number of nodes with available pods: 0
Mar  1 14:13:43.309: INFO: Node gke-conformance-default-pool-eca581b0-00fq is running more than one daemon pod
Mar  1 14:13:44.309: INFO: Number of nodes with available pods: 0
Mar  1 14:13:44.309: INFO: Node gke-conformance-default-pool-eca581b0-00fq is running more than one daemon pod
Mar  1 14:13:45.309: INFO: Number of nodes with available pods: 0
Mar  1 14:13:45.309: INFO: Node gke-conformance-default-pool-eca581b0-00fq is running more than one daemon pod
Mar  1 14:13:46.309: INFO: Number of nodes with available pods: 0
Mar  1 14:13:46.309: INFO: Node gke-conformance-default-pool-eca581b0-00fq is running more than one daemon pod
Mar  1 14:13:47.309: INFO: Number of nodes with available pods: 0
Mar  1 14:13:47.309: INFO: Node gke-conformance-default-pool-eca581b0-00fq is running more than one daemon pod
Mar  1 14:13:48.309: INFO: Number of nodes with available pods: 0
Mar  1 14:13:48.309: INFO: Node gke-conformance-default-pool-eca581b0-00fq is running more than one daemon pod
Mar  1 14:13:49.309: INFO: Number of nodes with available pods: 0
Mar  1 14:13:49.309: INFO: Node gke-conformance-default-pool-eca581b0-00fq is running more than one daemon pod
Mar  1 14:13:50.310: INFO: Number of nodes with available pods: 0
Mar  1 14:13:50.310: INFO: Node gke-conformance-default-pool-eca581b0-00fq is running more than one daemon pod
Mar  1 14:13:51.309: INFO: Number of nodes with available pods: 0
Mar  1 14:13:51.309: INFO: Node gke-conformance-default-pool-eca581b0-00fq is running more than one daemon pod
Mar  1 14:13:52.309: INFO: Number of nodes with available pods: 1
Mar  1 14:13:52.309: INFO: Number of running nodes: 1, number of available pods: 1
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:64
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting {extensions DaemonSet} daemon-set in namespace e2e-tests-daemonsets-2plsp, will wait for the garbage collector to delete the pods
Mar  1 14:13:52.374: INFO: Deleting {extensions DaemonSet} daemon-set took: 7.140793ms
Mar  1 14:13:52.474: INFO: Terminating {extensions DaemonSet} daemon-set pods took: 100.293208ms
Mar  1 14:14:30.486: INFO: Number of nodes with available pods: 0
Mar  1 14:14:30.486: INFO: Number of running nodes: 0, number of available pods: 0
Mar  1 14:14:30.494: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-2plsp/daemonsets","resourceVersion":"14205"},"items":null}

Mar  1 14:14:30.500: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-2plsp/pods","resourceVersion":"14206"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 14:14:30.546: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-2plsp" for this suite.
Mar  1 14:14:36.567: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 14:14:36.667: INFO: namespace: e2e-tests-daemonsets-2plsp, resource: bindings, ignored listing per whitelist
Mar  1 14:14:36.705: INFO: namespace e2e-tests-daemonsets-2plsp deletion completed in 6.152502409s

• [SLOW TEST:87.688 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[k8s.io] Probing container 
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 14:14:36.705: INFO: >>> kubeConfig: /tmp/kubeconfig-210205575
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Mar  1 14:15:00.851: INFO: Container started at 2019-03-01 14:14:38 +0000 UTC, pod became ready at 2019-03-01 14:15:00 +0000 UTC
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 14:15:00.851: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-8g795" for this suite.
Mar  1 14:15:22.867: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 14:15:22.914: INFO: namespace: e2e-tests-container-probe-8g795, resource: bindings, ignored listing per whitelist
Mar  1 14:15:23.063: INFO: namespace e2e-tests-container-probe-8g795 deletion completed in 22.207927367s

• [SLOW TEST:46.358 seconds]
[k8s.io] Probing container
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl logs 
  should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 14:15:23.063: INFO: >>> kubeConfig: /tmp/kubeconfig-210205575
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Kubectl logs
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1083
STEP: creating an rc
Mar  1 14:15:23.336: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-210205575 create -f - --namespace=e2e-tests-kubectl-dkj9m'
Mar  1 14:15:23.512: INFO: stderr: ""
Mar  1 14:15:23.512: INFO: stdout: "replicationcontroller/redis-master created\n"
[It] should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Waiting for Redis master to start.
Mar  1 14:15:24.516: INFO: Selector matched 1 pods for map[app:redis]
Mar  1 14:15:24.516: INFO: Found 0 / 1
Mar  1 14:15:25.516: INFO: Selector matched 1 pods for map[app:redis]
Mar  1 14:15:25.516: INFO: Found 1 / 1
Mar  1 14:15:25.516: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Mar  1 14:15:25.519: INFO: Selector matched 1 pods for map[app:redis]
Mar  1 14:15:25.519: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
STEP: checking for a matching strings
Mar  1 14:15:25.519: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-210205575 logs redis-master-rtln9 redis-master --namespace=e2e-tests-kubectl-dkj9m'
Mar  1 14:15:25.623: INFO: stderr: ""
Mar  1 14:15:25.623: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 01 Mar 14:15:24.561 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 01 Mar 14:15:24.561 # Server started, Redis version 3.2.12\n1:M 01 Mar 14:15:24.561 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 01 Mar 14:15:24.561 * The server is now ready to accept connections on port 6379\n"
STEP: limiting log lines
Mar  1 14:15:25.623: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-210205575 log redis-master-rtln9 redis-master --namespace=e2e-tests-kubectl-dkj9m --tail=1'
Mar  1 14:15:25.720: INFO: stderr: ""
Mar  1 14:15:25.720: INFO: stdout: "1:M 01 Mar 14:15:24.561 * The server is now ready to accept connections on port 6379\n"
STEP: limiting log bytes
Mar  1 14:15:25.720: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-210205575 log redis-master-rtln9 redis-master --namespace=e2e-tests-kubectl-dkj9m --limit-bytes=1'
Mar  1 14:15:25.816: INFO: stderr: ""
Mar  1 14:15:25.816: INFO: stdout: " "
STEP: exposing timestamps
Mar  1 14:15:25.816: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-210205575 log redis-master-rtln9 redis-master --namespace=e2e-tests-kubectl-dkj9m --tail=1 --timestamps'
Mar  1 14:15:25.917: INFO: stderr: ""
Mar  1 14:15:25.917: INFO: stdout: "2019-03-01T14:15:24.561379202Z 1:M 01 Mar 14:15:24.561 * The server is now ready to accept connections on port 6379\n"
STEP: restricting to a time range
Mar  1 14:15:28.417: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-210205575 log redis-master-rtln9 redis-master --namespace=e2e-tests-kubectl-dkj9m --since=1s'
Mar  1 14:15:28.516: INFO: stderr: ""
Mar  1 14:15:28.516: INFO: stdout: ""
Mar  1 14:15:28.516: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-210205575 log redis-master-rtln9 redis-master --namespace=e2e-tests-kubectl-dkj9m --since=24h'
Mar  1 14:15:28.618: INFO: stderr: ""
Mar  1 14:15:28.618: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 01 Mar 14:15:24.561 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 01 Mar 14:15:24.561 # Server started, Redis version 3.2.12\n1:M 01 Mar 14:15:24.561 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 01 Mar 14:15:24.561 * The server is now ready to accept connections on port 6379\n"
[AfterEach] [k8s.io] Kubectl logs
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1088
STEP: using delete to clean up resources
Mar  1 14:15:28.619: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-210205575 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-dkj9m'
Mar  1 14:15:28.729: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Mar  1 14:15:28.729: INFO: stdout: "replicationcontroller \"redis-master\" force deleted\n"
Mar  1 14:15:28.729: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-210205575 get rc,svc -l name=nginx --no-headers --namespace=e2e-tests-kubectl-dkj9m'
Mar  1 14:15:28.823: INFO: stderr: "No resources found.\n"
Mar  1 14:15:28.823: INFO: stdout: ""
Mar  1 14:15:28.823: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-210205575 get pods -l name=nginx --namespace=e2e-tests-kubectl-dkj9m -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Mar  1 14:15:28.907: INFO: stderr: ""
Mar  1 14:15:28.907: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 14:15:28.907: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-dkj9m" for this suite.
Mar  1 14:15:50.927: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 14:15:50.965: INFO: namespace: e2e-tests-kubectl-dkj9m, resource: bindings, ignored listing per whitelist
Mar  1 14:15:51.057: INFO: namespace e2e-tests-kubectl-dkj9m deletion completed in 22.145149758s

• [SLOW TEST:27.994 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl logs
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should be able to retrieve and filter logs  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 14:15:51.057: INFO: >>> kubeConfig: /tmp/kubeconfig-210205575
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-7hcpn
[It] should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a new StaefulSet
Mar  1 14:15:51.173: INFO: Found 0 stateful pods, waiting for 3
Mar  1 14:16:01.178: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Mar  1 14:16:01.178: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Mar  1 14:16:01.178: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Updating stateful set template: update image from docker.io/library/nginx:1.14-alpine to docker.io/library/nginx:1.15-alpine
Mar  1 14:16:01.215: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Not applying an update when the partition is greater than the number of replicas
STEP: Performing a canary update
Mar  1 14:16:11.255: INFO: Updating stateful set ss2
Mar  1 14:16:11.264: INFO: Waiting for Pod e2e-tests-statefulset-7hcpn/ss2-2 to have revision ss2-c79899b9 update revision ss2-787997d666
Mar  1 14:16:21.271: INFO: Waiting for Pod e2e-tests-statefulset-7hcpn/ss2-2 to have revision ss2-c79899b9 update revision ss2-787997d666
STEP: Restoring Pods to the correct revision when they are deleted
Mar  1 14:16:31.343: INFO: Found 1 stateful pods, waiting for 3
Mar  1 14:16:41.347: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Mar  1 14:16:41.347: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Mar  1 14:16:41.347: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Performing a phased rolling update
Mar  1 14:16:41.377: INFO: Updating stateful set ss2
Mar  1 14:16:41.407: INFO: Waiting for Pod e2e-tests-statefulset-7hcpn/ss2-1 to have revision ss2-c79899b9 update revision ss2-787997d666
Mar  1 14:16:51.436: INFO: Updating stateful set ss2
Mar  1 14:16:51.448: INFO: Waiting for StatefulSet e2e-tests-statefulset-7hcpn/ss2 to complete update
Mar  1 14:16:51.448: INFO: Waiting for Pod e2e-tests-statefulset-7hcpn/ss2-0 to have revision ss2-c79899b9 update revision ss2-787997d666
Mar  1 14:17:01.455: INFO: Waiting for StatefulSet e2e-tests-statefulset-7hcpn/ss2 to complete update
Mar  1 14:17:01.455: INFO: Waiting for Pod e2e-tests-statefulset-7hcpn/ss2-0 to have revision ss2-c79899b9 update revision ss2-787997d666
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Mar  1 14:17:11.467: INFO: Deleting all statefulset in ns e2e-tests-statefulset-7hcpn
Mar  1 14:17:11.474: INFO: Scaling statefulset ss2 to 0
Mar  1 14:17:41.510: INFO: Waiting for statefulset status.replicas updated to 0
Mar  1 14:17:41.513: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 14:17:41.534: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-7hcpn" for this suite.
Mar  1 14:17:47.557: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 14:17:47.613: INFO: namespace: e2e-tests-statefulset-7hcpn, resource: bindings, ignored listing per whitelist
Mar  1 14:17:47.694: INFO: namespace e2e-tests-statefulset-7hcpn deletion completed in 6.155699348s

• [SLOW TEST:116.637 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should perform canary updates and phased rolling updates of template modifications [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 14:17:47.695: INFO: >>> kubeConfig: /tmp/kubeconfig-210205575
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
Mar  1 14:17:47.793: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 14:17:50.600: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-init-container-fztg5" for this suite.
Mar  1 14:17:56.620: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 14:17:56.749: INFO: namespace: e2e-tests-init-container-fztg5, resource: bindings, ignored listing per whitelist
Mar  1 14:17:56.796: INFO: namespace e2e-tests-init-container-fztg5 deletion completed in 6.18684515s

• [SLOW TEST:9.101 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 14:17:56.796: INFO: >>> kubeConfig: /tmp/kubeconfig-210205575
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Mar  1 14:17:56.935: INFO: Waiting up to 5m0s for pod "downwardapi-volume-cf832e03-3c2c-11e9-a154-0a580a280202" in namespace "e2e-tests-downward-api-nvj8g" to be "success or failure"
Mar  1 14:17:56.940: INFO: Pod "downwardapi-volume-cf832e03-3c2c-11e9-a154-0a580a280202": Phase="Pending", Reason="", readiness=false. Elapsed: 5.174022ms
Mar  1 14:17:58.943: INFO: Pod "downwardapi-volume-cf832e03-3c2c-11e9-a154-0a580a280202": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008677484s
STEP: Saw pod success
Mar  1 14:17:58.944: INFO: Pod "downwardapi-volume-cf832e03-3c2c-11e9-a154-0a580a280202" satisfied condition "success or failure"
Mar  1 14:17:58.946: INFO: Trying to get logs from node gke-conformance-default-pool-eca581b0-sqmc pod downwardapi-volume-cf832e03-3c2c-11e9-a154-0a580a280202 container client-container: <nil>
STEP: delete the pod
Mar  1 14:17:58.970: INFO: Waiting for pod downwardapi-volume-cf832e03-3c2c-11e9-a154-0a580a280202 to disappear
Mar  1 14:17:58.982: INFO: Pod downwardapi-volume-cf832e03-3c2c-11e9-a154-0a580a280202 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 14:17:58.982: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-nvj8g" for this suite.
Mar  1 14:18:09.001: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 14:18:09.135: INFO: namespace: e2e-tests-downward-api-nvj8g, resource: bindings, ignored listing per whitelist
Mar  1 14:18:09.233: INFO: namespace e2e-tests-downward-api-nvj8g deletion completed in 10.244487514s

• [SLOW TEST:12.438 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on tmpfs should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 14:18:09.234: INFO: >>> kubeConfig: /tmp/kubeconfig-210205575
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on tmpfs should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir volume type on tmpfs
Mar  1 14:18:09.349: INFO: Waiting up to 5m0s for pod "pod-d6ea03e4-3c2c-11e9-a154-0a580a280202" in namespace "e2e-tests-emptydir-mq8wx" to be "success or failure"
Mar  1 14:18:09.353: INFO: Pod "pod-d6ea03e4-3c2c-11e9-a154-0a580a280202": Phase="Pending", Reason="", readiness=false. Elapsed: 3.613277ms
Mar  1 14:18:11.356: INFO: Pod "pod-d6ea03e4-3c2c-11e9-a154-0a580a280202": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007070945s
STEP: Saw pod success
Mar  1 14:18:11.356: INFO: Pod "pod-d6ea03e4-3c2c-11e9-a154-0a580a280202" satisfied condition "success or failure"
Mar  1 14:18:11.360: INFO: Trying to get logs from node gke-conformance-default-pool-eca581b0-sqmc pod pod-d6ea03e4-3c2c-11e9-a154-0a580a280202 container test-container: <nil>
STEP: delete the pod
Mar  1 14:18:11.385: INFO: Waiting for pod pod-d6ea03e4-3c2c-11e9-a154-0a580a280202 to disappear
Mar  1 14:18:11.390: INFO: Pod pod-d6ea03e4-3c2c-11e9-a154-0a580a280202 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 14:18:11.390: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-mq8wx" for this suite.
Mar  1 14:18:17.408: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 14:18:17.474: INFO: namespace: e2e-tests-emptydir-mq8wx, resource: bindings, ignored listing per whitelist
Mar  1 14:18:17.539: INFO: namespace e2e-tests-emptydir-mq8wx deletion completed in 6.144310298s

• [SLOW TEST:8.305 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  volume on tmpfs should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 14:18:17.539: INFO: >>> kubeConfig: /tmp/kubeconfig-210205575
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with configMap that has name projected-configmap-test-upd-dbdadbf5-3c2c-11e9-a154-0a580a280202
STEP: Creating the pod
STEP: Updating configmap projected-configmap-test-upd-dbdadbf5-3c2c-11e9-a154-0a580a280202
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 14:19:28.260: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-4x7g5" for this suite.
Mar  1 14:19:50.276: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 14:19:50.329: INFO: namespace: e2e-tests-projected-4x7g5, resource: bindings, ignored listing per whitelist
Mar  1 14:19:50.416: INFO: namespace e2e-tests-projected-4x7g5 deletion completed in 22.152009683s

• [SLOW TEST:92.877 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run rc 
  should create an rc from an image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 14:19:50.416: INFO: >>> kubeConfig: /tmp/kubeconfig-210205575
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Kubectl run rc
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1246
[It] should create an rc from an image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Mar  1 14:19:50.522: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-210205575 run e2e-test-nginx-rc --image=docker.io/library/nginx:1.14-alpine --generator=run/v1 --namespace=e2e-tests-kubectl-wgn5k'
Mar  1 14:19:50.624: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl create instead.\n"
Mar  1 14:19:50.624: INFO: stdout: "replicationcontroller/e2e-test-nginx-rc created\n"
STEP: verifying the rc e2e-test-nginx-rc was created
STEP: verifying the pod controlled by rc e2e-test-nginx-rc was created
STEP: confirm that you can get logs from an rc
Mar  1 14:19:50.646: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [e2e-test-nginx-rc-vtctr]
Mar  1 14:19:50.646: INFO: Waiting up to 5m0s for pod "e2e-test-nginx-rc-vtctr" in namespace "e2e-tests-kubectl-wgn5k" to be "running and ready"
Mar  1 14:19:50.670: INFO: Pod "e2e-test-nginx-rc-vtctr": Phase="Pending", Reason="", readiness=false. Elapsed: 23.575889ms
Mar  1 14:19:52.673: INFO: Pod "e2e-test-nginx-rc-vtctr": Phase="Pending", Reason="", readiness=false. Elapsed: 2.027421843s
Mar  1 14:19:54.677: INFO: Pod "e2e-test-nginx-rc-vtctr": Phase="Running", Reason="", readiness=true. Elapsed: 4.031293286s
Mar  1 14:19:54.677: INFO: Pod "e2e-test-nginx-rc-vtctr" satisfied condition "running and ready"
Mar  1 14:19:54.677: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [e2e-test-nginx-rc-vtctr]
Mar  1 14:19:54.678: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-210205575 logs rc/e2e-test-nginx-rc --namespace=e2e-tests-kubectl-wgn5k'
Mar  1 14:19:54.803: INFO: stderr: ""
Mar  1 14:19:54.803: INFO: stdout: ""
[AfterEach] [k8s.io] Kubectl run rc
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1251
Mar  1 14:19:54.803: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-210205575 delete rc e2e-test-nginx-rc --namespace=e2e-tests-kubectl-wgn5k'
Mar  1 14:19:54.901: INFO: stderr: ""
Mar  1 14:19:54.901: INFO: stdout: "replicationcontroller \"e2e-test-nginx-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 14:19:54.901: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-wgn5k" for this suite.
Mar  1 14:20:00.925: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 14:20:00.975: INFO: namespace: e2e-tests-kubectl-wgn5k, resource: bindings, ignored listing per whitelist
Mar  1 14:20:01.067: INFO: namespace e2e-tests-kubectl-wgn5k deletion completed in 6.158922131s

• [SLOW TEST:10.651 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run rc
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create an rc from an image  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 14:20:01.067: INFO: >>> kubeConfig: /tmp/kubeconfig-210205575
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-kg4zd
[It] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Initializing watcher for selector baz=blah,foo=bar
STEP: Creating stateful set ss in namespace e2e-tests-statefulset-kg4zd
STEP: Waiting until all stateful set ss replicas will be running in namespace e2e-tests-statefulset-kg4zd
Mar  1 14:20:01.228: INFO: Found 0 stateful pods, waiting for 1
Mar  1 14:20:11.232: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will halt with unhealthy stateful pod
Mar  1 14:20:11.235: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-210205575 exec --namespace=e2e-tests-statefulset-kg4zd ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Mar  1 14:20:11.397: INFO: stderr: ""
Mar  1 14:20:11.397: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Mar  1 14:20:11.397: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Mar  1 14:20:11.400: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Mar  1 14:20:21.404: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Mar  1 14:20:21.404: INFO: Waiting for statefulset status.replicas updated to 0
Mar  1 14:20:21.426: INFO: Verifying statefulset ss doesn't scale past 1 for another 9.999999431s
Mar  1 14:20:22.430: INFO: Verifying statefulset ss doesn't scale past 1 for another 8.992331755s
Mar  1 14:20:23.434: INFO: Verifying statefulset ss doesn't scale past 1 for another 7.988001845s
Mar  1 14:20:24.438: INFO: Verifying statefulset ss doesn't scale past 1 for another 6.983927935s
Mar  1 14:20:25.443: INFO: Verifying statefulset ss doesn't scale past 1 for another 5.979717791s
Mar  1 14:20:26.454: INFO: Verifying statefulset ss doesn't scale past 1 for another 4.974733003s
Mar  1 14:20:27.457: INFO: Verifying statefulset ss doesn't scale past 1 for another 3.964455726s
Mar  1 14:20:28.461: INFO: Verifying statefulset ss doesn't scale past 1 for another 2.960791432s
Mar  1 14:20:29.465: INFO: Verifying statefulset ss doesn't scale past 1 for another 1.956708493s
Mar  1 14:20:30.469: INFO: Verifying statefulset ss doesn't scale past 1 for another 952.642335ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace e2e-tests-statefulset-kg4zd
Mar  1 14:20:31.473: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-210205575 exec --namespace=e2e-tests-statefulset-kg4zd ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar  1 14:20:31.629: INFO: stderr: ""
Mar  1 14:20:31.629: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Mar  1 14:20:31.629: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Mar  1 14:20:31.632: INFO: Found 1 stateful pods, waiting for 3
Mar  1 14:20:41.637: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Mar  1 14:20:41.637: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Mar  1 14:20:41.637: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Verifying that stateful set ss was scaled up in order
STEP: Scale down will halt with unhealthy stateful pod
Mar  1 14:20:41.643: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-210205575 exec --namespace=e2e-tests-statefulset-kg4zd ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Mar  1 14:20:41.810: INFO: stderr: ""
Mar  1 14:20:41.810: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Mar  1 14:20:41.810: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Mar  1 14:20:41.810: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-210205575 exec --namespace=e2e-tests-statefulset-kg4zd ss-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Mar  1 14:20:41.974: INFO: stderr: ""
Mar  1 14:20:41.974: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Mar  1 14:20:41.974: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Mar  1 14:20:41.974: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-210205575 exec --namespace=e2e-tests-statefulset-kg4zd ss-2 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Mar  1 14:20:42.157: INFO: stderr: ""
Mar  1 14:20:42.157: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Mar  1 14:20:42.157: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-2: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Mar  1 14:20:42.157: INFO: Waiting for statefulset status.replicas updated to 0
Mar  1 14:20:42.163: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 2
Mar  1 14:20:52.171: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Mar  1 14:20:52.171: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Mar  1 14:20:52.171: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Mar  1 14:20:52.187: INFO: Verifying statefulset ss doesn't scale past 3 for another 9.999999558s
Mar  1 14:20:53.191: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.992348164s
Mar  1 14:20:54.195: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.98835041s
Mar  1 14:20:55.203: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.984187239s
Mar  1 14:20:56.208: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.976238493s
Mar  1 14:20:57.212: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.972068915s
Mar  1 14:20:58.216: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.967784146s
Mar  1 14:20:59.221: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.963700086s
Mar  1 14:21:00.225: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.958849206s
Mar  1 14:21:01.229: INFO: Verifying statefulset ss doesn't scale past 3 for another 954.980107ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacee2e-tests-statefulset-kg4zd
Mar  1 14:21:02.233: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-210205575 exec --namespace=e2e-tests-statefulset-kg4zd ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar  1 14:21:02.387: INFO: stderr: ""
Mar  1 14:21:02.387: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Mar  1 14:21:02.387: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Mar  1 14:21:02.387: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-210205575 exec --namespace=e2e-tests-statefulset-kg4zd ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar  1 14:21:02.544: INFO: stderr: ""
Mar  1 14:21:02.544: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Mar  1 14:21:02.544: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Mar  1 14:21:02.544: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-210205575 exec --namespace=e2e-tests-statefulset-kg4zd ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar  1 14:21:02.700: INFO: stderr: ""
Mar  1 14:21:02.700: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Mar  1 14:21:02.700: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-2: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Mar  1 14:21:02.700: INFO: Scaling statefulset ss to 0
STEP: Verifying that stateful set ss was scaled down in reverse order
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Mar  1 14:21:22.717: INFO: Deleting all statefulset in ns e2e-tests-statefulset-kg4zd
Mar  1 14:21:22.720: INFO: Scaling statefulset ss to 0
Mar  1 14:21:22.729: INFO: Waiting for statefulset status.replicas updated to 0
Mar  1 14:21:22.731: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 14:21:22.746: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-kg4zd" for this suite.
Mar  1 14:21:28.765: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 14:21:28.810: INFO: namespace: e2e-tests-statefulset-kg4zd, resource: bindings, ignored listing per whitelist
Mar  1 14:21:28.923: INFO: namespace e2e-tests-statefulset-kg4zd deletion completed in 6.1704594s

• [SLOW TEST:87.855 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 14:21:28.923: INFO: >>> kubeConfig: /tmp/kubeconfig-210205575
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-dg765
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Mar  1 14:21:29.042: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Mar  1 14:21:55.295: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.40.4.91:8080/dial?request=hostName&protocol=udp&host=10.40.2.28&port=8081&tries=1'] Namespace:e2e-tests-pod-network-test-dg765 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar  1 14:21:55.295: INFO: >>> kubeConfig: /tmp/kubeconfig-210205575
Mar  1 14:21:55.376: INFO: Waiting for endpoints: map[]
Mar  1 14:21:55.380: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.40.4.91:8080/dial?request=hostName&protocol=udp&host=10.40.3.76&port=8081&tries=1'] Namespace:e2e-tests-pod-network-test-dg765 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar  1 14:21:55.380: INFO: >>> kubeConfig: /tmp/kubeconfig-210205575
Mar  1 14:21:55.454: INFO: Waiting for endpoints: map[]
Mar  1 14:21:55.458: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.40.4.91:8080/dial?request=hostName&protocol=udp&host=10.40.1.72&port=8081&tries=1'] Namespace:e2e-tests-pod-network-test-dg765 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar  1 14:21:55.458: INFO: >>> kubeConfig: /tmp/kubeconfig-210205575
Mar  1 14:21:55.543: INFO: Waiting for endpoints: map[]
Mar  1 14:21:55.549: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.40.4.91:8080/dial?request=hostName&protocol=udp&host=10.40.0.22&port=8081&tries=1'] Namespace:e2e-tests-pod-network-test-dg765 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar  1 14:21:55.549: INFO: >>> kubeConfig: /tmp/kubeconfig-210205575
Mar  1 14:21:55.972: INFO: Waiting for endpoints: map[]
Mar  1 14:21:55.976: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.40.4.91:8080/dial?request=hostName&protocol=udp&host=10.40.4.90&port=8081&tries=1'] Namespace:e2e-tests-pod-network-test-dg765 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar  1 14:21:55.976: INFO: >>> kubeConfig: /tmp/kubeconfig-210205575
Mar  1 14:21:56.052: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 14:21:56.052: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-dg765" for this suite.
Mar  1 14:22:18.070: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 14:22:18.191: INFO: namespace: e2e-tests-pod-network-test-dg765, resource: bindings, ignored listing per whitelist
Mar  1 14:22:18.200: INFO: namespace e2e-tests-pod-network-test-dg765 deletion completed in 22.142815812s

• [SLOW TEST:49.277 seconds]
[sig-network] Networking
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: udp [NodeConformance] [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Downward API 
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 14:22:18.200: INFO: >>> kubeConfig: /tmp/kubeconfig-210205575
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Mar  1 14:22:18.314: INFO: Waiting up to 5m0s for pod "downward-api-6b4e2a0f-3c2d-11e9-a154-0a580a280202" in namespace "e2e-tests-downward-api-d2xn8" to be "success or failure"
Mar  1 14:22:18.331: INFO: Pod "downward-api-6b4e2a0f-3c2d-11e9-a154-0a580a280202": Phase="Pending", Reason="", readiness=false. Elapsed: 17.791878ms
Mar  1 14:22:20.335: INFO: Pod "downward-api-6b4e2a0f-3c2d-11e9-a154-0a580a280202": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.021452042s
STEP: Saw pod success
Mar  1 14:22:20.335: INFO: Pod "downward-api-6b4e2a0f-3c2d-11e9-a154-0a580a280202" satisfied condition "success or failure"
Mar  1 14:22:20.338: INFO: Trying to get logs from node gke-conformance-default-pool-eca581b0-czl4 pod downward-api-6b4e2a0f-3c2d-11e9-a154-0a580a280202 container dapi-container: <nil>
STEP: delete the pod
Mar  1 14:22:20.365: INFO: Waiting for pod downward-api-6b4e2a0f-3c2d-11e9-a154-0a580a280202 to disappear
Mar  1 14:22:20.373: INFO: Pod downward-api-6b4e2a0f-3c2d-11e9-a154-0a580a280202 no longer exists
[AfterEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 14:22:20.373: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-d2xn8" for this suite.
Mar  1 14:22:26.393: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 14:22:26.495: INFO: namespace: e2e-tests-downward-api-d2xn8, resource: bindings, ignored listing per whitelist
Mar  1 14:22:26.519: INFO: namespace e2e-tests-downward-api-d2xn8 deletion completed in 6.142785953s

• [SLOW TEST:8.319 seconds]
[sig-api-machinery] Downward API
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 14:22:26.519: INFO: >>> kubeConfig: /tmp/kubeconfig-210205575
STEP: Building a namespace api object, basename namespaces
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a test namespace
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a pod in the namespace
STEP: Waiting for the pod to have running status
STEP: Creating an uninitialized pod in the namespace
Mar  1 14:22:30.686: INFO: error from create uninitialized namespace: <nil>
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Verifying there are no pods in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 14:22:54.729: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-namespaces-wnvsp" for this suite.
Mar  1 14:23:00.752: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 14:23:00.951: INFO: namespace: e2e-tests-namespaces-wnvsp, resource: bindings, ignored listing per whitelist
Mar  1 14:23:00.953: INFO: namespace e2e-tests-namespaces-wnvsp deletion completed in 6.219722917s
STEP: Destroying namespace "e2e-tests-nsdeletetest-7h7nn" for this suite.
Mar  1 14:23:00.956: INFO: Namespace e2e-tests-nsdeletetest-7h7nn was already deleted
STEP: Destroying namespace "e2e-tests-nsdeletetest-dshpj" for this suite.
Mar  1 14:23:08.968: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 14:23:09.018: INFO: namespace: e2e-tests-nsdeletetest-dshpj, resource: bindings, ignored listing per whitelist
Mar  1 14:23:09.085: INFO: namespace e2e-tests-nsdeletetest-dshpj deletion completed in 8.128970982s

• [SLOW TEST:42.566 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 14:23:09.085: INFO: >>> kubeConfig: /tmp/kubeconfig-210205575
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-89a2552f-3c2d-11e9-a154-0a580a280202
STEP: Creating a pod to test consume configMaps
Mar  1 14:23:09.195: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-89a2dee0-3c2d-11e9-a154-0a580a280202" in namespace "e2e-tests-projected-wr7p4" to be "success or failure"
Mar  1 14:23:09.201: INFO: Pod "pod-projected-configmaps-89a2dee0-3c2d-11e9-a154-0a580a280202": Phase="Pending", Reason="", readiness=false. Elapsed: 5.896176ms
Mar  1 14:23:11.205: INFO: Pod "pod-projected-configmaps-89a2dee0-3c2d-11e9-a154-0a580a280202": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009798157s
STEP: Saw pod success
Mar  1 14:23:11.205: INFO: Pod "pod-projected-configmaps-89a2dee0-3c2d-11e9-a154-0a580a280202" satisfied condition "success or failure"
Mar  1 14:23:11.213: INFO: Trying to get logs from node gke-conformance-default-pool-eca581b0-sww9 pod pod-projected-configmaps-89a2dee0-3c2d-11e9-a154-0a580a280202 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Mar  1 14:23:11.242: INFO: Waiting for pod pod-projected-configmaps-89a2dee0-3c2d-11e9-a154-0a580a280202 to disappear
Mar  1 14:23:11.246: INFO: Pod pod-projected-configmaps-89a2dee0-3c2d-11e9-a154-0a580a280202 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 14:23:11.246: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-wr7p4" for this suite.
Mar  1 14:23:17.263: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 14:23:17.296: INFO: namespace: e2e-tests-projected-wr7p4, resource: bindings, ignored listing per whitelist
Mar  1 14:23:17.402: INFO: namespace e2e-tests-projected-wr7p4 deletion completed in 6.15229954s

• [SLOW TEST:8.317 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 14:23:17.402: INFO: >>> kubeConfig: /tmp/kubeconfig-210205575
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-8ea17a9e-3c2d-11e9-a154-0a580a280202
STEP: Creating a pod to test consume configMaps
Mar  1 14:23:17.589: INFO: Waiting up to 5m0s for pod "pod-configmaps-8ea26f37-3c2d-11e9-a154-0a580a280202" in namespace "e2e-tests-configmap-9c5ws" to be "success or failure"
Mar  1 14:23:17.599: INFO: Pod "pod-configmaps-8ea26f37-3c2d-11e9-a154-0a580a280202": Phase="Pending", Reason="", readiness=false. Elapsed: 9.717569ms
Mar  1 14:23:19.608: INFO: Pod "pod-configmaps-8ea26f37-3c2d-11e9-a154-0a580a280202": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.018687461s
STEP: Saw pod success
Mar  1 14:23:19.608: INFO: Pod "pod-configmaps-8ea26f37-3c2d-11e9-a154-0a580a280202" satisfied condition "success or failure"
Mar  1 14:23:19.612: INFO: Trying to get logs from node gke-conformance-default-pool-eca581b0-sqmc pod pod-configmaps-8ea26f37-3c2d-11e9-a154-0a580a280202 container configmap-volume-test: <nil>
STEP: delete the pod
Mar  1 14:23:19.642: INFO: Waiting for pod pod-configmaps-8ea26f37-3c2d-11e9-a154-0a580a280202 to disappear
Mar  1 14:23:19.646: INFO: Pod pod-configmaps-8ea26f37-3c2d-11e9-a154-0a580a280202 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 14:23:19.646: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-9c5ws" for this suite.
Mar  1 14:23:25.670: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 14:23:25.755: INFO: namespace: e2e-tests-configmap-9c5ws, resource: bindings, ignored listing per whitelist
Mar  1 14:23:25.804: INFO: namespace e2e-tests-configmap-9c5ws deletion completed in 6.152748562s

• [SLOW TEST:8.401 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 14:23:25.804: INFO: >>> kubeConfig: /tmp/kubeconfig-210205575
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-bjjrj
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Mar  1 14:23:25.908: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Mar  1 14:23:50.117: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.40.3.81:8080/dial?request=hostName&protocol=http&host=10.40.4.95&port=8080&tries=1'] Namespace:e2e-tests-pod-network-test-bjjrj PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar  1 14:23:50.117: INFO: >>> kubeConfig: /tmp/kubeconfig-210205575
Mar  1 14:23:50.195: INFO: Waiting for endpoints: map[]
Mar  1 14:23:50.199: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.40.3.81:8080/dial?request=hostName&protocol=http&host=10.40.0.23&port=8080&tries=1'] Namespace:e2e-tests-pod-network-test-bjjrj PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar  1 14:23:50.199: INFO: >>> kubeConfig: /tmp/kubeconfig-210205575
Mar  1 14:23:50.276: INFO: Waiting for endpoints: map[]
Mar  1 14:23:50.281: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.40.3.81:8080/dial?request=hostName&protocol=http&host=10.40.1.74&port=8080&tries=1'] Namespace:e2e-tests-pod-network-test-bjjrj PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar  1 14:23:50.281: INFO: >>> kubeConfig: /tmp/kubeconfig-210205575
Mar  1 14:23:50.360: INFO: Waiting for endpoints: map[]
Mar  1 14:23:50.367: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.40.3.81:8080/dial?request=hostName&protocol=http&host=10.40.2.29&port=8080&tries=1'] Namespace:e2e-tests-pod-network-test-bjjrj PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar  1 14:23:50.367: INFO: >>> kubeConfig: /tmp/kubeconfig-210205575
Mar  1 14:23:50.465: INFO: Waiting for endpoints: map[]
Mar  1 14:23:50.468: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.40.3.81:8080/dial?request=hostName&protocol=http&host=10.40.3.80&port=8080&tries=1'] Namespace:e2e-tests-pod-network-test-bjjrj PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar  1 14:23:50.468: INFO: >>> kubeConfig: /tmp/kubeconfig-210205575
Mar  1 14:23:50.544: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 14:23:50.544: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-bjjrj" for this suite.
Mar  1 14:24:12.564: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 14:24:12.603: INFO: namespace: e2e-tests-pod-network-test-bjjrj, resource: bindings, ignored listing per whitelist
Mar  1 14:24:12.705: INFO: namespace e2e-tests-pod-network-test-bjjrj deletion completed in 22.156080409s

• [SLOW TEST:46.902 seconds]
[sig-network] Networking
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: http [NodeConformance] [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with secret pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 14:24:12.705: INFO: >>> kubeConfig: /tmp/kubeconfig-210205575
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with secret pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-secret-svxz
STEP: Creating a pod to test atomic-volume-subpath
Mar  1 14:24:12.849: INFO: Waiting up to 5m0s for pod "pod-subpath-test-secret-svxz" in namespace "e2e-tests-subpath-8frb2" to be "success or failure"
Mar  1 14:24:12.858: INFO: Pod "pod-subpath-test-secret-svxz": Phase="Pending", Reason="", readiness=false. Elapsed: 8.735621ms
Mar  1 14:24:14.947: INFO: Pod "pod-subpath-test-secret-svxz": Phase="Pending", Reason="", readiness=false. Elapsed: 2.098389562s
Mar  1 14:24:16.951: INFO: Pod "pod-subpath-test-secret-svxz": Phase="Running", Reason="", readiness=false. Elapsed: 4.102033568s
Mar  1 14:24:18.954: INFO: Pod "pod-subpath-test-secret-svxz": Phase="Running", Reason="", readiness=false. Elapsed: 6.105591778s
Mar  1 14:24:20.958: INFO: Pod "pod-subpath-test-secret-svxz": Phase="Running", Reason="", readiness=false. Elapsed: 8.109520299s
Mar  1 14:24:22.962: INFO: Pod "pod-subpath-test-secret-svxz": Phase="Running", Reason="", readiness=false. Elapsed: 10.113285976s
Mar  1 14:24:24.966: INFO: Pod "pod-subpath-test-secret-svxz": Phase="Running", Reason="", readiness=false. Elapsed: 12.117143003s
Mar  1 14:24:26.969: INFO: Pod "pod-subpath-test-secret-svxz": Phase="Running", Reason="", readiness=false. Elapsed: 14.120328337s
Mar  1 14:24:28.973: INFO: Pod "pod-subpath-test-secret-svxz": Phase="Running", Reason="", readiness=false. Elapsed: 16.124124722s
Mar  1 14:24:30.976: INFO: Pod "pod-subpath-test-secret-svxz": Phase="Running", Reason="", readiness=false. Elapsed: 18.127629954s
Mar  1 14:24:32.980: INFO: Pod "pod-subpath-test-secret-svxz": Phase="Running", Reason="", readiness=false. Elapsed: 20.131296784s
Mar  1 14:24:34.986: INFO: Pod "pod-subpath-test-secret-svxz": Phase="Running", Reason="", readiness=false. Elapsed: 22.136936693s
Mar  1 14:24:36.990: INFO: Pod "pod-subpath-test-secret-svxz": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.140967439s
STEP: Saw pod success
Mar  1 14:24:36.990: INFO: Pod "pod-subpath-test-secret-svxz" satisfied condition "success or failure"
Mar  1 14:24:36.993: INFO: Trying to get logs from node gke-conformance-default-pool-eca581b0-sqmc pod pod-subpath-test-secret-svxz container test-container-subpath-secret-svxz: <nil>
STEP: delete the pod
Mar  1 14:24:37.024: INFO: Waiting for pod pod-subpath-test-secret-svxz to disappear
Mar  1 14:24:37.028: INFO: Pod pod-subpath-test-secret-svxz no longer exists
STEP: Deleting pod pod-subpath-test-secret-svxz
Mar  1 14:24:37.028: INFO: Deleting pod "pod-subpath-test-secret-svxz" in namespace "e2e-tests-subpath-8frb2"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 14:24:37.031: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-8frb2" for this suite.
Mar  1 14:24:43.049: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 14:24:43.160: INFO: namespace: e2e-tests-subpath-8frb2, resource: bindings, ignored listing per whitelist
Mar  1 14:24:43.160: INFO: namespace e2e-tests-subpath-8frb2 deletion completed in 6.122682338s

• [SLOW TEST:30.454 seconds]
[sig-storage] Subpath
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with secret pod [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 14:24:43.160: INFO: >>> kubeConfig: /tmp/kubeconfig-210205575
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test env composition
Mar  1 14:24:43.259: INFO: Waiting up to 5m0s for pod "var-expansion-c1b40d23-3c2d-11e9-a154-0a580a280202" in namespace "e2e-tests-var-expansion-4tb4s" to be "success or failure"
Mar  1 14:24:43.270: INFO: Pod "var-expansion-c1b40d23-3c2d-11e9-a154-0a580a280202": Phase="Pending", Reason="", readiness=false. Elapsed: 11.252025ms
Mar  1 14:24:45.275: INFO: Pod "var-expansion-c1b40d23-3c2d-11e9-a154-0a580a280202": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.01621466s
STEP: Saw pod success
Mar  1 14:24:45.275: INFO: Pod "var-expansion-c1b40d23-3c2d-11e9-a154-0a580a280202" satisfied condition "success or failure"
Mar  1 14:24:45.278: INFO: Trying to get logs from node gke-conformance-default-pool-eca581b0-czl4 pod var-expansion-c1b40d23-3c2d-11e9-a154-0a580a280202 container dapi-container: <nil>
STEP: delete the pod
Mar  1 14:24:45.300: INFO: Waiting for pod var-expansion-c1b40d23-3c2d-11e9-a154-0a580a280202 to disappear
Mar  1 14:24:45.306: INFO: Pod var-expansion-c1b40d23-3c2d-11e9-a154-0a580a280202 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 14:24:45.306: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-var-expansion-4tb4s" for this suite.
Mar  1 14:24:51.323: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 14:24:51.365: INFO: namespace: e2e-tests-var-expansion-4tb4s, resource: bindings, ignored listing per whitelist
Mar  1 14:24:51.507: INFO: namespace e2e-tests-var-expansion-4tb4s deletion completed in 6.195476201s

• [SLOW TEST:8.347 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-auth] ServiceAccounts 
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 14:24:51.507: INFO: >>> kubeConfig: /tmp/kubeconfig-210205575
STEP: Building a namespace api object, basename svcaccounts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: getting the auto-created API token
Mar  1 14:24:52.196: INFO: created pod pod-service-account-defaultsa
Mar  1 14:24:52.196: INFO: pod pod-service-account-defaultsa service account token volume mount: true
Mar  1 14:24:52.224: INFO: created pod pod-service-account-mountsa
Mar  1 14:24:52.224: INFO: pod pod-service-account-mountsa service account token volume mount: true
Mar  1 14:24:52.242: INFO: created pod pod-service-account-nomountsa
Mar  1 14:24:52.242: INFO: pod pod-service-account-nomountsa service account token volume mount: false
Mar  1 14:24:52.262: INFO: created pod pod-service-account-defaultsa-mountspec
Mar  1 14:24:52.262: INFO: pod pod-service-account-defaultsa-mountspec service account token volume mount: true
Mar  1 14:24:52.288: INFO: created pod pod-service-account-mountsa-mountspec
Mar  1 14:24:52.288: INFO: pod pod-service-account-mountsa-mountspec service account token volume mount: true
Mar  1 14:24:52.331: INFO: created pod pod-service-account-nomountsa-mountspec
Mar  1 14:24:52.331: INFO: pod pod-service-account-nomountsa-mountspec service account token volume mount: true
Mar  1 14:24:52.356: INFO: created pod pod-service-account-defaultsa-nomountspec
Mar  1 14:24:52.356: INFO: pod pod-service-account-defaultsa-nomountspec service account token volume mount: false
Mar  1 14:24:52.386: INFO: created pod pod-service-account-mountsa-nomountspec
Mar  1 14:24:52.386: INFO: pod pod-service-account-mountsa-nomountspec service account token volume mount: false
Mar  1 14:24:52.422: INFO: created pod pod-service-account-nomountsa-nomountspec
Mar  1 14:24:52.422: INFO: pod pod-service-account-nomountsa-nomountspec service account token volume mount: false
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 14:24:52.422: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-svcaccounts-nbb9s" for this suite.
Mar  1 14:25:14.453: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 14:25:14.648: INFO: namespace: e2e-tests-svcaccounts-nbb9s, resource: bindings, ignored listing per whitelist
Mar  1 14:25:14.700: INFO: namespace e2e-tests-svcaccounts-nbb9s deletion completed in 22.272835747s

• [SLOW TEST:23.194 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:22
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 14:25:14.700: INFO: >>> kubeConfig: /tmp/kubeconfig-210205575
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-map-d483b61e-3c2d-11e9-a154-0a580a280202
STEP: Creating a pod to test consume configMaps
Mar  1 14:25:14.835: INFO: Waiting up to 5m0s for pod "pod-configmaps-d484a1f0-3c2d-11e9-a154-0a580a280202" in namespace "e2e-tests-configmap-cbv98" to be "success or failure"
Mar  1 14:25:14.860: INFO: Pod "pod-configmaps-d484a1f0-3c2d-11e9-a154-0a580a280202": Phase="Pending", Reason="", readiness=false. Elapsed: 24.458083ms
Mar  1 14:25:16.864: INFO: Pod "pod-configmaps-d484a1f0-3c2d-11e9-a154-0a580a280202": Phase="Running", Reason="", readiness=true. Elapsed: 2.02875221s
Mar  1 14:25:18.867: INFO: Pod "pod-configmaps-d484a1f0-3c2d-11e9-a154-0a580a280202": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.032268055s
STEP: Saw pod success
Mar  1 14:25:18.868: INFO: Pod "pod-configmaps-d484a1f0-3c2d-11e9-a154-0a580a280202" satisfied condition "success or failure"
Mar  1 14:25:18.870: INFO: Trying to get logs from node gke-conformance-default-pool-eca581b0-sqmc pod pod-configmaps-d484a1f0-3c2d-11e9-a154-0a580a280202 container configmap-volume-test: <nil>
STEP: delete the pod
Mar  1 14:25:18.894: INFO: Waiting for pod pod-configmaps-d484a1f0-3c2d-11e9-a154-0a580a280202 to disappear
Mar  1 14:25:18.898: INFO: Pod pod-configmaps-d484a1f0-3c2d-11e9-a154-0a580a280202 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 14:25:18.898: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-cbv98" for this suite.
Mar  1 14:25:24.915: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 14:25:24.963: INFO: namespace: e2e-tests-configmap-cbv98, resource: bindings, ignored listing per whitelist
Mar  1 14:25:25.069: INFO: namespace e2e-tests-configmap-cbv98 deletion completed in 6.165308793s

• [SLOW TEST:10.369 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-api-machinery] Downward API 
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 14:25:25.069: INFO: >>> kubeConfig: /tmp/kubeconfig-210205575
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Mar  1 14:25:25.198: INFO: Waiting up to 5m0s for pod "downward-api-dab260aa-3c2d-11e9-a154-0a580a280202" in namespace "e2e-tests-downward-api-ds2mr" to be "success or failure"
Mar  1 14:25:25.208: INFO: Pod "downward-api-dab260aa-3c2d-11e9-a154-0a580a280202": Phase="Pending", Reason="", readiness=false. Elapsed: 9.946511ms
Mar  1 14:25:27.212: INFO: Pod "downward-api-dab260aa-3c2d-11e9-a154-0a580a280202": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013656384s
Mar  1 14:25:29.215: INFO: Pod "downward-api-dab260aa-3c2d-11e9-a154-0a580a280202": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.016802814s
STEP: Saw pod success
Mar  1 14:25:29.215: INFO: Pod "downward-api-dab260aa-3c2d-11e9-a154-0a580a280202" satisfied condition "success or failure"
Mar  1 14:25:29.218: INFO: Trying to get logs from node gke-conformance-default-pool-eca581b0-czl4 pod downward-api-dab260aa-3c2d-11e9-a154-0a580a280202 container dapi-container: <nil>
STEP: delete the pod
Mar  1 14:25:29.241: INFO: Waiting for pod downward-api-dab260aa-3c2d-11e9-a154-0a580a280202 to disappear
Mar  1 14:25:29.244: INFO: Pod downward-api-dab260aa-3c2d-11e9-a154-0a580a280202 no longer exists
[AfterEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 14:25:29.244: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-ds2mr" for this suite.
Mar  1 14:25:35.258: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 14:25:35.369: INFO: namespace: e2e-tests-downward-api-ds2mr, resource: bindings, ignored listing per whitelist
Mar  1 14:25:35.397: INFO: namespace e2e-tests-downward-api-ds2mr deletion completed in 6.1488012s

• [SLOW TEST:10.327 seconds]
[sig-api-machinery] Downward API
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 14:25:35.397: INFO: >>> kubeConfig: /tmp/kubeconfig-210205575
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-e0e2af6d-3c2d-11e9-a154-0a580a280202
STEP: Creating a pod to test consume secrets
Mar  1 14:25:35.596: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-e0e3aa90-3c2d-11e9-a154-0a580a280202" in namespace "e2e-tests-projected-wsjp4" to be "success or failure"
Mar  1 14:25:35.600: INFO: Pod "pod-projected-secrets-e0e3aa90-3c2d-11e9-a154-0a580a280202": Phase="Pending", Reason="", readiness=false. Elapsed: 3.603527ms
Mar  1 14:25:37.604: INFO: Pod "pod-projected-secrets-e0e3aa90-3c2d-11e9-a154-0a580a280202": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007506781s
STEP: Saw pod success
Mar  1 14:25:37.604: INFO: Pod "pod-projected-secrets-e0e3aa90-3c2d-11e9-a154-0a580a280202" satisfied condition "success or failure"
Mar  1 14:25:37.607: INFO: Trying to get logs from node gke-conformance-default-pool-eca581b0-sww9 pod pod-projected-secrets-e0e3aa90-3c2d-11e9-a154-0a580a280202 container projected-secret-volume-test: <nil>
STEP: delete the pod
Mar  1 14:25:37.637: INFO: Waiting for pod pod-projected-secrets-e0e3aa90-3c2d-11e9-a154-0a580a280202 to disappear
Mar  1 14:25:37.642: INFO: Pod pod-projected-secrets-e0e3aa90-3c2d-11e9-a154-0a580a280202 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 14:25:37.643: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-wsjp4" for this suite.
Mar  1 14:25:43.658: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 14:25:43.694: INFO: namespace: e2e-tests-projected-wsjp4, resource: bindings, ignored listing per whitelist
Mar  1 14:25:43.776: INFO: namespace e2e-tests-projected-wsjp4 deletion completed in 6.129081144s

• [SLOW TEST:8.379 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run job 
  should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 14:25:43.776: INFO: >>> kubeConfig: /tmp/kubeconfig-210205575
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Kubectl run job
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1402
[It] should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Mar  1 14:25:43.868: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-210205575 run e2e-test-nginx-job --restart=OnFailure --generator=job/v1 --image=docker.io/library/nginx:1.14-alpine --namespace=e2e-tests-kubectl-lwppc'
Mar  1 14:25:44.178: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl create instead.\n"
Mar  1 14:25:44.178: INFO: stdout: "job.batch/e2e-test-nginx-job created\n"
STEP: verifying the job e2e-test-nginx-job was created
[AfterEach] [k8s.io] Kubectl run job
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1407
Mar  1 14:25:44.182: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-210205575 delete jobs e2e-test-nginx-job --namespace=e2e-tests-kubectl-lwppc'
Mar  1 14:25:44.270: INFO: stderr: ""
Mar  1 14:25:44.270: INFO: stdout: "job.batch \"e2e-test-nginx-job\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 14:25:44.270: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-lwppc" for this suite.
Mar  1 14:26:06.296: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 14:26:06.339: INFO: namespace: e2e-tests-kubectl-lwppc, resource: bindings, ignored listing per whitelist
Mar  1 14:26:06.403: INFO: namespace e2e-tests-kubectl-lwppc deletion completed in 22.124073977s

• [SLOW TEST:22.627 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run job
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create a job from an image when restart is OnFailure  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-network] DNS 
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 14:26:06.403: INFO: >>> kubeConfig: /tmp/kubeconfig-210205575
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for services  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(dig +notcp +noall +answer +search dns-test-service A)" && echo OK > /results/wheezy_udp@dns-test-service;test -n "$$(dig +tcp +noall +answer +search dns-test-service A)" && echo OK > /results/wheezy_tcp@dns-test-service;test -n "$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-tt5jt A)" && echo OK > /results/wheezy_udp@dns-test-service.e2e-tests-dns-tt5jt;test -n "$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-tt5jt A)" && echo OK > /results/wheezy_tcp@dns-test-service.e2e-tests-dns-tt5jt;test -n "$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-tt5jt.svc A)" && echo OK > /results/wheezy_udp@dns-test-service.e2e-tests-dns-tt5jt.svc;test -n "$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-tt5jt.svc A)" && echo OK > /results/wheezy_tcp@dns-test-service.e2e-tests-dns-tt5jt.svc;test -n "$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-tt5jt.svc SRV)" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.e2e-tests-dns-tt5jt.svc;test -n "$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-tt5jt.svc SRV)" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.e2e-tests-dns-tt5jt.svc;test -n "$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-tt5jt.svc SRV)" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.e2e-tests-dns-tt5jt.svc;test -n "$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-tt5jt.svc SRV)" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.e2e-tests-dns-tt5jt.svc;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-tt5jt.pod.cluster.local"}');test -n "$$(dig +notcp +noall +answer +search $${podARec} A)" && echo OK > /results/wheezy_udp@PodARecord;test -n "$$(dig +tcp +noall +answer +search $${podARec} A)" && echo OK > /results/wheezy_tcp@PodARecord;test -n "$$(dig +notcp +noall +answer +search 217.253.43.10.in-addr.arpa. PTR)" && echo OK > /results/10.43.253.217_udp@PTR;test -n "$$(dig +tcp +noall +answer +search 217.253.43.10.in-addr.arpa. PTR)" && echo OK > /results/10.43.253.217_tcp@PTR;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(dig +notcp +noall +answer +search dns-test-service A)" && echo OK > /results/jessie_udp@dns-test-service;test -n "$$(dig +tcp +noall +answer +search dns-test-service A)" && echo OK > /results/jessie_tcp@dns-test-service;test -n "$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-tt5jt A)" && echo OK > /results/jessie_udp@dns-test-service.e2e-tests-dns-tt5jt;test -n "$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-tt5jt A)" && echo OK > /results/jessie_tcp@dns-test-service.e2e-tests-dns-tt5jt;test -n "$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-tt5jt.svc A)" && echo OK > /results/jessie_udp@dns-test-service.e2e-tests-dns-tt5jt.svc;test -n "$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-tt5jt.svc A)" && echo OK > /results/jessie_tcp@dns-test-service.e2e-tests-dns-tt5jt.svc;test -n "$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-tt5jt.svc SRV)" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-tt5jt.svc;test -n "$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-tt5jt.svc SRV)" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-tt5jt.svc;test -n "$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-tt5jt.svc SRV)" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.e2e-tests-dns-tt5jt.svc;test -n "$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-tt5jt.svc SRV)" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.e2e-tests-dns-tt5jt.svc;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-tt5jt.pod.cluster.local"}');test -n "$$(dig +notcp +noall +answer +search $${podARec} A)" && echo OK > /results/jessie_udp@PodARecord;test -n "$$(dig +tcp +noall +answer +search $${podARec} A)" && echo OK > /results/jessie_tcp@PodARecord;test -n "$$(dig +notcp +noall +answer +search 217.253.43.10.in-addr.arpa. PTR)" && echo OK > /results/10.43.253.217_udp@PTR;test -n "$$(dig +tcp +noall +answer +search 217.253.43.10.in-addr.arpa. PTR)" && echo OK > /results/10.43.253.217_tcp@PTR;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Mar  1 14:26:26.853: INFO: DNS probes using e2e-tests-dns-tt5jt/dns-test-f35607df-3c2d-11e9-a154-0a580a280202 succeeded

STEP: deleting the pod
STEP: deleting the test service
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 14:26:27.217: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-dns-tt5jt" for this suite.
Mar  1 14:26:33.267: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 14:26:33.316: INFO: namespace: e2e-tests-dns-tt5jt, resource: bindings, ignored listing per whitelist
Mar  1 14:26:33.385: INFO: namespace e2e-tests-dns-tt5jt deletion completed in 6.153688514s

• [SLOW TEST:26.982 seconds]
[sig-network] DNS
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-storage] Projected 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 14:26:33.385: INFO: >>> kubeConfig: /tmp/kubeconfig-210205575
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Mar  1 14:26:33.488: INFO: Waiting up to 5m0s for pod "downwardapi-volume-03679db0-3c2e-11e9-a154-0a580a280202" in namespace "e2e-tests-projected-kvjzz" to be "success or failure"
Mar  1 14:26:33.493: INFO: Pod "downwardapi-volume-03679db0-3c2e-11e9-a154-0a580a280202": Phase="Pending", Reason="", readiness=false. Elapsed: 4.399559ms
Mar  1 14:26:35.496: INFO: Pod "downwardapi-volume-03679db0-3c2e-11e9-a154-0a580a280202": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007750639s
STEP: Saw pod success
Mar  1 14:26:35.496: INFO: Pod "downwardapi-volume-03679db0-3c2e-11e9-a154-0a580a280202" satisfied condition "success or failure"
Mar  1 14:26:35.499: INFO: Trying to get logs from node gke-conformance-default-pool-eca581b0-czl4 pod downwardapi-volume-03679db0-3c2e-11e9-a154-0a580a280202 container client-container: <nil>
STEP: delete the pod
Mar  1 14:26:35.522: INFO: Waiting for pod downwardapi-volume-03679db0-3c2e-11e9-a154-0a580a280202 to disappear
Mar  1 14:26:35.526: INFO: Pod downwardapi-volume-03679db0-3c2e-11e9-a154-0a580a280202 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 14:26:35.526: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-kvjzz" for this suite.
Mar  1 14:26:41.543: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 14:26:41.696: INFO: namespace: e2e-tests-projected-kvjzz, resource: bindings, ignored listing per whitelist
Mar  1 14:26:41.721: INFO: namespace e2e-tests-projected-kvjzz deletion completed in 6.190366474s

• [SLOW TEST:8.336 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-api-machinery] Downward API 
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 14:26:41.721: INFO: >>> kubeConfig: /tmp/kubeconfig-210205575
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Mar  1 14:26:41.843: INFO: Waiting up to 5m0s for pod "downward-api-0861f8fa-3c2e-11e9-a154-0a580a280202" in namespace "e2e-tests-downward-api-rgwbs" to be "success or failure"
Mar  1 14:26:41.846: INFO: Pod "downward-api-0861f8fa-3c2e-11e9-a154-0a580a280202": Phase="Pending", Reason="", readiness=false. Elapsed: 3.371568ms
Mar  1 14:26:43.850: INFO: Pod "downward-api-0861f8fa-3c2e-11e9-a154-0a580a280202": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006816624s
Mar  1 14:26:45.929: INFO: Pod "downward-api-0861f8fa-3c2e-11e9-a154-0a580a280202": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.086577625s
STEP: Saw pod success
Mar  1 14:26:45.929: INFO: Pod "downward-api-0861f8fa-3c2e-11e9-a154-0a580a280202" satisfied condition "success or failure"
Mar  1 14:26:46.010: INFO: Trying to get logs from node gke-conformance-default-pool-eca581b0-sqmc pod downward-api-0861f8fa-3c2e-11e9-a154-0a580a280202 container dapi-container: <nil>
STEP: delete the pod
Mar  1 14:26:46.055: INFO: Waiting for pod downward-api-0861f8fa-3c2e-11e9-a154-0a580a280202 to disappear
Mar  1 14:26:46.058: INFO: Pod downward-api-0861f8fa-3c2e-11e9-a154-0a580a280202 no longer exists
[AfterEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 14:26:46.058: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-rgwbs" for this suite.
Mar  1 14:26:52.073: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 14:26:52.187: INFO: namespace: e2e-tests-downward-api-rgwbs, resource: bindings, ignored listing per whitelist
Mar  1 14:26:52.208: INFO: namespace e2e-tests-downward-api-rgwbs deletion completed in 6.146025562s

• [SLOW TEST:10.487 seconds]
[sig-api-machinery] Downward API
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-api-machinery] Watchers 
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 14:26:52.208: INFO: >>> kubeConfig: /tmp/kubeconfig-210205575
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a watch on configmaps with a certain label
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: changing the label value of the configmap
STEP: Expecting to observe a delete notification for the watched object
Mar  1 14:26:52.327: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-qbctp,SelfLink:/api/v1/namespaces/e2e-tests-watch-qbctp/configmaps/e2e-watch-test-label-changed,UID:0e9b8e59-3c2e-11e9-83c3-42010a800094,ResourceVersion:17237,Generation:0,CreationTimestamp:2019-03-01 14:26:52 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Mar  1 14:26:52.327: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-qbctp,SelfLink:/api/v1/namespaces/e2e-tests-watch-qbctp/configmaps/e2e-watch-test-label-changed,UID:0e9b8e59-3c2e-11e9-83c3-42010a800094,ResourceVersion:17238,Generation:0,CreationTimestamp:2019-03-01 14:26:52 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Mar  1 14:26:52.327: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-qbctp,SelfLink:/api/v1/namespaces/e2e-tests-watch-qbctp/configmaps/e2e-watch-test-label-changed,UID:0e9b8e59-3c2e-11e9-83c3-42010a800094,ResourceVersion:17239,Generation:0,CreationTimestamp:2019-03-01 14:26:52 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time
STEP: Expecting not to observe a notification because the object no longer meets the selector's requirements
STEP: changing the label value of the configmap back
STEP: modifying the configmap a third time
STEP: deleting the configmap
STEP: Expecting to observe an add notification for the watched object when the label value was restored
Mar  1 14:27:02.356: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-qbctp,SelfLink:/api/v1/namespaces/e2e-tests-watch-qbctp/configmaps/e2e-watch-test-label-changed,UID:0e9b8e59-3c2e-11e9-83c3-42010a800094,ResourceVersion:17270,Generation:0,CreationTimestamp:2019-03-01 14:26:52 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Mar  1 14:27:02.356: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-qbctp,SelfLink:/api/v1/namespaces/e2e-tests-watch-qbctp/configmaps/e2e-watch-test-label-changed,UID:0e9b8e59-3c2e-11e9-83c3-42010a800094,ResourceVersion:17271,Generation:0,CreationTimestamp:2019-03-01 14:26:52 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
Mar  1 14:27:02.356: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-qbctp,SelfLink:/api/v1/namespaces/e2e-tests-watch-qbctp/configmaps/e2e-watch-test-label-changed,UID:0e9b8e59-3c2e-11e9-83c3-42010a800094,ResourceVersion:17272,Generation:0,CreationTimestamp:2019-03-01 14:26:52 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 14:27:02.356: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-qbctp" for this suite.
Mar  1 14:27:08.372: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 14:27:08.419: INFO: namespace: e2e-tests-watch-qbctp, resource: bindings, ignored listing per whitelist
Mar  1 14:27:08.500: INFO: namespace e2e-tests-watch-qbctp deletion completed in 6.139420325s

• [SLOW TEST:16.292 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 14:27:08.500: INFO: >>> kubeConfig: /tmp/kubeconfig-210205575
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating the pod
Mar  1 14:27:13.156: INFO: Successfully updated pod "annotationupdate18557250-3c2e-11e9-a154-0a580a280202"
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 14:27:15.326: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-vwxxb" for this suite.
Mar  1 14:27:37.632: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 14:27:37.712: INFO: namespace: e2e-tests-projected-vwxxb, resource: bindings, ignored listing per whitelist
Mar  1 14:27:37.756: INFO: namespace e2e-tests-projected-vwxxb deletion completed in 22.269104606s

• [SLOW TEST:29.256 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-network] Services 
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 14:27:37.756: INFO: >>> kubeConfig: /tmp/kubeconfig-210205575
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:83
[It] should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating service multi-endpoint-test in namespace e2e-tests-services-zsczq
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-zsczq to expose endpoints map[]
Mar  1 14:27:37.879: INFO: Get endpoints failed (9.30802ms elapsed, ignoring for 5s): endpoints "multi-endpoint-test" not found
Mar  1 14:27:38.882: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-zsczq exposes endpoints map[] (1.012671387s elapsed)
STEP: Creating pod pod1 in namespace e2e-tests-services-zsczq
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-zsczq to expose endpoints map[pod1:[100]]
Mar  1 14:27:40.923: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-zsczq exposes endpoints map[pod1:[100]] (2.028815394s elapsed)
STEP: Creating pod pod2 in namespace e2e-tests-services-zsczq
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-zsczq to expose endpoints map[pod1:[100] pod2:[101]]
Mar  1 14:27:43.996: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-zsczq exposes endpoints map[pod1:[100] pod2:[101]] (3.059749532s elapsed)
STEP: Deleting pod pod1 in namespace e2e-tests-services-zsczq
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-zsczq to expose endpoints map[pod2:[101]]
Mar  1 14:27:45.029: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-zsczq exposes endpoints map[pod2:[101]] (1.026828622s elapsed)
STEP: Deleting pod pod2 in namespace e2e-tests-services-zsczq
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-zsczq to expose endpoints map[]
Mar  1 14:27:46.095: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-zsczq exposes endpoints map[] (1.056838826s elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 14:27:46.162: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-services-zsczq" for this suite.
Mar  1 14:28:10.174: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 14:28:10.231: INFO: namespace: e2e-tests-services-zsczq, resource: bindings, ignored listing per whitelist
Mar  1 14:28:10.293: INFO: namespace e2e-tests-services-zsczq deletion completed in 24.127574832s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:88

• [SLOW TEST:32.537 seconds]
[sig-network] Services
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] Projected 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 14:28:10.293: INFO: >>> kubeConfig: /tmp/kubeconfig-210205575
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Mar  1 14:28:10.390: INFO: Waiting up to 5m0s for pod "downwardapi-volume-3d29a366-3c2e-11e9-a154-0a580a280202" in namespace "e2e-tests-projected-ps5kw" to be "success or failure"
Mar  1 14:28:10.400: INFO: Pod "downwardapi-volume-3d29a366-3c2e-11e9-a154-0a580a280202": Phase="Pending", Reason="", readiness=false. Elapsed: 10.168579ms
Mar  1 14:28:12.404: INFO: Pod "downwardapi-volume-3d29a366-3c2e-11e9-a154-0a580a280202": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014115218s
Mar  1 14:28:14.407: INFO: Pod "downwardapi-volume-3d29a366-3c2e-11e9-a154-0a580a280202": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.017594616s
STEP: Saw pod success
Mar  1 14:28:14.407: INFO: Pod "downwardapi-volume-3d29a366-3c2e-11e9-a154-0a580a280202" satisfied condition "success or failure"
Mar  1 14:28:14.410: INFO: Trying to get logs from node gke-conformance-default-pool-eca581b0-czl4 pod downwardapi-volume-3d29a366-3c2e-11e9-a154-0a580a280202 container client-container: <nil>
STEP: delete the pod
Mar  1 14:28:14.437: INFO: Waiting for pod downwardapi-volume-3d29a366-3c2e-11e9-a154-0a580a280202 to disappear
Mar  1 14:28:14.442: INFO: Pod downwardapi-volume-3d29a366-3c2e-11e9-a154-0a580a280202 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 14:28:14.442: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-ps5kw" for this suite.
Mar  1 14:28:20.457: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 14:28:20.746: INFO: namespace: e2e-tests-projected-ps5kw, resource: bindings, ignored listing per whitelist
Mar  1 14:28:20.751: INFO: namespace e2e-tests-projected-ps5kw deletion completed in 6.305151079s

• [SLOW TEST:10.458 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Downward API volume 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 14:28:20.751: INFO: >>> kubeConfig: /tmp/kubeconfig-210205575
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating the pod
Mar  1 14:28:25.473: INFO: Successfully updated pod "labelsupdate43700f8c-3c2e-11e9-a154-0a580a280202"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 14:28:27.498: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-vdll4" for this suite.
Mar  1 14:28:49.514: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 14:28:49.681: INFO: namespace: e2e-tests-downward-api-vdll4, resource: bindings, ignored listing per whitelist
Mar  1 14:28:49.702: INFO: namespace e2e-tests-downward-api-vdll4 deletion completed in 22.199971735s

• [SLOW TEST:28.951 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should scale a replication controller  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 14:28:49.702: INFO: >>> kubeConfig: /tmp/kubeconfig-210205575
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:293
[It] should scale a replication controller  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a replication controller
Mar  1 14:28:49.829: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-210205575 create -f - --namespace=e2e-tests-kubectl-5zk9j'
Mar  1 14:28:50.011: INFO: stderr: ""
Mar  1 14:28:50.011: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Mar  1 14:28:50.011: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-210205575 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-5zk9j'
Mar  1 14:28:50.127: INFO: stderr: ""
Mar  1 14:28:50.127: INFO: stdout: "update-demo-nautilus-cd6mh update-demo-nautilus-kqxsg "
Mar  1 14:28:50.127: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-210205575 get pods update-demo-nautilus-cd6mh -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-5zk9j'
Mar  1 14:28:50.227: INFO: stderr: ""
Mar  1 14:28:50.227: INFO: stdout: ""
Mar  1 14:28:50.227: INFO: update-demo-nautilus-cd6mh is created but not running
Mar  1 14:28:55.227: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-210205575 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-5zk9j'
Mar  1 14:28:55.313: INFO: stderr: ""
Mar  1 14:28:55.313: INFO: stdout: "update-demo-nautilus-cd6mh update-demo-nautilus-kqxsg "
Mar  1 14:28:55.313: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-210205575 get pods update-demo-nautilus-cd6mh -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-5zk9j'
Mar  1 14:28:55.393: INFO: stderr: ""
Mar  1 14:28:55.393: INFO: stdout: "true"
Mar  1 14:28:55.393: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-210205575 get pods update-demo-nautilus-cd6mh -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-5zk9j'
Mar  1 14:28:55.474: INFO: stderr: ""
Mar  1 14:28:55.474: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Mar  1 14:28:55.474: INFO: validating pod update-demo-nautilus-cd6mh
Mar  1 14:28:55.483: INFO: got data: {
  "image": "nautilus.jpg"
}

Mar  1 14:28:55.483: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Mar  1 14:28:55.483: INFO: update-demo-nautilus-cd6mh is verified up and running
Mar  1 14:28:55.483: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-210205575 get pods update-demo-nautilus-kqxsg -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-5zk9j'
Mar  1 14:28:55.564: INFO: stderr: ""
Mar  1 14:28:55.564: INFO: stdout: "true"
Mar  1 14:28:55.564: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-210205575 get pods update-demo-nautilus-kqxsg -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-5zk9j'
Mar  1 14:28:55.646: INFO: stderr: ""
Mar  1 14:28:55.646: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Mar  1 14:28:55.646: INFO: validating pod update-demo-nautilus-kqxsg
Mar  1 14:28:55.656: INFO: got data: {
  "image": "nautilus.jpg"
}

Mar  1 14:28:55.656: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Mar  1 14:28:55.656: INFO: update-demo-nautilus-kqxsg is verified up and running
STEP: scaling down the replication controller
Mar  1 14:28:55.658: INFO: scanned /root for discovery docs: <nil>
Mar  1 14:28:55.658: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-210205575 scale rc update-demo-nautilus --replicas=1 --timeout=5m --namespace=e2e-tests-kubectl-5zk9j'
Mar  1 14:28:56.770: INFO: stderr: ""
Mar  1 14:28:56.770: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Mar  1 14:28:56.770: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-210205575 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-5zk9j'
Mar  1 14:28:56.857: INFO: stderr: ""
Mar  1 14:28:56.857: INFO: stdout: "update-demo-nautilus-cd6mh update-demo-nautilus-kqxsg "
STEP: Replicas for name=update-demo: expected=1 actual=2
Mar  1 14:29:01.857: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-210205575 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-5zk9j'
Mar  1 14:29:01.944: INFO: stderr: ""
Mar  1 14:29:01.944: INFO: stdout: "update-demo-nautilus-cd6mh "
Mar  1 14:29:01.945: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-210205575 get pods update-demo-nautilus-cd6mh -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-5zk9j'
Mar  1 14:29:02.030: INFO: stderr: ""
Mar  1 14:29:02.030: INFO: stdout: "true"
Mar  1 14:29:02.030: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-210205575 get pods update-demo-nautilus-cd6mh -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-5zk9j'
Mar  1 14:29:02.111: INFO: stderr: ""
Mar  1 14:29:02.111: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Mar  1 14:29:02.111: INFO: validating pod update-demo-nautilus-cd6mh
Mar  1 14:29:02.119: INFO: got data: {
  "image": "nautilus.jpg"
}

Mar  1 14:29:02.119: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Mar  1 14:29:02.119: INFO: update-demo-nautilus-cd6mh is verified up and running
STEP: scaling up the replication controller
Mar  1 14:29:02.120: INFO: scanned /root for discovery docs: <nil>
Mar  1 14:29:02.120: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-210205575 scale rc update-demo-nautilus --replicas=2 --timeout=5m --namespace=e2e-tests-kubectl-5zk9j'
Mar  1 14:29:03.238: INFO: stderr: ""
Mar  1 14:29:03.238: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Mar  1 14:29:03.238: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-210205575 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-5zk9j'
Mar  1 14:29:03.323: INFO: stderr: ""
Mar  1 14:29:03.323: INFO: stdout: "update-demo-nautilus-cd6mh update-demo-nautilus-st7d2 "
Mar  1 14:29:03.323: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-210205575 get pods update-demo-nautilus-cd6mh -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-5zk9j'
Mar  1 14:29:03.412: INFO: stderr: ""
Mar  1 14:29:03.412: INFO: stdout: "true"
Mar  1 14:29:03.412: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-210205575 get pods update-demo-nautilus-cd6mh -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-5zk9j'
Mar  1 14:29:03.495: INFO: stderr: ""
Mar  1 14:29:03.495: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Mar  1 14:29:03.495: INFO: validating pod update-demo-nautilus-cd6mh
Mar  1 14:29:03.501: INFO: got data: {
  "image": "nautilus.jpg"
}

Mar  1 14:29:03.501: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Mar  1 14:29:03.501: INFO: update-demo-nautilus-cd6mh is verified up and running
Mar  1 14:29:03.501: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-210205575 get pods update-demo-nautilus-st7d2 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-5zk9j'
Mar  1 14:29:03.585: INFO: stderr: ""
Mar  1 14:29:03.585: INFO: stdout: ""
Mar  1 14:29:03.585: INFO: update-demo-nautilus-st7d2 is created but not running
Mar  1 14:29:08.585: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-210205575 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-5zk9j'
Mar  1 14:29:08.672: INFO: stderr: ""
Mar  1 14:29:08.672: INFO: stdout: "update-demo-nautilus-cd6mh update-demo-nautilus-st7d2 "
Mar  1 14:29:08.672: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-210205575 get pods update-demo-nautilus-cd6mh -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-5zk9j'
Mar  1 14:29:08.753: INFO: stderr: ""
Mar  1 14:29:08.753: INFO: stdout: "true"
Mar  1 14:29:08.753: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-210205575 get pods update-demo-nautilus-cd6mh -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-5zk9j'
Mar  1 14:29:08.842: INFO: stderr: ""
Mar  1 14:29:08.842: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Mar  1 14:29:08.842: INFO: validating pod update-demo-nautilus-cd6mh
Mar  1 14:29:08.851: INFO: got data: {
  "image": "nautilus.jpg"
}

Mar  1 14:29:08.851: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Mar  1 14:29:08.851: INFO: update-demo-nautilus-cd6mh is verified up and running
Mar  1 14:29:08.851: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-210205575 get pods update-demo-nautilus-st7d2 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-5zk9j'
Mar  1 14:29:08.932: INFO: stderr: ""
Mar  1 14:29:08.932: INFO: stdout: "true"
Mar  1 14:29:08.932: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-210205575 get pods update-demo-nautilus-st7d2 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-5zk9j'
Mar  1 14:29:09.014: INFO: stderr: ""
Mar  1 14:29:09.014: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Mar  1 14:29:09.014: INFO: validating pod update-demo-nautilus-st7d2
Mar  1 14:29:09.023: INFO: got data: {
  "image": "nautilus.jpg"
}

Mar  1 14:29:09.024: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Mar  1 14:29:09.024: INFO: update-demo-nautilus-st7d2 is verified up and running
STEP: using delete to clean up resources
Mar  1 14:29:09.024: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-210205575 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-5zk9j'
Mar  1 14:29:09.125: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Mar  1 14:29:09.125: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Mar  1 14:29:09.125: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-210205575 get rc,svc -l name=update-demo --no-headers --namespace=e2e-tests-kubectl-5zk9j'
Mar  1 14:29:09.222: INFO: stderr: "No resources found.\n"
Mar  1 14:29:09.222: INFO: stdout: ""
Mar  1 14:29:09.222: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-210205575 get pods -l name=update-demo --namespace=e2e-tests-kubectl-5zk9j -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Mar  1 14:29:09.309: INFO: stderr: ""
Mar  1 14:29:09.309: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 14:29:09.309: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-5zk9j" for this suite.
Mar  1 14:29:31.326: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 14:29:31.436: INFO: namespace: e2e-tests-kubectl-5zk9j, resource: bindings, ignored listing per whitelist
Mar  1 14:29:31.450: INFO: namespace e2e-tests-kubectl-5zk9j deletion completed in 22.135701107s

• [SLOW TEST:41.748 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Update Demo
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should scale a replication controller  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 14:29:31.450: INFO: >>> kubeConfig: /tmp/kubeconfig-210205575
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-exec in namespace e2e-tests-container-probe-blx9l
Mar  1 14:29:33.588: INFO: Started pod liveness-exec in namespace e2e-tests-container-probe-blx9l
STEP: checking the pod's current state and verifying that restartCount is present
Mar  1 14:29:33.591: INFO: Initial restart count of pod liveness-exec is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 14:33:34.573: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-blx9l" for this suite.
Mar  1 14:33:40.595: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 14:33:40.774: INFO: namespace: e2e-tests-container-probe-blx9l, resource: bindings, ignored listing per whitelist
Mar  1 14:33:40.783: INFO: namespace e2e-tests-container-probe-blx9l deletion completed in 6.203486701s

• [SLOW TEST:249.333 seconds]
[k8s.io] Probing container
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 14:33:40.783: INFO: >>> kubeConfig: /tmp/kubeconfig-210205575
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Mar  1 14:33:40.908: INFO: Waiting up to 5m0s for pod "downwardapi-volume-0229db92-3c2f-11e9-a154-0a580a280202" in namespace "e2e-tests-downward-api-n59t2" to be "success or failure"
Mar  1 14:33:40.923: INFO: Pod "downwardapi-volume-0229db92-3c2f-11e9-a154-0a580a280202": Phase="Pending", Reason="", readiness=false. Elapsed: 14.747596ms
Mar  1 14:33:42.926: INFO: Pod "downwardapi-volume-0229db92-3c2f-11e9-a154-0a580a280202": Phase="Running", Reason="", readiness=true. Elapsed: 2.018012802s
Mar  1 14:33:44.932: INFO: Pod "downwardapi-volume-0229db92-3c2f-11e9-a154-0a580a280202": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.024376813s
STEP: Saw pod success
Mar  1 14:33:44.932: INFO: Pod "downwardapi-volume-0229db92-3c2f-11e9-a154-0a580a280202" satisfied condition "success or failure"
Mar  1 14:33:44.936: INFO: Trying to get logs from node gke-conformance-default-pool-eca581b0-sqmc pod downwardapi-volume-0229db92-3c2f-11e9-a154-0a580a280202 container client-container: <nil>
STEP: delete the pod
Mar  1 14:33:44.991: INFO: Waiting for pod downwardapi-volume-0229db92-3c2f-11e9-a154-0a580a280202 to disappear
Mar  1 14:33:44.997: INFO: Pod downwardapi-volume-0229db92-3c2f-11e9-a154-0a580a280202 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 14:33:44.997: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-n59t2" for this suite.
Mar  1 14:33:51.017: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 14:33:51.097: INFO: namespace: e2e-tests-downward-api-n59t2, resource: bindings, ignored listing per whitelist
Mar  1 14:33:51.139: INFO: namespace e2e-tests-downward-api-n59t2 deletion completed in 6.136072523s

• [SLOW TEST:10.356 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod with mountPath of existing file [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 14:33:51.139: INFO: >>> kubeConfig: /tmp/kubeconfig-210205575
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with configmap pod with mountPath of existing file [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-configmap-lcdx
STEP: Creating a pod to test atomic-volume-subpath
Mar  1 14:33:51.249: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-lcdx" in namespace "e2e-tests-subpath-mssxb" to be "success or failure"
Mar  1 14:33:51.252: INFO: Pod "pod-subpath-test-configmap-lcdx": Phase="Pending", Reason="", readiness=false. Elapsed: 2.389222ms
Mar  1 14:33:53.255: INFO: Pod "pod-subpath-test-configmap-lcdx": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005851827s
Mar  1 14:33:55.258: INFO: Pod "pod-subpath-test-configmap-lcdx": Phase="Running", Reason="", readiness=false. Elapsed: 4.009225945s
Mar  1 14:33:57.262: INFO: Pod "pod-subpath-test-configmap-lcdx": Phase="Running", Reason="", readiness=false. Elapsed: 6.013004671s
Mar  1 14:33:59.268: INFO: Pod "pod-subpath-test-configmap-lcdx": Phase="Running", Reason="", readiness=false. Elapsed: 8.018299486s
Mar  1 14:34:01.271: INFO: Pod "pod-subpath-test-configmap-lcdx": Phase="Running", Reason="", readiness=false. Elapsed: 10.021897437s
Mar  1 14:34:03.279: INFO: Pod "pod-subpath-test-configmap-lcdx": Phase="Running", Reason="", readiness=false. Elapsed: 12.029320098s
Mar  1 14:34:05.282: INFO: Pod "pod-subpath-test-configmap-lcdx": Phase="Running", Reason="", readiness=false. Elapsed: 14.03273497s
Mar  1 14:34:07.285: INFO: Pod "pod-subpath-test-configmap-lcdx": Phase="Running", Reason="", readiness=false. Elapsed: 16.036159568s
Mar  1 14:34:09.290: INFO: Pod "pod-subpath-test-configmap-lcdx": Phase="Running", Reason="", readiness=false. Elapsed: 18.04031105s
Mar  1 14:34:11.293: INFO: Pod "pod-subpath-test-configmap-lcdx": Phase="Running", Reason="", readiness=false. Elapsed: 20.043941891s
Mar  1 14:34:13.298: INFO: Pod "pod-subpath-test-configmap-lcdx": Phase="Running", Reason="", readiness=false. Elapsed: 22.048571539s
Mar  1 14:34:15.301: INFO: Pod "pod-subpath-test-configmap-lcdx": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.051802628s
STEP: Saw pod success
Mar  1 14:34:15.301: INFO: Pod "pod-subpath-test-configmap-lcdx" satisfied condition "success or failure"
Mar  1 14:34:15.306: INFO: Trying to get logs from node gke-conformance-default-pool-eca581b0-czl4 pod pod-subpath-test-configmap-lcdx container test-container-subpath-configmap-lcdx: <nil>
STEP: delete the pod
Mar  1 14:34:15.346: INFO: Waiting for pod pod-subpath-test-configmap-lcdx to disappear
Mar  1 14:34:15.350: INFO: Pod pod-subpath-test-configmap-lcdx no longer exists
STEP: Deleting pod pod-subpath-test-configmap-lcdx
Mar  1 14:34:15.350: INFO: Deleting pod "pod-subpath-test-configmap-lcdx" in namespace "e2e-tests-subpath-mssxb"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 14:34:15.354: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-mssxb" for this suite.
Mar  1 14:34:21.370: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 14:34:21.487: INFO: namespace: e2e-tests-subpath-mssxb, resource: bindings, ignored listing per whitelist
Mar  1 14:34:21.492: INFO: namespace e2e-tests-subpath-mssxb deletion completed in 6.133666694s

• [SLOW TEST:30.353 seconds]
[sig-storage] Subpath
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with configmap pod with mountPath of existing file [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 14:34:21.492: INFO: >>> kubeConfig: /tmp/kubeconfig-210205575
STEP: Building a namespace api object, basename namespaces
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a test namespace
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a service in the namespace
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Verifying there is no service in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 14:34:27.699: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-namespaces-6d7mf" for this suite.
Mar  1 14:34:33.714: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 14:34:33.821: INFO: namespace: e2e-tests-namespaces-6d7mf, resource: bindings, ignored listing per whitelist
Mar  1 14:34:33.830: INFO: namespace e2e-tests-namespaces-6d7mf deletion completed in 6.12701613s
STEP: Destroying namespace "e2e-tests-nsdeletetest-vzrf2" for this suite.
Mar  1 14:34:33.832: INFO: Namespace e2e-tests-nsdeletetest-vzrf2 was already deleted
STEP: Destroying namespace "e2e-tests-nsdeletetest-zssbm" for this suite.
Mar  1 14:34:39.852: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 14:34:39.906: INFO: namespace: e2e-tests-nsdeletetest-zssbm, resource: bindings, ignored listing per whitelist
Mar  1 14:34:39.979: INFO: namespace e2e-tests-nsdeletetest-zssbm deletion completed in 6.147160352s

• [SLOW TEST:18.487 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl api-versions 
  should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 14:34:39.980: INFO: >>> kubeConfig: /tmp/kubeconfig-210205575
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: validating api versions
Mar  1 14:34:40.075: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-210205575 api-versions'
Mar  1 14:34:40.160: INFO: stderr: ""
Mar  1 14:34:40.160: INFO: stdout: "admissionregistration.k8s.io/v1beta1\napiextensions.k8s.io/v1beta1\napiregistration.k8s.io/v1\napiregistration.k8s.io/v1beta1\napps/v1\napps/v1beta1\napps/v1beta2\nauthentication.k8s.io/v1\nauthentication.k8s.io/v1beta1\nauthorization.k8s.io/v1\nauthorization.k8s.io/v1beta1\nautoscaling/v1\nautoscaling/v2beta1\nbatch/v1\nbatch/v1beta1\ncertificates.k8s.io/v1beta1\ncloud.google.com/v1beta1\nextensions/v1beta1\nmetrics.k8s.io/v1beta1\nnetworking.k8s.io/v1\npolicy/v1beta1\nrbac.authorization.k8s.io/v1\nrbac.authorization.k8s.io/v1beta1\nscalingpolicy.kope.io/v1alpha1\nscheduling.k8s.io/v1beta1\nstorage.k8s.io/v1\nstorage.k8s.io/v1beta1\nv1\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 14:34:40.160: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-87tbb" for this suite.
Mar  1 14:34:46.392: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 14:34:46.533: INFO: namespace: e2e-tests-kubectl-87tbb, resource: bindings, ignored listing per whitelist
Mar  1 14:34:46.590: INFO: namespace e2e-tests-kubectl-87tbb deletion completed in 6.424849524s

• [SLOW TEST:6.610 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl api-versions
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should check if v1 is in available api versions  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-apps] Deployment 
  deployment should support rollover [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 14:34:46.590: INFO: >>> kubeConfig: /tmp/kubeconfig-210205575
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should support rollover [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Mar  1 14:34:46.683: INFO: Pod name rollover-pod: Found 0 pods out of 1
Mar  1 14:34:51.686: INFO: Pod name rollover-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Mar  1 14:34:51.686: INFO: Waiting for pods owned by replica set "test-rollover-controller" to become ready
Mar  1 14:34:53.689: INFO: Creating deployment "test-rollover-deployment"
Mar  1 14:34:53.701: INFO: Make sure deployment "test-rollover-deployment" performs scaling operations
Mar  1 14:34:55.707: INFO: Check revision of new replica set for deployment "test-rollover-deployment"
Mar  1 14:34:55.713: INFO: Ensure that both replica sets have 1 created replica
Mar  1 14:34:55.718: INFO: Rollover old replica sets for deployment "test-rollover-deployment" with new image update
Mar  1 14:34:55.728: INFO: Updating deployment test-rollover-deployment
Mar  1 14:34:55.728: INFO: Wait deployment "test-rollover-deployment" to be observed by the deployment controller
Mar  1 14:34:57.736: INFO: Wait for revision update of deployment "test-rollover-deployment" to 2
Mar  1 14:34:57.743: INFO: Make sure deployment "test-rollover-deployment" is complete
Mar  1 14:34:57.750: INFO: all replica sets need to contain the pod-template-hash label
Mar  1 14:34:57.750: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63687047693, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63687047693, loc:(*time.Location)(0x6c43b60)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63687047696, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63687047693, loc:(*time.Location)(0x6c43b60)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-5b76ff8c4\" is progressing."}}, CollisionCount:(*int32)(nil)}
Mar  1 14:34:59.758: INFO: all replica sets need to contain the pod-template-hash label
Mar  1 14:34:59.758: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63687047693, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63687047693, loc:(*time.Location)(0x6c43b60)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63687047696, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63687047693, loc:(*time.Location)(0x6c43b60)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-5b76ff8c4\" is progressing."}}, CollisionCount:(*int32)(nil)}
Mar  1 14:35:01.757: INFO: all replica sets need to contain the pod-template-hash label
Mar  1 14:35:01.757: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63687047693, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63687047693, loc:(*time.Location)(0x6c43b60)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63687047696, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63687047693, loc:(*time.Location)(0x6c43b60)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-5b76ff8c4\" is progressing."}}, CollisionCount:(*int32)(nil)}
Mar  1 14:35:03.757: INFO: all replica sets need to contain the pod-template-hash label
Mar  1 14:35:03.757: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63687047693, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63687047693, loc:(*time.Location)(0x6c43b60)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63687047696, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63687047693, loc:(*time.Location)(0x6c43b60)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-5b76ff8c4\" is progressing."}}, CollisionCount:(*int32)(nil)}
Mar  1 14:35:05.757: INFO: all replica sets need to contain the pod-template-hash label
Mar  1 14:35:05.757: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63687047693, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63687047693, loc:(*time.Location)(0x6c43b60)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63687047696, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63687047693, loc:(*time.Location)(0x6c43b60)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-5b76ff8c4\" is progressing."}}, CollisionCount:(*int32)(nil)}
Mar  1 14:35:07.756: INFO: 
Mar  1 14:35:07.756: INFO: Ensure that both old replica sets have no replicas
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Mar  1 14:35:07.764: INFO: Deployment "test-rollover-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment,GenerateName:,Namespace:e2e-tests-deployment-vw2pv,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-vw2pv/deployments/test-rollover-deployment,UID:2d8cc1c1-3c2f-11e9-83c3-42010a800094,ResourceVersion:18905,Generation:2,CreationTimestamp:2019-03-01 14:34:53 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:0,MaxSurge:1,},},MinReadySeconds:10,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[{Available True 2019-03-01 14:34:53 +0000 UTC 2019-03-01 14:34:53 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2019-03-01 14:35:06 +0000 UTC 2019-03-01 14:34:53 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-rollover-deployment-5b76ff8c4" has successfully progressed.}],ReadyReplicas:1,CollisionCount:nil,},}

Mar  1 14:35:07.767: INFO: New ReplicaSet "test-rollover-deployment-5b76ff8c4" of Deployment "test-rollover-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-5b76ff8c4,GenerateName:,Namespace:e2e-tests-deployment-vw2pv,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-vw2pv/replicasets/test-rollover-deployment-5b76ff8c4,UID:2ec3bc53-3c2f-11e9-83c3-42010a800094,ResourceVersion:18897,Generation:2,CreationTimestamp:2019-03-01 14:34:55 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 5b76ff8c4,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment 2d8cc1c1-3c2f-11e9-83c3-42010a800094 0xc422750cd7 0xc422750cd8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 5b76ff8c4,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 5b76ff8c4,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:2,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Mar  1 14:35:07.767: INFO: All old ReplicaSets of Deployment "test-rollover-deployment":
Mar  1 14:35:07.768: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-controller,GenerateName:,Namespace:e2e-tests-deployment-vw2pv,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-vw2pv/replicasets/test-rollover-controller,UID:295de4ad-3c2f-11e9-83c3-42010a800094,ResourceVersion:18903,Generation:2,CreationTimestamp:2019-03-01 14:34:46 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod: nginx,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment 2d8cc1c1-3c2f-11e9-83c3-42010a800094 0xc422750c0e 0xc422750c0f}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Mar  1 14:35:07.768: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-6975f4fb87,GenerateName:,Namespace:e2e-tests-deployment-vw2pv,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-vw2pv/replicasets/test-rollover-deployment-6975f4fb87,UID:2d8fd571-3c2f-11e9-83c3-42010a800094,ResourceVersion:18857,Generation:2,CreationTimestamp:2019-03-01 14:34:53 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6975f4fb87,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment 2d8cc1c1-3c2f-11e9-83c3-42010a800094 0xc422750e57 0xc422750e58}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 6975f4fb87,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6975f4fb87,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis-slave gcr.io/google_samples/gb-redisslave:nonexistent [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Mar  1 14:35:07.771: INFO: Pod "test-rollover-deployment-5b76ff8c4-bnvkv" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-5b76ff8c4-bnvkv,GenerateName:test-rollover-deployment-5b76ff8c4-,Namespace:e2e-tests-deployment-vw2pv,SelfLink:/api/v1/namespaces/e2e-tests-deployment-vw2pv/pods/test-rollover-deployment-5b76ff8c4-bnvkv,UID:2eced2d6-3c2f-11e9-83c3-42010a800094,ResourceVersion:18867,Generation:0,CreationTimestamp:2019-03-01 14:34:55 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 5b76ff8c4,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet test-rollover-deployment-5b76ff8c4 2ec3bc53-3c2f-11e9-83c3-42010a800094 0xc4224c9400 0xc4224c9401}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-hw6jz {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-hw6jz,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-hw6jz true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:gke-conformance-default-pool-eca581b0-sww9,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc4224c9460} {node.kubernetes.io/unreachable Exists  NoExecute 0xc4224c9480}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 14:34:55 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 14:34:56 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 14:34:56 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 14:34:55 +0000 UTC  }],Message:,Reason:,HostIP:10.128.0.18,PodIP:10.40.1.84,StartTime:2019-03-01 14:34:55 +0000 UTC,ContainerStatuses:[{redis {nil ContainerStateRunning{StartedAt:2019-03-01 14:34:56 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/redis:1.0 docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830 docker://93608f594eba242e43a5cd3776977644a3d891ebd5b58f697b4bb2b9867e1970}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 14:35:07.771: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-vw2pv" for this suite.
Mar  1 14:35:13.784: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 14:35:13.845: INFO: namespace: e2e-tests-deployment-vw2pv, resource: bindings, ignored listing per whitelist
Mar  1 14:35:13.922: INFO: namespace e2e-tests-deployment-vw2pv deletion completed in 6.147820432s

• [SLOW TEST:27.332 seconds]
[sig-apps] Deployment
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  deployment should support rollover [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 14:35:13.922: INFO: >>> kubeConfig: /tmp/kubeconfig-210205575
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-b9vnf
[It] Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Looking for a node to schedule stateful set and pod
STEP: Creating pod with conflicting port in namespace e2e-tests-statefulset-b9vnf
STEP: Creating statefulset with conflicting port in namespace e2e-tests-statefulset-b9vnf
STEP: Waiting until pod test-pod will start running in namespace e2e-tests-statefulset-b9vnf
STEP: Waiting until stateful pod ss-0 will be recreated and deleted at least once in namespace e2e-tests-statefulset-b9vnf
Mar  1 14:35:16.115: INFO: Observed stateful pod in namespace: e2e-tests-statefulset-b9vnf, name: ss-0, uid: 39cfa200-3c2f-11e9-83c3-42010a800094, status phase: Pending. Waiting for statefulset controller to delete.
Mar  1 14:35:20.108: INFO: Observed stateful pod in namespace: e2e-tests-statefulset-b9vnf, name: ss-0, uid: 39cfa200-3c2f-11e9-83c3-42010a800094, status phase: Failed. Waiting for statefulset controller to delete.
Mar  1 14:35:20.121: INFO: Observed stateful pod in namespace: e2e-tests-statefulset-b9vnf, name: ss-0, uid: 39cfa200-3c2f-11e9-83c3-42010a800094, status phase: Failed. Waiting for statefulset controller to delete.
Mar  1 14:35:20.131: INFO: Observed delete event for stateful pod ss-0 in namespace e2e-tests-statefulset-b9vnf
STEP: Removing pod with conflicting port in namespace e2e-tests-statefulset-b9vnf
STEP: Waiting when stateful pod ss-0 will be recreated in namespace e2e-tests-statefulset-b9vnf and will be in running state
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Mar  1 14:35:24.192: INFO: Deleting all statefulset in ns e2e-tests-statefulset-b9vnf
Mar  1 14:35:24.196: INFO: Scaling statefulset ss to 0
Mar  1 14:35:34.214: INFO: Waiting for statefulset status.replicas updated to 0
Mar  1 14:35:34.217: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 14:35:34.242: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-b9vnf" for this suite.
Mar  1 14:35:40.264: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 14:35:40.295: INFO: namespace: e2e-tests-statefulset-b9vnf, resource: bindings, ignored listing per whitelist
Mar  1 14:35:40.386: INFO: namespace e2e-tests-statefulset-b9vnf deletion completed in 6.138159498s

• [SLOW TEST:26.464 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    Should recreate evicted statefulset [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 14:35:40.386: INFO: >>> kubeConfig: /tmp/kubeconfig-210205575
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Mar  1 14:35:48.547: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Mar  1 14:35:48.550: INFO: Pod pod-with-prestop-exec-hook still exists
Mar  1 14:35:50.551: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Mar  1 14:35:50.554: INFO: Pod pod-with-prestop-exec-hook still exists
Mar  1 14:35:52.551: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Mar  1 14:35:52.555: INFO: Pod pod-with-prestop-exec-hook still exists
Mar  1 14:35:54.551: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Mar  1 14:35:54.558: INFO: Pod pod-with-prestop-exec-hook still exists
Mar  1 14:35:56.551: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Mar  1 14:35:56.555: INFO: Pod pod-with-prestop-exec-hook still exists
Mar  1 14:35:58.551: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Mar  1 14:35:58.557: INFO: Pod pod-with-prestop-exec-hook still exists
Mar  1 14:36:00.551: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Mar  1 14:36:00.555: INFO: Pod pod-with-prestop-exec-hook still exists
Mar  1 14:36:02.551: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Mar  1 14:36:02.555: INFO: Pod pod-with-prestop-exec-hook still exists
Mar  1 14:36:04.551: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Mar  1 14:36:04.555: INFO: Pod pod-with-prestop-exec-hook still exists
Mar  1 14:36:06.551: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Mar  1 14:36:06.555: INFO: Pod pod-with-prestop-exec-hook still exists
Mar  1 14:36:08.551: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Mar  1 14:36:08.555: INFO: Pod pod-with-prestop-exec-hook still exists
Mar  1 14:36:10.551: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Mar  1 14:36:10.559: INFO: Pod pod-with-prestop-exec-hook still exists
Mar  1 14:36:12.551: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Mar  1 14:36:12.554: INFO: Pod pod-with-prestop-exec-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 14:36:12.566: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-lifecycle-hook-52gmm" for this suite.
Mar  1 14:36:34.583: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 14:36:34.646: INFO: namespace: e2e-tests-container-lifecycle-hook-52gmm, resource: bindings, ignored listing per whitelist
Mar  1 14:36:34.721: INFO: namespace e2e-tests-container-lifecycle-hook-52gmm deletion completed in 22.150679929s

• [SLOW TEST:54.335 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when create a pod with lifecycle hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute prestop exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 14:36:34.721: INFO: >>> kubeConfig: /tmp/kubeconfig-210205575
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0666 on node default medium
Mar  1 14:36:34.862: INFO: Waiting up to 5m0s for pod "pod-69d87565-3c2f-11e9-a154-0a580a280202" in namespace "e2e-tests-emptydir-kbn68" to be "success or failure"
Mar  1 14:36:34.872: INFO: Pod "pod-69d87565-3c2f-11e9-a154-0a580a280202": Phase="Pending", Reason="", readiness=false. Elapsed: 9.664431ms
Mar  1 14:36:36.875: INFO: Pod "pod-69d87565-3c2f-11e9-a154-0a580a280202": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.01336319s
STEP: Saw pod success
Mar  1 14:36:36.875: INFO: Pod "pod-69d87565-3c2f-11e9-a154-0a580a280202" satisfied condition "success or failure"
Mar  1 14:36:36.879: INFO: Trying to get logs from node gke-conformance-default-pool-eca581b0-sww9 pod pod-69d87565-3c2f-11e9-a154-0a580a280202 container test-container: <nil>
STEP: delete the pod
Mar  1 14:36:36.904: INFO: Waiting for pod pod-69d87565-3c2f-11e9-a154-0a580a280202 to disappear
Mar  1 14:36:36.911: INFO: Pod pod-69d87565-3c2f-11e9-a154-0a580a280202 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 14:36:36.911: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-kbn68" for this suite.
Mar  1 14:36:42.931: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 14:36:43.045: INFO: namespace: e2e-tests-emptydir-kbn68, resource: bindings, ignored listing per whitelist
Mar  1 14:36:43.063: INFO: namespace e2e-tests-emptydir-kbn68 deletion completed in 6.144863709s

• [SLOW TEST:8.341 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-api-machinery] Secrets 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 14:36:43.063: INFO: >>> kubeConfig: /tmp/kubeconfig-210205575
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating secret e2e-tests-secrets-n4kzs/secret-test-6ecc8594-3c2f-11e9-a154-0a580a280202
STEP: Creating a pod to test consume secrets
Mar  1 14:36:43.171: INFO: Waiting up to 5m0s for pod "pod-configmaps-6ecd8757-3c2f-11e9-a154-0a580a280202" in namespace "e2e-tests-secrets-n4kzs" to be "success or failure"
Mar  1 14:36:43.183: INFO: Pod "pod-configmaps-6ecd8757-3c2f-11e9-a154-0a580a280202": Phase="Pending", Reason="", readiness=false. Elapsed: 11.282935ms
Mar  1 14:36:45.186: INFO: Pod "pod-configmaps-6ecd8757-3c2f-11e9-a154-0a580a280202": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015158519s
Mar  1 14:36:47.190: INFO: Pod "pod-configmaps-6ecd8757-3c2f-11e9-a154-0a580a280202": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.019025575s
STEP: Saw pod success
Mar  1 14:36:47.190: INFO: Pod "pod-configmaps-6ecd8757-3c2f-11e9-a154-0a580a280202" satisfied condition "success or failure"
Mar  1 14:36:47.193: INFO: Trying to get logs from node gke-conformance-default-pool-eca581b0-sqmc pod pod-configmaps-6ecd8757-3c2f-11e9-a154-0a580a280202 container env-test: <nil>
STEP: delete the pod
Mar  1 14:36:47.217: INFO: Waiting for pod pod-configmaps-6ecd8757-3c2f-11e9-a154-0a580a280202 to disappear
Mar  1 14:36:47.221: INFO: Pod pod-configmaps-6ecd8757-3c2f-11e9-a154-0a580a280202 no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 14:36:47.221: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-n4kzs" for this suite.
Mar  1 14:36:53.240: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 14:36:53.321: INFO: namespace: e2e-tests-secrets-n4kzs, resource: bindings, ignored listing per whitelist
Mar  1 14:36:53.363: INFO: namespace e2e-tests-secrets-n4kzs deletion completed in 6.137605051s

• [SLOW TEST:10.300 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:31
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 14:36:53.363: INFO: >>> kubeConfig: /tmp/kubeconfig-210205575
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-74f41392-3c2f-11e9-a154-0a580a280202
STEP: Creating a pod to test consume configMaps
Mar  1 14:36:53.496: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-74f4e447-3c2f-11e9-a154-0a580a280202" in namespace "e2e-tests-projected-m9pbx" to be "success or failure"
Mar  1 14:36:53.503: INFO: Pod "pod-projected-configmaps-74f4e447-3c2f-11e9-a154-0a580a280202": Phase="Pending", Reason="", readiness=false. Elapsed: 7.761511ms
Mar  1 14:36:55.508: INFO: Pod "pod-projected-configmaps-74f4e447-3c2f-11e9-a154-0a580a280202": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.012175319s
STEP: Saw pod success
Mar  1 14:36:55.508: INFO: Pod "pod-projected-configmaps-74f4e447-3c2f-11e9-a154-0a580a280202" satisfied condition "success or failure"
Mar  1 14:36:55.511: INFO: Trying to get logs from node gke-conformance-default-pool-eca581b0-czl4 pod pod-projected-configmaps-74f4e447-3c2f-11e9-a154-0a580a280202 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Mar  1 14:36:55.535: INFO: Waiting for pod pod-projected-configmaps-74f4e447-3c2f-11e9-a154-0a580a280202 to disappear
Mar  1 14:36:55.539: INFO: Pod pod-projected-configmaps-74f4e447-3c2f-11e9-a154-0a580a280202 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 14:36:55.539: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-m9pbx" for this suite.
Mar  1 14:37:01.554: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 14:37:01.638: INFO: namespace: e2e-tests-projected-m9pbx, resource: bindings, ignored listing per whitelist
Mar  1 14:37:01.677: INFO: namespace e2e-tests-projected-m9pbx deletion completed in 6.133728886s

• [SLOW TEST:8.314 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[k8s.io] [sig-node] Events 
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 14:37:01.677: INFO: >>> kubeConfig: /tmp/kubeconfig-210205575
STEP: Building a namespace api object, basename events
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: retrieving the pod
Mar  1 14:37:03.825: INFO: &Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:send-events-79e9618d-3c2f-11e9-a154-0a580a280202,GenerateName:,Namespace:e2e-tests-events-flt2t,SelfLink:/api/v1/namespaces/e2e-tests-events-flt2t/pods/send-events-79e9618d-3c2f-11e9-a154-0a580a280202,UID:79e96c56-3c2f-11e9-83c3-42010a800094,ResourceVersion:19395,Generation:0,CreationTimestamp:2019-03-01 14:37:01 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: foo,time: 797832308,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-d57kf {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-d57kf,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{p gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1 [] []  [{ 0 80 TCP }] [] [] {map[] map[]} [{default-token-d57kf true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*30,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:gke-conformance-default-pool-eca581b0-sww9,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc4218ba450} {node.kubernetes.io/unreachable Exists  NoExecute 0xc4218ba470}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 14:37:01 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 14:37:03 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 14:37:03 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 14:37:01 +0000 UTC  }],Message:,Reason:,HostIP:10.128.0.18,PodIP:10.40.1.86,StartTime:2019-03-01 14:37:01 +0000 UTC,ContainerStatuses:[{p {nil ContainerStateRunning{StartedAt:2019-03-01 14:37:02 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1 docker-pullable://gcr.io/kubernetes-e2e-test-images/serve-hostname@sha256:bab70473a6d8ef65a22625dc9a1b0f0452e811530fdbe77e4408523460177ff1 docker://b99e061d7500752a878446e7e6d63d3d15ac38f5a4db084618f0882fc576812f}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}

STEP: checking for scheduler event about the pod
Mar  1 14:37:05.829: INFO: Saw scheduler event for our pod.
STEP: checking for kubelet event about the pod
Mar  1 14:37:07.833: INFO: Saw kubelet event for our pod.
STEP: deleting the pod
[AfterEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 14:37:07.840: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-events-flt2t" for this suite.
Mar  1 14:37:47.861: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 14:37:47.916: INFO: namespace: e2e-tests-events-flt2t, resource: bindings, ignored listing per whitelist
Mar  1 14:37:47.975: INFO: namespace e2e-tests-events-flt2t deletion completed in 40.129206445s

• [SLOW TEST:46.298 seconds]
[k8s.io] [sig-node] Events
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 14:37:47.976: INFO: >>> kubeConfig: /tmp/kubeconfig-210205575
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-957d4be3-3c2f-11e9-a154-0a580a280202
STEP: Creating a pod to test consume configMaps
Mar  1 14:37:48.078: INFO: Waiting up to 5m0s for pod "pod-configmaps-957e1734-3c2f-11e9-a154-0a580a280202" in namespace "e2e-tests-configmap-nwfdz" to be "success or failure"
Mar  1 14:37:48.088: INFO: Pod "pod-configmaps-957e1734-3c2f-11e9-a154-0a580a280202": Phase="Pending", Reason="", readiness=false. Elapsed: 9.266674ms
Mar  1 14:37:50.091: INFO: Pod "pod-configmaps-957e1734-3c2f-11e9-a154-0a580a280202": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.012847739s
STEP: Saw pod success
Mar  1 14:37:50.091: INFO: Pod "pod-configmaps-957e1734-3c2f-11e9-a154-0a580a280202" satisfied condition "success or failure"
Mar  1 14:37:50.094: INFO: Trying to get logs from node gke-conformance-default-pool-eca581b0-sqmc pod pod-configmaps-957e1734-3c2f-11e9-a154-0a580a280202 container configmap-volume-test: <nil>
STEP: delete the pod
Mar  1 14:37:50.116: INFO: Waiting for pod pod-configmaps-957e1734-3c2f-11e9-a154-0a580a280202 to disappear
Mar  1 14:37:50.120: INFO: Pod pod-configmaps-957e1734-3c2f-11e9-a154-0a580a280202 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 14:37:50.120: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-nwfdz" for this suite.
Mar  1 14:37:56.135: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 14:37:56.250: INFO: namespace: e2e-tests-configmap-nwfdz, resource: bindings, ignored listing per whitelist
Mar  1 14:37:56.290: INFO: namespace e2e-tests-configmap-nwfdz deletion completed in 6.166324901s

• [SLOW TEST:8.315 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 14:37:56.291: INFO: >>> kubeConfig: /tmp/kubeconfig-210205575
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: Gathering metrics
W0301 14:38:02.426525      19 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Mar  1 14:38:02.426: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 14:38:02.426: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-b6xkz" for this suite.
Mar  1 14:38:08.444: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 14:38:08.559: INFO: namespace: e2e-tests-gc-b6xkz, resource: bindings, ignored listing per whitelist
Mar  1 14:38:08.588: INFO: namespace e2e-tests-gc-b6xkz deletion completed in 6.157480118s

• [SLOW TEST:12.298 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 14:38:08.589: INFO: >>> kubeConfig: /tmp/kubeconfig-210205575
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-nngxq
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Mar  1 14:38:08.703: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Mar  1 14:38:33.116: INFO: ExecWithOptions {Command:[/bin/sh -c echo 'hostName' | timeout -t 2 nc -w 1 -u 10.40.1.89 8081 | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-nngxq PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar  1 14:38:33.116: INFO: >>> kubeConfig: /tmp/kubeconfig-210205575
Mar  1 14:38:34.193: INFO: Found all expected endpoints: [netserver-0]
Mar  1 14:38:34.196: INFO: ExecWithOptions {Command:[/bin/sh -c echo 'hostName' | timeout -t 2 nc -w 1 -u 10.40.4.119 8081 | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-nngxq PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar  1 14:38:34.196: INFO: >>> kubeConfig: /tmp/kubeconfig-210205575
Mar  1 14:38:35.270: INFO: Found all expected endpoints: [netserver-1]
Mar  1 14:38:35.273: INFO: ExecWithOptions {Command:[/bin/sh -c echo 'hostName' | timeout -t 2 nc -w 1 -u 10.40.2.36 8081 | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-nngxq PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar  1 14:38:35.273: INFO: >>> kubeConfig: /tmp/kubeconfig-210205575
Mar  1 14:38:36.346: INFO: Found all expected endpoints: [netserver-2]
Mar  1 14:38:36.351: INFO: ExecWithOptions {Command:[/bin/sh -c echo 'hostName' | timeout -t 2 nc -w 1 -u 10.40.0.24 8081 | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-nngxq PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar  1 14:38:36.351: INFO: >>> kubeConfig: /tmp/kubeconfig-210205575
Mar  1 14:38:37.427: INFO: Found all expected endpoints: [netserver-3]
Mar  1 14:38:37.434: INFO: ExecWithOptions {Command:[/bin/sh -c echo 'hostName' | timeout -t 2 nc -w 1 -u 10.40.3.99 8081 | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-nngxq PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar  1 14:38:37.434: INFO: >>> kubeConfig: /tmp/kubeconfig-210205575
Mar  1 14:38:38.511: INFO: Found all expected endpoints: [netserver-4]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 14:38:38.511: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-nngxq" for this suite.
Mar  1 14:39:00.529: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 14:39:00.633: INFO: namespace: e2e-tests-pod-network-test-nngxq, resource: bindings, ignored listing per whitelist
Mar  1 14:39:00.665: INFO: namespace e2e-tests-pod-network-test-nngxq deletion completed in 22.149531503s

• [SLOW TEST:52.076 seconds]
[sig-network] Networking
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: udp [NodeConformance] [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Projected 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 14:39:00.665: INFO: >>> kubeConfig: /tmp/kubeconfig-210205575
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating the pod
Mar  1 14:39:05.311: INFO: Successfully updated pod "labelsupdatec0d1d8d2-3c2f-11e9-a154-0a580a280202"
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 14:39:07.331: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-cf6d6" for this suite.
Mar  1 14:39:29.349: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 14:39:29.444: INFO: namespace: e2e-tests-projected-cf6d6, resource: bindings, ignored listing per whitelist
Mar  1 14:39:29.491: INFO: namespace e2e-tests-projected-cf6d6 deletion completed in 22.154776052s

• [SLOW TEST:28.826 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Guestbook application 
  should create and stop a working application  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 14:39:29.491: INFO: >>> kubeConfig: /tmp/kubeconfig-210205575
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should create and stop a working application  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating all guestbook components
Mar  1 14:39:29.598: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-slave
  labels:
    app: redis
    role: slave
    tier: backend
spec:
  ports:
  - port: 6379
  selector:
    app: redis
    role: slave
    tier: backend

Mar  1 14:39:29.598: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-210205575 create -f - --namespace=e2e-tests-kubectl-264z8'
Mar  1 14:39:30.579: INFO: stderr: ""
Mar  1 14:39:30.579: INFO: stdout: "service/redis-slave created\n"
Mar  1 14:39:30.579: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-master
  labels:
    app: redis
    role: master
    tier: backend
spec:
  ports:
  - port: 6379
    targetPort: 6379
  selector:
    app: redis
    role: master
    tier: backend

Mar  1 14:39:30.579: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-210205575 create -f - --namespace=e2e-tests-kubectl-264z8'
Mar  1 14:39:30.775: INFO: stderr: ""
Mar  1 14:39:30.775: INFO: stdout: "service/redis-master created\n"
Mar  1 14:39:30.775: INFO: apiVersion: v1
kind: Service
metadata:
  name: frontend
  labels:
    app: guestbook
    tier: frontend
spec:
  # if your cluster supports it, uncomment the following to automatically create
  # an external load-balanced IP for the frontend service.
  # type: LoadBalancer
  ports:
  - port: 80
  selector:
    app: guestbook
    tier: frontend

Mar  1 14:39:30.775: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-210205575 create -f - --namespace=e2e-tests-kubectl-264z8'
Mar  1 14:39:30.968: INFO: stderr: ""
Mar  1 14:39:30.968: INFO: stdout: "service/frontend created\n"
Mar  1 14:39:30.968: INFO: apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: frontend
spec:
  replicas: 3
  template:
    metadata:
      labels:
        app: guestbook
        tier: frontend
    spec:
      containers:
      - name: php-redis
        image: gcr.io/google-samples/gb-frontend:v6
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access environment variables to find service host
          # info, comment out the 'value: dns' line above, and uncomment the
          # line below:
          # value: env
        ports:
        - containerPort: 80

Mar  1 14:39:30.968: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-210205575 create -f - --namespace=e2e-tests-kubectl-264z8'
Mar  1 14:39:31.146: INFO: stderr: ""
Mar  1 14:39:31.146: INFO: stdout: "deployment.extensions/frontend created\n"
Mar  1 14:39:31.146: INFO: apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: redis-master
spec:
  replicas: 1
  template:
    metadata:
      labels:
        app: redis
        role: master
        tier: backend
    spec:
      containers:
      - name: master
        image: gcr.io/kubernetes-e2e-test-images/redis:1.0
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        ports:
        - containerPort: 6379

Mar  1 14:39:31.147: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-210205575 create -f - --namespace=e2e-tests-kubectl-264z8'
Mar  1 14:39:31.354: INFO: stderr: ""
Mar  1 14:39:31.354: INFO: stdout: "deployment.extensions/redis-master created\n"
Mar  1 14:39:31.354: INFO: apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: redis-slave
spec:
  replicas: 2
  template:
    metadata:
      labels:
        app: redis
        role: slave
        tier: backend
    spec:
      containers:
      - name: slave
        image: gcr.io/google-samples/gb-redisslave:v3
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access an environment variable to find the master
          # service's host, comment out the 'value: dns' line above, and
          # uncomment the line below:
          # value: env
        ports:
        - containerPort: 6379

Mar  1 14:39:31.354: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-210205575 create -f - --namespace=e2e-tests-kubectl-264z8'
Mar  1 14:39:31.560: INFO: stderr: ""
Mar  1 14:39:31.560: INFO: stdout: "deployment.extensions/redis-slave created\n"
STEP: validating guestbook app
Mar  1 14:39:31.560: INFO: Waiting for all frontend pods to be Running.
Mar  1 14:39:51.612: INFO: Waiting for frontend to serve content.
Mar  1 14:39:51.631: INFO: Trying to add a new entry to the guestbook.
Mar  1 14:39:51.648: INFO: Verifying that added entry can be retrieved.
STEP: using delete to clean up resources
Mar  1 14:39:51.661: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-210205575 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-264z8'
Mar  1 14:39:51.782: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Mar  1 14:39:51.782: INFO: stdout: "service \"redis-slave\" force deleted\n"
STEP: using delete to clean up resources
Mar  1 14:39:51.782: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-210205575 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-264z8'
Mar  1 14:39:51.900: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Mar  1 14:39:51.900: INFO: stdout: "service \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
Mar  1 14:39:51.900: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-210205575 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-264z8'
Mar  1 14:39:52.001: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Mar  1 14:39:52.001: INFO: stdout: "service \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Mar  1 14:39:52.001: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-210205575 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-264z8'
Mar  1 14:39:52.092: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Mar  1 14:39:52.092: INFO: stdout: "deployment.extensions \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Mar  1 14:39:52.093: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-210205575 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-264z8'
Mar  1 14:39:52.187: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Mar  1 14:39:52.187: INFO: stdout: "deployment.extensions \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
Mar  1 14:39:52.187: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-210205575 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-264z8'
Mar  1 14:39:52.278: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Mar  1 14:39:52.278: INFO: stdout: "deployment.extensions \"redis-slave\" force deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 14:39:52.278: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-264z8" for this suite.
Mar  1 14:40:32.319: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 14:40:32.389: INFO: namespace: e2e-tests-kubectl-264z8, resource: bindings, ignored listing per whitelist
Mar  1 14:40:32.486: INFO: namespace e2e-tests-kubectl-264z8 deletion completed in 40.197562779s

• [SLOW TEST:62.995 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Guestbook application
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create and stop a working application  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 14:40:32.486: INFO: >>> kubeConfig: /tmp/kubeconfig-210205575
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
Mar  1 14:40:32.588: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 14:40:37.216: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-init-container-bfggb" for this suite.
Mar  1 14:40:43.241: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 14:40:43.430: INFO: namespace: e2e-tests-init-container-bfggb, resource: bindings, ignored listing per whitelist
Mar  1 14:40:43.461: INFO: namespace e2e-tests-init-container-bfggb deletion completed in 6.232238982s

• [SLOW TEST:10.975 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with projected pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 14:40:43.461: INFO: >>> kubeConfig: /tmp/kubeconfig-210205575
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with projected pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-projected-dnk8
STEP: Creating a pod to test atomic-volume-subpath
Mar  1 14:40:43.584: INFO: Waiting up to 5m0s for pod "pod-subpath-test-projected-dnk8" in namespace "e2e-tests-subpath-t6n49" to be "success or failure"
Mar  1 14:40:43.587: INFO: Pod "pod-subpath-test-projected-dnk8": Phase="Pending", Reason="", readiness=false. Elapsed: 3.020876ms
Mar  1 14:40:45.591: INFO: Pod "pod-subpath-test-projected-dnk8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007334241s
Mar  1 14:40:47.595: INFO: Pod "pod-subpath-test-projected-dnk8": Phase="Running", Reason="", readiness=false. Elapsed: 4.011153965s
Mar  1 14:40:49.599: INFO: Pod "pod-subpath-test-projected-dnk8": Phase="Running", Reason="", readiness=false. Elapsed: 6.015150826s
Mar  1 14:40:51.603: INFO: Pod "pod-subpath-test-projected-dnk8": Phase="Running", Reason="", readiness=false. Elapsed: 8.019141796s
Mar  1 14:40:53.607: INFO: Pod "pod-subpath-test-projected-dnk8": Phase="Running", Reason="", readiness=false. Elapsed: 10.023612412s
Mar  1 14:40:55.611: INFO: Pod "pod-subpath-test-projected-dnk8": Phase="Running", Reason="", readiness=false. Elapsed: 12.027271385s
Mar  1 14:40:57.615: INFO: Pod "pod-subpath-test-projected-dnk8": Phase="Running", Reason="", readiness=false. Elapsed: 14.03114062s
Mar  1 14:40:59.619: INFO: Pod "pod-subpath-test-projected-dnk8": Phase="Running", Reason="", readiness=false. Elapsed: 16.03502231s
Mar  1 14:41:01.623: INFO: Pod "pod-subpath-test-projected-dnk8": Phase="Running", Reason="", readiness=false. Elapsed: 18.038937953s
Mar  1 14:41:03.634: INFO: Pod "pod-subpath-test-projected-dnk8": Phase="Running", Reason="", readiness=false. Elapsed: 20.049965624s
Mar  1 14:41:05.637: INFO: Pod "pod-subpath-test-projected-dnk8": Phase="Running", Reason="", readiness=false. Elapsed: 22.053821714s
Mar  1 14:41:07.641: INFO: Pod "pod-subpath-test-projected-dnk8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.057636323s
STEP: Saw pod success
Mar  1 14:41:07.641: INFO: Pod "pod-subpath-test-projected-dnk8" satisfied condition "success or failure"
Mar  1 14:41:07.644: INFO: Trying to get logs from node gke-conformance-default-pool-eca581b0-sqmc pod pod-subpath-test-projected-dnk8 container test-container-subpath-projected-dnk8: <nil>
STEP: delete the pod
Mar  1 14:41:07.671: INFO: Waiting for pod pod-subpath-test-projected-dnk8 to disappear
Mar  1 14:41:07.678: INFO: Pod pod-subpath-test-projected-dnk8 no longer exists
STEP: Deleting pod pod-subpath-test-projected-dnk8
Mar  1 14:41:07.678: INFO: Deleting pod "pod-subpath-test-projected-dnk8" in namespace "e2e-tests-subpath-t6n49"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 14:41:07.681: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-t6n49" for this suite.
Mar  1 14:41:13.696: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 14:41:13.720: INFO: namespace: e2e-tests-subpath-t6n49, resource: bindings, ignored listing per whitelist
Mar  1 14:41:13.924: INFO: namespace e2e-tests-subpath-t6n49 deletion completed in 6.239205487s

• [SLOW TEST:30.463 seconds]
[sig-storage] Subpath
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with projected pod [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 14:41:13.924: INFO: >>> kubeConfig: /tmp/kubeconfig-210205575
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:293
[It] should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a replication controller
Mar  1 14:41:14.220: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-210205575 create -f - --namespace=e2e-tests-kubectl-qcvbh'
Mar  1 14:41:14.443: INFO: stderr: ""
Mar  1 14:41:14.443: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Mar  1 14:41:14.443: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-210205575 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-qcvbh'
Mar  1 14:41:14.607: INFO: stderr: ""
Mar  1 14:41:14.607: INFO: stdout: "update-demo-nautilus-64688 update-demo-nautilus-q9wnv "
Mar  1 14:41:14.607: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-210205575 get pods update-demo-nautilus-64688 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-qcvbh'
Mar  1 14:41:14.689: INFO: stderr: ""
Mar  1 14:41:14.690: INFO: stdout: ""
Mar  1 14:41:14.690: INFO: update-demo-nautilus-64688 is created but not running
Mar  1 14:41:19.690: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-210205575 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-qcvbh'
Mar  1 14:41:19.775: INFO: stderr: ""
Mar  1 14:41:19.775: INFO: stdout: "update-demo-nautilus-64688 update-demo-nautilus-q9wnv "
Mar  1 14:41:19.775: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-210205575 get pods update-demo-nautilus-64688 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-qcvbh'
Mar  1 14:41:19.854: INFO: stderr: ""
Mar  1 14:41:19.854: INFO: stdout: "true"
Mar  1 14:41:19.854: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-210205575 get pods update-demo-nautilus-64688 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-qcvbh'
Mar  1 14:41:19.938: INFO: stderr: ""
Mar  1 14:41:19.938: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Mar  1 14:41:19.938: INFO: validating pod update-demo-nautilus-64688
Mar  1 14:41:19.949: INFO: got data: {
  "image": "nautilus.jpg"
}

Mar  1 14:41:19.949: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Mar  1 14:41:19.949: INFO: update-demo-nautilus-64688 is verified up and running
Mar  1 14:41:19.949: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-210205575 get pods update-demo-nautilus-q9wnv -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-qcvbh'
Mar  1 14:41:20.027: INFO: stderr: ""
Mar  1 14:41:20.027: INFO: stdout: "true"
Mar  1 14:41:20.027: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-210205575 get pods update-demo-nautilus-q9wnv -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-qcvbh'
Mar  1 14:41:20.108: INFO: stderr: ""
Mar  1 14:41:20.108: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Mar  1 14:41:20.108: INFO: validating pod update-demo-nautilus-q9wnv
Mar  1 14:41:20.116: INFO: got data: {
  "image": "nautilus.jpg"
}

Mar  1 14:41:20.117: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Mar  1 14:41:20.117: INFO: update-demo-nautilus-q9wnv is verified up and running
STEP: using delete to clean up resources
Mar  1 14:41:20.117: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-210205575 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-qcvbh'
Mar  1 14:41:20.204: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Mar  1 14:41:20.204: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Mar  1 14:41:20.204: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-210205575 get rc,svc -l name=update-demo --no-headers --namespace=e2e-tests-kubectl-qcvbh'
Mar  1 14:41:20.296: INFO: stderr: "No resources found.\n"
Mar  1 14:41:20.296: INFO: stdout: ""
Mar  1 14:41:20.296: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-210205575 get pods -l name=update-demo --namespace=e2e-tests-kubectl-qcvbh -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Mar  1 14:41:20.379: INFO: stderr: ""
Mar  1 14:41:20.379: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 14:41:20.379: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-qcvbh" for this suite.
Mar  1 14:41:42.395: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 14:41:42.607: INFO: namespace: e2e-tests-kubectl-qcvbh, resource: bindings, ignored listing per whitelist
Mar  1 14:41:42.617: INFO: namespace e2e-tests-kubectl-qcvbh deletion completed in 22.233199098s

• [SLOW TEST:28.693 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Update Demo
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create and stop a replication controller  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Projected 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 14:41:42.617: INFO: >>> kubeConfig: /tmp/kubeconfig-210205575
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name s-test-opt-del-215995a1-3c30-11e9-a154-0a580a280202
STEP: Creating secret with name s-test-opt-upd-215995e6-3c30-11e9-a154-0a580a280202
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-215995a1-3c30-11e9-a154-0a580a280202
STEP: Updating secret s-test-opt-upd-215995e6-3c30-11e9-a154-0a580a280202
STEP: Creating secret with name s-test-opt-create-215995fb-3c30-11e9-a154-0a580a280202
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 14:41:46.841: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-chkcw" for this suite.
Mar  1 14:42:08.858: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 14:42:08.948: INFO: namespace: e2e-tests-projected-chkcw, resource: bindings, ignored listing per whitelist
Mar  1 14:42:09.072: INFO: namespace e2e-tests-projected-chkcw deletion completed in 22.22648s

• [SLOW TEST:26.455 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 14:42:09.072: INFO: >>> kubeConfig: /tmp/kubeconfig-210205575
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test substitution in container's command
Mar  1 14:42:09.272: INFO: Waiting up to 5m0s for pod "var-expansion-312b91f6-3c30-11e9-a154-0a580a280202" in namespace "e2e-tests-var-expansion-pb6sf" to be "success or failure"
Mar  1 14:42:09.283: INFO: Pod "var-expansion-312b91f6-3c30-11e9-a154-0a580a280202": Phase="Pending", Reason="", readiness=false. Elapsed: 11.172187ms
Mar  1 14:42:11.290: INFO: Pod "var-expansion-312b91f6-3c30-11e9-a154-0a580a280202": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.017930836s
STEP: Saw pod success
Mar  1 14:42:11.290: INFO: Pod "var-expansion-312b91f6-3c30-11e9-a154-0a580a280202" satisfied condition "success or failure"
Mar  1 14:42:11.293: INFO: Trying to get logs from node gke-conformance-default-pool-eca581b0-czl4 pod var-expansion-312b91f6-3c30-11e9-a154-0a580a280202 container dapi-container: <nil>
STEP: delete the pod
Mar  1 14:42:11.315: INFO: Waiting for pod var-expansion-312b91f6-3c30-11e9-a154-0a580a280202 to disappear
Mar  1 14:42:11.320: INFO: Pod var-expansion-312b91f6-3c30-11e9-a154-0a580a280202 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 14:42:11.320: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-var-expansion-pb6sf" for this suite.
Mar  1 14:42:17.334: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 14:42:17.402: INFO: namespace: e2e-tests-var-expansion-pb6sf, resource: bindings, ignored listing per whitelist
Mar  1 14:42:17.488: INFO: namespace e2e-tests-var-expansion-pb6sf deletion completed in 6.164648981s

• [SLOW TEST:8.416 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Projected 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 14:42:17.488: INFO: >>> kubeConfig: /tmp/kubeconfig-210205575
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Mar  1 14:42:17.617: INFO: Waiting up to 5m0s for pod "downwardapi-volume-3625686b-3c30-11e9-a154-0a580a280202" in namespace "e2e-tests-projected-7rv9l" to be "success or failure"
Mar  1 14:42:17.623: INFO: Pod "downwardapi-volume-3625686b-3c30-11e9-a154-0a580a280202": Phase="Pending", Reason="", readiness=false. Elapsed: 6.107346ms
Mar  1 14:42:19.627: INFO: Pod "downwardapi-volume-3625686b-3c30-11e9-a154-0a580a280202": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010272617s
STEP: Saw pod success
Mar  1 14:42:19.627: INFO: Pod "downwardapi-volume-3625686b-3c30-11e9-a154-0a580a280202" satisfied condition "success or failure"
Mar  1 14:42:19.631: INFO: Trying to get logs from node gke-conformance-default-pool-eca581b0-czl4 pod downwardapi-volume-3625686b-3c30-11e9-a154-0a580a280202 container client-container: <nil>
STEP: delete the pod
Mar  1 14:42:19.656: INFO: Waiting for pod downwardapi-volume-3625686b-3c30-11e9-a154-0a580a280202 to disappear
Mar  1 14:42:19.666: INFO: Pod downwardapi-volume-3625686b-3c30-11e9-a154-0a580a280202 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 14:42:19.666: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-7rv9l" for this suite.
Mar  1 14:42:25.682: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 14:42:25.798: INFO: namespace: e2e-tests-projected-7rv9l, resource: bindings, ignored listing per whitelist
Mar  1 14:42:25.817: INFO: namespace e2e-tests-projected-7rv9l deletion completed in 6.146360427s

• [SLOW TEST:8.329 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 14:42:25.817: INFO: >>> kubeConfig: /tmp/kubeconfig-210205575
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:83
[It] should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating service endpoint-test2 in namespace e2e-tests-services-68bsz
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-68bsz to expose endpoints map[]
Mar  1 14:42:25.937: INFO: Get endpoints failed (5.399605ms elapsed, ignoring for 5s): endpoints "endpoint-test2" not found
Mar  1 14:42:26.941: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-68bsz exposes endpoints map[] (1.009036158s elapsed)
STEP: Creating pod pod1 in namespace e2e-tests-services-68bsz
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-68bsz to expose endpoints map[pod1:[80]]
Mar  1 14:42:30.136: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-68bsz exposes endpoints map[pod1:[80]] (3.180008007s elapsed)
STEP: Creating pod pod2 in namespace e2e-tests-services-68bsz
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-68bsz to expose endpoints map[pod1:[80] pod2:[80]]
Mar  1 14:42:33.349: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-68bsz exposes endpoints map[pod2:[80] pod1:[80]] (3.043924413s elapsed)
STEP: Deleting pod pod1 in namespace e2e-tests-services-68bsz
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-68bsz to expose endpoints map[pod2:[80]]
Mar  1 14:42:34.375: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-68bsz exposes endpoints map[pod2:[80]] (1.019536657s elapsed)
STEP: Deleting pod pod2 in namespace e2e-tests-services-68bsz
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-68bsz to expose endpoints map[]
Mar  1 14:42:34.399: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-68bsz exposes endpoints map[] (17.398037ms elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 14:42:34.418: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-services-68bsz" for this suite.
Mar  1 14:42:56.433: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 14:42:56.518: INFO: namespace: e2e-tests-services-68bsz, resource: bindings, ignored listing per whitelist
Mar  1 14:42:56.554: INFO: namespace e2e-tests-services-68bsz deletion completed in 22.131532978s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:88

• [SLOW TEST:30.737 seconds]
[sig-network] Services
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] version v1
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 14:42:56.554: INFO: >>> kubeConfig: /tmp/kubeconfig-210205575
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Mar  1 14:42:56.668: INFO: (0) /api/v1/nodes/gke-conformance-default-pool-eca581b0-00fq:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="cloud-init.log">cloud-init.log</a>
<a href="containers/">c... (200; 8.897907ms)
Mar  1 14:42:56.673: INFO: (1) /api/v1/nodes/gke-conformance-default-pool-eca581b0-00fq:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="cloud-init.log">cloud-init.log</a>
<a href="containers/">c... (200; 4.998714ms)
Mar  1 14:42:56.679: INFO: (2) /api/v1/nodes/gke-conformance-default-pool-eca581b0-00fq:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="cloud-init.log">cloud-init.log</a>
<a href="containers/">c... (200; 5.897084ms)
Mar  1 14:42:56.687: INFO: (3) /api/v1/nodes/gke-conformance-default-pool-eca581b0-00fq:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="cloud-init.log">cloud-init.log</a>
<a href="containers/">c... (200; 7.958422ms)
Mar  1 14:42:56.692: INFO: (4) /api/v1/nodes/gke-conformance-default-pool-eca581b0-00fq:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="cloud-init.log">cloud-init.log</a>
<a href="containers/">c... (200; 5.239953ms)
Mar  1 14:42:56.697: INFO: (5) /api/v1/nodes/gke-conformance-default-pool-eca581b0-00fq:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="cloud-init.log">cloud-init.log</a>
<a href="containers/">c... (200; 4.83697ms)
Mar  1 14:42:56.705: INFO: (6) /api/v1/nodes/gke-conformance-default-pool-eca581b0-00fq:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="cloud-init.log">cloud-init.log</a>
<a href="containers/">c... (200; 8.301376ms)
Mar  1 14:42:56.716: INFO: (7) /api/v1/nodes/gke-conformance-default-pool-eca581b0-00fq:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="cloud-init.log">cloud-init.log</a>
<a href="containers/">c... (200; 10.697962ms)
Mar  1 14:42:56.721: INFO: (8) /api/v1/nodes/gke-conformance-default-pool-eca581b0-00fq:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="cloud-init.log">cloud-init.log</a>
<a href="containers/">c... (200; 4.741886ms)
Mar  1 14:42:56.726: INFO: (9) /api/v1/nodes/gke-conformance-default-pool-eca581b0-00fq:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="cloud-init.log">cloud-init.log</a>
<a href="containers/">c... (200; 5.158354ms)
Mar  1 14:42:56.731: INFO: (10) /api/v1/nodes/gke-conformance-default-pool-eca581b0-00fq:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="cloud-init.log">cloud-init.log</a>
<a href="containers/">c... (200; 5.267547ms)
Mar  1 14:42:56.736: INFO: (11) /api/v1/nodes/gke-conformance-default-pool-eca581b0-00fq:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="cloud-init.log">cloud-init.log</a>
<a href="containers/">c... (200; 4.771381ms)
Mar  1 14:42:56.741: INFO: (12) /api/v1/nodes/gke-conformance-default-pool-eca581b0-00fq:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="cloud-init.log">cloud-init.log</a>
<a href="containers/">c... (200; 4.638382ms)
Mar  1 14:42:56.746: INFO: (13) /api/v1/nodes/gke-conformance-default-pool-eca581b0-00fq:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="cloud-init.log">cloud-init.log</a>
<a href="containers/">c... (200; 4.98118ms)
Mar  1 14:42:56.753: INFO: (14) /api/v1/nodes/gke-conformance-default-pool-eca581b0-00fq:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="cloud-init.log">cloud-init.log</a>
<a href="containers/">c... (200; 7.631294ms)
Mar  1 14:42:56.758: INFO: (15) /api/v1/nodes/gke-conformance-default-pool-eca581b0-00fq:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="cloud-init.log">cloud-init.log</a>
<a href="containers/">c... (200; 5.088232ms)
Mar  1 14:42:56.764: INFO: (16) /api/v1/nodes/gke-conformance-default-pool-eca581b0-00fq:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="cloud-init.log">cloud-init.log</a>
<a href="containers/">c... (200; 5.203032ms)
Mar  1 14:42:56.768: INFO: (17) /api/v1/nodes/gke-conformance-default-pool-eca581b0-00fq:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="cloud-init.log">cloud-init.log</a>
<a href="containers/">c... (200; 4.631557ms)
Mar  1 14:42:56.774: INFO: (18) /api/v1/nodes/gke-conformance-default-pool-eca581b0-00fq:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="cloud-init.log">cloud-init.log</a>
<a href="containers/">c... (200; 5.446018ms)
Mar  1 14:42:56.784: INFO: (19) /api/v1/nodes/gke-conformance-default-pool-eca581b0-00fq:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="cloud-init.log">cloud-init.log</a>
<a href="containers/">c... (200; 10.418316ms)
[AfterEach] version v1
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 14:42:56.784: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-proxy-rpn79" for this suite.
Mar  1 14:43:02.815: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 14:43:02.912: INFO: namespace: e2e-tests-proxy-rpn79, resource: bindings, ignored listing per whitelist
Mar  1 14:43:02.980: INFO: namespace e2e-tests-proxy-rpn79 deletion completed in 6.192347722s

• [SLOW TEST:6.427 seconds]
[sig-network] Proxy
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl patch 
  should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 14:43:02.981: INFO: >>> kubeConfig: /tmp/kubeconfig-210205575
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating Redis RC
Mar  1 14:43:03.063: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-210205575 create -f - --namespace=e2e-tests-kubectl-hfl9j'
Mar  1 14:43:03.251: INFO: stderr: ""
Mar  1 14:43:03.251: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
Mar  1 14:43:04.318: INFO: Selector matched 1 pods for map[app:redis]
Mar  1 14:43:04.318: INFO: Found 0 / 1
Mar  1 14:43:05.371: INFO: Selector matched 1 pods for map[app:redis]
Mar  1 14:43:05.371: INFO: Found 1 / 1
Mar  1 14:43:05.371: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
STEP: patching all pods
Mar  1 14:43:05.472: INFO: Selector matched 1 pods for map[app:redis]
Mar  1 14:43:05.472: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Mar  1 14:43:05.472: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-210205575 patch pod redis-master-xm25m --namespace=e2e-tests-kubectl-hfl9j -p {"metadata":{"annotations":{"x":"y"}}}'
Mar  1 14:43:05.741: INFO: stderr: ""
Mar  1 14:43:05.741: INFO: stdout: "pod/redis-master-xm25m patched\n"
STEP: checking annotations
Mar  1 14:43:05.799: INFO: Selector matched 1 pods for map[app:redis]
Mar  1 14:43:05.799: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 14:43:05.799: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-hfl9j" for this suite.
Mar  1 14:43:28.084: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 14:43:28.158: INFO: namespace: e2e-tests-kubectl-hfl9j, resource: bindings, ignored listing per whitelist
Mar  1 14:43:28.213: INFO: namespace e2e-tests-kubectl-hfl9j deletion completed in 22.333703927s

• [SLOW TEST:25.232 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl patch
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should add annotations for pods in rc  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-apps] Deployment 
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 14:43:28.213: INFO: >>> kubeConfig: /tmp/kubeconfig-210205575
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Mar  1 14:43:28.404: INFO: Creating replica set "test-rolling-update-controller" (going to be adopted)
Mar  1 14:43:28.417: INFO: Pod name sample-pod: Found 0 pods out of 1
Mar  1 14:43:33.422: INFO: Pod name sample-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Mar  1 14:43:33.422: INFO: Creating deployment "test-rolling-update-deployment"
Mar  1 14:43:33.428: INFO: Ensuring deployment "test-rolling-update-deployment" gets the next revision from the one the adopted replica set "test-rolling-update-controller" has
Mar  1 14:43:33.439: INFO: new replicaset for deployment "test-rolling-update-deployment" is yet to be created
Mar  1 14:43:35.446: INFO: Ensuring status for deployment "test-rolling-update-deployment" is the expected
Mar  1 14:43:35.449: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:2, UpdatedReplicas:1, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63687048213, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63687048213, loc:(*time.Location)(0x6c43b60)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63687048213, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63687048213, loc:(*time.Location)(0x6c43b60)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rolling-update-deployment-65b7695dcf\" is progressing."}}, CollisionCount:(*int32)(nil)}
Mar  1 14:43:37.453: INFO: Ensuring deployment "test-rolling-update-deployment" has one old replica set (the one it adopted)
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Mar  1 14:43:37.464: INFO: Deployment "test-rolling-update-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment,GenerateName:,Namespace:e2e-tests-deployment-4vthd,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-4vthd/deployments/test-rolling-update-deployment,UID:635673b4-3c30-11e9-83c3-42010a800094,ResourceVersion:21063,Generation:1,CreationTimestamp:2019-03-01 14:43:33 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,},Annotations:map[string]string{deployment.kubernetes.io/revision: 3546343826724305833,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[{Available True 2019-03-01 14:43:33 +0000 UTC 2019-03-01 14:43:33 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2019-03-01 14:43:36 +0000 UTC 2019-03-01 14:43:33 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-rolling-update-deployment-65b7695dcf" has successfully progressed.}],ReadyReplicas:1,CollisionCount:nil,},}

Mar  1 14:43:37.467: INFO: New ReplicaSet "test-rolling-update-deployment-65b7695dcf" of Deployment "test-rolling-update-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment-65b7695dcf,GenerateName:,Namespace:e2e-tests-deployment-4vthd,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-4vthd/replicasets/test-rolling-update-deployment-65b7695dcf,UID:635a511f-3c30-11e9-83c3-42010a800094,ResourceVersion:21055,Generation:1,CreationTimestamp:2019-03-01 14:43:33 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 65b7695dcf,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 3546343826724305833,},OwnerReferences:[{apps/v1 Deployment test-rolling-update-deployment 635673b4-3c30-11e9-83c3-42010a800094 0xc421fe2997 0xc421fe2998}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod-template-hash: 65b7695dcf,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 65b7695dcf,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Mar  1 14:43:37.467: INFO: All old ReplicaSets of Deployment "test-rolling-update-deployment":
Mar  1 14:43:37.467: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-controller,GenerateName:,Namespace:e2e-tests-deployment-4vthd,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-4vthd/replicasets/test-rolling-update-controller,UID:6058da06-3c30-11e9-83c3-42010a800094,ResourceVersion:21062,Generation:2,CreationTimestamp:2019-03-01 14:43:28 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod: nginx,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 3546343826724305832,},OwnerReferences:[{apps/v1 Deployment test-rolling-update-deployment 635673b4-3c30-11e9-83c3-42010a800094 0xc421fe280e 0xc421fe280f}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Mar  1 14:43:37.471: INFO: Pod "test-rolling-update-deployment-65b7695dcf-tqlj4" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment-65b7695dcf-tqlj4,GenerateName:test-rolling-update-deployment-65b7695dcf-,Namespace:e2e-tests-deployment-4vthd,SelfLink:/api/v1/namespaces/e2e-tests-deployment-4vthd/pods/test-rolling-update-deployment-65b7695dcf-tqlj4,UID:635b1f45-3c30-11e9-83c3-42010a800094,ResourceVersion:21054,Generation:0,CreationTimestamp:2019-03-01 14:43:33 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 65b7695dcf,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet test-rolling-update-deployment-65b7695dcf 635a511f-3c30-11e9-83c3-42010a800094 0xc421fe3477 0xc421fe3478}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-z7rp7 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-z7rp7,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-z7rp7 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:gke-conformance-default-pool-eca581b0-czl4,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc421fe34e0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421fe3500}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 14:43:33 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 14:43:36 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 14:43:36 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 14:43:33 +0000 UTC  }],Message:,Reason:,HostIP:10.128.0.14,PodIP:10.40.4.129,StartTime:2019-03-01 14:43:33 +0000 UTC,ContainerStatuses:[{redis {nil ContainerStateRunning{StartedAt:2019-03-01 14:43:35 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/redis:1.0 docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830 docker://30aeafb82ad66b5981d119ecefb8eb0a419f783b2572e020933002d0796b324a}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 14:43:37.471: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-4vthd" for this suite.
Mar  1 14:43:43.487: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 14:43:43.589: INFO: namespace: e2e-tests-deployment-4vthd, resource: bindings, ignored listing per whitelist
Mar  1 14:43:43.639: INFO: namespace e2e-tests-deployment-4vthd deletion completed in 6.164068077s

• [SLOW TEST:15.426 seconds]
[sig-apps] Deployment
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-api-machinery] Garbage collector 
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 14:43:43.639: INFO: >>> kubeConfig: /tmp/kubeconfig-210205575
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for all rs to be garbage collected
STEP: expected 0 rs, got 1 rs
STEP: expected 0 pods, got 2 pods
STEP: Gathering metrics
W0301 14:43:44.818006      19 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Mar  1 14:43:44.818: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 14:43:44.818: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-z8vjj" for this suite.
Mar  1 14:43:50.842: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 14:43:50.907: INFO: namespace: e2e-tests-gc-z8vjj, resource: bindings, ignored listing per whitelist
Mar  1 14:43:50.963: INFO: namespace e2e-tests-gc-z8vjj deletion completed in 6.134553672s

• [SLOW TEST:7.324 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 14:43:50.963: INFO: >>> kubeConfig: /tmp/kubeconfig-210205575
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name cm-test-opt-del-6dd89f2f-3c30-11e9-a154-0a580a280202
STEP: Creating configMap with name cm-test-opt-upd-6dd89f66-3c30-11e9-a154-0a580a280202
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-6dd89f2f-3c30-11e9-a154-0a580a280202
STEP: Updating configmap cm-test-opt-upd-6dd89f66-3c30-11e9-a154-0a580a280202
STEP: Creating configMap with name cm-test-opt-create-6dd89f76-3c30-11e9-a154-0a580a280202
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 14:43:55.174: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-8jndt" for this suite.
Mar  1 14:44:17.197: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 14:44:17.224: INFO: namespace: e2e-tests-configmap-8jndt, resource: bindings, ignored listing per whitelist
Mar  1 14:44:17.324: INFO: namespace e2e-tests-configmap-8jndt deletion completed in 22.145975866s

• [SLOW TEST:26.361 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Downward API volume 
  should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 14:44:17.324: INFO: >>> kubeConfig: /tmp/kubeconfig-210205575
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Mar  1 14:44:17.428: INFO: Waiting up to 5m0s for pod "downwardapi-volume-7d9038b7-3c30-11e9-a154-0a580a280202" in namespace "e2e-tests-downward-api-n5qzk" to be "success or failure"
Mar  1 14:44:17.437: INFO: Pod "downwardapi-volume-7d9038b7-3c30-11e9-a154-0a580a280202": Phase="Pending", Reason="", readiness=false. Elapsed: 8.815812ms
Mar  1 14:44:19.440: INFO: Pod "downwardapi-volume-7d9038b7-3c30-11e9-a154-0a580a280202": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.012530352s
STEP: Saw pod success
Mar  1 14:44:19.441: INFO: Pod "downwardapi-volume-7d9038b7-3c30-11e9-a154-0a580a280202" satisfied condition "success or failure"
Mar  1 14:44:19.443: INFO: Trying to get logs from node gke-conformance-default-pool-eca581b0-sww9 pod downwardapi-volume-7d9038b7-3c30-11e9-a154-0a580a280202 container client-container: <nil>
STEP: delete the pod
Mar  1 14:44:19.468: INFO: Waiting for pod downwardapi-volume-7d9038b7-3c30-11e9-a154-0a580a280202 to disappear
Mar  1 14:44:19.472: INFO: Pod downwardapi-volume-7d9038b7-3c30-11e9-a154-0a580a280202 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 14:44:19.472: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-n5qzk" for this suite.
Mar  1 14:44:25.486: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 14:44:25.521: INFO: namespace: e2e-tests-downward-api-n5qzk, resource: bindings, ignored listing per whitelist
Mar  1 14:44:25.645: INFO: namespace e2e-tests-downward-api-n5qzk deletion completed in 6.169574048s

• [SLOW TEST:8.321 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] [sig-node] PreStop 
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 14:44:25.646: INFO: >>> kubeConfig: /tmp/kubeconfig-210205575
STEP: Building a namespace api object, basename prestop
STEP: Waiting for a default service account to be provisioned in namespace
[It] should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating server pod server in namespace e2e-tests-prestop-4dtll
STEP: Waiting for pods to come up.
STEP: Creating tester pod tester in namespace e2e-tests-prestop-4dtll
STEP: Deleting pre-stop pod
Mar  1 14:44:36.789: INFO: Saw: {
	"Hostname": "server",
	"Sent": null,
	"Received": {
		"prestop": 1
	},
	"Errors": null,
	"Log": [
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up."
	],
	"StillContactingPeers": true
}
STEP: Deleting the server pod
[AfterEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 14:44:36.799: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-prestop-4dtll" for this suite.
Mar  1 14:45:16.846: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 14:45:16.961: INFO: namespace: e2e-tests-prestop-4dtll, resource: bindings, ignored listing per whitelist
Mar  1 14:45:16.997: INFO: namespace e2e-tests-prestop-4dtll deletion completed in 40.183551225s

• [SLOW TEST:51.351 seconds]
[k8s.io] [sig-node] PreStop
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Burst scaling should run to completion even with unhealthy pods [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 14:45:16.997: INFO: >>> kubeConfig: /tmp/kubeconfig-210205575
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-6x647
[It] Burst scaling should run to completion even with unhealthy pods [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating stateful set ss in namespace e2e-tests-statefulset-6x647
STEP: Waiting until all stateful set ss replicas will be running in namespace e2e-tests-statefulset-6x647
Mar  1 14:45:17.122: INFO: Found 0 stateful pods, waiting for 1
Mar  1 14:45:27.126: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will not halt with unhealthy stateful pod
Mar  1 14:45:27.129: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-210205575 exec --namespace=e2e-tests-statefulset-6x647 ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Mar  1 14:45:27.290: INFO: stderr: ""
Mar  1 14:45:27.290: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Mar  1 14:45:27.290: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Mar  1 14:45:27.294: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Mar  1 14:45:37.299: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Mar  1 14:45:37.299: INFO: Waiting for statefulset status.replicas updated to 0
Mar  1 14:45:37.322: INFO: POD   NODE                                        PHASE    GRACE  CONDITIONS
Mar  1 14:45:37.322: INFO: ss-0  gke-conformance-default-pool-eca581b0-sww9  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 14:45:17 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-01 14:45:27 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-01 14:45:27 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 14:45:17 +0000 UTC  }]
Mar  1 14:45:37.322: INFO: 
Mar  1 14:45:37.322: INFO: StatefulSet ss has not reached scale 3, at 1
Mar  1 14:45:38.327: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.991020974s
Mar  1 14:45:39.333: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.985830584s
Mar  1 14:45:40.338: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.980608083s
Mar  1 14:45:41.344: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.975429832s
Mar  1 14:45:42.348: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.969334726s
Mar  1 14:45:43.353: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.965062045s
Mar  1 14:45:44.357: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.960686925s
Mar  1 14:45:45.362: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.956549968s
Mar  1 14:45:46.368: INFO: Verifying statefulset ss doesn't scale past 3 for another 949.35206ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace e2e-tests-statefulset-6x647
Mar  1 14:45:47.373: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-210205575 exec --namespace=e2e-tests-statefulset-6x647 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar  1 14:45:47.542: INFO: stderr: ""
Mar  1 14:45:47.542: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Mar  1 14:45:47.542: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Mar  1 14:45:47.542: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-210205575 exec --namespace=e2e-tests-statefulset-6x647 ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar  1 14:45:47.730: INFO: stderr: "mv: can't rename '/tmp/index.html': No such file or directory\n"
Mar  1 14:45:47.730: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Mar  1 14:45:47.730: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Mar  1 14:45:47.730: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-210205575 exec --namespace=e2e-tests-statefulset-6x647 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Mar  1 14:45:47.900: INFO: stderr: "mv: can't rename '/tmp/index.html': No such file or directory\n"
Mar  1 14:45:47.900: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Mar  1 14:45:47.900: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-2: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Mar  1 14:45:47.904: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Mar  1 14:45:47.904: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Mar  1 14:45:47.904: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Scale down will not halt with unhealthy stateful pod
Mar  1 14:45:47.908: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-210205575 exec --namespace=e2e-tests-statefulset-6x647 ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Mar  1 14:45:48.080: INFO: stderr: ""
Mar  1 14:45:48.080: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Mar  1 14:45:48.080: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Mar  1 14:45:48.080: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-210205575 exec --namespace=e2e-tests-statefulset-6x647 ss-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Mar  1 14:45:48.250: INFO: stderr: ""
Mar  1 14:45:48.250: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Mar  1 14:45:48.250: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Mar  1 14:45:48.250: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-210205575 exec --namespace=e2e-tests-statefulset-6x647 ss-2 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Mar  1 14:45:48.423: INFO: stderr: ""
Mar  1 14:45:48.423: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Mar  1 14:45:48.423: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-2: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Mar  1 14:45:48.423: INFO: Waiting for statefulset status.replicas updated to 0
Mar  1 14:45:48.427: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 3
Mar  1 14:45:58.435: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Mar  1 14:45:58.435: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Mar  1 14:45:58.435: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Mar  1 14:45:58.450: INFO: POD   NODE                                        PHASE    GRACE  CONDITIONS
Mar  1 14:45:58.450: INFO: ss-0  gke-conformance-default-pool-eca581b0-sww9  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 14:45:17 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-01 14:45:48 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-01 14:45:48 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 14:45:17 +0000 UTC  }]
Mar  1 14:45:58.450: INFO: ss-1  gke-conformance-default-pool-eca581b0-sqmc  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 14:45:37 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-01 14:45:48 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-01 14:45:48 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 14:45:37 +0000 UTC  }]
Mar  1 14:45:58.450: INFO: ss-2  gke-conformance-default-pool-eca581b0-czl4  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 14:45:37 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-01 14:45:49 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-01 14:45:49 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 14:45:37 +0000 UTC  }]
Mar  1 14:45:58.450: INFO: 
Mar  1 14:45:58.450: INFO: StatefulSet ss has not reached scale 0, at 3
Mar  1 14:45:59.454: INFO: POD   NODE                                        PHASE    GRACE  CONDITIONS
Mar  1 14:45:59.454: INFO: ss-0  gke-conformance-default-pool-eca581b0-sww9  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 14:45:17 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-01 14:45:48 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-01 14:45:48 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 14:45:17 +0000 UTC  }]
Mar  1 14:45:59.455: INFO: ss-1  gke-conformance-default-pool-eca581b0-sqmc  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 14:45:37 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-01 14:45:48 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-01 14:45:48 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 14:45:37 +0000 UTC  }]
Mar  1 14:45:59.455: INFO: ss-2  gke-conformance-default-pool-eca581b0-czl4  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 14:45:37 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-01 14:45:49 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-01 14:45:49 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 14:45:37 +0000 UTC  }]
Mar  1 14:45:59.455: INFO: 
Mar  1 14:45:59.455: INFO: StatefulSet ss has not reached scale 0, at 3
Mar  1 14:46:00.458: INFO: POD   NODE                                        PHASE    GRACE  CONDITIONS
Mar  1 14:46:00.458: INFO: ss-1  gke-conformance-default-pool-eca581b0-sqmc  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 14:45:37 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-03-01 14:45:48 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-03-01 14:45:48 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-03-01 14:45:37 +0000 UTC  }]
Mar  1 14:46:00.458: INFO: 
Mar  1 14:46:00.458: INFO: StatefulSet ss has not reached scale 0, at 1
Mar  1 14:46:01.463: INFO: Verifying statefulset ss doesn't scale past 0 for another 6.987868316s
Mar  1 14:46:02.466: INFO: Verifying statefulset ss doesn't scale past 0 for another 5.983710818s
Mar  1 14:46:03.471: INFO: Verifying statefulset ss doesn't scale past 0 for another 4.979692102s
Mar  1 14:46:04.474: INFO: Verifying statefulset ss doesn't scale past 0 for another 3.975694354s
Mar  1 14:46:05.478: INFO: Verifying statefulset ss doesn't scale past 0 for another 2.972250405s
Mar  1 14:46:06.482: INFO: Verifying statefulset ss doesn't scale past 0 for another 1.968447977s
Mar  1 14:46:07.486: INFO: Verifying statefulset ss doesn't scale past 0 for another 964.534655ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacee2e-tests-statefulset-6x647
Mar  1 14:46:08.489: INFO: Scaling statefulset ss to 0
Mar  1 14:46:08.501: INFO: Waiting for statefulset status.replicas updated to 0
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Mar  1 14:46:08.503: INFO: Deleting all statefulset in ns e2e-tests-statefulset-6x647
Mar  1 14:46:08.507: INFO: Scaling statefulset ss to 0
Mar  1 14:46:08.519: INFO: Waiting for statefulset status.replicas updated to 0
Mar  1 14:46:08.522: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 14:46:08.540: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-6x647" for this suite.
Mar  1 14:46:14.563: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 14:46:14.607: INFO: namespace: e2e-tests-statefulset-6x647, resource: bindings, ignored listing per whitelist
Mar  1 14:46:14.777: INFO: namespace e2e-tests-statefulset-6x647 deletion completed in 6.230883939s

• [SLOW TEST:57.780 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    Burst scaling should run to completion even with unhealthy pods [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 14:46:14.777: INFO: >>> kubeConfig: /tmp/kubeconfig-210205575
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-map-c40548d5-3c30-11e9-a154-0a580a280202
STEP: Creating a pod to test consume secrets
Mar  1 14:46:15.647: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-c40604fd-3c30-11e9-a154-0a580a280202" in namespace "e2e-tests-projected-cgfr7" to be "success or failure"
Mar  1 14:46:15.658: INFO: Pod "pod-projected-secrets-c40604fd-3c30-11e9-a154-0a580a280202": Phase="Pending", Reason="", readiness=false. Elapsed: 11.1816ms
Mar  1 14:46:17.662: INFO: Pod "pod-projected-secrets-c40604fd-3c30-11e9-a154-0a580a280202": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.015024207s
STEP: Saw pod success
Mar  1 14:46:17.662: INFO: Pod "pod-projected-secrets-c40604fd-3c30-11e9-a154-0a580a280202" satisfied condition "success or failure"
Mar  1 14:46:17.665: INFO: Trying to get logs from node gke-conformance-default-pool-eca581b0-sww9 pod pod-projected-secrets-c40604fd-3c30-11e9-a154-0a580a280202 container projected-secret-volume-test: <nil>
STEP: delete the pod
Mar  1 14:46:17.688: INFO: Waiting for pod pod-projected-secrets-c40604fd-3c30-11e9-a154-0a580a280202 to disappear
Mar  1 14:46:17.691: INFO: Pod pod-projected-secrets-c40604fd-3c30-11e9-a154-0a580a280202 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 14:46:17.691: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-cgfr7" for this suite.
Mar  1 14:46:23.711: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 14:46:23.792: INFO: namespace: e2e-tests-projected-cgfr7, resource: bindings, ignored listing per whitelist
Mar  1 14:46:23.838: INFO: namespace e2e-tests-projected-cgfr7 deletion completed in 6.140771526s

• [SLOW TEST:9.061 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 14:46:23.838: INFO: >>> kubeConfig: /tmp/kubeconfig-210205575
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the rs
STEP: Gathering metrics
W0301 14:46:54.478010      19 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Mar  1 14:46:54.478: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 14:46:54.478: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-hvgg2" for this suite.
Mar  1 14:47:02.492: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 14:47:02.608: INFO: namespace: e2e-tests-gc-hvgg2, resource: bindings, ignored listing per whitelist
Mar  1 14:47:02.676: INFO: namespace e2e-tests-gc-hvgg2 deletion completed in 8.193981687s

• [SLOW TEST:38.837 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 14:47:02.676: INFO: >>> kubeConfig: /tmp/kubeconfig-210205575
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:293
[It] should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the initial replication controller
Mar  1 14:47:02.777: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-210205575 create -f - --namespace=e2e-tests-kubectl-twzx2'
Mar  1 14:47:02.982: INFO: stderr: ""
Mar  1 14:47:02.982: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Mar  1 14:47:02.982: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-210205575 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-twzx2'
Mar  1 14:47:03.105: INFO: stderr: ""
Mar  1 14:47:03.105: INFO: stdout: "update-demo-nautilus-b7sf7 update-demo-nautilus-m5k2h "
Mar  1 14:47:03.105: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-210205575 get pods update-demo-nautilus-b7sf7 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-twzx2'
Mar  1 14:47:03.196: INFO: stderr: ""
Mar  1 14:47:03.196: INFO: stdout: ""
Mar  1 14:47:03.196: INFO: update-demo-nautilus-b7sf7 is created but not running
Mar  1 14:47:08.197: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-210205575 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-twzx2'
Mar  1 14:47:08.285: INFO: stderr: ""
Mar  1 14:47:08.285: INFO: stdout: "update-demo-nautilus-b7sf7 update-demo-nautilus-m5k2h "
Mar  1 14:47:08.285: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-210205575 get pods update-demo-nautilus-b7sf7 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-twzx2'
Mar  1 14:47:08.371: INFO: stderr: ""
Mar  1 14:47:08.371: INFO: stdout: "true"
Mar  1 14:47:08.371: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-210205575 get pods update-demo-nautilus-b7sf7 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-twzx2'
Mar  1 14:47:08.454: INFO: stderr: ""
Mar  1 14:47:08.454: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Mar  1 14:47:08.454: INFO: validating pod update-demo-nautilus-b7sf7
Mar  1 14:47:08.462: INFO: got data: {
  "image": "nautilus.jpg"
}

Mar  1 14:47:08.462: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Mar  1 14:47:08.462: INFO: update-demo-nautilus-b7sf7 is verified up and running
Mar  1 14:47:08.462: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-210205575 get pods update-demo-nautilus-m5k2h -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-twzx2'
Mar  1 14:47:08.544: INFO: stderr: ""
Mar  1 14:47:08.544: INFO: stdout: "true"
Mar  1 14:47:08.544: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-210205575 get pods update-demo-nautilus-m5k2h -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-twzx2'
Mar  1 14:47:08.628: INFO: stderr: ""
Mar  1 14:47:08.628: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Mar  1 14:47:08.628: INFO: validating pod update-demo-nautilus-m5k2h
Mar  1 14:47:08.635: INFO: got data: {
  "image": "nautilus.jpg"
}

Mar  1 14:47:08.635: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Mar  1 14:47:08.635: INFO: update-demo-nautilus-m5k2h is verified up and running
STEP: rolling-update to new replication controller
Mar  1 14:47:08.637: INFO: scanned /root for discovery docs: <nil>
Mar  1 14:47:08.637: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-210205575 rolling-update update-demo-nautilus --update-period=1s -f - --namespace=e2e-tests-kubectl-twzx2'
Mar  1 14:47:31.049: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Mar  1 14:47:31.049: INFO: stdout: "Created update-demo-kitten\nScaling up update-demo-kitten from 0 to 2, scaling down update-demo-nautilus from 2 to 0 (keep 2 pods available, don't exceed 3 pods)\nScaling update-demo-kitten up to 1\nScaling update-demo-nautilus down to 1\nScaling update-demo-kitten up to 2\nScaling update-demo-nautilus down to 0\nUpdate succeeded. Deleting old controller: update-demo-nautilus\nRenaming update-demo-kitten to update-demo-nautilus\nreplicationcontroller/update-demo-nautilus rolling updated\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Mar  1 14:47:31.049: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-210205575 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-twzx2'
Mar  1 14:47:31.179: INFO: stderr: ""
Mar  1 14:47:31.179: INFO: stdout: "update-demo-kitten-hfvxr update-demo-kitten-xnwdl "
Mar  1 14:47:31.179: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-210205575 get pods update-demo-kitten-hfvxr -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-twzx2'
Mar  1 14:47:31.265: INFO: stderr: ""
Mar  1 14:47:31.265: INFO: stdout: "true"
Mar  1 14:47:31.265: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-210205575 get pods update-demo-kitten-hfvxr -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-twzx2'
Mar  1 14:47:31.355: INFO: stderr: ""
Mar  1 14:47:31.355: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
Mar  1 14:47:31.355: INFO: validating pod update-demo-kitten-hfvxr
Mar  1 14:47:31.368: INFO: got data: {
  "image": "kitten.jpg"
}

Mar  1 14:47:31.368: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Mar  1 14:47:31.368: INFO: update-demo-kitten-hfvxr is verified up and running
Mar  1 14:47:31.368: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-210205575 get pods update-demo-kitten-xnwdl -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-twzx2'
Mar  1 14:47:31.459: INFO: stderr: ""
Mar  1 14:47:31.459: INFO: stdout: "true"
Mar  1 14:47:31.459: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-210205575 get pods update-demo-kitten-xnwdl -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-twzx2'
Mar  1 14:47:31.548: INFO: stderr: ""
Mar  1 14:47:31.548: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
Mar  1 14:47:31.548: INFO: validating pod update-demo-kitten-xnwdl
Mar  1 14:47:31.559: INFO: got data: {
  "image": "kitten.jpg"
}

Mar  1 14:47:31.559: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Mar  1 14:47:31.559: INFO: update-demo-kitten-xnwdl is verified up and running
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 14:47:31.559: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-twzx2" for this suite.
Mar  1 14:47:53.579: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 14:47:53.674: INFO: namespace: e2e-tests-kubectl-twzx2, resource: bindings, ignored listing per whitelist
Mar  1 14:47:53.720: INFO: namespace e2e-tests-kubectl-twzx2 deletion completed in 22.156868046s

• [SLOW TEST:51.044 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Update Demo
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should do a rolling update of a replication controller  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 14:47:53.720: INFO: >>> kubeConfig: /tmp/kubeconfig-210205575
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-fe8aba0f-3c30-11e9-a154-0a580a280202
STEP: Creating a pod to test consume configMaps
Mar  1 14:47:53.824: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-fe8b4aa0-3c30-11e9-a154-0a580a280202" in namespace "e2e-tests-projected-lbgcz" to be "success or failure"
Mar  1 14:47:53.833: INFO: Pod "pod-projected-configmaps-fe8b4aa0-3c30-11e9-a154-0a580a280202": Phase="Pending", Reason="", readiness=false. Elapsed: 9.435431ms
Mar  1 14:47:55.837: INFO: Pod "pod-projected-configmaps-fe8b4aa0-3c30-11e9-a154-0a580a280202": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013212552s
Mar  1 14:47:57.840: INFO: Pod "pod-projected-configmaps-fe8b4aa0-3c30-11e9-a154-0a580a280202": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.016859046s
STEP: Saw pod success
Mar  1 14:47:57.840: INFO: Pod "pod-projected-configmaps-fe8b4aa0-3c30-11e9-a154-0a580a280202" satisfied condition "success or failure"
Mar  1 14:47:57.843: INFO: Trying to get logs from node gke-conformance-default-pool-eca581b0-sqmc pod pod-projected-configmaps-fe8b4aa0-3c30-11e9-a154-0a580a280202 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Mar  1 14:47:57.869: INFO: Waiting for pod pod-projected-configmaps-fe8b4aa0-3c30-11e9-a154-0a580a280202 to disappear
Mar  1 14:47:57.876: INFO: Pod pod-projected-configmaps-fe8b4aa0-3c30-11e9-a154-0a580a280202 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 14:47:57.876: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-lbgcz" for this suite.
Mar  1 14:48:03.892: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 14:48:04.864: INFO: namespace: e2e-tests-projected-lbgcz, resource: bindings, ignored listing per whitelist
Mar  1 14:48:06.527: INFO: namespace e2e-tests-projected-lbgcz deletion completed in 8.647362782s

• [SLOW TEST:12.807 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 14:48:06.527: INFO: >>> kubeConfig: /tmp/kubeconfig-210205575
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test override all
Mar  1 14:48:08.133: INFO: Waiting up to 5m0s for pod "client-containers-0712caf8-3c31-11e9-a154-0a580a280202" in namespace "e2e-tests-containers-4cdc6" to be "success or failure"
Mar  1 14:48:08.137: INFO: Pod "client-containers-0712caf8-3c31-11e9-a154-0a580a280202": Phase="Pending", Reason="", readiness=false. Elapsed: 4.275889ms
Mar  1 14:48:10.141: INFO: Pod "client-containers-0712caf8-3c31-11e9-a154-0a580a280202": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008135239s
STEP: Saw pod success
Mar  1 14:48:10.141: INFO: Pod "client-containers-0712caf8-3c31-11e9-a154-0a580a280202" satisfied condition "success or failure"
Mar  1 14:48:10.144: INFO: Trying to get logs from node gke-conformance-default-pool-eca581b0-czl4 pod client-containers-0712caf8-3c31-11e9-a154-0a580a280202 container test-container: <nil>
STEP: delete the pod
Mar  1 14:48:10.170: INFO: Waiting for pod client-containers-0712caf8-3c31-11e9-a154-0a580a280202 to disappear
Mar  1 14:48:10.173: INFO: Pod client-containers-0712caf8-3c31-11e9-a154-0a580a280202 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 14:48:10.173: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-4cdc6" for this suite.
Mar  1 14:48:16.191: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 14:48:16.395: INFO: namespace: e2e-tests-containers-4cdc6, resource: bindings, ignored listing per whitelist
Mar  1 14:48:16.419: INFO: namespace e2e-tests-containers-4cdc6 deletion completed in 6.242403176s

• [SLOW TEST:9.892 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 14:48:16.420: INFO: >>> kubeConfig: /tmp/kubeconfig-210205575
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-map-0c16914c-3c31-11e9-a154-0a580a280202
STEP: Creating a pod to test consume configMaps
Mar  1 14:48:16.554: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-0c176604-3c31-11e9-a154-0a580a280202" in namespace "e2e-tests-projected-svppt" to be "success or failure"
Mar  1 14:48:16.556: INFO: Pod "pod-projected-configmaps-0c176604-3c31-11e9-a154-0a580a280202": Phase="Pending", Reason="", readiness=false. Elapsed: 2.587291ms
Mar  1 14:48:18.560: INFO: Pod "pod-projected-configmaps-0c176604-3c31-11e9-a154-0a580a280202": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006412105s
STEP: Saw pod success
Mar  1 14:48:18.560: INFO: Pod "pod-projected-configmaps-0c176604-3c31-11e9-a154-0a580a280202" satisfied condition "success or failure"
Mar  1 14:48:18.564: INFO: Trying to get logs from node gke-conformance-default-pool-eca581b0-sww9 pod pod-projected-configmaps-0c176604-3c31-11e9-a154-0a580a280202 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Mar  1 14:48:18.588: INFO: Waiting for pod pod-projected-configmaps-0c176604-3c31-11e9-a154-0a580a280202 to disappear
Mar  1 14:48:18.590: INFO: Pod pod-projected-configmaps-0c176604-3c31-11e9-a154-0a580a280202 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 14:48:18.590: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-svppt" for this suite.
Mar  1 14:48:24.605: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 14:48:24.711: INFO: namespace: e2e-tests-projected-svppt, resource: bindings, ignored listing per whitelist
Mar  1 14:48:24.711: INFO: namespace e2e-tests-projected-svppt deletion completed in 6.117385901s

• [SLOW TEST:8.292 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 14:48:24.712: INFO: >>> kubeConfig: /tmp/kubeconfig-210205575
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-1106433e-3c31-11e9-a154-0a580a280202
STEP: Creating a pod to test consume secrets
Mar  1 14:48:24.873: INFO: Waiting up to 5m0s for pod "pod-secrets-110d1cec-3c31-11e9-a154-0a580a280202" in namespace "e2e-tests-secrets-2rbzv" to be "success or failure"
Mar  1 14:48:24.876: INFO: Pod "pod-secrets-110d1cec-3c31-11e9-a154-0a580a280202": Phase="Pending", Reason="", readiness=false. Elapsed: 2.663399ms
Mar  1 14:48:26.880: INFO: Pod "pod-secrets-110d1cec-3c31-11e9-a154-0a580a280202": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006495592s
Mar  1 14:48:28.884: INFO: Pod "pod-secrets-110d1cec-3c31-11e9-a154-0a580a280202": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.0103167s
STEP: Saw pod success
Mar  1 14:48:28.884: INFO: Pod "pod-secrets-110d1cec-3c31-11e9-a154-0a580a280202" satisfied condition "success or failure"
Mar  1 14:48:28.887: INFO: Trying to get logs from node gke-conformance-default-pool-eca581b0-sqmc pod pod-secrets-110d1cec-3c31-11e9-a154-0a580a280202 container secret-volume-test: <nil>
STEP: delete the pod
Mar  1 14:48:28.909: INFO: Waiting for pod pod-secrets-110d1cec-3c31-11e9-a154-0a580a280202 to disappear
Mar  1 14:48:28.913: INFO: Pod pod-secrets-110d1cec-3c31-11e9-a154-0a580a280202 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 14:48:28.913: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-2rbzv" for this suite.
Mar  1 14:48:34.930: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 14:48:35.014: INFO: namespace: e2e-tests-secrets-2rbzv, resource: bindings, ignored listing per whitelist
Mar  1 14:48:35.078: INFO: namespace e2e-tests-secrets-2rbzv deletion completed in 6.160888747s
STEP: Destroying namespace "e2e-tests-secret-namespace-57zzc" for this suite.
Mar  1 14:48:41.094: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 14:48:41.177: INFO: namespace: e2e-tests-secret-namespace-57zzc, resource: bindings, ignored listing per whitelist
Mar  1 14:48:41.209: INFO: namespace e2e-tests-secret-namespace-57zzc deletion completed in 6.131315793s

• [SLOW TEST:16.497 seconds]
[sig-storage] Secrets
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run --rm job 
  should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 14:48:41.209: INFO: >>> kubeConfig: /tmp/kubeconfig-210205575
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: executing a command with run --rm and attach with stdin
Mar  1 14:48:41.304: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-210205575 --namespace=e2e-tests-kubectl-bbqjn run e2e-test-rm-busybox-job --image=docker.io/library/busybox:1.29 --rm=true --generator=job/v1 --restart=OnFailure --attach=true --stdin -- sh -c cat && echo 'stdin closed''
Mar  1 14:48:42.711: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl create instead.\nIf you don't see a command prompt, try pressing enter.\n"
Mar  1 14:48:42.711: INFO: stdout: "abcd1234stdin closed\njob.batch \"e2e-test-rm-busybox-job\" deleted\n"
STEP: verifying the job e2e-test-rm-busybox-job was deleted
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 14:48:44.718: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-bbqjn" for this suite.
Mar  1 14:48:52.735: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 14:48:52.879: INFO: namespace: e2e-tests-kubectl-bbqjn, resource: bindings, ignored listing per whitelist
Mar  1 14:48:52.968: INFO: namespace e2e-tests-kubectl-bbqjn deletion completed in 8.245915125s

• [SLOW TEST:11.759 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run --rm job
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create a job from an image, then delete the job  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 14:48:52.968: INFO: >>> kubeConfig: /tmp/kubeconfig-210205575
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0666 on tmpfs
Mar  1 14:48:53.084: INFO: Waiting up to 5m0s for pod "pod-21ddbbc8-3c31-11e9-a154-0a580a280202" in namespace "e2e-tests-emptydir-cjfww" to be "success or failure"
Mar  1 14:48:53.087: INFO: Pod "pod-21ddbbc8-3c31-11e9-a154-0a580a280202": Phase="Pending", Reason="", readiness=false. Elapsed: 3.180431ms
Mar  1 14:48:55.091: INFO: Pod "pod-21ddbbc8-3c31-11e9-a154-0a580a280202": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006848108s
STEP: Saw pod success
Mar  1 14:48:55.091: INFO: Pod "pod-21ddbbc8-3c31-11e9-a154-0a580a280202" satisfied condition "success or failure"
Mar  1 14:48:55.094: INFO: Trying to get logs from node gke-conformance-default-pool-eca581b0-sww9 pod pod-21ddbbc8-3c31-11e9-a154-0a580a280202 container test-container: <nil>
STEP: delete the pod
Mar  1 14:48:55.121: INFO: Waiting for pod pod-21ddbbc8-3c31-11e9-a154-0a580a280202 to disappear
Mar  1 14:48:55.125: INFO: Pod pod-21ddbbc8-3c31-11e9-a154-0a580a280202 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 14:48:55.125: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-cjfww" for this suite.
Mar  1 14:49:01.139: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 14:49:01.183: INFO: namespace: e2e-tests-emptydir-cjfww, resource: bindings, ignored listing per whitelist
Mar  1 14:49:01.262: INFO: namespace e2e-tests-emptydir-cjfww deletion completed in 6.133924265s

• [SLOW TEST:8.294 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 14:49:01.262: INFO: >>> kubeConfig: /tmp/kubeconfig-210205575
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Mar  1 14:49:07.433: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Mar  1 14:49:07.437: INFO: Pod pod-with-poststart-exec-hook still exists
Mar  1 14:49:09.437: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Mar  1 14:49:09.441: INFO: Pod pod-with-poststart-exec-hook still exists
Mar  1 14:49:11.437: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Mar  1 14:49:11.441: INFO: Pod pod-with-poststart-exec-hook still exists
Mar  1 14:49:13.437: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Mar  1 14:49:13.441: INFO: Pod pod-with-poststart-exec-hook still exists
Mar  1 14:49:15.437: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Mar  1 14:49:15.441: INFO: Pod pod-with-poststart-exec-hook still exists
Mar  1 14:49:17.437: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Mar  1 14:49:17.441: INFO: Pod pod-with-poststart-exec-hook still exists
Mar  1 14:49:19.437: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Mar  1 14:49:19.441: INFO: Pod pod-with-poststart-exec-hook still exists
Mar  1 14:49:21.437: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Mar  1 14:49:21.440: INFO: Pod pod-with-poststart-exec-hook still exists
Mar  1 14:49:23.437: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Mar  1 14:49:23.441: INFO: Pod pod-with-poststart-exec-hook still exists
Mar  1 14:49:25.437: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Mar  1 14:49:25.441: INFO: Pod pod-with-poststart-exec-hook still exists
Mar  1 14:49:27.437: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Mar  1 14:49:27.446: INFO: Pod pod-with-poststart-exec-hook still exists
Mar  1 14:49:29.437: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Mar  1 14:49:29.441: INFO: Pod pod-with-poststart-exec-hook still exists
Mar  1 14:49:31.437: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Mar  1 14:49:31.441: INFO: Pod pod-with-poststart-exec-hook still exists
Mar  1 14:49:33.437: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Mar  1 14:49:33.444: INFO: Pod pod-with-poststart-exec-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 14:49:33.444: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-lifecycle-hook-qmtqn" for this suite.
Mar  1 14:49:55.468: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 14:49:55.522: INFO: namespace: e2e-tests-container-lifecycle-hook-qmtqn, resource: bindings, ignored listing per whitelist
Mar  1 14:49:55.613: INFO: namespace e2e-tests-container-lifecycle-hook-qmtqn deletion completed in 22.163803931s

• [SLOW TEST:54.350 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when create a pod with lifecycle hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute poststart exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 14:49:55.613: INFO: >>> kubeConfig: /tmp/kubeconfig-210205575
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating pod
Mar  1 14:49:59.732: INFO: Pod pod-hostip-4732c883-3c31-11e9-a154-0a580a280202 has hostIP: 10.128.0.18
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 14:49:59.732: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-4h6ss" for this suite.
Mar  1 14:50:21.747: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 14:50:21.799: INFO: namespace: e2e-tests-pods-4h6ss, resource: bindings, ignored listing per whitelist
Mar  1 14:50:21.880: INFO: namespace e2e-tests-pods-4h6ss deletion completed in 22.143955717s

• [SLOW TEST:26.268 seconds]
[k8s.io] Pods
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[k8s.io] Probing container 
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 14:50:21.881: INFO: >>> kubeConfig: /tmp/kubeconfig-210205575
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 14:51:21.985: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-26zw5" for this suite.
Mar  1 14:51:43.999: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 14:51:44.027: INFO: namespace: e2e-tests-container-probe-26zw5, resource: bindings, ignored listing per whitelist
Mar  1 14:51:44.140: INFO: namespace e2e-tests-container-probe-26zw5 deletion completed in 22.151637264s

• [SLOW TEST:82.260 seconds]
[k8s.io] Probing container
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Mar  1 14:51:44.141: INFO: >>> kubeConfig: /tmp/kubeconfig-210205575
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-map-87e1b8be-3c31-11e9-a154-0a580a280202
STEP: Creating a pod to test consume configMaps
Mar  1 14:51:44.244: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-87e27d18-3c31-11e9-a154-0a580a280202" in namespace "e2e-tests-projected-rmghv" to be "success or failure"
Mar  1 14:51:44.249: INFO: Pod "pod-projected-configmaps-87e27d18-3c31-11e9-a154-0a580a280202": Phase="Pending", Reason="", readiness=false. Elapsed: 4.440517ms
Mar  1 14:51:46.252: INFO: Pod "pod-projected-configmaps-87e27d18-3c31-11e9-a154-0a580a280202": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007848375s
STEP: Saw pod success
Mar  1 14:51:46.252: INFO: Pod "pod-projected-configmaps-87e27d18-3c31-11e9-a154-0a580a280202" satisfied condition "success or failure"
Mar  1 14:51:46.255: INFO: Trying to get logs from node gke-conformance-default-pool-eca581b0-czl4 pod pod-projected-configmaps-87e27d18-3c31-11e9-a154-0a580a280202 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Mar  1 14:51:46.280: INFO: Waiting for pod pod-projected-configmaps-87e27d18-3c31-11e9-a154-0a580a280202 to disappear
Mar  1 14:51:46.288: INFO: Pod pod-projected-configmaps-87e27d18-3c31-11e9-a154-0a580a280202 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Mar  1 14:51:46.288: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-rmghv" for this suite.
Mar  1 14:51:52.315: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  1 14:51:52.422: INFO: namespace: e2e-tests-projected-rmghv, resource: bindings, ignored listing per whitelist
Mar  1 14:51:52.467: INFO: namespace e2e-tests-projected-rmghv deletion completed in 6.172235861s

• [SLOW TEST:8.326 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
Mar  1 14:51:52.467: INFO: Running AfterSuite actions on all node
Mar  1 14:51:52.467: INFO: Running AfterSuite actions on node 1
Mar  1 14:51:52.467: INFO: Skipping dumping logs from cluster

Ran 187 of 1814 Specs in 5129.441 seconds
SUCCESS! -- 187 Passed | 0 Failed | 0 Pending | 1627 Skipped PASS

Ginkgo ran 1 suite in 1h25m30.351213156s
Test Suite Passed
