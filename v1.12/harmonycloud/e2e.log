Dec 28 04:29:08.288: INFO: Overriding default scale value of zero to 1
Dec 28 04:29:08.323: INFO: Overriding default milliseconds value of zero to 5000
I1228 04:29:10.735119      14 test_context.go:385] Using a temporary kubeconfig file from in-cluster config : /tmp/kubeconfig-994138694
I1228 04:29:10.735371      14 e2e.go:304] Starting e2e run "1d5b0634-0a59-11e9-8a07-628dff7095f4" on Ginkgo node 1
Running Suite: Kubernetes e2e suite
===================================
Random Seed: 1545971341 - Will randomize all specs
Will run 188 of 1814 specs

Dec 28 04:29:11.219: INFO: >>> kubeConfig: /tmp/kubeconfig-994138694
Dec 28 04:29:11.277: INFO: Waiting up to 30m0s for all (but 0) nodes to be schedulable
Dec 28 04:29:11.367: INFO: Waiting up to 10m0s for all pods (need at least 0) in namespace 'kube-system' to be running and ready
Dec 28 04:29:11.500: INFO: 40 / 40 pods in namespace 'kube-system' are running and ready (0 seconds elapsed)
Dec 28 04:29:11.500: INFO: expected 20 pod replicas in namespace 'kube-system', 20 are Running and Ready.
Dec 28 04:29:11.500: INFO: Waiting up to 5m0s for all daemonsets in namespace 'kube-system' to start
Dec 28 04:29:11.530: INFO: 5 / 5 pods ready in namespace 'kube-system' in daemonset 'calico-node' (0 seconds elapsed)
Dec 28 04:29:11.530: INFO: 4 / 4 pods ready in namespace 'kube-system' in daemonset 'fluentd-es-v1.22' (0 seconds elapsed)
Dec 28 04:29:11.530: INFO: 5 / 5 pods ready in namespace 'kube-system' in daemonset 'kube-proxy' (0 seconds elapsed)
Dec 28 04:29:11.530: INFO: 2 / 2 pods ready in namespace 'kube-system' in daemonset 'nginx-ingress-controller' (0 seconds elapsed)
Dec 28 04:29:11.530: INFO: e2e test version: v1.12.1
Dec 28 04:29:11.533: INFO: kube-apiserver version: v1.12.3
SSSS
------------------------------
[sig-storage] Downward API volume 
  should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 28 04:29:11.534: INFO: >>> kubeConfig: /tmp/kubeconfig-994138694
STEP: Building a namespace api object, basename downward-api
Dec 28 04:29:11.854: INFO: No PodSecurityPolicies found; assuming PodSecurityPolicy is disabled.
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Dec 28 04:29:11.895: INFO: Waiting up to 5m0s for pod "downwardapi-volume-201bf5db-0a59-11e9-8a07-628dff7095f4" in namespace "e2e-tests-downward-api-d8xlj" to be "success or failure"
Dec 28 04:29:11.913: INFO: Pod "downwardapi-volume-201bf5db-0a59-11e9-8a07-628dff7095f4": Phase="Pending", Reason="", readiness=false. Elapsed: 17.667433ms
Dec 28 04:29:13.935: INFO: Pod "downwardapi-volume-201bf5db-0a59-11e9-8a07-628dff7095f4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.03920558s
Dec 28 04:29:15.942: INFO: Pod "downwardapi-volume-201bf5db-0a59-11e9-8a07-628dff7095f4": Phase="Pending", Reason="", readiness=false. Elapsed: 4.04683163s
Dec 28 04:29:17.950: INFO: Pod "downwardapi-volume-201bf5db-0a59-11e9-8a07-628dff7095f4": Phase="Pending", Reason="", readiness=false. Elapsed: 6.054321496s
Dec 28 04:29:19.998: INFO: Pod "downwardapi-volume-201bf5db-0a59-11e9-8a07-628dff7095f4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.10278916s
STEP: Saw pod success
Dec 28 04:29:19.998: INFO: Pod "downwardapi-volume-201bf5db-0a59-11e9-8a07-628dff7095f4" satisfied condition "success or failure"
Dec 28 04:29:20.124: INFO: Trying to get logs from node 10.10.102.69-build pod downwardapi-volume-201bf5db-0a59-11e9-8a07-628dff7095f4 container client-container: <nil>
STEP: delete the pod
Dec 28 04:29:20.189: INFO: Waiting for pod downwardapi-volume-201bf5db-0a59-11e9-8a07-628dff7095f4 to disappear
Dec 28 04:29:20.242: INFO: Pod downwardapi-volume-201bf5db-0a59-11e9-8a07-628dff7095f4 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 28 04:29:20.243: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-d8xlj" for this suite.
Dec 28 04:29:26.283: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 04:29:26.555: INFO: namespace: e2e-tests-downward-api-d8xlj, resource: bindings, ignored listing per whitelist
Dec 28 04:29:26.738: INFO: namespace e2e-tests-downward-api-d8xlj deletion completed in 6.480706996s

• [SLOW TEST:15.205 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Secrets 
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 28 04:29:26.739: INFO: >>> kubeConfig: /tmp/kubeconfig-994138694
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-292d8690-0a59-11e9-8a07-628dff7095f4
STEP: Creating a pod to test consume secrets
Dec 28 04:29:27.094: INFO: Waiting up to 5m0s for pod "pod-secrets-292ed08b-0a59-11e9-8a07-628dff7095f4" in namespace "e2e-tests-secrets-fbpkc" to be "success or failure"
Dec 28 04:29:27.145: INFO: Pod "pod-secrets-292ed08b-0a59-11e9-8a07-628dff7095f4": Phase="Pending", Reason="", readiness=false. Elapsed: 50.630413ms
Dec 28 04:29:29.155: INFO: Pod "pod-secrets-292ed08b-0a59-11e9-8a07-628dff7095f4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.05987093s
Dec 28 04:29:31.194: INFO: Pod "pod-secrets-292ed08b-0a59-11e9-8a07-628dff7095f4": Phase="Pending", Reason="", readiness=false. Elapsed: 4.098922557s
Dec 28 04:29:33.216: INFO: Pod "pod-secrets-292ed08b-0a59-11e9-8a07-628dff7095f4": Phase="Pending", Reason="", readiness=false. Elapsed: 6.12163687s
Dec 28 04:29:35.294: INFO: Pod "pod-secrets-292ed08b-0a59-11e9-8a07-628dff7095f4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.199622937s
STEP: Saw pod success
Dec 28 04:29:35.294: INFO: Pod "pod-secrets-292ed08b-0a59-11e9-8a07-628dff7095f4" satisfied condition "success or failure"
Dec 28 04:29:35.301: INFO: Trying to get logs from node 10.10.102.68-share pod pod-secrets-292ed08b-0a59-11e9-8a07-628dff7095f4 container secret-env-test: <nil>
STEP: delete the pod
Dec 28 04:29:35.432: INFO: Waiting for pod pod-secrets-292ed08b-0a59-11e9-8a07-628dff7095f4 to disappear
Dec 28 04:29:35.461: INFO: Pod pod-secrets-292ed08b-0a59-11e9-8a07-628dff7095f4 no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 28 04:29:35.461: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-fbpkc" for this suite.
Dec 28 04:29:43.522: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 04:29:43.544: INFO: namespace: e2e-tests-secrets-fbpkc, resource: bindings, ignored listing per whitelist
Dec 28 04:29:43.741: INFO: namespace e2e-tests-secrets-fbpkc deletion completed in 8.26514497s

• [SLOW TEST:17.002 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:31
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 28 04:29:43.742: INFO: >>> kubeConfig: /tmp/kubeconfig-994138694
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Dec 28 04:29:44.138: INFO: pod1.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod3", UID:"3365992c-0a59-11e9-a0ee-005056bc4922", Controller:(*bool)(0xc4210f4bca), BlockOwnerDeletion:(*bool)(0xc4210f4bcb)}}
Dec 28 04:29:44.191: INFO: pod2.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod1", UID:"3361e6ad-0a59-11e9-a0ee-005056bc4922", Controller:(*bool)(0xc421381422), BlockOwnerDeletion:(*bool)(0xc421381423)}}
Dec 28 04:29:44.210: INFO: pod3.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod2", UID:"3362f466-0a59-11e9-a0ee-005056bc4922", Controller:(*bool)(0xc4210f4f72), BlockOwnerDeletion:(*bool)(0xc4210f4f73)}}
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 28 04:29:49.346: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-76n47" for this suite.
Dec 28 04:29:57.386: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 04:29:57.577: INFO: namespace: e2e-tests-gc-76n47, resource: bindings, ignored listing per whitelist
Dec 28 04:29:57.608: INFO: namespace e2e-tests-gc-76n47 deletion completed in 8.25114866s

• [SLOW TEST:13.866 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-api-machinery] Downward API 
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 28 04:29:57.608: INFO: >>> kubeConfig: /tmp/kubeconfig-994138694
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Dec 28 04:29:57.820: INFO: Waiting up to 5m0s for pod "downward-api-3b7c31f0-0a59-11e9-8a07-628dff7095f4" in namespace "e2e-tests-downward-api-6t4tb" to be "success or failure"
Dec 28 04:29:57.836: INFO: Pod "downward-api-3b7c31f0-0a59-11e9-8a07-628dff7095f4": Phase="Pending", Reason="", readiness=false. Elapsed: 15.301873ms
Dec 28 04:29:59.844: INFO: Pod "downward-api-3b7c31f0-0a59-11e9-8a07-628dff7095f4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.023678833s
Dec 28 04:30:01.851: INFO: Pod "downward-api-3b7c31f0-0a59-11e9-8a07-628dff7095f4": Phase="Pending", Reason="", readiness=false. Elapsed: 4.030488633s
Dec 28 04:30:03.857: INFO: Pod "downward-api-3b7c31f0-0a59-11e9-8a07-628dff7095f4": Phase="Pending", Reason="", readiness=false. Elapsed: 6.037190123s
Dec 28 04:30:05.864: INFO: Pod "downward-api-3b7c31f0-0a59-11e9-8a07-628dff7095f4": Phase="Pending", Reason="", readiness=false. Elapsed: 8.04416472s
Dec 28 04:30:07.871: INFO: Pod "downward-api-3b7c31f0-0a59-11e9-8a07-628dff7095f4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 10.050928603s
STEP: Saw pod success
Dec 28 04:30:07.871: INFO: Pod "downward-api-3b7c31f0-0a59-11e9-8a07-628dff7095f4" satisfied condition "success or failure"
Dec 28 04:30:07.876: INFO: Trying to get logs from node 10.10.102.68-share pod downward-api-3b7c31f0-0a59-11e9-8a07-628dff7095f4 container dapi-container: <nil>
STEP: delete the pod
Dec 28 04:30:07.923: INFO: Waiting for pod downward-api-3b7c31f0-0a59-11e9-8a07-628dff7095f4 to disappear
Dec 28 04:30:07.968: INFO: Pod downward-api-3b7c31f0-0a59-11e9-8a07-628dff7095f4 no longer exists
[AfterEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 28 04:30:07.968: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-6t4tb" for this suite.
Dec 28 04:30:14.037: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 04:30:14.107: INFO: namespace: e2e-tests-downward-api-6t4tb, resource: bindings, ignored listing per whitelist
Dec 28 04:30:14.236: INFO: namespace e2e-tests-downward-api-6t4tb deletion completed in 6.226107534s

• [SLOW TEST:16.628 seconds]
[sig-api-machinery] Downward API
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 28 04:30:14.237: INFO: >>> kubeConfig: /tmp/kubeconfig-994138694
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-http in namespace e2e-tests-container-probe-f2l5f
Dec 28 04:30:22.549: INFO: Started pod liveness-http in namespace e2e-tests-container-probe-f2l5f
STEP: checking the pod's current state and verifying that restartCount is present
Dec 28 04:30:22.554: INFO: Initial restart count of pod liveness-http is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 28 04:34:23.932: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-f2l5f" for this suite.
Dec 28 04:34:29.981: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 04:34:30.044: INFO: namespace: e2e-tests-container-probe-f2l5f, resource: bindings, ignored listing per whitelist
Dec 28 04:34:30.263: INFO: namespace e2e-tests-container-probe-f2l5f deletion completed in 6.310074643s

• [SLOW TEST:256.027 seconds]
[k8s.io] Probing container
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 28 04:34:30.264: INFO: >>> kubeConfig: /tmp/kubeconfig-994138694
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
Dec 28 04:34:30.492: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 28 04:34:44.822: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-init-container-bjn7s" for this suite.
Dec 28 04:34:50.923: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 04:34:50.953: INFO: namespace: e2e-tests-init-container-bjn7s, resource: bindings, ignored listing per whitelist
Dec 28 04:34:51.139: INFO: namespace e2e-tests-init-container-bjn7s deletion completed in 6.27652411s

• [SLOW TEST:20.875 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 28 04:34:51.140: INFO: >>> kubeConfig: /tmp/kubeconfig-994138694
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Dec 28 04:34:51.373: INFO: Waiting up to 5m0s for pod "downwardapi-volume-ea78307f-0a59-11e9-8a07-628dff7095f4" in namespace "e2e-tests-downward-api-j7xlm" to be "success or failure"
Dec 28 04:34:51.390: INFO: Pod "downwardapi-volume-ea78307f-0a59-11e9-8a07-628dff7095f4": Phase="Pending", Reason="", readiness=false. Elapsed: 16.920903ms
Dec 28 04:34:53.410: INFO: Pod "downwardapi-volume-ea78307f-0a59-11e9-8a07-628dff7095f4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.0367688s
Dec 28 04:34:55.422: INFO: Pod "downwardapi-volume-ea78307f-0a59-11e9-8a07-628dff7095f4": Phase="Pending", Reason="", readiness=false. Elapsed: 4.048041946s
Dec 28 04:34:57.429: INFO: Pod "downwardapi-volume-ea78307f-0a59-11e9-8a07-628dff7095f4": Phase="Pending", Reason="", readiness=false. Elapsed: 6.055773493s
Dec 28 04:34:59.437: INFO: Pod "downwardapi-volume-ea78307f-0a59-11e9-8a07-628dff7095f4": Phase="Running", Reason="", readiness=true. Elapsed: 8.063969086s
Dec 28 04:35:01.447: INFO: Pod "downwardapi-volume-ea78307f-0a59-11e9-8a07-628dff7095f4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 10.073222093s
STEP: Saw pod success
Dec 28 04:35:01.447: INFO: Pod "downwardapi-volume-ea78307f-0a59-11e9-8a07-628dff7095f4" satisfied condition "success or failure"
Dec 28 04:35:01.453: INFO: Trying to get logs from node 10.10.102.68-share pod downwardapi-volume-ea78307f-0a59-11e9-8a07-628dff7095f4 container client-container: <nil>
STEP: delete the pod
Dec 28 04:35:01.599: INFO: Waiting for pod downwardapi-volume-ea78307f-0a59-11e9-8a07-628dff7095f4 to disappear
Dec 28 04:35:01.607: INFO: Pod downwardapi-volume-ea78307f-0a59-11e9-8a07-628dff7095f4 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 28 04:35:01.607: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-j7xlm" for this suite.
Dec 28 04:35:07.699: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 04:35:07.888: INFO: namespace: e2e-tests-downward-api-j7xlm, resource: bindings, ignored listing per whitelist
Dec 28 04:35:08.069: INFO: namespace e2e-tests-downward-api-j7xlm deletion completed in 6.452616907s

• [SLOW TEST:16.930 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod with mountPath of existing file [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 28 04:35:08.070: INFO: >>> kubeConfig: /tmp/kubeconfig-994138694
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with configmap pod with mountPath of existing file [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-configmap-xkcs
STEP: Creating a pod to test atomic-volume-subpath
Dec 28 04:35:08.488: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-xkcs" in namespace "e2e-tests-subpath-zm8cs" to be "success or failure"
Dec 28 04:35:08.507: INFO: Pod "pod-subpath-test-configmap-xkcs": Phase="Pending", Reason="", readiness=false. Elapsed: 19.156217ms
Dec 28 04:35:10.514: INFO: Pod "pod-subpath-test-configmap-xkcs": Phase="Pending", Reason="", readiness=false. Elapsed: 2.026173887s
Dec 28 04:35:12.531: INFO: Pod "pod-subpath-test-configmap-xkcs": Phase="Pending", Reason="", readiness=false. Elapsed: 4.04318232s
Dec 28 04:35:14.536: INFO: Pod "pod-subpath-test-configmap-xkcs": Phase="Pending", Reason="", readiness=false. Elapsed: 6.048639543s
Dec 28 04:35:16.546: INFO: Pod "pod-subpath-test-configmap-xkcs": Phase="Pending", Reason="", readiness=false. Elapsed: 8.058644323s
Dec 28 04:35:18.588: INFO: Pod "pod-subpath-test-configmap-xkcs": Phase="Pending", Reason="", readiness=false. Elapsed: 10.100455027s
Dec 28 04:35:20.599: INFO: Pod "pod-subpath-test-configmap-xkcs": Phase="Pending", Reason="", readiness=false. Elapsed: 12.11095558s
Dec 28 04:35:22.626: INFO: Pod "pod-subpath-test-configmap-xkcs": Phase="Running", Reason="", readiness=true. Elapsed: 14.138700613s
Dec 28 04:35:24.633: INFO: Pod "pod-subpath-test-configmap-xkcs": Phase="Running", Reason="", readiness=false. Elapsed: 16.145800687s
Dec 28 04:35:26.690: INFO: Pod "pod-subpath-test-configmap-xkcs": Phase="Running", Reason="", readiness=false. Elapsed: 18.20251269s
Dec 28 04:35:28.804: INFO: Pod "pod-subpath-test-configmap-xkcs": Phase="Running", Reason="", readiness=false. Elapsed: 20.316722607s
Dec 28 04:35:30.812: INFO: Pod "pod-subpath-test-configmap-xkcs": Phase="Running", Reason="", readiness=false. Elapsed: 22.324421303s
Dec 28 04:35:32.819: INFO: Pod "pod-subpath-test-configmap-xkcs": Phase="Running", Reason="", readiness=false. Elapsed: 24.331421203s
Dec 28 04:35:34.827: INFO: Pod "pod-subpath-test-configmap-xkcs": Phase="Running", Reason="", readiness=false. Elapsed: 26.33925714s
Dec 28 04:35:37.039: INFO: Pod "pod-subpath-test-configmap-xkcs": Phase="Running", Reason="", readiness=false. Elapsed: 28.550929303s
Dec 28 04:35:39.051: INFO: Pod "pod-subpath-test-configmap-xkcs": Phase="Running", Reason="", readiness=false. Elapsed: 30.562911923s
Dec 28 04:35:41.058: INFO: Pod "pod-subpath-test-configmap-xkcs": Phase="Succeeded", Reason="", readiness=false. Elapsed: 32.569903127s
STEP: Saw pod success
Dec 28 04:35:41.058: INFO: Pod "pod-subpath-test-configmap-xkcs" satisfied condition "success or failure"
Dec 28 04:35:41.062: INFO: Trying to get logs from node 10.10.102.68-share pod pod-subpath-test-configmap-xkcs container test-container-subpath-configmap-xkcs: <nil>
STEP: delete the pod
Dec 28 04:35:41.182: INFO: Waiting for pod pod-subpath-test-configmap-xkcs to disappear
Dec 28 04:35:41.193: INFO: Pod pod-subpath-test-configmap-xkcs no longer exists
STEP: Deleting pod pod-subpath-test-configmap-xkcs
Dec 28 04:35:41.193: INFO: Deleting pod "pod-subpath-test-configmap-xkcs" in namespace "e2e-tests-subpath-zm8cs"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 28 04:35:41.213: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-zm8cs" for this suite.
Dec 28 04:35:49.263: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 04:35:49.425: INFO: namespace: e2e-tests-subpath-zm8cs, resource: bindings, ignored listing per whitelist
Dec 28 04:35:49.478: INFO: namespace e2e-tests-subpath-zm8cs deletion completed in 8.254332163s

• [SLOW TEST:41.408 seconds]
[sig-storage] Subpath
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with configmap pod with mountPath of existing file [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[k8s.io] Probing container 
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 28 04:35:49.478: INFO: >>> kubeConfig: /tmp/kubeconfig-994138694
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-http in namespace e2e-tests-container-probe-wxqm5
Dec 28 04:35:57.753: INFO: Started pod liveness-http in namespace e2e-tests-container-probe-wxqm5
STEP: checking the pod's current state and verifying that restartCount is present
Dec 28 04:35:57.758: INFO: Initial restart count of pod liveness-http is 0
Dec 28 04:36:23.938: INFO: Restart count of pod e2e-tests-container-probe-wxqm5/liveness-http is now 1 (26.179575327s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 28 04:36:23.972: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-wxqm5" for this suite.
Dec 28 04:36:30.012: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 04:36:30.171: INFO: namespace: e2e-tests-container-probe-wxqm5, resource: bindings, ignored listing per whitelist
Dec 28 04:36:30.224: INFO: namespace e2e-tests-container-probe-wxqm5 deletion completed in 6.235883303s

• [SLOW TEST:40.745 seconds]
[k8s.io] Probing container
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] version v1
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 28 04:36:30.224: INFO: >>> kubeConfig: /tmp/kubeconfig-994138694
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Dec 28 04:36:30.526: INFO: (0) /api/v1/nodes/10.10.102.66-slave/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 13.24682ms)
Dec 28 04:36:30.534: INFO: (1) /api/v1/nodes/10.10.102.66-slave/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 7.234153ms)
Dec 28 04:36:30.542: INFO: (2) /api/v1/nodes/10.10.102.66-slave/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 7.668107ms)
Dec 28 04:36:30.550: INFO: (3) /api/v1/nodes/10.10.102.66-slave/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 7.954126ms)
Dec 28 04:36:30.558: INFO: (4) /api/v1/nodes/10.10.102.66-slave/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 7.616553ms)
Dec 28 04:36:30.565: INFO: (5) /api/v1/nodes/10.10.102.66-slave/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 7.33984ms)
Dec 28 04:36:30.572: INFO: (6) /api/v1/nodes/10.10.102.66-slave/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 6.81552ms)
Dec 28 04:36:30.580: INFO: (7) /api/v1/nodes/10.10.102.66-slave/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 8.270297ms)
Dec 28 04:36:30.589: INFO: (8) /api/v1/nodes/10.10.102.66-slave/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 8.366463ms)
Dec 28 04:36:30.597: INFO: (9) /api/v1/nodes/10.10.102.66-slave/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 8.288887ms)
Dec 28 04:36:30.604: INFO: (10) /api/v1/nodes/10.10.102.66-slave/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 7.02926ms)
Dec 28 04:36:30.612: INFO: (11) /api/v1/nodes/10.10.102.66-slave/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 7.300726ms)
Dec 28 04:36:30.619: INFO: (12) /api/v1/nodes/10.10.102.66-slave/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 7.420087ms)
Dec 28 04:36:30.626: INFO: (13) /api/v1/nodes/10.10.102.66-slave/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 6.887517ms)
Dec 28 04:36:30.633: INFO: (14) /api/v1/nodes/10.10.102.66-slave/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 6.958556ms)
Dec 28 04:36:30.641: INFO: (15) /api/v1/nodes/10.10.102.66-slave/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 8.104123ms)
Dec 28 04:36:30.650: INFO: (16) /api/v1/nodes/10.10.102.66-slave/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 8.893877ms)
Dec 28 04:36:30.658: INFO: (17) /api/v1/nodes/10.10.102.66-slave/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 7.96225ms)
Dec 28 04:36:30.666: INFO: (18) /api/v1/nodes/10.10.102.66-slave/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 7.261277ms)
Dec 28 04:36:30.673: INFO: (19) /api/v1/nodes/10.10.102.66-slave/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 7.59333ms)
[AfterEach] version v1
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 28 04:36:30.674: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-proxy-gsk7t" for this suite.
Dec 28 04:36:36.708: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 04:36:36.766: INFO: namespace: e2e-tests-proxy-gsk7t, resource: bindings, ignored listing per whitelist
Dec 28 04:36:36.928: INFO: namespace e2e-tests-proxy-gsk7t deletion completed in 6.245620984s

• [SLOW TEST:6.704 seconds]
[sig-network] Proxy
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy logs on node using proxy subresource  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 28 04:36:36.929: INFO: >>> kubeConfig: /tmp/kubeconfig-994138694
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Dec 28 04:36:53.298: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Dec 28 04:36:53.325: INFO: Pod pod-with-poststart-exec-hook still exists
Dec 28 04:36:55.326: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Dec 28 04:36:55.333: INFO: Pod pod-with-poststart-exec-hook still exists
Dec 28 04:36:57.326: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Dec 28 04:36:57.333: INFO: Pod pod-with-poststart-exec-hook still exists
Dec 28 04:36:59.326: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Dec 28 04:36:59.332: INFO: Pod pod-with-poststart-exec-hook still exists
Dec 28 04:37:01.326: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Dec 28 04:37:01.334: INFO: Pod pod-with-poststart-exec-hook still exists
Dec 28 04:37:03.326: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Dec 28 04:37:03.333: INFO: Pod pod-with-poststart-exec-hook still exists
Dec 28 04:37:05.328: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Dec 28 04:37:05.340: INFO: Pod pod-with-poststart-exec-hook still exists
Dec 28 04:37:07.326: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Dec 28 04:37:07.333: INFO: Pod pod-with-poststart-exec-hook still exists
Dec 28 04:37:09.326: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Dec 28 04:37:09.332: INFO: Pod pod-with-poststart-exec-hook still exists
Dec 28 04:37:11.326: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Dec 28 04:37:11.334: INFO: Pod pod-with-poststart-exec-hook still exists
Dec 28 04:37:13.326: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Dec 28 04:37:13.333: INFO: Pod pod-with-poststart-exec-hook still exists
Dec 28 04:37:15.326: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Dec 28 04:37:15.333: INFO: Pod pod-with-poststart-exec-hook still exists
Dec 28 04:37:17.326: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Dec 28 04:37:17.342: INFO: Pod pod-with-poststart-exec-hook still exists
Dec 28 04:37:19.326: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Dec 28 04:37:19.333: INFO: Pod pod-with-poststart-exec-hook still exists
Dec 28 04:37:21.326: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Dec 28 04:37:21.332: INFO: Pod pod-with-poststart-exec-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 28 04:37:21.332: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-lifecycle-hook-rrhs6" for this suite.
Dec 28 04:37:45.370: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 04:37:45.563: INFO: namespace: e2e-tests-container-lifecycle-hook-rrhs6, resource: bindings, ignored listing per whitelist
Dec 28 04:37:45.581: INFO: namespace e2e-tests-container-lifecycle-hook-rrhs6 deletion completed in 24.237228357s

• [SLOW TEST:68.651 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when create a pod with lifecycle hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute poststart exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 28 04:37:45.581: INFO: >>> kubeConfig: /tmp/kubeconfig-994138694
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-5281fe22-0a5a-11e9-8a07-628dff7095f4
STEP: Creating a pod to test consume configMaps
Dec 28 04:37:45.983: INFO: Waiting up to 5m0s for pod "pod-configmaps-5283118b-0a5a-11e9-8a07-628dff7095f4" in namespace "e2e-tests-configmap-wvs4f" to be "success or failure"
Dec 28 04:37:46.003: INFO: Pod "pod-configmaps-5283118b-0a5a-11e9-8a07-628dff7095f4": Phase="Pending", Reason="", readiness=false. Elapsed: 20.29033ms
Dec 28 04:37:48.009: INFO: Pod "pod-configmaps-5283118b-0a5a-11e9-8a07-628dff7095f4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.026327263s
Dec 28 04:37:50.018: INFO: Pod "pod-configmaps-5283118b-0a5a-11e9-8a07-628dff7095f4": Phase="Pending", Reason="", readiness=false. Elapsed: 4.034587513s
Dec 28 04:37:52.025: INFO: Pod "pod-configmaps-5283118b-0a5a-11e9-8a07-628dff7095f4": Phase="Pending", Reason="", readiness=false. Elapsed: 6.041412147s
Dec 28 04:37:54.230: INFO: Pod "pod-configmaps-5283118b-0a5a-11e9-8a07-628dff7095f4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.24693933s
STEP: Saw pod success
Dec 28 04:37:54.230: INFO: Pod "pod-configmaps-5283118b-0a5a-11e9-8a07-628dff7095f4" satisfied condition "success or failure"
Dec 28 04:37:54.236: INFO: Trying to get logs from node 10.10.102.68-share pod pod-configmaps-5283118b-0a5a-11e9-8a07-628dff7095f4 container configmap-volume-test: <nil>
STEP: delete the pod
Dec 28 04:37:54.298: INFO: Waiting for pod pod-configmaps-5283118b-0a5a-11e9-8a07-628dff7095f4 to disappear
Dec 28 04:37:54.315: INFO: Pod pod-configmaps-5283118b-0a5a-11e9-8a07-628dff7095f4 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 28 04:37:54.315: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-wvs4f" for this suite.
Dec 28 04:38:00.409: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 04:38:00.618: INFO: namespace: e2e-tests-configmap-wvs4f, resource: bindings, ignored listing per whitelist
Dec 28 04:38:00.682: INFO: namespace e2e-tests-configmap-wvs4f deletion completed in 6.35459578s

• [SLOW TEST:15.100 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 28 04:38:00.682: INFO: >>> kubeConfig: /tmp/kubeconfig-994138694
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for services  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(dig +notcp +noall +answer +search dns-test-service A)" && echo OK > /results/wheezy_udp@dns-test-service;test -n "$$(dig +tcp +noall +answer +search dns-test-service A)" && echo OK > /results/wheezy_tcp@dns-test-service;test -n "$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-kbhgh A)" && echo OK > /results/wheezy_udp@dns-test-service.e2e-tests-dns-kbhgh;test -n "$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-kbhgh A)" && echo OK > /results/wheezy_tcp@dns-test-service.e2e-tests-dns-kbhgh;test -n "$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-kbhgh.svc A)" && echo OK > /results/wheezy_udp@dns-test-service.e2e-tests-dns-kbhgh.svc;test -n "$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-kbhgh.svc A)" && echo OK > /results/wheezy_tcp@dns-test-service.e2e-tests-dns-kbhgh.svc;test -n "$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-kbhgh.svc SRV)" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.e2e-tests-dns-kbhgh.svc;test -n "$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-kbhgh.svc SRV)" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.e2e-tests-dns-kbhgh.svc;test -n "$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-kbhgh.svc SRV)" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.e2e-tests-dns-kbhgh.svc;test -n "$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-kbhgh.svc SRV)" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.e2e-tests-dns-kbhgh.svc;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-kbhgh.pod.cluster.local"}');test -n "$$(dig +notcp +noall +answer +search $${podARec} A)" && echo OK > /results/wheezy_udp@PodARecord;test -n "$$(dig +tcp +noall +answer +search $${podARec} A)" && echo OK > /results/wheezy_tcp@PodARecord;test -n "$$(dig +notcp +noall +answer +search 70.84.99.10.in-addr.arpa. PTR)" && echo OK > /results/10.99.84.70_udp@PTR;test -n "$$(dig +tcp +noall +answer +search 70.84.99.10.in-addr.arpa. PTR)" && echo OK > /results/10.99.84.70_tcp@PTR;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(dig +notcp +noall +answer +search dns-test-service A)" && echo OK > /results/jessie_udp@dns-test-service;test -n "$$(dig +tcp +noall +answer +search dns-test-service A)" && echo OK > /results/jessie_tcp@dns-test-service;test -n "$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-kbhgh A)" && echo OK > /results/jessie_udp@dns-test-service.e2e-tests-dns-kbhgh;test -n "$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-kbhgh A)" && echo OK > /results/jessie_tcp@dns-test-service.e2e-tests-dns-kbhgh;test -n "$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-kbhgh.svc A)" && echo OK > /results/jessie_udp@dns-test-service.e2e-tests-dns-kbhgh.svc;test -n "$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-kbhgh.svc A)" && echo OK > /results/jessie_tcp@dns-test-service.e2e-tests-dns-kbhgh.svc;test -n "$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-kbhgh.svc SRV)" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-kbhgh.svc;test -n "$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-kbhgh.svc SRV)" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-kbhgh.svc;test -n "$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-kbhgh.svc SRV)" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.e2e-tests-dns-kbhgh.svc;test -n "$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-kbhgh.svc SRV)" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.e2e-tests-dns-kbhgh.svc;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-kbhgh.pod.cluster.local"}');test -n "$$(dig +notcp +noall +answer +search $${podARec} A)" && echo OK > /results/jessie_udp@PodARecord;test -n "$$(dig +tcp +noall +answer +search $${podARec} A)" && echo OK > /results/jessie_tcp@PodARecord;test -n "$$(dig +notcp +noall +answer +search 70.84.99.10.in-addr.arpa. PTR)" && echo OK > /results/10.99.84.70_udp@PTR;test -n "$$(dig +tcp +noall +answer +search 70.84.99.10.in-addr.arpa. PTR)" && echo OK > /results/10.99.84.70_tcp@PTR;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Dec 28 04:38:25.344: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-kbhgh.svc from pod e2e-tests-dns-kbhgh/dns-test-5b820497-0a5a-11e9-8a07-628dff7095f4: the server could not find the requested resource (get pods dns-test-5b820497-0a5a-11e9-8a07-628dff7095f4)
Dec 28 04:38:25.406: INFO: Lookups using e2e-tests-dns-kbhgh/dns-test-5b820497-0a5a-11e9-8a07-628dff7095f4 failed for: [jessie_udp@dns-test-service.e2e-tests-dns-kbhgh.svc]

Dec 28 04:38:35.539: INFO: DNS probes using e2e-tests-dns-kbhgh/dns-test-5b820497-0a5a-11e9-8a07-628dff7095f4 succeeded

STEP: deleting the pod
STEP: deleting the test service
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 28 04:38:35.795: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-dns-kbhgh" for this suite.
Dec 28 04:38:43.992: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 04:38:44.142: INFO: namespace: e2e-tests-dns-kbhgh, resource: bindings, ignored listing per whitelist
Dec 28 04:38:44.185: INFO: namespace e2e-tests-dns-kbhgh deletion completed in 8.351297837s

• [SLOW TEST:43.503 seconds]
[sig-network] DNS
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 28 04:38:44.186: INFO: >>> kubeConfig: /tmp/kubeconfig-994138694
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Dec 28 04:39:12.422: INFO: Container started at 2018-12-28 04:38:51 +0000 UTC, pod became ready at 2018-12-28 04:39:11 +0000 UTC
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 28 04:39:12.422: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-hv8gh" for this suite.
Dec 28 04:39:36.460: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 04:39:36.496: INFO: namespace: e2e-tests-container-probe-hv8gh, resource: bindings, ignored listing per whitelist
Dec 28 04:39:36.702: INFO: namespace e2e-tests-container-probe-hv8gh deletion completed in 24.269510796s

• [SLOW TEST:52.515 seconds]
[k8s.io] Probing container
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 28 04:39:36.702: INFO: >>> kubeConfig: /tmp/kubeconfig-994138694
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the pods
STEP: Gathering metrics
Dec 28 04:40:17.078: INFO: MetricsGrabber failed grab metrics. Skipping metrics gathering.
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 28 04:40:17.078: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-8llh9" for this suite.
Dec 28 04:40:27.143: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 04:40:27.224: INFO: namespace: e2e-tests-gc-8llh9, resource: bindings, ignored listing per whitelist
Dec 28 04:40:27.342: INFO: namespace e2e-tests-gc-8llh9 deletion completed in 10.254422063s

• [SLOW TEST:50.640 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 28 04:40:27.343: INFO: >>> kubeConfig: /tmp/kubeconfig-994138694
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-pjzv7
[It] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Initializing watcher for selector baz=blah,foo=bar
STEP: Creating stateful set ss in namespace e2e-tests-statefulset-pjzv7
STEP: Waiting until all stateful set ss replicas will be running in namespace e2e-tests-statefulset-pjzv7
Dec 28 04:40:27.847: INFO: Found 0 stateful pods, waiting for 1
Dec 28 04:40:37.854: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=false
Dec 28 04:40:47.854: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will halt with unhealthy stateful pod
Dec 28 04:40:47.861: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994138694 exec --namespace=e2e-tests-statefulset-pjzv7 ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Dec 28 04:40:49.014: INFO: stderr: ""
Dec 28 04:40:49.014: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Dec 28 04:40:49.014: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Dec 28 04:40:49.021: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Dec 28 04:40:59.029: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Dec 28 04:40:59.029: INFO: Waiting for statefulset status.replicas updated to 0
Dec 28 04:40:59.099: INFO: Verifying statefulset ss doesn't scale past 1 for another 9.999999337s
Dec 28 04:41:00.111: INFO: Verifying statefulset ss doesn't scale past 1 for another 8.948265507s
Dec 28 04:41:01.119: INFO: Verifying statefulset ss doesn't scale past 1 for another 7.935934197s
Dec 28 04:41:02.127: INFO: Verifying statefulset ss doesn't scale past 1 for another 6.92733551s
Dec 28 04:41:03.136: INFO: Verifying statefulset ss doesn't scale past 1 for another 5.919704447s
Dec 28 04:41:04.144: INFO: Verifying statefulset ss doesn't scale past 1 for another 4.911377744s
Dec 28 04:41:05.151: INFO: Verifying statefulset ss doesn't scale past 1 for another 3.903307767s
Dec 28 04:41:06.160: INFO: Verifying statefulset ss doesn't scale past 1 for another 2.896089804s
Dec 28 04:41:07.168: INFO: Verifying statefulset ss doesn't scale past 1 for another 1.887127764s
Dec 28 04:41:08.176: INFO: Verifying statefulset ss doesn't scale past 1 for another 878.836064ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace e2e-tests-statefulset-pjzv7
Dec 28 04:41:09.183: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994138694 exec --namespace=e2e-tests-statefulset-pjzv7 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec 28 04:41:09.689: INFO: stderr: ""
Dec 28 04:41:09.689: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Dec 28 04:41:09.689: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Dec 28 04:41:09.696: INFO: Found 1 stateful pods, waiting for 3
Dec 28 04:41:19.704: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Dec 28 04:41:19.705: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Dec 28 04:41:19.705: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Pending - Ready=false
Dec 28 04:41:29.704: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Dec 28 04:41:29.704: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Dec 28 04:41:29.704: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Verifying that stateful set ss was scaled up in order
STEP: Scale down will halt with unhealthy stateful pod
Dec 28 04:41:29.715: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994138694 exec --namespace=e2e-tests-statefulset-pjzv7 ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Dec 28 04:41:30.232: INFO: stderr: ""
Dec 28 04:41:30.232: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Dec 28 04:41:30.232: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Dec 28 04:41:30.232: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994138694 exec --namespace=e2e-tests-statefulset-pjzv7 ss-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Dec 28 04:41:30.927: INFO: stderr: ""
Dec 28 04:41:30.927: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Dec 28 04:41:30.927: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Dec 28 04:41:30.927: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994138694 exec --namespace=e2e-tests-statefulset-pjzv7 ss-2 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Dec 28 04:41:31.414: INFO: stderr: ""
Dec 28 04:41:31.414: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Dec 28 04:41:31.414: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-2: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Dec 28 04:41:31.414: INFO: Waiting for statefulset status.replicas updated to 0
Dec 28 04:41:31.421: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 2
Dec 28 04:41:41.443: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Dec 28 04:41:41.443: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Dec 28 04:41:41.443: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Dec 28 04:41:41.489: INFO: Verifying statefulset ss doesn't scale past 3 for another 9.999999143s
Dec 28 04:41:42.497: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.96751091s
Dec 28 04:41:43.506: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.959610407s
Dec 28 04:41:44.517: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.95010801s
Dec 28 04:41:45.526: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.93942255s
Dec 28 04:41:46.535: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.929717153s
Dec 28 04:41:47.546: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.920920747s
Dec 28 04:41:48.554: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.91061767s
Dec 28 04:41:49.562: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.902414503s
Dec 28 04:41:50.571: INFO: Verifying statefulset ss doesn't scale past 3 for another 893.78522ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacee2e-tests-statefulset-pjzv7
Dec 28 04:41:51.582: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994138694 exec --namespace=e2e-tests-statefulset-pjzv7 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec 28 04:41:52.047: INFO: stderr: ""
Dec 28 04:41:52.047: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Dec 28 04:41:52.047: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Dec 28 04:41:52.047: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994138694 exec --namespace=e2e-tests-statefulset-pjzv7 ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec 28 04:41:52.650: INFO: stderr: ""
Dec 28 04:41:52.650: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Dec 28 04:41:52.650: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Dec 28 04:41:52.650: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994138694 exec --namespace=e2e-tests-statefulset-pjzv7 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec 28 04:41:53.779: INFO: rc: 1
Dec 28 04:41:53.779: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-994138694 exec --namespace=e2e-tests-statefulset-pjzv7 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  error: unable to upgrade connection: container not found ("nginx")
 [] <nil> 0xc421690a20 exit status 1 <nil> <nil> true [0xc42000fcc0 0xc42000fd40 0xc42000fe20] [0xc42000fcc0 0xc42000fd40 0xc42000fe20] [0xc42000fd30 0xc42000fe18] [0x8fd520 0x8fd520] 0xc4214f9560 <nil>}:
Command stdout:

stderr:
error: unable to upgrade connection: container not found ("nginx")

error:
exit status 1

Dec 28 04:42:03.780: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994138694 exec --namespace=e2e-tests-statefulset-pjzv7 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec 28 04:42:04.048: INFO: rc: 1
Dec 28 04:42:04.049: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-994138694 exec --namespace=e2e-tests-statefulset-pjzv7 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc421690e10 exit status 1 <nil> <nil> true [0xc42000fe30 0xc42000fe90 0xc42000ff88] [0xc42000fe30 0xc42000fe90 0xc42000ff88] [0xc42000fe40 0xc42000ff48] [0x8fd520 0x8fd520] 0xc4214f9680 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Dec 28 04:42:14.049: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994138694 exec --namespace=e2e-tests-statefulset-pjzv7 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec 28 04:42:14.311: INFO: rc: 1
Dec 28 04:42:14.312: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-994138694 exec --namespace=e2e-tests-statefulset-pjzv7 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc421691200 exit status 1 <nil> <nil> true [0xc42000ff90 0xc42000ffd0 0xc42000fff8] [0xc42000ff90 0xc42000ffd0 0xc42000fff8] [0xc42000ffb8 0xc42000ffe0] [0x8fd520 0x8fd520] 0xc4214f97a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Dec 28 04:42:24.313: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994138694 exec --namespace=e2e-tests-statefulset-pjzv7 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec 28 04:42:24.581: INFO: rc: 1
Dec 28 04:42:24.581: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-994138694 exec --namespace=e2e-tests-statefulset-pjzv7 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc420f41bc0 exit status 1 <nil> <nil> true [0xc4200cad08 0xc4200cad70 0xc4200cade8] [0xc4200cad08 0xc4200cad70 0xc4200cade8] [0xc4200cad38 0xc4200cade0] [0x8fd520 0x8fd520] 0xc4210991a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Dec 28 04:42:34.582: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994138694 exec --namespace=e2e-tests-statefulset-pjzv7 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec 28 04:42:34.832: INFO: rc: 1
Dec 28 04:42:34.832: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-994138694 exec --namespace=e2e-tests-statefulset-pjzv7 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc420f41f80 exit status 1 <nil> <nil> true [0xc4200cadf8 0xc4200cae30 0xc4200cafb8] [0xc4200cadf8 0xc4200cae30 0xc4200cafb8] [0xc4200cae28 0xc4200caf10] [0x8fd520 0x8fd520] 0xc4210992c0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Dec 28 04:42:44.833: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994138694 exec --namespace=e2e-tests-statefulset-pjzv7 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec 28 04:42:45.117: INFO: rc: 1
Dec 28 04:42:45.117: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-994138694 exec --namespace=e2e-tests-statefulset-pjzv7 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc421718390 exit status 1 <nil> <nil> true [0xc4200cafe0 0xc4200cb040 0xc4200cb088] [0xc4200cafe0 0xc4200cb040 0xc4200cb088] [0xc4200cb008 0xc4200cb070] [0x8fd520 0x8fd520] 0xc4210993e0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Dec 28 04:42:55.118: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994138694 exec --namespace=e2e-tests-statefulset-pjzv7 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec 28 04:42:55.384: INFO: rc: 1
Dec 28 04:42:55.384: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-994138694 exec --namespace=e2e-tests-statefulset-pjzv7 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc421691650 exit status 1 <nil> <nil> true [0xc4207360d8 0xc420736150 0xc420736230] [0xc4207360d8 0xc420736150 0xc420736230] [0xc4207360f8 0xc4207361d0] [0x8fd520 0x8fd520] 0xc4214f98c0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Dec 28 04:43:05.385: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994138694 exec --namespace=e2e-tests-statefulset-pjzv7 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec 28 04:43:05.632: INFO: rc: 1
Dec 28 04:43:05.632: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-994138694 exec --namespace=e2e-tests-statefulset-pjzv7 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc421691c20 exit status 1 <nil> <nil> true [0xc420736290 0xc420736380 0xc4207364a8] [0xc420736290 0xc420736380 0xc4207364a8] [0xc420736320 0xc420736438] [0x8fd520 0x8fd520] 0xc4214f99e0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Dec 28 04:43:15.633: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994138694 exec --namespace=e2e-tests-statefulset-pjzv7 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec 28 04:43:15.892: INFO: rc: 1
Dec 28 04:43:15.892: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-994138694 exec --namespace=e2e-tests-statefulset-pjzv7 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc42136c1e0 exit status 1 <nil> <nil> true [0xc4207364c8 0xc420736580 0xc4207365d0] [0xc4207364c8 0xc420736580 0xc4207365d0] [0xc420736528 0xc4207365b0] [0x8fd520 0x8fd520] 0xc4214f9b00 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Dec 28 04:43:25.892: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994138694 exec --namespace=e2e-tests-statefulset-pjzv7 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec 28 04:43:26.168: INFO: rc: 1
Dec 28 04:43:26.169: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-994138694 exec --namespace=e2e-tests-statefulset-pjzv7 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc42136c630 exit status 1 <nil> <nil> true [0xc4207365d8 0xc4207366e8 0xc4207367e8] [0xc4207365d8 0xc4207366e8 0xc4207367e8] [0xc420736638 0xc4207367d8] [0x8fd520 0x8fd520] 0xc4214f9c20 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Dec 28 04:43:36.169: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994138694 exec --namespace=e2e-tests-statefulset-pjzv7 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec 28 04:43:36.522: INFO: rc: 1
Dec 28 04:43:36.522: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-994138694 exec --namespace=e2e-tests-statefulset-pjzv7 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc4217187b0 exit status 1 <nil> <nil> true [0xc4200cb0a0 0xc4200cb138 0xc421744030] [0xc4200cb0a0 0xc4200cb138 0xc421744030] [0xc4200cb120 0xc421744020] [0x8fd520 0x8fd520] 0xc421099500 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Dec 28 04:43:46.523: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994138694 exec --namespace=e2e-tests-statefulset-pjzv7 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec 28 04:43:46.938: INFO: rc: 1
Dec 28 04:43:46.939: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-994138694 exec --namespace=e2e-tests-statefulset-pjzv7 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc421b1a420 exit status 1 <nil> <nil> true [0xc42000e570 0xc42000ea40 0xc42000eba8] [0xc42000e570 0xc42000ea40 0xc42000eba8] [0xc42000e938 0xc42000eba0] [0x8fd520 0x8fd520] 0xc421098000 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Dec 28 04:43:56.940: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994138694 exec --namespace=e2e-tests-statefulset-pjzv7 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec 28 04:43:57.203: INFO: rc: 1
Dec 28 04:43:57.203: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-994138694 exec --namespace=e2e-tests-statefulset-pjzv7 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc4216903f0 exit status 1 <nil> <nil> true [0xc4200ca148 0xc4200ca2b0 0xc4200ca390] [0xc4200ca148 0xc4200ca2b0 0xc4200ca390] [0xc4200ca210 0xc4200ca360] [0x8fd520 0x8fd520] 0xc4214f8060 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Dec 28 04:44:07.203: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994138694 exec --namespace=e2e-tests-statefulset-pjzv7 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec 28 04:44:07.456: INFO: rc: 1
Dec 28 04:44:07.456: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-994138694 exec --namespace=e2e-tests-statefulset-pjzv7 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc421b1a870 exit status 1 <nil> <nil> true [0xc42000ec40 0xc42000ed18 0xc42000edd0] [0xc42000ec40 0xc42000ed18 0xc42000edd0] [0xc42000ece0 0xc42000ed90] [0x8fd520 0x8fd520] 0xc421098120 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Dec 28 04:44:17.457: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994138694 exec --namespace=e2e-tests-statefulset-pjzv7 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec 28 04:44:17.718: INFO: rc: 1
Dec 28 04:44:17.718: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-994138694 exec --namespace=e2e-tests-statefulset-pjzv7 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc421690810 exit status 1 <nil> <nil> true [0xc4200ca428 0xc4200ca5c0 0xc4200ca688] [0xc4200ca428 0xc4200ca5c0 0xc4200ca688] [0xc4200ca5b0 0xc4200ca5d8] [0x8fd520 0x8fd520] 0xc4214f8180 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Dec 28 04:44:27.719: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994138694 exec --namespace=e2e-tests-statefulset-pjzv7 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec 28 04:44:28.058: INFO: rc: 1
Dec 28 04:44:28.058: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-994138694 exec --namespace=e2e-tests-statefulset-pjzv7 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc421690c30 exit status 1 <nil> <nil> true [0xc4200ca690 0xc4200cab48 0xc4200cabc0] [0xc4200ca690 0xc4200cab48 0xc4200cabc0] [0xc4200ca7b0 0xc4200caba8] [0x8fd520 0x8fd520] 0xc4214f82a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Dec 28 04:44:38.059: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994138694 exec --namespace=e2e-tests-statefulset-pjzv7 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec 28 04:44:38.339: INFO: rc: 1
Dec 28 04:44:38.339: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-994138694 exec --namespace=e2e-tests-statefulset-pjzv7 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc421691020 exit status 1 <nil> <nil> true [0xc4200cabd0 0xc4200cacc0 0xc4200cad38] [0xc4200cabd0 0xc4200cacc0 0xc4200cad38] [0xc4200cac80 0xc4200cad28] [0x8fd520 0x8fd520] 0xc4214f83c0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Dec 28 04:44:48.339: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994138694 exec --namespace=e2e-tests-statefulset-pjzv7 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec 28 04:44:48.602: INFO: rc: 1
Dec 28 04:44:48.602: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-994138694 exec --namespace=e2e-tests-statefulset-pjzv7 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc421691470 exit status 1 <nil> <nil> true [0xc4200cad70 0xc4200cade8 0xc4200cae28] [0xc4200cad70 0xc4200cade8 0xc4200cae28] [0xc4200cade0 0xc4200cae20] [0x8fd520 0x8fd520] 0xc4214f84e0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Dec 28 04:44:58.602: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994138694 exec --namespace=e2e-tests-statefulset-pjzv7 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec 28 04:44:58.861: INFO: rc: 1
Dec 28 04:44:58.861: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-994138694 exec --namespace=e2e-tests-statefulset-pjzv7 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc4216919b0 exit status 1 <nil> <nil> true [0xc4200cae30 0xc4200cafb8 0xc4200cb008] [0xc4200cae30 0xc4200cafb8 0xc4200cb008] [0xc4200caf10 0xc4200cafe8] [0x8fd520 0x8fd520] 0xc4214f8600 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Dec 28 04:45:08.861: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994138694 exec --namespace=e2e-tests-statefulset-pjzv7 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec 28 04:45:09.156: INFO: rc: 1
Dec 28 04:45:09.156: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-994138694 exec --namespace=e2e-tests-statefulset-pjzv7 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc421691e90 exit status 1 <nil> <nil> true [0xc4200cb040 0xc4200cb088 0xc4200cb120] [0xc4200cb040 0xc4200cb088 0xc4200cb120] [0xc4200cb070 0xc4200cb0c0] [0x8fd520 0x8fd520] 0xc4214f8720 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Dec 28 04:45:19.157: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994138694 exec --namespace=e2e-tests-statefulset-pjzv7 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec 28 04:45:19.415: INFO: rc: 1
Dec 28 04:45:19.415: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-994138694 exec --namespace=e2e-tests-statefulset-pjzv7 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc420f40330 exit status 1 <nil> <nil> true [0xc4200cb138 0xc421744030 0xc421744058] [0xc4200cb138 0xc421744030 0xc421744058] [0xc421744020 0xc421744050] [0x8fd520 0x8fd520] 0xc4214f9200 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Dec 28 04:45:29.415: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994138694 exec --namespace=e2e-tests-statefulset-pjzv7 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec 28 04:45:29.678: INFO: rc: 1
Dec 28 04:45:29.678: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-994138694 exec --namespace=e2e-tests-statefulset-pjzv7 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc420f40750 exit status 1 <nil> <nil> true [0xc421744070 0xc4217440c0 0xc421744108] [0xc421744070 0xc4217440c0 0xc421744108] [0xc4217440b8 0xc421744100] [0x8fd520 0x8fd520] 0xc4214f93e0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Dec 28 04:45:39.679: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994138694 exec --namespace=e2e-tests-statefulset-pjzv7 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec 28 04:45:39.988: INFO: rc: 1
Dec 28 04:45:39.989: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-994138694 exec --namespace=e2e-tests-statefulset-pjzv7 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc420f40b10 exit status 1 <nil> <nil> true [0xc421744110 0xc421744130 0xc4217441b0] [0xc421744110 0xc421744130 0xc4217441b0] [0xc421744120 0xc421744148] [0x8fd520 0x8fd520] 0xc4214f9500 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Dec 28 04:45:49.989: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994138694 exec --namespace=e2e-tests-statefulset-pjzv7 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec 28 04:45:50.273: INFO: rc: 1
Dec 28 04:45:50.273: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-994138694 exec --namespace=e2e-tests-statefulset-pjzv7 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc420f40b70 exit status 1 <nil> <nil> true [0xc42000ee98 0xc42000f058 0xc42000f0d0] [0xc42000ee98 0xc42000f058 0xc42000f0d0] [0xc42000efa0 0xc42000f0a0] [0x8fd520 0x8fd520] 0xc4214f95c0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Dec 28 04:46:00.274: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994138694 exec --namespace=e2e-tests-statefulset-pjzv7 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec 28 04:46:00.551: INFO: rc: 1
Dec 28 04:46:00.552: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-994138694 exec --namespace=e2e-tests-statefulset-pjzv7 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc4216903c0 exit status 1 <nil> <nil> true [0xc4200ca198 0xc4200ca308 0xc4200ca428] [0xc4200ca198 0xc4200ca308 0xc4200ca428] [0xc4200ca2b0 0xc4200ca390] [0x8fd520 0x8fd520] 0xc421098000 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Dec 28 04:46:10.552: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994138694 exec --namespace=e2e-tests-statefulset-pjzv7 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec 28 04:46:10.803: INFO: rc: 1
Dec 28 04:46:10.803: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-994138694 exec --namespace=e2e-tests-statefulset-pjzv7 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc421b1a450 exit status 1 <nil> <nil> true [0xc42000e010 0xc42000e938 0xc42000eba0] [0xc42000e010 0xc42000e938 0xc42000eba0] [0xc42000e730 0xc42000eac0] [0x8fd520 0x8fd520] 0xc4214f8060 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Dec 28 04:46:20.804: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994138694 exec --namespace=e2e-tests-statefulset-pjzv7 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec 28 04:46:21.089: INFO: rc: 1
Dec 28 04:46:21.089: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-994138694 exec --namespace=e2e-tests-statefulset-pjzv7 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc421690840 exit status 1 <nil> <nil> true [0xc4200ca4c8 0xc4200ca5d0 0xc4200ca690] [0xc4200ca4c8 0xc4200ca5d0 0xc4200ca690] [0xc4200ca5c0 0xc4200ca688] [0x8fd520 0x8fd520] 0xc421098120 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Dec 28 04:46:31.089: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994138694 exec --namespace=e2e-tests-statefulset-pjzv7 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec 28 04:46:31.357: INFO: rc: 1
Dec 28 04:46:31.358: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-994138694 exec --namespace=e2e-tests-statefulset-pjzv7 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc421b1a8d0 exit status 1 <nil> <nil> true [0xc42000eba8 0xc42000ece0 0xc42000ed90] [0xc42000eba8 0xc42000ece0 0xc42000ed90] [0xc42000ecb0 0xc42000ed70] [0x8fd520 0x8fd520] 0xc4214f8180 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Dec 28 04:46:41.358: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994138694 exec --namespace=e2e-tests-statefulset-pjzv7 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec 28 04:46:41.749: INFO: rc: 1
Dec 28 04:46:41.749: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-994138694 exec --namespace=e2e-tests-statefulset-pjzv7 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc421b1af90 exit status 1 <nil> <nil> true [0xc42000edd0 0xc42000f138 0xc42000f420] [0xc42000edd0 0xc42000f138 0xc42000f420] [0xc42000f088 0xc42000f290] [0x8fd520 0x8fd520] 0xc4214f82a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Dec 28 04:46:51.750: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994138694 exec --namespace=e2e-tests-statefulset-pjzv7 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec 28 04:46:52.019: INFO: rc: 1
Dec 28 04:46:52.019: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-994138694 exec --namespace=e2e-tests-statefulset-pjzv7 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc421690c90 exit status 1 <nil> <nil> true [0xc4200ca798 0xc4200caba0 0xc4200cabd0] [0xc4200ca798 0xc4200caba0 0xc4200cabd0] [0xc4200cab48 0xc4200cabc0] [0x8fd520 0x8fd520] 0xc421098240 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Dec 28 04:47:02.021: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994138694 exec --namespace=e2e-tests-statefulset-pjzv7 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec 28 04:47:02.363: INFO: rc: 1
Dec 28 04:47:02.364: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-2: 
Dec 28 04:47:02.364: INFO: Scaling statefulset ss to 0
STEP: Verifying that stateful set ss was scaled down in reverse order
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Dec 28 04:47:02.394: INFO: Deleting all statefulset in ns e2e-tests-statefulset-pjzv7
Dec 28 04:47:02.400: INFO: Scaling statefulset ss to 0
Dec 28 04:47:02.420: INFO: Waiting for statefulset status.replicas updated to 0
Dec 28 04:47:02.425: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 28 04:47:02.470: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-pjzv7" for this suite.
Dec 28 04:47:10.784: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 04:47:10.953: INFO: namespace: e2e-tests-statefulset-pjzv7, resource: bindings, ignored listing per whitelist
Dec 28 04:47:11.056: INFO: namespace e2e-tests-statefulset-pjzv7 deletion completed in 8.4108366s

• [SLOW TEST:403.714 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 28 04:47:11.057: INFO: >>> kubeConfig: /tmp/kubeconfig-994138694
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test substitution in container's command
Dec 28 04:47:11.296: INFO: Waiting up to 5m0s for pod "var-expansion-a37ba09e-0a5b-11e9-8a07-628dff7095f4" in namespace "e2e-tests-var-expansion-sqtxb" to be "success or failure"
Dec 28 04:47:11.307: INFO: Pod "var-expansion-a37ba09e-0a5b-11e9-8a07-628dff7095f4": Phase="Pending", Reason="", readiness=false. Elapsed: 10.686473ms
Dec 28 04:47:13.314: INFO: Pod "var-expansion-a37ba09e-0a5b-11e9-8a07-628dff7095f4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01774927s
Dec 28 04:47:15.321: INFO: Pod "var-expansion-a37ba09e-0a5b-11e9-8a07-628dff7095f4": Phase="Pending", Reason="", readiness=false. Elapsed: 4.024679006s
Dec 28 04:47:17.327: INFO: Pod "var-expansion-a37ba09e-0a5b-11e9-8a07-628dff7095f4": Phase="Pending", Reason="", readiness=false. Elapsed: 6.031204176s
Dec 28 04:47:19.334: INFO: Pod "var-expansion-a37ba09e-0a5b-11e9-8a07-628dff7095f4": Phase="Running", Reason="", readiness=true. Elapsed: 8.03777283s
Dec 28 04:47:21.341: INFO: Pod "var-expansion-a37ba09e-0a5b-11e9-8a07-628dff7095f4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 10.044609673s
STEP: Saw pod success
Dec 28 04:47:21.341: INFO: Pod "var-expansion-a37ba09e-0a5b-11e9-8a07-628dff7095f4" satisfied condition "success or failure"
Dec 28 04:47:21.346: INFO: Trying to get logs from node 10.10.102.68-share pod var-expansion-a37ba09e-0a5b-11e9-8a07-628dff7095f4 container dapi-container: <nil>
STEP: delete the pod
Dec 28 04:47:21.498: INFO: Waiting for pod var-expansion-a37ba09e-0a5b-11e9-8a07-628dff7095f4 to disappear
Dec 28 04:47:21.514: INFO: Pod var-expansion-a37ba09e-0a5b-11e9-8a07-628dff7095f4 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 28 04:47:21.514: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-var-expansion-sqtxb" for this suite.
Dec 28 04:47:27.617: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 04:47:27.735: INFO: namespace: e2e-tests-var-expansion-sqtxb, resource: bindings, ignored listing per whitelist
Dec 28 04:47:27.820: INFO: namespace e2e-tests-var-expansion-sqtxb deletion completed in 6.237700797s

• [SLOW TEST:16.763 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Projected 
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 28 04:47:27.820: INFO: >>> kubeConfig: /tmp/kubeconfig-994138694
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-projected-all-test-volume-ad7aa439-0a5b-11e9-8a07-628dff7095f4
STEP: Creating secret with name secret-projected-all-test-volume-ad7aa3f1-0a5b-11e9-8a07-628dff7095f4
STEP: Creating a pod to test Check all projections for projected volume plugin
Dec 28 04:47:28.097: INFO: Waiting up to 5m0s for pod "projected-volume-ad7aa333-0a5b-11e9-8a07-628dff7095f4" in namespace "e2e-tests-projected-q7fxs" to be "success or failure"
Dec 28 04:47:28.108: INFO: Pod "projected-volume-ad7aa333-0a5b-11e9-8a07-628dff7095f4": Phase="Pending", Reason="", readiness=false. Elapsed: 10.226927ms
Dec 28 04:47:30.115: INFO: Pod "projected-volume-ad7aa333-0a5b-11e9-8a07-628dff7095f4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.017938544s
Dec 28 04:47:32.123: INFO: Pod "projected-volume-ad7aa333-0a5b-11e9-8a07-628dff7095f4": Phase="Pending", Reason="", readiness=false. Elapsed: 4.02534316s
Dec 28 04:47:34.130: INFO: Pod "projected-volume-ad7aa333-0a5b-11e9-8a07-628dff7095f4": Phase="Pending", Reason="", readiness=false. Elapsed: 6.03251387s
Dec 28 04:47:36.139: INFO: Pod "projected-volume-ad7aa333-0a5b-11e9-8a07-628dff7095f4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.041158444s
STEP: Saw pod success
Dec 28 04:47:36.139: INFO: Pod "projected-volume-ad7aa333-0a5b-11e9-8a07-628dff7095f4" satisfied condition "success or failure"
Dec 28 04:47:36.144: INFO: Trying to get logs from node 10.10.102.69-build pod projected-volume-ad7aa333-0a5b-11e9-8a07-628dff7095f4 container projected-all-volume-test: <nil>
STEP: delete the pod
Dec 28 04:47:36.228: INFO: Waiting for pod projected-volume-ad7aa333-0a5b-11e9-8a07-628dff7095f4 to disappear
Dec 28 04:47:36.238: INFO: Pod projected-volume-ad7aa333-0a5b-11e9-8a07-628dff7095f4 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 28 04:47:36.238: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-q7fxs" for this suite.
Dec 28 04:47:42.296: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 04:47:42.382: INFO: namespace: e2e-tests-projected-q7fxs, resource: bindings, ignored listing per whitelist
Dec 28 04:47:42.510: INFO: namespace e2e-tests-projected-q7fxs deletion completed in 6.252751604s

• [SLOW TEST:14.690 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 28 04:47:42.511: INFO: >>> kubeConfig: /tmp/kubeconfig-994138694
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0666 on node default medium
Dec 28 04:47:42.788: INFO: Waiting up to 5m0s for pod "pod-b63e494b-0a5b-11e9-8a07-628dff7095f4" in namespace "e2e-tests-emptydir-v5fwc" to be "success or failure"
Dec 28 04:47:42.802: INFO: Pod "pod-b63e494b-0a5b-11e9-8a07-628dff7095f4": Phase="Pending", Reason="", readiness=false. Elapsed: 13.790964ms
Dec 28 04:47:44.809: INFO: Pod "pod-b63e494b-0a5b-11e9-8a07-628dff7095f4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.020951187s
Dec 28 04:47:46.818: INFO: Pod "pod-b63e494b-0a5b-11e9-8a07-628dff7095f4": Phase="Pending", Reason="", readiness=false. Elapsed: 4.029725337s
Dec 28 04:47:48.827: INFO: Pod "pod-b63e494b-0a5b-11e9-8a07-628dff7095f4": Phase="Pending", Reason="", readiness=false. Elapsed: 6.038245407s
Dec 28 04:47:50.839: INFO: Pod "pod-b63e494b-0a5b-11e9-8a07-628dff7095f4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.051046467s
STEP: Saw pod success
Dec 28 04:47:50.841: INFO: Pod "pod-b63e494b-0a5b-11e9-8a07-628dff7095f4" satisfied condition "success or failure"
Dec 28 04:47:50.876: INFO: Trying to get logs from node 10.10.102.68-share pod pod-b63e494b-0a5b-11e9-8a07-628dff7095f4 container test-container: <nil>
STEP: delete the pod
Dec 28 04:47:50.976: INFO: Waiting for pod pod-b63e494b-0a5b-11e9-8a07-628dff7095f4 to disappear
Dec 28 04:47:51.020: INFO: Pod pod-b63e494b-0a5b-11e9-8a07-628dff7095f4 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 28 04:47:51.020: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-v5fwc" for this suite.
Dec 28 04:47:57.061: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 04:47:57.298: INFO: namespace: e2e-tests-emptydir-v5fwc, resource: bindings, ignored listing per whitelist
Dec 28 04:47:57.385: INFO: namespace e2e-tests-emptydir-v5fwc deletion completed in 6.350944106s

• [SLOW TEST:14.874 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Downward API volume 
  should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 28 04:47:57.385: INFO: >>> kubeConfig: /tmp/kubeconfig-994138694
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Dec 28 04:47:57.647: INFO: Waiting up to 5m0s for pod "downwardapi-volume-bf1a23aa-0a5b-11e9-8a07-628dff7095f4" in namespace "e2e-tests-downward-api-rhjpq" to be "success or failure"
Dec 28 04:47:57.732: INFO: Pod "downwardapi-volume-bf1a23aa-0a5b-11e9-8a07-628dff7095f4": Phase="Pending", Reason="", readiness=false. Elapsed: 84.7394ms
Dec 28 04:47:59.739: INFO: Pod "downwardapi-volume-bf1a23aa-0a5b-11e9-8a07-628dff7095f4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.092214853s
Dec 28 04:48:01.753: INFO: Pod "downwardapi-volume-bf1a23aa-0a5b-11e9-8a07-628dff7095f4": Phase="Pending", Reason="", readiness=false. Elapsed: 4.10609156s
Dec 28 04:48:03.761: INFO: Pod "downwardapi-volume-bf1a23aa-0a5b-11e9-8a07-628dff7095f4": Phase="Pending", Reason="", readiness=false. Elapsed: 6.113708143s
Dec 28 04:48:05.768: INFO: Pod "downwardapi-volume-bf1a23aa-0a5b-11e9-8a07-628dff7095f4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.12067138s
STEP: Saw pod success
Dec 28 04:48:05.768: INFO: Pod "downwardapi-volume-bf1a23aa-0a5b-11e9-8a07-628dff7095f4" satisfied condition "success or failure"
Dec 28 04:48:05.775: INFO: Trying to get logs from node 10.10.102.69-build pod downwardapi-volume-bf1a23aa-0a5b-11e9-8a07-628dff7095f4 container client-container: <nil>
STEP: delete the pod
Dec 28 04:48:05.826: INFO: Waiting for pod downwardapi-volume-bf1a23aa-0a5b-11e9-8a07-628dff7095f4 to disappear
Dec 28 04:48:05.848: INFO: Pod downwardapi-volume-bf1a23aa-0a5b-11e9-8a07-628dff7095f4 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 28 04:48:05.848: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-rhjpq" for this suite.
Dec 28 04:48:12.235: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 04:48:12.274: INFO: namespace: e2e-tests-downward-api-rhjpq, resource: bindings, ignored listing per whitelist
Dec 28 04:48:12.447: INFO: namespace e2e-tests-downward-api-rhjpq deletion completed in 6.581730773s

• [SLOW TEST:15.062 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 28 04:48:12.447: INFO: >>> kubeConfig: /tmp/kubeconfig-994138694
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0644 on tmpfs
Dec 28 04:48:12.939: INFO: Waiting up to 5m0s for pod "pod-c83cae73-0a5b-11e9-8a07-628dff7095f4" in namespace "e2e-tests-emptydir-5wp2j" to be "success or failure"
Dec 28 04:48:12.949: INFO: Pod "pod-c83cae73-0a5b-11e9-8a07-628dff7095f4": Phase="Pending", Reason="", readiness=false. Elapsed: 10.19725ms
Dec 28 04:48:14.956: INFO: Pod "pod-c83cae73-0a5b-11e9-8a07-628dff7095f4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.016406904s
Dec 28 04:48:16.963: INFO: Pod "pod-c83cae73-0a5b-11e9-8a07-628dff7095f4": Phase="Pending", Reason="", readiness=false. Elapsed: 4.02370296s
Dec 28 04:48:18.982: INFO: Pod "pod-c83cae73-0a5b-11e9-8a07-628dff7095f4": Phase="Pending", Reason="", readiness=false. Elapsed: 6.042357354s
Dec 28 04:48:20.989: INFO: Pod "pod-c83cae73-0a5b-11e9-8a07-628dff7095f4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.050128264s
STEP: Saw pod success
Dec 28 04:48:20.989: INFO: Pod "pod-c83cae73-0a5b-11e9-8a07-628dff7095f4" satisfied condition "success or failure"
Dec 28 04:48:20.997: INFO: Trying to get logs from node 10.10.102.68-share pod pod-c83cae73-0a5b-11e9-8a07-628dff7095f4 container test-container: <nil>
STEP: delete the pod
Dec 28 04:48:21.543: INFO: Waiting for pod pod-c83cae73-0a5b-11e9-8a07-628dff7095f4 to disappear
Dec 28 04:48:21.567: INFO: Pod pod-c83cae73-0a5b-11e9-8a07-628dff7095f4 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 28 04:48:21.567: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-5wp2j" for this suite.
Dec 28 04:48:27.706: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 04:48:27.888: INFO: namespace: e2e-tests-emptydir-5wp2j, resource: bindings, ignored listing per whitelist
Dec 28 04:48:27.969: INFO: namespace e2e-tests-emptydir-5wp2j deletion completed in 6.36325547s

• [SLOW TEST:15.522 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[k8s.io] Pods 
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 28 04:48:27.970: INFO: >>> kubeConfig: /tmp/kubeconfig-994138694
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: setting up watch
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: verifying pod creation was observed
Dec 28 04:48:36.302: INFO: running pod: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-submit-remove-d155bba6-0a5b-11e9-8a07-628dff7095f4", GenerateName:"", Namespace:"e2e-tests-pods-rjf7d", SelfLink:"/api/v1/namespaces/e2e-tests-pods-rjf7d/pods/pod-submit-remove-d155bba6-0a5b-11e9-8a07-628dff7095f4", UID:"d173108d-0a5b-11e9-a0ee-005056bc4922", ResourceVersion:"522914", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63681569308, loc:(*time.Location)(0x6c43b60)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"186932427"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Initializers:(*v1.Initializers)(nil), Finalizers:[]string(nil), ClusterName:""}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"default-token-wvh9h", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(0xc422067bc0), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil)}}}, InitContainers:[]v1.Container(nil), Containers:[]v1.Container{v1.Container{Name:"nginx", Image:"docker.io/library/nginx:1.14-alpine", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-wvh9h", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc421f9fe98), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"10.10.102.69-build", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc421e4d980), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc421f9fed0)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc421f9fef0)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc421f9fef8), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil)}, Status:v1.PodStatus{Phase:"Running", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63681569308, loc:(*time.Location)(0x6c43b60)}}, Reason:"", Message:""}, v1.PodCondition{Type:"Ready", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63681569316, loc:(*time.Location)(0x6c43b60)}}, Reason:"", Message:""}, v1.PodCondition{Type:"ContainersReady", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63681569316, loc:(*time.Location)(0x6c43b60)}}, Reason:"", Message:""}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63681569308, loc:(*time.Location)(0x6c43b60)}}, Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"10.10.102.69", PodIP:"10.168.192.51", StartTime:(*v1.Time)(0xc421572d60), InitContainerStatuses:[]v1.ContainerStatus(nil), ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"nginx", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(0xc421572da0), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:true, RestartCount:0, Image:"nginx:1.14-alpine", ImageID:"docker-pullable://nginx@sha256:e3f77f7f4a6bb5e7820e013fa60b96602b34f5704e796cfd94b561ae73adcf96", ContainerID:"docker://c991778b9847fc4e9eb607ff2b207e765dd8393ca71cff4380ee4d57e0cd0b14"}}, QOSClass:"BestEffort"}}
STEP: deleting the pod gracefully
STEP: verifying the kubelet observed the termination notice
Dec 28 04:48:41.368: INFO: no pod exists with the name we were looking for, assuming the termination request was observed and completed
STEP: verifying pod deletion was observed
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 28 04:48:41.375: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-rjf7d" for this suite.
Dec 28 04:48:47.417: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 04:48:47.556: INFO: namespace: e2e-tests-pods-rjf7d, resource: bindings, ignored listing per whitelist
Dec 28 04:48:47.743: INFO: namespace e2e-tests-pods-rjf7d deletion completed in 6.35494672s

• [SLOW TEST:19.774 seconds]
[k8s.io] Pods
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 28 04:48:47.744: INFO: >>> kubeConfig: /tmp/kubeconfig-994138694
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-dd27df0c-0a5b-11e9-8a07-628dff7095f4
STEP: Creating a pod to test consume secrets
Dec 28 04:48:48.097: INFO: Waiting up to 5m0s for pod "pod-secrets-dd2b19fe-0a5b-11e9-8a07-628dff7095f4" in namespace "e2e-tests-secrets-zjvj6" to be "success or failure"
Dec 28 04:48:48.109: INFO: Pod "pod-secrets-dd2b19fe-0a5b-11e9-8a07-628dff7095f4": Phase="Pending", Reason="", readiness=false. Elapsed: 11.77622ms
Dec 28 04:48:50.117: INFO: Pod "pod-secrets-dd2b19fe-0a5b-11e9-8a07-628dff7095f4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01926021s
Dec 28 04:48:52.139: INFO: Pod "pod-secrets-dd2b19fe-0a5b-11e9-8a07-628dff7095f4": Phase="Pending", Reason="", readiness=false. Elapsed: 4.04151016s
Dec 28 04:48:54.185: INFO: Pod "pod-secrets-dd2b19fe-0a5b-11e9-8a07-628dff7095f4": Phase="Pending", Reason="", readiness=false. Elapsed: 6.08796081s
Dec 28 04:48:56.191: INFO: Pod "pod-secrets-dd2b19fe-0a5b-11e9-8a07-628dff7095f4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.09390702s
STEP: Saw pod success
Dec 28 04:48:56.191: INFO: Pod "pod-secrets-dd2b19fe-0a5b-11e9-8a07-628dff7095f4" satisfied condition "success or failure"
Dec 28 04:48:56.197: INFO: Trying to get logs from node 10.10.102.68-share pod pod-secrets-dd2b19fe-0a5b-11e9-8a07-628dff7095f4 container secret-volume-test: <nil>
STEP: delete the pod
Dec 28 04:48:56.248: INFO: Waiting for pod pod-secrets-dd2b19fe-0a5b-11e9-8a07-628dff7095f4 to disappear
Dec 28 04:48:56.310: INFO: Pod pod-secrets-dd2b19fe-0a5b-11e9-8a07-628dff7095f4 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 28 04:48:56.310: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-zjvj6" for this suite.
Dec 28 04:49:02.348: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 04:49:02.449: INFO: namespace: e2e-tests-secrets-zjvj6, resource: bindings, ignored listing per whitelist
Dec 28 04:49:02.564: INFO: namespace e2e-tests-secrets-zjvj6 deletion completed in 6.241052543s

• [SLOW TEST:14.820 seconds]
[sig-storage] Secrets
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 28 04:49:02.564: INFO: >>> kubeConfig: /tmp/kubeconfig-994138694
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-e5f72aad-0a5b-11e9-8a07-628dff7095f4
STEP: Creating a pod to test consume secrets
Dec 28 04:49:02.821: INFO: Waiting up to 5m0s for pod "pod-secrets-e5f86caa-0a5b-11e9-8a07-628dff7095f4" in namespace "e2e-tests-secrets-msg7c" to be "success or failure"
Dec 28 04:49:02.836: INFO: Pod "pod-secrets-e5f86caa-0a5b-11e9-8a07-628dff7095f4": Phase="Pending", Reason="", readiness=false. Elapsed: 14.985283ms
Dec 28 04:49:04.843: INFO: Pod "pod-secrets-e5f86caa-0a5b-11e9-8a07-628dff7095f4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.021890853s
Dec 28 04:49:06.850: INFO: Pod "pod-secrets-e5f86caa-0a5b-11e9-8a07-628dff7095f4": Phase="Pending", Reason="", readiness=false. Elapsed: 4.0287529s
Dec 28 04:49:08.856: INFO: Pod "pod-secrets-e5f86caa-0a5b-11e9-8a07-628dff7095f4": Phase="Pending", Reason="", readiness=false. Elapsed: 6.035030406s
Dec 28 04:49:10.867: INFO: Pod "pod-secrets-e5f86caa-0a5b-11e9-8a07-628dff7095f4": Phase="Running", Reason="", readiness=true. Elapsed: 8.04627784s
Dec 28 04:49:12.875: INFO: Pod "pod-secrets-e5f86caa-0a5b-11e9-8a07-628dff7095f4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 10.05382292s
STEP: Saw pod success
Dec 28 04:49:12.875: INFO: Pod "pod-secrets-e5f86caa-0a5b-11e9-8a07-628dff7095f4" satisfied condition "success or failure"
Dec 28 04:49:12.881: INFO: Trying to get logs from node 10.10.102.69-build pod pod-secrets-e5f86caa-0a5b-11e9-8a07-628dff7095f4 container secret-volume-test: <nil>
STEP: delete the pod
Dec 28 04:49:13.187: INFO: Waiting for pod pod-secrets-e5f86caa-0a5b-11e9-8a07-628dff7095f4 to disappear
Dec 28 04:49:13.217: INFO: Pod pod-secrets-e5f86caa-0a5b-11e9-8a07-628dff7095f4 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 28 04:49:13.217: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-msg7c" for this suite.
Dec 28 04:49:19.304: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 04:49:19.506: INFO: namespace: e2e-tests-secrets-msg7c, resource: bindings, ignored listing per whitelist
Dec 28 04:49:19.570: INFO: namespace e2e-tests-secrets-msg7c deletion completed in 6.33946478s

• [SLOW TEST:17.006 seconds]
[sig-storage] Secrets
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 28 04:49:19.571: INFO: >>> kubeConfig: /tmp/kubeconfig-994138694
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-exec in namespace e2e-tests-container-probe-kd4l7
Dec 28 04:49:27.915: INFO: Started pod liveness-exec in namespace e2e-tests-container-probe-kd4l7
STEP: checking the pod's current state and verifying that restartCount is present
Dec 28 04:49:27.920: INFO: Initial restart count of pod liveness-exec is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 28 04:53:29.172: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-kd4l7" for this suite.
Dec 28 04:53:35.243: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 04:53:35.498: INFO: namespace: e2e-tests-container-probe-kd4l7, resource: bindings, ignored listing per whitelist
Dec 28 04:53:35.529: INFO: namespace e2e-tests-container-probe-kd4l7 deletion completed in 6.311155583s

• [SLOW TEST:255.957 seconds]
[k8s.io] Probing container
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-api-machinery] Garbage collector 
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 28 04:53:35.529: INFO: >>> kubeConfig: /tmp/kubeconfig-994138694
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the rc1
STEP: create the rc2
STEP: set half of pods created by rc simpletest-rc-to-be-deleted to have rc simpletest-rc-to-stay as owner as well
STEP: delete the rc simpletest-rc-to-be-deleted
STEP: wait for the rc to be deleted
STEP: Gathering metrics
Dec 28 04:53:46.233: INFO: MetricsGrabber failed grab metrics. Skipping metrics gathering.
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 28 04:53:46.233: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-grllk" for this suite.
Dec 28 04:53:54.276: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 04:53:54.457: INFO: namespace: e2e-tests-gc-grllk, resource: bindings, ignored listing per whitelist
Dec 28 04:53:54.493: INFO: namespace e2e-tests-gc-grllk deletion completed in 8.2515066s

• [SLOW TEST:18.964 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 28 04:53:54.493: INFO: >>> kubeConfig: /tmp/kubeconfig-994138694
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Dec 28 04:53:54.834: INFO: Waiting up to 5m0s for pod "downwardapi-volume-9405a526-0a5c-11e9-8a07-628dff7095f4" in namespace "e2e-tests-downward-api-tlj6l" to be "success or failure"
Dec 28 04:53:54.902: INFO: Pod "downwardapi-volume-9405a526-0a5c-11e9-8a07-628dff7095f4": Phase="Pending", Reason="", readiness=false. Elapsed: 67.988084ms
Dec 28 04:53:56.910: INFO: Pod "downwardapi-volume-9405a526-0a5c-11e9-8a07-628dff7095f4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.07670265s
Dec 28 04:53:58.918: INFO: Pod "downwardapi-volume-9405a526-0a5c-11e9-8a07-628dff7095f4": Phase="Pending", Reason="", readiness=false. Elapsed: 4.08475967s
Dec 28 04:54:00.926: INFO: Pod "downwardapi-volume-9405a526-0a5c-11e9-8a07-628dff7095f4": Phase="Pending", Reason="", readiness=false. Elapsed: 6.09231484s
Dec 28 04:54:02.936: INFO: Pod "downwardapi-volume-9405a526-0a5c-11e9-8a07-628dff7095f4": Phase="Pending", Reason="", readiness=false. Elapsed: 8.1020805s
Dec 28 04:54:04.953: INFO: Pod "downwardapi-volume-9405a526-0a5c-11e9-8a07-628dff7095f4": Phase="Pending", Reason="", readiness=false. Elapsed: 10.119597367s
Dec 28 04:54:06.962: INFO: Pod "downwardapi-volume-9405a526-0a5c-11e9-8a07-628dff7095f4": Phase="Pending", Reason="", readiness=false. Elapsed: 12.128012314s
Dec 28 04:54:08.968: INFO: Pod "downwardapi-volume-9405a526-0a5c-11e9-8a07-628dff7095f4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 14.13468923s
STEP: Saw pod success
Dec 28 04:54:08.968: INFO: Pod "downwardapi-volume-9405a526-0a5c-11e9-8a07-628dff7095f4" satisfied condition "success or failure"
Dec 28 04:54:08.973: INFO: Trying to get logs from node 10.10.102.69-build pod downwardapi-volume-9405a526-0a5c-11e9-8a07-628dff7095f4 container client-container: <nil>
STEP: delete the pod
Dec 28 04:54:09.054: INFO: Waiting for pod downwardapi-volume-9405a526-0a5c-11e9-8a07-628dff7095f4 to disappear
Dec 28 04:54:09.125: INFO: Pod downwardapi-volume-9405a526-0a5c-11e9-8a07-628dff7095f4 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 28 04:54:09.125: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-tlj6l" for this suite.
Dec 28 04:54:15.217: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 04:54:15.336: INFO: namespace: e2e-tests-downward-api-tlj6l, resource: bindings, ignored listing per whitelist
Dec 28 04:54:15.446: INFO: namespace e2e-tests-downward-api-tlj6l deletion completed in 6.307990427s

• [SLOW TEST:20.952 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl version 
  should check is all data is printed  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 28 04:54:15.456: INFO: >>> kubeConfig: /tmp/kubeconfig-994138694
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should check is all data is printed  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Dec 28 04:54:15.791: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994138694 version'
Dec 28 04:54:16.219: INFO: stderr: ""
Dec 28 04:54:16.220: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"12\", GitVersion:\"v1.12.1\", GitCommit:\"4ed3216f3ec431b140b1d899130a69fc671678f4\", GitTreeState:\"clean\", BuildDate:\"2018-10-05T16:46:06Z\", GoVersion:\"go1.10.4\", Compiler:\"gc\", Platform:\"linux/amd64\"}\nServer Version: version.Info{Major:\"1\", Minor:\"12\", GitVersion:\"v1.12.3\", GitCommit:\"435f92c719f279a3a67808c80521ea17d5715c66\", GitTreeState:\"clean\", BuildDate:\"2018-11-26T12:46:57Z\", GoVersion:\"go1.10.4\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 28 04:54:16.220: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-bzm4k" for this suite.
Dec 28 04:54:22.285: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 04:54:22.308: INFO: namespace: e2e-tests-kubectl-bzm4k, resource: bindings, ignored listing per whitelist
Dec 28 04:54:22.554: INFO: namespace e2e-tests-kubectl-bzm4k deletion completed in 6.324244944s

• [SLOW TEST:7.098 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl version
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should check is all data is printed  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] Projected 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 28 04:54:22.555: INFO: >>> kubeConfig: /tmp/kubeconfig-994138694
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with configMap that has name projected-configmap-test-upd-a4b3b8f6-0a5c-11e9-8a07-628dff7095f4
STEP: Creating the pod
STEP: Updating configmap projected-configmap-test-upd-a4b3b8f6-0a5c-11e9-8a07-628dff7095f4
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 28 04:54:33.013: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-9lv6x" for this suite.
Dec 28 04:54:57.057: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 04:54:57.154: INFO: namespace: e2e-tests-projected-9lv6x, resource: bindings, ignored listing per whitelist
Dec 28 04:54:57.245: INFO: namespace e2e-tests-projected-9lv6x deletion completed in 24.221815577s

• [SLOW TEST:34.690 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl patch 
  should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 28 04:54:57.245: INFO: >>> kubeConfig: /tmp/kubeconfig-994138694
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating Redis RC
Dec 28 04:54:57.498: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994138694 create -f - --namespace=e2e-tests-kubectl-n49w2'
Dec 28 04:55:00.509: INFO: stderr: ""
Dec 28 04:55:00.510: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
Dec 28 04:55:01.516: INFO: Selector matched 1 pods for map[app:redis]
Dec 28 04:55:01.517: INFO: Found 0 / 1
Dec 28 04:55:02.516: INFO: Selector matched 1 pods for map[app:redis]
Dec 28 04:55:02.517: INFO: Found 0 / 1
Dec 28 04:55:03.576: INFO: Selector matched 1 pods for map[app:redis]
Dec 28 04:55:03.576: INFO: Found 0 / 1
Dec 28 04:55:04.518: INFO: Selector matched 1 pods for map[app:redis]
Dec 28 04:55:04.518: INFO: Found 0 / 1
Dec 28 04:55:05.518: INFO: Selector matched 1 pods for map[app:redis]
Dec 28 04:55:05.518: INFO: Found 0 / 1
Dec 28 04:55:06.518: INFO: Selector matched 1 pods for map[app:redis]
Dec 28 04:55:06.518: INFO: Found 0 / 1
Dec 28 04:55:07.518: INFO: Selector matched 1 pods for map[app:redis]
Dec 28 04:55:07.518: INFO: Found 0 / 1
Dec 28 04:55:08.518: INFO: Selector matched 1 pods for map[app:redis]
Dec 28 04:55:08.518: INFO: Found 1 / 1
Dec 28 04:55:08.518: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
STEP: patching all pods
Dec 28 04:55:08.524: INFO: Selector matched 1 pods for map[app:redis]
Dec 28 04:55:08.524: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Dec 28 04:55:08.524: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994138694 patch pod redis-master-wfqb7 --namespace=e2e-tests-kubectl-n49w2 -p {"metadata":{"annotations":{"x":"y"}}}'
Dec 28 04:55:08.854: INFO: stderr: ""
Dec 28 04:55:08.854: INFO: stdout: "pod/redis-master-wfqb7 patched\n"
STEP: checking annotations
Dec 28 04:55:08.902: INFO: Selector matched 1 pods for map[app:redis]
Dec 28 04:55:08.902: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 28 04:55:08.903: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-n49w2" for this suite.
Dec 28 04:55:32.993: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 04:55:33.179: INFO: namespace: e2e-tests-kubectl-n49w2, resource: bindings, ignored listing per whitelist
Dec 28 04:55:33.264: INFO: namespace e2e-tests-kubectl-n49w2 deletion completed in 24.348896896s

• [SLOW TEST:36.019 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl patch
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should add annotations for pods in rc  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl cluster-info 
  should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 28 04:55:33.264: INFO: >>> kubeConfig: /tmp/kubeconfig-994138694
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: validating cluster-info
Dec 28 04:55:33.508: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994138694 cluster-info'
Dec 28 04:55:33.805: INFO: stderr: ""
Dec 28 04:55:33.805: INFO: stdout: "\x1b[0;32mKubernetes master\x1b[0m is running at \x1b[0;33mhttps://10.96.0.1:443\x1b[0m\n\x1b[0;32mElasticsearch\x1b[0m is running at \x1b[0;33mhttps://10.96.0.1:443/api/v1/namespaces/kube-system/services/elasticsearch-logging:es/proxy\x1b[0m\n\x1b[0;32mHeapster\x1b[0m is running at \x1b[0;33mhttps://10.96.0.1:443/api/v1/namespaces/kube-system/services/heapster/proxy\x1b[0m\n\x1b[0;32mjenkins\x1b[0m is running at \x1b[0;33mhttps://10.96.0.1:443/api/v1/namespaces/kube-system/services/jenkins:jenkins/proxy\x1b[0m\n\x1b[0;32mKubeDNS\x1b[0m is running at \x1b[0;33mhttps://10.96.0.1:443/api/v1/namespaces/kube-system/services/kube-dns:dns/proxy\x1b[0m\n\x1b[0;32mmonitoring-influxdb\x1b[0m is running at \x1b[0;33mhttps://10.96.0.1:443/api/v1/namespaces/kube-system/services/monitoring-influxdb:http/proxy\x1b[0m\n\x1b[0;32mwebapi-service\x1b[0m is running at \x1b[0;33mhttps://10.96.0.1:443/api/v1/namespaces/kube-system/services/webapi-service/proxy\x1b[0m\n\x1b[0;32mwebpage-service\x1b[0m is running at \x1b[0;33mhttps://10.96.0.1:443/api/v1/namespaces/kube-system/services/webpage-service/proxy\x1b[0m\n\nTo further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 28 04:55:33.806: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-g9rm5" for this suite.
Dec 28 04:55:39.844: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 04:55:40.042: INFO: namespace: e2e-tests-kubectl-g9rm5, resource: bindings, ignored listing per whitelist
Dec 28 04:55:40.169: INFO: namespace e2e-tests-kubectl-g9rm5 deletion completed in 6.35192822s

• [SLOW TEST:6.905 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl cluster-info
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should check if Kubernetes master services is included in cluster-info  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl rolling-update 
  should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 28 04:55:40.170: INFO: >>> kubeConfig: /tmp/kubeconfig-994138694
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1306
[It] should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Dec 28 04:55:40.369: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994138694 run e2e-test-nginx-rc --image=docker.io/library/nginx:1.14-alpine --generator=run/v1 --namespace=e2e-tests-kubectl-5cwqq'
Dec 28 04:55:40.663: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl create instead.\n"
Dec 28 04:55:40.663: INFO: stdout: "replicationcontroller/e2e-test-nginx-rc created\n"
STEP: verifying the rc e2e-test-nginx-rc was created
Dec 28 04:55:40.687: INFO: Waiting for rc e2e-test-nginx-rc to stabilize, generation 1 observed generation 1 spec.replicas 1 status.replicas 0
STEP: rolling-update to same image controller
Dec 28 04:55:40.746: INFO: scanned /root for discovery docs: <nil>
Dec 28 04:55:40.746: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994138694 rolling-update e2e-test-nginx-rc --update-period=1s --image=docker.io/library/nginx:1.14-alpine --image-pull-policy=IfNotPresent --namespace=e2e-tests-kubectl-5cwqq'
Dec 28 04:56:01.221: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Dec 28 04:56:01.221: INFO: stdout: "Created e2e-test-nginx-rc-24f140d6b49c95cb77961c55d0a032e3\nScaling up e2e-test-nginx-rc-24f140d6b49c95cb77961c55d0a032e3 from 0 to 1, scaling down e2e-test-nginx-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-nginx-rc-24f140d6b49c95cb77961c55d0a032e3 up to 1\nScaling e2e-test-nginx-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-nginx-rc\nRenaming e2e-test-nginx-rc-24f140d6b49c95cb77961c55d0a032e3 to e2e-test-nginx-rc\nreplicationcontroller/e2e-test-nginx-rc rolling updated\n"
Dec 28 04:56:01.221: INFO: stdout: "Created e2e-test-nginx-rc-24f140d6b49c95cb77961c55d0a032e3\nScaling up e2e-test-nginx-rc-24f140d6b49c95cb77961c55d0a032e3 from 0 to 1, scaling down e2e-test-nginx-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-nginx-rc-24f140d6b49c95cb77961c55d0a032e3 up to 1\nScaling e2e-test-nginx-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-nginx-rc\nRenaming e2e-test-nginx-rc-24f140d6b49c95cb77961c55d0a032e3 to e2e-test-nginx-rc\nreplicationcontroller/e2e-test-nginx-rc rolling updated\n"
STEP: waiting for all containers in run=e2e-test-nginx-rc pods to come up.
Dec 28 04:56:01.221: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994138694 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l run=e2e-test-nginx-rc --namespace=e2e-tests-kubectl-5cwqq'
Dec 28 04:56:01.532: INFO: stderr: ""
Dec 28 04:56:01.532: INFO: stdout: "e2e-test-nginx-rc-24f140d6b49c95cb77961c55d0a032e3-xg5jk "
Dec 28 04:56:01.533: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994138694 get pods e2e-test-nginx-rc-24f140d6b49c95cb77961c55d0a032e3-xg5jk -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "e2e-test-nginx-rc") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-5cwqq'
Dec 28 04:56:01.811: INFO: stderr: ""
Dec 28 04:56:01.811: INFO: stdout: "true"
Dec 28 04:56:01.811: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994138694 get pods e2e-test-nginx-rc-24f140d6b49c95cb77961c55d0a032e3-xg5jk -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "e2e-test-nginx-rc"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-5cwqq'
Dec 28 04:56:02.138: INFO: stderr: ""
Dec 28 04:56:02.138: INFO: stdout: "nginx:1.14-alpine"
Dec 28 04:56:02.138: INFO: e2e-test-nginx-rc-24f140d6b49c95cb77961c55d0a032e3-xg5jk is verified up and running
[AfterEach] [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1312
Dec 28 04:56:02.138: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994138694 delete rc e2e-test-nginx-rc --namespace=e2e-tests-kubectl-5cwqq'
Dec 28 04:56:02.501: INFO: stderr: ""
Dec 28 04:56:02.501: INFO: stdout: "replicationcontroller \"e2e-test-nginx-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 28 04:56:02.501: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-5cwqq" for this suite.
Dec 28 04:56:26.552: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 04:56:26.977: INFO: namespace: e2e-tests-kubectl-5cwqq, resource: bindings, ignored listing per whitelist
Dec 28 04:56:27.639: INFO: namespace e2e-tests-kubectl-5cwqq deletion completed in 25.126251443s

• [SLOW TEST:47.469 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should support rolling-update to same image  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[k8s.io] [sig-node] Events 
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 28 04:56:27.639: INFO: >>> kubeConfig: /tmp/kubeconfig-994138694
STEP: Building a namespace api object, basename events
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: retrieving the pod
Dec 28 04:56:35.967: INFO: &Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:send-events-ef451b43-0a5c-11e9-8a07-628dff7095f4,GenerateName:,Namespace:e2e-tests-events-4zbth,SelfLink:/api/v1/namespaces/e2e-tests-events-4zbth/pods/send-events-ef451b43-0a5c-11e9-8a07-628dff7095f4,UID:ef5a50e2-0a5c-11e9-a0ee-005056bc4922,ResourceVersion:524365,Generation:0,CreationTimestamp:2018-12-28 04:56:28 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: foo,time: 906349984,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-ls54l {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-ls54l,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{p gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1 [] []  [{ 0 80 TCP }] [] [] {map[] map[]} [{default-token-ls54l true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*30,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.10.102.68-share,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc420e5f190} {node.kubernetes.io/unreachable Exists  NoExecute 0xc420e5f240}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-28 04:56:27 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-12-28 04:56:35 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2018-12-28 04:56:35 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-28 04:56:28 +0000 UTC  }],Message:,Reason:,HostIP:10.10.102.68,PodIP:10.168.194.188,StartTime:2018-12-28 04:56:27 +0000 UTC,ContainerStatuses:[{p {nil ContainerStateRunning{StartedAt:2018-12-28 04:56:34 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1 docker-pullable://gcr.io/kubernetes-e2e-test-images/serve-hostname@sha256:bab70473a6d8ef65a22625dc9a1b0f0452e811530fdbe77e4408523460177ff1 docker://423bade57501606ea4c04d7664bb4b23898d076d66d06f18922cba13bae00842}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}

STEP: checking for scheduler event about the pod
Dec 28 04:56:38.004: INFO: Saw scheduler event for our pod.
STEP: checking for kubelet event about the pod
Dec 28 04:56:40.012: INFO: Saw kubelet event for our pod.
STEP: deleting the pod
[AfterEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 28 04:56:40.022: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-events-4zbth" for this suite.
Dec 28 04:57:20.103: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 04:57:20.188: INFO: namespace: e2e-tests-events-4zbth, resource: bindings, ignored listing per whitelist
Dec 28 04:57:20.308: INFO: namespace e2e-tests-events-4zbth deletion completed in 40.269484267s

• [SLOW TEST:52.669 seconds]
[k8s.io] [sig-node] Events
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] version v1
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 28 04:57:20.308: INFO: >>> kubeConfig: /tmp/kubeconfig-994138694
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Dec 28 04:57:20.618: INFO: (0) /api/v1/nodes/10.10.102.66-slave:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 51.61536ms)
Dec 28 04:57:20.626: INFO: (1) /api/v1/nodes/10.10.102.66-slave:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 8.581723ms)
Dec 28 04:57:20.635: INFO: (2) /api/v1/nodes/10.10.102.66-slave:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 8.46461ms)
Dec 28 04:57:20.642: INFO: (3) /api/v1/nodes/10.10.102.66-slave:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 7.53319ms)
Dec 28 04:57:20.652: INFO: (4) /api/v1/nodes/10.10.102.66-slave:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 9.87764ms)
Dec 28 04:57:20.661: INFO: (5) /api/v1/nodes/10.10.102.66-slave:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 8.71399ms)
Dec 28 04:57:20.670: INFO: (6) /api/v1/nodes/10.10.102.66-slave:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 8.691183ms)
Dec 28 04:57:20.679: INFO: (7) /api/v1/nodes/10.10.102.66-slave:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 8.80731ms)
Dec 28 04:57:20.689: INFO: (8) /api/v1/nodes/10.10.102.66-slave:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 10.044676ms)
Dec 28 04:57:20.699: INFO: (9) /api/v1/nodes/10.10.102.66-slave:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 9.63886ms)
Dec 28 04:57:20.709: INFO: (10) /api/v1/nodes/10.10.102.66-slave:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 9.888944ms)
Dec 28 04:57:20.719: INFO: (11) /api/v1/nodes/10.10.102.66-slave:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 10.287046ms)
Dec 28 04:57:20.734: INFO: (12) /api/v1/nodes/10.10.102.66-slave:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 14.417524ms)
Dec 28 04:57:20.743: INFO: (13) /api/v1/nodes/10.10.102.66-slave:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 9.14562ms)
Dec 28 04:57:20.753: INFO: (14) /api/v1/nodes/10.10.102.66-slave:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 9.836566ms)
Dec 28 04:57:20.761: INFO: (15) /api/v1/nodes/10.10.102.66-slave:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 8.536826ms)
Dec 28 04:57:20.772: INFO: (16) /api/v1/nodes/10.10.102.66-slave:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 10.31964ms)
Dec 28 04:57:20.785: INFO: (17) /api/v1/nodes/10.10.102.66-slave:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 13.336274ms)
Dec 28 04:57:20.807: INFO: (18) /api/v1/nodes/10.10.102.66-slave:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 21.47475ms)
Dec 28 04:57:20.819: INFO: (19) /api/v1/nodes/10.10.102.66-slave:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 12.10546ms)
[AfterEach] version v1
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 28 04:57:20.819: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-proxy-lgd7m" for this suite.
Dec 28 04:57:26.877: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 04:57:26.964: INFO: namespace: e2e-tests-proxy-lgd7m, resource: bindings, ignored listing per whitelist
Dec 28 04:57:27.087: INFO: namespace e2e-tests-proxy-lgd7m deletion completed in 6.250045267s

• [SLOW TEST:6.780 seconds]
[sig-network] Proxy
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[k8s.io] Pods 
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 28 04:57:27.088: INFO: >>> kubeConfig: /tmp/kubeconfig-994138694
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating pod
Dec 28 04:57:35.496: INFO: Pod pod-hostip-12aa5b83-0a5d-11e9-8a07-628dff7095f4 has hostIP: 10.10.102.69
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 28 04:57:35.496: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-7krrm" for this suite.
Dec 28 04:57:59.664: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 04:57:59.723: INFO: namespace: e2e-tests-pods-7krrm, resource: bindings, ignored listing per whitelist
Dec 28 04:57:59.897: INFO: namespace e2e-tests-pods-7krrm deletion completed in 24.389164663s

• [SLOW TEST:32.809 seconds]
[k8s.io] Pods
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 28 04:57:59.897: INFO: >>> kubeConfig: /tmp/kubeconfig-994138694
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-2644e9ea-0a5d-11e9-8a07-628dff7095f4
STEP: Creating a pod to test consume secrets
Dec 28 04:58:00.249: INFO: Waiting up to 5m0s for pod "pod-secrets-264697ea-0a5d-11e9-8a07-628dff7095f4" in namespace "e2e-tests-secrets-6gcr7" to be "success or failure"
Dec 28 04:58:00.257: INFO: Pod "pod-secrets-264697ea-0a5d-11e9-8a07-628dff7095f4": Phase="Pending", Reason="", readiness=false. Elapsed: 7.855557ms
Dec 28 04:58:02.266: INFO: Pod "pod-secrets-264697ea-0a5d-11e9-8a07-628dff7095f4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01626044s
Dec 28 04:58:04.274: INFO: Pod "pod-secrets-264697ea-0a5d-11e9-8a07-628dff7095f4": Phase="Pending", Reason="", readiness=false. Elapsed: 4.02434388s
Dec 28 04:58:06.281: INFO: Pod "pod-secrets-264697ea-0a5d-11e9-8a07-628dff7095f4": Phase="Pending", Reason="", readiness=false. Elapsed: 6.03184991s
Dec 28 04:58:08.289: INFO: Pod "pod-secrets-264697ea-0a5d-11e9-8a07-628dff7095f4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.04010836s
STEP: Saw pod success
Dec 28 04:58:08.290: INFO: Pod "pod-secrets-264697ea-0a5d-11e9-8a07-628dff7095f4" satisfied condition "success or failure"
Dec 28 04:58:08.298: INFO: Trying to get logs from node 10.10.102.68-share pod pod-secrets-264697ea-0a5d-11e9-8a07-628dff7095f4 container secret-volume-test: <nil>
STEP: delete the pod
Dec 28 04:58:08.391: INFO: Waiting for pod pod-secrets-264697ea-0a5d-11e9-8a07-628dff7095f4 to disappear
Dec 28 04:58:08.400: INFO: Pod pod-secrets-264697ea-0a5d-11e9-8a07-628dff7095f4 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 28 04:58:08.400: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-6gcr7" for this suite.
Dec 28 04:58:14.563: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 04:58:14.770: INFO: namespace: e2e-tests-secrets-6gcr7, resource: bindings, ignored listing per whitelist
Dec 28 04:58:14.797: INFO: namespace e2e-tests-secrets-6gcr7 deletion completed in 6.33072764s

• [SLOW TEST:14.900 seconds]
[sig-storage] Secrets
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 28 04:58:14.798: INFO: >>> kubeConfig: /tmp/kubeconfig-994138694
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0777 on node default medium
Dec 28 04:58:15.068: INFO: Waiting up to 5m0s for pod "pod-2f225e17-0a5d-11e9-8a07-628dff7095f4" in namespace "e2e-tests-emptydir-b728c" to be "success or failure"
Dec 28 04:58:15.079: INFO: Pod "pod-2f225e17-0a5d-11e9-8a07-628dff7095f4": Phase="Pending", Reason="", readiness=false. Elapsed: 11.847206ms
Dec 28 04:58:17.087: INFO: Pod "pod-2f225e17-0a5d-11e9-8a07-628dff7095f4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01930406s
Dec 28 04:58:19.094: INFO: Pod "pod-2f225e17-0a5d-11e9-8a07-628dff7095f4": Phase="Pending", Reason="", readiness=false. Elapsed: 4.026881536s
Dec 28 04:58:21.103: INFO: Pod "pod-2f225e17-0a5d-11e9-8a07-628dff7095f4": Phase="Pending", Reason="", readiness=false. Elapsed: 6.03511818s
Dec 28 04:58:23.111: INFO: Pod "pod-2f225e17-0a5d-11e9-8a07-628dff7095f4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.04386587s
STEP: Saw pod success
Dec 28 04:58:23.112: INFO: Pod "pod-2f225e17-0a5d-11e9-8a07-628dff7095f4" satisfied condition "success or failure"
Dec 28 04:58:23.119: INFO: Trying to get logs from node 10.10.102.69-build pod pod-2f225e17-0a5d-11e9-8a07-628dff7095f4 container test-container: <nil>
STEP: delete the pod
Dec 28 04:58:23.200: INFO: Waiting for pod pod-2f225e17-0a5d-11e9-8a07-628dff7095f4 to disappear
Dec 28 04:58:23.214: INFO: Pod pod-2f225e17-0a5d-11e9-8a07-628dff7095f4 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 28 04:58:23.214: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-b728c" for this suite.
Dec 28 04:58:29.286: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 04:58:29.375: INFO: namespace: e2e-tests-emptydir-b728c, resource: bindings, ignored listing per whitelist
Dec 28 04:58:29.511: INFO: namespace e2e-tests-emptydir-b728c deletion completed in 6.282298817s

• [SLOW TEST:14.713 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Proxy server 
  should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 28 04:58:29.512: INFO: >>> kubeConfig: /tmp/kubeconfig-994138694
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: starting the proxy server
Dec 28 04:58:29.780: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-994138694 proxy -p 0 --disable-filter'
STEP: curling proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 28 04:58:30.056: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-v7bd4" for this suite.
Dec 28 04:58:36.092: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 04:58:36.167: INFO: namespace: e2e-tests-kubectl-v7bd4, resource: bindings, ignored listing per whitelist
Dec 28 04:58:36.317: INFO: namespace e2e-tests-kubectl-v7bd4 deletion completed in 6.251326777s

• [SLOW TEST:6.805 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Proxy server
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should support proxy with --port 0  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-storage] Secrets 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 28 04:58:36.317: INFO: >>> kubeConfig: /tmp/kubeconfig-994138694
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name s-test-opt-del-3bf8f4c6-0a5d-11e9-8a07-628dff7095f4
STEP: Creating secret with name s-test-opt-upd-3bf8f562-0a5d-11e9-8a07-628dff7095f4
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-3bf8f4c6-0a5d-11e9-8a07-628dff7095f4
STEP: Updating secret s-test-opt-upd-3bf8f562-0a5d-11e9-8a07-628dff7095f4
STEP: Creating secret with name s-test-opt-create-3bf8f596-0a5d-11e9-8a07-628dff7095f4
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 28 05:00:06.213: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-2qj8k" for this suite.
Dec 28 05:00:30.250: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 05:00:30.426: INFO: namespace: e2e-tests-secrets-2qj8k, resource: bindings, ignored listing per whitelist
Dec 28 05:00:30.476: INFO: namespace e2e-tests-secrets-2qj8k deletion completed in 24.25298459s

• [SLOW TEST:114.158 seconds]
[sig-storage] Secrets
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 28 05:00:30.476: INFO: >>> kubeConfig: /tmp/kubeconfig-994138694
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0666 on tmpfs
Dec 28 05:00:30.839: INFO: Waiting up to 5m0s for pod "pod-8006b0a5-0a5d-11e9-8a07-628dff7095f4" in namespace "e2e-tests-emptydir-pv9h7" to be "success or failure"
Dec 28 05:00:30.855: INFO: Pod "pod-8006b0a5-0a5d-11e9-8a07-628dff7095f4": Phase="Pending", Reason="", readiness=false. Elapsed: 15.659364ms
Dec 28 05:00:32.862: INFO: Pod "pod-8006b0a5-0a5d-11e9-8a07-628dff7095f4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.02318555s
Dec 28 05:00:34.883: INFO: Pod "pod-8006b0a5-0a5d-11e9-8a07-628dff7095f4": Phase="Pending", Reason="", readiness=false. Elapsed: 4.04413449s
Dec 28 05:00:36.921: INFO: Pod "pod-8006b0a5-0a5d-11e9-8a07-628dff7095f4": Phase="Pending", Reason="", readiness=false. Elapsed: 6.082149247s
Dec 28 05:00:38.928: INFO: Pod "pod-8006b0a5-0a5d-11e9-8a07-628dff7095f4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.088841257s
STEP: Saw pod success
Dec 28 05:00:38.928: INFO: Pod "pod-8006b0a5-0a5d-11e9-8a07-628dff7095f4" satisfied condition "success or failure"
Dec 28 05:00:38.952: INFO: Trying to get logs from node 10.10.102.69-build pod pod-8006b0a5-0a5d-11e9-8a07-628dff7095f4 container test-container: <nil>
STEP: delete the pod
Dec 28 05:00:39.064: INFO: Waiting for pod pod-8006b0a5-0a5d-11e9-8a07-628dff7095f4 to disappear
Dec 28 05:00:39.077: INFO: Pod pod-8006b0a5-0a5d-11e9-8a07-628dff7095f4 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 28 05:00:39.078: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-pv9h7" for this suite.
Dec 28 05:00:45.184: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 05:00:45.400: INFO: namespace: e2e-tests-emptydir-pv9h7, resource: bindings, ignored listing per whitelist
Dec 28 05:00:45.501: INFO: namespace e2e-tests-emptydir-pv9h7 deletion completed in 6.398608813s

• [SLOW TEST:15.025 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 28 05:00:45.502: INFO: >>> kubeConfig: /tmp/kubeconfig-994138694
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-f9fr8
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Dec 28 05:00:45.705: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Dec 28 05:01:24.103: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.168.194.186:8080/dial?request=hostName&protocol=http&host=10.168.66.252&port=8080&tries=1'] Namespace:e2e-tests-pod-network-test-f9fr8 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 28 05:01:24.103: INFO: >>> kubeConfig: /tmp/kubeconfig-994138694
Dec 28 05:01:24.450: INFO: Waiting for endpoints: map[]
Dec 28 05:01:24.457: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.168.194.186:8080/dial?request=hostName&protocol=http&host=10.168.192.61&port=8080&tries=1'] Namespace:e2e-tests-pod-network-test-f9fr8 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 28 05:01:24.457: INFO: >>> kubeConfig: /tmp/kubeconfig-994138694
Dec 28 05:01:24.623: INFO: Waiting for endpoints: map[]
Dec 28 05:01:24.630: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.168.194.186:8080/dial?request=hostName&protocol=http&host=10.168.176.61&port=8080&tries=1'] Namespace:e2e-tests-pod-network-test-f9fr8 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 28 05:01:24.630: INFO: >>> kubeConfig: /tmp/kubeconfig-994138694
Dec 28 05:01:24.810: INFO: Waiting for endpoints: map[]
Dec 28 05:01:24.817: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.168.194.186:8080/dial?request=hostName&protocol=http&host=10.168.194.183&port=8080&tries=1'] Namespace:e2e-tests-pod-network-test-f9fr8 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 28 05:01:24.817: INFO: >>> kubeConfig: /tmp/kubeconfig-994138694
Dec 28 05:01:24.990: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 28 05:01:24.991: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-f9fr8" for this suite.
Dec 28 05:01:51.046: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 05:01:51.193: INFO: namespace: e2e-tests-pod-network-test-f9fr8, resource: bindings, ignored listing per whitelist
Dec 28 05:01:51.299: INFO: namespace e2e-tests-pod-network-test-f9fr8 deletion completed in 26.298308137s

• [SLOW TEST:65.798 seconds]
[sig-network] Networking
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: http [NodeConformance] [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 28 05:01:51.300: INFO: >>> kubeConfig: /tmp/kubeconfig-994138694
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test override arguments
Dec 28 05:01:51.581: INFO: Waiting up to 5m0s for pod "client-containers-b030709d-0a5d-11e9-8a07-628dff7095f4" in namespace "e2e-tests-containers-hsj6t" to be "success or failure"
Dec 28 05:01:51.620: INFO: Pod "client-containers-b030709d-0a5d-11e9-8a07-628dff7095f4": Phase="Pending", Reason="", readiness=false. Elapsed: 38.90367ms
Dec 28 05:01:53.627: INFO: Pod "client-containers-b030709d-0a5d-11e9-8a07-628dff7095f4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.04552754s
Dec 28 05:01:55.635: INFO: Pod "client-containers-b030709d-0a5d-11e9-8a07-628dff7095f4": Phase="Pending", Reason="", readiness=false. Elapsed: 4.05333378s
Dec 28 05:01:57.644: INFO: Pod "client-containers-b030709d-0a5d-11e9-8a07-628dff7095f4": Phase="Pending", Reason="", readiness=false. Elapsed: 6.062322284s
Dec 28 05:01:59.651: INFO: Pod "client-containers-b030709d-0a5d-11e9-8a07-628dff7095f4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.069495587s
STEP: Saw pod success
Dec 28 05:01:59.651: INFO: Pod "client-containers-b030709d-0a5d-11e9-8a07-628dff7095f4" satisfied condition "success or failure"
Dec 28 05:01:59.666: INFO: Trying to get logs from node 10.10.102.68-share pod client-containers-b030709d-0a5d-11e9-8a07-628dff7095f4 container test-container: <nil>
STEP: delete the pod
Dec 28 05:02:00.249: INFO: Waiting for pod client-containers-b030709d-0a5d-11e9-8a07-628dff7095f4 to disappear
Dec 28 05:02:00.266: INFO: Pod client-containers-b030709d-0a5d-11e9-8a07-628dff7095f4 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 28 05:02:00.266: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-hsj6t" for this suite.
Dec 28 05:02:08.307: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 05:02:08.444: INFO: namespace: e2e-tests-containers-hsj6t, resource: bindings, ignored listing per whitelist
Dec 28 05:02:08.509: INFO: namespace e2e-tests-containers-hsj6t deletion completed in 8.231016927s

• [SLOW TEST:17.209 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on tmpfs should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 28 05:02:08.510: INFO: >>> kubeConfig: /tmp/kubeconfig-994138694
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on tmpfs should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir volume type on tmpfs
Dec 28 05:02:08.849: INFO: Waiting up to 5m0s for pod "pod-ba77e8e4-0a5d-11e9-8a07-628dff7095f4" in namespace "e2e-tests-emptydir-z4w84" to be "success or failure"
Dec 28 05:02:08.887: INFO: Pod "pod-ba77e8e4-0a5d-11e9-8a07-628dff7095f4": Phase="Pending", Reason="", readiness=false. Elapsed: 38.188087ms
Dec 28 05:02:10.895: INFO: Pod "pod-ba77e8e4-0a5d-11e9-8a07-628dff7095f4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.045854023s
Dec 28 05:02:12.902: INFO: Pod "pod-ba77e8e4-0a5d-11e9-8a07-628dff7095f4": Phase="Pending", Reason="", readiness=false. Elapsed: 4.053310637s
Dec 28 05:02:14.909: INFO: Pod "pod-ba77e8e4-0a5d-11e9-8a07-628dff7095f4": Phase="Pending", Reason="", readiness=false. Elapsed: 6.060048053s
Dec 28 05:02:16.917: INFO: Pod "pod-ba77e8e4-0a5d-11e9-8a07-628dff7095f4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.067574477s
STEP: Saw pod success
Dec 28 05:02:16.917: INFO: Pod "pod-ba77e8e4-0a5d-11e9-8a07-628dff7095f4" satisfied condition "success or failure"
Dec 28 05:02:16.922: INFO: Trying to get logs from node 10.10.102.69-build pod pod-ba77e8e4-0a5d-11e9-8a07-628dff7095f4 container test-container: <nil>
STEP: delete the pod
Dec 28 05:02:17.083: INFO: Waiting for pod pod-ba77e8e4-0a5d-11e9-8a07-628dff7095f4 to disappear
Dec 28 05:02:17.094: INFO: Pod pod-ba77e8e4-0a5d-11e9-8a07-628dff7095f4 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 28 05:02:17.094: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-z4w84" for this suite.
Dec 28 05:02:23.220: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 05:02:23.420: INFO: namespace: e2e-tests-emptydir-z4w84, resource: bindings, ignored listing per whitelist
Dec 28 05:02:23.473: INFO: namespace e2e-tests-emptydir-z4w84 deletion completed in 6.334380994s

• [SLOW TEST:14.963 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  volume on tmpfs should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 28 05:02:23.474: INFO: >>> kubeConfig: /tmp/kubeconfig-994138694
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-c3669f02-0a5d-11e9-8a07-628dff7095f4
STEP: Creating a pod to test consume secrets
Dec 28 05:02:23.962: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-c3680c2b-0a5d-11e9-8a07-628dff7095f4" in namespace "e2e-tests-projected-76nv5" to be "success or failure"
Dec 28 05:02:24.114: INFO: Pod "pod-projected-secrets-c3680c2b-0a5d-11e9-8a07-628dff7095f4": Phase="Pending", Reason="", readiness=false. Elapsed: 151.31935ms
Dec 28 05:02:26.121: INFO: Pod "pod-projected-secrets-c3680c2b-0a5d-11e9-8a07-628dff7095f4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.158592397s
Dec 28 05:02:28.150: INFO: Pod "pod-projected-secrets-c3680c2b-0a5d-11e9-8a07-628dff7095f4": Phase="Pending", Reason="", readiness=false. Elapsed: 4.187058723s
Dec 28 05:02:30.156: INFO: Pod "pod-projected-secrets-c3680c2b-0a5d-11e9-8a07-628dff7095f4": Phase="Pending", Reason="", readiness=false. Elapsed: 6.193890333s
Dec 28 05:02:32.175: INFO: Pod "pod-projected-secrets-c3680c2b-0a5d-11e9-8a07-628dff7095f4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.212115863s
STEP: Saw pod success
Dec 28 05:02:32.175: INFO: Pod "pod-projected-secrets-c3680c2b-0a5d-11e9-8a07-628dff7095f4" satisfied condition "success or failure"
Dec 28 05:02:32.183: INFO: Trying to get logs from node 10.10.102.68-share pod pod-projected-secrets-c3680c2b-0a5d-11e9-8a07-628dff7095f4 container projected-secret-volume-test: <nil>
STEP: delete the pod
Dec 28 05:02:32.263: INFO: Waiting for pod pod-projected-secrets-c3680c2b-0a5d-11e9-8a07-628dff7095f4 to disappear
Dec 28 05:02:32.281: INFO: Pod pod-projected-secrets-c3680c2b-0a5d-11e9-8a07-628dff7095f4 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 28 05:02:32.281: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-76nv5" for this suite.
Dec 28 05:02:38.353: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 05:02:38.589: INFO: namespace: e2e-tests-projected-76nv5, resource: bindings, ignored listing per whitelist
Dec 28 05:02:38.625: INFO: namespace e2e-tests-projected-76nv5 deletion completed in 6.331156887s

• [SLOW TEST:15.152 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run pod 
  should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 28 05:02:38.626: INFO: >>> kubeConfig: /tmp/kubeconfig-994138694
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Kubectl run pod
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1475
[It] should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Dec 28 05:02:38.861: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994138694 run e2e-test-nginx-pod --restart=Never --generator=run-pod/v1 --image=docker.io/library/nginx:1.14-alpine --namespace=e2e-tests-kubectl-7lshz'
Dec 28 05:02:39.192: INFO: stderr: ""
Dec 28 05:02:39.192: INFO: stdout: "pod/e2e-test-nginx-pod created\n"
STEP: verifying the pod e2e-test-nginx-pod was created
[AfterEach] [k8s.io] Kubectl run pod
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1480
Dec 28 05:02:39.200: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994138694 delete pods e2e-test-nginx-pod --namespace=e2e-tests-kubectl-7lshz'
Dec 28 05:02:45.478: INFO: stderr: ""
Dec 28 05:02:45.478: INFO: stdout: "pod \"e2e-test-nginx-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 28 05:02:45.478: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-7lshz" for this suite.
Dec 28 05:02:51.542: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 05:02:51.735: INFO: namespace: e2e-tests-kubectl-7lshz, resource: bindings, ignored listing per whitelist
Dec 28 05:02:51.785: INFO: namespace e2e-tests-kubectl-7lshz deletion completed in 6.276795657s

• [SLOW TEST:13.159 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run pod
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create a pod from an image when restart is Never  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl replace 
  should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 28 05:02:51.786: INFO: >>> kubeConfig: /tmp/kubeconfig-994138694
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Kubectl replace
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1511
[It] should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Dec 28 05:02:52.122: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994138694 run e2e-test-nginx-pod --generator=run-pod/v1 --image=docker.io/library/nginx:1.14-alpine --labels=run=e2e-test-nginx-pod --namespace=e2e-tests-kubectl-87v6g'
Dec 28 05:02:52.462: INFO: stderr: ""
Dec 28 05:02:52.462: INFO: stdout: "pod/e2e-test-nginx-pod created\n"
STEP: verifying the pod e2e-test-nginx-pod is running
STEP: verifying the pod e2e-test-nginx-pod was created
Dec 28 05:03:02.513: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994138694 get pod e2e-test-nginx-pod --namespace=e2e-tests-kubectl-87v6g -o json'
Dec 28 05:03:02.821: INFO: stderr: ""
Dec 28 05:03:02.821: INFO: stdout: "{\n    \"apiVersion\": \"v1\",\n    \"kind\": \"Pod\",\n    \"metadata\": {\n        \"creationTimestamp\": \"2018-12-28T05:02:52Z\",\n        \"labels\": {\n            \"run\": \"e2e-test-nginx-pod\"\n        },\n        \"name\": \"e2e-test-nginx-pod\",\n        \"namespace\": \"e2e-tests-kubectl-87v6g\",\n        \"resourceVersion\": \"525593\",\n        \"selfLink\": \"/api/v1/namespaces/e2e-tests-kubectl-87v6g/pods/e2e-test-nginx-pod\",\n        \"uid\": \"d489a57a-0a5d-11e9-a0ee-005056bc4922\"\n    },\n    \"spec\": {\n        \"containers\": [\n            {\n                \"image\": \"docker.io/library/nginx:1.14-alpine\",\n                \"imagePullPolicy\": \"IfNotPresent\",\n                \"name\": \"e2e-test-nginx-pod\",\n                \"resources\": {},\n                \"terminationMessagePath\": \"/dev/termination-log\",\n                \"terminationMessagePolicy\": \"File\",\n                \"volumeMounts\": [\n                    {\n                        \"mountPath\": \"/var/run/secrets/kubernetes.io/serviceaccount\",\n                        \"name\": \"default-token-btjwm\",\n                        \"readOnly\": true\n                    }\n                ]\n            }\n        ],\n        \"dnsPolicy\": \"ClusterFirst\",\n        \"nodeName\": \"10.10.102.68-share\",\n        \"priority\": 0,\n        \"restartPolicy\": \"Always\",\n        \"schedulerName\": \"default-scheduler\",\n        \"securityContext\": {},\n        \"serviceAccount\": \"default\",\n        \"serviceAccountName\": \"default\",\n        \"terminationGracePeriodSeconds\": 30,\n        \"tolerations\": [\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/not-ready\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            },\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/unreachable\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            }\n        ],\n        \"volumes\": [\n            {\n                \"name\": \"default-token-btjwm\",\n                \"secret\": {\n                    \"defaultMode\": 420,\n                    \"secretName\": \"default-token-btjwm\"\n                }\n            }\n        ]\n    },\n    \"status\": {\n        \"conditions\": [\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2018-12-28T05:02:52Z\",\n                \"status\": \"True\",\n                \"type\": \"Initialized\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2018-12-28T05:02:59Z\",\n                \"status\": \"True\",\n                \"type\": \"Ready\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2018-12-28T05:02:59Z\",\n                \"status\": \"True\",\n                \"type\": \"ContainersReady\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2018-12-28T05:02:52Z\",\n                \"status\": \"True\",\n                \"type\": \"PodScheduled\"\n            }\n        ],\n        \"containerStatuses\": [\n            {\n                \"containerID\": \"docker://08ea7bf03aca254cc444fdb64ee933213d526f668fa69d08a5acde16fcfa3c54\",\n                \"image\": \"nginx:1.14-alpine\",\n                \"imageID\": \"docker-pullable://nginx@sha256:e3f77f7f4a6bb5e7820e013fa60b96602b34f5704e796cfd94b561ae73adcf96\",\n                \"lastState\": {},\n                \"name\": \"e2e-test-nginx-pod\",\n                \"ready\": true,\n                \"restartCount\": 0,\n                \"state\": {\n                    \"running\": {\n                        \"startedAt\": \"2018-12-28T05:02:59Z\"\n                    }\n                }\n            }\n        ],\n        \"hostIP\": \"10.10.102.68\",\n        \"phase\": \"Running\",\n        \"podIP\": \"10.168.194.137\",\n        \"qosClass\": \"BestEffort\",\n        \"startTime\": \"2018-12-28T05:02:52Z\"\n    }\n}\n"
STEP: replace the image in the pod
Dec 28 05:03:02.822: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994138694 replace -f - --namespace=e2e-tests-kubectl-87v6g'
Dec 28 05:03:03.765: INFO: stderr: ""
Dec 28 05:03:03.765: INFO: stdout: "pod/e2e-test-nginx-pod replaced\n"
STEP: verifying the pod e2e-test-nginx-pod has the right image docker.io/library/busybox:1.29
[AfterEach] [k8s.io] Kubectl replace
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1516
Dec 28 05:03:03.771: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994138694 delete pods e2e-test-nginx-pod --namespace=e2e-tests-kubectl-87v6g'
Dec 28 05:03:09.798: INFO: stderr: ""
Dec 28 05:03:09.798: INFO: stdout: "pod \"e2e-test-nginx-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 28 05:03:09.799: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-87v6g" for this suite.
Dec 28 05:03:15.874: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 05:03:16.012: INFO: namespace: e2e-tests-kubectl-87v6g, resource: bindings, ignored listing per whitelist
Dec 28 05:03:16.064: INFO: namespace e2e-tests-kubectl-87v6g deletion completed in 6.253639663s

• [SLOW TEST:24.279 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl replace
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should update a single-container pod's image  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] Downward API volume 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 28 05:03:16.064: INFO: >>> kubeConfig: /tmp/kubeconfig-994138694
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating the pod
Dec 28 05:03:24.897: INFO: Successfully updated pod "annotationupdatee2b01806-0a5d-11e9-8a07-628dff7095f4"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 28 05:03:27.108: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-qpmhz" for this suite.
Dec 28 05:03:51.146: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 05:03:51.210: INFO: namespace: e2e-tests-downward-api-qpmhz, resource: bindings, ignored listing per whitelist
Dec 28 05:03:51.355: INFO: namespace e2e-tests-downward-api-qpmhz deletion completed in 24.237178037s

• [SLOW TEST:35.291 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should scale a replication controller  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 28 05:03:51.356: INFO: >>> kubeConfig: /tmp/kubeconfig-994138694
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:293
[It] should scale a replication controller  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a replication controller
Dec 28 05:03:51.606: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994138694 create -f - --namespace=e2e-tests-kubectl-br659'
Dec 28 05:03:52.620: INFO: stderr: ""
Dec 28 05:03:52.621: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Dec 28 05:03:52.621: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994138694 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-br659'
Dec 28 05:03:52.971: INFO: stderr: ""
Dec 28 05:03:52.971: INFO: stdout: "update-demo-nautilus-2wxkv update-demo-nautilus-lw5p2 "
Dec 28 05:03:52.971: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994138694 get pods update-demo-nautilus-2wxkv -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-br659'
Dec 28 05:03:53.302: INFO: stderr: ""
Dec 28 05:03:53.302: INFO: stdout: ""
Dec 28 05:03:53.302: INFO: update-demo-nautilus-2wxkv is created but not running
Dec 28 05:03:58.303: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994138694 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-br659'
Dec 28 05:03:58.589: INFO: stderr: ""
Dec 28 05:03:58.589: INFO: stdout: "update-demo-nautilus-2wxkv update-demo-nautilus-lw5p2 "
Dec 28 05:03:58.590: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994138694 get pods update-demo-nautilus-2wxkv -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-br659'
Dec 28 05:03:58.963: INFO: stderr: ""
Dec 28 05:03:58.963: INFO: stdout: ""
Dec 28 05:03:58.963: INFO: update-demo-nautilus-2wxkv is created but not running
Dec 28 05:04:03.963: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994138694 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-br659'
Dec 28 05:04:04.252: INFO: stderr: ""
Dec 28 05:04:04.253: INFO: stdout: "update-demo-nautilus-2wxkv update-demo-nautilus-lw5p2 "
Dec 28 05:04:04.253: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994138694 get pods update-demo-nautilus-2wxkv -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-br659'
Dec 28 05:04:04.595: INFO: stderr: ""
Dec 28 05:04:04.595: INFO: stdout: "true"
Dec 28 05:04:04.595: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994138694 get pods update-demo-nautilus-2wxkv -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-br659'
Dec 28 05:04:04.889: INFO: stderr: ""
Dec 28 05:04:04.889: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Dec 28 05:04:04.889: INFO: validating pod update-demo-nautilus-2wxkv
Dec 28 05:04:04.907: INFO: got data: {
  "image": "nautilus.jpg"
}

Dec 28 05:04:04.907: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Dec 28 05:04:04.907: INFO: update-demo-nautilus-2wxkv is verified up and running
Dec 28 05:04:04.907: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994138694 get pods update-demo-nautilus-lw5p2 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-br659'
Dec 28 05:04:05.202: INFO: stderr: ""
Dec 28 05:04:05.202: INFO: stdout: "true"
Dec 28 05:04:05.202: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994138694 get pods update-demo-nautilus-lw5p2 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-br659'
Dec 28 05:04:05.548: INFO: stderr: ""
Dec 28 05:04:05.548: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Dec 28 05:04:05.548: INFO: validating pod update-demo-nautilus-lw5p2
Dec 28 05:04:05.652: INFO: got data: {
  "image": "nautilus.jpg"
}

Dec 28 05:04:05.652: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Dec 28 05:04:05.652: INFO: update-demo-nautilus-lw5p2 is verified up and running
STEP: scaling down the replication controller
Dec 28 05:04:05.655: INFO: scanned /root for discovery docs: <nil>
Dec 28 05:04:05.655: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994138694 scale rc update-demo-nautilus --replicas=1 --timeout=5m --namespace=e2e-tests-kubectl-br659'
Dec 28 05:04:07.050: INFO: stderr: ""
Dec 28 05:04:07.050: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Dec 28 05:04:07.050: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994138694 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-br659'
Dec 28 05:04:07.354: INFO: stderr: ""
Dec 28 05:04:07.354: INFO: stdout: "update-demo-nautilus-2wxkv update-demo-nautilus-lw5p2 "
STEP: Replicas for name=update-demo: expected=1 actual=2
Dec 28 05:04:12.355: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994138694 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-br659'
Dec 28 05:04:12.666: INFO: stderr: ""
Dec 28 05:04:12.666: INFO: stdout: "update-demo-nautilus-lw5p2 "
Dec 28 05:04:12.666: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994138694 get pods update-demo-nautilus-lw5p2 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-br659'
Dec 28 05:04:12.992: INFO: stderr: ""
Dec 28 05:04:12.992: INFO: stdout: "true"
Dec 28 05:04:12.992: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994138694 get pods update-demo-nautilus-lw5p2 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-br659'
Dec 28 05:04:13.315: INFO: stderr: ""
Dec 28 05:04:13.315: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Dec 28 05:04:13.315: INFO: validating pod update-demo-nautilus-lw5p2
Dec 28 05:04:13.323: INFO: got data: {
  "image": "nautilus.jpg"
}

Dec 28 05:04:13.323: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Dec 28 05:04:13.323: INFO: update-demo-nautilus-lw5p2 is verified up and running
STEP: scaling up the replication controller
Dec 28 05:04:13.326: INFO: scanned /root for discovery docs: <nil>
Dec 28 05:04:13.326: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994138694 scale rc update-demo-nautilus --replicas=2 --timeout=5m --namespace=e2e-tests-kubectl-br659'
Dec 28 05:04:14.871: INFO: stderr: ""
Dec 28 05:04:14.871: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Dec 28 05:04:14.871: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994138694 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-br659'
Dec 28 05:04:15.188: INFO: stderr: ""
Dec 28 05:04:15.189: INFO: stdout: "update-demo-nautilus-2r9hz update-demo-nautilus-lw5p2 "
Dec 28 05:04:15.189: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994138694 get pods update-demo-nautilus-2r9hz -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-br659'
Dec 28 05:04:15.496: INFO: stderr: ""
Dec 28 05:04:15.496: INFO: stdout: ""
Dec 28 05:04:15.496: INFO: update-demo-nautilus-2r9hz is created but not running
Dec 28 05:04:20.496: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994138694 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-br659'
Dec 28 05:04:20.808: INFO: stderr: ""
Dec 28 05:04:20.808: INFO: stdout: "update-demo-nautilus-2r9hz update-demo-nautilus-lw5p2 "
Dec 28 05:04:20.808: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994138694 get pods update-demo-nautilus-2r9hz -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-br659'
Dec 28 05:04:21.096: INFO: stderr: ""
Dec 28 05:04:21.096: INFO: stdout: "true"
Dec 28 05:04:21.096: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994138694 get pods update-demo-nautilus-2r9hz -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-br659'
Dec 28 05:04:21.373: INFO: stderr: ""
Dec 28 05:04:21.373: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Dec 28 05:04:21.373: INFO: validating pod update-demo-nautilus-2r9hz
Dec 28 05:04:21.497: INFO: got data: {
  "image": "nautilus.jpg"
}

Dec 28 05:04:21.497: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Dec 28 05:04:21.497: INFO: update-demo-nautilus-2r9hz is verified up and running
Dec 28 05:04:21.497: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994138694 get pods update-demo-nautilus-lw5p2 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-br659'
Dec 28 05:04:21.809: INFO: stderr: ""
Dec 28 05:04:21.809: INFO: stdout: "true"
Dec 28 05:04:21.809: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994138694 get pods update-demo-nautilus-lw5p2 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-br659'
Dec 28 05:04:22.149: INFO: stderr: ""
Dec 28 05:04:22.149: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Dec 28 05:04:22.149: INFO: validating pod update-demo-nautilus-lw5p2
Dec 28 05:04:22.163: INFO: got data: {
  "image": "nautilus.jpg"
}

Dec 28 05:04:22.163: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Dec 28 05:04:22.163: INFO: update-demo-nautilus-lw5p2 is verified up and running
STEP: using delete to clean up resources
Dec 28 05:04:22.163: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994138694 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-br659'
Dec 28 05:04:22.548: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Dec 28 05:04:22.548: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Dec 28 05:04:22.548: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994138694 get rc,svc -l name=update-demo --no-headers --namespace=e2e-tests-kubectl-br659'
Dec 28 05:04:23.100: INFO: stderr: "No resources found.\n"
Dec 28 05:04:23.101: INFO: stdout: ""
Dec 28 05:04:23.101: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994138694 get pods -l name=update-demo --namespace=e2e-tests-kubectl-br659 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Dec 28 05:04:23.486: INFO: stderr: ""
Dec 28 05:04:23.487: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 28 05:04:23.487: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-br659" for this suite.
Dec 28 05:04:29.560: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 05:04:29.658: INFO: namespace: e2e-tests-kubectl-br659, resource: bindings, ignored listing per whitelist
Dec 28 05:04:29.872: INFO: namespace e2e-tests-kubectl-br659 deletion completed in 6.35486352s

• [SLOW TEST:38.516 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Update Demo
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should scale a replication controller  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 28 05:04:29.872: INFO: >>> kubeConfig: /tmp/kubeconfig-994138694
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
Dec 28 05:04:30.107: INFO: PodSpec: initContainers in spec.initContainers
Dec 28 05:05:26.080: INFO: init container has failed twice: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-init-0eaf1a46-0a5e-11e9-8a07-628dff7095f4", GenerateName:"", Namespace:"e2e-tests-init-container-lhclr", SelfLink:"/api/v1/namespaces/e2e-tests-init-container-lhclr/pods/pod-init-0eaf1a46-0a5e-11e9-8a07-628dff7095f4", UID:"0ed772f1-0a5e-11e9-a0ee-005056bc4922", ResourceVersion:"526050", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63681570270, loc:(*time.Location)(0x6c43b60)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"time":"107108654", "name":"foo"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Initializers:(*v1.Initializers)(nil), Finalizers:[]string(nil), ClusterName:""}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"default-token-gstdp", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(0xc421d3b680), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil)}}}, InitContainers:[]v1.Container{v1.Container{Name:"init1", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/false"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-gstdp", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}, v1.Container{Name:"init2", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/true"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-gstdp", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, Containers:[]v1.Container{v1.Container{Name:"run1", Image:"k8s.gcr.io/pause:3.1", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}, Requests:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-gstdp", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc4220b0158), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"10.10.102.69-build", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc4215919e0), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc4220b01d0)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc4220b01f0)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc4220b01f8), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil)}, Status:v1.PodStatus{Phase:"Pending", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63681570270, loc:(*time.Location)(0x6c43b60)}}, Reason:"ContainersNotInitialized", Message:"containers with incomplete status: [init1 init2]"}, v1.PodCondition{Type:"Ready", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63681570270, loc:(*time.Location)(0x6c43b60)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"ContainersReady", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63681570270, loc:(*time.Location)(0x6c43b60)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63681570270, loc:(*time.Location)(0x6c43b60)}}, Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"10.10.102.69", PodIP:"10.168.192.4", StartTime:(*v1.Time)(0xc42049ed20), InitContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"init1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc420967c00)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc420967c70)}, Ready:false, RestartCount:3, Image:"busybox:1.29", ImageID:"docker-pullable://busybox@sha256:8ccbac733d19c0dd4d70b4f0c1e12245b5fa3ad24758a11035ee505c629c0796", ContainerID:"docker://f8826a4b32a50858aaf89fde480a695425c71fc529f05e2a6c06ea734cdf2347"}, v1.ContainerStatus{Name:"init2", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc42049ed60), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"docker.io/library/busybox:1.29", ImageID:"", ContainerID:""}}, ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"run1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc42049ed40), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"k8s.gcr.io/pause:3.1", ImageID:"", ContainerID:""}}, QOSClass:"Guaranteed"}}
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 28 05:05:26.081: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-init-container-lhclr" for this suite.
Dec 28 05:05:50.298: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 05:05:50.444: INFO: namespace: e2e-tests-init-container-lhclr, resource: bindings, ignored listing per whitelist
Dec 28 05:05:50.509: INFO: namespace e2e-tests-init-container-lhclr deletion completed in 24.28865391s

• [SLOW TEST:80.637 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with downward pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 28 05:05:50.509: INFO: >>> kubeConfig: /tmp/kubeconfig-994138694
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with downward pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-downwardapi-hrgj
STEP: Creating a pod to test atomic-volume-subpath
Dec 28 05:05:50.825: INFO: Waiting up to 5m0s for pod "pod-subpath-test-downwardapi-hrgj" in namespace "e2e-tests-subpath-9ndht" to be "success or failure"
Dec 28 05:05:50.841: INFO: Pod "pod-subpath-test-downwardapi-hrgj": Phase="Pending", Reason="", readiness=false. Elapsed: 15.360886ms
Dec 28 05:05:52.849: INFO: Pod "pod-subpath-test-downwardapi-hrgj": Phase="Pending", Reason="", readiness=false. Elapsed: 2.02362535s
Dec 28 05:05:54.856: INFO: Pod "pod-subpath-test-downwardapi-hrgj": Phase="Pending", Reason="", readiness=false. Elapsed: 4.030133063s
Dec 28 05:05:56.864: INFO: Pod "pod-subpath-test-downwardapi-hrgj": Phase="Pending", Reason="", readiness=false. Elapsed: 6.03887545s
Dec 28 05:05:58.873: INFO: Pod "pod-subpath-test-downwardapi-hrgj": Phase="Pending", Reason="", readiness=false. Elapsed: 8.047446576s
Dec 28 05:06:00.883: INFO: Pod "pod-subpath-test-downwardapi-hrgj": Phase="Pending", Reason="", readiness=false. Elapsed: 10.057814956s
Dec 28 05:06:02.892: INFO: Pod "pod-subpath-test-downwardapi-hrgj": Phase="Pending", Reason="", readiness=false. Elapsed: 12.066379533s
Dec 28 05:06:04.900: INFO: Pod "pod-subpath-test-downwardapi-hrgj": Phase="Pending", Reason="", readiness=false. Elapsed: 14.074699826s
Dec 28 05:06:06.909: INFO: Pod "pod-subpath-test-downwardapi-hrgj": Phase="Pending", Reason="", readiness=false. Elapsed: 16.083322856s
Dec 28 05:06:08.916: INFO: Pod "pod-subpath-test-downwardapi-hrgj": Phase="Running", Reason="", readiness=false. Elapsed: 18.090353763s
Dec 28 05:06:10.924: INFO: Pod "pod-subpath-test-downwardapi-hrgj": Phase="Running", Reason="", readiness=false. Elapsed: 20.098617033s
Dec 28 05:06:12.932: INFO: Pod "pod-subpath-test-downwardapi-hrgj": Phase="Running", Reason="", readiness=false. Elapsed: 22.106735216s
Dec 28 05:06:14.940: INFO: Pod "pod-subpath-test-downwardapi-hrgj": Phase="Running", Reason="", readiness=false. Elapsed: 24.114920876s
Dec 28 05:06:16.985: INFO: Pod "pod-subpath-test-downwardapi-hrgj": Phase="Running", Reason="", readiness=false. Elapsed: 26.159217206s
Dec 28 05:06:18.993: INFO: Pod "pod-subpath-test-downwardapi-hrgj": Phase="Running", Reason="", readiness=false. Elapsed: 28.1678326s
Dec 28 05:06:21.001: INFO: Pod "pod-subpath-test-downwardapi-hrgj": Phase="Running", Reason="", readiness=false. Elapsed: 30.17504835s
Dec 28 05:06:23.013: INFO: Pod "pod-subpath-test-downwardapi-hrgj": Phase="Running", Reason="", readiness=false. Elapsed: 32.18745865s
Dec 28 05:06:25.043: INFO: Pod "pod-subpath-test-downwardapi-hrgj": Phase="Succeeded", Reason="", readiness=false. Elapsed: 34.217926913s
STEP: Saw pod success
Dec 28 05:06:25.044: INFO: Pod "pod-subpath-test-downwardapi-hrgj" satisfied condition "success or failure"
Dec 28 05:06:25.049: INFO: Trying to get logs from node 10.10.102.68-share pod pod-subpath-test-downwardapi-hrgj container test-container-subpath-downwardapi-hrgj: <nil>
STEP: delete the pod
Dec 28 05:06:25.139: INFO: Waiting for pod pod-subpath-test-downwardapi-hrgj to disappear
Dec 28 05:06:25.158: INFO: Pod pod-subpath-test-downwardapi-hrgj no longer exists
STEP: Deleting pod pod-subpath-test-downwardapi-hrgj
Dec 28 05:06:25.158: INFO: Deleting pod "pod-subpath-test-downwardapi-hrgj" in namespace "e2e-tests-subpath-9ndht"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 28 05:06:25.169: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-9ndht" for this suite.
Dec 28 05:06:31.263: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 05:06:31.313: INFO: namespace: e2e-tests-subpath-9ndht, resource: bindings, ignored listing per whitelist
Dec 28 05:06:31.492: INFO: namespace e2e-tests-subpath-9ndht deletion completed in 6.31107621s

• [SLOW TEST:40.983 seconds]
[sig-storage] Subpath
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with downward pod [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 28 05:06:31.492: INFO: >>> kubeConfig: /tmp/kubeconfig-994138694
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:78
Dec 28 05:06:31.730: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Dec 28 05:06:31.760: INFO: Waiting for terminating namespaces to be deleted...
Dec 28 05:06:31.766: INFO: 
Logging pods the kubelet thinks is on node 10.10.102.66-slave before test
Dec 28 05:06:31.790: INFO: nginx-ingress-controller-vnpqb from kube-system started at 2018-12-26 05:28:21 +0000 UTC (1 container statuses recorded)
Dec 28 05:06:31.790: INFO: 	Container nginx-ingress-lb ready: true, restart count 1
Dec 28 05:06:31.790: INFO: api-mysql-67cc46668c-bnm4p from kube-system started at 2018-12-27 09:21:23 +0000 UTC (1 container statuses recorded)
Dec 28 05:06:31.790: INFO: 	Container mysql ready: true, restart count 1
Dec 28 05:06:31.790: INFO: sonobuoy-systemd-logs-daemon-set-3ac5f2aeec8e4908-b5jj8 from heptio-sonobuoy started at 2018-12-28 04:28:42 +0000 UTC (2 container statuses recorded)
Dec 28 05:06:31.790: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 0
Dec 28 05:06:31.790: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Dec 28 05:06:31.790: INFO: oam-api-f8fb98b46-ck8zq from kube-system started at 2018-12-26 05:27:51 +0000 UTC (1 container statuses recorded)
Dec 28 05:06:31.790: INFO: 	Container oam-api ready: true, restart count 1
Dec 28 05:06:31.790: INFO: api-redis-84cb4999bb-gvcl2 from kube-system started at 2018-12-27 09:21:23 +0000 UTC (1 container statuses recorded)
Dec 28 05:06:31.790: INFO: 	Container redis ready: true, restart count 1
Dec 28 05:06:31.790: INFO: calico-node-67kmt from kube-system started at 2018-12-26 05:26:29 +0000 UTC (2 container statuses recorded)
Dec 28 05:06:31.790: INFO: 	Container calico-node ready: true, restart count 1
Dec 28 05:06:31.790: INFO: 	Container install-cni ready: true, restart count 1
Dec 28 05:06:31.790: INFO: fluentd-es-v1.22-v4v7d from kube-system started at 2018-12-26 07:34:43 +0000 UTC (1 container statuses recorded)
Dec 28 05:06:31.790: INFO: 	Container fluentd-es ready: true, restart count 1
Dec 28 05:06:31.790: INFO: elasticsearch-logging-7d54c5bbd-sjrzv from kube-system started at 2018-12-26 08:22:11 +0000 UTC (1 container statuses recorded)
Dec 28 05:06:31.790: INFO: 	Container elasticsearch-logging ready: true, restart count 1
Dec 28 05:06:31.790: INFO: kube-proxy-fwznq from kube-system started at 2018-12-26 05:27:26 +0000 UTC (1 container statuses recorded)
Dec 28 05:06:31.790: INFO: 	Container kube-proxy ready: true, restart count 1
Dec 28 05:06:31.790: INFO: webapi-848b7457ff-rpm9d from kube-system started at 2018-12-26 05:27:32 +0000 UTC (1 container statuses recorded)
Dec 28 05:06:31.790: INFO: 	Container webapi ready: true, restart count 1
Dec 28 05:06:31.790: INFO: monitoring-influxdb-6fc587d568-4vbxr from kube-system started at 2018-12-26 05:27:51 +0000 UTC (2 container statuses recorded)
Dec 28 05:06:31.790: INFO: 	Container influxdb ready: true, restart count 1
Dec 28 05:06:31.790: INFO: 	Container kapacitor ready: true, restart count 1
Dec 28 05:06:31.790: INFO: webpage-66948b5fd9-7r9xb from kube-system started at 2018-12-26 05:27:31 +0000 UTC (1 container statuses recorded)
Dec 28 05:06:31.790: INFO: 	Container hc ready: true, restart count 1
Dec 28 05:06:31.790: INFO: autoscale-controller-6b595cffcd-twj7w from kube-system started at 2018-12-27 09:21:23 +0000 UTC (1 container statuses recorded)
Dec 28 05:06:31.790: INFO: 	Container autoscale-controller ready: true, restart count 1
Dec 28 05:06:31.790: INFO: heapster-84bd55cd8b-ql8kq from kube-system started at 2018-12-26 05:26:32 +0000 UTC (1 container statuses recorded)
Dec 28 05:06:31.790: INFO: 	Container heapster ready: true, restart count 1
Dec 28 05:06:31.790: INFO: cluster-controller-dddf9d5b8-d9p54 from kube-system started at 2018-12-27 09:21:23 +0000 UTC (1 container statuses recorded)
Dec 28 05:06:31.790: INFO: 	Container cluster-controller ready: true, restart count 1
Dec 28 05:06:31.790: INFO: file-upload-75b89d597b-9r4wl from kube-system started at 2018-12-27 09:21:24 +0000 UTC (1 container statuses recorded)
Dec 28 05:06:31.790: INFO: 	Container file-upload ready: true, restart count 1
Dec 28 05:06:31.790: INFO: 
Logging pods the kubelet thinks is on node 10.10.102.67-slave before test
Dec 28 05:06:31.811: INFO: elasticsearch-logging-7d54c5bbd-lggjp from kube-system started at 2018-12-27 09:56:48 +0000 UTC (1 container statuses recorded)
Dec 28 05:06:31.811: INFO: 	Container elasticsearch-logging ready: true, restart count 1
Dec 28 05:06:31.811: INFO: oam-task-75fcbc8c6f-7lk67 from kube-system started at 2018-12-27 09:56:43 +0000 UTC (1 container statuses recorded)
Dec 28 05:06:31.811: INFO: 	Container oam-task ready: true, restart count 1
Dec 28 05:06:31.811: INFO: jenkins-85bb95f67b-p598t from kube-system started at 2018-12-27 09:56:43 +0000 UTC (1 container statuses recorded)
Dec 28 05:06:31.811: INFO: 	Container jenkins ready: true, restart count 1
Dec 28 05:06:31.811: INFO: nginx-ingress-controller-dqpcw from kube-system started at 2018-12-26 05:28:21 +0000 UTC (1 container statuses recorded)
Dec 28 05:06:31.811: INFO: 	Container nginx-ingress-lb ready: true, restart count 2
Dec 28 05:06:31.811: INFO: calico-node-8kbvn from kube-system started at 2018-12-26 05:26:28 +0000 UTC (2 container statuses recorded)
Dec 28 05:06:31.811: INFO: 	Container calico-node ready: true, restart count 2
Dec 28 05:06:31.811: INFO: 	Container install-cni ready: true, restart count 2
Dec 28 05:06:31.811: INFO: fluentd-es-v1.22-5r2gg from kube-system started at 2018-12-26 07:34:44 +0000 UTC (1 container statuses recorded)
Dec 28 05:06:31.811: INFO: 	Container fluentd-es ready: true, restart count 2
Dec 28 05:06:31.811: INFO: sonobuoy-systemd-logs-daemon-set-3ac5f2aeec8e4908-vd5rl from heptio-sonobuoy started at 2018-12-28 04:41:57 +0000 UTC (2 container statuses recorded)
Dec 28 05:06:31.811: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 0
Dec 28 05:06:31.811: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Dec 28 05:06:31.811: INFO: kube-proxy-krwtq from kube-system started at 2018-12-26 05:28:31 +0000 UTC (1 container statuses recorded)
Dec 28 05:06:31.811: INFO: 	Container kube-proxy ready: true, restart count 2
Dec 28 05:06:31.811: INFO: 
Logging pods the kubelet thinks is on node 10.10.102.68-share before test
Dec 28 05:06:31.878: INFO: coredns-664589b88-4q6kf from kube-system started at 2018-12-26 05:26:30 +0000 UTC (1 container statuses recorded)
Dec 28 05:06:31.878: INFO: 	Container coredns ready: true, restart count 2
Dec 28 05:06:31.878: INFO: sonobuoy-e2e-job-efc254e3f08a4c61 from heptio-sonobuoy started at 2018-12-28 04:28:42 +0000 UTC (2 container statuses recorded)
Dec 28 05:06:31.878: INFO: 	Container e2e ready: true, restart count 0
Dec 28 05:06:31.878: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Dec 28 05:06:31.878: INFO: calico-node-l9kkx from kube-system started at 2018-12-26 05:26:29 +0000 UTC (2 container statuses recorded)
Dec 28 05:06:31.878: INFO: 	Container calico-node ready: true, restart count 2
Dec 28 05:06:31.878: INFO: 	Container install-cni ready: true, restart count 2
Dec 28 05:06:31.878: INFO: default-http-backend-77958d7c8c-stdqt from kube-system started at 2018-12-26 05:26:30 +0000 UTC (1 container statuses recorded)
Dec 28 05:06:31.878: INFO: 	Container default-http-backend ready: true, restart count 2
Dec 28 05:06:31.878: INFO: kube-proxy-x6fqp from kube-system started at 2018-12-26 05:27:17 +0000 UTC (1 container statuses recorded)
Dec 28 05:06:31.878: INFO: 	Container kube-proxy ready: true, restart count 4
Dec 28 05:06:31.878: INFO: fluentd-es-v1.22-bbfwn from kube-system started at 2018-12-26 07:34:44 +0000 UTC (1 container statuses recorded)
Dec 28 05:06:31.878: INFO: 	Container fluentd-es ready: true, restart count 2
Dec 28 05:06:31.878: INFO: sonobuoy-systemd-logs-daemon-set-3ac5f2aeec8e4908-nsbv9 from heptio-sonobuoy started at 2018-12-28 04:28:42 +0000 UTC (2 container statuses recorded)
Dec 28 05:06:31.878: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 0
Dec 28 05:06:31.878: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Dec 28 05:06:31.878: INFO: 
Logging pods the kubelet thinks is on node 10.10.102.69-build before test
Dec 28 05:06:31.897: INFO: kube-proxy-kwmsc from kube-system started at 2018-12-26 05:27:15 +0000 UTC (1 container statuses recorded)
Dec 28 05:06:31.897: INFO: 	Container kube-proxy ready: true, restart count 3
Dec 28 05:06:31.897: INFO: calico-node-lbbsm from kube-system started at 2018-12-26 05:26:32 +0000 UTC (2 container statuses recorded)
Dec 28 05:06:31.897: INFO: 	Container calico-node ready: true, restart count 3
Dec 28 05:06:31.897: INFO: 	Container install-cni ready: true, restart count 2
Dec 28 05:06:31.897: INFO: coredns-664589b88-tmf5k from kube-system started at 2018-12-26 05:26:32 +0000 UTC (1 container statuses recorded)
Dec 28 05:06:31.897: INFO: 	Container coredns ready: true, restart count 2
Dec 28 05:06:31.897: INFO: sonobuoy from heptio-sonobuoy started at 2018-12-28 04:28:35 +0000 UTC (1 container statuses recorded)
Dec 28 05:06:31.897: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Dec 28 05:06:31.897: INFO: fluentd-es-v1.22-swx8q from kube-system started at 2018-12-26 07:34:44 +0000 UTC (1 container statuses recorded)
Dec 28 05:06:31.897: INFO: 	Container fluentd-es ready: true, restart count 2
Dec 28 05:06:31.897: INFO: calico-kube-controllers-5dd667cc5b-48bhs from kube-system started at 2018-12-26 05:26:29 +0000 UTC (1 container statuses recorded)
Dec 28 05:06:31.897: INFO: 	Container calico-kube-controllers ready: true, restart count 3
Dec 28 05:06:31.897: INFO: sonobuoy-systemd-logs-daemon-set-3ac5f2aeec8e4908-jxfv4 from heptio-sonobuoy started at 2018-12-28 04:28:43 +0000 UTC (2 container statuses recorded)
Dec 28 05:06:31.897: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 0
Dec 28 05:06:31.897: INFO: 	Container sonobuoy-worker ready: true, restart count 0
[It] validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Trying to launch a pod without a label to get a node which can launch it.
STEP: Explicitly delete pod here to free the resource it takes.
STEP: Trying to apply a random label on the found node.
STEP: verifying the node has the label kubernetes.io/e2e-5c1961df-0a5e-11e9-8a07-628dff7095f4 42
STEP: Trying to relaunch the pod, now with labels.
STEP: removing the label kubernetes.io/e2e-5c1961df-0a5e-11e9-8a07-628dff7095f4 off the node 10.10.102.69-build
STEP: verifying the node doesn't have the label kubernetes.io/e2e-5c1961df-0a5e-11e9-8a07-628dff7095f4
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 28 05:06:48.123: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-sched-pred-fltks" for this suite.
Dec 28 05:07:04.158: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 05:07:04.180: INFO: namespace: e2e-tests-sched-pred-fltks, resource: bindings, ignored listing per whitelist
Dec 28 05:07:04.364: INFO: namespace e2e-tests-sched-pred-fltks deletion completed in 16.23203818s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:69

• [SLOW TEST:32.872 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl api-versions 
  should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 28 05:07:04.364: INFO: >>> kubeConfig: /tmp/kubeconfig-994138694
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: validating api versions
Dec 28 05:07:04.600: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994138694 api-versions'
Dec 28 05:07:04.937: INFO: stderr: ""
Dec 28 05:07:04.937: INFO: stdout: "admissionregistration.k8s.io/v1beta1\napiextensions.k8s.io/v1beta1\napiregistration.k8s.io/v1\napiregistration.k8s.io/v1beta1\napps/v1\napps/v1beta1\napps/v1beta2\nauthentication.k8s.io/v1\nauthentication.k8s.io/v1beta1\nauthorization.k8s.io/v1\nauthorization.k8s.io/v1beta1\nautoscaling/v1\nautoscaling/v2beta1\nautoscaling/v2beta2\nbatch/v1\nbatch/v1beta1\ncertificates.k8s.io/v1beta1\ncoordination.k8s.io/v1beta1\nevents.k8s.io/v1beta1\nextensions/v1beta1\nharmonycloud.cn/v1\nnetworking.k8s.io/v1\npolicy/v1beta1\nrbac.authorization.k8s.io/v1\nrbac.authorization.k8s.io/v1beta1\nscheduling.k8s.io/v1beta1\nstorage.k8s.io/v1\nstorage.k8s.io/v1beta1\nv1\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 28 05:07:04.938: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-5kblh" for this suite.
Dec 28 05:07:11.023: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 05:07:11.229: INFO: namespace: e2e-tests-kubectl-5kblh, resource: bindings, ignored listing per whitelist
Dec 28 05:07:11.235: INFO: namespace e2e-tests-kubectl-5kblh deletion completed in 6.2862332s

• [SLOW TEST:6.871 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl api-versions
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should check if v1 is in available api versions  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] ConfigMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 28 05:07:11.235: INFO: >>> kubeConfig: /tmp/kubeconfig-994138694
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-upd-6ee1108a-0a5e-11e9-8a07-628dff7095f4
STEP: Creating the pod
STEP: Updating configmap configmap-test-upd-6ee1108a-0a5e-11e9-8a07-628dff7095f4
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 28 05:07:21.678: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-x689l" for this suite.
Dec 28 05:07:45.868: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 05:07:46.028: INFO: namespace: e2e-tests-configmap-x689l, resource: bindings, ignored listing per whitelist
Dec 28 05:07:46.076: INFO: namespace e2e-tests-configmap-x689l deletion completed in 24.38709917s

• [SLOW TEST:34.841 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts 
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 28 05:07:46.077: INFO: >>> kubeConfig: /tmp/kubeconfig-994138694
STEP: Building a namespace api object, basename svcaccounts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: getting the auto-created API token
Dec 28 05:07:47.030: INFO: created pod pod-service-account-defaultsa
Dec 28 05:07:47.030: INFO: pod pod-service-account-defaultsa service account token volume mount: true
Dec 28 05:07:47.045: INFO: created pod pod-service-account-mountsa
Dec 28 05:07:47.045: INFO: pod pod-service-account-mountsa service account token volume mount: true
Dec 28 05:07:47.103: INFO: created pod pod-service-account-nomountsa
Dec 28 05:07:47.103: INFO: pod pod-service-account-nomountsa service account token volume mount: false
Dec 28 05:07:47.142: INFO: created pod pod-service-account-defaultsa-mountspec
Dec 28 05:07:47.142: INFO: pod pod-service-account-defaultsa-mountspec service account token volume mount: true
Dec 28 05:07:47.167: INFO: created pod pod-service-account-mountsa-mountspec
Dec 28 05:07:47.167: INFO: pod pod-service-account-mountsa-mountspec service account token volume mount: true
Dec 28 05:07:47.194: INFO: created pod pod-service-account-nomountsa-mountspec
Dec 28 05:07:47.194: INFO: pod pod-service-account-nomountsa-mountspec service account token volume mount: true
Dec 28 05:07:47.255: INFO: created pod pod-service-account-defaultsa-nomountspec
Dec 28 05:07:47.255: INFO: pod pod-service-account-defaultsa-nomountspec service account token volume mount: false
Dec 28 05:07:47.273: INFO: created pod pod-service-account-mountsa-nomountspec
Dec 28 05:07:47.273: INFO: pod pod-service-account-mountsa-nomountspec service account token volume mount: false
Dec 28 05:07:47.293: INFO: created pod pod-service-account-nomountsa-nomountspec
Dec 28 05:07:47.293: INFO: pod pod-service-account-nomountsa-nomountspec service account token volume mount: false
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 28 05:07:47.293: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-svcaccounts-cxsmv" for this suite.
Dec 28 05:08:33.438: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 05:08:33.488: INFO: namespace: e2e-tests-svcaccounts-cxsmv, resource: bindings, ignored listing per whitelist
Dec 28 05:08:33.660: INFO: namespace e2e-tests-svcaccounts-cxsmv deletion completed in 46.327543827s

• [SLOW TEST:47.583 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:22
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-api-machinery] Garbage collector 
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 28 05:08:33.660: INFO: >>> kubeConfig: /tmp/kubeconfig-994138694
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: Gathering metrics
Dec 28 05:08:39.970: INFO: MetricsGrabber failed grab metrics. Skipping metrics gathering.
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 28 05:08:39.970: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-j6wv7" for this suite.
Dec 28 05:08:48.020: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 05:08:48.083: INFO: namespace: e2e-tests-gc-j6wv7, resource: bindings, ignored listing per whitelist
Dec 28 05:08:48.238: INFO: namespace e2e-tests-gc-j6wv7 deletion completed in 8.25671018s

• [SLOW TEST:14.578 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-network] Proxy version v1 
  should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] version v1
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 28 05:08:48.238: INFO: >>> kubeConfig: /tmp/kubeconfig-994138694
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: starting an echo server on multiple ports
STEP: creating replication controller proxy-service-6n2pt in namespace e2e-tests-proxy-g2zbb
I1228 05:08:48.688332      14 runners.go:180] Created replication controller with name: proxy-service-6n2pt, namespace: e2e-tests-proxy-g2zbb, replica count: 1
I1228 05:08:49.742121      14 runners.go:180] proxy-service-6n2pt Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1228 05:08:50.742603      14 runners.go:180] proxy-service-6n2pt Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1228 05:08:51.743021      14 runners.go:180] proxy-service-6n2pt Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1228 05:08:52.743394      14 runners.go:180] proxy-service-6n2pt Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1228 05:08:53.743850      14 runners.go:180] proxy-service-6n2pt Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1228 05:08:54.744354      14 runners.go:180] proxy-service-6n2pt Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1228 05:08:55.744721      14 runners.go:180] proxy-service-6n2pt Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1228 05:08:56.745146      14 runners.go:180] proxy-service-6n2pt Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I1228 05:08:57.745590      14 runners.go:180] proxy-service-6n2pt Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I1228 05:08:58.746002      14 runners.go:180] proxy-service-6n2pt Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I1228 05:08:59.746424      14 runners.go:180] proxy-service-6n2pt Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Dec 28 05:08:59.758: INFO: setup took 11.164909496s, starting test cases
STEP: running 16 cases, 20 attempts per case, 320 total attempts
Dec 28 05:08:59.836: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-g2zbb/pods/http:proxy-service-6n2pt-rsczg:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-g2zbb/pods/http:proxy-service-6n2pt-rsczg:1080/proxy/... (200; 77.981873ms)
Dec 28 05:08:59.843: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-g2zbb/pods/proxy-service-6n2pt-rsczg/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-g2zbb/pods/proxy-service-6n2pt-rsczg/proxy/rewriteme"... (200; 83.00087ms)
Dec 28 05:08:59.863: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-g2zbb/services/proxy-service-6n2pt:portname1/proxy/: foo (200; 103.82785ms)
Dec 28 05:08:59.863: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-g2zbb/services/http:proxy-service-6n2pt:portname2/proxy/: bar (200; 103.626394ms)
Dec 28 05:08:59.868: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-g2zbb/pods/proxy-service-6n2pt-rsczg:162/proxy/: bar (200; 108.91338ms)
Dec 28 05:08:59.878: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-g2zbb/pods/http:proxy-service-6n2pt-rsczg:160/proxy/: foo (200; 118.28838ms)
Dec 28 05:08:59.879: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-g2zbb/pods/proxy-service-6n2pt-rsczg:160/proxy/: foo (200; 119.12108ms)
Dec 28 05:08:59.881: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-g2zbb/services/http:proxy-service-6n2pt:portname1/proxy/: foo (200; 121.351053ms)
Dec 28 05:08:59.882: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-g2zbb/pods/http:proxy-service-6n2pt-rsczg:162/proxy/: bar (200; 123.45594ms)
Dec 28 05:08:59.882: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-g2zbb/pods/proxy-service-6n2pt-rsczg:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-g2zbb/pods/proxy-service-6n2pt-rsczg:1080/proxy/rewri... (200; 122.680506ms)
Dec 28 05:08:59.882: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-g2zbb/services/proxy-service-6n2pt:portname2/proxy/: bar (200; 122.12208ms)
Dec 28 05:08:59.911: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-g2zbb/services/https:proxy-service-6n2pt:tlsportname2/proxy/: tls qux (200; 151.318653ms)
Dec 28 05:08:59.911: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-g2zbb/pods/https:proxy-service-6n2pt-rsczg:462/proxy/: tls qux (200; 150.648ms)
Dec 28 05:08:59.914: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-g2zbb/services/https:proxy-service-6n2pt:tlsportname1/proxy/: tls baz (200; 153.563856ms)
Dec 28 05:08:59.914: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-g2zbb/pods/https:proxy-service-6n2pt-rsczg:460/proxy/: tls baz (200; 155.007ms)
Dec 28 05:08:59.923: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-g2zbb/pods/https:proxy-service-6n2pt-rsczg:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-g2zbb/pods/https:proxy-service-6n2pt-rsczg:443/proxy/... (200; 164.036377ms)
Dec 28 05:08:59.959: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-g2zbb/pods/proxy-service-6n2pt-rsczg:160/proxy/: foo (200; 33.648964ms)
Dec 28 05:08:59.964: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-g2zbb/pods/http:proxy-service-6n2pt-rsczg:162/proxy/: bar (200; 37.00028ms)
Dec 28 05:08:59.964: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-g2zbb/pods/http:proxy-service-6n2pt-rsczg:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-g2zbb/pods/http:proxy-service-6n2pt-rsczg:1080/proxy/... (200; 37.993233ms)
Dec 28 05:08:59.969: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-g2zbb/pods/proxy-service-6n2pt-rsczg:162/proxy/: bar (200; 42.950747ms)
Dec 28 05:08:59.969: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-g2zbb/pods/https:proxy-service-6n2pt-rsczg:462/proxy/: tls qux (200; 44.13291ms)
Dec 28 05:08:59.970: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-g2zbb/pods/proxy-service-6n2pt-rsczg/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-g2zbb/pods/proxy-service-6n2pt-rsczg/proxy/rewriteme"... (200; 45.0083ms)
Dec 28 05:08:59.970: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-g2zbb/services/http:proxy-service-6n2pt:portname1/proxy/: foo (200; 45.353747ms)
Dec 28 05:08:59.970: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-g2zbb/pods/http:proxy-service-6n2pt-rsczg:160/proxy/: foo (200; 44.926267ms)
Dec 28 05:08:59.970: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-g2zbb/pods/https:proxy-service-6n2pt-rsczg:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-g2zbb/pods/https:proxy-service-6n2pt-rsczg:443/proxy/... (200; 46.53229ms)
Dec 28 05:08:59.970: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-g2zbb/pods/proxy-service-6n2pt-rsczg:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-g2zbb/pods/proxy-service-6n2pt-rsczg:1080/proxy/rewri... (200; 45.928543ms)
Dec 28 05:08:59.970: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-g2zbb/services/http:proxy-service-6n2pt:portname2/proxy/: bar (200; 46.24113ms)
Dec 28 05:08:59.970: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-g2zbb/services/proxy-service-6n2pt:portname1/proxy/: foo (200; 44.00385ms)
Dec 28 05:08:59.970: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-g2zbb/services/proxy-service-6n2pt:portname2/proxy/: bar (200; 44.509306ms)
Dec 28 05:08:59.970: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-g2zbb/pods/https:proxy-service-6n2pt-rsczg:460/proxy/: tls baz (200; 44.820983ms)
Dec 28 05:08:59.970: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-g2zbb/services/https:proxy-service-6n2pt:tlsportname1/proxy/: tls baz (200; 44.549026ms)
Dec 28 05:08:59.970: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-g2zbb/services/https:proxy-service-6n2pt:tlsportname2/proxy/: tls qux (200; 42.69888ms)
Dec 28 05:08:59.985: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-g2zbb/pods/proxy-service-6n2pt-rsczg:162/proxy/: bar (200; 14.359966ms)
Dec 28 05:08:59.987: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-g2zbb/pods/proxy-service-6n2pt-rsczg/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-g2zbb/pods/proxy-service-6n2pt-rsczg/proxy/rewriteme"... (200; 15.373683ms)
Dec 28 05:08:59.987: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-g2zbb/pods/proxy-service-6n2pt-rsczg:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-g2zbb/pods/proxy-service-6n2pt-rsczg:1080/proxy/rewri... (200; 16.149533ms)
Dec 28 05:08:59.987: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-g2zbb/pods/proxy-service-6n2pt-rsczg:160/proxy/: foo (200; 14.607816ms)
Dec 28 05:08:59.995: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-g2zbb/pods/http:proxy-service-6n2pt-rsczg:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-g2zbb/pods/http:proxy-service-6n2pt-rsczg:1080/proxy/... (200; 22.753043ms)
Dec 28 05:08:59.996: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-g2zbb/pods/http:proxy-service-6n2pt-rsczg:160/proxy/: foo (200; 23.785107ms)
Dec 28 05:08:59.996: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-g2zbb/pods/https:proxy-service-6n2pt-rsczg:462/proxy/: tls qux (200; 23.470697ms)
Dec 28 05:08:59.996: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-g2zbb/pods/https:proxy-service-6n2pt-rsczg:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-g2zbb/pods/https:proxy-service-6n2pt-rsczg:443/proxy/... (200; 23.450194ms)
Dec 28 05:08:59.996: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-g2zbb/pods/https:proxy-service-6n2pt-rsczg:460/proxy/: tls baz (200; 23.406517ms)
Dec 28 05:08:59.996: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-g2zbb/pods/http:proxy-service-6n2pt-rsczg:162/proxy/: bar (200; 24.142734ms)
Dec 28 05:09:00.005: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-g2zbb/services/http:proxy-service-6n2pt:portname1/proxy/: foo (200; 34.27527ms)
Dec 28 05:09:00.005: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-g2zbb/services/http:proxy-service-6n2pt:portname2/proxy/: bar (200; 34.89109ms)
Dec 28 05:09:00.006: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-g2zbb/services/https:proxy-service-6n2pt:tlsportname2/proxy/: tls qux (200; 33.655067ms)
Dec 28 05:09:00.006: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-g2zbb/services/proxy-service-6n2pt:portname1/proxy/: foo (200; 33.800053ms)
Dec 28 05:09:00.006: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-g2zbb/services/proxy-service-6n2pt:portname2/proxy/: bar (200; 33.598433ms)
Dec 28 05:09:00.006: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-g2zbb/services/https:proxy-service-6n2pt:tlsportname1/proxy/: tls baz (200; 33.69608ms)
Dec 28 05:09:00.026: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-g2zbb/pods/proxy-service-6n2pt-rsczg:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-g2zbb/pods/proxy-service-6n2pt-rsczg:1080/proxy/rewri... (200; 17.02684ms)
Dec 28 05:09:00.028: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-g2zbb/pods/proxy-service-6n2pt-rsczg/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-g2zbb/pods/proxy-service-6n2pt-rsczg/proxy/rewriteme"... (200; 17.640914ms)
Dec 28 05:09:00.028: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-g2zbb/pods/http:proxy-service-6n2pt-rsczg:162/proxy/: bar (200; 21.001517ms)
Dec 28 05:09:00.031: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-g2zbb/pods/http:proxy-service-6n2pt-rsczg:160/proxy/: foo (200; 22.217924ms)
Dec 28 05:09:00.032: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-g2zbb/pods/http:proxy-service-6n2pt-rsczg:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-g2zbb/pods/http:proxy-service-6n2pt-rsczg:1080/proxy/... (200; 21.092977ms)
Dec 28 05:09:00.032: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-g2zbb/pods/https:proxy-service-6n2pt-rsczg:460/proxy/: tls baz (200; 23.886783ms)
Dec 28 05:09:00.032: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-g2zbb/pods/https:proxy-service-6n2pt-rsczg:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-g2zbb/pods/https:proxy-service-6n2pt-rsczg:443/proxy/... (200; 24.221153ms)
Dec 28 05:09:00.032: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-g2zbb/pods/https:proxy-service-6n2pt-rsczg:462/proxy/: tls qux (200; 22.299883ms)
Dec 28 05:09:00.032: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-g2zbb/pods/proxy-service-6n2pt-rsczg:160/proxy/: foo (200; 25.4207ms)
Dec 28 05:09:00.037: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-g2zbb/services/https:proxy-service-6n2pt:tlsportname2/proxy/: tls qux (200; 28.51481ms)
Dec 28 05:09:00.037: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-g2zbb/services/proxy-service-6n2pt:portname1/proxy/: foo (200; 28.967476ms)
Dec 28 05:09:00.037: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-g2zbb/services/http:proxy-service-6n2pt:portname1/proxy/: foo (200; 27.238657ms)
Dec 28 05:09:00.037: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-g2zbb/services/http:proxy-service-6n2pt:portname2/proxy/: bar (200; 28.597804ms)
Dec 28 05:09:00.040: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-g2zbb/services/proxy-service-6n2pt:portname2/proxy/: bar (200; 29.03132ms)
Dec 28 05:09:00.040: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-g2zbb/pods/proxy-service-6n2pt-rsczg:162/proxy/: bar (200; 32.9757ms)
Dec 28 05:09:00.040: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-g2zbb/services/https:proxy-service-6n2pt:tlsportname1/proxy/: tls baz (200; 34.131046ms)
Dec 28 05:09:00.076: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-g2zbb/pods/proxy-service-6n2pt-rsczg/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-g2zbb/pods/proxy-service-6n2pt-rsczg/proxy/rewriteme"... (200; 33.756407ms)
Dec 28 05:09:00.077: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-g2zbb/pods/proxy-service-6n2pt-rsczg:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-g2zbb/pods/proxy-service-6n2pt-rsczg:1080/proxy/rewri... (200; 34.3453ms)
Dec 28 05:09:00.085: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-g2zbb/pods/https:proxy-service-6n2pt-rsczg:460/proxy/: tls baz (200; 43.43568ms)
Dec 28 05:09:00.086: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-g2zbb/pods/https:proxy-service-6n2pt-rsczg:462/proxy/: tls qux (200; 45.705543ms)
Dec 28 05:09:00.086: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-g2zbb/pods/proxy-service-6n2pt-rsczg:162/proxy/: bar (200; 45.585233ms)
Dec 28 05:09:00.087: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-g2zbb/pods/proxy-service-6n2pt-rsczg:160/proxy/: foo (200; 44.69516ms)
Dec 28 05:09:00.087: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-g2zbb/services/https:proxy-service-6n2pt:tlsportname1/proxy/: tls baz (200; 45.705067ms)
Dec 28 05:09:00.087: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-g2zbb/pods/http:proxy-service-6n2pt-rsczg:160/proxy/: foo (200; 44.968977ms)
Dec 28 05:09:00.087: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-g2zbb/services/proxy-service-6n2pt:portname1/proxy/: foo (200; 45.76871ms)
Dec 28 05:09:00.088: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-g2zbb/services/http:proxy-service-6n2pt:portname1/proxy/: foo (200; 45.22633ms)
Dec 28 05:09:00.088: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-g2zbb/pods/https:proxy-service-6n2pt-rsczg:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-g2zbb/pods/https:proxy-service-6n2pt-rsczg:443/proxy/... (200; 46.288604ms)
Dec 28 05:09:00.093: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-g2zbb/pods/http:proxy-service-6n2pt-rsczg:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-g2zbb/pods/http:proxy-service-6n2pt-rsczg:1080/proxy/... (200; 51.248467ms)
Dec 28 05:09:00.093: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-g2zbb/services/https:proxy-service-6n2pt:tlsportname2/proxy/: tls qux (200; 51.273754ms)
Dec 28 05:09:00.093: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-g2zbb/services/proxy-service-6n2pt:portname2/proxy/: bar (200; 51.63638ms)
Dec 28 05:09:00.093: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-g2zbb/services/http:proxy-service-6n2pt:portname2/proxy/: bar (200; 51.018133ms)
Dec 28 05:09:00.093: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-g2zbb/pods/http:proxy-service-6n2pt-rsczg:162/proxy/: bar (200; 52.37414ms)
Dec 28 05:09:00.123: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-g2zbb/pods/proxy-service-6n2pt-rsczg:160/proxy/: foo (200; 25.445173ms)
Dec 28 05:09:00.124: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-g2zbb/pods/https:proxy-service-6n2pt-rsczg:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-g2zbb/pods/https:proxy-service-6n2pt-rsczg:443/proxy/... (200; 27.59464ms)
Dec 28 05:09:00.128: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-g2zbb/pods/https:proxy-service-6n2pt-rsczg:460/proxy/: tls baz (200; 30.794876ms)
Dec 28 05:09:00.128: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-g2zbb/pods/http:proxy-service-6n2pt-rsczg:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-g2zbb/pods/http:proxy-service-6n2pt-rsczg:1080/proxy/... (200; 32.32902ms)
Dec 28 05:09:00.128: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-g2zbb/pods/http:proxy-service-6n2pt-rsczg:160/proxy/: foo (200; 33.541816ms)
Dec 28 05:09:00.129: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-g2zbb/pods/proxy-service-6n2pt-rsczg:162/proxy/: bar (200; 32.474073ms)
Dec 28 05:09:00.131: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-g2zbb/pods/proxy-service-6n2pt-rsczg:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-g2zbb/pods/proxy-service-6n2pt-rsczg:1080/proxy/rewri... (200; 38.055286ms)
Dec 28 05:09:00.132: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-g2zbb/pods/http:proxy-service-6n2pt-rsczg:162/proxy/: bar (200; 35.09272ms)
Dec 28 05:09:00.133: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-g2zbb/pods/proxy-service-6n2pt-rsczg/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-g2zbb/pods/proxy-service-6n2pt-rsczg/proxy/rewriteme"... (200; 38.38344ms)
Dec 28 05:09:00.143: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-g2zbb/pods/https:proxy-service-6n2pt-rsczg:462/proxy/: tls qux (200; 49.68451ms)
Dec 28 05:09:00.155: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-g2zbb/services/https:proxy-service-6n2pt:tlsportname2/proxy/: tls qux (200; 57.131937ms)
Dec 28 05:09:00.155: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-g2zbb/services/http:proxy-service-6n2pt:portname1/proxy/: foo (200; 60.942493ms)
Dec 28 05:09:00.156: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-g2zbb/services/proxy-service-6n2pt:portname1/proxy/: foo (200; 58.313803ms)
Dec 28 05:09:00.156: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-g2zbb/services/proxy-service-6n2pt:portname2/proxy/: bar (200; 60.515643ms)
Dec 28 05:09:00.156: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-g2zbb/services/http:proxy-service-6n2pt:portname2/proxy/: bar (200; 57.523487ms)
Dec 28 05:09:00.158: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-g2zbb/services/https:proxy-service-6n2pt:tlsportname1/proxy/: tls baz (200; 62.095347ms)
Dec 28 05:09:00.190: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-g2zbb/pods/https:proxy-service-6n2pt-rsczg:462/proxy/: tls qux (200; 29.168953ms)
Dec 28 05:09:00.190: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-g2zbb/pods/proxy-service-6n2pt-rsczg:162/proxy/: bar (200; 30.460587ms)
Dec 28 05:09:00.190: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-g2zbb/pods/http:proxy-service-6n2pt-rsczg:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-g2zbb/pods/http:proxy-service-6n2pt-rsczg:1080/proxy/... (200; 31.596753ms)
Dec 28 05:09:00.190: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-g2zbb/pods/https:proxy-service-6n2pt-rsczg:460/proxy/: tls baz (200; 29.75879ms)
Dec 28 05:09:00.190: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-g2zbb/pods/proxy-service-6n2pt-rsczg:160/proxy/: foo (200; 30.98439ms)
Dec 28 05:09:00.190: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-g2zbb/services/http:proxy-service-6n2pt:portname1/proxy/: foo (200; 29.544203ms)
Dec 28 05:09:00.191: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-g2zbb/pods/proxy-service-6n2pt-rsczg:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-g2zbb/pods/proxy-service-6n2pt-rsczg:1080/proxy/rewri... (200; 30.349876ms)
Dec 28 05:09:00.190: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-g2zbb/services/https:proxy-service-6n2pt:tlsportname1/proxy/: tls baz (200; 30.9493ms)
Dec 28 05:09:00.191: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-g2zbb/pods/proxy-service-6n2pt-rsczg/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-g2zbb/pods/proxy-service-6n2pt-rsczg/proxy/rewriteme"... (200; 32.92897ms)
Dec 28 05:09:00.191: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-g2zbb/pods/https:proxy-service-6n2pt-rsczg:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-g2zbb/pods/https:proxy-service-6n2pt-rsczg:443/proxy/... (200; 30.9473ms)
Dec 28 05:09:00.191: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-g2zbb/pods/http:proxy-service-6n2pt-rsczg:162/proxy/: bar (200; 31.214097ms)
Dec 28 05:09:00.191: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-g2zbb/pods/http:proxy-service-6n2pt-rsczg:160/proxy/: foo (200; 30.487147ms)
Dec 28 05:09:00.191: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-g2zbb/services/http:proxy-service-6n2pt:portname2/proxy/: bar (200; 30.0834ms)
Dec 28 05:09:00.191: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-g2zbb/services/proxy-service-6n2pt:portname1/proxy/: foo (200; 30.225377ms)
Dec 28 05:09:00.191: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-g2zbb/services/proxy-service-6n2pt:portname2/proxy/: bar (200; 32.59915ms)
Dec 28 05:09:00.191: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-g2zbb/services/https:proxy-service-6n2pt:tlsportname2/proxy/: tls qux (200; 30.52165ms)
Dec 28 05:09:00.204: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-g2zbb/pods/http:proxy-service-6n2pt-rsczg:160/proxy/: foo (200; 12.883783ms)
Dec 28 05:09:00.205: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-g2zbb/services/proxy-service-6n2pt:portname1/proxy/: foo (200; 13.864876ms)
Dec 28 05:09:00.212: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-g2zbb/pods/proxy-service-6n2pt-rsczg:162/proxy/: bar (200; 20.479703ms)
Dec 28 05:09:00.216: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-g2zbb/pods/https:proxy-service-6n2pt-rsczg:462/proxy/: tls qux (200; 24.199813ms)
Dec 28 05:09:00.216: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-g2zbb/services/http:proxy-service-6n2pt:portname2/proxy/: bar (200; 24.10065ms)
Dec 28 05:09:00.218: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-g2zbb/pods/proxy-service-6n2pt-rsczg:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-g2zbb/pods/proxy-service-6n2pt-rsczg:1080/proxy/rewri... (200; 25.282296ms)
Dec 28 05:09:00.218: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-g2zbb/pods/http:proxy-service-6n2pt-rsczg:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-g2zbb/pods/http:proxy-service-6n2pt-rsczg:1080/proxy/... (200; 26.57485ms)
Dec 28 05:09:00.218: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-g2zbb/pods/https:proxy-service-6n2pt-rsczg:460/proxy/: tls baz (200; 26.400383ms)
Dec 28 05:09:00.222: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-g2zbb/pods/proxy-service-6n2pt-rsczg/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-g2zbb/pods/proxy-service-6n2pt-rsczg/proxy/rewriteme"... (200; 29.921934ms)
Dec 28 05:09:00.222: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-g2zbb/services/http:proxy-service-6n2pt:portname1/proxy/: foo (200; 30.08291ms)
Dec 28 05:09:00.222: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-g2zbb/pods/https:proxy-service-6n2pt-rsczg:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-g2zbb/pods/https:proxy-service-6n2pt-rsczg:443/proxy/... (200; 30.674447ms)
Dec 28 05:09:00.223: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-g2zbb/pods/http:proxy-service-6n2pt-rsczg:162/proxy/: bar (200; 30.788907ms)
Dec 28 05:09:00.223: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-g2zbb/services/proxy-service-6n2pt:portname2/proxy/: bar (200; 31.115114ms)
Dec 28 05:09:00.223: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-g2zbb/pods/proxy-service-6n2pt-rsczg:160/proxy/: foo (200; 30.47828ms)
Dec 28 05:09:00.225: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-g2zbb/services/https:proxy-service-6n2pt:tlsportname2/proxy/: tls qux (200; 32.623553ms)
Dec 28 05:09:00.226: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-g2zbb/services/https:proxy-service-6n2pt:tlsportname1/proxy/: tls baz (200; 34.204064ms)
Dec 28 05:09:00.248: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-g2zbb/pods/https:proxy-service-6n2pt-rsczg:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-g2zbb/pods/https:proxy-service-6n2pt-rsczg:443/proxy/... (200; 22.36349ms)
Dec 28 05:09:00.250: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-g2zbb/pods/http:proxy-service-6n2pt-rsczg:160/proxy/: foo (200; 21.995303ms)
Dec 28 05:09:00.250: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-g2zbb/pods/https:proxy-service-6n2pt-rsczg:460/proxy/: tls baz (200; 22.988733ms)
Dec 28 05:09:00.250: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-g2zbb/pods/proxy-service-6n2pt-rsczg/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-g2zbb/pods/proxy-service-6n2pt-rsczg/proxy/rewriteme"... (200; 23.603087ms)
Dec 28 05:09:00.254: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-g2zbb/pods/proxy-service-6n2pt-rsczg:160/proxy/: foo (200; 26.159906ms)
Dec 28 05:09:00.254: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-g2zbb/pods/http:proxy-service-6n2pt-rsczg:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-g2zbb/pods/http:proxy-service-6n2pt-rsczg:1080/proxy/... (200; 26.669217ms)
Dec 28 05:09:00.254: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-g2zbb/services/http:proxy-service-6n2pt:portname1/proxy/: foo (200; 27.25326ms)
Dec 28 05:09:00.254: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-g2zbb/services/proxy-service-6n2pt:portname1/proxy/: foo (200; 26.385713ms)
Dec 28 05:09:00.254: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-g2zbb/services/http:proxy-service-6n2pt:portname2/proxy/: bar (200; 28.226174ms)
Dec 28 05:09:00.255: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-g2zbb/pods/proxy-service-6n2pt-rsczg:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-g2zbb/pods/proxy-service-6n2pt-rsczg:1080/proxy/rewri... (200; 28.01204ms)
Dec 28 05:09:00.257: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-g2zbb/pods/http:proxy-service-6n2pt-rsczg:162/proxy/: bar (200; 29.62374ms)
Dec 28 05:09:00.258: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-g2zbb/pods/proxy-service-6n2pt-rsczg:162/proxy/: bar (200; 30.152147ms)
Dec 28 05:09:00.258: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-g2zbb/pods/https:proxy-service-6n2pt-rsczg:462/proxy/: tls qux (200; 29.782897ms)
Dec 28 05:09:00.258: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-g2zbb/services/https:proxy-service-6n2pt:tlsportname1/proxy/: tls baz (200; 31.951957ms)
Dec 28 05:09:00.258: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-g2zbb/services/https:proxy-service-6n2pt:tlsportname2/proxy/: tls qux (200; 30.936097ms)
Dec 28 05:09:00.260: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-g2zbb/services/proxy-service-6n2pt:portname2/proxy/: bar (200; 31.427826ms)
Dec 28 05:09:00.276: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-g2zbb/pods/proxy-service-6n2pt-rsczg:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-g2zbb/pods/proxy-service-6n2pt-rsczg:1080/proxy/rewri... (200; 15.43862ms)
Dec 28 05:09:00.276: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-g2zbb/pods/proxy-service-6n2pt-rsczg/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-g2zbb/pods/proxy-service-6n2pt-rsczg/proxy/rewriteme"... (200; 15.880243ms)
Dec 28 05:09:00.285: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-g2zbb/services/proxy-service-6n2pt:portname2/proxy/: bar (200; 23.803237ms)
Dec 28 05:09:00.285: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-g2zbb/pods/proxy-service-6n2pt-rsczg:160/proxy/: foo (200; 23.71692ms)
Dec 28 05:09:00.285: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-g2zbb/pods/https:proxy-service-6n2pt-rsczg:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-g2zbb/pods/https:proxy-service-6n2pt-rsczg:443/proxy/... (200; 23.37114ms)
Dec 28 05:09:00.285: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-g2zbb/pods/http:proxy-service-6n2pt-rsczg:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-g2zbb/pods/http:proxy-service-6n2pt-rsczg:1080/proxy/... (200; 25.00304ms)
Dec 28 05:09:00.285: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-g2zbb/pods/http:proxy-service-6n2pt-rsczg:162/proxy/: bar (200; 23.57392ms)
Dec 28 05:09:00.285: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-g2zbb/services/http:proxy-service-6n2pt:portname1/proxy/: foo (200; 24.443633ms)
Dec 28 05:09:00.285: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-g2zbb/pods/http:proxy-service-6n2pt-rsczg:160/proxy/: foo (200; 24.62685ms)
Dec 28 05:09:00.285: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-g2zbb/pods/proxy-service-6n2pt-rsczg:162/proxy/: bar (200; 24.523887ms)
Dec 28 05:09:00.285: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-g2zbb/services/https:proxy-service-6n2pt:tlsportname2/proxy/: tls qux (200; 25.60928ms)
Dec 28 05:09:00.285: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-g2zbb/pods/https:proxy-service-6n2pt-rsczg:462/proxy/: tls qux (200; 24.943167ms)
Dec 28 05:09:00.285: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-g2zbb/pods/https:proxy-service-6n2pt-rsczg:460/proxy/: tls baz (200; 24.268013ms)
Dec 28 05:09:00.285: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-g2zbb/services/https:proxy-service-6n2pt:tlsportname1/proxy/: tls baz (200; 24.598977ms)
Dec 28 05:09:00.285: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-g2zbb/services/proxy-service-6n2pt:portname1/proxy/: foo (200; 24.06529ms)
Dec 28 05:09:00.286: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-g2zbb/services/http:proxy-service-6n2pt:portname2/proxy/: bar (200; 25.45521ms)
Dec 28 05:09:00.294: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-g2zbb/pods/https:proxy-service-6n2pt-rsczg:462/proxy/: tls qux (200; 8.47116ms)
Dec 28 05:09:00.299: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-g2zbb/pods/https:proxy-service-6n2pt-rsczg:460/proxy/: tls baz (200; 11.579313ms)
Dec 28 05:09:00.300: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-g2zbb/pods/http:proxy-service-6n2pt-rsczg:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-g2zbb/pods/http:proxy-service-6n2pt-rsczg:1080/proxy/... (200; 13.179453ms)
Dec 28 05:09:00.303: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-g2zbb/pods/proxy-service-6n2pt-rsczg:160/proxy/: foo (200; 14.970107ms)
Dec 28 05:09:00.304: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-g2zbb/pods/proxy-service-6n2pt-rsczg/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-g2zbb/pods/proxy-service-6n2pt-rsczg/proxy/rewriteme"... (200; 13.804534ms)
Dec 28 05:09:00.311: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-g2zbb/services/proxy-service-6n2pt:portname2/proxy/: bar (200; 25.17668ms)
Dec 28 05:09:00.312: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-g2zbb/services/proxy-service-6n2pt:portname1/proxy/: foo (200; 24.678964ms)
Dec 28 05:09:00.312: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-g2zbb/pods/proxy-service-6n2pt-rsczg:162/proxy/: bar (200; 23.064653ms)
Dec 28 05:09:00.312: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-g2zbb/pods/https:proxy-service-6n2pt-rsczg:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-g2zbb/pods/https:proxy-service-6n2pt-rsczg:443/proxy/... (200; 20.906543ms)
Dec 28 05:09:00.312: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-g2zbb/pods/http:proxy-service-6n2pt-rsczg:160/proxy/: foo (200; 21.31498ms)
Dec 28 05:09:00.312: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-g2zbb/pods/proxy-service-6n2pt-rsczg:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-g2zbb/pods/proxy-service-6n2pt-rsczg:1080/proxy/rewri... (200; 22.181686ms)
Dec 28 05:09:00.312: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-g2zbb/services/http:proxy-service-6n2pt:portname1/proxy/: foo (200; 22.144003ms)
Dec 28 05:09:00.313: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-g2zbb/pods/http:proxy-service-6n2pt-rsczg:162/proxy/: bar (200; 23.905423ms)
Dec 28 05:09:00.313: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-g2zbb/services/https:proxy-service-6n2pt:tlsportname2/proxy/: tls qux (200; 24.847077ms)
Dec 28 05:09:00.313: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-g2zbb/services/http:proxy-service-6n2pt:portname2/proxy/: bar (200; 23.695854ms)
Dec 28 05:09:00.313: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-g2zbb/services/https:proxy-service-6n2pt:tlsportname1/proxy/: tls baz (200; 26.909996ms)
Dec 28 05:09:00.330: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-g2zbb/pods/http:proxy-service-6n2pt-rsczg:160/proxy/: foo (200; 16.9202ms)
Dec 28 05:09:00.334: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-g2zbb/services/http:proxy-service-6n2pt:portname1/proxy/: foo (200; 18.690823ms)
Dec 28 05:09:00.334: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-g2zbb/pods/proxy-service-6n2pt-rsczg/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-g2zbb/pods/proxy-service-6n2pt-rsczg/proxy/rewriteme"... (200; 19.145294ms)
Dec 28 05:09:00.337: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-g2zbb/pods/http:proxy-service-6n2pt-rsczg:162/proxy/: bar (200; 22.94803ms)
Dec 28 05:09:00.339: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-g2zbb/services/proxy-service-6n2pt:portname2/proxy/: bar (200; 24.91223ms)
Dec 28 05:09:00.341: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-g2zbb/pods/https:proxy-service-6n2pt-rsczg:462/proxy/: tls qux (200; 26.153717ms)
Dec 28 05:09:00.343: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-g2zbb/pods/proxy-service-6n2pt-rsczg:162/proxy/: bar (200; 28.343044ms)
Dec 28 05:09:00.343: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-g2zbb/pods/proxy-service-6n2pt-rsczg:160/proxy/: foo (200; 28.024857ms)
Dec 28 05:09:00.343: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-g2zbb/services/proxy-service-6n2pt:portname1/proxy/: foo (200; 28.805144ms)
Dec 28 05:09:00.343: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-g2zbb/pods/proxy-service-6n2pt-rsczg:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-g2zbb/pods/proxy-service-6n2pt-rsczg:1080/proxy/rewri... (200; 28.468296ms)
Dec 28 05:09:00.343: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-g2zbb/pods/http:proxy-service-6n2pt-rsczg:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-g2zbb/pods/http:proxy-service-6n2pt-rsczg:1080/proxy/... (200; 28.936223ms)
Dec 28 05:09:00.343: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-g2zbb/services/http:proxy-service-6n2pt:portname2/proxy/: bar (200; 28.487654ms)
Dec 28 05:09:00.343: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-g2zbb/pods/https:proxy-service-6n2pt-rsczg:460/proxy/: tls baz (200; 28.886787ms)
Dec 28 05:09:00.344: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-g2zbb/services/https:proxy-service-6n2pt:tlsportname2/proxy/: tls qux (200; 29.10645ms)
Dec 28 05:09:00.344: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-g2zbb/services/https:proxy-service-6n2pt:tlsportname1/proxy/: tls baz (200; 29.721717ms)
Dec 28 05:09:00.346: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-g2zbb/pods/https:proxy-service-6n2pt-rsczg:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-g2zbb/pods/https:proxy-service-6n2pt-rsczg:443/proxy/... (200; 31.088587ms)
Dec 28 05:09:00.358: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-g2zbb/pods/http:proxy-service-6n2pt-rsczg:160/proxy/: foo (200; 12.720143ms)
Dec 28 05:09:00.359: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-g2zbb/pods/http:proxy-service-6n2pt-rsczg:162/proxy/: bar (200; 11.67303ms)
Dec 28 05:09:00.360: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-g2zbb/pods/http:proxy-service-6n2pt-rsczg:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-g2zbb/pods/http:proxy-service-6n2pt-rsczg:1080/proxy/... (200; 13.37651ms)
Dec 28 05:09:00.363: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-g2zbb/services/https:proxy-service-6n2pt:tlsportname1/proxy/: tls baz (200; 16.343814ms)
Dec 28 05:09:00.364: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-g2zbb/pods/proxy-service-6n2pt-rsczg:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-g2zbb/pods/proxy-service-6n2pt-rsczg:1080/proxy/rewri... (200; 14.263516ms)
Dec 28 05:09:00.364: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-g2zbb/pods/https:proxy-service-6n2pt-rsczg:460/proxy/: tls baz (200; 15.32376ms)
Dec 28 05:09:00.365: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-g2zbb/pods/proxy-service-6n2pt-rsczg:160/proxy/: foo (200; 14.666524ms)
Dec 28 05:09:00.365: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-g2zbb/pods/https:proxy-service-6n2pt-rsczg:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-g2zbb/pods/https:proxy-service-6n2pt-rsczg:443/proxy/... (200; 16.739427ms)
Dec 28 05:09:00.365: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-g2zbb/pods/proxy-service-6n2pt-rsczg/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-g2zbb/pods/proxy-service-6n2pt-rsczg/proxy/rewriteme"... (200; 15.02175ms)
Dec 28 05:09:00.365: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-g2zbb/services/proxy-service-6n2pt:portname2/proxy/: bar (200; 18.748514ms)
Dec 28 05:09:00.371: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-g2zbb/pods/proxy-service-6n2pt-rsczg:162/proxy/: bar (200; 23.52189ms)
Dec 28 05:09:00.371: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-g2zbb/services/proxy-service-6n2pt:portname1/proxy/: foo (200; 22.202053ms)
Dec 28 05:09:00.371: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-g2zbb/services/http:proxy-service-6n2pt:portname2/proxy/: bar (200; 20.995673ms)
Dec 28 05:09:00.371: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-g2zbb/services/http:proxy-service-6n2pt:portname1/proxy/: foo (200; 21.506057ms)
Dec 28 05:09:00.371: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-g2zbb/pods/https:proxy-service-6n2pt-rsczg:462/proxy/: tls qux (200; 21.721957ms)
Dec 28 05:09:00.371: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-g2zbb/services/https:proxy-service-6n2pt:tlsportname2/proxy/: tls qux (200; 22.114044ms)
Dec 28 05:09:00.379: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-g2zbb/pods/proxy-service-6n2pt-rsczg:162/proxy/: bar (200; 7.453743ms)
Dec 28 05:09:00.386: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-g2zbb/pods/proxy-service-6n2pt-rsczg/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-g2zbb/pods/proxy-service-6n2pt-rsczg/proxy/rewriteme"... (200; 13.792393ms)
Dec 28 05:09:00.387: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-g2zbb/pods/proxy-service-6n2pt-rsczg:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-g2zbb/pods/proxy-service-6n2pt-rsczg:1080/proxy/rewri... (200; 14.693747ms)
Dec 28 05:09:00.388: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-g2zbb/pods/http:proxy-service-6n2pt-rsczg:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-g2zbb/pods/http:proxy-service-6n2pt-rsczg:1080/proxy/... (200; 14.24065ms)
Dec 28 05:09:00.389: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-g2zbb/pods/https:proxy-service-6n2pt-rsczg:462/proxy/: tls qux (200; 15.475686ms)
Dec 28 05:09:00.392: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-g2zbb/pods/http:proxy-service-6n2pt-rsczg:160/proxy/: foo (200; 19.001903ms)
Dec 28 05:09:00.392: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-g2zbb/pods/http:proxy-service-6n2pt-rsczg:162/proxy/: bar (200; 17.600877ms)
Dec 28 05:09:00.392: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-g2zbb/pods/proxy-service-6n2pt-rsczg:160/proxy/: foo (200; 15.861717ms)
Dec 28 05:09:00.392: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-g2zbb/pods/https:proxy-service-6n2pt-rsczg:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-g2zbb/pods/https:proxy-service-6n2pt-rsczg:443/proxy/... (200; 17.337217ms)
Dec 28 05:09:00.392: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-g2zbb/pods/https:proxy-service-6n2pt-rsczg:460/proxy/: tls baz (200; 17.018893ms)
Dec 28 05:09:00.396: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-g2zbb/services/proxy-service-6n2pt:portname2/proxy/: bar (200; 22.181556ms)
Dec 28 05:09:00.396: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-g2zbb/services/http:proxy-service-6n2pt:portname2/proxy/: bar (200; 24.221527ms)
Dec 28 05:09:00.396: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-g2zbb/services/proxy-service-6n2pt:portname1/proxy/: foo (200; 20.25923ms)
Dec 28 05:09:00.396: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-g2zbb/services/https:proxy-service-6n2pt:tlsportname2/proxy/: tls qux (200; 20.28807ms)
Dec 28 05:09:00.396: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-g2zbb/services/https:proxy-service-6n2pt:tlsportname1/proxy/: tls baz (200; 22.445803ms)
Dec 28 05:09:00.400: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-g2zbb/services/http:proxy-service-6n2pt:portname1/proxy/: foo (200; 27.381206ms)
Dec 28 05:09:00.407: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-g2zbb/pods/proxy-service-6n2pt-rsczg:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-g2zbb/pods/proxy-service-6n2pt-rsczg:1080/proxy/rewri... (200; 6.827477ms)
Dec 28 05:09:00.419: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-g2zbb/pods/proxy-service-6n2pt-rsczg:160/proxy/: foo (200; 17.904827ms)
Dec 28 05:09:00.420: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-g2zbb/pods/http:proxy-service-6n2pt-rsczg:160/proxy/: foo (200; 19.325927ms)
Dec 28 05:09:00.420: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-g2zbb/pods/https:proxy-service-6n2pt-rsczg:462/proxy/: tls qux (200; 19.139327ms)
Dec 28 05:09:00.420: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-g2zbb/pods/https:proxy-service-6n2pt-rsczg:460/proxy/: tls baz (200; 18.143463ms)
Dec 28 05:09:00.420: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-g2zbb/pods/http:proxy-service-6n2pt-rsczg:162/proxy/: bar (200; 18.13873ms)
Dec 28 05:09:00.420: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-g2zbb/pods/proxy-service-6n2pt-rsczg/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-g2zbb/pods/proxy-service-6n2pt-rsczg/proxy/rewriteme"... (200; 18.620633ms)
Dec 28 05:09:00.420: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-g2zbb/pods/proxy-service-6n2pt-rsczg:162/proxy/: bar (200; 18.77486ms)
Dec 28 05:09:00.420: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-g2zbb/pods/https:proxy-service-6n2pt-rsczg:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-g2zbb/pods/https:proxy-service-6n2pt-rsczg:443/proxy/... (200; 18.233537ms)
Dec 28 05:09:00.420: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-g2zbb/pods/http:proxy-service-6n2pt-rsczg:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-g2zbb/pods/http:proxy-service-6n2pt-rsczg:1080/proxy/... (200; 18.676393ms)
Dec 28 05:09:00.424: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-g2zbb/services/http:proxy-service-6n2pt:portname1/proxy/: foo (200; 23.556813ms)
Dec 28 05:09:00.425: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-g2zbb/services/https:proxy-service-6n2pt:tlsportname2/proxy/: tls qux (200; 23.157523ms)
Dec 28 05:09:00.426: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-g2zbb/services/proxy-service-6n2pt:portname1/proxy/: foo (200; 24.021584ms)
Dec 28 05:09:00.426: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-g2zbb/services/http:proxy-service-6n2pt:portname2/proxy/: bar (200; 23.9939ms)
Dec 28 05:09:00.426: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-g2zbb/services/https:proxy-service-6n2pt:tlsportname1/proxy/: tls baz (200; 24.52979ms)
Dec 28 05:09:00.426: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-g2zbb/services/proxy-service-6n2pt:portname2/proxy/: bar (200; 24.76591ms)
Dec 28 05:09:00.443: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-g2zbb/pods/proxy-service-6n2pt-rsczg:162/proxy/: bar (200; 16.506177ms)
Dec 28 05:09:00.443: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-g2zbb/pods/http:proxy-service-6n2pt-rsczg:162/proxy/: bar (200; 16.56158ms)
Dec 28 05:09:00.443: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-g2zbb/pods/https:proxy-service-6n2pt-rsczg:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-g2zbb/pods/https:proxy-service-6n2pt-rsczg:443/proxy/... (200; 17.033643ms)
Dec 28 05:09:00.444: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-g2zbb/services/http:proxy-service-6n2pt:portname1/proxy/: foo (200; 17.811814ms)
Dec 28 05:09:00.450: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-g2zbb/services/proxy-service-6n2pt:portname2/proxy/: bar (200; 23.22375ms)
Dec 28 05:09:00.450: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-g2zbb/pods/https:proxy-service-6n2pt-rsczg:460/proxy/: tls baz (200; 22.82058ms)
Dec 28 05:09:00.450: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-g2zbb/services/http:proxy-service-6n2pt:portname2/proxy/: bar (200; 23.019703ms)
Dec 28 05:09:00.450: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-g2zbb/pods/https:proxy-service-6n2pt-rsczg:462/proxy/: tls qux (200; 22.681487ms)
Dec 28 05:09:00.450: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-g2zbb/pods/proxy-service-6n2pt-rsczg/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-g2zbb/pods/proxy-service-6n2pt-rsczg/proxy/rewriteme"... (200; 22.81517ms)
Dec 28 05:09:00.450: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-g2zbb/pods/proxy-service-6n2pt-rsczg:160/proxy/: foo (200; 23.504963ms)
Dec 28 05:09:00.450: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-g2zbb/services/proxy-service-6n2pt:portname1/proxy/: foo (200; 23.159176ms)
Dec 28 05:09:00.450: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-g2zbb/services/https:proxy-service-6n2pt:tlsportname2/proxy/: tls qux (200; 23.704824ms)
Dec 28 05:09:00.450: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-g2zbb/services/https:proxy-service-6n2pt:tlsportname1/proxy/: tls baz (200; 23.90058ms)
Dec 28 05:09:00.450: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-g2zbb/pods/http:proxy-service-6n2pt-rsczg:160/proxy/: foo (200; 23.13717ms)
Dec 28 05:09:00.451: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-g2zbb/pods/http:proxy-service-6n2pt-rsczg:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-g2zbb/pods/http:proxy-service-6n2pt-rsczg:1080/proxy/... (200; 23.93488ms)
Dec 28 05:09:00.451: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-g2zbb/pods/proxy-service-6n2pt-rsczg:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-g2zbb/pods/proxy-service-6n2pt-rsczg:1080/proxy/rewri... (200; 23.271004ms)
Dec 28 05:09:00.465: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-g2zbb/pods/https:proxy-service-6n2pt-rsczg:462/proxy/: tls qux (200; 14.507843ms)
Dec 28 05:09:00.471: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-g2zbb/pods/proxy-service-6n2pt-rsczg:160/proxy/: foo (200; 20.54788ms)
Dec 28 05:09:00.471: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-g2zbb/pods/https:proxy-service-6n2pt-rsczg:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-g2zbb/pods/https:proxy-service-6n2pt-rsczg:443/proxy/... (200; 20.309324ms)
Dec 28 05:09:00.478: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-g2zbb/services/https:proxy-service-6n2pt:tlsportname2/proxy/: tls qux (200; 26.49349ms)
Dec 28 05:09:00.478: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-g2zbb/services/proxy-service-6n2pt:portname2/proxy/: bar (200; 27.06718ms)
Dec 28 05:09:00.478: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-g2zbb/pods/proxy-service-6n2pt-rsczg/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-g2zbb/pods/proxy-service-6n2pt-rsczg/proxy/rewriteme"... (200; 26.214514ms)
Dec 28 05:09:00.478: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-g2zbb/services/http:proxy-service-6n2pt:portname1/proxy/: foo (200; 26.439723ms)
Dec 28 05:09:00.478: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-g2zbb/services/proxy-service-6n2pt:portname1/proxy/: foo (200; 26.849487ms)
Dec 28 05:09:00.478: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-g2zbb/services/http:proxy-service-6n2pt:portname2/proxy/: bar (200; 26.634733ms)
Dec 28 05:09:00.478: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-g2zbb/pods/http:proxy-service-6n2pt-rsczg:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-g2zbb/pods/http:proxy-service-6n2pt-rsczg:1080/proxy/... (200; 27.275484ms)
Dec 28 05:09:00.478: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-g2zbb/pods/proxy-service-6n2pt-rsczg:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-g2zbb/pods/proxy-service-6n2pt-rsczg:1080/proxy/rewri... (200; 27.06147ms)
Dec 28 05:09:00.479: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-g2zbb/pods/http:proxy-service-6n2pt-rsczg:162/proxy/: bar (200; 26.92548ms)
Dec 28 05:09:00.479: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-g2zbb/pods/http:proxy-service-6n2pt-rsczg:160/proxy/: foo (200; 26.948854ms)
Dec 28 05:09:00.479: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-g2zbb/pods/proxy-service-6n2pt-rsczg:162/proxy/: bar (200; 27.149726ms)
Dec 28 05:09:00.479: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-g2zbb/pods/https:proxy-service-6n2pt-rsczg:460/proxy/: tls baz (200; 27.527114ms)
Dec 28 05:09:00.479: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-g2zbb/services/https:proxy-service-6n2pt:tlsportname1/proxy/: tls baz (200; 27.818016ms)
Dec 28 05:09:00.486: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-g2zbb/pods/https:proxy-service-6n2pt-rsczg:462/proxy/: tls qux (200; 7.3612ms)
Dec 28 05:09:00.499: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-g2zbb/pods/proxy-service-6n2pt-rsczg/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-g2zbb/pods/proxy-service-6n2pt-rsczg/proxy/rewriteme"... (200; 17.619367ms)
Dec 28 05:09:00.500: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-g2zbb/pods/http:proxy-service-6n2pt-rsczg:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-g2zbb/pods/http:proxy-service-6n2pt-rsczg:1080/proxy/... (200; 19.908146ms)
Dec 28 05:09:00.500: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-g2zbb/pods/proxy-service-6n2pt-rsczg:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-g2zbb/pods/proxy-service-6n2pt-rsczg:1080/proxy/rewri... (200; 19.37469ms)
Dec 28 05:09:00.501: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-g2zbb/pods/https:proxy-service-6n2pt-rsczg:460/proxy/: tls baz (200; 19.632703ms)
Dec 28 05:09:00.504: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-g2zbb/pods/http:proxy-service-6n2pt-rsczg:160/proxy/: foo (200; 22.55148ms)
Dec 28 05:09:00.504: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-g2zbb/pods/proxy-service-6n2pt-rsczg:160/proxy/: foo (200; 23.222303ms)
Dec 28 05:09:00.504: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-g2zbb/services/proxy-service-6n2pt:portname2/proxy/: bar (200; 24.40322ms)
Dec 28 05:09:00.506: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-g2zbb/pods/http:proxy-service-6n2pt-rsczg:162/proxy/: bar (200; 24.782157ms)
Dec 28 05:09:00.506: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-g2zbb/services/http:proxy-service-6n2pt:portname1/proxy/: foo (200; 24.47815ms)
Dec 28 05:09:00.507: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-g2zbb/pods/https:proxy-service-6n2pt-rsczg:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-g2zbb/pods/https:proxy-service-6n2pt-rsczg:443/proxy/... (200; 25.83459ms)
Dec 28 05:09:00.509: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-g2zbb/services/https:proxy-service-6n2pt:tlsportname1/proxy/: tls baz (200; 28.90554ms)
Dec 28 05:09:00.509: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-g2zbb/services/http:proxy-service-6n2pt:portname2/proxy/: bar (200; 27.86746ms)
Dec 28 05:09:00.510: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-g2zbb/pods/proxy-service-6n2pt-rsczg:162/proxy/: bar (200; 29.059917ms)
Dec 28 05:09:00.510: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-g2zbb/services/proxy-service-6n2pt:portname1/proxy/: foo (200; 29.387356ms)
Dec 28 05:09:00.510: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-g2zbb/services/https:proxy-service-6n2pt:tlsportname2/proxy/: tls qux (200; 29.316807ms)
Dec 28 05:09:00.522: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-g2zbb/pods/proxy-service-6n2pt-rsczg:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-g2zbb/pods/proxy-service-6n2pt-rsczg:1080/proxy/rewri... (200; 12.333326ms)
Dec 28 05:09:00.523: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-g2zbb/pods/https:proxy-service-6n2pt-rsczg:460/proxy/: tls baz (200; 8.59222ms)
Dec 28 05:09:00.532: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-g2zbb/services/https:proxy-service-6n2pt:tlsportname1/proxy/: tls baz (200; 20.27082ms)
Dec 28 05:09:00.532: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-g2zbb/pods/http:proxy-service-6n2pt-rsczg:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-g2zbb/pods/http:proxy-service-6n2pt-rsczg:1080/proxy/... (200; 20.042657ms)
Dec 28 05:09:00.532: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-g2zbb/pods/proxy-service-6n2pt-rsczg/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-g2zbb/pods/proxy-service-6n2pt-rsczg/proxy/rewriteme"... (200; 21.863247ms)
Dec 28 05:09:00.534: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-g2zbb/pods/https:proxy-service-6n2pt-rsczg:462/proxy/: tls qux (200; 23.203673ms)
Dec 28 05:09:00.538: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-g2zbb/pods/http:proxy-service-6n2pt-rsczg:160/proxy/: foo (200; 27.5019ms)
Dec 28 05:09:00.540: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-g2zbb/pods/proxy-service-6n2pt-rsczg:162/proxy/: bar (200; 25.938486ms)
Dec 28 05:09:00.540: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-g2zbb/pods/proxy-service-6n2pt-rsczg:160/proxy/: foo (200; 26.43066ms)
Dec 28 05:09:00.540: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-g2zbb/services/proxy-service-6n2pt:portname2/proxy/: bar (200; 28.607147ms)
Dec 28 05:09:00.540: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-g2zbb/services/proxy-service-6n2pt:portname1/proxy/: foo (200; 27.758027ms)
Dec 28 05:09:00.540: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-g2zbb/pods/http:proxy-service-6n2pt-rsczg:162/proxy/: bar (200; 25.70626ms)
Dec 28 05:09:00.540: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-g2zbb/pods/https:proxy-service-6n2pt-rsczg:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-g2zbb/pods/https:proxy-service-6n2pt-rsczg:443/proxy/... (200; 25.94241ms)
Dec 28 05:09:00.540: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-g2zbb/services/https:proxy-service-6n2pt:tlsportname2/proxy/: tls qux (200; 27.520967ms)
Dec 28 05:09:00.540: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-g2zbb/services/http:proxy-service-6n2pt:portname2/proxy/: bar (200; 25.755787ms)
Dec 28 05:09:00.540: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-g2zbb/services/http:proxy-service-6n2pt:portname1/proxy/: foo (200; 30.118917ms)
Dec 28 05:09:00.554: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-g2zbb/pods/https:proxy-service-6n2pt-rsczg:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-g2zbb/pods/https:proxy-service-6n2pt-rsczg:443/proxy/... (200; 11.69274ms)
Dec 28 05:09:00.554: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-g2zbb/pods/https:proxy-service-6n2pt-rsczg:460/proxy/: tls baz (200; 10.207144ms)
Dec 28 05:09:00.559: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-g2zbb/pods/https:proxy-service-6n2pt-rsczg:462/proxy/: tls qux (200; 13.134837ms)
Dec 28 05:09:00.559: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-g2zbb/pods/proxy-service-6n2pt-rsczg:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-g2zbb/pods/proxy-service-6n2pt-rsczg:1080/proxy/rewri... (200; 13.510127ms)
Dec 28 05:09:00.560: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-g2zbb/pods/http:proxy-service-6n2pt-rsczg:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-g2zbb/pods/http:proxy-service-6n2pt-rsczg:1080/proxy/... (200; 14.198234ms)
Dec 28 05:09:00.563: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-g2zbb/pods/http:proxy-service-6n2pt-rsczg:162/proxy/: bar (200; 21.569277ms)
Dec 28 05:09:00.563: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-g2zbb/pods/proxy-service-6n2pt-rsczg/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-g2zbb/pods/proxy-service-6n2pt-rsczg/proxy/rewriteme"... (200; 17.67697ms)
Dec 28 05:09:00.563: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-g2zbb/pods/http:proxy-service-6n2pt-rsczg:160/proxy/: foo (200; 18.043457ms)
Dec 28 05:09:00.573: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-g2zbb/services/https:proxy-service-6n2pt:tlsportname1/proxy/: tls baz (200; 32.361697ms)
Dec 28 05:09:00.573: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-g2zbb/pods/proxy-service-6n2pt-rsczg:160/proxy/: foo (200; 32.171904ms)
Dec 28 05:09:00.573: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-g2zbb/pods/proxy-service-6n2pt-rsczg:162/proxy/: bar (200; 31.917394ms)
Dec 28 05:09:00.573: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-g2zbb/services/proxy-service-6n2pt:portname2/proxy/: bar (200; 27.581174ms)
Dec 28 05:09:00.573: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-g2zbb/services/proxy-service-6n2pt:portname1/proxy/: foo (200; 29.173273ms)
Dec 28 05:09:00.573: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-g2zbb/services/https:proxy-service-6n2pt:tlsportname2/proxy/: tls qux (200; 28.85151ms)
Dec 28 05:09:00.573: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-g2zbb/services/http:proxy-service-6n2pt:portname1/proxy/: foo (200; 27.71147ms)
Dec 28 05:09:00.573: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-g2zbb/services/http:proxy-service-6n2pt:portname2/proxy/: bar (200; 28.736563ms)
STEP: deleting { ReplicationController} proxy-service-6n2pt in namespace e2e-tests-proxy-g2zbb, will wait for the garbage collector to delete the pods
Dec 28 05:09:00.643: INFO: Deleting { ReplicationController} proxy-service-6n2pt took: 14.035257ms
Dec 28 05:09:00.750: INFO: Terminating { ReplicationController} proxy-service-6n2pt pods took: 106.982506ms
[AfterEach] version v1
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 28 05:09:03.950: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-proxy-g2zbb" for this suite.
Dec 28 05:09:12.015: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 05:09:12.156: INFO: namespace: e2e-tests-proxy-g2zbb, resource: bindings, ignored listing per whitelist
Dec 28 05:09:12.245: INFO: namespace e2e-tests-proxy-g2zbb deletion completed in 8.284885263s

• [SLOW TEST:24.007 seconds]
[sig-network] Proxy
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy through a service and a pod  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 28 05:09:12.246: INFO: >>> kubeConfig: /tmp/kubeconfig-994138694
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-b700d800-0a5e-11e9-8a07-628dff7095f4
STEP: Creating a pod to test consume configMaps
Dec 28 05:09:12.548: INFO: Waiting up to 5m0s for pod "pod-configmaps-b70209cf-0a5e-11e9-8a07-628dff7095f4" in namespace "e2e-tests-configmap-ghz56" to be "success or failure"
Dec 28 05:09:12.560: INFO: Pod "pod-configmaps-b70209cf-0a5e-11e9-8a07-628dff7095f4": Phase="Pending", Reason="", readiness=false. Elapsed: 11.906093ms
Dec 28 05:09:14.567: INFO: Pod "pod-configmaps-b70209cf-0a5e-11e9-8a07-628dff7095f4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.018801436s
Dec 28 05:09:16.574: INFO: Pod "pod-configmaps-b70209cf-0a5e-11e9-8a07-628dff7095f4": Phase="Pending", Reason="", readiness=false. Elapsed: 4.02538739s
Dec 28 05:09:18.583: INFO: Pod "pod-configmaps-b70209cf-0a5e-11e9-8a07-628dff7095f4": Phase="Pending", Reason="", readiness=false. Elapsed: 6.034877916s
Dec 28 05:09:20.591: INFO: Pod "pod-configmaps-b70209cf-0a5e-11e9-8a07-628dff7095f4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.042527996s
STEP: Saw pod success
Dec 28 05:09:20.591: INFO: Pod "pod-configmaps-b70209cf-0a5e-11e9-8a07-628dff7095f4" satisfied condition "success or failure"
Dec 28 05:09:20.596: INFO: Trying to get logs from node 10.10.102.69-build pod pod-configmaps-b70209cf-0a5e-11e9-8a07-628dff7095f4 container configmap-volume-test: <nil>
STEP: delete the pod
Dec 28 05:09:20.692: INFO: Waiting for pod pod-configmaps-b70209cf-0a5e-11e9-8a07-628dff7095f4 to disappear
Dec 28 05:09:20.709: INFO: Pod pod-configmaps-b70209cf-0a5e-11e9-8a07-628dff7095f4 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 28 05:09:20.709: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-ghz56" for this suite.
Dec 28 05:09:26.768: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 05:09:26.836: INFO: namespace: e2e-tests-configmap-ghz56, resource: bindings, ignored listing per whitelist
Dec 28 05:09:26.976: INFO: namespace e2e-tests-configmap-ghz56 deletion completed in 6.237422854s

• [SLOW TEST:14.730 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 28 05:09:26.976: INFO: >>> kubeConfig: /tmp/kubeconfig-994138694
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-map-bfc84b4d-0a5e-11e9-8a07-628dff7095f4
STEP: Creating a pod to test consume secrets
Dec 28 05:09:27.293: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-bfc9dbd9-0a5e-11e9-8a07-628dff7095f4" in namespace "e2e-tests-projected-hs5ww" to be "success or failure"
Dec 28 05:09:27.308: INFO: Pod "pod-projected-secrets-bfc9dbd9-0a5e-11e9-8a07-628dff7095f4": Phase="Pending", Reason="", readiness=false. Elapsed: 14.71612ms
Dec 28 05:09:29.351: INFO: Pod "pod-projected-secrets-bfc9dbd9-0a5e-11e9-8a07-628dff7095f4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.05700107s
Dec 28 05:09:31.358: INFO: Pod "pod-projected-secrets-bfc9dbd9-0a5e-11e9-8a07-628dff7095f4": Phase="Pending", Reason="", readiness=false. Elapsed: 4.06433842s
Dec 28 05:09:33.366: INFO: Pod "pod-projected-secrets-bfc9dbd9-0a5e-11e9-8a07-628dff7095f4": Phase="Pending", Reason="", readiness=false. Elapsed: 6.072856903s
Dec 28 05:09:35.426: INFO: Pod "pod-projected-secrets-bfc9dbd9-0a5e-11e9-8a07-628dff7095f4": Phase="Running", Reason="", readiness=true. Elapsed: 8.132446016s
Dec 28 05:09:37.434: INFO: Pod "pod-projected-secrets-bfc9dbd9-0a5e-11e9-8a07-628dff7095f4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 10.14035857s
STEP: Saw pod success
Dec 28 05:09:37.434: INFO: Pod "pod-projected-secrets-bfc9dbd9-0a5e-11e9-8a07-628dff7095f4" satisfied condition "success or failure"
Dec 28 05:09:37.439: INFO: Trying to get logs from node 10.10.102.68-share pod pod-projected-secrets-bfc9dbd9-0a5e-11e9-8a07-628dff7095f4 container projected-secret-volume-test: <nil>
STEP: delete the pod
Dec 28 05:09:37.676: INFO: Waiting for pod pod-projected-secrets-bfc9dbd9-0a5e-11e9-8a07-628dff7095f4 to disappear
Dec 28 05:09:37.681: INFO: Pod pod-projected-secrets-bfc9dbd9-0a5e-11e9-8a07-628dff7095f4 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 28 05:09:37.682: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-hs5ww" for this suite.
Dec 28 05:09:43.776: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 05:09:43.986: INFO: namespace: e2e-tests-projected-hs5ww, resource: bindings, ignored listing per whitelist
Dec 28 05:09:44.036: INFO: namespace e2e-tests-projected-hs5ww deletion completed in 6.32442956s

• [SLOW TEST:17.059 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 28 05:09:44.036: INFO: >>> kubeConfig: /tmp/kubeconfig-994138694
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a watch on configmaps with label A
STEP: creating a watch on configmaps with label B
STEP: creating a watch on configmaps with label A or B
STEP: creating a configmap with label A and ensuring the correct watchers observe the notification
Dec 28 05:09:44.411: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-29t8t,SelfLink:/api/v1/namespaces/e2e-tests-watch-29t8t/configmaps/e2e-watch-test-configmap-a,UID:ca05d083-0a5e-11e9-a0ee-005056bc4922,ResourceVersion:527138,Generation:0,CreationTimestamp:2018-12-28 05:09:44 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Dec 28 05:09:44.411: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-29t8t,SelfLink:/api/v1/namespaces/e2e-tests-watch-29t8t/configmaps/e2e-watch-test-configmap-a,UID:ca05d083-0a5e-11e9-a0ee-005056bc4922,ResourceVersion:527138,Generation:0,CreationTimestamp:2018-12-28 05:09:44 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: modifying configmap A and ensuring the correct watchers observe the notification
Dec 28 05:09:54.424: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-29t8t,SelfLink:/api/v1/namespaces/e2e-tests-watch-29t8t/configmaps/e2e-watch-test-configmap-a,UID:ca05d083-0a5e-11e9-a0ee-005056bc4922,ResourceVersion:527157,Generation:0,CreationTimestamp:2018-12-28 05:09:44 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Dec 28 05:09:54.424: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-29t8t,SelfLink:/api/v1/namespaces/e2e-tests-watch-29t8t/configmaps/e2e-watch-test-configmap-a,UID:ca05d083-0a5e-11e9-a0ee-005056bc4922,ResourceVersion:527157,Generation:0,CreationTimestamp:2018-12-28 05:09:44 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying configmap A again and ensuring the correct watchers observe the notification
Dec 28 05:10:04.438: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-29t8t,SelfLink:/api/v1/namespaces/e2e-tests-watch-29t8t/configmaps/e2e-watch-test-configmap-a,UID:ca05d083-0a5e-11e9-a0ee-005056bc4922,ResourceVersion:527175,Generation:0,CreationTimestamp:2018-12-28 05:09:44 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Dec 28 05:10:04.438: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-29t8t,SelfLink:/api/v1/namespaces/e2e-tests-watch-29t8t/configmaps/e2e-watch-test-configmap-a,UID:ca05d083-0a5e-11e9-a0ee-005056bc4922,ResourceVersion:527175,Generation:0,CreationTimestamp:2018-12-28 05:09:44 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: deleting configmap A and ensuring the correct watchers observe the notification
Dec 28 05:10:14.449: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-29t8t,SelfLink:/api/v1/namespaces/e2e-tests-watch-29t8t/configmaps/e2e-watch-test-configmap-a,UID:ca05d083-0a5e-11e9-a0ee-005056bc4922,ResourceVersion:527193,Generation:0,CreationTimestamp:2018-12-28 05:09:44 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Dec 28 05:10:14.450: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-29t8t,SelfLink:/api/v1/namespaces/e2e-tests-watch-29t8t/configmaps/e2e-watch-test-configmap-a,UID:ca05d083-0a5e-11e9-a0ee-005056bc4922,ResourceVersion:527193,Generation:0,CreationTimestamp:2018-12-28 05:09:44 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: creating a configmap with label B and ensuring the correct watchers observe the notification
Dec 28 05:10:24.466: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-29t8t,SelfLink:/api/v1/namespaces/e2e-tests-watch-29t8t/configmaps/e2e-watch-test-configmap-b,UID:e1f67052-0a5e-11e9-a0ee-005056bc4922,ResourceVersion:527212,Generation:0,CreationTimestamp:2018-12-28 05:10:24 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Dec 28 05:10:24.466: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-29t8t,SelfLink:/api/v1/namespaces/e2e-tests-watch-29t8t/configmaps/e2e-watch-test-configmap-b,UID:e1f67052-0a5e-11e9-a0ee-005056bc4922,ResourceVersion:527212,Generation:0,CreationTimestamp:2018-12-28 05:10:24 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: deleting configmap B and ensuring the correct watchers observe the notification
Dec 28 05:10:34.479: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-29t8t,SelfLink:/api/v1/namespaces/e2e-tests-watch-29t8t/configmaps/e2e-watch-test-configmap-b,UID:e1f67052-0a5e-11e9-a0ee-005056bc4922,ResourceVersion:527230,Generation:0,CreationTimestamp:2018-12-28 05:10:24 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Dec 28 05:10:34.479: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-29t8t,SelfLink:/api/v1/namespaces/e2e-tests-watch-29t8t/configmaps/e2e-watch-test-configmap-b,UID:e1f67052-0a5e-11e9-a0ee-005056bc4922,ResourceVersion:527230,Generation:0,CreationTimestamp:2018-12-28 05:10:24 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 28 05:10:44.480: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-29t8t" for this suite.
Dec 28 05:10:50.574: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 05:10:50.593: INFO: namespace: e2e-tests-watch-29t8t, resource: bindings, ignored listing per whitelist
Dec 28 05:10:50.927: INFO: namespace e2e-tests-watch-29t8t deletion completed in 6.43529899s

• [SLOW TEST:66.891 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Projected 
  should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 28 05:10:50.928: INFO: >>> kubeConfig: /tmp/kubeconfig-994138694
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Dec 28 05:10:51.152: INFO: Waiting up to 5m0s for pod "downwardapi-volume-f1cbacb6-0a5e-11e9-8a07-628dff7095f4" in namespace "e2e-tests-projected-w2gnz" to be "success or failure"
Dec 28 05:10:51.177: INFO: Pod "downwardapi-volume-f1cbacb6-0a5e-11e9-8a07-628dff7095f4": Phase="Pending", Reason="", readiness=false. Elapsed: 24.416877ms
Dec 28 05:10:53.185: INFO: Pod "downwardapi-volume-f1cbacb6-0a5e-11e9-8a07-628dff7095f4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.032549623s
Dec 28 05:10:55.192: INFO: Pod "downwardapi-volume-f1cbacb6-0a5e-11e9-8a07-628dff7095f4": Phase="Pending", Reason="", readiness=false. Elapsed: 4.039460567s
Dec 28 05:10:57.198: INFO: Pod "downwardapi-volume-f1cbacb6-0a5e-11e9-8a07-628dff7095f4": Phase="Pending", Reason="", readiness=false. Elapsed: 6.046270607s
Dec 28 05:10:59.226: INFO: Pod "downwardapi-volume-f1cbacb6-0a5e-11e9-8a07-628dff7095f4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.074001077s
STEP: Saw pod success
Dec 28 05:10:59.226: INFO: Pod "downwardapi-volume-f1cbacb6-0a5e-11e9-8a07-628dff7095f4" satisfied condition "success or failure"
Dec 28 05:10:59.232: INFO: Trying to get logs from node 10.10.102.69-build pod downwardapi-volume-f1cbacb6-0a5e-11e9-8a07-628dff7095f4 container client-container: <nil>
STEP: delete the pod
Dec 28 05:10:59.285: INFO: Waiting for pod downwardapi-volume-f1cbacb6-0a5e-11e9-8a07-628dff7095f4 to disappear
Dec 28 05:10:59.297: INFO: Pod downwardapi-volume-f1cbacb6-0a5e-11e9-8a07-628dff7095f4 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 28 05:10:59.298: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-w2gnz" for this suite.
Dec 28 05:11:05.386: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 05:11:05.465: INFO: namespace: e2e-tests-projected-w2gnz, resource: bindings, ignored listing per whitelist
Dec 28 05:11:05.654: INFO: namespace e2e-tests-projected-w2gnz deletion completed in 6.347284837s

• [SLOW TEST:14.727 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 28 05:11:05.654: INFO: >>> kubeConfig: /tmp/kubeconfig-994138694
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-m6nkr
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Dec 28 05:11:05.926: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Dec 28 05:11:46.290: INFO: ExecWithOptions {Command:[/bin/sh -c echo 'hostName' | timeout -t 2 nc -w 1 -u 10.168.66.197 8081 | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-m6nkr PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 28 05:11:46.290: INFO: >>> kubeConfig: /tmp/kubeconfig-994138694
Dec 28 05:11:47.601: INFO: Found all expected endpoints: [netserver-0]
Dec 28 05:11:47.607: INFO: ExecWithOptions {Command:[/bin/sh -c echo 'hostName' | timeout -t 2 nc -w 1 -u 10.168.192.15 8081 | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-m6nkr PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 28 05:11:47.607: INFO: >>> kubeConfig: /tmp/kubeconfig-994138694
Dec 28 05:11:48.778: INFO: Found all expected endpoints: [netserver-1]
Dec 28 05:11:48.887: INFO: ExecWithOptions {Command:[/bin/sh -c echo 'hostName' | timeout -t 2 nc -w 1 -u 10.168.194.145 8081 | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-m6nkr PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 28 05:11:48.887: INFO: >>> kubeConfig: /tmp/kubeconfig-994138694
Dec 28 05:11:50.038: INFO: Found all expected endpoints: [netserver-2]
Dec 28 05:11:50.045: INFO: ExecWithOptions {Command:[/bin/sh -c echo 'hostName' | timeout -t 2 nc -w 1 -u 10.168.176.62 8081 | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-m6nkr PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 28 05:11:50.045: INFO: >>> kubeConfig: /tmp/kubeconfig-994138694
Dec 28 05:11:51.194: INFO: Found all expected endpoints: [netserver-3]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 28 05:11:51.194: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-m6nkr" for this suite.
Dec 28 05:12:15.241: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 05:12:15.291: INFO: namespace: e2e-tests-pod-network-test-m6nkr, resource: bindings, ignored listing per whitelist
Dec 28 05:12:15.441: INFO: namespace e2e-tests-pod-network-test-m6nkr deletion completed in 24.23061007s

• [SLOW TEST:69.786 seconds]
[sig-network] Networking
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: udp [NodeConformance] [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] Projected 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 28 05:12:15.441: INFO: >>> kubeConfig: /tmp/kubeconfig-994138694
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Dec 28 05:12:15.684: INFO: Waiting up to 5m0s for pod "downwardapi-volume-242ac296-0a5f-11e9-8a07-628dff7095f4" in namespace "e2e-tests-projected-w5jsb" to be "success or failure"
Dec 28 05:12:15.700: INFO: Pod "downwardapi-volume-242ac296-0a5f-11e9-8a07-628dff7095f4": Phase="Pending", Reason="", readiness=false. Elapsed: 15.970024ms
Dec 28 05:12:17.707: INFO: Pod "downwardapi-volume-242ac296-0a5f-11e9-8a07-628dff7095f4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.022911544s
Dec 28 05:12:19.714: INFO: Pod "downwardapi-volume-242ac296-0a5f-11e9-8a07-628dff7095f4": Phase="Pending", Reason="", readiness=false. Elapsed: 4.030099927s
Dec 28 05:12:21.721: INFO: Pod "downwardapi-volume-242ac296-0a5f-11e9-8a07-628dff7095f4": Phase="Pending", Reason="", readiness=false. Elapsed: 6.037500617s
Dec 28 05:12:23.729: INFO: Pod "downwardapi-volume-242ac296-0a5f-11e9-8a07-628dff7095f4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.044994167s
STEP: Saw pod success
Dec 28 05:12:23.729: INFO: Pod "downwardapi-volume-242ac296-0a5f-11e9-8a07-628dff7095f4" satisfied condition "success or failure"
Dec 28 05:12:23.734: INFO: Trying to get logs from node 10.10.102.69-build pod downwardapi-volume-242ac296-0a5f-11e9-8a07-628dff7095f4 container client-container: <nil>
STEP: delete the pod
Dec 28 05:12:23.831: INFO: Waiting for pod downwardapi-volume-242ac296-0a5f-11e9-8a07-628dff7095f4 to disappear
Dec 28 05:12:23.838: INFO: Pod downwardapi-volume-242ac296-0a5f-11e9-8a07-628dff7095f4 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 28 05:12:23.838: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-w5jsb" for this suite.
Dec 28 05:12:29.879: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 05:12:30.025: INFO: namespace: e2e-tests-projected-w5jsb, resource: bindings, ignored listing per whitelist
Dec 28 05:12:30.075: INFO: namespace e2e-tests-projected-w5jsb deletion completed in 6.21889324s

• [SLOW TEST:14.634 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 28 05:12:30.075: INFO: >>> kubeConfig: /tmp/kubeconfig-994138694
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-6xzfw
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Dec 28 05:12:30.330: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Dec 28 05:13:12.726: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.168.192.19:8080/dial?request=hostName&protocol=udp&host=10.168.192.18&port=8081&tries=1'] Namespace:e2e-tests-pod-network-test-6xzfw PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 28 05:13:12.726: INFO: >>> kubeConfig: /tmp/kubeconfig-994138694
Dec 28 05:13:13.088: INFO: Waiting for endpoints: map[]
Dec 28 05:13:13.110: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.168.192.19:8080/dial?request=hostName&protocol=udp&host=10.168.194.146&port=8081&tries=1'] Namespace:e2e-tests-pod-network-test-6xzfw PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 28 05:13:13.111: INFO: >>> kubeConfig: /tmp/kubeconfig-994138694
Dec 28 05:13:13.306: INFO: Waiting for endpoints: map[]
Dec 28 05:13:13.312: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.168.192.19:8080/dial?request=hostName&protocol=udp&host=10.168.66.201&port=8081&tries=1'] Namespace:e2e-tests-pod-network-test-6xzfw PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 28 05:13:13.312: INFO: >>> kubeConfig: /tmp/kubeconfig-994138694
Dec 28 05:13:13.498: INFO: Waiting for endpoints: map[]
Dec 28 05:13:13.505: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.168.192.19:8080/dial?request=hostName&protocol=udp&host=10.168.176.63&port=8081&tries=1'] Namespace:e2e-tests-pod-network-test-6xzfw PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 28 05:13:13.505: INFO: >>> kubeConfig: /tmp/kubeconfig-994138694
Dec 28 05:13:13.696: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 28 05:13:13.696: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-6xzfw" for this suite.
Dec 28 05:13:37.840: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 05:13:37.868: INFO: namespace: e2e-tests-pod-network-test-6xzfw, resource: bindings, ignored listing per whitelist
Dec 28 05:13:38.329: INFO: namespace e2e-tests-pod-network-test-6xzfw deletion completed in 24.537161477s

• [SLOW TEST:68.254 seconds]
[sig-network] Networking
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: udp [NodeConformance] [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected 
  should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 28 05:13:38.330: INFO: >>> kubeConfig: /tmp/kubeconfig-994138694
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Dec 28 05:13:38.558: INFO: Waiting up to 5m0s for pod "downwardapi-volume-55946998-0a5f-11e9-8a07-628dff7095f4" in namespace "e2e-tests-projected-jl8gp" to be "success or failure"
Dec 28 05:13:38.580: INFO: Pod "downwardapi-volume-55946998-0a5f-11e9-8a07-628dff7095f4": Phase="Pending", Reason="", readiness=false. Elapsed: 21.885737ms
Dec 28 05:13:40.587: INFO: Pod "downwardapi-volume-55946998-0a5f-11e9-8a07-628dff7095f4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.028894417s
Dec 28 05:13:42.596: INFO: Pod "downwardapi-volume-55946998-0a5f-11e9-8a07-628dff7095f4": Phase="Pending", Reason="", readiness=false. Elapsed: 4.03708708s
Dec 28 05:13:44.603: INFO: Pod "downwardapi-volume-55946998-0a5f-11e9-8a07-628dff7095f4": Phase="Pending", Reason="", readiness=false. Elapsed: 6.043952517s
Dec 28 05:13:46.609: INFO: Pod "downwardapi-volume-55946998-0a5f-11e9-8a07-628dff7095f4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.050008407s
STEP: Saw pod success
Dec 28 05:13:46.609: INFO: Pod "downwardapi-volume-55946998-0a5f-11e9-8a07-628dff7095f4" satisfied condition "success or failure"
Dec 28 05:13:46.614: INFO: Trying to get logs from node 10.10.102.69-build pod downwardapi-volume-55946998-0a5f-11e9-8a07-628dff7095f4 container client-container: <nil>
STEP: delete the pod
Dec 28 05:13:46.702: INFO: Waiting for pod downwardapi-volume-55946998-0a5f-11e9-8a07-628dff7095f4 to disappear
Dec 28 05:13:46.718: INFO: Pod downwardapi-volume-55946998-0a5f-11e9-8a07-628dff7095f4 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 28 05:13:46.718: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-jl8gp" for this suite.
Dec 28 05:13:52.777: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 05:13:52.897: INFO: namespace: e2e-tests-projected-jl8gp, resource: bindings, ignored listing per whitelist
Dec 28 05:13:52.984: INFO: namespace e2e-tests-projected-jl8gp deletion completed in 6.237053933s

• [SLOW TEST:14.655 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on default medium should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 28 05:13:52.985: INFO: >>> kubeConfig: /tmp/kubeconfig-994138694
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on default medium should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir volume type on node default medium
Dec 28 05:13:53.247: INFO: Waiting up to 5m0s for pod "pod-5e543def-0a5f-11e9-8a07-628dff7095f4" in namespace "e2e-tests-emptydir-pkhq9" to be "success or failure"
Dec 28 05:13:53.282: INFO: Pod "pod-5e543def-0a5f-11e9-8a07-628dff7095f4": Phase="Pending", Reason="", readiness=false. Elapsed: 34.406747ms
Dec 28 05:13:55.291: INFO: Pod "pod-5e543def-0a5f-11e9-8a07-628dff7095f4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.043289677s
Dec 28 05:13:57.298: INFO: Pod "pod-5e543def-0a5f-11e9-8a07-628dff7095f4": Phase="Pending", Reason="", readiness=false. Elapsed: 4.050166363s
Dec 28 05:13:59.316: INFO: Pod "pod-5e543def-0a5f-11e9-8a07-628dff7095f4": Phase="Pending", Reason="", readiness=false. Elapsed: 6.068854073s
Dec 28 05:14:01.325: INFO: Pod "pod-5e543def-0a5f-11e9-8a07-628dff7095f4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.07719158s
STEP: Saw pod success
Dec 28 05:14:01.325: INFO: Pod "pod-5e543def-0a5f-11e9-8a07-628dff7095f4" satisfied condition "success or failure"
Dec 28 05:14:01.330: INFO: Trying to get logs from node 10.10.102.68-share pod pod-5e543def-0a5f-11e9-8a07-628dff7095f4 container test-container: <nil>
STEP: delete the pod
Dec 28 05:14:01.447: INFO: Waiting for pod pod-5e543def-0a5f-11e9-8a07-628dff7095f4 to disappear
Dec 28 05:14:01.469: INFO: Pod pod-5e543def-0a5f-11e9-8a07-628dff7095f4 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 28 05:14:01.469: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-pkhq9" for this suite.
Dec 28 05:14:07.514: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 05:14:07.546: INFO: namespace: e2e-tests-emptydir-pkhq9, resource: bindings, ignored listing per whitelist
Dec 28 05:14:07.820: INFO: namespace e2e-tests-emptydir-pkhq9 deletion completed in 6.339797147s

• [SLOW TEST:14.835 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  volume on default medium should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 28 05:14:07.820: INFO: >>> kubeConfig: /tmp/kubeconfig-994138694
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
Dec 28 05:14:08.062: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 28 05:14:19.945: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-init-container-sz428" for this suite.
Dec 28 05:14:25.983: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 05:14:26.013: INFO: namespace: e2e-tests-init-container-sz428, resource: bindings, ignored listing per whitelist
Dec 28 05:14:26.230: INFO: namespace e2e-tests-init-container-sz428 deletion completed in 6.271888503s

• [SLOW TEST:18.410 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 28 05:14:26.230: INFO: >>> kubeConfig: /tmp/kubeconfig-994138694
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-ppr8k
[It] should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a new StaefulSet
Dec 28 05:14:26.497: INFO: Found 0 stateful pods, waiting for 3
Dec 28 05:14:36.505: INFO: Found 2 stateful pods, waiting for 3
Dec 28 05:14:46.510: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Dec 28 05:14:46.510: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Dec 28 05:14:46.510: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Pending - Ready=false
Dec 28 05:14:56.506: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Dec 28 05:14:56.506: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Dec 28 05:14:56.506: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Updating stateful set template: update image from docker.io/library/nginx:1.14-alpine to docker.io/library/nginx:1.15-alpine
Dec 28 05:14:56.547: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Not applying an update when the partition is greater than the number of replicas
STEP: Performing a canary update
Dec 28 05:15:06.614: INFO: Updating stateful set ss2
Dec 28 05:15:06.631: INFO: Waiting for Pod e2e-tests-statefulset-ppr8k/ss2-2 to have revision ss2-c79899b9 update revision ss2-787997d666
STEP: Restoring Pods to the correct revision when they are deleted
Dec 28 05:15:17.369: INFO: Found 2 stateful pods, waiting for 3
Dec 28 05:15:27.378: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Dec 28 05:15:27.378: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Dec 28 05:15:27.378: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Pending - Ready=false
Dec 28 05:15:37.376: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Dec 28 05:15:37.376: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Dec 28 05:15:37.376: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Performing a phased rolling update
Dec 28 05:15:37.410: INFO: Updating stateful set ss2
Dec 28 05:15:37.431: INFO: Waiting for Pod e2e-tests-statefulset-ppr8k/ss2-1 to have revision ss2-c79899b9 update revision ss2-787997d666
Dec 28 05:15:47.446: INFO: Waiting for Pod e2e-tests-statefulset-ppr8k/ss2-1 to have revision ss2-c79899b9 update revision ss2-787997d666
Dec 28 05:15:57.494: INFO: Updating stateful set ss2
Dec 28 05:15:57.513: INFO: Waiting for StatefulSet e2e-tests-statefulset-ppr8k/ss2 to complete update
Dec 28 05:15:57.513: INFO: Waiting for Pod e2e-tests-statefulset-ppr8k/ss2-0 to have revision ss2-c79899b9 update revision ss2-787997d666
Dec 28 05:16:07.528: INFO: Waiting for StatefulSet e2e-tests-statefulset-ppr8k/ss2 to complete update
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Dec 28 05:16:17.526: INFO: Deleting all statefulset in ns e2e-tests-statefulset-ppr8k
Dec 28 05:16:17.531: INFO: Scaling statefulset ss2 to 0
Dec 28 05:16:37.596: INFO: Waiting for statefulset status.replicas updated to 0
Dec 28 05:16:37.602: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 28 05:16:37.640: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-ppr8k" for this suite.
Dec 28 05:16:45.734: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 05:16:45.772: INFO: namespace: e2e-tests-statefulset-ppr8k, resource: bindings, ignored listing per whitelist
Dec 28 05:16:45.937: INFO: namespace e2e-tests-statefulset-ppr8k deletion completed in 8.282359476s

• [SLOW TEST:139.707 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should perform canary updates and phased rolling updates of template modifications [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Projected 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 28 05:16:45.937: INFO: >>> kubeConfig: /tmp/kubeconfig-994138694
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name projected-secret-test-c568990c-0a5f-11e9-8a07-628dff7095f4
STEP: Creating a pod to test consume secrets
Dec 28 05:16:46.185: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-c569a71d-0a5f-11e9-8a07-628dff7095f4" in namespace "e2e-tests-projected-k4rbp" to be "success or failure"
Dec 28 05:16:46.192: INFO: Pod "pod-projected-secrets-c569a71d-0a5f-11e9-8a07-628dff7095f4": Phase="Pending", Reason="", readiness=false. Elapsed: 6.82738ms
Dec 28 05:16:48.199: INFO: Pod "pod-projected-secrets-c569a71d-0a5f-11e9-8a07-628dff7095f4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014646547s
Dec 28 05:16:50.206: INFO: Pod "pod-projected-secrets-c569a71d-0a5f-11e9-8a07-628dff7095f4": Phase="Pending", Reason="", readiness=false. Elapsed: 4.020769437s
Dec 28 05:16:52.216: INFO: Pod "pod-projected-secrets-c569a71d-0a5f-11e9-8a07-628dff7095f4": Phase="Pending", Reason="", readiness=false. Elapsed: 6.030971844s
Dec 28 05:16:54.233: INFO: Pod "pod-projected-secrets-c569a71d-0a5f-11e9-8a07-628dff7095f4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.04772425s
STEP: Saw pod success
Dec 28 05:16:54.233: INFO: Pod "pod-projected-secrets-c569a71d-0a5f-11e9-8a07-628dff7095f4" satisfied condition "success or failure"
Dec 28 05:16:54.246: INFO: Trying to get logs from node 10.10.102.68-share pod pod-projected-secrets-c569a71d-0a5f-11e9-8a07-628dff7095f4 container secret-volume-test: <nil>
STEP: delete the pod
Dec 28 05:16:54.321: INFO: Waiting for pod pod-projected-secrets-c569a71d-0a5f-11e9-8a07-628dff7095f4 to disappear
Dec 28 05:16:54.328: INFO: Pod pod-projected-secrets-c569a71d-0a5f-11e9-8a07-628dff7095f4 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 28 05:16:54.328: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-k4rbp" for this suite.
Dec 28 05:17:00.362: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 05:17:00.428: INFO: namespace: e2e-tests-projected-k4rbp, resource: bindings, ignored listing per whitelist
Dec 28 05:17:00.613: INFO: namespace e2e-tests-projected-k4rbp deletion completed in 6.275531376s

• [SLOW TEST:14.676 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 28 05:17:00.614: INFO: >>> kubeConfig: /tmp/kubeconfig-994138694
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test override all
Dec 28 05:17:00.961: INFO: Waiting up to 5m0s for pod "client-containers-ce37dfd7-0a5f-11e9-8a07-628dff7095f4" in namespace "e2e-tests-containers-k2h8n" to be "success or failure"
Dec 28 05:17:00.972: INFO: Pod "client-containers-ce37dfd7-0a5f-11e9-8a07-628dff7095f4": Phase="Pending", Reason="", readiness=false. Elapsed: 11.793757ms
Dec 28 05:17:02.980: INFO: Pod "client-containers-ce37dfd7-0a5f-11e9-8a07-628dff7095f4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.019287464s
Dec 28 05:17:04.987: INFO: Pod "client-containers-ce37dfd7-0a5f-11e9-8a07-628dff7095f4": Phase="Pending", Reason="", readiness=false. Elapsed: 4.02607845s
Dec 28 05:17:06.995: INFO: Pod "client-containers-ce37dfd7-0a5f-11e9-8a07-628dff7095f4": Phase="Pending", Reason="", readiness=false. Elapsed: 6.033988314s
Dec 28 05:17:09.002: INFO: Pod "client-containers-ce37dfd7-0a5f-11e9-8a07-628dff7095f4": Phase="Running", Reason="", readiness=true. Elapsed: 8.041149677s
Dec 28 05:17:11.009: INFO: Pod "client-containers-ce37dfd7-0a5f-11e9-8a07-628dff7095f4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 10.048324337s
STEP: Saw pod success
Dec 28 05:17:11.009: INFO: Pod "client-containers-ce37dfd7-0a5f-11e9-8a07-628dff7095f4" satisfied condition "success or failure"
Dec 28 05:17:11.014: INFO: Trying to get logs from node 10.10.102.69-build pod client-containers-ce37dfd7-0a5f-11e9-8a07-628dff7095f4 container test-container: <nil>
STEP: delete the pod
Dec 28 05:17:11.464: INFO: Waiting for pod client-containers-ce37dfd7-0a5f-11e9-8a07-628dff7095f4 to disappear
Dec 28 05:17:11.497: INFO: Pod client-containers-ce37dfd7-0a5f-11e9-8a07-628dff7095f4 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 28 05:17:11.497: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-k2h8n" for this suite.
Dec 28 05:17:17.610: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 05:17:17.683: INFO: namespace: e2e-tests-containers-k2h8n, resource: bindings, ignored listing per whitelist
Dec 28 05:17:17.812: INFO: namespace e2e-tests-containers-k2h8n deletion completed in 6.30397264s

• [SLOW TEST:17.198 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 28 05:17:17.813: INFO: >>> kubeConfig: /tmp/kubeconfig-994138694
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-map-d8663172-0a5f-11e9-8a07-628dff7095f4
STEP: Creating a pod to test consume configMaps
Dec 28 05:17:18.101: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-d86f7d05-0a5f-11e9-8a07-628dff7095f4" in namespace "e2e-tests-projected-sthc7" to be "success or failure"
Dec 28 05:17:18.107: INFO: Pod "pod-projected-configmaps-d86f7d05-0a5f-11e9-8a07-628dff7095f4": Phase="Pending", Reason="", readiness=false. Elapsed: 5.97813ms
Dec 28 05:17:20.116: INFO: Pod "pod-projected-configmaps-d86f7d05-0a5f-11e9-8a07-628dff7095f4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014265717s
Dec 28 05:17:22.126: INFO: Pod "pod-projected-configmaps-d86f7d05-0a5f-11e9-8a07-628dff7095f4": Phase="Pending", Reason="", readiness=false. Elapsed: 4.024165434s
Dec 28 05:17:24.134: INFO: Pod "pod-projected-configmaps-d86f7d05-0a5f-11e9-8a07-628dff7095f4": Phase="Pending", Reason="", readiness=false. Elapsed: 6.032336187s
Dec 28 05:17:26.144: INFO: Pod "pod-projected-configmaps-d86f7d05-0a5f-11e9-8a07-628dff7095f4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.042384177s
STEP: Saw pod success
Dec 28 05:17:26.144: INFO: Pod "pod-projected-configmaps-d86f7d05-0a5f-11e9-8a07-628dff7095f4" satisfied condition "success or failure"
Dec 28 05:17:26.151: INFO: Trying to get logs from node 10.10.102.68-share pod pod-projected-configmaps-d86f7d05-0a5f-11e9-8a07-628dff7095f4 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Dec 28 05:17:26.239: INFO: Waiting for pod pod-projected-configmaps-d86f7d05-0a5f-11e9-8a07-628dff7095f4 to disappear
Dec 28 05:17:26.250: INFO: Pod pod-projected-configmaps-d86f7d05-0a5f-11e9-8a07-628dff7095f4 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 28 05:17:26.250: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-sthc7" for this suite.
Dec 28 05:17:32.350: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 05:17:32.540: INFO: namespace: e2e-tests-projected-sthc7, resource: bindings, ignored listing per whitelist
Dec 28 05:17:32.569: INFO: namespace e2e-tests-projected-sthc7 deletion completed in 6.274617123s

• [SLOW TEST:14.756 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 28 05:17:32.569: INFO: >>> kubeConfig: /tmp/kubeconfig-994138694
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-map-e1355d0a-0a5f-11e9-8a07-628dff7095f4
STEP: Creating a pod to test consume configMaps
Dec 28 05:17:32.877: INFO: Waiting up to 5m0s for pod "pod-configmaps-e13e76d1-0a5f-11e9-8a07-628dff7095f4" in namespace "e2e-tests-configmap-8xb2r" to be "success or failure"
Dec 28 05:17:32.909: INFO: Pod "pod-configmaps-e13e76d1-0a5f-11e9-8a07-628dff7095f4": Phase="Pending", Reason="", readiness=false. Elapsed: 31.718937ms
Dec 28 05:17:34.917: INFO: Pod "pod-configmaps-e13e76d1-0a5f-11e9-8a07-628dff7095f4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.038963263s
Dec 28 05:17:36.925: INFO: Pod "pod-configmaps-e13e76d1-0a5f-11e9-8a07-628dff7095f4": Phase="Pending", Reason="", readiness=false. Elapsed: 4.04714967s
Dec 28 05:17:38.997: INFO: Pod "pod-configmaps-e13e76d1-0a5f-11e9-8a07-628dff7095f4": Phase="Pending", Reason="", readiness=false. Elapsed: 6.119776423s
Dec 28 05:17:41.050: INFO: Pod "pod-configmaps-e13e76d1-0a5f-11e9-8a07-628dff7095f4": Phase="Running", Reason="", readiness=true. Elapsed: 8.17239108s
Dec 28 05:17:43.057: INFO: Pod "pod-configmaps-e13e76d1-0a5f-11e9-8a07-628dff7095f4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 10.17939223s
STEP: Saw pod success
Dec 28 05:17:43.057: INFO: Pod "pod-configmaps-e13e76d1-0a5f-11e9-8a07-628dff7095f4" satisfied condition "success or failure"
Dec 28 05:17:43.063: INFO: Trying to get logs from node 10.10.102.69-build pod pod-configmaps-e13e76d1-0a5f-11e9-8a07-628dff7095f4 container configmap-volume-test: <nil>
STEP: delete the pod
Dec 28 05:17:43.707: INFO: Waiting for pod pod-configmaps-e13e76d1-0a5f-11e9-8a07-628dff7095f4 to disappear
Dec 28 05:17:43.738: INFO: Pod pod-configmaps-e13e76d1-0a5f-11e9-8a07-628dff7095f4 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 28 05:17:43.738: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-8xb2r" for this suite.
Dec 28 05:17:51.829: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 05:17:52.137: INFO: namespace: e2e-tests-configmap-8xb2r, resource: bindings, ignored listing per whitelist
Dec 28 05:17:52.243: INFO: namespace e2e-tests-configmap-8xb2r deletion completed in 8.492190767s

• [SLOW TEST:19.674 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl label 
  should update the label on a resource  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 28 05:17:52.243: INFO: >>> kubeConfig: /tmp/kubeconfig-994138694
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Kubectl label
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1042
STEP: creating the pod
Dec 28 05:17:52.446: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994138694 create -f - --namespace=e2e-tests-kubectl-95z6p'
Dec 28 05:17:55.057: INFO: stderr: ""
Dec 28 05:17:55.058: INFO: stdout: "pod/pause created\n"
Dec 28 05:17:55.058: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [pause]
Dec 28 05:17:55.058: INFO: Waiting up to 5m0s for pod "pause" in namespace "e2e-tests-kubectl-95z6p" to be "running and ready"
Dec 28 05:17:55.088: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 29.944654ms
Dec 28 05:17:57.095: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 2.037256837s
Dec 28 05:17:59.102: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 4.04372491s
Dec 28 05:18:01.168: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 6.110011167s
Dec 28 05:18:03.176: INFO: Pod "pause": Phase="Running", Reason="", readiness=true. Elapsed: 8.11759426s
Dec 28 05:18:03.176: INFO: Pod "pause" satisfied condition "running and ready"
Dec 28 05:18:03.176: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [pause]
[It] should update the label on a resource  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: adding the label testing-label with value testing-label-value to a pod
Dec 28 05:18:03.176: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994138694 label pods pause testing-label=testing-label-value --namespace=e2e-tests-kubectl-95z6p'
Dec 28 05:18:03.554: INFO: stderr: ""
Dec 28 05:18:03.554: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod has the label testing-label with the value testing-label-value
Dec 28 05:18:03.554: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994138694 get pod pause -L testing-label --namespace=e2e-tests-kubectl-95z6p'
Dec 28 05:18:03.910: INFO: stderr: ""
Dec 28 05:18:03.910: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          9s    testing-label-value\n"
STEP: removing the label testing-label of a pod
Dec 28 05:18:03.910: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994138694 label pods pause testing-label- --namespace=e2e-tests-kubectl-95z6p'
Dec 28 05:18:04.301: INFO: stderr: ""
Dec 28 05:18:04.301: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod doesn't have the label testing-label
Dec 28 05:18:04.302: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994138694 get pod pause -L testing-label --namespace=e2e-tests-kubectl-95z6p'
Dec 28 05:18:04.687: INFO: stderr: ""
Dec 28 05:18:04.688: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          9s    \n"
[AfterEach] [k8s.io] Kubectl label
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1048
STEP: using delete to clean up resources
Dec 28 05:18:04.688: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994138694 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-95z6p'
Dec 28 05:18:05.065: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Dec 28 05:18:05.065: INFO: stdout: "pod \"pause\" force deleted\n"
Dec 28 05:18:05.065: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994138694 get rc,svc -l name=pause --no-headers --namespace=e2e-tests-kubectl-95z6p'
Dec 28 05:18:05.680: INFO: stderr: "No resources found.\n"
Dec 28 05:18:05.680: INFO: stdout: ""
Dec 28 05:18:05.680: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994138694 get pods -l name=pause --namespace=e2e-tests-kubectl-95z6p -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Dec 28 05:18:06.107: INFO: stderr: ""
Dec 28 05:18:06.107: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 28 05:18:06.108: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-95z6p" for this suite.
Dec 28 05:18:12.149: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 05:18:12.203: INFO: namespace: e2e-tests-kubectl-95z6p, resource: bindings, ignored listing per whitelist
Dec 28 05:18:12.430: INFO: namespace e2e-tests-kubectl-95z6p deletion completed in 6.30857053s

• [SLOW TEST:20.187 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl label
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should update the label on a resource  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] Projected 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 28 05:18:12.431: INFO: >>> kubeConfig: /tmp/kubeconfig-994138694
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Dec 28 05:18:12.682: INFO: Waiting up to 5m0s for pod "downwardapi-volume-f8f63c56-0a5f-11e9-8a07-628dff7095f4" in namespace "e2e-tests-projected-zqdkg" to be "success or failure"
Dec 28 05:18:12.772: INFO: Pod "downwardapi-volume-f8f63c56-0a5f-11e9-8a07-628dff7095f4": Phase="Pending", Reason="", readiness=false. Elapsed: 90.125007ms
Dec 28 05:18:14.780: INFO: Pod "downwardapi-volume-f8f63c56-0a5f-11e9-8a07-628dff7095f4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.09817716s
Dec 28 05:18:16.789: INFO: Pod "downwardapi-volume-f8f63c56-0a5f-11e9-8a07-628dff7095f4": Phase="Pending", Reason="", readiness=false. Elapsed: 4.106710603s
Dec 28 05:18:18.795: INFO: Pod "downwardapi-volume-f8f63c56-0a5f-11e9-8a07-628dff7095f4": Phase="Pending", Reason="", readiness=false. Elapsed: 6.11311248s
Dec 28 05:18:20.804: INFO: Pod "downwardapi-volume-f8f63c56-0a5f-11e9-8a07-628dff7095f4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.121678623s
STEP: Saw pod success
Dec 28 05:18:20.804: INFO: Pod "downwardapi-volume-f8f63c56-0a5f-11e9-8a07-628dff7095f4" satisfied condition "success or failure"
Dec 28 05:18:20.810: INFO: Trying to get logs from node 10.10.102.67-slave pod downwardapi-volume-f8f63c56-0a5f-11e9-8a07-628dff7095f4 container client-container: <nil>
STEP: delete the pod
Dec 28 05:18:20.867: INFO: Waiting for pod downwardapi-volume-f8f63c56-0a5f-11e9-8a07-628dff7095f4 to disappear
Dec 28 05:18:20.894: INFO: Pod downwardapi-volume-f8f63c56-0a5f-11e9-8a07-628dff7095f4 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 28 05:18:20.894: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-zqdkg" for this suite.
Dec 28 05:18:26.971: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 05:18:27.168: INFO: namespace: e2e-tests-projected-zqdkg, resource: bindings, ignored listing per whitelist
Dec 28 05:18:27.190: INFO: namespace e2e-tests-projected-zqdkg deletion completed in 6.284309273s

• [SLOW TEST:14.759 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources Simple CustomResourceDefinition 
  creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 28 05:18:27.191: INFO: >>> kubeConfig: /tmp/kubeconfig-994138694
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Waiting for a default service account to be provisioned in namespace
[It] creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Dec 28 05:18:27.510: INFO: >>> kubeConfig: /tmp/kubeconfig-994138694
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 28 05:18:28.628: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-custom-resource-definition-lwktn" for this suite.
Dec 28 05:18:34.684: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 05:18:34.871: INFO: namespace: e2e-tests-custom-resource-definition-lwktn, resource: bindings, ignored listing per whitelist
Dec 28 05:18:34.929: INFO: namespace e2e-tests-custom-resource-definition-lwktn deletion completed in 6.285143633s

• [SLOW TEST:7.738 seconds]
[sig-api-machinery] CustomResourceDefinition resources
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  Simple CustomResourceDefinition
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/custom_resource_definition.go:35
    creating/deleting custom resource definition objects works  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-api-machinery] ConfigMap 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 28 05:18:34.929: INFO: >>> kubeConfig: /tmp/kubeconfig-994138694
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap e2e-tests-configmap-qs2b4/configmap-test-0658322a-0a60-11e9-8a07-628dff7095f4
STEP: Creating a pod to test consume configMaps
Dec 28 05:18:35.131: INFO: Waiting up to 5m0s for pod "pod-configmaps-06594bdd-0a60-11e9-8a07-628dff7095f4" in namespace "e2e-tests-configmap-qs2b4" to be "success or failure"
Dec 28 05:18:35.155: INFO: Pod "pod-configmaps-06594bdd-0a60-11e9-8a07-628dff7095f4": Phase="Pending", Reason="", readiness=false. Elapsed: 23.84872ms
Dec 28 05:18:37.165: INFO: Pod "pod-configmaps-06594bdd-0a60-11e9-8a07-628dff7095f4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.033274986s
Dec 28 05:18:39.172: INFO: Pod "pod-configmaps-06594bdd-0a60-11e9-8a07-628dff7095f4": Phase="Pending", Reason="", readiness=false. Elapsed: 4.040306566s
Dec 28 05:18:41.238: INFO: Pod "pod-configmaps-06594bdd-0a60-11e9-8a07-628dff7095f4": Phase="Pending", Reason="", readiness=false. Elapsed: 6.106291286s
Dec 28 05:18:43.245: INFO: Pod "pod-configmaps-06594bdd-0a60-11e9-8a07-628dff7095f4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.113972746s
STEP: Saw pod success
Dec 28 05:18:43.246: INFO: Pod "pod-configmaps-06594bdd-0a60-11e9-8a07-628dff7095f4" satisfied condition "success or failure"
Dec 28 05:18:43.251: INFO: Trying to get logs from node 10.10.102.68-share pod pod-configmaps-06594bdd-0a60-11e9-8a07-628dff7095f4 container env-test: <nil>
STEP: delete the pod
Dec 28 05:18:43.365: INFO: Waiting for pod pod-configmaps-06594bdd-0a60-11e9-8a07-628dff7095f4 to disappear
Dec 28 05:18:43.374: INFO: Pod pod-configmaps-06594bdd-0a60-11e9-8a07-628dff7095f4 no longer exists
[AfterEach] [sig-api-machinery] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 28 05:18:43.374: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-qs2b4" for this suite.
Dec 28 05:18:49.419: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 05:18:49.545: INFO: namespace: e2e-tests-configmap-qs2b4, resource: bindings, ignored listing per whitelist
Dec 28 05:18:49.648: INFO: namespace e2e-tests-configmap-qs2b4 deletion completed in 6.258049903s

• [SLOW TEST:14.720 seconds]
[sig-api-machinery] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:30
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 28 05:18:49.650: INFO: >>> kubeConfig: /tmp/kubeconfig-994138694
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-0f334225-0a60-11e9-8a07-628dff7095f4
STEP: Creating a pod to test consume secrets
Dec 28 05:18:50.159: INFO: Waiting up to 5m0s for pod "pod-secrets-0f4e494c-0a60-11e9-8a07-628dff7095f4" in namespace "e2e-tests-secrets-7lb2f" to be "success or failure"
Dec 28 05:18:50.171: INFO: Pod "pod-secrets-0f4e494c-0a60-11e9-8a07-628dff7095f4": Phase="Pending", Reason="", readiness=false. Elapsed: 11.92931ms
Dec 28 05:18:52.177: INFO: Pod "pod-secrets-0f4e494c-0a60-11e9-8a07-628dff7095f4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01811564s
Dec 28 05:18:54.214: INFO: Pod "pod-secrets-0f4e494c-0a60-11e9-8a07-628dff7095f4": Phase="Pending", Reason="", readiness=false. Elapsed: 4.05559865s
Dec 28 05:18:56.267: INFO: Pod "pod-secrets-0f4e494c-0a60-11e9-8a07-628dff7095f4": Phase="Pending", Reason="", readiness=false. Elapsed: 6.10778549s
Dec 28 05:18:58.278: INFO: Pod "pod-secrets-0f4e494c-0a60-11e9-8a07-628dff7095f4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.119348523s
STEP: Saw pod success
Dec 28 05:18:58.278: INFO: Pod "pod-secrets-0f4e494c-0a60-11e9-8a07-628dff7095f4" satisfied condition "success or failure"
Dec 28 05:18:58.284: INFO: Trying to get logs from node 10.10.102.69-build pod pod-secrets-0f4e494c-0a60-11e9-8a07-628dff7095f4 container secret-volume-test: <nil>
STEP: delete the pod
Dec 28 05:18:58.369: INFO: Waiting for pod pod-secrets-0f4e494c-0a60-11e9-8a07-628dff7095f4 to disappear
Dec 28 05:18:58.382: INFO: Pod pod-secrets-0f4e494c-0a60-11e9-8a07-628dff7095f4 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 28 05:18:58.382: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-7lb2f" for this suite.
Dec 28 05:19:04.427: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 05:19:04.511: INFO: namespace: e2e-tests-secrets-7lb2f, resource: bindings, ignored listing per whitelist
Dec 28 05:19:04.813: INFO: namespace e2e-tests-secrets-7lb2f deletion completed in 6.415472237s
STEP: Destroying namespace "e2e-tests-secret-namespace-9chd5" for this suite.
Dec 28 05:19:10.844: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 05:19:11.122: INFO: namespace: e2e-tests-secret-namespace-9chd5, resource: bindings, ignored listing per whitelist
Dec 28 05:19:11.138: INFO: namespace e2e-tests-secret-namespace-9chd5 deletion completed in 6.32449771s

• [SLOW TEST:21.488 seconds]
[sig-storage] Secrets
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 28 05:19:11.138: INFO: >>> kubeConfig: /tmp/kubeconfig-994138694
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:98
[It] should run and stop simple daemon [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Dec 28 05:19:11.456: INFO: DaemonSet pods can't tolerate node 10.10.102.65-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 28 05:19:11.510: INFO: Number of nodes with available pods: 0
Dec 28 05:19:11.510: INFO: Node 10.10.102.66-slave is running more than one daemon pod
Dec 28 05:19:12.522: INFO: DaemonSet pods can't tolerate node 10.10.102.65-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 28 05:19:12.530: INFO: Number of nodes with available pods: 0
Dec 28 05:19:12.530: INFO: Node 10.10.102.66-slave is running more than one daemon pod
Dec 28 05:19:13.522: INFO: DaemonSet pods can't tolerate node 10.10.102.65-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 28 05:19:13.528: INFO: Number of nodes with available pods: 0
Dec 28 05:19:13.528: INFO: Node 10.10.102.66-slave is running more than one daemon pod
Dec 28 05:19:14.522: INFO: DaemonSet pods can't tolerate node 10.10.102.65-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 28 05:19:14.531: INFO: Number of nodes with available pods: 0
Dec 28 05:19:14.531: INFO: Node 10.10.102.66-slave is running more than one daemon pod
Dec 28 05:19:15.523: INFO: DaemonSet pods can't tolerate node 10.10.102.65-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 28 05:19:15.529: INFO: Number of nodes with available pods: 0
Dec 28 05:19:15.529: INFO: Node 10.10.102.66-slave is running more than one daemon pod
Dec 28 05:19:16.566: INFO: DaemonSet pods can't tolerate node 10.10.102.65-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 28 05:19:16.574: INFO: Number of nodes with available pods: 0
Dec 28 05:19:16.574: INFO: Node 10.10.102.66-slave is running more than one daemon pod
Dec 28 05:19:17.553: INFO: DaemonSet pods can't tolerate node 10.10.102.65-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 28 05:19:17.561: INFO: Number of nodes with available pods: 0
Dec 28 05:19:17.561: INFO: Node 10.10.102.66-slave is running more than one daemon pod
Dec 28 05:19:18.773: INFO: DaemonSet pods can't tolerate node 10.10.102.65-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 28 05:19:18.782: INFO: Number of nodes with available pods: 0
Dec 28 05:19:18.782: INFO: Node 10.10.102.66-slave is running more than one daemon pod
Dec 28 05:19:19.521: INFO: DaemonSet pods can't tolerate node 10.10.102.65-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 28 05:19:19.528: INFO: Number of nodes with available pods: 0
Dec 28 05:19:19.528: INFO: Node 10.10.102.66-slave is running more than one daemon pod
Dec 28 05:19:20.522: INFO: DaemonSet pods can't tolerate node 10.10.102.65-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 28 05:19:20.528: INFO: Number of nodes with available pods: 0
Dec 28 05:19:20.528: INFO: Node 10.10.102.66-slave is running more than one daemon pod
Dec 28 05:19:21.528: INFO: DaemonSet pods can't tolerate node 10.10.102.65-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 28 05:19:21.536: INFO: Number of nodes with available pods: 0
Dec 28 05:19:21.536: INFO: Node 10.10.102.66-slave is running more than one daemon pod
Dec 28 05:19:22.571: INFO: DaemonSet pods can't tolerate node 10.10.102.65-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 28 05:19:22.588: INFO: Number of nodes with available pods: 3
Dec 28 05:19:22.588: INFO: Node 10.10.102.68-share is running more than one daemon pod
Dec 28 05:19:23.522: INFO: DaemonSet pods can't tolerate node 10.10.102.65-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 28 05:19:23.529: INFO: Number of nodes with available pods: 4
Dec 28 05:19:23.529: INFO: Number of running nodes: 4, number of available pods: 4
STEP: Stop a daemon pod, check that the daemon pod is revived.
Dec 28 05:19:23.576: INFO: DaemonSet pods can't tolerate node 10.10.102.65-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 28 05:19:23.582: INFO: Number of nodes with available pods: 3
Dec 28 05:19:23.582: INFO: Node 10.10.102.69-build is running more than one daemon pod
Dec 28 05:19:24.593: INFO: DaemonSet pods can't tolerate node 10.10.102.65-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 28 05:19:24.600: INFO: Number of nodes with available pods: 3
Dec 28 05:19:24.600: INFO: Node 10.10.102.69-build is running more than one daemon pod
Dec 28 05:19:25.594: INFO: DaemonSet pods can't tolerate node 10.10.102.65-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 28 05:19:25.600: INFO: Number of nodes with available pods: 3
Dec 28 05:19:25.600: INFO: Node 10.10.102.69-build is running more than one daemon pod
Dec 28 05:19:26.702: INFO: DaemonSet pods can't tolerate node 10.10.102.65-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 28 05:19:26.714: INFO: Number of nodes with available pods: 3
Dec 28 05:19:26.714: INFO: Node 10.10.102.69-build is running more than one daemon pod
Dec 28 05:19:27.593: INFO: DaemonSet pods can't tolerate node 10.10.102.65-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 28 05:19:27.599: INFO: Number of nodes with available pods: 3
Dec 28 05:19:27.599: INFO: Node 10.10.102.69-build is running more than one daemon pod
Dec 28 05:19:28.778: INFO: DaemonSet pods can't tolerate node 10.10.102.65-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 28 05:19:28.786: INFO: Number of nodes with available pods: 3
Dec 28 05:19:28.786: INFO: Node 10.10.102.69-build is running more than one daemon pod
Dec 28 05:19:29.596: INFO: DaemonSet pods can't tolerate node 10.10.102.65-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 28 05:19:29.604: INFO: Number of nodes with available pods: 3
Dec 28 05:19:29.604: INFO: Node 10.10.102.69-build is running more than one daemon pod
Dec 28 05:19:30.595: INFO: DaemonSet pods can't tolerate node 10.10.102.65-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 28 05:19:30.602: INFO: Number of nodes with available pods: 3
Dec 28 05:19:30.602: INFO: Node 10.10.102.69-build is running more than one daemon pod
Dec 28 05:19:31.596: INFO: DaemonSet pods can't tolerate node 10.10.102.65-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 28 05:19:31.603: INFO: Number of nodes with available pods: 3
Dec 28 05:19:31.603: INFO: Node 10.10.102.69-build is running more than one daemon pod
Dec 28 05:19:32.596: INFO: DaemonSet pods can't tolerate node 10.10.102.65-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 28 05:19:32.602: INFO: Number of nodes with available pods: 3
Dec 28 05:19:32.602: INFO: Node 10.10.102.69-build is running more than one daemon pod
Dec 28 05:19:33.594: INFO: DaemonSet pods can't tolerate node 10.10.102.65-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 28 05:19:33.601: INFO: Number of nodes with available pods: 3
Dec 28 05:19:33.601: INFO: Node 10.10.102.69-build is running more than one daemon pod
Dec 28 05:19:34.592: INFO: DaemonSet pods can't tolerate node 10.10.102.65-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 28 05:19:34.599: INFO: Number of nodes with available pods: 3
Dec 28 05:19:34.599: INFO: Node 10.10.102.69-build is running more than one daemon pod
Dec 28 05:19:35.593: INFO: DaemonSet pods can't tolerate node 10.10.102.65-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 28 05:19:35.600: INFO: Number of nodes with available pods: 3
Dec 28 05:19:35.600: INFO: Node 10.10.102.69-build is running more than one daemon pod
Dec 28 05:19:36.594: INFO: DaemonSet pods can't tolerate node 10.10.102.65-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 28 05:19:36.601: INFO: Number of nodes with available pods: 3
Dec 28 05:19:36.601: INFO: Node 10.10.102.69-build is running more than one daemon pod
Dec 28 05:19:37.593: INFO: DaemonSet pods can't tolerate node 10.10.102.65-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 28 05:19:37.601: INFO: Number of nodes with available pods: 3
Dec 28 05:19:37.601: INFO: Node 10.10.102.69-build is running more than one daemon pod
Dec 28 05:19:38.603: INFO: DaemonSet pods can't tolerate node 10.10.102.65-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 28 05:19:38.610: INFO: Number of nodes with available pods: 3
Dec 28 05:19:38.610: INFO: Node 10.10.102.69-build is running more than one daemon pod
Dec 28 05:19:39.595: INFO: DaemonSet pods can't tolerate node 10.10.102.65-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 28 05:19:39.603: INFO: Number of nodes with available pods: 3
Dec 28 05:19:39.603: INFO: Node 10.10.102.69-build is running more than one daemon pod
Dec 28 05:19:40.595: INFO: DaemonSet pods can't tolerate node 10.10.102.65-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 28 05:19:40.603: INFO: Number of nodes with available pods: 3
Dec 28 05:19:40.603: INFO: Node 10.10.102.69-build is running more than one daemon pod
Dec 28 05:19:41.595: INFO: DaemonSet pods can't tolerate node 10.10.102.65-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 28 05:19:41.602: INFO: Number of nodes with available pods: 3
Dec 28 05:19:41.602: INFO: Node 10.10.102.69-build is running more than one daemon pod
Dec 28 05:19:42.594: INFO: DaemonSet pods can't tolerate node 10.10.102.65-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 28 05:19:42.600: INFO: Number of nodes with available pods: 3
Dec 28 05:19:42.600: INFO: Node 10.10.102.69-build is running more than one daemon pod
Dec 28 05:19:43.595: INFO: DaemonSet pods can't tolerate node 10.10.102.65-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 28 05:19:43.602: INFO: Number of nodes with available pods: 3
Dec 28 05:19:43.602: INFO: Node 10.10.102.69-build is running more than one daemon pod
Dec 28 05:19:44.593: INFO: DaemonSet pods can't tolerate node 10.10.102.65-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 28 05:19:44.600: INFO: Number of nodes with available pods: 3
Dec 28 05:19:44.600: INFO: Node 10.10.102.69-build is running more than one daemon pod
Dec 28 05:19:45.593: INFO: DaemonSet pods can't tolerate node 10.10.102.65-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 28 05:19:45.600: INFO: Number of nodes with available pods: 3
Dec 28 05:19:45.600: INFO: Node 10.10.102.69-build is running more than one daemon pod
Dec 28 05:19:46.594: INFO: DaemonSet pods can't tolerate node 10.10.102.65-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 28 05:19:46.601: INFO: Number of nodes with available pods: 3
Dec 28 05:19:46.601: INFO: Node 10.10.102.69-build is running more than one daemon pod
Dec 28 05:19:47.593: INFO: DaemonSet pods can't tolerate node 10.10.102.65-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 28 05:19:47.600: INFO: Number of nodes with available pods: 3
Dec 28 05:19:47.600: INFO: Node 10.10.102.69-build is running more than one daemon pod
Dec 28 05:19:48.594: INFO: DaemonSet pods can't tolerate node 10.10.102.65-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 28 05:19:48.601: INFO: Number of nodes with available pods: 3
Dec 28 05:19:48.601: INFO: Node 10.10.102.69-build is running more than one daemon pod
Dec 28 05:19:49.594: INFO: DaemonSet pods can't tolerate node 10.10.102.65-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 28 05:19:49.602: INFO: Number of nodes with available pods: 3
Dec 28 05:19:49.602: INFO: Node 10.10.102.69-build is running more than one daemon pod
Dec 28 05:19:50.596: INFO: DaemonSet pods can't tolerate node 10.10.102.65-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 28 05:19:50.604: INFO: Number of nodes with available pods: 3
Dec 28 05:19:50.604: INFO: Node 10.10.102.69-build is running more than one daemon pod
Dec 28 05:19:51.594: INFO: DaemonSet pods can't tolerate node 10.10.102.65-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 28 05:19:51.604: INFO: Number of nodes with available pods: 3
Dec 28 05:19:51.604: INFO: Node 10.10.102.69-build is running more than one daemon pod
Dec 28 05:19:52.593: INFO: DaemonSet pods can't tolerate node 10.10.102.65-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 28 05:19:52.600: INFO: Number of nodes with available pods: 3
Dec 28 05:19:52.600: INFO: Node 10.10.102.69-build is running more than one daemon pod
Dec 28 05:19:53.595: INFO: DaemonSet pods can't tolerate node 10.10.102.65-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 28 05:19:53.603: INFO: Number of nodes with available pods: 3
Dec 28 05:19:53.603: INFO: Node 10.10.102.69-build is running more than one daemon pod
Dec 28 05:19:54.603: INFO: DaemonSet pods can't tolerate node 10.10.102.65-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 28 05:19:54.619: INFO: Number of nodes with available pods: 3
Dec 28 05:19:54.620: INFO: Node 10.10.102.69-build is running more than one daemon pod
Dec 28 05:19:55.594: INFO: DaemonSet pods can't tolerate node 10.10.102.65-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 28 05:19:55.601: INFO: Number of nodes with available pods: 3
Dec 28 05:19:55.601: INFO: Node 10.10.102.69-build is running more than one daemon pod
Dec 28 05:19:56.595: INFO: DaemonSet pods can't tolerate node 10.10.102.65-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 28 05:19:56.602: INFO: Number of nodes with available pods: 3
Dec 28 05:19:56.602: INFO: Node 10.10.102.69-build is running more than one daemon pod
Dec 28 05:19:57.593: INFO: DaemonSet pods can't tolerate node 10.10.102.65-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 28 05:19:57.600: INFO: Number of nodes with available pods: 3
Dec 28 05:19:57.600: INFO: Node 10.10.102.69-build is running more than one daemon pod
Dec 28 05:19:58.594: INFO: DaemonSet pods can't tolerate node 10.10.102.65-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 28 05:19:58.601: INFO: Number of nodes with available pods: 3
Dec 28 05:19:58.601: INFO: Node 10.10.102.69-build is running more than one daemon pod
Dec 28 05:19:59.595: INFO: DaemonSet pods can't tolerate node 10.10.102.65-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 28 05:19:59.603: INFO: Number of nodes with available pods: 3
Dec 28 05:19:59.603: INFO: Node 10.10.102.69-build is running more than one daemon pod
Dec 28 05:20:00.594: INFO: DaemonSet pods can't tolerate node 10.10.102.65-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 28 05:20:00.602: INFO: Number of nodes with available pods: 3
Dec 28 05:20:00.602: INFO: Node 10.10.102.69-build is running more than one daemon pod
Dec 28 05:20:01.597: INFO: DaemonSet pods can't tolerate node 10.10.102.65-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 28 05:20:01.606: INFO: Number of nodes with available pods: 3
Dec 28 05:20:01.607: INFO: Node 10.10.102.69-build is running more than one daemon pod
Dec 28 05:20:02.597: INFO: DaemonSet pods can't tolerate node 10.10.102.65-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 28 05:20:02.607: INFO: Number of nodes with available pods: 3
Dec 28 05:20:02.607: INFO: Node 10.10.102.69-build is running more than one daemon pod
Dec 28 05:20:03.595: INFO: DaemonSet pods can't tolerate node 10.10.102.65-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 28 05:20:03.606: INFO: Number of nodes with available pods: 3
Dec 28 05:20:03.606: INFO: Node 10.10.102.69-build is running more than one daemon pod
Dec 28 05:20:04.599: INFO: DaemonSet pods can't tolerate node 10.10.102.65-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 28 05:20:04.609: INFO: Number of nodes with available pods: 3
Dec 28 05:20:04.609: INFO: Node 10.10.102.69-build is running more than one daemon pod
Dec 28 05:20:05.642: INFO: DaemonSet pods can't tolerate node 10.10.102.65-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 28 05:20:05.649: INFO: Number of nodes with available pods: 3
Dec 28 05:20:05.649: INFO: Node 10.10.102.69-build is running more than one daemon pod
Dec 28 05:20:06.593: INFO: DaemonSet pods can't tolerate node 10.10.102.65-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 28 05:20:06.600: INFO: Number of nodes with available pods: 3
Dec 28 05:20:06.600: INFO: Node 10.10.102.69-build is running more than one daemon pod
Dec 28 05:20:07.595: INFO: DaemonSet pods can't tolerate node 10.10.102.65-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 28 05:20:07.606: INFO: Number of nodes with available pods: 3
Dec 28 05:20:07.606: INFO: Node 10.10.102.69-build is running more than one daemon pod
Dec 28 05:20:08.594: INFO: DaemonSet pods can't tolerate node 10.10.102.65-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 28 05:20:08.603: INFO: Number of nodes with available pods: 4
Dec 28 05:20:08.604: INFO: Number of running nodes: 4, number of available pods: 4
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:64
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting {extensions DaemonSet} daemon-set in namespace e2e-tests-daemonsets-qjcrr, will wait for the garbage collector to delete the pods
Dec 28 05:20:08.728: INFO: Deleting {extensions DaemonSet} daemon-set took: 17.66328ms
Dec 28 05:20:08.828: INFO: Terminating {extensions DaemonSet} daemon-set pods took: 100.53169ms
Dec 28 05:20:43.734: INFO: Number of nodes with available pods: 0
Dec 28 05:20:43.735: INFO: Number of running nodes: 0, number of available pods: 0
Dec 28 05:20:43.747: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-qjcrr/daemonsets","resourceVersion":"529576"},"items":null}

Dec 28 05:20:43.753: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-qjcrr/pods","resourceVersion":"529576"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 28 05:20:43.828: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-qjcrr" for this suite.
Dec 28 05:20:51.861: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 05:20:51.935: INFO: namespace: e2e-tests-daemonsets-qjcrr, resource: bindings, ignored listing per whitelist
Dec 28 05:20:52.120: INFO: namespace e2e-tests-daemonsets-qjcrr deletion completed in 8.283286383s

• [SLOW TEST:100.982 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-auth] ServiceAccounts 
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 28 05:20:52.121: INFO: >>> kubeConfig: /tmp/kubeconfig-994138694
STEP: Building a namespace api object, basename svcaccounts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should mount an API token into pods  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: getting the auto-created API token
STEP: Creating a pod to test consume service account token
Dec 28 05:20:52.995: INFO: Waiting up to 5m0s for pod "pod-service-account-5885b7c8-0a60-11e9-8a07-628dff7095f4-bkwvj" in namespace "e2e-tests-svcaccounts-qkdxv" to be "success or failure"
Dec 28 05:20:53.022: INFO: Pod "pod-service-account-5885b7c8-0a60-11e9-8a07-628dff7095f4-bkwvj": Phase="Pending", Reason="", readiness=false. Elapsed: 26.814233ms
Dec 28 05:20:55.029: INFO: Pod "pod-service-account-5885b7c8-0a60-11e9-8a07-628dff7095f4-bkwvj": Phase="Pending", Reason="", readiness=false. Elapsed: 2.034113373s
Dec 28 05:20:57.036: INFO: Pod "pod-service-account-5885b7c8-0a60-11e9-8a07-628dff7095f4-bkwvj": Phase="Pending", Reason="", readiness=false. Elapsed: 4.04085721s
Dec 28 05:20:59.043: INFO: Pod "pod-service-account-5885b7c8-0a60-11e9-8a07-628dff7095f4-bkwvj": Phase="Pending", Reason="", readiness=false. Elapsed: 6.047809723s
Dec 28 05:21:01.056: INFO: Pod "pod-service-account-5885b7c8-0a60-11e9-8a07-628dff7095f4-bkwvj": Phase="Pending", Reason="", readiness=false. Elapsed: 8.06103842s
Dec 28 05:21:03.063: INFO: Pod "pod-service-account-5885b7c8-0a60-11e9-8a07-628dff7095f4-bkwvj": Phase="Pending", Reason="", readiness=false. Elapsed: 10.068034123s
Dec 28 05:21:05.071: INFO: Pod "pod-service-account-5885b7c8-0a60-11e9-8a07-628dff7095f4-bkwvj": Phase="Pending", Reason="", readiness=false. Elapsed: 12.076065776s
Dec 28 05:21:07.096: INFO: Pod "pod-service-account-5885b7c8-0a60-11e9-8a07-628dff7095f4-bkwvj": Phase="Running", Reason="", readiness=false. Elapsed: 14.101344223s
Dec 28 05:21:09.103: INFO: Pod "pod-service-account-5885b7c8-0a60-11e9-8a07-628dff7095f4-bkwvj": Phase="Succeeded", Reason="", readiness=false. Elapsed: 16.108460736s
STEP: Saw pod success
Dec 28 05:21:09.103: INFO: Pod "pod-service-account-5885b7c8-0a60-11e9-8a07-628dff7095f4-bkwvj" satisfied condition "success or failure"
Dec 28 05:21:09.108: INFO: Trying to get logs from node 10.10.102.68-share pod pod-service-account-5885b7c8-0a60-11e9-8a07-628dff7095f4-bkwvj container token-test: <nil>
STEP: delete the pod
Dec 28 05:21:09.185: INFO: Waiting for pod pod-service-account-5885b7c8-0a60-11e9-8a07-628dff7095f4-bkwvj to disappear
Dec 28 05:21:09.200: INFO: Pod pod-service-account-5885b7c8-0a60-11e9-8a07-628dff7095f4-bkwvj no longer exists
STEP: Creating a pod to test consume service account root CA
Dec 28 05:21:09.261: INFO: Waiting up to 5m0s for pod "pod-service-account-5885b7c8-0a60-11e9-8a07-628dff7095f4-4d8fs" in namespace "e2e-tests-svcaccounts-qkdxv" to be "success or failure"
Dec 28 05:21:09.269: INFO: Pod "pod-service-account-5885b7c8-0a60-11e9-8a07-628dff7095f4-4d8fs": Phase="Pending", Reason="", readiness=false. Elapsed: 7.97058ms
Dec 28 05:21:11.307: INFO: Pod "pod-service-account-5885b7c8-0a60-11e9-8a07-628dff7095f4-4d8fs": Phase="Pending", Reason="", readiness=false. Elapsed: 2.046533066s
Dec 28 05:21:13.318: INFO: Pod "pod-service-account-5885b7c8-0a60-11e9-8a07-628dff7095f4-4d8fs": Phase="Pending", Reason="", readiness=false. Elapsed: 4.056956963s
Dec 28 05:21:15.326: INFO: Pod "pod-service-account-5885b7c8-0a60-11e9-8a07-628dff7095f4-4d8fs": Phase="Pending", Reason="", readiness=false. Elapsed: 6.06470849s
Dec 28 05:21:17.332: INFO: Pod "pod-service-account-5885b7c8-0a60-11e9-8a07-628dff7095f4-4d8fs": Phase="Pending", Reason="", readiness=false. Elapsed: 8.071309403s
Dec 28 05:21:19.341: INFO: Pod "pod-service-account-5885b7c8-0a60-11e9-8a07-628dff7095f4-4d8fs": Phase="Pending", Reason="", readiness=false. Elapsed: 10.079721496s
Dec 28 05:21:21.348: INFO: Pod "pod-service-account-5885b7c8-0a60-11e9-8a07-628dff7095f4-4d8fs": Phase="Pending", Reason="", readiness=false. Elapsed: 12.086719046s
Dec 28 05:21:23.356: INFO: Pod "pod-service-account-5885b7c8-0a60-11e9-8a07-628dff7095f4-4d8fs": Phase="Succeeded", Reason="", readiness=false. Elapsed: 14.094641096s
STEP: Saw pod success
Dec 28 05:21:23.356: INFO: Pod "pod-service-account-5885b7c8-0a60-11e9-8a07-628dff7095f4-4d8fs" satisfied condition "success or failure"
Dec 28 05:21:23.361: INFO: Trying to get logs from node 10.10.102.69-build pod pod-service-account-5885b7c8-0a60-11e9-8a07-628dff7095f4-4d8fs container root-ca-test: <nil>
STEP: delete the pod
Dec 28 05:21:23.474: INFO: Waiting for pod pod-service-account-5885b7c8-0a60-11e9-8a07-628dff7095f4-4d8fs to disappear
Dec 28 05:21:23.488: INFO: Pod pod-service-account-5885b7c8-0a60-11e9-8a07-628dff7095f4-4d8fs no longer exists
STEP: Creating a pod to test consume service account namespace
Dec 28 05:21:23.508: INFO: Waiting up to 5m0s for pod "pod-service-account-5885b7c8-0a60-11e9-8a07-628dff7095f4-sz2rd" in namespace "e2e-tests-svcaccounts-qkdxv" to be "success or failure"
Dec 28 05:21:23.574: INFO: Pod "pod-service-account-5885b7c8-0a60-11e9-8a07-628dff7095f4-sz2rd": Phase="Pending", Reason="", readiness=false. Elapsed: 65.23683ms
Dec 28 05:21:25.580: INFO: Pod "pod-service-account-5885b7c8-0a60-11e9-8a07-628dff7095f4-sz2rd": Phase="Pending", Reason="", readiness=false. Elapsed: 2.071725683s
Dec 28 05:21:27.623: INFO: Pod "pod-service-account-5885b7c8-0a60-11e9-8a07-628dff7095f4-sz2rd": Phase="Pending", Reason="", readiness=false. Elapsed: 4.114548193s
Dec 28 05:21:29.637: INFO: Pod "pod-service-account-5885b7c8-0a60-11e9-8a07-628dff7095f4-sz2rd": Phase="Pending", Reason="", readiness=false. Elapsed: 6.129027987s
Dec 28 05:21:31.644: INFO: Pod "pod-service-account-5885b7c8-0a60-11e9-8a07-628dff7095f4-sz2rd": Phase="Pending", Reason="", readiness=false. Elapsed: 8.135810253s
Dec 28 05:21:33.651: INFO: Pod "pod-service-account-5885b7c8-0a60-11e9-8a07-628dff7095f4-sz2rd": Phase="Pending", Reason="", readiness=false. Elapsed: 10.14281703s
Dec 28 05:21:35.659: INFO: Pod "pod-service-account-5885b7c8-0a60-11e9-8a07-628dff7095f4-sz2rd": Phase="Pending", Reason="", readiness=false. Elapsed: 12.151035077s
Dec 28 05:21:37.666: INFO: Pod "pod-service-account-5885b7c8-0a60-11e9-8a07-628dff7095f4-sz2rd": Phase="Pending", Reason="", readiness=false. Elapsed: 14.15757184s
Dec 28 05:21:39.676: INFO: Pod "pod-service-account-5885b7c8-0a60-11e9-8a07-628dff7095f4-sz2rd": Phase="Succeeded", Reason="", readiness=false. Elapsed: 16.16754856s
STEP: Saw pod success
Dec 28 05:21:39.680: INFO: Pod "pod-service-account-5885b7c8-0a60-11e9-8a07-628dff7095f4-sz2rd" satisfied condition "success or failure"
Dec 28 05:21:39.685: INFO: Trying to get logs from node 10.10.102.68-share pod pod-service-account-5885b7c8-0a60-11e9-8a07-628dff7095f4-sz2rd container namespace-test: <nil>
STEP: delete the pod
Dec 28 05:21:39.835: INFO: Waiting for pod pod-service-account-5885b7c8-0a60-11e9-8a07-628dff7095f4-sz2rd to disappear
Dec 28 05:21:39.846: INFO: Pod pod-service-account-5885b7c8-0a60-11e9-8a07-628dff7095f4-sz2rd no longer exists
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 28 05:21:39.847: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-svcaccounts-qkdxv" for this suite.
Dec 28 05:21:48.030: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 05:21:48.302: INFO: namespace: e2e-tests-svcaccounts-qkdxv, resource: bindings, ignored listing per whitelist
Dec 28 05:21:48.438: INFO: namespace e2e-tests-svcaccounts-qkdxv deletion completed in 8.580856577s

• [SLOW TEST:56.317 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:22
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 28 05:21:48.438: INFO: >>> kubeConfig: /tmp/kubeconfig-994138694
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:98
[It] should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Dec 28 05:21:48.728: INFO: Creating simple daemon set daemon-set
STEP: Check that daemon pods launch on every node of the cluster.
Dec 28 05:21:48.761: INFO: DaemonSet pods can't tolerate node 10.10.102.65-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 28 05:21:48.782: INFO: Number of nodes with available pods: 0
Dec 28 05:21:48.782: INFO: Node 10.10.102.66-slave is running more than one daemon pod
Dec 28 05:21:49.795: INFO: DaemonSet pods can't tolerate node 10.10.102.65-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 28 05:21:49.802: INFO: Number of nodes with available pods: 0
Dec 28 05:21:49.802: INFO: Node 10.10.102.66-slave is running more than one daemon pod
Dec 28 05:21:50.822: INFO: DaemonSet pods can't tolerate node 10.10.102.65-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 28 05:21:50.830: INFO: Number of nodes with available pods: 0
Dec 28 05:21:50.830: INFO: Node 10.10.102.66-slave is running more than one daemon pod
Dec 28 05:21:51.793: INFO: DaemonSet pods can't tolerate node 10.10.102.65-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 28 05:21:51.800: INFO: Number of nodes with available pods: 0
Dec 28 05:21:51.800: INFO: Node 10.10.102.66-slave is running more than one daemon pod
Dec 28 05:21:52.792: INFO: DaemonSet pods can't tolerate node 10.10.102.65-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 28 05:21:52.798: INFO: Number of nodes with available pods: 0
Dec 28 05:21:52.798: INFO: Node 10.10.102.66-slave is running more than one daemon pod
Dec 28 05:21:53.818: INFO: DaemonSet pods can't tolerate node 10.10.102.65-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 28 05:21:53.840: INFO: Number of nodes with available pods: 0
Dec 28 05:21:53.841: INFO: Node 10.10.102.66-slave is running more than one daemon pod
Dec 28 05:21:54.797: INFO: DaemonSet pods can't tolerate node 10.10.102.65-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 28 05:21:54.806: INFO: Number of nodes with available pods: 0
Dec 28 05:21:54.806: INFO: Node 10.10.102.66-slave is running more than one daemon pod
Dec 28 05:21:55.794: INFO: DaemonSet pods can't tolerate node 10.10.102.65-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 28 05:21:55.801: INFO: Number of nodes with available pods: 0
Dec 28 05:21:55.801: INFO: Node 10.10.102.66-slave is running more than one daemon pod
Dec 28 05:21:56.828: INFO: DaemonSet pods can't tolerate node 10.10.102.65-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 28 05:21:56.838: INFO: Number of nodes with available pods: 0
Dec 28 05:21:56.838: INFO: Node 10.10.102.66-slave is running more than one daemon pod
Dec 28 05:21:57.794: INFO: DaemonSet pods can't tolerate node 10.10.102.65-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 28 05:21:57.801: INFO: Number of nodes with available pods: 0
Dec 28 05:21:57.801: INFO: Node 10.10.102.66-slave is running more than one daemon pod
Dec 28 05:21:58.793: INFO: DaemonSet pods can't tolerate node 10.10.102.65-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 28 05:21:58.802: INFO: Number of nodes with available pods: 1
Dec 28 05:21:58.802: INFO: Node 10.10.102.66-slave is running more than one daemon pod
Dec 28 05:21:59.793: INFO: DaemonSet pods can't tolerate node 10.10.102.65-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 28 05:21:59.800: INFO: Number of nodes with available pods: 4
Dec 28 05:21:59.800: INFO: Number of running nodes: 4, number of available pods: 4
STEP: Update daemon pods image.
STEP: Check that daemon pods images are updated.
Dec 28 05:22:00.001: INFO: Wrong image for pod: daemon-set-6m2s8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:22:00.001: INFO: Wrong image for pod: daemon-set-8kdnf. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:22:00.001: INFO: Wrong image for pod: daemon-set-dphp9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:22:00.001: INFO: Wrong image for pod: daemon-set-r7r94. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:22:00.013: INFO: DaemonSet pods can't tolerate node 10.10.102.65-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 28 05:22:01.022: INFO: Wrong image for pod: daemon-set-6m2s8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:22:01.022: INFO: Wrong image for pod: daemon-set-8kdnf. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:22:01.022: INFO: Wrong image for pod: daemon-set-dphp9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:22:01.022: INFO: Wrong image for pod: daemon-set-r7r94. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:22:01.032: INFO: DaemonSet pods can't tolerate node 10.10.102.65-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 28 05:22:02.021: INFO: Wrong image for pod: daemon-set-6m2s8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:22:02.021: INFO: Wrong image for pod: daemon-set-8kdnf. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:22:02.021: INFO: Wrong image for pod: daemon-set-dphp9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:22:02.021: INFO: Wrong image for pod: daemon-set-r7r94. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:22:02.030: INFO: DaemonSet pods can't tolerate node 10.10.102.65-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 28 05:22:03.022: INFO: Wrong image for pod: daemon-set-6m2s8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:22:03.022: INFO: Wrong image for pod: daemon-set-8kdnf. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:22:03.022: INFO: Wrong image for pod: daemon-set-dphp9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:22:03.022: INFO: Wrong image for pod: daemon-set-r7r94. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:22:03.035: INFO: DaemonSet pods can't tolerate node 10.10.102.65-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 28 05:22:04.021: INFO: Wrong image for pod: daemon-set-6m2s8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:22:04.021: INFO: Wrong image for pod: daemon-set-8kdnf. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:22:04.021: INFO: Wrong image for pod: daemon-set-dphp9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:22:04.021: INFO: Wrong image for pod: daemon-set-r7r94. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:22:04.032: INFO: DaemonSet pods can't tolerate node 10.10.102.65-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 28 05:22:05.104: INFO: Wrong image for pod: daemon-set-6m2s8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:22:05.104: INFO: Wrong image for pod: daemon-set-8kdnf. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:22:05.104: INFO: Wrong image for pod: daemon-set-dphp9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:22:05.104: INFO: Wrong image for pod: daemon-set-r7r94. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:22:05.116: INFO: DaemonSet pods can't tolerate node 10.10.102.65-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 28 05:22:06.022: INFO: Wrong image for pod: daemon-set-6m2s8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:22:06.023: INFO: Wrong image for pod: daemon-set-8kdnf. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:22:06.023: INFO: Wrong image for pod: daemon-set-dphp9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:22:06.023: INFO: Wrong image for pod: daemon-set-r7r94. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:22:06.031: INFO: DaemonSet pods can't tolerate node 10.10.102.65-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 28 05:22:07.021: INFO: Wrong image for pod: daemon-set-6m2s8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:22:07.021: INFO: Wrong image for pod: daemon-set-8kdnf. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:22:07.021: INFO: Wrong image for pod: daemon-set-dphp9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:22:07.021: INFO: Wrong image for pod: daemon-set-r7r94. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:22:07.031: INFO: DaemonSet pods can't tolerate node 10.10.102.65-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 28 05:22:08.022: INFO: Wrong image for pod: daemon-set-6m2s8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:22:08.022: INFO: Wrong image for pod: daemon-set-8kdnf. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:22:08.022: INFO: Wrong image for pod: daemon-set-dphp9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:22:08.022: INFO: Wrong image for pod: daemon-set-r7r94. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:22:08.032: INFO: DaemonSet pods can't tolerate node 10.10.102.65-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 28 05:22:09.027: INFO: Wrong image for pod: daemon-set-6m2s8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:22:09.028: INFO: Wrong image for pod: daemon-set-8kdnf. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:22:09.028: INFO: Wrong image for pod: daemon-set-dphp9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:22:09.028: INFO: Wrong image for pod: daemon-set-r7r94. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:22:09.042: INFO: DaemonSet pods can't tolerate node 10.10.102.65-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 28 05:22:10.022: INFO: Wrong image for pod: daemon-set-6m2s8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:22:10.022: INFO: Wrong image for pod: daemon-set-8kdnf. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:22:10.022: INFO: Wrong image for pod: daemon-set-dphp9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:22:10.022: INFO: Wrong image for pod: daemon-set-r7r94. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:22:10.033: INFO: DaemonSet pods can't tolerate node 10.10.102.65-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 28 05:22:11.021: INFO: Wrong image for pod: daemon-set-6m2s8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:22:11.021: INFO: Wrong image for pod: daemon-set-8kdnf. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:22:11.021: INFO: Wrong image for pod: daemon-set-dphp9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:22:11.021: INFO: Wrong image for pod: daemon-set-r7r94. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:22:11.072: INFO: DaemonSet pods can't tolerate node 10.10.102.65-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 28 05:22:12.022: INFO: Wrong image for pod: daemon-set-6m2s8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:22:12.022: INFO: Wrong image for pod: daemon-set-8kdnf. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:22:12.022: INFO: Wrong image for pod: daemon-set-dphp9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:22:12.022: INFO: Wrong image for pod: daemon-set-r7r94. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:22:12.031: INFO: DaemonSet pods can't tolerate node 10.10.102.65-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 28 05:22:13.021: INFO: Wrong image for pod: daemon-set-6m2s8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:22:13.021: INFO: Wrong image for pod: daemon-set-8kdnf. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:22:13.021: INFO: Wrong image for pod: daemon-set-dphp9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:22:13.021: INFO: Wrong image for pod: daemon-set-r7r94. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:22:13.030: INFO: DaemonSet pods can't tolerate node 10.10.102.65-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 28 05:22:14.021: INFO: Wrong image for pod: daemon-set-6m2s8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:22:14.021: INFO: Wrong image for pod: daemon-set-8kdnf. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:22:14.021: INFO: Wrong image for pod: daemon-set-dphp9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:22:14.021: INFO: Wrong image for pod: daemon-set-r7r94. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:22:14.032: INFO: DaemonSet pods can't tolerate node 10.10.102.65-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 28 05:22:15.021: INFO: Wrong image for pod: daemon-set-6m2s8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:22:15.021: INFO: Wrong image for pod: daemon-set-8kdnf. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:22:15.021: INFO: Wrong image for pod: daemon-set-dphp9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:22:15.021: INFO: Wrong image for pod: daemon-set-r7r94. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:22:15.039: INFO: DaemonSet pods can't tolerate node 10.10.102.65-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 28 05:22:16.022: INFO: Wrong image for pod: daemon-set-6m2s8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:22:16.022: INFO: Wrong image for pod: daemon-set-8kdnf. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:22:16.022: INFO: Wrong image for pod: daemon-set-dphp9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:22:16.022: INFO: Wrong image for pod: daemon-set-r7r94. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:22:16.034: INFO: DaemonSet pods can't tolerate node 10.10.102.65-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 28 05:22:17.043: INFO: Wrong image for pod: daemon-set-6m2s8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:22:17.043: INFO: Wrong image for pod: daemon-set-8kdnf. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:22:17.043: INFO: Wrong image for pod: daemon-set-dphp9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:22:17.043: INFO: Wrong image for pod: daemon-set-r7r94. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:22:17.053: INFO: DaemonSet pods can't tolerate node 10.10.102.65-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 28 05:22:18.021: INFO: Wrong image for pod: daemon-set-6m2s8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:22:18.021: INFO: Wrong image for pod: daemon-set-8kdnf. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:22:18.021: INFO: Wrong image for pod: daemon-set-dphp9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:22:18.021: INFO: Wrong image for pod: daemon-set-r7r94. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:22:18.031: INFO: DaemonSet pods can't tolerate node 10.10.102.65-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 28 05:22:19.022: INFO: Wrong image for pod: daemon-set-6m2s8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:22:19.022: INFO: Wrong image for pod: daemon-set-8kdnf. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:22:19.022: INFO: Wrong image for pod: daemon-set-dphp9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:22:19.022: INFO: Wrong image for pod: daemon-set-r7r94. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:22:19.043: INFO: DaemonSet pods can't tolerate node 10.10.102.65-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 28 05:22:20.021: INFO: Wrong image for pod: daemon-set-6m2s8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:22:20.022: INFO: Wrong image for pod: daemon-set-8kdnf. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:22:20.022: INFO: Wrong image for pod: daemon-set-dphp9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:22:20.022: INFO: Wrong image for pod: daemon-set-r7r94. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:22:20.031: INFO: DaemonSet pods can't tolerate node 10.10.102.65-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 28 05:22:21.021: INFO: Wrong image for pod: daemon-set-6m2s8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:22:21.021: INFO: Wrong image for pod: daemon-set-8kdnf. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:22:21.021: INFO: Wrong image for pod: daemon-set-dphp9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:22:21.021: INFO: Wrong image for pod: daemon-set-r7r94. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:22:21.033: INFO: DaemonSet pods can't tolerate node 10.10.102.65-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 28 05:22:22.020: INFO: Wrong image for pod: daemon-set-6m2s8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:22:22.021: INFO: Wrong image for pod: daemon-set-8kdnf. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:22:22.021: INFO: Wrong image for pod: daemon-set-dphp9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:22:22.021: INFO: Wrong image for pod: daemon-set-r7r94. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:22:22.031: INFO: DaemonSet pods can't tolerate node 10.10.102.65-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 28 05:22:23.021: INFO: Wrong image for pod: daemon-set-6m2s8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:22:23.021: INFO: Wrong image for pod: daemon-set-8kdnf. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:22:23.021: INFO: Wrong image for pod: daemon-set-dphp9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:22:23.021: INFO: Wrong image for pod: daemon-set-r7r94. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:22:23.030: INFO: DaemonSet pods can't tolerate node 10.10.102.65-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 28 05:22:24.022: INFO: Wrong image for pod: daemon-set-6m2s8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:22:24.022: INFO: Wrong image for pod: daemon-set-8kdnf. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:22:24.022: INFO: Wrong image for pod: daemon-set-dphp9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:22:24.022: INFO: Wrong image for pod: daemon-set-r7r94. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:22:24.033: INFO: DaemonSet pods can't tolerate node 10.10.102.65-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 28 05:22:25.021: INFO: Wrong image for pod: daemon-set-6m2s8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:22:25.021: INFO: Wrong image for pod: daemon-set-8kdnf. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:22:25.021: INFO: Wrong image for pod: daemon-set-dphp9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:22:25.021: INFO: Wrong image for pod: daemon-set-r7r94. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:22:25.031: INFO: DaemonSet pods can't tolerate node 10.10.102.65-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 28 05:22:26.022: INFO: Wrong image for pod: daemon-set-6m2s8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:22:26.022: INFO: Wrong image for pod: daemon-set-8kdnf. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:22:26.022: INFO: Wrong image for pod: daemon-set-dphp9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:22:26.022: INFO: Wrong image for pod: daemon-set-r7r94. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:22:26.033: INFO: DaemonSet pods can't tolerate node 10.10.102.65-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 28 05:22:27.021: INFO: Wrong image for pod: daemon-set-6m2s8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:22:27.022: INFO: Wrong image for pod: daemon-set-8kdnf. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:22:27.022: INFO: Wrong image for pod: daemon-set-dphp9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:22:27.022: INFO: Wrong image for pod: daemon-set-r7r94. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:22:27.032: INFO: DaemonSet pods can't tolerate node 10.10.102.65-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 28 05:22:28.021: INFO: Wrong image for pod: daemon-set-6m2s8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:22:28.021: INFO: Wrong image for pod: daemon-set-8kdnf. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:22:28.021: INFO: Wrong image for pod: daemon-set-dphp9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:22:28.021: INFO: Wrong image for pod: daemon-set-r7r94. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:22:28.031: INFO: DaemonSet pods can't tolerate node 10.10.102.65-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 28 05:22:29.112: INFO: Wrong image for pod: daemon-set-6m2s8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:22:29.112: INFO: Wrong image for pod: daemon-set-8kdnf. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:22:29.112: INFO: Wrong image for pod: daemon-set-dphp9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:22:29.112: INFO: Wrong image for pod: daemon-set-r7r94. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:22:29.130: INFO: DaemonSet pods can't tolerate node 10.10.102.65-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 28 05:22:30.021: INFO: Wrong image for pod: daemon-set-6m2s8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:22:30.021: INFO: Wrong image for pod: daemon-set-8kdnf. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:22:30.021: INFO: Wrong image for pod: daemon-set-dphp9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:22:30.021: INFO: Wrong image for pod: daemon-set-r7r94. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:22:30.029: INFO: DaemonSet pods can't tolerate node 10.10.102.65-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 28 05:22:31.022: INFO: Wrong image for pod: daemon-set-6m2s8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:22:31.022: INFO: Wrong image for pod: daemon-set-8kdnf. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:22:31.022: INFO: Wrong image for pod: daemon-set-dphp9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:22:31.022: INFO: Wrong image for pod: daemon-set-r7r94. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:22:31.032: INFO: DaemonSet pods can't tolerate node 10.10.102.65-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 28 05:22:32.038: INFO: Wrong image for pod: daemon-set-6m2s8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:22:32.038: INFO: Wrong image for pod: daemon-set-8kdnf. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:22:32.038: INFO: Wrong image for pod: daemon-set-dphp9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:22:32.038: INFO: Wrong image for pod: daemon-set-r7r94. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:22:32.064: INFO: DaemonSet pods can't tolerate node 10.10.102.65-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 28 05:22:33.021: INFO: Wrong image for pod: daemon-set-6m2s8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:22:33.021: INFO: Wrong image for pod: daemon-set-8kdnf. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:22:33.021: INFO: Wrong image for pod: daemon-set-dphp9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:22:33.021: INFO: Wrong image for pod: daemon-set-r7r94. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:22:33.029: INFO: DaemonSet pods can't tolerate node 10.10.102.65-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 28 05:22:34.021: INFO: Wrong image for pod: daemon-set-6m2s8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:22:34.021: INFO: Wrong image for pod: daemon-set-8kdnf. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:22:34.021: INFO: Pod daemon-set-8kdnf is not available
Dec 28 05:22:34.021: INFO: Wrong image for pod: daemon-set-dphp9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:22:34.021: INFO: Wrong image for pod: daemon-set-r7r94. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:22:34.031: INFO: DaemonSet pods can't tolerate node 10.10.102.65-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 28 05:22:35.022: INFO: Wrong image for pod: daemon-set-6m2s8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:22:35.022: INFO: Wrong image for pod: daemon-set-8kdnf. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:22:35.022: INFO: Pod daemon-set-8kdnf is not available
Dec 28 05:22:35.022: INFO: Wrong image for pod: daemon-set-dphp9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:22:35.022: INFO: Wrong image for pod: daemon-set-r7r94. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:22:35.031: INFO: DaemonSet pods can't tolerate node 10.10.102.65-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 28 05:22:36.021: INFO: Wrong image for pod: daemon-set-6m2s8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:22:36.021: INFO: Wrong image for pod: daemon-set-8kdnf. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:22:36.021: INFO: Pod daemon-set-8kdnf is not available
Dec 28 05:22:36.022: INFO: Wrong image for pod: daemon-set-dphp9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:22:36.022: INFO: Wrong image for pod: daemon-set-r7r94. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:22:36.032: INFO: DaemonSet pods can't tolerate node 10.10.102.65-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 28 05:22:37.026: INFO: Wrong image for pod: daemon-set-6m2s8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:22:37.027: INFO: Wrong image for pod: daemon-set-8kdnf. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:22:37.027: INFO: Pod daemon-set-8kdnf is not available
Dec 28 05:22:37.027: INFO: Wrong image for pod: daemon-set-dphp9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:22:37.027: INFO: Wrong image for pod: daemon-set-r7r94. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:22:37.036: INFO: DaemonSet pods can't tolerate node 10.10.102.65-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 28 05:22:38.021: INFO: Wrong image for pod: daemon-set-6m2s8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:22:38.021: INFO: Wrong image for pod: daemon-set-8kdnf. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:22:38.021: INFO: Pod daemon-set-8kdnf is not available
Dec 28 05:22:38.021: INFO: Wrong image for pod: daemon-set-dphp9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:22:38.021: INFO: Wrong image for pod: daemon-set-r7r94. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:22:38.031: INFO: DaemonSet pods can't tolerate node 10.10.102.65-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 28 05:22:39.020: INFO: Wrong image for pod: daemon-set-6m2s8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:22:39.021: INFO: Wrong image for pod: daemon-set-8kdnf. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:22:39.021: INFO: Pod daemon-set-8kdnf is not available
Dec 28 05:22:39.021: INFO: Wrong image for pod: daemon-set-dphp9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:22:39.021: INFO: Wrong image for pod: daemon-set-r7r94. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:22:39.029: INFO: DaemonSet pods can't tolerate node 10.10.102.65-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 28 05:22:40.021: INFO: Wrong image for pod: daemon-set-6m2s8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:22:40.021: INFO: Wrong image for pod: daemon-set-8kdnf. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:22:40.021: INFO: Pod daemon-set-8kdnf is not available
Dec 28 05:22:40.021: INFO: Wrong image for pod: daemon-set-dphp9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:22:40.021: INFO: Wrong image for pod: daemon-set-r7r94. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:22:40.030: INFO: DaemonSet pods can't tolerate node 10.10.102.65-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 28 05:22:41.111: INFO: Wrong image for pod: daemon-set-6m2s8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:22:41.111: INFO: Wrong image for pod: daemon-set-8kdnf. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:22:41.111: INFO: Pod daemon-set-8kdnf is not available
Dec 28 05:22:41.111: INFO: Wrong image for pod: daemon-set-dphp9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:22:41.111: INFO: Wrong image for pod: daemon-set-r7r94. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:22:41.121: INFO: DaemonSet pods can't tolerate node 10.10.102.65-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 28 05:22:42.021: INFO: Wrong image for pod: daemon-set-6m2s8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:22:42.021: INFO: Pod daemon-set-94pk6 is not available
Dec 28 05:22:42.021: INFO: Wrong image for pod: daemon-set-dphp9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:22:42.021: INFO: Wrong image for pod: daemon-set-r7r94. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:22:42.031: INFO: DaemonSet pods can't tolerate node 10.10.102.65-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 28 05:22:43.033: INFO: Wrong image for pod: daemon-set-6m2s8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:22:43.033: INFO: Pod daemon-set-94pk6 is not available
Dec 28 05:22:43.033: INFO: Wrong image for pod: daemon-set-dphp9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:22:43.033: INFO: Wrong image for pod: daemon-set-r7r94. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:22:43.042: INFO: DaemonSet pods can't tolerate node 10.10.102.65-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 28 05:22:44.022: INFO: Wrong image for pod: daemon-set-6m2s8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:22:44.022: INFO: Pod daemon-set-94pk6 is not available
Dec 28 05:22:44.022: INFO: Wrong image for pod: daemon-set-dphp9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:22:44.022: INFO: Wrong image for pod: daemon-set-r7r94. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:22:44.034: INFO: DaemonSet pods can't tolerate node 10.10.102.65-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 28 05:22:45.023: INFO: Wrong image for pod: daemon-set-6m2s8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:22:45.023: INFO: Pod daemon-set-94pk6 is not available
Dec 28 05:22:45.023: INFO: Wrong image for pod: daemon-set-dphp9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:22:45.023: INFO: Wrong image for pod: daemon-set-r7r94. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:22:45.034: INFO: DaemonSet pods can't tolerate node 10.10.102.65-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 28 05:22:46.023: INFO: Wrong image for pod: daemon-set-6m2s8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:22:46.023: INFO: Pod daemon-set-94pk6 is not available
Dec 28 05:22:46.023: INFO: Wrong image for pod: daemon-set-dphp9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:22:46.023: INFO: Wrong image for pod: daemon-set-r7r94. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:22:46.039: INFO: DaemonSet pods can't tolerate node 10.10.102.65-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 28 05:22:47.022: INFO: Wrong image for pod: daemon-set-6m2s8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:22:47.023: INFO: Pod daemon-set-94pk6 is not available
Dec 28 05:22:47.023: INFO: Wrong image for pod: daemon-set-dphp9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:22:47.023: INFO: Wrong image for pod: daemon-set-r7r94. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:22:47.032: INFO: DaemonSet pods can't tolerate node 10.10.102.65-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 28 05:22:48.065: INFO: Wrong image for pod: daemon-set-6m2s8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:22:48.065: INFO: Pod daemon-set-94pk6 is not available
Dec 28 05:22:48.065: INFO: Wrong image for pod: daemon-set-dphp9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:22:48.065: INFO: Wrong image for pod: daemon-set-r7r94. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:22:48.074: INFO: DaemonSet pods can't tolerate node 10.10.102.65-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 28 05:22:49.021: INFO: Wrong image for pod: daemon-set-6m2s8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:22:49.021: INFO: Wrong image for pod: daemon-set-dphp9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:22:49.021: INFO: Wrong image for pod: daemon-set-r7r94. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:22:49.031: INFO: DaemonSet pods can't tolerate node 10.10.102.65-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 28 05:22:50.021: INFO: Wrong image for pod: daemon-set-6m2s8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:22:50.021: INFO: Wrong image for pod: daemon-set-dphp9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:22:50.021: INFO: Wrong image for pod: daemon-set-r7r94. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:22:50.031: INFO: DaemonSet pods can't tolerate node 10.10.102.65-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 28 05:22:51.021: INFO: Wrong image for pod: daemon-set-6m2s8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:22:51.021: INFO: Wrong image for pod: daemon-set-dphp9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:22:51.021: INFO: Wrong image for pod: daemon-set-r7r94. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:22:51.035: INFO: DaemonSet pods can't tolerate node 10.10.102.65-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 28 05:22:52.024: INFO: Wrong image for pod: daemon-set-6m2s8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:22:52.024: INFO: Wrong image for pod: daemon-set-dphp9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:22:52.024: INFO: Wrong image for pod: daemon-set-r7r94. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:22:52.034: INFO: DaemonSet pods can't tolerate node 10.10.102.65-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 28 05:22:53.021: INFO: Wrong image for pod: daemon-set-6m2s8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:22:53.021: INFO: Wrong image for pod: daemon-set-dphp9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:22:53.021: INFO: Wrong image for pod: daemon-set-r7r94. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:22:53.031: INFO: DaemonSet pods can't tolerate node 10.10.102.65-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 28 05:22:54.022: INFO: Wrong image for pod: daemon-set-6m2s8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:22:54.022: INFO: Wrong image for pod: daemon-set-dphp9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:22:54.022: INFO: Wrong image for pod: daemon-set-r7r94. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:22:54.034: INFO: DaemonSet pods can't tolerate node 10.10.102.65-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 28 05:22:55.021: INFO: Wrong image for pod: daemon-set-6m2s8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:22:55.021: INFO: Wrong image for pod: daemon-set-dphp9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:22:55.021: INFO: Wrong image for pod: daemon-set-r7r94. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:22:55.031: INFO: DaemonSet pods can't tolerate node 10.10.102.65-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 28 05:22:56.021: INFO: Wrong image for pod: daemon-set-6m2s8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:22:56.021: INFO: Wrong image for pod: daemon-set-dphp9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:22:56.021: INFO: Wrong image for pod: daemon-set-r7r94. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:22:56.030: INFO: DaemonSet pods can't tolerate node 10.10.102.65-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 28 05:22:57.021: INFO: Wrong image for pod: daemon-set-6m2s8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:22:57.022: INFO: Wrong image for pod: daemon-set-dphp9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:22:57.022: INFO: Wrong image for pod: daemon-set-r7r94. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:22:57.031: INFO: DaemonSet pods can't tolerate node 10.10.102.65-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 28 05:22:58.020: INFO: Wrong image for pod: daemon-set-6m2s8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:22:58.020: INFO: Wrong image for pod: daemon-set-dphp9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:22:58.020: INFO: Wrong image for pod: daemon-set-r7r94. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:22:58.029: INFO: DaemonSet pods can't tolerate node 10.10.102.65-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 28 05:22:59.027: INFO: Wrong image for pod: daemon-set-6m2s8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:22:59.027: INFO: Wrong image for pod: daemon-set-dphp9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:22:59.027: INFO: Wrong image for pod: daemon-set-r7r94. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:22:59.039: INFO: DaemonSet pods can't tolerate node 10.10.102.65-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 28 05:23:00.022: INFO: Wrong image for pod: daemon-set-6m2s8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:23:00.022: INFO: Wrong image for pod: daemon-set-dphp9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:23:00.022: INFO: Wrong image for pod: daemon-set-r7r94. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:23:00.031: INFO: DaemonSet pods can't tolerate node 10.10.102.65-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 28 05:23:01.022: INFO: Wrong image for pod: daemon-set-6m2s8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:23:01.022: INFO: Wrong image for pod: daemon-set-dphp9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:23:01.022: INFO: Wrong image for pod: daemon-set-r7r94. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:23:01.032: INFO: DaemonSet pods can't tolerate node 10.10.102.65-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 28 05:23:02.023: INFO: Wrong image for pod: daemon-set-6m2s8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:23:02.023: INFO: Wrong image for pod: daemon-set-dphp9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:23:02.023: INFO: Wrong image for pod: daemon-set-r7r94. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:23:02.041: INFO: DaemonSet pods can't tolerate node 10.10.102.65-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 28 05:23:03.037: INFO: Wrong image for pod: daemon-set-6m2s8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:23:03.037: INFO: Wrong image for pod: daemon-set-dphp9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:23:03.037: INFO: Wrong image for pod: daemon-set-r7r94. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:23:03.054: INFO: DaemonSet pods can't tolerate node 10.10.102.65-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 28 05:23:04.132: INFO: Wrong image for pod: daemon-set-6m2s8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:23:04.132: INFO: Wrong image for pod: daemon-set-dphp9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:23:04.132: INFO: Wrong image for pod: daemon-set-r7r94. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:23:04.143: INFO: DaemonSet pods can't tolerate node 10.10.102.65-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 28 05:23:05.023: INFO: Wrong image for pod: daemon-set-6m2s8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:23:05.023: INFO: Wrong image for pod: daemon-set-dphp9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:23:05.023: INFO: Wrong image for pod: daemon-set-r7r94. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:23:05.032: INFO: DaemonSet pods can't tolerate node 10.10.102.65-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 28 05:23:06.022: INFO: Wrong image for pod: daemon-set-6m2s8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:23:06.022: INFO: Wrong image for pod: daemon-set-dphp9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:23:06.022: INFO: Wrong image for pod: daemon-set-r7r94. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:23:06.031: INFO: DaemonSet pods can't tolerate node 10.10.102.65-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 28 05:23:07.022: INFO: Wrong image for pod: daemon-set-6m2s8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:23:07.023: INFO: Wrong image for pod: daemon-set-dphp9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:23:07.023: INFO: Wrong image for pod: daemon-set-r7r94. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:23:07.033: INFO: DaemonSet pods can't tolerate node 10.10.102.65-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 28 05:23:08.022: INFO: Wrong image for pod: daemon-set-6m2s8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:23:08.022: INFO: Wrong image for pod: daemon-set-dphp9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:23:08.022: INFO: Wrong image for pod: daemon-set-r7r94. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:23:08.032: INFO: DaemonSet pods can't tolerate node 10.10.102.65-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 28 05:23:09.023: INFO: Wrong image for pod: daemon-set-6m2s8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:23:09.023: INFO: Wrong image for pod: daemon-set-dphp9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:23:09.023: INFO: Wrong image for pod: daemon-set-r7r94. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:23:09.034: INFO: DaemonSet pods can't tolerate node 10.10.102.65-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 28 05:23:10.021: INFO: Wrong image for pod: daemon-set-6m2s8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:23:10.021: INFO: Wrong image for pod: daemon-set-dphp9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:23:10.021: INFO: Wrong image for pod: daemon-set-r7r94. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:23:10.030: INFO: DaemonSet pods can't tolerate node 10.10.102.65-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 28 05:23:11.021: INFO: Wrong image for pod: daemon-set-6m2s8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:23:11.021: INFO: Wrong image for pod: daemon-set-dphp9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:23:11.021: INFO: Wrong image for pod: daemon-set-r7r94. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:23:11.033: INFO: DaemonSet pods can't tolerate node 10.10.102.65-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 28 05:23:12.021: INFO: Wrong image for pod: daemon-set-6m2s8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:23:12.021: INFO: Wrong image for pod: daemon-set-dphp9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:23:12.021: INFO: Wrong image for pod: daemon-set-r7r94. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:23:12.031: INFO: DaemonSet pods can't tolerate node 10.10.102.65-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 28 05:23:13.024: INFO: Wrong image for pod: daemon-set-6m2s8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:23:13.024: INFO: Wrong image for pod: daemon-set-dphp9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:23:13.024: INFO: Wrong image for pod: daemon-set-r7r94. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:23:13.034: INFO: DaemonSet pods can't tolerate node 10.10.102.65-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 28 05:23:14.021: INFO: Wrong image for pod: daemon-set-6m2s8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:23:14.021: INFO: Wrong image for pod: daemon-set-dphp9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:23:14.021: INFO: Wrong image for pod: daemon-set-r7r94. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:23:14.031: INFO: DaemonSet pods can't tolerate node 10.10.102.65-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 28 05:23:15.021: INFO: Wrong image for pod: daemon-set-6m2s8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:23:15.021: INFO: Wrong image for pod: daemon-set-dphp9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:23:15.021: INFO: Wrong image for pod: daemon-set-r7r94. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:23:15.030: INFO: DaemonSet pods can't tolerate node 10.10.102.65-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 28 05:23:16.021: INFO: Wrong image for pod: daemon-set-6m2s8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:23:16.021: INFO: Wrong image for pod: daemon-set-dphp9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:23:16.021: INFO: Wrong image for pod: daemon-set-r7r94. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:23:16.030: INFO: DaemonSet pods can't tolerate node 10.10.102.65-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 28 05:23:17.021: INFO: Wrong image for pod: daemon-set-6m2s8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:23:17.021: INFO: Wrong image for pod: daemon-set-dphp9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:23:17.021: INFO: Wrong image for pod: daemon-set-r7r94. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:23:17.031: INFO: DaemonSet pods can't tolerate node 10.10.102.65-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 28 05:23:18.020: INFO: Wrong image for pod: daemon-set-6m2s8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:23:18.020: INFO: Wrong image for pod: daemon-set-dphp9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:23:18.020: INFO: Wrong image for pod: daemon-set-r7r94. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:23:18.032: INFO: DaemonSet pods can't tolerate node 10.10.102.65-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 28 05:23:19.035: INFO: Wrong image for pod: daemon-set-6m2s8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:23:19.035: INFO: Wrong image for pod: daemon-set-dphp9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:23:19.035: INFO: Wrong image for pod: daemon-set-r7r94. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:23:19.045: INFO: DaemonSet pods can't tolerate node 10.10.102.65-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 28 05:23:20.021: INFO: Wrong image for pod: daemon-set-6m2s8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:23:20.021: INFO: Pod daemon-set-6m2s8 is not available
Dec 28 05:23:20.021: INFO: Wrong image for pod: daemon-set-dphp9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:23:20.021: INFO: Wrong image for pod: daemon-set-r7r94. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:23:20.030: INFO: DaemonSet pods can't tolerate node 10.10.102.65-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 28 05:23:21.023: INFO: Wrong image for pod: daemon-set-6m2s8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:23:21.023: INFO: Pod daemon-set-6m2s8 is not available
Dec 28 05:23:21.023: INFO: Wrong image for pod: daemon-set-dphp9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:23:21.023: INFO: Wrong image for pod: daemon-set-r7r94. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:23:21.033: INFO: DaemonSet pods can't tolerate node 10.10.102.65-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 28 05:23:22.026: INFO: Wrong image for pod: daemon-set-6m2s8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:23:22.027: INFO: Pod daemon-set-6m2s8 is not available
Dec 28 05:23:22.027: INFO: Wrong image for pod: daemon-set-dphp9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:23:22.027: INFO: Wrong image for pod: daemon-set-r7r94. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:23:22.037: INFO: DaemonSet pods can't tolerate node 10.10.102.65-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 28 05:23:23.021: INFO: Wrong image for pod: daemon-set-6m2s8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:23:23.021: INFO: Pod daemon-set-6m2s8 is not available
Dec 28 05:23:23.021: INFO: Wrong image for pod: daemon-set-dphp9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:23:23.021: INFO: Wrong image for pod: daemon-set-r7r94. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:23:23.031: INFO: DaemonSet pods can't tolerate node 10.10.102.65-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 28 05:23:24.021: INFO: Wrong image for pod: daemon-set-6m2s8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:23:24.021: INFO: Pod daemon-set-6m2s8 is not available
Dec 28 05:23:24.021: INFO: Wrong image for pod: daemon-set-dphp9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:23:24.021: INFO: Wrong image for pod: daemon-set-r7r94. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:23:24.032: INFO: DaemonSet pods can't tolerate node 10.10.102.65-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 28 05:23:25.021: INFO: Wrong image for pod: daemon-set-6m2s8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:23:25.022: INFO: Pod daemon-set-6m2s8 is not available
Dec 28 05:23:25.022: INFO: Wrong image for pod: daemon-set-dphp9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:23:25.022: INFO: Wrong image for pod: daemon-set-r7r94. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:23:25.031: INFO: DaemonSet pods can't tolerate node 10.10.102.65-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 28 05:23:26.021: INFO: Wrong image for pod: daemon-set-6m2s8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:23:26.021: INFO: Pod daemon-set-6m2s8 is not available
Dec 28 05:23:26.021: INFO: Wrong image for pod: daemon-set-dphp9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:23:26.021: INFO: Wrong image for pod: daemon-set-r7r94. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:23:26.032: INFO: DaemonSet pods can't tolerate node 10.10.102.65-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 28 05:23:27.023: INFO: Wrong image for pod: daemon-set-6m2s8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:23:27.023: INFO: Pod daemon-set-6m2s8 is not available
Dec 28 05:23:27.023: INFO: Wrong image for pod: daemon-set-dphp9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:23:27.023: INFO: Wrong image for pod: daemon-set-r7r94. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:23:27.032: INFO: DaemonSet pods can't tolerate node 10.10.102.65-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 28 05:23:28.021: INFO: Wrong image for pod: daemon-set-6m2s8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:23:28.021: INFO: Pod daemon-set-6m2s8 is not available
Dec 28 05:23:28.021: INFO: Wrong image for pod: daemon-set-dphp9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:23:28.021: INFO: Wrong image for pod: daemon-set-r7r94. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:23:28.030: INFO: DaemonSet pods can't tolerate node 10.10.102.65-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 28 05:23:29.022: INFO: Wrong image for pod: daemon-set-6m2s8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:23:29.022: INFO: Pod daemon-set-6m2s8 is not available
Dec 28 05:23:29.022: INFO: Wrong image for pod: daemon-set-dphp9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:23:29.022: INFO: Wrong image for pod: daemon-set-r7r94. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:23:29.034: INFO: DaemonSet pods can't tolerate node 10.10.102.65-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 28 05:23:30.021: INFO: Wrong image for pod: daemon-set-6m2s8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:23:30.021: INFO: Pod daemon-set-6m2s8 is not available
Dec 28 05:23:30.021: INFO: Wrong image for pod: daemon-set-dphp9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:23:30.021: INFO: Wrong image for pod: daemon-set-r7r94. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:23:30.030: INFO: DaemonSet pods can't tolerate node 10.10.102.65-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 28 05:23:31.082: INFO: Pod daemon-set-8q9qd is not available
Dec 28 05:23:31.083: INFO: Wrong image for pod: daemon-set-dphp9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:23:31.083: INFO: Wrong image for pod: daemon-set-r7r94. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:23:31.095: INFO: DaemonSet pods can't tolerate node 10.10.102.65-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 28 05:23:32.021: INFO: Pod daemon-set-8q9qd is not available
Dec 28 05:23:32.021: INFO: Wrong image for pod: daemon-set-dphp9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:23:32.021: INFO: Wrong image for pod: daemon-set-r7r94. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:23:32.041: INFO: DaemonSet pods can't tolerate node 10.10.102.65-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 28 05:23:33.022: INFO: Pod daemon-set-8q9qd is not available
Dec 28 05:23:33.022: INFO: Wrong image for pod: daemon-set-dphp9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:23:33.023: INFO: Wrong image for pod: daemon-set-r7r94. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:23:33.032: INFO: DaemonSet pods can't tolerate node 10.10.102.65-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 28 05:23:34.021: INFO: Pod daemon-set-8q9qd is not available
Dec 28 05:23:34.021: INFO: Wrong image for pod: daemon-set-dphp9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:23:34.021: INFO: Wrong image for pod: daemon-set-r7r94. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:23:34.034: INFO: DaemonSet pods can't tolerate node 10.10.102.65-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 28 05:23:35.029: INFO: Pod daemon-set-8q9qd is not available
Dec 28 05:23:35.029: INFO: Wrong image for pod: daemon-set-dphp9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:23:35.029: INFO: Wrong image for pod: daemon-set-r7r94. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:23:35.039: INFO: DaemonSet pods can't tolerate node 10.10.102.65-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 28 05:23:36.021: INFO: Pod daemon-set-8q9qd is not available
Dec 28 05:23:36.021: INFO: Wrong image for pod: daemon-set-dphp9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:23:36.021: INFO: Wrong image for pod: daemon-set-r7r94. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:23:36.030: INFO: DaemonSet pods can't tolerate node 10.10.102.65-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 28 05:23:37.023: INFO: Pod daemon-set-8q9qd is not available
Dec 28 05:23:37.023: INFO: Wrong image for pod: daemon-set-dphp9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:23:37.023: INFO: Wrong image for pod: daemon-set-r7r94. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:23:37.033: INFO: DaemonSet pods can't tolerate node 10.10.102.65-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 28 05:23:38.021: INFO: Wrong image for pod: daemon-set-dphp9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:23:38.021: INFO: Wrong image for pod: daemon-set-r7r94. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:23:38.030: INFO: DaemonSet pods can't tolerate node 10.10.102.65-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 28 05:23:39.040: INFO: Wrong image for pod: daemon-set-dphp9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:23:39.040: INFO: Wrong image for pod: daemon-set-r7r94. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:23:39.049: INFO: DaemonSet pods can't tolerate node 10.10.102.65-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 28 05:23:40.022: INFO: Wrong image for pod: daemon-set-dphp9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:23:40.023: INFO: Wrong image for pod: daemon-set-r7r94. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:23:40.031: INFO: DaemonSet pods can't tolerate node 10.10.102.65-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 28 05:23:41.021: INFO: Wrong image for pod: daemon-set-dphp9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:23:41.021: INFO: Wrong image for pod: daemon-set-r7r94. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:23:41.031: INFO: DaemonSet pods can't tolerate node 10.10.102.65-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 28 05:23:42.024: INFO: Wrong image for pod: daemon-set-dphp9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:23:42.024: INFO: Wrong image for pod: daemon-set-r7r94. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:23:42.035: INFO: DaemonSet pods can't tolerate node 10.10.102.65-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 28 05:23:43.021: INFO: Wrong image for pod: daemon-set-dphp9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:23:43.021: INFO: Wrong image for pod: daemon-set-r7r94. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:23:43.030: INFO: DaemonSet pods can't tolerate node 10.10.102.65-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 28 05:23:44.026: INFO: Wrong image for pod: daemon-set-dphp9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:23:44.026: INFO: Wrong image for pod: daemon-set-r7r94. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:23:44.038: INFO: DaemonSet pods can't tolerate node 10.10.102.65-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 28 05:23:45.022: INFO: Wrong image for pod: daemon-set-dphp9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:23:45.022: INFO: Wrong image for pod: daemon-set-r7r94. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:23:45.033: INFO: DaemonSet pods can't tolerate node 10.10.102.65-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 28 05:23:46.057: INFO: Wrong image for pod: daemon-set-dphp9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:23:46.057: INFO: Wrong image for pod: daemon-set-r7r94. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:23:46.068: INFO: DaemonSet pods can't tolerate node 10.10.102.65-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 28 05:23:47.021: INFO: Wrong image for pod: daemon-set-dphp9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:23:47.021: INFO: Wrong image for pod: daemon-set-r7r94. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:23:47.030: INFO: DaemonSet pods can't tolerate node 10.10.102.65-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 28 05:23:48.021: INFO: Wrong image for pod: daemon-set-dphp9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:23:48.021: INFO: Wrong image for pod: daemon-set-r7r94. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:23:48.030: INFO: DaemonSet pods can't tolerate node 10.10.102.65-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 28 05:23:49.028: INFO: Wrong image for pod: daemon-set-dphp9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:23:49.028: INFO: Wrong image for pod: daemon-set-r7r94. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:23:49.038: INFO: DaemonSet pods can't tolerate node 10.10.102.65-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 28 05:23:50.026: INFO: Wrong image for pod: daemon-set-dphp9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:23:50.027: INFO: Wrong image for pod: daemon-set-r7r94. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:23:50.038: INFO: DaemonSet pods can't tolerate node 10.10.102.65-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 28 05:23:51.023: INFO: Wrong image for pod: daemon-set-dphp9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:23:51.023: INFO: Wrong image for pod: daemon-set-r7r94. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:23:51.033: INFO: DaemonSet pods can't tolerate node 10.10.102.65-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 28 05:23:52.024: INFO: Wrong image for pod: daemon-set-dphp9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:23:52.024: INFO: Wrong image for pod: daemon-set-r7r94. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:23:52.036: INFO: DaemonSet pods can't tolerate node 10.10.102.65-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 28 05:23:53.026: INFO: Wrong image for pod: daemon-set-dphp9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:23:53.026: INFO: Wrong image for pod: daemon-set-r7r94. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:23:53.037: INFO: DaemonSet pods can't tolerate node 10.10.102.65-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 28 05:23:54.094: INFO: Wrong image for pod: daemon-set-dphp9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:23:54.094: INFO: Wrong image for pod: daemon-set-r7r94. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:23:54.104: INFO: DaemonSet pods can't tolerate node 10.10.102.65-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 28 05:23:55.021: INFO: Wrong image for pod: daemon-set-dphp9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:23:55.021: INFO: Wrong image for pod: daemon-set-r7r94. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:23:55.032: INFO: DaemonSet pods can't tolerate node 10.10.102.65-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 28 05:23:56.060: INFO: Wrong image for pod: daemon-set-dphp9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:23:56.060: INFO: Wrong image for pod: daemon-set-r7r94. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:23:56.081: INFO: DaemonSet pods can't tolerate node 10.10.102.65-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 28 05:23:57.020: INFO: Wrong image for pod: daemon-set-dphp9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:23:57.020: INFO: Wrong image for pod: daemon-set-r7r94. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:23:57.042: INFO: DaemonSet pods can't tolerate node 10.10.102.65-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 28 05:23:58.173: INFO: Wrong image for pod: daemon-set-dphp9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:23:58.173: INFO: Wrong image for pod: daemon-set-r7r94. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:23:58.186: INFO: DaemonSet pods can't tolerate node 10.10.102.65-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 28 05:23:59.022: INFO: Wrong image for pod: daemon-set-dphp9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:23:59.022: INFO: Wrong image for pod: daemon-set-r7r94. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:23:59.034: INFO: DaemonSet pods can't tolerate node 10.10.102.65-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 28 05:24:00.020: INFO: Wrong image for pod: daemon-set-dphp9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:24:00.020: INFO: Wrong image for pod: daemon-set-r7r94. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:24:00.030: INFO: DaemonSet pods can't tolerate node 10.10.102.65-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 28 05:24:01.023: INFO: Wrong image for pod: daemon-set-dphp9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:24:01.023: INFO: Wrong image for pod: daemon-set-r7r94. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:24:01.033: INFO: DaemonSet pods can't tolerate node 10.10.102.65-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 28 05:24:02.021: INFO: Wrong image for pod: daemon-set-dphp9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:24:02.021: INFO: Wrong image for pod: daemon-set-r7r94. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:24:02.032: INFO: DaemonSet pods can't tolerate node 10.10.102.65-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 28 05:24:03.021: INFO: Wrong image for pod: daemon-set-dphp9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:24:03.021: INFO: Wrong image for pod: daemon-set-r7r94. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:24:03.031: INFO: DaemonSet pods can't tolerate node 10.10.102.65-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 28 05:24:04.020: INFO: Wrong image for pod: daemon-set-dphp9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:24:04.020: INFO: Wrong image for pod: daemon-set-r7r94. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:24:04.030: INFO: DaemonSet pods can't tolerate node 10.10.102.65-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 28 05:24:05.022: INFO: Wrong image for pod: daemon-set-dphp9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:24:05.022: INFO: Wrong image for pod: daemon-set-r7r94. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:24:05.032: INFO: DaemonSet pods can't tolerate node 10.10.102.65-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 28 05:24:06.021: INFO: Wrong image for pod: daemon-set-dphp9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:24:06.021: INFO: Wrong image for pod: daemon-set-r7r94. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:24:06.031: INFO: DaemonSet pods can't tolerate node 10.10.102.65-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 28 05:24:07.022: INFO: Wrong image for pod: daemon-set-dphp9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:24:07.022: INFO: Wrong image for pod: daemon-set-r7r94. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:24:07.032: INFO: DaemonSet pods can't tolerate node 10.10.102.65-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 28 05:24:08.085: INFO: Wrong image for pod: daemon-set-dphp9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:24:08.085: INFO: Wrong image for pod: daemon-set-r7r94. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:24:08.098: INFO: DaemonSet pods can't tolerate node 10.10.102.65-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 28 05:24:09.027: INFO: Wrong image for pod: daemon-set-dphp9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:24:09.027: INFO: Wrong image for pod: daemon-set-r7r94. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:24:09.027: INFO: Pod daemon-set-r7r94 is not available
Dec 28 05:24:09.040: INFO: DaemonSet pods can't tolerate node 10.10.102.65-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 28 05:24:10.021: INFO: Wrong image for pod: daemon-set-dphp9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:24:10.021: INFO: Wrong image for pod: daemon-set-r7r94. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:24:10.021: INFO: Pod daemon-set-r7r94 is not available
Dec 28 05:24:10.030: INFO: DaemonSet pods can't tolerate node 10.10.102.65-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 28 05:24:11.021: INFO: Wrong image for pod: daemon-set-dphp9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:24:11.021: INFO: Wrong image for pod: daemon-set-r7r94. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:24:11.021: INFO: Pod daemon-set-r7r94 is not available
Dec 28 05:24:11.032: INFO: DaemonSet pods can't tolerate node 10.10.102.65-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 28 05:24:12.022: INFO: Wrong image for pod: daemon-set-dphp9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:24:12.022: INFO: Wrong image for pod: daemon-set-r7r94. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:24:12.022: INFO: Pod daemon-set-r7r94 is not available
Dec 28 05:24:12.032: INFO: DaemonSet pods can't tolerate node 10.10.102.65-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 28 05:24:13.021: INFO: Wrong image for pod: daemon-set-dphp9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:24:13.021: INFO: Wrong image for pod: daemon-set-r7r94. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:24:13.021: INFO: Pod daemon-set-r7r94 is not available
Dec 28 05:24:13.031: INFO: DaemonSet pods can't tolerate node 10.10.102.65-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 28 05:24:14.021: INFO: Pod daemon-set-6rgqw is not available
Dec 28 05:24:14.021: INFO: Wrong image for pod: daemon-set-dphp9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:24:14.033: INFO: DaemonSet pods can't tolerate node 10.10.102.65-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 28 05:24:15.021: INFO: Pod daemon-set-6rgqw is not available
Dec 28 05:24:15.021: INFO: Wrong image for pod: daemon-set-dphp9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:24:15.032: INFO: DaemonSet pods can't tolerate node 10.10.102.65-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 28 05:24:16.021: INFO: Pod daemon-set-6rgqw is not available
Dec 28 05:24:16.021: INFO: Wrong image for pod: daemon-set-dphp9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:24:16.032: INFO: DaemonSet pods can't tolerate node 10.10.102.65-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 28 05:24:17.031: INFO: Pod daemon-set-6rgqw is not available
Dec 28 05:24:17.031: INFO: Wrong image for pod: daemon-set-dphp9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:24:17.092: INFO: DaemonSet pods can't tolerate node 10.10.102.65-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 28 05:24:18.021: INFO: Pod daemon-set-6rgqw is not available
Dec 28 05:24:18.021: INFO: Wrong image for pod: daemon-set-dphp9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:24:18.032: INFO: DaemonSet pods can't tolerate node 10.10.102.65-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 28 05:24:19.022: INFO: Pod daemon-set-6rgqw is not available
Dec 28 05:24:19.022: INFO: Wrong image for pod: daemon-set-dphp9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:24:19.050: INFO: DaemonSet pods can't tolerate node 10.10.102.65-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 28 05:24:20.047: INFO: Wrong image for pod: daemon-set-dphp9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:24:20.057: INFO: DaemonSet pods can't tolerate node 10.10.102.65-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 28 05:24:21.021: INFO: Wrong image for pod: daemon-set-dphp9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:24:21.033: INFO: DaemonSet pods can't tolerate node 10.10.102.65-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 28 05:24:22.021: INFO: Wrong image for pod: daemon-set-dphp9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:24:22.031: INFO: DaemonSet pods can't tolerate node 10.10.102.65-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 28 05:24:23.022: INFO: Wrong image for pod: daemon-set-dphp9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:24:23.033: INFO: DaemonSet pods can't tolerate node 10.10.102.65-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 28 05:24:24.022: INFO: Wrong image for pod: daemon-set-dphp9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:24:24.032: INFO: DaemonSet pods can't tolerate node 10.10.102.65-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 28 05:24:25.024: INFO: Wrong image for pod: daemon-set-dphp9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:24:25.035: INFO: DaemonSet pods can't tolerate node 10.10.102.65-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 28 05:24:26.057: INFO: Wrong image for pod: daemon-set-dphp9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:24:26.068: INFO: DaemonSet pods can't tolerate node 10.10.102.65-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 28 05:24:27.021: INFO: Wrong image for pod: daemon-set-dphp9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:24:27.032: INFO: DaemonSet pods can't tolerate node 10.10.102.65-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 28 05:24:28.034: INFO: Wrong image for pod: daemon-set-dphp9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:24:28.045: INFO: DaemonSet pods can't tolerate node 10.10.102.65-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 28 05:24:29.045: INFO: Wrong image for pod: daemon-set-dphp9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:24:29.056: INFO: DaemonSet pods can't tolerate node 10.10.102.65-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 28 05:24:30.033: INFO: Wrong image for pod: daemon-set-dphp9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:24:30.042: INFO: DaemonSet pods can't tolerate node 10.10.102.65-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 28 05:24:31.022: INFO: Wrong image for pod: daemon-set-dphp9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:24:31.032: INFO: DaemonSet pods can't tolerate node 10.10.102.65-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 28 05:24:32.064: INFO: Wrong image for pod: daemon-set-dphp9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:24:32.075: INFO: DaemonSet pods can't tolerate node 10.10.102.65-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 28 05:24:33.021: INFO: Wrong image for pod: daemon-set-dphp9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:24:33.029: INFO: DaemonSet pods can't tolerate node 10.10.102.65-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 28 05:24:34.021: INFO: Wrong image for pod: daemon-set-dphp9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:24:34.034: INFO: DaemonSet pods can't tolerate node 10.10.102.65-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 28 05:24:35.022: INFO: Wrong image for pod: daemon-set-dphp9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:24:35.033: INFO: DaemonSet pods can't tolerate node 10.10.102.65-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 28 05:24:36.021: INFO: Wrong image for pod: daemon-set-dphp9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:24:36.031: INFO: DaemonSet pods can't tolerate node 10.10.102.65-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 28 05:24:37.022: INFO: Wrong image for pod: daemon-set-dphp9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:24:37.032: INFO: DaemonSet pods can't tolerate node 10.10.102.65-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 28 05:24:38.021: INFO: Wrong image for pod: daemon-set-dphp9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:24:38.037: INFO: DaemonSet pods can't tolerate node 10.10.102.65-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 28 05:24:39.022: INFO: Wrong image for pod: daemon-set-dphp9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:24:39.034: INFO: DaemonSet pods can't tolerate node 10.10.102.65-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 28 05:24:40.021: INFO: Wrong image for pod: daemon-set-dphp9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:24:40.031: INFO: DaemonSet pods can't tolerate node 10.10.102.65-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 28 05:24:41.022: INFO: Wrong image for pod: daemon-set-dphp9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:24:41.032: INFO: DaemonSet pods can't tolerate node 10.10.102.65-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 28 05:24:42.024: INFO: Wrong image for pod: daemon-set-dphp9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:24:42.036: INFO: DaemonSet pods can't tolerate node 10.10.102.65-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 28 05:24:43.028: INFO: Wrong image for pod: daemon-set-dphp9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:24:43.041: INFO: DaemonSet pods can't tolerate node 10.10.102.65-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 28 05:24:44.026: INFO: Wrong image for pod: daemon-set-dphp9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:24:44.034: INFO: DaemonSet pods can't tolerate node 10.10.102.65-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 28 05:24:45.026: INFO: Wrong image for pod: daemon-set-dphp9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:24:45.036: INFO: DaemonSet pods can't tolerate node 10.10.102.65-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 28 05:24:46.025: INFO: Wrong image for pod: daemon-set-dphp9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:24:46.035: INFO: DaemonSet pods can't tolerate node 10.10.102.65-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 28 05:24:47.022: INFO: Wrong image for pod: daemon-set-dphp9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:24:47.041: INFO: DaemonSet pods can't tolerate node 10.10.102.65-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 28 05:24:48.023: INFO: Wrong image for pod: daemon-set-dphp9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:24:48.032: INFO: DaemonSet pods can't tolerate node 10.10.102.65-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 28 05:24:49.024: INFO: Wrong image for pod: daemon-set-dphp9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:24:49.036: INFO: DaemonSet pods can't tolerate node 10.10.102.65-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 28 05:24:50.026: INFO: Wrong image for pod: daemon-set-dphp9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:24:50.036: INFO: DaemonSet pods can't tolerate node 10.10.102.65-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 28 05:24:51.027: INFO: Wrong image for pod: daemon-set-dphp9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:24:51.038: INFO: DaemonSet pods can't tolerate node 10.10.102.65-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 28 05:24:52.029: INFO: Wrong image for pod: daemon-set-dphp9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:24:52.029: INFO: Pod daemon-set-dphp9 is not available
Dec 28 05:24:52.041: INFO: DaemonSet pods can't tolerate node 10.10.102.65-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 28 05:24:53.020: INFO: Wrong image for pod: daemon-set-dphp9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:24:53.021: INFO: Pod daemon-set-dphp9 is not available
Dec 28 05:24:53.032: INFO: DaemonSet pods can't tolerate node 10.10.102.65-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 28 05:24:54.020: INFO: Wrong image for pod: daemon-set-dphp9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:24:54.020: INFO: Pod daemon-set-dphp9 is not available
Dec 28 05:24:54.033: INFO: DaemonSet pods can't tolerate node 10.10.102.65-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 28 05:24:55.022: INFO: Wrong image for pod: daemon-set-dphp9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:24:55.022: INFO: Pod daemon-set-dphp9 is not available
Dec 28 05:24:55.035: INFO: DaemonSet pods can't tolerate node 10.10.102.65-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 28 05:24:56.034: INFO: Wrong image for pod: daemon-set-dphp9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:24:56.034: INFO: Pod daemon-set-dphp9 is not available
Dec 28 05:24:56.044: INFO: DaemonSet pods can't tolerate node 10.10.102.65-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 28 05:24:57.021: INFO: Wrong image for pod: daemon-set-dphp9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Dec 28 05:24:57.021: INFO: Pod daemon-set-dphp9 is not available
Dec 28 05:24:57.040: INFO: DaemonSet pods can't tolerate node 10.10.102.65-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 28 05:24:58.035: INFO: Pod daemon-set-pqmlv is not available
Dec 28 05:24:58.046: INFO: DaemonSet pods can't tolerate node 10.10.102.65-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
STEP: Check that daemon pods are still running on every node of the cluster.
Dec 28 05:24:58.056: INFO: DaemonSet pods can't tolerate node 10.10.102.65-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 28 05:24:58.062: INFO: Number of nodes with available pods: 3
Dec 28 05:24:58.062: INFO: Node 10.10.102.68-share is running more than one daemon pod
Dec 28 05:24:59.074: INFO: DaemonSet pods can't tolerate node 10.10.102.65-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 28 05:24:59.081: INFO: Number of nodes with available pods: 3
Dec 28 05:24:59.081: INFO: Node 10.10.102.68-share is running more than one daemon pod
Dec 28 05:25:00.074: INFO: DaemonSet pods can't tolerate node 10.10.102.65-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 28 05:25:00.082: INFO: Number of nodes with available pods: 3
Dec 28 05:25:00.082: INFO: Node 10.10.102.68-share is running more than one daemon pod
Dec 28 05:25:01.083: INFO: DaemonSet pods can't tolerate node 10.10.102.65-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 28 05:25:01.098: INFO: Number of nodes with available pods: 3
Dec 28 05:25:01.098: INFO: Node 10.10.102.68-share is running more than one daemon pod
Dec 28 05:25:02.077: INFO: DaemonSet pods can't tolerate node 10.10.102.65-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 28 05:25:02.084: INFO: Number of nodes with available pods: 3
Dec 28 05:25:02.084: INFO: Node 10.10.102.68-share is running more than one daemon pod
Dec 28 05:25:03.075: INFO: DaemonSet pods can't tolerate node 10.10.102.65-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 28 05:25:03.082: INFO: Number of nodes with available pods: 3
Dec 28 05:25:03.082: INFO: Node 10.10.102.68-share is running more than one daemon pod
Dec 28 05:25:04.074: INFO: DaemonSet pods can't tolerate node 10.10.102.65-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 28 05:25:04.089: INFO: Number of nodes with available pods: 3
Dec 28 05:25:04.089: INFO: Node 10.10.102.68-share is running more than one daemon pod
Dec 28 05:25:05.074: INFO: DaemonSet pods can't tolerate node 10.10.102.65-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 28 05:25:05.082: INFO: Number of nodes with available pods: 3
Dec 28 05:25:05.082: INFO: Node 10.10.102.68-share is running more than one daemon pod
Dec 28 05:25:06.074: INFO: DaemonSet pods can't tolerate node 10.10.102.65-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 28 05:25:06.081: INFO: Number of nodes with available pods: 4
Dec 28 05:25:06.081: INFO: Number of running nodes: 4, number of available pods: 4
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:64
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting {extensions DaemonSet} daemon-set in namespace e2e-tests-daemonsets-qchbh, will wait for the garbage collector to delete the pods
Dec 28 05:25:06.179: INFO: Deleting {extensions DaemonSet} daemon-set took: 12.241303ms
Dec 28 05:25:06.379: INFO: Terminating {extensions DaemonSet} daemon-set pods took: 200.620683ms
Dec 28 05:25:17.611: INFO: Number of nodes with available pods: 0
Dec 28 05:25:17.611: INFO: Number of running nodes: 0, number of available pods: 0
Dec 28 05:25:17.616: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-qchbh/daemonsets","resourceVersion":"530434"},"items":null}

Dec 28 05:25:17.621: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-qchbh/pods","resourceVersion":"530434"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 28 05:25:17.651: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-qchbh" for this suite.
Dec 28 05:25:25.698: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 05:25:25.869: INFO: namespace: e2e-tests-daemonsets-qchbh, resource: bindings, ignored listing per whitelist
Dec 28 05:25:25.897: INFO: namespace e2e-tests-daemonsets-qchbh deletion completed in 8.237789837s

• [SLOW TEST:217.459 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 28 05:25:25.898: INFO: >>> kubeConfig: /tmp/kubeconfig-994138694
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Dec 28 05:25:26.181: INFO: Waiting up to 5m0s for pod "downwardapi-volume-fb5a70fd-0a60-11e9-8a07-628dff7095f4" in namespace "e2e-tests-projected-tl7cn" to be "success or failure"
Dec 28 05:25:26.198: INFO: Pod "downwardapi-volume-fb5a70fd-0a60-11e9-8a07-628dff7095f4": Phase="Pending", Reason="", readiness=false. Elapsed: 17.382203ms
Dec 28 05:25:28.206: INFO: Pod "downwardapi-volume-fb5a70fd-0a60-11e9-8a07-628dff7095f4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.02440517s
Dec 28 05:25:30.214: INFO: Pod "downwardapi-volume-fb5a70fd-0a60-11e9-8a07-628dff7095f4": Phase="Pending", Reason="", readiness=false. Elapsed: 4.032520003s
Dec 28 05:25:32.221: INFO: Pod "downwardapi-volume-fb5a70fd-0a60-11e9-8a07-628dff7095f4": Phase="Pending", Reason="", readiness=false. Elapsed: 6.040214703s
Dec 28 05:25:34.229: INFO: Pod "downwardapi-volume-fb5a70fd-0a60-11e9-8a07-628dff7095f4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.04797428s
STEP: Saw pod success
Dec 28 05:25:34.229: INFO: Pod "downwardapi-volume-fb5a70fd-0a60-11e9-8a07-628dff7095f4" satisfied condition "success or failure"
Dec 28 05:25:34.234: INFO: Trying to get logs from node 10.10.102.67-slave pod downwardapi-volume-fb5a70fd-0a60-11e9-8a07-628dff7095f4 container client-container: <nil>
STEP: delete the pod
Dec 28 05:25:35.108: INFO: Waiting for pod downwardapi-volume-fb5a70fd-0a60-11e9-8a07-628dff7095f4 to disappear
Dec 28 05:25:35.130: INFO: Pod downwardapi-volume-fb5a70fd-0a60-11e9-8a07-628dff7095f4 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 28 05:25:35.130: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-tl7cn" for this suite.
Dec 28 05:25:43.167: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 05:25:43.434: INFO: namespace: e2e-tests-projected-tl7cn, resource: bindings, ignored listing per whitelist
Dec 28 05:25:43.531: INFO: namespace e2e-tests-projected-tl7cn deletion completed in 8.387968644s

• [SLOW TEST:17.634 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 28 05:25:43.532: INFO: >>> kubeConfig: /tmp/kubeconfig-994138694
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for all rs to be garbage collected
STEP: expected 0 rs, got 1 rs
STEP: expected 0 pods, got 2 pods
STEP: Gathering metrics
Dec 28 05:25:44.982: INFO: MetricsGrabber failed grab metrics. Skipping metrics gathering.
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 28 05:25:44.983: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-btnsl" for this suite.
Dec 28 05:25:51.018: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 05:25:51.084: INFO: namespace: e2e-tests-gc-btnsl, resource: bindings, ignored listing per whitelist
Dec 28 05:25:51.222: INFO: namespace e2e-tests-gc-btnsl deletion completed in 6.230506947s

• [SLOW TEST:7.690 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 28 05:25:51.222: INFO: >>> kubeConfig: /tmp/kubeconfig-994138694
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-map-0a6c6862-0a61-11e9-8a07-628dff7095f4
STEP: Creating a pod to test consume configMaps
Dec 28 05:25:51.502: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-0a6dd84b-0a61-11e9-8a07-628dff7095f4" in namespace "e2e-tests-projected-vsbrp" to be "success or failure"
Dec 28 05:25:51.514: INFO: Pod "pod-projected-configmaps-0a6dd84b-0a61-11e9-8a07-628dff7095f4": Phase="Pending", Reason="", readiness=false. Elapsed: 12.08383ms
Dec 28 05:25:53.524: INFO: Pod "pod-projected-configmaps-0a6dd84b-0a61-11e9-8a07-628dff7095f4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.02188784s
Dec 28 05:25:55.533: INFO: Pod "pod-projected-configmaps-0a6dd84b-0a61-11e9-8a07-628dff7095f4": Phase="Pending", Reason="", readiness=false. Elapsed: 4.031063163s
Dec 28 05:25:57.546: INFO: Pod "pod-projected-configmaps-0a6dd84b-0a61-11e9-8a07-628dff7095f4": Phase="Pending", Reason="", readiness=false. Elapsed: 6.044077783s
Dec 28 05:25:59.555: INFO: Pod "pod-projected-configmaps-0a6dd84b-0a61-11e9-8a07-628dff7095f4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.053558167s
STEP: Saw pod success
Dec 28 05:25:59.555: INFO: Pod "pod-projected-configmaps-0a6dd84b-0a61-11e9-8a07-628dff7095f4" satisfied condition "success or failure"
Dec 28 05:25:59.560: INFO: Trying to get logs from node 10.10.102.68-share pod pod-projected-configmaps-0a6dd84b-0a61-11e9-8a07-628dff7095f4 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Dec 28 05:25:59.705: INFO: Waiting for pod pod-projected-configmaps-0a6dd84b-0a61-11e9-8a07-628dff7095f4 to disappear
Dec 28 05:25:59.739: INFO: Pod pod-projected-configmaps-0a6dd84b-0a61-11e9-8a07-628dff7095f4 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 28 05:25:59.739: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-vsbrp" for this suite.
Dec 28 05:26:05.786: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 05:26:05.842: INFO: namespace: e2e-tests-projected-vsbrp, resource: bindings, ignored listing per whitelist
Dec 28 05:26:05.997: INFO: namespace e2e-tests-projected-vsbrp deletion completed in 6.246425777s

• [SLOW TEST:14.774 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 28 05:26:05.998: INFO: >>> kubeConfig: /tmp/kubeconfig-994138694
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test substitution in container's args
Dec 28 05:26:06.266: INFO: Waiting up to 5m0s for pod "var-expansion-133f133b-0a61-11e9-8a07-628dff7095f4" in namespace "e2e-tests-var-expansion-vr2r9" to be "success or failure"
Dec 28 05:26:06.302: INFO: Pod "var-expansion-133f133b-0a61-11e9-8a07-628dff7095f4": Phase="Pending", Reason="", readiness=false. Elapsed: 36.085074ms
Dec 28 05:26:08.310: INFO: Pod "var-expansion-133f133b-0a61-11e9-8a07-628dff7095f4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.043660834s
Dec 28 05:26:10.318: INFO: Pod "var-expansion-133f133b-0a61-11e9-8a07-628dff7095f4": Phase="Pending", Reason="", readiness=false. Elapsed: 4.051352837s
Dec 28 05:26:12.325: INFO: Pod "var-expansion-133f133b-0a61-11e9-8a07-628dff7095f4": Phase="Pending", Reason="", readiness=false. Elapsed: 6.058819654s
Dec 28 05:26:14.332: INFO: Pod "var-expansion-133f133b-0a61-11e9-8a07-628dff7095f4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.0657784s
STEP: Saw pod success
Dec 28 05:26:14.332: INFO: Pod "var-expansion-133f133b-0a61-11e9-8a07-628dff7095f4" satisfied condition "success or failure"
Dec 28 05:26:14.337: INFO: Trying to get logs from node 10.10.102.69-build pod var-expansion-133f133b-0a61-11e9-8a07-628dff7095f4 container dapi-container: <nil>
STEP: delete the pod
Dec 28 05:26:14.865: INFO: Waiting for pod var-expansion-133f133b-0a61-11e9-8a07-628dff7095f4 to disappear
Dec 28 05:26:15.002: INFO: Pod var-expansion-133f133b-0a61-11e9-8a07-628dff7095f4 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 28 05:26:15.003: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-var-expansion-vr2r9" for this suite.
Dec 28 05:26:21.064: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 05:26:21.261: INFO: namespace: e2e-tests-var-expansion-vr2r9, resource: bindings, ignored listing per whitelist
Dec 28 05:26:21.393: INFO: namespace e2e-tests-var-expansion-vr2r9 deletion completed in 6.37689477s

• [SLOW TEST:15.396 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 28 05:26:21.394: INFO: >>> kubeConfig: /tmp/kubeconfig-994138694
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-986qx
[It] should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a new StatefulSet
Dec 28 05:26:21.640: INFO: Found 0 stateful pods, waiting for 3
Dec 28 05:26:31.648: INFO: Found 2 stateful pods, waiting for 3
Dec 28 05:26:41.649: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Dec 28 05:26:41.649: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Dec 28 05:26:41.649: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Pending - Ready=false
Dec 28 05:26:51.649: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Dec 28 05:26:51.649: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Dec 28 05:26:51.649: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
Dec 28 05:26:51.666: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994138694 exec --namespace=e2e-tests-statefulset-986qx ss2-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Dec 28 05:26:52.228: INFO: stderr: ""
Dec 28 05:26:52.228: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Dec 28 05:26:52.228: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss2-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

STEP: Updating StatefulSet template: update image from docker.io/library/nginx:1.14-alpine to docker.io/library/nginx:1.15-alpine
Dec 28 05:27:02.283: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Updating Pods in reverse ordinal order
Dec 28 05:27:12.330: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994138694 exec --namespace=e2e-tests-statefulset-986qx ss2-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec 28 05:27:12.771: INFO: stderr: ""
Dec 28 05:27:12.771: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Dec 28 05:27:12.771: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss2-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Dec 28 05:27:22.817: INFO: Waiting for StatefulSet e2e-tests-statefulset-986qx/ss2 to complete update
Dec 28 05:27:22.817: INFO: Waiting for Pod e2e-tests-statefulset-986qx/ss2-0 to have revision ss2-c79899b9 update revision ss2-787997d666
Dec 28 05:27:22.817: INFO: Waiting for Pod e2e-tests-statefulset-986qx/ss2-1 to have revision ss2-c79899b9 update revision ss2-787997d666
Dec 28 05:27:32.834: INFO: Waiting for StatefulSet e2e-tests-statefulset-986qx/ss2 to complete update
Dec 28 05:27:32.834: INFO: Waiting for Pod e2e-tests-statefulset-986qx/ss2-0 to have revision ss2-c79899b9 update revision ss2-787997d666
Dec 28 05:27:42.831: INFO: Waiting for StatefulSet e2e-tests-statefulset-986qx/ss2 to complete update
STEP: Rolling back to a previous revision
Dec 28 05:27:52.831: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994138694 exec --namespace=e2e-tests-statefulset-986qx ss2-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Dec 28 05:27:53.334: INFO: stderr: ""
Dec 28 05:27:53.334: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Dec 28 05:27:53.335: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss2-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Dec 28 05:28:03.390: INFO: Updating stateful set ss2
STEP: Rolling back update in reverse ordinal order
Dec 28 05:28:13.427: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994138694 exec --namespace=e2e-tests-statefulset-986qx ss2-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec 28 05:28:13.896: INFO: stderr: ""
Dec 28 05:28:13.896: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Dec 28 05:28:13.896: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss2-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Dec 28 05:28:23.936: INFO: Waiting for StatefulSet e2e-tests-statefulset-986qx/ss2 to complete update
Dec 28 05:28:23.936: INFO: Waiting for Pod e2e-tests-statefulset-986qx/ss2-0 to have revision ss2-787997d666 update revision ss2-c79899b9
Dec 28 05:28:23.936: INFO: Waiting for Pod e2e-tests-statefulset-986qx/ss2-1 to have revision ss2-787997d666 update revision ss2-c79899b9
Dec 28 05:28:33.951: INFO: Waiting for StatefulSet e2e-tests-statefulset-986qx/ss2 to complete update
Dec 28 05:28:33.951: INFO: Waiting for Pod e2e-tests-statefulset-986qx/ss2-0 to have revision ss2-787997d666 update revision ss2-c79899b9
Dec 28 05:28:33.951: INFO: Waiting for Pod e2e-tests-statefulset-986qx/ss2-1 to have revision ss2-787997d666 update revision ss2-c79899b9
Dec 28 05:28:43.952: INFO: Waiting for StatefulSet e2e-tests-statefulset-986qx/ss2 to complete update
Dec 28 05:28:43.952: INFO: Waiting for Pod e2e-tests-statefulset-986qx/ss2-0 to have revision ss2-787997d666 update revision ss2-c79899b9
Dec 28 05:28:53.950: INFO: Waiting for StatefulSet e2e-tests-statefulset-986qx/ss2 to complete update
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Dec 28 05:29:03.952: INFO: Deleting all statefulset in ns e2e-tests-statefulset-986qx
Dec 28 05:29:03.957: INFO: Scaling statefulset ss2 to 0
Dec 28 05:29:34.010: INFO: Waiting for statefulset status.replicas updated to 0
Dec 28 05:29:34.016: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 28 05:29:34.052: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-986qx" for this suite.
Dec 28 05:29:42.157: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 05:29:42.325: INFO: namespace: e2e-tests-statefulset-986qx, resource: bindings, ignored listing per whitelist
Dec 28 05:29:42.405: INFO: namespace e2e-tests-statefulset-986qx deletion completed in 8.335874804s

• [SLOW TEST:201.012 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should perform rolling updates and roll backs of template modifications [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 28 05:29:42.406: INFO: >>> kubeConfig: /tmp/kubeconfig-994138694
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a watch on configmaps with a certain label
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: changing the label value of the configmap
STEP: Expecting to observe a delete notification for the watched object
Dec 28 05:29:42.774: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-7jb77,SelfLink:/api/v1/namespaces/e2e-tests-watch-7jb77/configmaps/e2e-watch-test-label-changed,UID:945419dd-0a61-11e9-a0ee-005056bc4922,ResourceVersion:531630,Generation:0,CreationTimestamp:2018-12-28 05:29:42 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Dec 28 05:29:42.775: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-7jb77,SelfLink:/api/v1/namespaces/e2e-tests-watch-7jb77/configmaps/e2e-watch-test-label-changed,UID:945419dd-0a61-11e9-a0ee-005056bc4922,ResourceVersion:531631,Generation:0,CreationTimestamp:2018-12-28 05:29:42 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Dec 28 05:29:42.775: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-7jb77,SelfLink:/api/v1/namespaces/e2e-tests-watch-7jb77/configmaps/e2e-watch-test-label-changed,UID:945419dd-0a61-11e9-a0ee-005056bc4922,ResourceVersion:531632,Generation:0,CreationTimestamp:2018-12-28 05:29:42 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time
STEP: Expecting not to observe a notification because the object no longer meets the selector's requirements
STEP: changing the label value of the configmap back
STEP: modifying the configmap a third time
STEP: deleting the configmap
STEP: Expecting to observe an add notification for the watched object when the label value was restored
Dec 28 05:29:53.018: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-7jb77,SelfLink:/api/v1/namespaces/e2e-tests-watch-7jb77/configmaps/e2e-watch-test-label-changed,UID:945419dd-0a61-11e9-a0ee-005056bc4922,ResourceVersion:531652,Generation:0,CreationTimestamp:2018-12-28 05:29:42 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Dec 28 05:29:53.018: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-7jb77,SelfLink:/api/v1/namespaces/e2e-tests-watch-7jb77/configmaps/e2e-watch-test-label-changed,UID:945419dd-0a61-11e9-a0ee-005056bc4922,ResourceVersion:531653,Generation:0,CreationTimestamp:2018-12-28 05:29:42 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
Dec 28 05:29:53.018: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-7jb77,SelfLink:/api/v1/namespaces/e2e-tests-watch-7jb77/configmaps/e2e-watch-test-label-changed,UID:945419dd-0a61-11e9-a0ee-005056bc4922,ResourceVersion:531654,Generation:0,CreationTimestamp:2018-12-28 05:29:42 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 28 05:29:53.019: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-7jb77" for this suite.
Dec 28 05:29:59.077: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 05:29:59.178: INFO: namespace: e2e-tests-watch-7jb77, resource: bindings, ignored listing per whitelist
Dec 28 05:29:59.268: INFO: namespace e2e-tests-watch-7jb77 deletion completed in 6.220097913s

• [SLOW TEST:16.862 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 28 05:29:59.268: INFO: >>> kubeConfig: /tmp/kubeconfig-994138694
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0777 on node default medium
Dec 28 05:29:59.627: INFO: Waiting up to 5m0s for pod "pod-9e579cc7-0a61-11e9-8a07-628dff7095f4" in namespace "e2e-tests-emptydir-9cz7p" to be "success or failure"
Dec 28 05:29:59.635: INFO: Pod "pod-9e579cc7-0a61-11e9-8a07-628dff7095f4": Phase="Pending", Reason="", readiness=false. Elapsed: 7.881566ms
Dec 28 05:30:01.651: INFO: Pod "pod-9e579cc7-0a61-11e9-8a07-628dff7095f4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.02340036s
Dec 28 05:30:03.659: INFO: Pod "pod-9e579cc7-0a61-11e9-8a07-628dff7095f4": Phase="Pending", Reason="", readiness=false. Elapsed: 4.03150274s
Dec 28 05:30:05.738: INFO: Pod "pod-9e579cc7-0a61-11e9-8a07-628dff7095f4": Phase="Pending", Reason="", readiness=false. Elapsed: 6.11023254s
Dec 28 05:30:07.745: INFO: Pod "pod-9e579cc7-0a61-11e9-8a07-628dff7095f4": Phase="Pending", Reason="", readiness=false. Elapsed: 8.117298986s
Dec 28 05:30:09.754: INFO: Pod "pod-9e579cc7-0a61-11e9-8a07-628dff7095f4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 10.126080656s
STEP: Saw pod success
Dec 28 05:30:09.754: INFO: Pod "pod-9e579cc7-0a61-11e9-8a07-628dff7095f4" satisfied condition "success or failure"
Dec 28 05:30:09.762: INFO: Trying to get logs from node 10.10.102.69-build pod pod-9e579cc7-0a61-11e9-8a07-628dff7095f4 container test-container: <nil>
STEP: delete the pod
Dec 28 05:30:09.830: INFO: Waiting for pod pod-9e579cc7-0a61-11e9-8a07-628dff7095f4 to disappear
Dec 28 05:30:09.843: INFO: Pod pod-9e579cc7-0a61-11e9-8a07-628dff7095f4 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 28 05:30:09.843: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-9cz7p" for this suite.
Dec 28 05:30:18.068: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 05:30:18.169: INFO: namespace: e2e-tests-emptydir-9cz7p, resource: bindings, ignored listing per whitelist
Dec 28 05:30:18.282: INFO: namespace e2e-tests-emptydir-9cz7p deletion completed in 8.425853653s

• [SLOW TEST:19.014 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Guestbook application 
  should create and stop a working application  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 28 05:30:18.282: INFO: >>> kubeConfig: /tmp/kubeconfig-994138694
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should create and stop a working application  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating all guestbook components
Dec 28 05:30:18.543: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-slave
  labels:
    app: redis
    role: slave
    tier: backend
spec:
  ports:
  - port: 6379
  selector:
    app: redis
    role: slave
    tier: backend

Dec 28 05:30:18.543: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994138694 create -f - --namespace=e2e-tests-kubectl-sc49r'
Dec 28 05:30:22.593: INFO: stderr: ""
Dec 28 05:30:22.593: INFO: stdout: "service/redis-slave created\n"
Dec 28 05:30:22.593: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-master
  labels:
    app: redis
    role: master
    tier: backend
spec:
  ports:
  - port: 6379
    targetPort: 6379
  selector:
    app: redis
    role: master
    tier: backend

Dec 28 05:30:22.593: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994138694 create -f - --namespace=e2e-tests-kubectl-sc49r'
Dec 28 05:30:23.680: INFO: stderr: ""
Dec 28 05:30:23.680: INFO: stdout: "service/redis-master created\n"
Dec 28 05:30:23.680: INFO: apiVersion: v1
kind: Service
metadata:
  name: frontend
  labels:
    app: guestbook
    tier: frontend
spec:
  # if your cluster supports it, uncomment the following to automatically create
  # an external load-balanced IP for the frontend service.
  # type: LoadBalancer
  ports:
  - port: 80
  selector:
    app: guestbook
    tier: frontend

Dec 28 05:30:23.680: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994138694 create -f - --namespace=e2e-tests-kubectl-sc49r'
Dec 28 05:30:24.814: INFO: stderr: ""
Dec 28 05:30:24.814: INFO: stdout: "service/frontend created\n"
Dec 28 05:30:24.815: INFO: apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: frontend
spec:
  replicas: 3
  template:
    metadata:
      labels:
        app: guestbook
        tier: frontend
    spec:
      containers:
      - name: php-redis
        image: gcr.io/google-samples/gb-frontend:v6
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access environment variables to find service host
          # info, comment out the 'value: dns' line above, and uncomment the
          # line below:
          # value: env
        ports:
        - containerPort: 80

Dec 28 05:30:24.815: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994138694 create -f - --namespace=e2e-tests-kubectl-sc49r'
Dec 28 05:30:25.926: INFO: stderr: ""
Dec 28 05:30:25.926: INFO: stdout: "deployment.extensions/frontend created\n"
Dec 28 05:30:25.926: INFO: apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: redis-master
spec:
  replicas: 1
  template:
    metadata:
      labels:
        app: redis
        role: master
        tier: backend
    spec:
      containers:
      - name: master
        image: gcr.io/kubernetes-e2e-test-images/redis:1.0
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        ports:
        - containerPort: 6379

Dec 28 05:30:25.926: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994138694 create -f - --namespace=e2e-tests-kubectl-sc49r'
Dec 28 05:30:26.812: INFO: stderr: ""
Dec 28 05:30:26.812: INFO: stdout: "deployment.extensions/redis-master created\n"
Dec 28 05:30:26.813: INFO: apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: redis-slave
spec:
  replicas: 2
  template:
    metadata:
      labels:
        app: redis
        role: slave
        tier: backend
    spec:
      containers:
      - name: slave
        image: gcr.io/google-samples/gb-redisslave:v3
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access an environment variable to find the master
          # service's host, comment out the 'value: dns' line above, and
          # uncomment the line below:
          # value: env
        ports:
        - containerPort: 6379

Dec 28 05:30:26.813: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994138694 create -f - --namespace=e2e-tests-kubectl-sc49r'
Dec 28 05:30:28.264: INFO: stderr: ""
Dec 28 05:30:28.264: INFO: stdout: "deployment.extensions/redis-slave created\n"
STEP: validating guestbook app
Dec 28 05:30:28.264: INFO: Waiting for all frontend pods to be Running.
Dec 28 05:30:53.317: INFO: Waiting for frontend to serve content.
Dec 28 05:30:53.611: INFO: Trying to add a new entry to the guestbook.
Dec 28 05:30:54.892: INFO: Verifying that added entry can be retrieved.
STEP: using delete to clean up resources
Dec 28 05:30:54.934: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994138694 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-sc49r'
Dec 28 05:30:55.390: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Dec 28 05:30:55.390: INFO: stdout: "service \"redis-slave\" force deleted\n"
STEP: using delete to clean up resources
Dec 28 05:30:55.390: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994138694 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-sc49r'
Dec 28 05:30:55.969: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Dec 28 05:30:55.969: INFO: stdout: "service \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
Dec 28 05:30:55.969: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994138694 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-sc49r'
Dec 28 05:30:56.559: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Dec 28 05:30:56.559: INFO: stdout: "service \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Dec 28 05:30:56.560: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994138694 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-sc49r'
Dec 28 05:30:57.002: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Dec 28 05:30:57.002: INFO: stdout: "deployment.extensions \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Dec 28 05:30:57.003: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994138694 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-sc49r'
Dec 28 05:30:58.073: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Dec 28 05:30:58.073: INFO: stdout: "deployment.extensions \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
Dec 28 05:30:58.073: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994138694 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-sc49r'
Dec 28 05:30:59.230: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Dec 28 05:30:59.230: INFO: stdout: "deployment.extensions \"redis-slave\" force deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 28 05:30:59.230: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-sc49r" for this suite.
Dec 28 05:31:43.506: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 05:31:43.773: INFO: namespace: e2e-tests-kubectl-sc49r, resource: bindings, ignored listing per whitelist
Dec 28 05:31:43.883: INFO: namespace e2e-tests-kubectl-sc49r deletion completed in 44.618615473s

• [SLOW TEST:85.601 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Guestbook application
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create and stop a working application  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 28 05:31:43.884: INFO: >>> kubeConfig: /tmp/kubeconfig-994138694
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the rc
STEP: delete the rc
STEP: wait for all pods to be garbage collected
STEP: Gathering metrics
Dec 28 05:31:54.134: INFO: MetricsGrabber failed grab metrics. Skipping metrics gathering.
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 28 05:31:54.134: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-g9mtv" for this suite.
Dec 28 05:32:00.181: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 05:32:00.327: INFO: namespace: e2e-tests-gc-g9mtv, resource: bindings, ignored listing per whitelist
Dec 28 05:32:00.453: INFO: namespace e2e-tests-gc-g9mtv deletion completed in 6.308403737s

• [SLOW TEST:16.569 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 28 05:32:00.453: INFO: >>> kubeConfig: /tmp/kubeconfig-994138694
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-e68667c9-0a61-11e9-8a07-628dff7095f4
STEP: Creating a pod to test consume configMaps
Dec 28 05:32:00.748: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-e687b31b-0a61-11e9-8a07-628dff7095f4" in namespace "e2e-tests-projected-m78f6" to be "success or failure"
Dec 28 05:32:00.776: INFO: Pod "pod-projected-configmaps-e687b31b-0a61-11e9-8a07-628dff7095f4": Phase="Pending", Reason="", readiness=false. Elapsed: 28.720376ms
Dec 28 05:32:02.785: INFO: Pod "pod-projected-configmaps-e687b31b-0a61-11e9-8a07-628dff7095f4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.037284936s
Dec 28 05:32:04.794: INFO: Pod "pod-projected-configmaps-e687b31b-0a61-11e9-8a07-628dff7095f4": Phase="Pending", Reason="", readiness=false. Elapsed: 4.04585678s
Dec 28 05:32:06.923: INFO: Pod "pod-projected-configmaps-e687b31b-0a61-11e9-8a07-628dff7095f4": Phase="Pending", Reason="", readiness=false. Elapsed: 6.1753686s
Dec 28 05:32:08.929: INFO: Pod "pod-projected-configmaps-e687b31b-0a61-11e9-8a07-628dff7095f4": Phase="Pending", Reason="", readiness=false. Elapsed: 8.18109526s
Dec 28 05:32:10.938: INFO: Pod "pod-projected-configmaps-e687b31b-0a61-11e9-8a07-628dff7095f4": Phase="Pending", Reason="", readiness=false. Elapsed: 10.18974524s
Dec 28 05:32:12.946: INFO: Pod "pod-projected-configmaps-e687b31b-0a61-11e9-8a07-628dff7095f4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 12.198620343s
STEP: Saw pod success
Dec 28 05:32:12.946: INFO: Pod "pod-projected-configmaps-e687b31b-0a61-11e9-8a07-628dff7095f4" satisfied condition "success or failure"
Dec 28 05:32:12.952: INFO: Trying to get logs from node 10.10.102.68-share pod pod-projected-configmaps-e687b31b-0a61-11e9-8a07-628dff7095f4 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Dec 28 05:32:12.998: INFO: Waiting for pod pod-projected-configmaps-e687b31b-0a61-11e9-8a07-628dff7095f4 to disappear
Dec 28 05:32:13.023: INFO: Pod pod-projected-configmaps-e687b31b-0a61-11e9-8a07-628dff7095f4 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 28 05:32:13.023: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-m78f6" for this suite.
Dec 28 05:32:19.137: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 05:32:19.321: INFO: namespace: e2e-tests-projected-m78f6, resource: bindings, ignored listing per whitelist
Dec 28 05:32:19.346: INFO: namespace e2e-tests-projected-m78f6 deletion completed in 6.23707608s

• [SLOW TEST:18.894 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 28 05:32:19.347: INFO: >>> kubeConfig: /tmp/kubeconfig-994138694
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 28 05:33:19.718: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-p9ff7" for this suite.
Dec 28 05:33:43.883: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 05:33:43.952: INFO: namespace: e2e-tests-container-probe-p9ff7, resource: bindings, ignored listing per whitelist
Dec 28 05:33:44.098: INFO: namespace e2e-tests-container-probe-p9ff7 deletion completed in 24.371289577s

• [SLOW TEST:84.752 seconds]
[k8s.io] Probing container
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-apps] Deployment 
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 28 05:33:44.099: INFO: >>> kubeConfig: /tmp/kubeconfig-994138694
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Dec 28 05:33:44.588: INFO: Creating replica set "test-rolling-update-controller" (going to be adopted)
Dec 28 05:33:44.628: INFO: Pod name sample-pod: Found 0 pods out of 1
Dec 28 05:33:49.646: INFO: Pod name sample-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Dec 28 05:33:55.697: INFO: Creating deployment "test-rolling-update-deployment"
Dec 28 05:33:55.734: INFO: Ensuring deployment "test-rolling-update-deployment" gets the next revision from the one the adopted replica set "test-rolling-update-controller" has
Dec 28 05:33:55.766: INFO: new replicaset for deployment "test-rolling-update-deployment" is yet to be created
Dec 28 05:33:57.787: INFO: Ensuring status for deployment "test-rolling-update-deployment" is the expected
Dec 28 05:33:57.793: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:2, UpdatedReplicas:1, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63681572036, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63681572036, loc:(*time.Location)(0x6c43b60)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63681572036, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63681572035, loc:(*time.Location)(0x6c43b60)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rolling-update-deployment-65b7695dcf\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec 28 05:33:59.800: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:2, UpdatedReplicas:1, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63681572036, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63681572036, loc:(*time.Location)(0x6c43b60)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63681572036, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63681572035, loc:(*time.Location)(0x6c43b60)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rolling-update-deployment-65b7695dcf\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec 28 05:34:01.801: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:2, UpdatedReplicas:1, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63681572036, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63681572036, loc:(*time.Location)(0x6c43b60)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63681572036, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63681572035, loc:(*time.Location)(0x6c43b60)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rolling-update-deployment-65b7695dcf\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec 28 05:34:03.800: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:2, UpdatedReplicas:1, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63681572036, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63681572036, loc:(*time.Location)(0x6c43b60)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63681572036, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63681572035, loc:(*time.Location)(0x6c43b60)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rolling-update-deployment-65b7695dcf\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec 28 05:34:05.801: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:2, UpdatedReplicas:1, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63681572036, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63681572036, loc:(*time.Location)(0x6c43b60)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63681572036, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63681572035, loc:(*time.Location)(0x6c43b60)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rolling-update-deployment-65b7695dcf\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec 28 05:34:07.810: INFO: Ensuring deployment "test-rolling-update-deployment" has one old replica set (the one it adopted)
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Dec 28 05:34:07.948: INFO: Deployment "test-rolling-update-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment,GenerateName:,Namespace:e2e-tests-deployment-cqcpl,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-cqcpl/deployments/test-rolling-update-deployment,UID:2b218fcd-0a62-11e9-a0ee-005056bc4922,ResourceVersion:532568,Generation:1,CreationTimestamp:2018-12-28 05:33:55 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,},Annotations:map[string]string{deployment.kubernetes.io/revision: 3546343826724305833,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[{Available True 2018-12-28 05:33:56 +0000 UTC 2018-12-28 05:33:56 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2018-12-28 05:34:06 +0000 UTC 2018-12-28 05:33:55 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-rolling-update-deployment-65b7695dcf" has successfully progressed.}],ReadyReplicas:1,CollisionCount:nil,},}

Dec 28 05:34:07.967: INFO: New ReplicaSet "test-rolling-update-deployment-65b7695dcf" of Deployment "test-rolling-update-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment-65b7695dcf,GenerateName:,Namespace:e2e-tests-deployment-cqcpl,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-cqcpl/replicasets/test-rolling-update-deployment-65b7695dcf,UID:2b2dc7b4-0a62-11e9-a0ee-005056bc4922,ResourceVersion:532559,Generation:1,CreationTimestamp:2018-12-28 05:33:55 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 65b7695dcf,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 3546343826724305833,},OwnerReferences:[{apps/v1 Deployment test-rolling-update-deployment 2b218fcd-0a62-11e9-a0ee-005056bc4922 0xc421e486a7 0xc421e486a8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod-template-hash: 65b7695dcf,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 65b7695dcf,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Dec 28 05:34:07.967: INFO: All old ReplicaSets of Deployment "test-rolling-update-deployment":
Dec 28 05:34:07.967: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-controller,GenerateName:,Namespace:e2e-tests-deployment-cqcpl,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-cqcpl/replicasets/test-rolling-update-controller,UID:24828e4b-0a62-11e9-a0ee-005056bc4922,ResourceVersion:532567,Generation:2,CreationTimestamp:2018-12-28 05:33:44 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod: nginx,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 3546343826724305832,},OwnerReferences:[{apps/v1 Deployment test-rolling-update-deployment 2b218fcd-0a62-11e9-a0ee-005056bc4922 0xc421e485be 0xc421e485bf}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Dec 28 05:34:07.978: INFO: Pod "test-rolling-update-deployment-65b7695dcf-qqq4r" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment-65b7695dcf-qqq4r,GenerateName:test-rolling-update-deployment-65b7695dcf-,Namespace:e2e-tests-deployment-cqcpl,SelfLink:/api/v1/namespaces/e2e-tests-deployment-cqcpl/pods/test-rolling-update-deployment-65b7695dcf-qqq4r,UID:2b4a13bb-0a62-11e9-a0ee-005056bc4922,ResourceVersion:532558,Generation:0,CreationTimestamp:2018-12-28 05:33:56 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 65b7695dcf,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet test-rolling-update-deployment-65b7695dcf 2b2dc7b4-0a62-11e9-a0ee-005056bc4922 0xc421e62327 0xc421e62328}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-9wht6 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-9wht6,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-9wht6 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.10.102.69-build,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc421e62390} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421e623b0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-28 05:33:56 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-12-28 05:34:06 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2018-12-28 05:34:06 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-28 05:33:56 +0000 UTC  }],Message:,Reason:,HostIP:10.10.102.69,PodIP:10.168.192.44,StartTime:2018-12-28 05:33:56 +0000 UTC,ContainerStatuses:[{redis {nil ContainerStateRunning{StartedAt:2018-12-28 05:34:06 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/redis:1.0 docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830 docker://6e1208865fb61455ace09621ab0d3511477900136f6156637ac258b553743602}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 28 05:34:07.978: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-cqcpl" for this suite.
Dec 28 05:34:16.297: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 05:34:16.413: INFO: namespace: e2e-tests-deployment-cqcpl, resource: bindings, ignored listing per whitelist
Dec 28 05:34:16.509: INFO: namespace e2e-tests-deployment-cqcpl deletion completed in 8.5177738s

• [SLOW TEST:32.410 seconds]
[sig-apps] Deployment
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-api-machinery] Downward API 
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 28 05:34:16.510: INFO: >>> kubeConfig: /tmp/kubeconfig-994138694
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Dec 28 05:34:16.853: INFO: Waiting up to 5m0s for pod "downward-api-37a0780a-0a62-11e9-8a07-628dff7095f4" in namespace "e2e-tests-downward-api-bfxwf" to be "success or failure"
Dec 28 05:34:16.884: INFO: Pod "downward-api-37a0780a-0a62-11e9-8a07-628dff7095f4": Phase="Pending", Reason="", readiness=false. Elapsed: 30.99603ms
Dec 28 05:34:18.892: INFO: Pod "downward-api-37a0780a-0a62-11e9-8a07-628dff7095f4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.03887319s
Dec 28 05:34:20.902: INFO: Pod "downward-api-37a0780a-0a62-11e9-8a07-628dff7095f4": Phase="Pending", Reason="", readiness=false. Elapsed: 4.048999273s
Dec 28 05:34:22.933: INFO: Pod "downward-api-37a0780a-0a62-11e9-8a07-628dff7095f4": Phase="Pending", Reason="", readiness=false. Elapsed: 6.079354283s
Dec 28 05:34:24.941: INFO: Pod "downward-api-37a0780a-0a62-11e9-8a07-628dff7095f4": Phase="Pending", Reason="", readiness=false. Elapsed: 8.087210117s
Dec 28 05:34:26.974: INFO: Pod "downward-api-37a0780a-0a62-11e9-8a07-628dff7095f4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 10.12084193s
STEP: Saw pod success
Dec 28 05:34:26.974: INFO: Pod "downward-api-37a0780a-0a62-11e9-8a07-628dff7095f4" satisfied condition "success or failure"
Dec 28 05:34:26.981: INFO: Trying to get logs from node 10.10.102.67-slave pod downward-api-37a0780a-0a62-11e9-8a07-628dff7095f4 container dapi-container: <nil>
STEP: delete the pod
Dec 28 05:34:27.579: INFO: Waiting for pod downward-api-37a0780a-0a62-11e9-8a07-628dff7095f4 to disappear
Dec 28 05:34:27.599: INFO: Pod downward-api-37a0780a-0a62-11e9-8a07-628dff7095f4 no longer exists
[AfterEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 28 05:34:27.600: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-bfxwf" for this suite.
Dec 28 05:34:33.636: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 05:34:33.802: INFO: namespace: e2e-tests-downward-api-bfxwf, resource: bindings, ignored listing per whitelist
Dec 28 05:34:33.914: INFO: namespace e2e-tests-downward-api-bfxwf deletion completed in 6.304550236s

• [SLOW TEST:17.405 seconds]
[sig-api-machinery] Downward API
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 28 05:34:33.915: INFO: >>> kubeConfig: /tmp/kubeconfig-994138694
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Dec 28 05:34:34.232: INFO: Waiting up to 5m0s for pod "downwardapi-volume-420507e8-0a62-11e9-8a07-628dff7095f4" in namespace "e2e-tests-downward-api-zkxxj" to be "success or failure"
Dec 28 05:34:34.253: INFO: Pod "downwardapi-volume-420507e8-0a62-11e9-8a07-628dff7095f4": Phase="Pending", Reason="", readiness=false. Elapsed: 20.326627ms
Dec 28 05:34:36.260: INFO: Pod "downwardapi-volume-420507e8-0a62-11e9-8a07-628dff7095f4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.02768221s
Dec 28 05:34:38.268: INFO: Pod "downwardapi-volume-420507e8-0a62-11e9-8a07-628dff7095f4": Phase="Pending", Reason="", readiness=false. Elapsed: 4.03547754s
Dec 28 05:34:40.275: INFO: Pod "downwardapi-volume-420507e8-0a62-11e9-8a07-628dff7095f4": Phase="Pending", Reason="", readiness=false. Elapsed: 6.042694357s
Dec 28 05:34:42.283: INFO: Pod "downwardapi-volume-420507e8-0a62-11e9-8a07-628dff7095f4": Phase="Pending", Reason="", readiness=false. Elapsed: 8.050562313s
Dec 28 05:34:44.321: INFO: Pod "downwardapi-volume-420507e8-0a62-11e9-8a07-628dff7095f4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 10.088602627s
STEP: Saw pod success
Dec 28 05:34:44.321: INFO: Pod "downwardapi-volume-420507e8-0a62-11e9-8a07-628dff7095f4" satisfied condition "success or failure"
Dec 28 05:34:44.327: INFO: Trying to get logs from node 10.10.102.69-build pod downwardapi-volume-420507e8-0a62-11e9-8a07-628dff7095f4 container client-container: <nil>
STEP: delete the pod
Dec 28 05:34:44.381: INFO: Waiting for pod downwardapi-volume-420507e8-0a62-11e9-8a07-628dff7095f4 to disappear
Dec 28 05:34:44.392: INFO: Pod downwardapi-volume-420507e8-0a62-11e9-8a07-628dff7095f4 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 28 05:34:44.392: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-zkxxj" for this suite.
Dec 28 05:34:50.474: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 05:34:50.610: INFO: namespace: e2e-tests-downward-api-zkxxj, resource: bindings, ignored listing per whitelist
Dec 28 05:34:50.767: INFO: namespace e2e-tests-downward-api-zkxxj deletion completed in 6.3642295s

• [SLOW TEST:16.852 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 28 05:34:50.767: INFO: >>> kubeConfig: /tmp/kubeconfig-994138694
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a watch on configmaps
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: closing the watch once it receives two notifications
Dec 28 05:34:51.253: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-6bqwj,SelfLink:/api/v1/namespaces/e2e-tests-watch-6bqwj/configmaps/e2e-watch-test-watch-closed,UID:4c285722-0a62-11e9-a0ee-005056bc4922,ResourceVersion:532754,Generation:0,CreationTimestamp:2018-12-28 05:34:51 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Dec 28 05:34:51.253: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-6bqwj,SelfLink:/api/v1/namespaces/e2e-tests-watch-6bqwj/configmaps/e2e-watch-test-watch-closed,UID:4c285722-0a62-11e9-a0ee-005056bc4922,ResourceVersion:532755,Generation:0,CreationTimestamp:2018-12-28 05:34:51 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time, while the watch is closed
STEP: creating a new watch on configmaps from the last resource version observed by the first watch
STEP: deleting the configmap
STEP: Expecting to observe notifications for all changes to the configmap since the first watch closed
Dec 28 05:34:51.326: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-6bqwj,SelfLink:/api/v1/namespaces/e2e-tests-watch-6bqwj/configmaps/e2e-watch-test-watch-closed,UID:4c285722-0a62-11e9-a0ee-005056bc4922,ResourceVersion:532756,Generation:0,CreationTimestamp:2018-12-28 05:34:51 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Dec 28 05:34:51.327: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-6bqwj,SelfLink:/api/v1/namespaces/e2e-tests-watch-6bqwj/configmaps/e2e-watch-test-watch-closed,UID:4c285722-0a62-11e9-a0ee-005056bc4922,ResourceVersion:532757,Generation:0,CreationTimestamp:2018-12-28 05:34:51 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 28 05:34:51.327: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-6bqwj" for this suite.
Dec 28 05:34:57.432: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 05:34:57.535: INFO: namespace: e2e-tests-watch-6bqwj, resource: bindings, ignored listing per whitelist
Dec 28 05:34:57.660: INFO: namespace e2e-tests-watch-6bqwj deletion completed in 6.27928247s

• [SLOW TEST:6.894 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Burst scaling should run to completion even with unhealthy pods [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 28 05:34:57.661: INFO: >>> kubeConfig: /tmp/kubeconfig-994138694
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-xrnq4
[It] Burst scaling should run to completion even with unhealthy pods [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating stateful set ss in namespace e2e-tests-statefulset-xrnq4
STEP: Waiting until all stateful set ss replicas will be running in namespace e2e-tests-statefulset-xrnq4
Dec 28 05:34:57.948: INFO: Found 0 stateful pods, waiting for 1
Dec 28 05:35:07.957: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will not halt with unhealthy stateful pod
Dec 28 05:35:07.963: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994138694 exec --namespace=e2e-tests-statefulset-xrnq4 ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Dec 28 05:35:08.717: INFO: stderr: ""
Dec 28 05:35:08.717: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Dec 28 05:35:08.717: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Dec 28 05:35:08.724: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Dec 28 05:35:18.763: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Dec 28 05:35:18.764: INFO: Waiting for statefulset status.replicas updated to 0
Dec 28 05:35:18.799: INFO: POD   NODE                PHASE    GRACE  CONDITIONS
Dec 28 05:35:18.799: INFO: ss-0  10.10.102.68-share  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-28 05:34:58 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-28 05:35:09 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-28 05:35:09 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-28 05:34:58 +0000 UTC  }]
Dec 28 05:35:18.799: INFO: 
Dec 28 05:35:18.799: INFO: StatefulSet ss has not reached scale 3, at 1
Dec 28 05:35:19.806: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.98541919s
Dec 28 05:35:20.816: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.978246603s
Dec 28 05:35:21.824: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.968404013s
Dec 28 05:35:22.832: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.960008333s
Dec 28 05:35:23.842: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.95194722s
Dec 28 05:35:24.851: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.94223441s
Dec 28 05:35:25.860: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.93278258s
Dec 28 05:35:26.869: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.924378563s
Dec 28 05:35:27.878: INFO: Verifying statefulset ss doesn't scale past 3 for another 914.99271ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace e2e-tests-statefulset-xrnq4
Dec 28 05:35:28.887: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994138694 exec --namespace=e2e-tests-statefulset-xrnq4 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec 28 05:35:29.428: INFO: stderr: ""
Dec 28 05:35:29.429: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Dec 28 05:35:29.429: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Dec 28 05:35:29.429: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994138694 exec --namespace=e2e-tests-statefulset-xrnq4 ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec 28 05:35:30.160: INFO: stderr: "mv: can't rename '/tmp/index.html': No such file or directory\n"
Dec 28 05:35:30.160: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Dec 28 05:35:30.160: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Dec 28 05:35:30.160: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994138694 exec --namespace=e2e-tests-statefulset-xrnq4 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec 28 05:35:30.847: INFO: stderr: "mv: can't rename '/tmp/index.html': No such file or directory\n"
Dec 28 05:35:30.847: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Dec 28 05:35:30.847: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-2: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Dec 28 05:35:30.855: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Dec 28 05:35:30.855: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Dec 28 05:35:30.855: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Scale down will not halt with unhealthy stateful pod
Dec 28 05:35:30.862: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994138694 exec --namespace=e2e-tests-statefulset-xrnq4 ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Dec 28 05:35:31.398: INFO: stderr: ""
Dec 28 05:35:31.398: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Dec 28 05:35:31.398: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Dec 28 05:35:31.398: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994138694 exec --namespace=e2e-tests-statefulset-xrnq4 ss-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Dec 28 05:35:32.212: INFO: stderr: ""
Dec 28 05:35:32.212: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Dec 28 05:35:32.212: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Dec 28 05:35:32.212: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994138694 exec --namespace=e2e-tests-statefulset-xrnq4 ss-2 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Dec 28 05:35:32.751: INFO: stderr: ""
Dec 28 05:35:32.751: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Dec 28 05:35:32.751: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-2: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Dec 28 05:35:32.751: INFO: Waiting for statefulset status.replicas updated to 0
Dec 28 05:35:32.782: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 1
Dec 28 05:35:42.796: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Dec 28 05:35:42.797: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Dec 28 05:35:42.797: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Dec 28 05:35:42.991: INFO: POD   NODE                PHASE    GRACE  CONDITIONS
Dec 28 05:35:42.991: INFO: ss-0  10.10.102.68-share  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-28 05:34:58 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-28 05:35:31 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-28 05:35:31 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-28 05:34:58 +0000 UTC  }]
Dec 28 05:35:42.992: INFO: ss-1  10.10.102.69-build  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-28 05:35:19 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-28 05:35:33 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-28 05:35:33 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-28 05:35:18 +0000 UTC  }]
Dec 28 05:35:42.992: INFO: ss-2  10.10.102.67-slave  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-28 05:48:33 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-28 05:48:47 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-28 05:48:47 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-28 05:35:19 +0000 UTC  }]
Dec 28 05:35:42.992: INFO: 
Dec 28 05:35:42.992: INFO: StatefulSet ss has not reached scale 0, at 3
Dec 28 05:35:44.050: INFO: POD   NODE                PHASE    GRACE  CONDITIONS
Dec 28 05:35:44.050: INFO: ss-0  10.10.102.68-share  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-28 05:34:58 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-28 05:35:31 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-28 05:35:31 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-28 05:34:58 +0000 UTC  }]
Dec 28 05:35:44.050: INFO: ss-1  10.10.102.69-build  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-28 05:35:19 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-28 05:35:33 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-28 05:35:33 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-28 05:35:18 +0000 UTC  }]
Dec 28 05:35:44.050: INFO: ss-2  10.10.102.67-slave  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-28 05:48:33 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-28 05:48:47 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-28 05:48:47 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-28 05:35:19 +0000 UTC  }]
Dec 28 05:35:44.050: INFO: 
Dec 28 05:35:44.050: INFO: StatefulSet ss has not reached scale 0, at 3
Dec 28 05:35:45.117: INFO: POD   NODE                PHASE    GRACE  CONDITIONS
Dec 28 05:35:45.117: INFO: ss-0  10.10.102.68-share  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-28 05:34:58 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-28 05:35:31 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-28 05:35:31 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-28 05:34:58 +0000 UTC  }]
Dec 28 05:35:45.118: INFO: ss-1  10.10.102.69-build  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-28 05:35:19 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-28 05:35:33 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-28 05:35:33 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-28 05:35:18 +0000 UTC  }]
Dec 28 05:35:45.118: INFO: ss-2  10.10.102.67-slave  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-28 05:48:33 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-28 05:48:47 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-28 05:48:47 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-28 05:35:19 +0000 UTC  }]
Dec 28 05:35:45.118: INFO: 
Dec 28 05:35:45.118: INFO: StatefulSet ss has not reached scale 0, at 3
Dec 28 05:35:46.130: INFO: POD   NODE                PHASE    GRACE  CONDITIONS
Dec 28 05:35:46.130: INFO: ss-0  10.10.102.68-share  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-28 05:34:58 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-28 05:35:31 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-28 05:35:31 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-28 05:34:58 +0000 UTC  }]
Dec 28 05:35:46.131: INFO: ss-1  10.10.102.69-build  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-28 05:35:19 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-28 05:35:33 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-28 05:35:33 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-28 05:35:18 +0000 UTC  }]
Dec 28 05:35:46.131: INFO: ss-2  10.10.102.67-slave  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-28 05:48:33 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-28 05:48:47 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-28 05:48:47 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-28 05:35:19 +0000 UTC  }]
Dec 28 05:35:46.131: INFO: 
Dec 28 05:35:46.131: INFO: StatefulSet ss has not reached scale 0, at 3
Dec 28 05:35:47.139: INFO: POD   NODE                PHASE    GRACE  CONDITIONS
Dec 28 05:35:47.139: INFO: ss-0  10.10.102.68-share  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-28 05:34:58 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-28 05:35:31 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-28 05:35:31 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-28 05:34:58 +0000 UTC  }]
Dec 28 05:35:47.139: INFO: ss-1  10.10.102.69-build  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-28 05:35:19 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-28 05:35:33 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-28 05:35:33 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-28 05:35:18 +0000 UTC  }]
Dec 28 05:35:47.140: INFO: ss-2  10.10.102.67-slave  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-28 05:48:33 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-28 05:48:47 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-28 05:48:47 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-28 05:35:19 +0000 UTC  }]
Dec 28 05:35:47.140: INFO: 
Dec 28 05:35:47.140: INFO: StatefulSet ss has not reached scale 0, at 3
Dec 28 05:35:48.248: INFO: POD   NODE                PHASE    GRACE  CONDITIONS
Dec 28 05:35:48.248: INFO: ss-2  10.10.102.67-slave  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-28 05:48:33 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-28 05:48:47 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-28 05:48:47 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-28 05:35:19 +0000 UTC  }]
Dec 28 05:35:48.248: INFO: 
Dec 28 05:35:48.248: INFO: StatefulSet ss has not reached scale 0, at 1
Dec 28 05:35:49.257: INFO: POD   NODE                PHASE    GRACE  CONDITIONS
Dec 28 05:35:49.257: INFO: ss-2  10.10.102.67-slave  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-28 05:48:33 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-28 05:48:47 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-28 05:48:47 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-28 05:35:19 +0000 UTC  }]
Dec 28 05:35:49.257: INFO: 
Dec 28 05:35:49.257: INFO: StatefulSet ss has not reached scale 0, at 1
Dec 28 05:35:50.265: INFO: POD   NODE                PHASE    GRACE  CONDITIONS
Dec 28 05:35:50.265: INFO: ss-2  10.10.102.67-slave  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-28 05:48:33 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-28 05:48:47 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-28 05:48:47 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-28 05:35:19 +0000 UTC  }]
Dec 28 05:35:50.265: INFO: 
Dec 28 05:35:50.265: INFO: StatefulSet ss has not reached scale 0, at 1
Dec 28 05:35:51.273: INFO: POD   NODE                PHASE    GRACE  CONDITIONS
Dec 28 05:35:51.273: INFO: ss-2  10.10.102.67-slave  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-28 05:48:33 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-28 05:48:47 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-28 05:48:47 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-28 05:35:19 +0000 UTC  }]
Dec 28 05:35:51.273: INFO: 
Dec 28 05:35:51.273: INFO: StatefulSet ss has not reached scale 0, at 1
Dec 28 05:35:52.291: INFO: POD   NODE                PHASE    GRACE  CONDITIONS
Dec 28 05:35:52.291: INFO: ss-2  10.10.102.67-slave  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-28 05:48:33 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-28 05:48:47 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-28 05:48:47 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-28 05:35:19 +0000 UTC  }]
Dec 28 05:35:52.291: INFO: 
Dec 28 05:35:52.291: INFO: StatefulSet ss has not reached scale 0, at 1
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacee2e-tests-statefulset-xrnq4
Dec 28 05:35:53.300: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994138694 exec --namespace=e2e-tests-statefulset-xrnq4 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec 28 05:35:53.641: INFO: rc: 1
Dec 28 05:35:53.641: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-994138694 exec --namespace=e2e-tests-statefulset-xrnq4 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  error: unable to upgrade connection: pod does not exist
 [] <nil> 0xc42267f4a0 exit status 1 <nil> <nil> true [0xc420b48d00 0xc420b48d20 0xc420b48d38] [0xc420b48d00 0xc420b48d20 0xc420b48d38] [0xc420b48d18 0xc420b48d30] [0x8fd520 0x8fd520] 0xc422d8e900 <nil>}:
Command stdout:

stderr:
error: unable to upgrade connection: pod does not exist

error:
exit status 1

Dec 28 05:36:03.642: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994138694 exec --namespace=e2e-tests-statefulset-xrnq4 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec 28 05:36:03.963: INFO: rc: 1
Dec 28 05:36:03.963: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-994138694 exec --namespace=e2e-tests-statefulset-xrnq4 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc42198e330 exit status 1 <nil> <nil> true [0xc420b48d40 0xc420b48d58 0xc420b48d80] [0xc420b48d40 0xc420b48d58 0xc420b48d80] [0xc420b48d50 0xc420b48d78] [0x8fd520 0x8fd520] 0xc422168120 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Dec 28 05:36:13.964: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994138694 exec --namespace=e2e-tests-statefulset-xrnq4 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec 28 05:36:14.221: INFO: rc: 1
Dec 28 05:36:14.221: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-994138694 exec --namespace=e2e-tests-statefulset-xrnq4 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc4228a0450 exit status 1 <nil> <nil> true [0xc42000e010 0xc42000e938 0xc42000eba0] [0xc42000e010 0xc42000e938 0xc42000eba0] [0xc42000e730 0xc42000eac0] [0x8fd520 0x8fd520] 0xc4212fa060 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Dec 28 05:36:24.222: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994138694 exec --namespace=e2e-tests-statefulset-xrnq4 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec 28 05:36:24.501: INFO: rc: 1
Dec 28 05:36:24.501: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-994138694 exec --namespace=e2e-tests-statefulset-xrnq4 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc4228a08a0 exit status 1 <nil> <nil> true [0xc42000eba8 0xc42000ece0 0xc42000ed90] [0xc42000eba8 0xc42000ece0 0xc42000ed90] [0xc42000ecb0 0xc42000ed70] [0x8fd520 0x8fd520] 0xc4212fa180 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Dec 28 05:36:34.502: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994138694 exec --namespace=e2e-tests-statefulset-xrnq4 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec 28 05:36:34.800: INFO: rc: 1
Dec 28 05:36:34.800: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-994138694 exec --namespace=e2e-tests-statefulset-xrnq4 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc422a7a570 exit status 1 <nil> <nil> true [0xc422440008 0xc422440020 0xc422440038] [0xc422440008 0xc422440020 0xc422440038] [0xc422440018 0xc422440030] [0x8fd520 0x8fd520] 0xc42230c060 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Dec 28 05:36:44.800: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994138694 exec --namespace=e2e-tests-statefulset-xrnq4 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec 28 05:36:45.092: INFO: rc: 1
Dec 28 05:36:45.092: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-994138694 exec --namespace=e2e-tests-statefulset-xrnq4 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc422a7a960 exit status 1 <nil> <nil> true [0xc422440040 0xc422440058 0xc422440070] [0xc422440040 0xc422440058 0xc422440070] [0xc422440050 0xc422440068] [0x8fd520 0x8fd520] 0xc42230c180 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Dec 28 05:36:55.092: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994138694 exec --namespace=e2e-tests-statefulset-xrnq4 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec 28 05:36:55.368: INFO: rc: 1
Dec 28 05:36:55.369: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-994138694 exec --namespace=e2e-tests-statefulset-xrnq4 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc4228a0cc0 exit status 1 <nil> <nil> true [0xc42000edd0 0xc42000efa0 0xc42000f0a0] [0xc42000edd0 0xc42000efa0 0xc42000f0a0] [0xc42000eef8 0xc42000f088] [0x8fd520 0x8fd520] 0xc4212fa2a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Dec 28 05:37:05.369: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994138694 exec --namespace=e2e-tests-statefulset-xrnq4 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec 28 05:37:05.691: INFO: rc: 1
Dec 28 05:37:05.691: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-994138694 exec --namespace=e2e-tests-statefulset-xrnq4 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc422a7adb0 exit status 1 <nil> <nil> true [0xc422440078 0xc422440090 0xc4224400a8] [0xc422440078 0xc422440090 0xc4224400a8] [0xc422440088 0xc4224400a0] [0x8fd520 0x8fd520] 0xc42230c2a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Dec 28 05:37:15.692: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994138694 exec --namespace=e2e-tests-statefulset-xrnq4 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec 28 05:37:15.942: INFO: rc: 1
Dec 28 05:37:15.943: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-994138694 exec --namespace=e2e-tests-statefulset-xrnq4 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc422a7b200 exit status 1 <nil> <nil> true [0xc4224400b0 0xc4224400c8 0xc4224400e0] [0xc4224400b0 0xc4224400c8 0xc4224400e0] [0xc4224400c0 0xc4224400d8] [0x8fd520 0x8fd520] 0xc42230c3c0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Dec 28 05:37:25.943: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994138694 exec --namespace=e2e-tests-statefulset-xrnq4 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec 28 05:37:26.218: INFO: rc: 1
Dec 28 05:37:26.218: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-994138694 exec --namespace=e2e-tests-statefulset-xrnq4 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc4228a1110 exit status 1 <nil> <nil> true [0xc42000f0d0 0xc42000f290 0xc42000f448] [0xc42000f0d0 0xc42000f290 0xc42000f448] [0xc42000f208 0xc42000f420] [0x8fd520 0x8fd520] 0xc4212fa3c0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Dec 28 05:37:36.218: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994138694 exec --namespace=e2e-tests-statefulset-xrnq4 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec 28 05:37:36.516: INFO: rc: 1
Dec 28 05:37:36.516: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-994138694 exec --namespace=e2e-tests-statefulset-xrnq4 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc4228a14d0 exit status 1 <nil> <nil> true [0xc42000f4d0 0xc42000f610 0xc42000f6e8] [0xc42000f4d0 0xc42000f610 0xc42000f6e8] [0xc42000f590 0xc42000f690] [0x8fd520 0x8fd520] 0xc4212fa4e0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Dec 28 05:37:46.517: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994138694 exec --namespace=e2e-tests-statefulset-xrnq4 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec 28 05:37:46.805: INFO: rc: 1
Dec 28 05:37:46.805: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-994138694 exec --namespace=e2e-tests-statefulset-xrnq4 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc422a7b620 exit status 1 <nil> <nil> true [0xc4224400e8 0xc422440100 0xc422440118] [0xc4224400e8 0xc422440100 0xc422440118] [0xc4224400f8 0xc422440110] [0x8fd520 0x8fd520] 0xc42230c4e0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Dec 28 05:37:56.805: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994138694 exec --namespace=e2e-tests-statefulset-xrnq4 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec 28 05:37:57.090: INFO: rc: 1
Dec 28 05:37:57.090: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-994138694 exec --namespace=e2e-tests-statefulset-xrnq4 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc4228a18c0 exit status 1 <nil> <nil> true [0xc42000f708 0xc42000f780 0xc42000f840] [0xc42000f708 0xc42000f780 0xc42000f840] [0xc42000f760 0xc42000f7a8] [0x8fd520 0x8fd520] 0xc4212fa600 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Dec 28 05:38:07.091: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994138694 exec --namespace=e2e-tests-statefulset-xrnq4 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec 28 05:38:07.392: INFO: rc: 1
Dec 28 05:38:07.392: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-994138694 exec --namespace=e2e-tests-statefulset-xrnq4 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc422a7a5a0 exit status 1 <nil> <nil> true [0xc422440008 0xc422440020 0xc422440038] [0xc422440008 0xc422440020 0xc422440038] [0xc422440018 0xc422440030] [0x8fd520 0x8fd520] 0xc42230c060 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Dec 28 05:38:17.393: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994138694 exec --namespace=e2e-tests-statefulset-xrnq4 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec 28 05:38:17.671: INFO: rc: 1
Dec 28 05:38:17.671: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-994138694 exec --namespace=e2e-tests-statefulset-xrnq4 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc422a7a9c0 exit status 1 <nil> <nil> true [0xc422440040 0xc422440058 0xc422440070] [0xc422440040 0xc422440058 0xc422440070] [0xc422440050 0xc422440068] [0x8fd520 0x8fd520] 0xc42230c180 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Dec 28 05:38:27.671: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994138694 exec --namespace=e2e-tests-statefulset-xrnq4 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec 28 05:38:27.942: INFO: rc: 1
Dec 28 05:38:27.942: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-994138694 exec --namespace=e2e-tests-statefulset-xrnq4 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc422a7ae40 exit status 1 <nil> <nil> true [0xc422440078 0xc422440090 0xc4224400a8] [0xc422440078 0xc422440090 0xc4224400a8] [0xc422440088 0xc4224400a0] [0x8fd520 0x8fd520] 0xc42230c2a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Dec 28 05:38:37.942: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994138694 exec --namespace=e2e-tests-statefulset-xrnq4 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec 28 05:38:38.244: INFO: rc: 1
Dec 28 05:38:38.244: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-994138694 exec --namespace=e2e-tests-statefulset-xrnq4 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc4228a0480 exit status 1 <nil> <nil> true [0xc42000e010 0xc42000e938 0xc42000eba0] [0xc42000e010 0xc42000e938 0xc42000eba0] [0xc42000e730 0xc42000eac0] [0x8fd520 0x8fd520] 0xc4212fa060 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Dec 28 05:38:48.245: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994138694 exec --namespace=e2e-tests-statefulset-xrnq4 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec 28 05:38:48.524: INFO: rc: 1
Dec 28 05:38:48.525: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-994138694 exec --namespace=e2e-tests-statefulset-xrnq4 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc422a7b2f0 exit status 1 <nil> <nil> true [0xc4224400b0 0xc4224400c8 0xc4224400e0] [0xc4224400b0 0xc4224400c8 0xc4224400e0] [0xc4224400c0 0xc4224400d8] [0x8fd520 0x8fd520] 0xc42230c3c0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Dec 28 05:38:58.525: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994138694 exec --namespace=e2e-tests-statefulset-xrnq4 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec 28 05:38:58.824: INFO: rc: 1
Dec 28 05:38:58.824: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-994138694 exec --namespace=e2e-tests-statefulset-xrnq4 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc422a7b710 exit status 1 <nil> <nil> true [0xc4224400e8 0xc422440100 0xc422440118] [0xc4224400e8 0xc422440100 0xc422440118] [0xc4224400f8 0xc422440110] [0x8fd520 0x8fd520] 0xc42230c4e0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Dec 28 05:39:08.825: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994138694 exec --namespace=e2e-tests-statefulset-xrnq4 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec 28 05:39:09.095: INFO: rc: 1
Dec 28 05:39:09.095: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-994138694 exec --namespace=e2e-tests-statefulset-xrnq4 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc4228a0930 exit status 1 <nil> <nil> true [0xc42000eba8 0xc42000ece0 0xc42000ed90] [0xc42000eba8 0xc42000ece0 0xc42000ed90] [0xc42000ecb0 0xc42000ed70] [0x8fd520 0x8fd520] 0xc4212fa180 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Dec 28 05:39:19.096: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994138694 exec --namespace=e2e-tests-statefulset-xrnq4 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec 28 05:39:19.388: INFO: rc: 1
Dec 28 05:39:19.388: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-994138694 exec --namespace=e2e-tests-statefulset-xrnq4 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc4228a0d50 exit status 1 <nil> <nil> true [0xc42000edd0 0xc42000efa0 0xc42000f0a0] [0xc42000edd0 0xc42000efa0 0xc42000f0a0] [0xc42000eef8 0xc42000f088] [0x8fd520 0x8fd520] 0xc4212fa2a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Dec 28 05:39:29.388: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994138694 exec --namespace=e2e-tests-statefulset-xrnq4 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec 28 05:39:29.670: INFO: rc: 1
Dec 28 05:39:29.670: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-994138694 exec --namespace=e2e-tests-statefulset-xrnq4 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc422a7bb30 exit status 1 <nil> <nil> true [0xc422440120 0xc422440138 0xc422440150] [0xc422440120 0xc422440138 0xc422440150] [0xc422440130 0xc422440148] [0x8fd520 0x8fd520] 0xc42230c660 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Dec 28 05:39:39.671: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994138694 exec --namespace=e2e-tests-statefulset-xrnq4 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec 28 05:39:39.939: INFO: rc: 1
Dec 28 05:39:39.939: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-994138694 exec --namespace=e2e-tests-statefulset-xrnq4 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc4228a1140 exit status 1 <nil> <nil> true [0xc42000f0d0 0xc42000f290 0xc42000f448] [0xc42000f0d0 0xc42000f290 0xc42000f448] [0xc42000f208 0xc42000f420] [0x8fd520 0x8fd520] 0xc4212fa3c0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Dec 28 05:39:49.939: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994138694 exec --namespace=e2e-tests-statefulset-xrnq4 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec 28 05:39:50.260: INFO: rc: 1
Dec 28 05:39:50.260: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-994138694 exec --namespace=e2e-tests-statefulset-xrnq4 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc4228a1560 exit status 1 <nil> <nil> true [0xc42000f4d0 0xc42000f610 0xc42000f6e8] [0xc42000f4d0 0xc42000f610 0xc42000f6e8] [0xc42000f590 0xc42000f690] [0x8fd520 0x8fd520] 0xc4212fa4e0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Dec 28 05:40:00.264: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994138694 exec --namespace=e2e-tests-statefulset-xrnq4 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec 28 05:40:00.624: INFO: rc: 1
Dec 28 05:40:00.624: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-994138694 exec --namespace=e2e-tests-statefulset-xrnq4 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc422a7bf50 exit status 1 <nil> <nil> true [0xc422440158 0xc422440170 0xc422440188] [0xc422440158 0xc422440170 0xc422440188] [0xc422440168 0xc422440180] [0x8fd520 0x8fd520] 0xc42230c780 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Dec 28 05:40:10.624: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994138694 exec --namespace=e2e-tests-statefulset-xrnq4 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec 28 05:40:10.896: INFO: rc: 1
Dec 28 05:40:10.896: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-994138694 exec --namespace=e2e-tests-statefulset-xrnq4 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc4228a1950 exit status 1 <nil> <nil> true [0xc42000f708 0xc42000f780 0xc42000f840] [0xc42000f708 0xc42000f780 0xc42000f840] [0xc42000f760 0xc42000f7a8] [0x8fd520 0x8fd520] 0xc4212fa600 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Dec 28 05:40:20.897: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994138694 exec --namespace=e2e-tests-statefulset-xrnq4 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec 28 05:40:21.180: INFO: rc: 1
Dec 28 05:40:21.181: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-994138694 exec --namespace=e2e-tests-statefulset-xrnq4 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc422a7a570 exit status 1 <nil> <nil> true [0xc422440000 0xc422440018 0xc422440030] [0xc422440000 0xc422440018 0xc422440030] [0xc422440010 0xc422440028] [0x8fd520 0x8fd520] 0xc4212fa060 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Dec 28 05:40:31.181: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994138694 exec --namespace=e2e-tests-statefulset-xrnq4 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec 28 05:40:31.436: INFO: rc: 1
Dec 28 05:40:31.436: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-994138694 exec --namespace=e2e-tests-statefulset-xrnq4 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc422a7a990 exit status 1 <nil> <nil> true [0xc422440038 0xc422440050 0xc422440068] [0xc422440038 0xc422440050 0xc422440068] [0xc422440048 0xc422440060] [0x8fd520 0x8fd520] 0xc4212fa180 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Dec 28 05:40:41.436: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994138694 exec --namespace=e2e-tests-statefulset-xrnq4 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec 28 05:40:41.719: INFO: rc: 1
Dec 28 05:40:41.720: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-994138694 exec --namespace=e2e-tests-statefulset-xrnq4 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc422a7ae10 exit status 1 <nil> <nil> true [0xc422440070 0xc422440088 0xc4224400a0] [0xc422440070 0xc422440088 0xc4224400a0] [0xc422440080 0xc422440098] [0x8fd520 0x8fd520] 0xc4212fa2a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Dec 28 05:40:51.720: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994138694 exec --namespace=e2e-tests-statefulset-xrnq4 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec 28 05:40:51.987: INFO: rc: 1
Dec 28 05:40:51.987: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-994138694 exec --namespace=e2e-tests-statefulset-xrnq4 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc4228a04b0 exit status 1 <nil> <nil> true [0xc42000e570 0xc42000ea40 0xc42000eba8] [0xc42000e570 0xc42000ea40 0xc42000eba8] [0xc42000e938 0xc42000eba0] [0x8fd520 0x8fd520] 0xc42230c060 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Dec 28 05:41:01.988: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994138694 exec --namespace=e2e-tests-statefulset-xrnq4 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec 28 05:41:02.344: INFO: rc: 1
Dec 28 05:41:02.345: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-2: 
Dec 28 05:41:02.345: INFO: Scaling statefulset ss to 0
Dec 28 05:41:02.364: INFO: Waiting for statefulset status.replicas updated to 0
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Dec 28 05:41:02.370: INFO: Deleting all statefulset in ns e2e-tests-statefulset-xrnq4
Dec 28 05:41:02.375: INFO: Scaling statefulset ss to 0
Dec 28 05:41:02.395: INFO: Waiting for statefulset status.replicas updated to 0
Dec 28 05:41:02.400: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 28 05:41:02.449: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-xrnq4" for this suite.
Dec 28 05:41:10.496: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 05:41:10.630: INFO: namespace: e2e-tests-statefulset-xrnq4, resource: bindings, ignored listing per whitelist
Dec 28 05:41:10.786: INFO: namespace e2e-tests-statefulset-xrnq4 deletion completed in 8.318857356s

• [SLOW TEST:373.125 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    Burst scaling should run to completion even with unhealthy pods [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl logs 
  should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 28 05:41:10.787: INFO: >>> kubeConfig: /tmp/kubeconfig-994138694
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Kubectl logs
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1083
STEP: creating an rc
Dec 28 05:41:11.297: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994138694 create -f - --namespace=e2e-tests-kubectl-j22ts'
Dec 28 05:41:14.968: INFO: stderr: ""
Dec 28 05:41:14.969: INFO: stdout: "replicationcontroller/redis-master created\n"
[It] should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Waiting for Redis master to start.
Dec 28 05:41:15.976: INFO: Selector matched 1 pods for map[app:redis]
Dec 28 05:41:15.977: INFO: Found 0 / 1
Dec 28 05:41:16.977: INFO: Selector matched 1 pods for map[app:redis]
Dec 28 05:41:16.977: INFO: Found 0 / 1
Dec 28 05:41:17.976: INFO: Selector matched 1 pods for map[app:redis]
Dec 28 05:41:17.976: INFO: Found 0 / 1
Dec 28 05:41:18.976: INFO: Selector matched 1 pods for map[app:redis]
Dec 28 05:41:18.976: INFO: Found 0 / 1
Dec 28 05:41:19.976: INFO: Selector matched 1 pods for map[app:redis]
Dec 28 05:41:19.976: INFO: Found 0 / 1
Dec 28 05:41:20.977: INFO: Selector matched 1 pods for map[app:redis]
Dec 28 05:41:20.977: INFO: Found 0 / 1
Dec 28 05:41:22.015: INFO: Selector matched 1 pods for map[app:redis]
Dec 28 05:41:22.015: INFO: Found 0 / 1
Dec 28 05:41:22.977: INFO: Selector matched 1 pods for map[app:redis]
Dec 28 05:41:22.977: INFO: Found 1 / 1
Dec 28 05:41:22.977: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Dec 28 05:41:22.984: INFO: Selector matched 1 pods for map[app:redis]
Dec 28 05:41:22.984: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
STEP: checking for a matching strings
Dec 28 05:41:22.984: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994138694 logs redis-master-qcsbc redis-master --namespace=e2e-tests-kubectl-j22ts'
Dec 28 05:41:23.336: INFO: stderr: ""
Dec 28 05:41:23.336: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 28 Dec 05:41:23.091 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 28 Dec 05:41:23.094 # Server started, Redis version 3.2.12\n1:M 28 Dec 05:41:23.095 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 28 Dec 05:41:23.095 * The server is now ready to accept connections on port 6379\n"
STEP: limiting log lines
Dec 28 05:41:23.337: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994138694 log redis-master-qcsbc redis-master --namespace=e2e-tests-kubectl-j22ts --tail=1'
Dec 28 05:41:23.670: INFO: stderr: ""
Dec 28 05:41:23.670: INFO: stdout: "1:M 28 Dec 05:41:23.095 * The server is now ready to accept connections on port 6379\n"
STEP: limiting log bytes
Dec 28 05:41:23.671: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994138694 log redis-master-qcsbc redis-master --namespace=e2e-tests-kubectl-j22ts --limit-bytes=1'
Dec 28 05:41:24.003: INFO: stderr: ""
Dec 28 05:41:24.003: INFO: stdout: " "
STEP: exposing timestamps
Dec 28 05:41:24.004: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994138694 log redis-master-qcsbc redis-master --namespace=e2e-tests-kubectl-j22ts --tail=1 --timestamps'
Dec 28 05:41:24.355: INFO: stderr: ""
Dec 28 05:41:24.355: INFO: stdout: "2018-12-28T05:41:23.096230742Z 1:M 28 Dec 05:41:23.095 * The server is now ready to accept connections on port 6379\n"
STEP: restricting to a time range
Dec 28 05:41:26.855: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994138694 log redis-master-qcsbc redis-master --namespace=e2e-tests-kubectl-j22ts --since=1s'
Dec 28 05:41:27.257: INFO: stderr: ""
Dec 28 05:41:27.257: INFO: stdout: ""
Dec 28 05:41:27.257: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994138694 log redis-master-qcsbc redis-master --namespace=e2e-tests-kubectl-j22ts --since=24h'
Dec 28 05:41:27.596: INFO: stderr: ""
Dec 28 05:41:27.596: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 28 Dec 05:41:23.091 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 28 Dec 05:41:23.094 # Server started, Redis version 3.2.12\n1:M 28 Dec 05:41:23.095 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 28 Dec 05:41:23.095 * The server is now ready to accept connections on port 6379\n"
[AfterEach] [k8s.io] Kubectl logs
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1088
STEP: using delete to clean up resources
Dec 28 05:41:27.596: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994138694 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-j22ts'
Dec 28 05:41:27.922: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Dec 28 05:41:27.922: INFO: stdout: "replicationcontroller \"redis-master\" force deleted\n"
Dec 28 05:41:27.922: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994138694 get rc,svc -l name=nginx --no-headers --namespace=e2e-tests-kubectl-j22ts'
Dec 28 05:41:28.216: INFO: stderr: "No resources found.\n"
Dec 28 05:41:28.216: INFO: stdout: ""
Dec 28 05:41:28.216: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994138694 get pods -l name=nginx --namespace=e2e-tests-kubectl-j22ts -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Dec 28 05:41:28.490: INFO: stderr: ""
Dec 28 05:41:28.491: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 28 05:41:28.491: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-j22ts" for this suite.
Dec 28 05:41:34.595: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 05:41:34.845: INFO: namespace: e2e-tests-kubectl-j22ts, resource: bindings, ignored listing per whitelist
Dec 28 05:41:34.904: INFO: namespace e2e-tests-kubectl-j22ts deletion completed in 6.40480053s

• [SLOW TEST:24.117 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl logs
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should be able to retrieve and filter logs  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 28 05:41:34.906: INFO: >>> kubeConfig: /tmp/kubeconfig-994138694
STEP: Building a namespace api object, basename namespaces
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a test namespace
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a service in the namespace
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Verifying there is no service in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 28 05:41:42.827: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-namespaces-zvwsv" for this suite.
Dec 28 05:41:48.886: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 05:41:49.028: INFO: namespace: e2e-tests-namespaces-zvwsv, resource: bindings, ignored listing per whitelist
Dec 28 05:41:49.108: INFO: namespace e2e-tests-namespaces-zvwsv deletion completed in 6.268907193s
STEP: Destroying namespace "e2e-tests-nsdeletetest-rzfpc" for this suite.
Dec 28 05:41:49.127: INFO: Namespace e2e-tests-nsdeletetest-rzfpc was already deleted
STEP: Destroying namespace "e2e-tests-nsdeletetest-srz8t" for this suite.
Dec 28 05:41:55.153: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 05:41:55.181: INFO: namespace: e2e-tests-nsdeletetest-srz8t, resource: bindings, ignored listing per whitelist
Dec 28 05:41:55.373: INFO: namespace e2e-tests-nsdeletetest-srz8t deletion completed in 6.246252406s

• [SLOW TEST:20.468 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 28 05:41:55.374: INFO: >>> kubeConfig: /tmp/kubeconfig-994138694
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0644 on tmpfs
Dec 28 05:41:55.706: INFO: Waiting up to 5m0s for pod "pod-4927f7d7-0a63-11e9-8a07-628dff7095f4" in namespace "e2e-tests-emptydir-jcqv2" to be "success or failure"
Dec 28 05:41:55.716: INFO: Pod "pod-4927f7d7-0a63-11e9-8a07-628dff7095f4": Phase="Pending", Reason="", readiness=false. Elapsed: 9.815066ms
Dec 28 05:41:57.725: INFO: Pod "pod-4927f7d7-0a63-11e9-8a07-628dff7095f4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.018498133s
Dec 28 05:41:59.732: INFO: Pod "pod-4927f7d7-0a63-11e9-8a07-628dff7095f4": Phase="Pending", Reason="", readiness=false. Elapsed: 4.02615466s
Dec 28 05:42:01.739: INFO: Pod "pod-4927f7d7-0a63-11e9-8a07-628dff7095f4": Phase="Pending", Reason="", readiness=false. Elapsed: 6.032642956s
Dec 28 05:42:03.746: INFO: Pod "pod-4927f7d7-0a63-11e9-8a07-628dff7095f4": Phase="Pending", Reason="", readiness=false. Elapsed: 8.04021036s
Dec 28 05:42:05.756: INFO: Pod "pod-4927f7d7-0a63-11e9-8a07-628dff7095f4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 10.04977643s
STEP: Saw pod success
Dec 28 05:42:05.756: INFO: Pod "pod-4927f7d7-0a63-11e9-8a07-628dff7095f4" satisfied condition "success or failure"
Dec 28 05:42:05.764: INFO: Trying to get logs from node 10.10.102.68-share pod pod-4927f7d7-0a63-11e9-8a07-628dff7095f4 container test-container: <nil>
STEP: delete the pod
Dec 28 05:42:05.929: INFO: Waiting for pod pod-4927f7d7-0a63-11e9-8a07-628dff7095f4 to disappear
Dec 28 05:42:05.946: INFO: Pod pod-4927f7d7-0a63-11e9-8a07-628dff7095f4 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 28 05:42:05.946: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-jcqv2" for this suite.
Dec 28 05:42:14.062: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 05:42:14.144: INFO: namespace: e2e-tests-emptydir-jcqv2, resource: bindings, ignored listing per whitelist
Dec 28 05:42:14.253: INFO: namespace e2e-tests-emptydir-jcqv2 deletion completed in 8.291064426s

• [SLOW TEST:18.879 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 28 05:42:14.254: INFO: >>> kubeConfig: /tmp/kubeconfig-994138694
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-map-5464a580-0a63-11e9-8a07-628dff7095f4
STEP: Creating a pod to test consume configMaps
Dec 28 05:42:14.602: INFO: Waiting up to 5m0s for pod "pod-configmaps-54661738-0a63-11e9-8a07-628dff7095f4" in namespace "e2e-tests-configmap-tf7sq" to be "success or failure"
Dec 28 05:42:14.623: INFO: Pod "pod-configmaps-54661738-0a63-11e9-8a07-628dff7095f4": Phase="Pending", Reason="", readiness=false. Elapsed: 20.421103ms
Dec 28 05:42:16.637: INFO: Pod "pod-configmaps-54661738-0a63-11e9-8a07-628dff7095f4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.03425861s
Dec 28 05:42:18.645: INFO: Pod "pod-configmaps-54661738-0a63-11e9-8a07-628dff7095f4": Phase="Pending", Reason="", readiness=false. Elapsed: 4.042912633s
Dec 28 05:42:20.654: INFO: Pod "pod-configmaps-54661738-0a63-11e9-8a07-628dff7095f4": Phase="Pending", Reason="", readiness=false. Elapsed: 6.050981423s
Dec 28 05:42:22.661: INFO: Pod "pod-configmaps-54661738-0a63-11e9-8a07-628dff7095f4": Phase="Running", Reason="", readiness=true. Elapsed: 8.058681767s
Dec 28 05:42:24.669: INFO: Pod "pod-configmaps-54661738-0a63-11e9-8a07-628dff7095f4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 10.06624504s
STEP: Saw pod success
Dec 28 05:42:24.669: INFO: Pod "pod-configmaps-54661738-0a63-11e9-8a07-628dff7095f4" satisfied condition "success or failure"
Dec 28 05:42:24.676: INFO: Trying to get logs from node 10.10.102.69-build pod pod-configmaps-54661738-0a63-11e9-8a07-628dff7095f4 container configmap-volume-test: <nil>
STEP: delete the pod
Dec 28 05:42:24.851: INFO: Waiting for pod pod-configmaps-54661738-0a63-11e9-8a07-628dff7095f4 to disappear
Dec 28 05:42:24.960: INFO: Pod pod-configmaps-54661738-0a63-11e9-8a07-628dff7095f4 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 28 05:42:24.961: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-tf7sq" for this suite.
Dec 28 05:42:31.018: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 05:42:31.336: INFO: namespace: e2e-tests-configmap-tf7sq, resource: bindings, ignored listing per whitelist
Dec 28 05:42:31.364: INFO: namespace e2e-tests-configmap-tf7sq deletion completed in 6.388718317s

• [SLOW TEST:17.110 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] [sig-node] Pods Extended [k8s.io] Pods Set QOS Class 
  should be submitted and removed  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 28 05:42:31.365: INFO: >>> kubeConfig: /tmp/kubeconfig-994138694
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pods.go:204
[It] should be submitted and removed  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying QOS class is set on the pod
[AfterEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 28 05:42:31.657: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-wm98s" for this suite.
Dec 28 05:42:55.707: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 05:42:55.750: INFO: namespace: e2e-tests-pods-wm98s, resource: bindings, ignored listing per whitelist
Dec 28 05:42:55.915: INFO: namespace e2e-tests-pods-wm98s deletion completed in 24.239041577s

• [SLOW TEST:24.550 seconds]
[k8s.io] [sig-node] Pods Extended
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should be submitted and removed  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[k8s.io] Pods 
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 28 05:42:55.915: INFO: >>> kubeConfig: /tmp/kubeconfig-994138694
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Dec 28 05:43:08.815: INFO: Successfully updated pod "pod-update-activedeadlineseconds-6d34fde1-0a63-11e9-8a07-628dff7095f4"
Dec 28 05:43:08.816: INFO: Waiting up to 5m0s for pod "pod-update-activedeadlineseconds-6d34fde1-0a63-11e9-8a07-628dff7095f4" in namespace "e2e-tests-pods-d9bnp" to be "terminated due to deadline exceeded"
Dec 28 05:43:08.831: INFO: Pod "pod-update-activedeadlineseconds-6d34fde1-0a63-11e9-8a07-628dff7095f4": Phase="Running", Reason="", readiness=true. Elapsed: 15.81615ms
Dec 28 05:43:10.845: INFO: Pod "pod-update-activedeadlineseconds-6d34fde1-0a63-11e9-8a07-628dff7095f4": Phase="Failed", Reason="DeadlineExceeded", readiness=false. Elapsed: 2.029029306s
Dec 28 05:43:10.845: INFO: Pod "pod-update-activedeadlineseconds-6d34fde1-0a63-11e9-8a07-628dff7095f4" satisfied condition "terminated due to deadline exceeded"
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 28 05:43:10.845: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-d9bnp" for this suite.
Dec 28 05:43:18.948: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 05:43:19.038: INFO: namespace: e2e-tests-pods-d9bnp, resource: bindings, ignored listing per whitelist
Dec 28 05:43:19.174: INFO: namespace e2e-tests-pods-d9bnp deletion completed in 8.316261006s

• [SLOW TEST:23.258 seconds]
[k8s.io] Pods
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run deployment 
  should create a deployment from an image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 28 05:43:19.174: INFO: >>> kubeConfig: /tmp/kubeconfig-994138694
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Kubectl run deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1347
[It] should create a deployment from an image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Dec 28 05:43:19.408: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994138694 run e2e-test-nginx-deployment --image=docker.io/library/nginx:1.14-alpine --generator=deployment/v1beta1 --namespace=e2e-tests-kubectl-xzgzr'
Dec 28 05:43:19.735: INFO: stderr: "kubectl run --generator=deployment/v1beta1 is DEPRECATED and will be removed in a future version. Use kubectl create instead.\n"
Dec 28 05:43:19.735: INFO: stdout: "deployment.extensions/e2e-test-nginx-deployment created\n"
STEP: verifying the deployment e2e-test-nginx-deployment was created
STEP: verifying the pod controlled by deployment e2e-test-nginx-deployment was created
[AfterEach] [k8s.io] Kubectl run deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1352
Dec 28 05:43:23.903: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994138694 delete deployment e2e-test-nginx-deployment --namespace=e2e-tests-kubectl-xzgzr'
Dec 28 05:43:24.264: INFO: stderr: ""
Dec 28 05:43:24.264: INFO: stdout: "deployment.extensions \"e2e-test-nginx-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 28 05:43:24.264: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-xzgzr" for this suite.
Dec 28 05:43:48.456: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 05:43:48.650: INFO: namespace: e2e-tests-kubectl-xzgzr, resource: bindings, ignored listing per whitelist
Dec 28 05:43:48.673: INFO: namespace e2e-tests-kubectl-xzgzr deletion completed in 24.393830407s

• [SLOW TEST:29.499 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create a deployment from an image  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl expose 
  should create services for rc  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 28 05:43:48.674: INFO: >>> kubeConfig: /tmp/kubeconfig-994138694
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should create services for rc  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating Redis RC
Dec 28 05:43:49.014: INFO: namespace e2e-tests-kubectl-hrsdj
Dec 28 05:43:49.014: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994138694 create -f - --namespace=e2e-tests-kubectl-hrsdj'
Dec 28 05:43:49.964: INFO: stderr: ""
Dec 28 05:43:49.964: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
Dec 28 05:43:50.972: INFO: Selector matched 1 pods for map[app:redis]
Dec 28 05:43:50.973: INFO: Found 0 / 1
Dec 28 05:43:51.972: INFO: Selector matched 1 pods for map[app:redis]
Dec 28 05:43:51.972: INFO: Found 0 / 1
Dec 28 05:43:52.973: INFO: Selector matched 1 pods for map[app:redis]
Dec 28 05:43:52.973: INFO: Found 0 / 1
Dec 28 05:43:53.973: INFO: Selector matched 1 pods for map[app:redis]
Dec 28 05:43:53.973: INFO: Found 0 / 1
Dec 28 05:43:54.973: INFO: Selector matched 1 pods for map[app:redis]
Dec 28 05:43:54.973: INFO: Found 0 / 1
Dec 28 05:43:55.972: INFO: Selector matched 1 pods for map[app:redis]
Dec 28 05:43:55.972: INFO: Found 0 / 1
Dec 28 05:43:56.972: INFO: Selector matched 1 pods for map[app:redis]
Dec 28 05:43:56.972: INFO: Found 0 / 1
Dec 28 05:43:57.971: INFO: Selector matched 1 pods for map[app:redis]
Dec 28 05:43:57.971: INFO: Found 1 / 1
Dec 28 05:43:57.972: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Dec 28 05:43:57.977: INFO: Selector matched 1 pods for map[app:redis]
Dec 28 05:43:57.977: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Dec 28 05:43:57.977: INFO: wait on redis-master startup in e2e-tests-kubectl-hrsdj 
Dec 28 05:43:57.978: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994138694 logs redis-master-wtj52 redis-master --namespace=e2e-tests-kubectl-hrsdj'
Dec 28 05:43:58.359: INFO: stderr: ""
Dec 28 05:43:58.359: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 28 Dec 05:43:57.919 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 28 Dec 05:43:57.925 # Server started, Redis version 3.2.12\n1:M 28 Dec 05:43:57.925 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 28 Dec 05:43:57.926 * The server is now ready to accept connections on port 6379\n"
STEP: exposing RC
Dec 28 05:43:58.360: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994138694 expose rc redis-master --name=rm2 --port=1234 --target-port=6379 --namespace=e2e-tests-kubectl-hrsdj'
Dec 28 05:43:58.785: INFO: stderr: ""
Dec 28 05:43:58.785: INFO: stdout: "service/rm2 exposed\n"
Dec 28 05:43:58.796: INFO: Service rm2 in namespace e2e-tests-kubectl-hrsdj found.
STEP: exposing service
Dec 28 05:44:00.811: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994138694 expose service rm2 --name=rm3 --port=2345 --target-port=6379 --namespace=e2e-tests-kubectl-hrsdj'
Dec 28 05:44:01.272: INFO: stderr: ""
Dec 28 05:44:01.272: INFO: stdout: "service/rm3 exposed\n"
Dec 28 05:44:01.297: INFO: Service rm3 in namespace e2e-tests-kubectl-hrsdj found.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 28 05:44:03.309: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-hrsdj" for this suite.
Dec 28 05:44:27.347: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 05:44:27.446: INFO: namespace: e2e-tests-kubectl-hrsdj, resource: bindings, ignored listing per whitelist
Dec 28 05:44:27.555: INFO: namespace e2e-tests-kubectl-hrsdj deletion completed in 24.235134307s

• [SLOW TEST:38.881 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl expose
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create services for rc  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 28 05:44:27.556: INFO: >>> kubeConfig: /tmp/kubeconfig-994138694
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test use defaults
Dec 28 05:44:28.197: INFO: Waiting up to 5m0s for pod "client-containers-a40ce931-0a63-11e9-8a07-628dff7095f4" in namespace "e2e-tests-containers-4tmsc" to be "success or failure"
Dec 28 05:44:28.213: INFO: Pod "client-containers-a40ce931-0a63-11e9-8a07-628dff7095f4": Phase="Pending", Reason="", readiness=false. Elapsed: 15.96285ms
Dec 28 05:44:30.230: INFO: Pod "client-containers-a40ce931-0a63-11e9-8a07-628dff7095f4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.032739027s
Dec 28 05:44:32.264: INFO: Pod "client-containers-a40ce931-0a63-11e9-8a07-628dff7095f4": Phase="Pending", Reason="", readiness=false. Elapsed: 4.067512217s
Dec 28 05:44:34.327: INFO: Pod "client-containers-a40ce931-0a63-11e9-8a07-628dff7095f4": Phase="Pending", Reason="", readiness=false. Elapsed: 6.13001404s
Dec 28 05:44:36.403: INFO: Pod "client-containers-a40ce931-0a63-11e9-8a07-628dff7095f4": Phase="Pending", Reason="", readiness=false. Elapsed: 8.205712194s
Dec 28 05:44:38.411: INFO: Pod "client-containers-a40ce931-0a63-11e9-8a07-628dff7095f4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 10.214208214s
STEP: Saw pod success
Dec 28 05:44:38.411: INFO: Pod "client-containers-a40ce931-0a63-11e9-8a07-628dff7095f4" satisfied condition "success or failure"
Dec 28 05:44:38.416: INFO: Trying to get logs from node 10.10.102.68-share pod client-containers-a40ce931-0a63-11e9-8a07-628dff7095f4 container test-container: <nil>
STEP: delete the pod
Dec 28 05:44:38.482: INFO: Waiting for pod client-containers-a40ce931-0a63-11e9-8a07-628dff7095f4 to disappear
Dec 28 05:44:38.627: INFO: Pod client-containers-a40ce931-0a63-11e9-8a07-628dff7095f4 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 28 05:44:38.627: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-4tmsc" for this suite.
Dec 28 05:44:46.700: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 05:44:46.967: INFO: namespace: e2e-tests-containers-4tmsc, resource: bindings, ignored listing per whitelist
Dec 28 05:44:47.002: INFO: namespace e2e-tests-containers-4tmsc deletion completed in 8.364459963s

• [SLOW TEST:19.446 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-apps] Deployment 
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 28 05:44:47.002: INFO: >>> kubeConfig: /tmp/kubeconfig-994138694
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Dec 28 05:44:47.229: INFO: Creating deployment "nginx-deployment"
Dec 28 05:44:47.240: INFO: Waiting for observed generation 1
Dec 28 05:44:49.266: INFO: Waiting for all required pods to come up
Dec 28 05:44:49.275: INFO: Pod name nginx: Found 10 pods out of 10
STEP: ensuring each pod is running
Dec 28 05:45:21.326: INFO: Waiting for deployment "nginx-deployment" to complete
Dec 28 05:45:21.338: INFO: Updating deployment "nginx-deployment" with a non-existent image
Dec 28 05:45:21.353: INFO: Updating deployment nginx-deployment
Dec 28 05:45:21.353: INFO: Waiting for observed generation 2
Dec 28 05:45:23.367: INFO: Waiting for the first rollout's replicaset to have .status.availableReplicas = 8
Dec 28 05:45:23.411: INFO: Waiting for the first rollout's replicaset to have .spec.replicas = 8
Dec 28 05:45:23.416: INFO: Waiting for the first rollout's replicaset of deployment "nginx-deployment" to have desired number of replicas
Dec 28 05:45:23.433: INFO: Verifying that the second rollout's replicaset has .status.availableReplicas = 0
Dec 28 05:45:23.433: INFO: Waiting for the second rollout's replicaset to have .spec.replicas = 5
Dec 28 05:45:23.438: INFO: Waiting for the second rollout's replicaset of deployment "nginx-deployment" to have desired number of replicas
Dec 28 05:45:23.455: INFO: Verifying that deployment "nginx-deployment" has minimum required number of available replicas
Dec 28 05:45:23.455: INFO: Scaling up the deployment "nginx-deployment" from 10 to 30
Dec 28 05:45:23.467: INFO: Updating deployment nginx-deployment
Dec 28 05:45:23.467: INFO: Waiting for the replicasets of deployment "nginx-deployment" to have desired number of replicas
Dec 28 05:45:23.511: INFO: Verifying that first rollout's replicaset has .spec.replicas = 20
Dec 28 05:45:23.750: INFO: Verifying that second rollout's replicaset has .spec.replicas = 13
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Dec 28 05:45:24.139: INFO: Deployment "nginx-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment,GenerateName:,Namespace:e2e-tests-deployment-fnnm9,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-fnnm9/deployments/nginx-deployment,UID:af7984c4-0a63-11e9-a0ee-005056bc4922,ResourceVersion:534719,Generation:3,CreationTimestamp:2018-12-28 05:44:47 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*30,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:2,MaxSurge:3,},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:3,Replicas:13,UpdatedReplicas:5,AvailableReplicas:8,UnavailableReplicas:25,Conditions:[{Progressing True 2018-12-28 05:45:22 +0000 UTC 2018-12-28 05:44:47 +0000 UTC ReplicaSetUpdated ReplicaSet "nginx-deployment-7dc8f79789" is progressing.} {Available False 2018-12-28 05:45:23 +0000 UTC 2018-12-28 05:45:23 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}],ReadyReplicas:8,CollisionCount:nil,},}

Dec 28 05:45:24.278: INFO: New ReplicaSet "nginx-deployment-7dc8f79789" of Deployment "nginx-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789,GenerateName:,Namespace:e2e-tests-deployment-fnnm9,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-fnnm9/replicasets/nginx-deployment-7dc8f79789,UID:c3cfc7dd-0a63-11e9-a0ee-005056bc4922,ResourceVersion:534697,Generation:3,CreationTimestamp:2018-12-28 05:45:21 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 30,deployment.kubernetes.io/max-replicas: 33,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment nginx-deployment af7984c4-0a63-11e9-a0ee-005056bc4922 0xc4212b6e87 0xc4212b6e88}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*13,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:5,FullyLabeledReplicas:5,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Dec 28 05:45:24.279: INFO: All old ReplicaSets of Deployment "nginx-deployment":
Dec 28 05:45:24.279: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b,GenerateName:,Namespace:e2e-tests-deployment-fnnm9,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-fnnm9/replicasets/nginx-deployment-7f9675fb8b,UID:af7e61b6-0a63-11e9-a0ee-005056bc4922,ResourceVersion:534738,Generation:3,CreationTimestamp:2018-12-28 05:44:47 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 30,deployment.kubernetes.io/max-replicas: 33,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment nginx-deployment af7984c4-0a63-11e9-a0ee-005056bc4922 0xc4212b7337 0xc4212b7338}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*20,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:8,FullyLabeledReplicas:8,ObservedGeneration:3,ReadyReplicas:8,AvailableReplicas:8,Conditions:[],},}
Dec 28 05:45:24.394: INFO: Pod "nginx-deployment-7dc8f79789-5mw2r" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-5mw2r,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-fnnm9,SelfLink:/api/v1/namespaces/e2e-tests-deployment-fnnm9/pods/nginx-deployment-7dc8f79789-5mw2r,UID:c51fedff-0a63-11e9-a0ee-005056bc4922,ResourceVersion:534734,Generation:0,CreationTimestamp:2018-12-28 05:45:23 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 c3cfc7dd-0a63-11e9-a0ee-005056bc4922 0xc421950237 0xc421950238}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-vrzvs {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-vrzvs,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-vrzvs true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.10.102.67-slave,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc4219502a0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc4219502d0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-28 05:45:23 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec 28 05:45:24.394: INFO: Pod "nginx-deployment-7dc8f79789-6vk4d" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-6vk4d,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-fnnm9,SelfLink:/api/v1/namespaces/e2e-tests-deployment-fnnm9/pods/nginx-deployment-7dc8f79789-6vk4d,UID:c41d9c54-0a63-11e9-a0ee-005056bc4922,ResourceVersion:534688,Generation:0,CreationTimestamp:2018-12-28 05:45:21 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 c3cfc7dd-0a63-11e9-a0ee-005056bc4922 0xc4219503d0 0xc4219503d1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-vrzvs {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-vrzvs,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-vrzvs true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.10.102.68-share,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc421950460} {node.kubernetes.io/unreachable Exists  NoExecute 0xc4219504e0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-28 05:45:22 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-28 05:45:22 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-28 05:45:22 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-28 05:45:22 +0000 UTC  }],Message:,Reason:,HostIP:10.10.102.68,PodIP:,StartTime:2018-12-28 05:45:22 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec 28 05:45:24.395: INFO: Pod "nginx-deployment-7dc8f79789-bjm88" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-bjm88,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-fnnm9,SelfLink:/api/v1/namespaces/e2e-tests-deployment-fnnm9/pods/nginx-deployment-7dc8f79789-bjm88,UID:c40006c4-0a63-11e9-a0ee-005056bc4922,ResourceVersion:534687,Generation:0,CreationTimestamp:2018-12-28 05:45:21 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 c3cfc7dd-0a63-11e9-a0ee-005056bc4922 0xc421950720 0xc421950721}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-vrzvs {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-vrzvs,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-vrzvs true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.10.102.66-slave,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc421950a10} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421950a30}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-28 05:45:21 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-28 05:45:21 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-28 05:45:21 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-28 05:45:21 +0000 UTC  }],Message:,Reason:,HostIP:10.10.102.66,PodIP:,StartTime:2018-12-28 05:45:21 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec 28 05:45:24.395: INFO: Pod "nginx-deployment-7dc8f79789-bpnrs" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-bpnrs,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-fnnm9,SelfLink:/api/v1/namespaces/e2e-tests-deployment-fnnm9/pods/nginx-deployment-7dc8f79789-bpnrs,UID:c51feca4-0a63-11e9-a0ee-005056bc4922,ResourceVersion:534735,Generation:0,CreationTimestamp:2018-12-28 05:45:23 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 c3cfc7dd-0a63-11e9-a0ee-005056bc4922 0xc421f743d0 0xc421f743d1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-vrzvs {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-vrzvs,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-vrzvs true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.10.102.67-slave,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc421f74450} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421f74500}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-28 05:45:23 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec 28 05:45:24.395: INFO: Pod "nginx-deployment-7dc8f79789-gmvhg" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-gmvhg,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-fnnm9,SelfLink:/api/v1/namespaces/e2e-tests-deployment-fnnm9/pods/nginx-deployment-7dc8f79789-gmvhg,UID:c3d6ffd5-0a63-11e9-a0ee-005056bc4922,ResourceVersion:534684,Generation:0,CreationTimestamp:2018-12-28 05:45:21 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 c3cfc7dd-0a63-11e9-a0ee-005056bc4922 0xc421f74a50 0xc421f74a51}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-vrzvs {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-vrzvs,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-vrzvs true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.10.102.67-slave,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc421f74b60} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421f74b80}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-28 05:58:36 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-28 05:58:36 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-28 05:58:36 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-28 05:45:21 +0000 UTC  }],Message:,Reason:,HostIP:10.10.102.67,PodIP:,StartTime:2018-12-28 05:58:36 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec 28 05:45:24.396: INFO: Pod "nginx-deployment-7dc8f79789-kfx8r" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-kfx8r,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-fnnm9,SelfLink:/api/v1/namespaces/e2e-tests-deployment-fnnm9/pods/nginx-deployment-7dc8f79789-kfx8r,UID:c543e0c1-0a63-11e9-a0ee-005056bc4922,ResourceVersion:534745,Generation:0,CreationTimestamp:2018-12-28 05:45:23 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 c3cfc7dd-0a63-11e9-a0ee-005056bc4922 0xc421f753b0 0xc421f753b1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-vrzvs {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-vrzvs,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-vrzvs true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.10.102.66-slave,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc421f75500} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421f75550}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-28 05:45:24 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec 28 05:45:24.396: INFO: Pod "nginx-deployment-7dc8f79789-kj976" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-kj976,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-fnnm9,SelfLink:/api/v1/namespaces/e2e-tests-deployment-fnnm9/pods/nginx-deployment-7dc8f79789-kj976,UID:c5441a44-0a63-11e9-a0ee-005056bc4922,ResourceVersion:534746,Generation:0,CreationTimestamp:2018-12-28 05:45:23 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 c3cfc7dd-0a63-11e9-a0ee-005056bc4922 0xc421f75660 0xc421f75661}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-vrzvs {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-vrzvs,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-vrzvs true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.10.102.69-build,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc421f758d0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421f758f0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-28 05:45:24 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec 28 05:45:24.397: INFO: Pod "nginx-deployment-7dc8f79789-km5q8" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-km5q8,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-fnnm9,SelfLink:/api/v1/namespaces/e2e-tests-deployment-fnnm9/pods/nginx-deployment-7dc8f79789-km5q8,UID:c544167b-0a63-11e9-a0ee-005056bc4922,ResourceVersion:534749,Generation:0,CreationTimestamp:2018-12-28 05:45:23 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 c3cfc7dd-0a63-11e9-a0ee-005056bc4922 0xc421f75970 0xc421f75971}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-vrzvs {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-vrzvs,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-vrzvs true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.10.102.68-share,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc421f759e0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421f75b60}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-28 05:45:24 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec 28 05:45:24.397: INFO: Pod "nginx-deployment-7dc8f79789-pbzrx" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-pbzrx,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-fnnm9,SelfLink:/api/v1/namespaces/e2e-tests-deployment-fnnm9/pods/nginx-deployment-7dc8f79789-pbzrx,UID:c3d3c177-0a63-11e9-a0ee-005056bc4922,ResourceVersion:534663,Generation:0,CreationTimestamp:2018-12-28 05:45:21 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 c3cfc7dd-0a63-11e9-a0ee-005056bc4922 0xc421f75c50 0xc421f75c51}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-vrzvs {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-vrzvs,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-vrzvs true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.10.102.69-build,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc421f75d70} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421f75d90}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-28 05:45:22 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-28 05:45:22 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-28 05:45:22 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-28 05:45:21 +0000 UTC  }],Message:,Reason:,HostIP:10.10.102.69,PodIP:,StartTime:2018-12-28 05:45:22 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec 28 05:45:24.397: INFO: Pod "nginx-deployment-7dc8f79789-rgrgr" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-rgrgr,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-fnnm9,SelfLink:/api/v1/namespaces/e2e-tests-deployment-fnnm9/pods/nginx-deployment-7dc8f79789-rgrgr,UID:c3d6c0e4-0a63-11e9-a0ee-005056bc4922,ResourceVersion:534673,Generation:0,CreationTimestamp:2018-12-28 05:45:21 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 c3cfc7dd-0a63-11e9-a0ee-005056bc4922 0xc421f75f30 0xc421f75f31}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-vrzvs {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-vrzvs,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-vrzvs true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.10.102.68-share,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc420e5e170} {node.kubernetes.io/unreachable Exists  NoExecute 0xc420e5e1a0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-28 05:45:21 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-28 05:45:21 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-28 05:45:21 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-28 05:45:21 +0000 UTC  }],Message:,Reason:,HostIP:10.10.102.68,PodIP:,StartTime:2018-12-28 05:45:21 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec 28 05:45:24.398: INFO: Pod "nginx-deployment-7dc8f79789-vkjc6" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-vkjc6,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-fnnm9,SelfLink:/api/v1/namespaces/e2e-tests-deployment-fnnm9/pods/nginx-deployment-7dc8f79789-vkjc6,UID:c5430ccf-0a63-11e9-a0ee-005056bc4922,ResourceVersion:534739,Generation:0,CreationTimestamp:2018-12-28 05:45:23 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 c3cfc7dd-0a63-11e9-a0ee-005056bc4922 0xc420e5ecb0 0xc420e5ecb1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-vrzvs {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-vrzvs,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-vrzvs true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.10.102.66-slave,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc420e5ed20} {node.kubernetes.io/unreachable Exists  NoExecute 0xc420e5edf0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-28 05:45:24 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec 28 05:45:24.398: INFO: Pod "nginx-deployment-7dc8f79789-wpsr6" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-wpsr6,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-fnnm9,SelfLink:/api/v1/namespaces/e2e-tests-deployment-fnnm9/pods/nginx-deployment-7dc8f79789-wpsr6,UID:c51adb07-0a63-11e9-a0ee-005056bc4922,ResourceVersion:534748,Generation:0,CreationTimestamp:2018-12-28 05:45:23 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 c3cfc7dd-0a63-11e9-a0ee-005056bc4922 0xc420e5f1c0 0xc420e5f1c1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-vrzvs {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-vrzvs,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-vrzvs true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.10.102.69-build,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc420e5f230} {node.kubernetes.io/unreachable Exists  NoExecute 0xc420e5f4e0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-28 05:45:24 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-28 05:45:24 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-28 05:45:24 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-28 05:45:23 +0000 UTC  }],Message:,Reason:,HostIP:10.10.102.69,PodIP:,StartTime:2018-12-28 05:45:24 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec 28 05:45:24.398: INFO: Pod "nginx-deployment-7dc8f79789-xwvfn" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-xwvfn,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-fnnm9,SelfLink:/api/v1/namespaces/e2e-tests-deployment-fnnm9/pods/nginx-deployment-7dc8f79789-xwvfn,UID:c57c5a36-0a63-11e9-a0ee-005056bc4922,ResourceVersion:534754,Generation:0,CreationTimestamp:2018-12-28 05:45:24 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 c3cfc7dd-0a63-11e9-a0ee-005056bc4922 0xc420e5fc50 0xc420e5fc51}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-vrzvs {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-vrzvs,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-vrzvs true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.10.102.67-slave,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc420e5fd30} {node.kubernetes.io/unreachable Exists  NoExecute 0xc420e5fd50}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-28 05:45:24 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec 28 05:45:24.399: INFO: Pod "nginx-deployment-7f9675fb8b-55b9w" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-55b9w,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-fnnm9,SelfLink:/api/v1/namespaces/e2e-tests-deployment-fnnm9/pods/nginx-deployment-7f9675fb8b-55b9w,UID:af95453e-0a63-11e9-a0ee-005056bc4922,ResourceVersion:534633,Generation:0,CreationTimestamp:2018-12-28 05:44:47 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b af7e61b6-0a63-11e9-a0ee-005056bc4922 0xc420e5fdc0 0xc420e5fdc1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-vrzvs {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-vrzvs,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-vrzvs true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.10.102.69-build,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc420e5ff80} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421d86400}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-28 05:44:48 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-12-28 05:45:20 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2018-12-28 05:45:20 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-28 05:44:47 +0000 UTC  }],Message:,Reason:,HostIP:10.10.102.69,PodIP:10.168.192.52,StartTime:2018-12-28 05:44:48 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2018-12-28 05:45:17 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:e3f77f7f4a6bb5e7820e013fa60b96602b34f5704e796cfd94b561ae73adcf96 docker://cece74716540844f26e508df47c6b971f078360398b1af31ea3fa15d7d7db459}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec 28 05:45:24.399: INFO: Pod "nginx-deployment-7f9675fb8b-645q2" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-645q2,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-fnnm9,SelfLink:/api/v1/namespaces/e2e-tests-deployment-fnnm9/pods/nginx-deployment-7f9675fb8b-645q2,UID:c543fb2b-0a63-11e9-a0ee-005056bc4922,ResourceVersion:534744,Generation:0,CreationTimestamp:2018-12-28 05:45:23 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b af7e61b6-0a63-11e9-a0ee-005056bc4922 0xc421d864f7 0xc421d864f8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-vrzvs {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-vrzvs,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-vrzvs true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.10.102.66-slave,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc421d865d0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421d865f0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-28 05:45:24 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec 28 05:45:24.399: INFO: Pod "nginx-deployment-7f9675fb8b-6fls2" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-6fls2,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-fnnm9,SelfLink:/api/v1/namespaces/e2e-tests-deployment-fnnm9/pods/nginx-deployment-7f9675fb8b-6fls2,UID:c543d120-0a63-11e9-a0ee-005056bc4922,ResourceVersion:534740,Generation:0,CreationTimestamp:2018-12-28 05:45:23 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b af7e61b6-0a63-11e9-a0ee-005056bc4922 0xc421d86770 0xc421d86771}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-vrzvs {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-vrzvs,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-vrzvs true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.10.102.66-slave,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc421d867e0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421d86800}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-28 05:45:24 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec 28 05:45:24.400: INFO: Pod "nginx-deployment-7f9675fb8b-7wm26" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-7wm26,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-fnnm9,SelfLink:/api/v1/namespaces/e2e-tests-deployment-fnnm9/pods/nginx-deployment-7f9675fb8b-7wm26,UID:c51e6841-0a63-11e9-a0ee-005056bc4922,ResourceVersion:534721,Generation:0,CreationTimestamp:2018-12-28 05:45:23 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b af7e61b6-0a63-11e9-a0ee-005056bc4922 0xc421d86970 0xc421d86971}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-vrzvs {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-vrzvs,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-vrzvs true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.10.102.67-slave,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc421d86b80} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421d86bb0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-28 05:45:23 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec 28 05:45:24.400: INFO: Pod "nginx-deployment-7f9675fb8b-88plf" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-88plf,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-fnnm9,SelfLink:/api/v1/namespaces/e2e-tests-deployment-fnnm9/pods/nginx-deployment-7f9675fb8b-88plf,UID:af9992c5-0a63-11e9-a0ee-005056bc4922,ResourceVersion:534638,Generation:0,CreationTimestamp:2018-12-28 05:44:47 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b af7e61b6-0a63-11e9-a0ee-005056bc4922 0xc421d86c90 0xc421d86c91}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-vrzvs {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-vrzvs,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-vrzvs true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.10.102.69-build,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc421d86cf0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421d86d20}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-28 05:44:48 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-12-28 05:45:21 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2018-12-28 05:45:21 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-28 05:44:47 +0000 UTC  }],Message:,Reason:,HostIP:10.10.102.69,PodIP:10.168.192.53,StartTime:2018-12-28 05:44:48 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2018-12-28 05:45:20 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:e3f77f7f4a6bb5e7820e013fa60b96602b34f5704e796cfd94b561ae73adcf96 docker://f9def6536210bc038d4168dbeba8020ac524675229a7e954316c1d6190406e69}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec 28 05:45:24.400: INFO: Pod "nginx-deployment-7f9675fb8b-92zlk" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-92zlk,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-fnnm9,SelfLink:/api/v1/namespaces/e2e-tests-deployment-fnnm9/pods/nginx-deployment-7f9675fb8b-92zlk,UID:af836584-0a63-11e9-a0ee-005056bc4922,ResourceVersion:534607,Generation:0,CreationTimestamp:2018-12-28 05:44:47 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b af7e61b6-0a63-11e9-a0ee-005056bc4922 0xc421d86f57 0xc421d86f58}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-vrzvs {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-vrzvs,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-vrzvs true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.10.102.69-build,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc421d86fc0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421d86fe0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-28 05:44:48 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-12-28 05:45:14 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2018-12-28 05:45:14 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-28 05:44:47 +0000 UTC  }],Message:,Reason:,HostIP:10.10.102.69,PodIP:10.168.192.50,StartTime:2018-12-28 05:44:48 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2018-12-28 05:45:10 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:e3f77f7f4a6bb5e7820e013fa60b96602b34f5704e796cfd94b561ae73adcf96 docker://2ef0ba25a0b3417ca0b52ee04e838c4ef589d32566e9f10674f6e5d65721c55f}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec 28 05:45:24.401: INFO: Pod "nginx-deployment-7f9675fb8b-cggh2" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-cggh2,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-fnnm9,SelfLink:/api/v1/namespaces/e2e-tests-deployment-fnnm9/pods/nginx-deployment-7f9675fb8b-cggh2,UID:c544519c-0a63-11e9-a0ee-005056bc4922,ResourceVersion:534747,Generation:0,CreationTimestamp:2018-12-28 05:45:23 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b af7e61b6-0a63-11e9-a0ee-005056bc4922 0xc421d871b7 0xc421d871b8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-vrzvs {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-vrzvs,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-vrzvs true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.10.102.67-slave,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc421d87220} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421d87240}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-28 05:45:24 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec 28 05:45:24.401: INFO: Pod "nginx-deployment-7f9675fb8b-dlprj" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-dlprj,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-fnnm9,SelfLink:/api/v1/namespaces/e2e-tests-deployment-fnnm9/pods/nginx-deployment-7f9675fb8b-dlprj,UID:af951d4a-0a63-11e9-a0ee-005056bc4922,ResourceVersion:534629,Generation:0,CreationTimestamp:2018-12-28 05:44:47 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b af7e61b6-0a63-11e9-a0ee-005056bc4922 0xc421d87330 0xc421d87331}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-vrzvs {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-vrzvs,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-vrzvs true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.10.102.69-build,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc421d87410} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421d87430}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-28 05:44:48 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-12-28 05:45:20 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2018-12-28 05:45:20 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-28 05:44:47 +0000 UTC  }],Message:,Reason:,HostIP:10.10.102.69,PodIP:10.168.192.51,StartTime:2018-12-28 05:44:48 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2018-12-28 05:45:14 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:e3f77f7f4a6bb5e7820e013fa60b96602b34f5704e796cfd94b561ae73adcf96 docker://ff2e9ebd06c9a86a3253f4cd816f21077a85eb08f04eac37a9bdd5e0c783196f}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec 28 05:45:24.401: INFO: Pod "nginx-deployment-7f9675fb8b-flvvj" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-flvvj,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-fnnm9,SelfLink:/api/v1/namespaces/e2e-tests-deployment-fnnm9/pods/nginx-deployment-7f9675fb8b-flvvj,UID:c51b0f85-0a63-11e9-a0ee-005056bc4922,ResourceVersion:534743,Generation:0,CreationTimestamp:2018-12-28 05:45:23 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b af7e61b6-0a63-11e9-a0ee-005056bc4922 0xc421d874f7 0xc421d874f8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-vrzvs {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-vrzvs,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-vrzvs true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.10.102.68-share,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc421d875e0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421d87600}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-28 05:45:24 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-28 05:45:24 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-28 05:45:24 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-28 05:45:23 +0000 UTC  }],Message:,Reason:,HostIP:10.10.102.68,PodIP:,StartTime:2018-12-28 05:45:24 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec 28 05:45:24.402: INFO: Pod "nginx-deployment-7f9675fb8b-gfqw7" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-gfqw7,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-fnnm9,SelfLink:/api/v1/namespaces/e2e-tests-deployment-fnnm9/pods/nginx-deployment-7f9675fb8b-gfqw7,UID:af8710e7-0a63-11e9-a0ee-005056bc4922,ResourceVersion:534604,Generation:0,CreationTimestamp:2018-12-28 05:44:47 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b af7e61b6-0a63-11e9-a0ee-005056bc4922 0xc421d87937 0xc421d87938}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-vrzvs {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-vrzvs,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-vrzvs true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.10.102.68-share,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc421d879b0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421d879e0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-28 05:44:47 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-12-28 05:45:13 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2018-12-28 05:45:13 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-28 05:44:47 +0000 UTC  }],Message:,Reason:,HostIP:10.10.102.68,PodIP:10.168.194.179,StartTime:2018-12-28 05:44:47 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2018-12-28 05:45:11 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:e3f77f7f4a6bb5e7820e013fa60b96602b34f5704e796cfd94b561ae73adcf96 docker://d8042a107826d51d5fa9cb363c06964676f2a1788e06ce0325d182dd9077fc35}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec 28 05:45:24.402: INFO: Pod "nginx-deployment-7f9675fb8b-gmt8v" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-gmt8v,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-fnnm9,SelfLink:/api/v1/namespaces/e2e-tests-deployment-fnnm9/pods/nginx-deployment-7f9675fb8b-gmt8v,UID:af994172-0a63-11e9-a0ee-005056bc4922,ResourceVersion:534613,Generation:0,CreationTimestamp:2018-12-28 05:44:47 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b af7e61b6-0a63-11e9-a0ee-005056bc4922 0xc421d87aa7 0xc421d87aa8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-vrzvs {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-vrzvs,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-vrzvs true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.10.102.68-share,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc421d87b10} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421d87b30}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-28 05:44:47 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-12-28 05:45:14 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2018-12-28 05:45:14 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-28 05:44:47 +0000 UTC  }],Message:,Reason:,HostIP:10.10.102.68,PodIP:10.168.194.167,StartTime:2018-12-28 05:44:47 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2018-12-28 05:45:14 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:e3f77f7f4a6bb5e7820e013fa60b96602b34f5704e796cfd94b561ae73adcf96 docker://dac47e9bf739aa29ce531eb4a40d0b4dea63b6d9ace6be45af1f2f15a1b9d912}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec 28 05:45:24.402: INFO: Pod "nginx-deployment-7f9675fb8b-jd6jk" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-jd6jk,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-fnnm9,SelfLink:/api/v1/namespaces/e2e-tests-deployment-fnnm9/pods/nginx-deployment-7f9675fb8b-jd6jk,UID:c5427a16-0a63-11e9-a0ee-005056bc4922,ResourceVersion:534741,Generation:0,CreationTimestamp:2018-12-28 05:45:23 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b af7e61b6-0a63-11e9-a0ee-005056bc4922 0xc421d87bf7 0xc421d87bf8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-vrzvs {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-vrzvs,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-vrzvs true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.10.102.66-slave,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc421d87c60} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421d87c80}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-28 05:45:24 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec 28 05:45:24.403: INFO: Pod "nginx-deployment-7f9675fb8b-mvrk8" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-mvrk8,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-fnnm9,SelfLink:/api/v1/namespaces/e2e-tests-deployment-fnnm9/pods/nginx-deployment-7f9675fb8b-mvrk8,UID:af87159d-0a63-11e9-a0ee-005056bc4922,ResourceVersion:534554,Generation:0,CreationTimestamp:2018-12-28 05:44:47 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b af7e61b6-0a63-11e9-a0ee-005056bc4922 0xc421d87cf0 0xc421d87cf1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-vrzvs {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-vrzvs,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-vrzvs true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.10.102.67-slave,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc421d87d50} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421d87d70}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-28 05:58:01 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-12-28 05:58:18 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2018-12-28 05:58:18 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-28 05:44:47 +0000 UTC  }],Message:,Reason:,HostIP:10.10.102.67,PodIP:10.168.66.218,StartTime:2018-12-28 05:58:01 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2018-12-28 05:58:18 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:e3f77f7f4a6bb5e7820e013fa60b96602b34f5704e796cfd94b561ae73adcf96 docker://9787584be7e3b20efa4ceb0de67b147527ade95a58f29466bb51ed69c1f54130}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec 28 05:45:24.403: INFO: Pod "nginx-deployment-7f9675fb8b-pd24w" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-pd24w,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-fnnm9,SelfLink:/api/v1/namespaces/e2e-tests-deployment-fnnm9/pods/nginx-deployment-7f9675fb8b-pd24w,UID:c51afb65-0a63-11e9-a0ee-005056bc4922,ResourceVersion:534711,Generation:0,CreationTimestamp:2018-12-28 05:45:23 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b af7e61b6-0a63-11e9-a0ee-005056bc4922 0xc421d87e37 0xc421d87e38}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-vrzvs {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-vrzvs,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-vrzvs true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.10.102.67-slave,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc421d87ea0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421d87ec0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-28 05:45:23 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec 28 05:45:24.404: INFO: Pod "nginx-deployment-7f9675fb8b-q76s2" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-q76s2,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-fnnm9,SelfLink:/api/v1/namespaces/e2e-tests-deployment-fnnm9/pods/nginx-deployment-7f9675fb8b-q76s2,UID:af9504e8-0a63-11e9-a0ee-005056bc4922,ResourceVersion:534592,Generation:0,CreationTimestamp:2018-12-28 05:44:47 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b af7e61b6-0a63-11e9-a0ee-005056bc4922 0xc421d87f30 0xc421d87f31}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-vrzvs {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-vrzvs,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-vrzvs true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.10.102.68-share,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc421d87f90} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421d87fb0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-28 05:44:47 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-12-28 05:45:11 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2018-12-28 05:45:11 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-28 05:44:47 +0000 UTC  }],Message:,Reason:,HostIP:10.10.102.68,PodIP:10.168.194.176,StartTime:2018-12-28 05:44:47 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2018-12-28 05:45:06 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:e3f77f7f4a6bb5e7820e013fa60b96602b34f5704e796cfd94b561ae73adcf96 docker://255ebf6cdda2367711b196beb003704231f2f0a915b69310d4ac8546c4f99971}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec 28 05:45:24.404: INFO: Pod "nginx-deployment-7f9675fb8b-tf2vw" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-tf2vw,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-fnnm9,SelfLink:/api/v1/namespaces/e2e-tests-deployment-fnnm9/pods/nginx-deployment-7f9675fb8b-tf2vw,UID:c51eb972-0a63-11e9-a0ee-005056bc4922,ResourceVersion:534720,Generation:0,CreationTimestamp:2018-12-28 05:45:23 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b af7e61b6-0a63-11e9-a0ee-005056bc4922 0xc422056167 0xc422056168}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-vrzvs {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-vrzvs,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-vrzvs true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.10.102.66-slave,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc4220561d0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc4220561f0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-28 05:45:23 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec 28 05:45:24.404: INFO: Pod "nginx-deployment-7f9675fb8b-wdbr7" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-wdbr7,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-fnnm9,SelfLink:/api/v1/namespaces/e2e-tests-deployment-fnnm9/pods/nginx-deployment-7f9675fb8b-wdbr7,UID:c51ed195-0a63-11e9-a0ee-005056bc4922,ResourceVersion:534729,Generation:0,CreationTimestamp:2018-12-28 05:45:23 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b af7e61b6-0a63-11e9-a0ee-005056bc4922 0xc422056260 0xc422056261}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-vrzvs {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-vrzvs,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-vrzvs true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.10.102.68-share,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc422056340} {node.kubernetes.io/unreachable Exists  NoExecute 0xc422056360}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-28 05:45:23 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec 28 05:45:24.404: INFO: Pod "nginx-deployment-7f9675fb8b-xdznl" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-xdznl,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-fnnm9,SelfLink:/api/v1/namespaces/e2e-tests-deployment-fnnm9/pods/nginx-deployment-7f9675fb8b-xdznl,UID:c515fbfd-0a63-11e9-a0ee-005056bc4922,ResourceVersion:534756,Generation:0,CreationTimestamp:2018-12-28 05:45:23 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b af7e61b6-0a63-11e9-a0ee-005056bc4922 0xc422056410 0xc422056411}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-vrzvs {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-vrzvs,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-vrzvs true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.10.102.67-slave,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc422056470} {node.kubernetes.io/unreachable Exists  NoExecute 0xc422056490}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-28 05:58:38 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-28 05:58:38 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-28 05:58:38 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-28 05:45:23 +0000 UTC  }],Message:,Reason:,HostIP:10.10.102.67,PodIP:,StartTime:2018-12-28 05:58:38 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec 28 05:45:24.405: INFO: Pod "nginx-deployment-7f9675fb8b-z8rcn" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-z8rcn,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-fnnm9,SelfLink:/api/v1/namespaces/e2e-tests-deployment-fnnm9/pods/nginx-deployment-7f9675fb8b-z8rcn,UID:c54416fa-0a63-11e9-a0ee-005056bc4922,ResourceVersion:534751,Generation:0,CreationTimestamp:2018-12-28 05:45:23 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b af7e61b6-0a63-11e9-a0ee-005056bc4922 0xc4220566f7 0xc4220566f8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-vrzvs {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-vrzvs,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-vrzvs true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.10.102.66-slave,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc422056760} {node.kubernetes.io/unreachable Exists  NoExecute 0xc422056780}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-28 05:45:24 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec 28 05:45:24.406: INFO: Pod "nginx-deployment-7f9675fb8b-zv7m2" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-zv7m2,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-fnnm9,SelfLink:/api/v1/namespaces/e2e-tests-deployment-fnnm9/pods/nginx-deployment-7f9675fb8b-zv7m2,UID:c51f013f-0a63-11e9-a0ee-005056bc4922,ResourceVersion:534727,Generation:0,CreationTimestamp:2018-12-28 05:45:23 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b af7e61b6-0a63-11e9-a0ee-005056bc4922 0xc422056810 0xc422056811}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-vrzvs {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-vrzvs,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-vrzvs true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.10.102.69-build,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc422056910} {node.kubernetes.io/unreachable Exists  NoExecute 0xc422056930}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-28 05:45:23 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 28 05:45:24.406: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-fnnm9" for this suite.
Dec 28 05:45:42.808: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 05:45:42.996: INFO: namespace: e2e-tests-deployment-fnnm9, resource: bindings, ignored listing per whitelist
Dec 28 05:45:43.249: INFO: namespace e2e-tests-deployment-fnnm9 deletion completed in 18.660616373s

• [SLOW TEST:56.247 seconds]
[sig-apps] Deployment
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-api-machinery] Downward API 
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 28 05:45:43.250: INFO: >>> kubeConfig: /tmp/kubeconfig-994138694
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Dec 28 05:45:43.980: INFO: Waiting up to 5m0s for pod "downward-api-d13870bf-0a63-11e9-8a07-628dff7095f4" in namespace "e2e-tests-downward-api-s96fl" to be "success or failure"
Dec 28 05:45:44.015: INFO: Pod "downward-api-d13870bf-0a63-11e9-8a07-628dff7095f4": Phase="Pending", Reason="", readiness=false. Elapsed: 34.379413ms
Dec 28 05:45:46.023: INFO: Pod "downward-api-d13870bf-0a63-11e9-8a07-628dff7095f4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.042310123s
Dec 28 05:45:48.030: INFO: Pod "downward-api-d13870bf-0a63-11e9-8a07-628dff7095f4": Phase="Pending", Reason="", readiness=false. Elapsed: 4.049555257s
Dec 28 05:45:50.037: INFO: Pod "downward-api-d13870bf-0a63-11e9-8a07-628dff7095f4": Phase="Pending", Reason="", readiness=false. Elapsed: 6.056329223s
Dec 28 05:45:52.063: INFO: Pod "downward-api-d13870bf-0a63-11e9-8a07-628dff7095f4": Phase="Pending", Reason="", readiness=false. Elapsed: 8.082587593s
Dec 28 05:45:54.852: INFO: Pod "downward-api-d13870bf-0a63-11e9-8a07-628dff7095f4": Phase="Pending", Reason="", readiness=false. Elapsed: 10.871465733s
Dec 28 05:45:56.961: INFO: Pod "downward-api-d13870bf-0a63-11e9-8a07-628dff7095f4": Phase="Pending", Reason="", readiness=false. Elapsed: 12.98040304s
Dec 28 05:45:58.969: INFO: Pod "downward-api-d13870bf-0a63-11e9-8a07-628dff7095f4": Phase="Pending", Reason="", readiness=false. Elapsed: 14.98886122s
Dec 28 05:46:00.977: INFO: Pod "downward-api-d13870bf-0a63-11e9-8a07-628dff7095f4": Phase="Pending", Reason="", readiness=false. Elapsed: 16.996546297s
Dec 28 05:46:02.983: INFO: Pod "downward-api-d13870bf-0a63-11e9-8a07-628dff7095f4": Phase="Pending", Reason="", readiness=false. Elapsed: 19.00257016s
Dec 28 05:46:04.990: INFO: Pod "downward-api-d13870bf-0a63-11e9-8a07-628dff7095f4": Phase="Pending", Reason="", readiness=false. Elapsed: 21.009812953s
Dec 28 05:46:06.997: INFO: Pod "downward-api-d13870bf-0a63-11e9-8a07-628dff7095f4": Phase="Pending", Reason="", readiness=false. Elapsed: 23.01717717s
Dec 28 05:46:09.289: INFO: Pod "downward-api-d13870bf-0a63-11e9-8a07-628dff7095f4": Phase="Pending", Reason="", readiness=false. Elapsed: 25.308215013s
Dec 28 05:46:11.297: INFO: Pod "downward-api-d13870bf-0a63-11e9-8a07-628dff7095f4": Phase="Pending", Reason="", readiness=false. Elapsed: 27.316260373s
Dec 28 05:46:13.420: INFO: Pod "downward-api-d13870bf-0a63-11e9-8a07-628dff7095f4": Phase="Pending", Reason="", readiness=false. Elapsed: 29.43949099s
Dec 28 05:46:15.427: INFO: Pod "downward-api-d13870bf-0a63-11e9-8a07-628dff7095f4": Phase="Pending", Reason="", readiness=false. Elapsed: 31.446769517s
Dec 28 05:46:17.434: INFO: Pod "downward-api-d13870bf-0a63-11e9-8a07-628dff7095f4": Phase="Pending", Reason="", readiness=false. Elapsed: 33.45340848s
Dec 28 05:46:19.447: INFO: Pod "downward-api-d13870bf-0a63-11e9-8a07-628dff7095f4": Phase="Pending", Reason="", readiness=false. Elapsed: 35.466813883s
Dec 28 05:46:21.461: INFO: Pod "downward-api-d13870bf-0a63-11e9-8a07-628dff7095f4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 37.48031723s
STEP: Saw pod success
Dec 28 05:46:21.461: INFO: Pod "downward-api-d13870bf-0a63-11e9-8a07-628dff7095f4" satisfied condition "success or failure"
Dec 28 05:46:21.468: INFO: Trying to get logs from node 10.10.102.67-slave pod downward-api-d13870bf-0a63-11e9-8a07-628dff7095f4 container dapi-container: <nil>
STEP: delete the pod
Dec 28 05:46:21.571: INFO: Waiting for pod downward-api-d13870bf-0a63-11e9-8a07-628dff7095f4 to disappear
Dec 28 05:46:21.586: INFO: Pod downward-api-d13870bf-0a63-11e9-8a07-628dff7095f4 no longer exists
[AfterEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 28 05:46:21.586: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-s96fl" for this suite.
Dec 28 05:46:29.627: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 05:46:29.780: INFO: namespace: e2e-tests-downward-api-s96fl, resource: bindings, ignored listing per whitelist
Dec 28 05:46:29.845: INFO: namespace e2e-tests-downward-api-s96fl deletion completed in 8.245869733s

• [SLOW TEST:46.596 seconds]
[sig-api-machinery] Downward API
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-network] Services 
  should provide secure master service  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 28 05:46:29.845: INFO: >>> kubeConfig: /tmp/kubeconfig-994138694
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:83
[It] should provide secure master service  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 28 05:46:30.392: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-services-67pq4" for this suite.
Dec 28 05:46:36.461: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 05:46:36.603: INFO: namespace: e2e-tests-services-67pq4, resource: bindings, ignored listing per whitelist
Dec 28 05:46:36.681: INFO: namespace e2e-tests-services-67pq4 deletion completed in 6.270296847s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:88

• [SLOW TEST:6.835 seconds]
[sig-network] Services
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide secure master service  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 28 05:46:36.681: INFO: >>> kubeConfig: /tmp/kubeconfig-994138694
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0644 on node default medium
Dec 28 05:46:36.936: INFO: Waiting up to 5m0s for pod "pod-f0c5040c-0a63-11e9-8a07-628dff7095f4" in namespace "e2e-tests-emptydir-djjn6" to be "success or failure"
Dec 28 05:46:37.008: INFO: Pod "pod-f0c5040c-0a63-11e9-8a07-628dff7095f4": Phase="Pending", Reason="", readiness=false. Elapsed: 72.29431ms
Dec 28 05:46:39.017: INFO: Pod "pod-f0c5040c-0a63-11e9-8a07-628dff7095f4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.081256944s
Dec 28 05:46:41.028: INFO: Pod "pod-f0c5040c-0a63-11e9-8a07-628dff7095f4": Phase="Pending", Reason="", readiness=false. Elapsed: 4.09169233s
Dec 28 05:46:43.038: INFO: Pod "pod-f0c5040c-0a63-11e9-8a07-628dff7095f4": Phase="Pending", Reason="", readiness=false. Elapsed: 6.101482327s
Dec 28 05:46:45.392: INFO: Pod "pod-f0c5040c-0a63-11e9-8a07-628dff7095f4": Phase="Pending", Reason="", readiness=false. Elapsed: 8.45629104s
Dec 28 05:46:47.446: INFO: Pod "pod-f0c5040c-0a63-11e9-8a07-628dff7095f4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 10.509523134s
STEP: Saw pod success
Dec 28 05:46:47.446: INFO: Pod "pod-f0c5040c-0a63-11e9-8a07-628dff7095f4" satisfied condition "success or failure"
Dec 28 05:46:47.452: INFO: Trying to get logs from node 10.10.102.69-build pod pod-f0c5040c-0a63-11e9-8a07-628dff7095f4 container test-container: <nil>
STEP: delete the pod
Dec 28 05:46:47.817: INFO: Waiting for pod pod-f0c5040c-0a63-11e9-8a07-628dff7095f4 to disappear
Dec 28 05:46:47.837: INFO: Pod pod-f0c5040c-0a63-11e9-8a07-628dff7095f4 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 28 05:46:47.837: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-djjn6" for this suite.
Dec 28 05:46:53.977: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 05:46:54.091: INFO: namespace: e2e-tests-emptydir-djjn6, resource: bindings, ignored listing per whitelist
Dec 28 05:46:54.200: INFO: namespace e2e-tests-emptydir-djjn6 deletion completed in 6.349373383s

• [SLOW TEST:17.519 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl describe 
  should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 28 05:46:54.200: INFO: >>> kubeConfig: /tmp/kubeconfig-994138694
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Dec 28 05:46:54.417: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994138694 version --client'
Dec 28 05:46:54.668: INFO: stderr: ""
Dec 28 05:46:54.668: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"12\", GitVersion:\"v1.12.1\", GitCommit:\"4ed3216f3ec431b140b1d899130a69fc671678f4\", GitTreeState:\"clean\", BuildDate:\"2018-10-05T16:46:06Z\", GoVersion:\"go1.10.4\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
Dec 28 05:46:54.671: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994138694 create -f - --namespace=e2e-tests-kubectl-vzzrv'
Dec 28 05:46:55.439: INFO: stderr: ""
Dec 28 05:46:55.439: INFO: stdout: "replicationcontroller/redis-master created\n"
Dec 28 05:46:55.440: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994138694 create -f - --namespace=e2e-tests-kubectl-vzzrv'
Dec 28 05:46:56.382: INFO: stderr: ""
Dec 28 05:46:56.383: INFO: stdout: "service/redis-master created\n"
STEP: Waiting for Redis master to start.
Dec 28 05:46:57.391: INFO: Selector matched 1 pods for map[app:redis]
Dec 28 05:46:57.391: INFO: Found 0 / 1
Dec 28 05:46:58.392: INFO: Selector matched 1 pods for map[app:redis]
Dec 28 05:46:58.392: INFO: Found 0 / 1
Dec 28 05:46:59.391: INFO: Selector matched 1 pods for map[app:redis]
Dec 28 05:46:59.391: INFO: Found 0 / 1
Dec 28 05:47:00.390: INFO: Selector matched 1 pods for map[app:redis]
Dec 28 05:47:00.390: INFO: Found 0 / 1
Dec 28 05:47:01.390: INFO: Selector matched 1 pods for map[app:redis]
Dec 28 05:47:01.390: INFO: Found 0 / 1
Dec 28 05:47:02.390: INFO: Selector matched 1 pods for map[app:redis]
Dec 28 05:47:02.390: INFO: Found 0 / 1
Dec 28 05:47:03.391: INFO: Selector matched 1 pods for map[app:redis]
Dec 28 05:47:03.391: INFO: Found 0 / 1
Dec 28 05:47:04.399: INFO: Selector matched 1 pods for map[app:redis]
Dec 28 05:47:04.399: INFO: Found 0 / 1
Dec 28 05:47:05.412: INFO: Selector matched 1 pods for map[app:redis]
Dec 28 05:47:05.412: INFO: Found 1 / 1
Dec 28 05:47:05.412: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Dec 28 05:47:05.427: INFO: Selector matched 1 pods for map[app:redis]
Dec 28 05:47:05.427: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Dec 28 05:47:05.427: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994138694 describe pod redis-master-8jk4v --namespace=e2e-tests-kubectl-vzzrv'
Dec 28 05:47:05.864: INFO: stderr: ""
Dec 28 05:47:05.864: INFO: stdout: "Name:               redis-master-8jk4v\nNamespace:          e2e-tests-kubectl-vzzrv\nPriority:           0\nPriorityClassName:  <none>\nNode:               10.10.102.68-share/10.10.102.68\nStart Time:         Fri, 28 Dec 2018 05:46:55 +0000\nLabels:             app=redis\n                    role=master\nAnnotations:        <none>\nStatus:             Running\nIP:                 10.168.194.178\nControlled By:      ReplicationController/redis-master\nContainers:\n  redis-master:\n    Container ID:   docker://6b15f14c5998c614cbbfc40a54e6f27fcad8ff2c2f36cd1e68ec2ec1ca8e155c\n    Image:          gcr.io/kubernetes-e2e-test-images/redis:1.0\n    Image ID:       docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830\n    Port:           6379/TCP\n    Host Port:      0/TCP\n    State:          Running\n      Started:      Fri, 28 Dec 2018 05:47:05 +0000\n    Ready:          True\n    Restart Count:  0\n    Environment:    <none>\n    Mounts:\n      /var/run/secrets/kubernetes.io/serviceaccount from default-token-7jqfd (ro)\nConditions:\n  Type              Status\n  Initialized       True \n  Ready             True \n  ContainersReady   True \n  PodScheduled      True \nVolumes:\n  default-token-7jqfd:\n    Type:        Secret (a volume populated by a Secret)\n    SecretName:  default-token-7jqfd\n    Optional:    false\nQoS Class:       BestEffort\nNode-Selectors:  <none>\nTolerations:     node.kubernetes.io/not-ready:NoExecute for 300s\n                 node.kubernetes.io/unreachable:NoExecute for 300s\nEvents:\n  Type    Reason     Age   From                         Message\n  ----    ------     ----  ----                         -------\n  Normal  Scheduled  10s   default-scheduler            Successfully assigned e2e-tests-kubectl-vzzrv/redis-master-8jk4v to 10.10.102.68-share\n  Normal  Pulled     4s    kubelet, 10.10.102.68-share  Container image \"gcr.io/kubernetes-e2e-test-images/redis:1.0\" already present on machine\n  Normal  Created    1s    kubelet, 10.10.102.68-share  Created container\n  Normal  Started    0s    kubelet, 10.10.102.68-share  Started container\n"
Dec 28 05:47:05.864: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994138694 describe rc redis-master --namespace=e2e-tests-kubectl-vzzrv'
Dec 28 05:47:06.228: INFO: stderr: ""
Dec 28 05:47:06.228: INFO: stdout: "Name:         redis-master\nNamespace:    e2e-tests-kubectl-vzzrv\nSelector:     app=redis,role=master\nLabels:       app=redis\n              role=master\nAnnotations:  <none>\nReplicas:     1 current / 1 desired\nPods Status:  1 Running / 0 Waiting / 0 Succeeded / 0 Failed\nPod Template:\n  Labels:  app=redis\n           role=master\n  Containers:\n   redis-master:\n    Image:        gcr.io/kubernetes-e2e-test-images/redis:1.0\n    Port:         6379/TCP\n    Host Port:    0/TCP\n    Environment:  <none>\n    Mounts:       <none>\n  Volumes:        <none>\nEvents:\n  Type    Reason            Age   From                    Message\n  ----    ------            ----  ----                    -------\n  Normal  SuccessfulCreate  11s   replication-controller  Created pod: redis-master-8jk4v\n"
Dec 28 05:47:06.228: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994138694 describe service redis-master --namespace=e2e-tests-kubectl-vzzrv'
Dec 28 05:47:06.587: INFO: stderr: ""
Dec 28 05:47:06.587: INFO: stdout: "Name:              redis-master\nNamespace:         e2e-tests-kubectl-vzzrv\nLabels:            app=redis\n                   role=master\nAnnotations:       <none>\nSelector:          app=redis,role=master\nType:              ClusterIP\nIP:                10.97.90.114\nPort:              <unset>  6379/TCP\nTargetPort:        redis-server/TCP\nEndpoints:         10.168.194.178:6379\nSession Affinity:  None\nEvents:            <none>\n"
Dec 28 05:47:06.598: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994138694 describe node 10.10.102.65-master'
Dec 28 05:47:06.977: INFO: stderr: ""
Dec 28 05:47:06.977: INFO: stdout: "Name:               10.10.102.65-master\nRoles:              master\nLabels:             beta.kubernetes.io/arch=amd64\n                    beta.kubernetes.io/os=linux\n                    kubernetes.io/hostname=10.10.102.65-master\n                    node-role.kubernetes.io/master=\nAnnotations:        kubeadm.alpha.kubernetes.io/cri-socket: /var/run/dockershim.sock\n                    node.alpha.kubernetes.io/ttl: 0\n                    volumes.kubernetes.io/controller-managed-attach-detach: true\nCreationTimestamp:  Tue, 25 Dec 2018 03:31:19 +0000\nTaints:             node-role.kubernetes.io/master:NoSchedule\nUnschedulable:      false\nConditions:\n  Type                 Status  LastHeartbeatTime                 LastTransitionTime                Reason                       Message\n  ----                 ------  -----------------                 ------------------                ------                       -------\n  NetworkUnavailable   False   Wed, 26 Dec 2018 05:26:54 +0000   Wed, 26 Dec 2018 05:26:54 +0000   CalicoIsUp                   Calico is running on this node\n  OutOfDisk            False   Fri, 28 Dec 2018 05:47:01 +0000   Tue, 25 Dec 2018 03:31:10 +0000   KubeletHasSufficientDisk     kubelet has sufficient disk space available\n  MemoryPressure       False   Fri, 28 Dec 2018 05:47:01 +0000   Tue, 25 Dec 2018 03:31:10 +0000   KubeletHasSufficientMemory   kubelet has sufficient memory available\n  DiskPressure         False   Fri, 28 Dec 2018 05:47:01 +0000   Tue, 25 Dec 2018 03:31:10 +0000   KubeletHasNoDiskPressure     kubelet has no disk pressure\n  Ready                True    Fri, 28 Dec 2018 05:47:01 +0000   Wed, 26 Dec 2018 02:58:01 +0000   KubeletReady                 kubelet is posting ready status\n  PIDPressure          False   Fri, 28 Dec 2018 05:47:01 +0000   Wed, 26 Dec 2018 01:53:42 +0000   KubeletHasSufficientPID      kubelet has sufficient PID available\nAddresses:\n  InternalIP:  10.10.102.65\n  Hostname:    10.10.102.65-master\nCapacity:\n cpu:                4\n ephemeral-storage:  99688900Ki\n hugepages-2Mi:      0\n memory:             8010576Ki\n pods:               110\nAllocatable:\n cpu:                4\n ephemeral-storage:  91873290088\n hugepages-2Mi:      0\n memory:             7507792Ki\n pods:               110\nSystem Info:\n Machine ID:                 b0a9be79668f4797a761637ca2925876\n System UUID:                423CA07E-2ED9-C2C8-94F7-DD274EBD6C46\n Boot ID:                    4dbe4523-d1cc-4df9-87ea-9c48dae4ac4b\n Kernel Version:             3.10.0-693.el7.x86_64\n OS Image:                   CentOS Linux 7 (Core)\n Operating System:           linux\n Architecture:               amd64\n Container Runtime Version:  docker://17.3.1\n Kubelet Version:            v1.12.3\n Kube-Proxy Version:         v1.12.3\nNon-terminated Pods:         (9 in total)\n  Namespace                  Name                                                       CPU Requests  CPU Limits  Memory Requests  Memory Limits\n  ---------                  ----                                                       ------------  ----------  ---------------  -------------\n  heptio-sonobuoy            sonobuoy-systemd-logs-daemon-set-3ac5f2aeec8e4908-c9h2g    0 (0%)        0 (0%)      0 (0%)           0 (0%)\n  kube-system                calico-node-2klrf                                          250m (6%)     0 (0%)      0 (0%)           0 (0%)\n  kube-system                etcd-10.10.102.65-master                                   0 (0%)        0 (0%)      0 (0%)           0 (0%)\n  kube-system                kube-apiserver-10.10.102.65-master                         250m (6%)     0 (0%)      0 (0%)           0 (0%)\n  kube-system                kube-controller-manager-10.10.102.65-master                200m (5%)     0 (0%)      0 (0%)           0 (0%)\n  kube-system                kube-proxy-9qw6h                                           0 (0%)        0 (0%)      0 (0%)           0 (0%)\n  kube-system                kube-scheduler-10.10.102.65-master                         100m (2%)     0 (0%)      0 (0%)           0 (0%)\n  kube-system                nfs-controller-95tdv                                       500m (12%)    500m (12%)  512Mi (6%)       512Mi (6%)\n  kube-system                node-up-down-956675868-2s2k6                               500m (12%)    500m (12%)  512Mi (6%)       512Mi (6%)\nAllocated resources:\n  (Total limits may be over 100 percent, i.e., overcommitted.)\n  Resource  Requests     Limits\n  --------  --------     ------\n  cpu       1800m (45%)  1 (25%)\n  memory    1Gi (13%)    1Gi (13%)\nEvents:     <none>\n"
Dec 28 05:47:06.977: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994138694 describe namespace e2e-tests-kubectl-vzzrv'
Dec 28 05:47:07.330: INFO: stderr: ""
Dec 28 05:47:07.330: INFO: stdout: "Name:         e2e-tests-kubectl-vzzrv\nLabels:       e2e-framework=kubectl\n              e2e-run=1d5b0634-0a59-11e9-8a07-628dff7095f4\nAnnotations:  <none>\nStatus:       Active\n\nNo resource quota.\n\nNo resource limits.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 28 05:47:07.330: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-vzzrv" for this suite.
Dec 28 05:47:31.407: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 05:47:31.630: INFO: namespace: e2e-tests-kubectl-vzzrv, resource: bindings, ignored listing per whitelist
Dec 28 05:47:31.708: INFO: namespace e2e-tests-kubectl-vzzrv deletion completed in 24.36717752s

• [SLOW TEST:37.508 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl describe
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should check if kubectl describe prints relevant information for rc and pods  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 28 05:47:31.709: INFO: >>> kubeConfig: /tmp/kubeconfig-994138694
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Dec 28 05:47:31.985: INFO: Waiting up to 5m0s for pod "downwardapi-volume-11984e84-0a64-11e9-8a07-628dff7095f4" in namespace "e2e-tests-projected-9q7tt" to be "success or failure"
Dec 28 05:47:32.053: INFO: Pod "downwardapi-volume-11984e84-0a64-11e9-8a07-628dff7095f4": Phase="Pending", Reason="", readiness=false. Elapsed: 67.500497ms
Dec 28 05:47:34.257: INFO: Pod "downwardapi-volume-11984e84-0a64-11e9-8a07-628dff7095f4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.27198568s
Dec 28 05:47:36.268: INFO: Pod "downwardapi-volume-11984e84-0a64-11e9-8a07-628dff7095f4": Phase="Pending", Reason="", readiness=false. Elapsed: 4.28262055s
Dec 28 05:47:38.275: INFO: Pod "downwardapi-volume-11984e84-0a64-11e9-8a07-628dff7095f4": Phase="Pending", Reason="", readiness=false. Elapsed: 6.289524587s
Dec 28 05:47:40.284: INFO: Pod "downwardapi-volume-11984e84-0a64-11e9-8a07-628dff7095f4": Phase="Pending", Reason="", readiness=false. Elapsed: 8.29814382s
Dec 28 05:47:42.291: INFO: Pod "downwardapi-volume-11984e84-0a64-11e9-8a07-628dff7095f4": Phase="Pending", Reason="", readiness=false. Elapsed: 10.305394293s
Dec 28 05:47:44.298: INFO: Pod "downwardapi-volume-11984e84-0a64-11e9-8a07-628dff7095f4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 12.312939753s
STEP: Saw pod success
Dec 28 05:47:44.298: INFO: Pod "downwardapi-volume-11984e84-0a64-11e9-8a07-628dff7095f4" satisfied condition "success or failure"
Dec 28 05:47:44.305: INFO: Trying to get logs from node 10.10.102.68-share pod downwardapi-volume-11984e84-0a64-11e9-8a07-628dff7095f4 container client-container: <nil>
STEP: delete the pod
Dec 28 05:47:44.439: INFO: Waiting for pod downwardapi-volume-11984e84-0a64-11e9-8a07-628dff7095f4 to disappear
Dec 28 05:47:44.452: INFO: Pod downwardapi-volume-11984e84-0a64-11e9-8a07-628dff7095f4 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 28 05:47:44.452: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-9q7tt" for this suite.
Dec 28 05:47:50.526: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 05:47:50.815: INFO: namespace: e2e-tests-projected-9q7tt, resource: bindings, ignored listing per whitelist
Dec 28 05:47:50.834: INFO: namespace e2e-tests-projected-9q7tt deletion completed in 6.368454513s

• [SLOW TEST:19.125 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-network] DNS 
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 28 05:47:50.835: INFO: >>> kubeConfig: /tmp/kubeconfig-994138694
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(dig +notcp +noall +answer +search kubernetes.default A)" && echo OK > /results/wheezy_udp@kubernetes.default;test -n "$$(dig +tcp +noall +answer +search kubernetes.default A)" && echo OK > /results/wheezy_tcp@kubernetes.default;test -n "$$(dig +notcp +noall +answer +search kubernetes.default.svc A)" && echo OK > /results/wheezy_udp@kubernetes.default.svc;test -n "$$(dig +tcp +noall +answer +search kubernetes.default.svc A)" && echo OK > /results/wheezy_tcp@kubernetes.default.svc;test -n "$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && echo OK > /results/wheezy_udp@kubernetes.default.svc.cluster.local;test -n "$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && echo OK > /results/wheezy_tcp@kubernetes.default.svc.cluster.local;test -n "$$(getent hosts dns-querier-1.dns-test-service.e2e-tests-dns-vsfpb.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-1.dns-test-service.e2e-tests-dns-vsfpb.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/wheezy_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-vsfpb.pod.cluster.local"}');test -n "$$(dig +notcp +noall +answer +search $${podARec} A)" && echo OK > /results/wheezy_udp@PodARecord;test -n "$$(dig +tcp +noall +answer +search $${podARec} A)" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(dig +notcp +noall +answer +search kubernetes.default A)" && echo OK > /results/jessie_udp@kubernetes.default;test -n "$$(dig +tcp +noall +answer +search kubernetes.default A)" && echo OK > /results/jessie_tcp@kubernetes.default;test -n "$$(dig +notcp +noall +answer +search kubernetes.default.svc A)" && echo OK > /results/jessie_udp@kubernetes.default.svc;test -n "$$(dig +tcp +noall +answer +search kubernetes.default.svc A)" && echo OK > /results/jessie_tcp@kubernetes.default.svc;test -n "$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && echo OK > /results/jessie_udp@kubernetes.default.svc.cluster.local;test -n "$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && echo OK > /results/jessie_tcp@kubernetes.default.svc.cluster.local;test -n "$$(getent hosts dns-querier-1.dns-test-service.e2e-tests-dns-vsfpb.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-1.dns-test-service.e2e-tests-dns-vsfpb.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/jessie_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-vsfpb.pod.cluster.local"}');test -n "$$(dig +notcp +noall +answer +search $${podARec} A)" && echo OK > /results/jessie_udp@PodARecord;test -n "$$(dig +tcp +noall +answer +search $${podARec} A)" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Dec 28 05:48:21.855: INFO: DNS probes using e2e-tests-dns-vsfpb/dns-test-1d18702c-0a64-11e9-8a07-628dff7095f4 succeeded

STEP: deleting the pod
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 28 05:48:22.028: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-dns-vsfpb" for this suite.
Dec 28 05:48:28.368: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 05:48:28.698: INFO: namespace: e2e-tests-dns-vsfpb, resource: bindings, ignored listing per whitelist
Dec 28 05:48:28.733: INFO: namespace e2e-tests-dns-vsfpb deletion completed in 6.663507833s

• [SLOW TEST:37.898 seconds]
[sig-network] DNS
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 28 05:48:28.734: INFO: >>> kubeConfig: /tmp/kubeconfig-994138694
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-339ddf34-0a64-11e9-8a07-628dff7095f4
STEP: Creating a pod to test consume secrets
Dec 28 05:48:29.081: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-339efee8-0a64-11e9-8a07-628dff7095f4" in namespace "e2e-tests-projected-rrqqj" to be "success or failure"
Dec 28 05:48:29.093: INFO: Pod "pod-projected-secrets-339efee8-0a64-11e9-8a07-628dff7095f4": Phase="Pending", Reason="", readiness=false. Elapsed: 11.51682ms
Dec 28 05:48:31.103: INFO: Pod "pod-projected-secrets-339efee8-0a64-11e9-8a07-628dff7095f4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.021930714s
Dec 28 05:48:33.117: INFO: Pod "pod-projected-secrets-339efee8-0a64-11e9-8a07-628dff7095f4": Phase="Pending", Reason="", readiness=false. Elapsed: 4.035846644s
Dec 28 05:48:35.124: INFO: Pod "pod-projected-secrets-339efee8-0a64-11e9-8a07-628dff7095f4": Phase="Pending", Reason="", readiness=false. Elapsed: 6.04322822s
Dec 28 05:48:37.133: INFO: Pod "pod-projected-secrets-339efee8-0a64-11e9-8a07-628dff7095f4": Phase="Pending", Reason="", readiness=false. Elapsed: 8.05191781s
Dec 28 05:48:39.165: INFO: Pod "pod-projected-secrets-339efee8-0a64-11e9-8a07-628dff7095f4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 10.083445434s
STEP: Saw pod success
Dec 28 05:48:39.165: INFO: Pod "pod-projected-secrets-339efee8-0a64-11e9-8a07-628dff7095f4" satisfied condition "success or failure"
Dec 28 05:48:39.241: INFO: Trying to get logs from node 10.10.102.69-build pod pod-projected-secrets-339efee8-0a64-11e9-8a07-628dff7095f4 container projected-secret-volume-test: <nil>
STEP: delete the pod
Dec 28 05:48:39.330: INFO: Waiting for pod pod-projected-secrets-339efee8-0a64-11e9-8a07-628dff7095f4 to disappear
Dec 28 05:48:39.358: INFO: Pod pod-projected-secrets-339efee8-0a64-11e9-8a07-628dff7095f4 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 28 05:48:39.359: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-rrqqj" for this suite.
Dec 28 05:48:45.504: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 05:48:45.645: INFO: namespace: e2e-tests-projected-rrqqj, resource: bindings, ignored listing per whitelist
Dec 28 05:48:45.749: INFO: namespace e2e-tests-projected-rrqqj deletion completed in 6.375778484s

• [SLOW TEST:17.015 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should support rollover [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 28 05:48:45.749: INFO: >>> kubeConfig: /tmp/kubeconfig-994138694
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should support rollover [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Dec 28 05:48:46.146: INFO: Pod name rollover-pod: Found 0 pods out of 1
Dec 28 05:48:51.218: INFO: Pod name rollover-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Dec 28 05:48:57.231: INFO: Waiting for pods owned by replica set "test-rollover-controller" to become ready
Dec 28 05:48:59.267: INFO: Creating deployment "test-rollover-deployment"
Dec 28 05:48:59.309: INFO: Make sure deployment "test-rollover-deployment" performs scaling operations
Dec 28 05:49:01.327: INFO: Check revision of new replica set for deployment "test-rollover-deployment"
Dec 28 05:49:01.356: INFO: Ensure that both replica sets have 1 created replica
Dec 28 05:49:01.401: INFO: Rollover old replica sets for deployment "test-rollover-deployment" with new image update
Dec 28 05:49:01.418: INFO: Updating deployment test-rollover-deployment
Dec 28 05:49:01.418: INFO: Wait deployment "test-rollover-deployment" to be observed by the deployment controller
Dec 28 05:49:03.529: INFO: Wait for revision update of deployment "test-rollover-deployment" to 2
Dec 28 05:49:03.545: INFO: Make sure deployment "test-rollover-deployment" is complete
Dec 28 05:49:03.562: INFO: all replica sets need to contain the pod-template-hash label
Dec 28 05:49:03.562: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63681572939, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63681572939, loc:(*time.Location)(0x6c43b60)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63681572941, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63681572939, loc:(*time.Location)(0x6c43b60)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-5b76ff8c4\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec 28 05:49:05.593: INFO: all replica sets need to contain the pod-template-hash label
Dec 28 05:49:05.593: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63681572939, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63681572939, loc:(*time.Location)(0x6c43b60)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63681572941, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63681572939, loc:(*time.Location)(0x6c43b60)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-5b76ff8c4\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec 28 05:49:07.577: INFO: all replica sets need to contain the pod-template-hash label
Dec 28 05:49:07.577: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63681572939, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63681572939, loc:(*time.Location)(0x6c43b60)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63681572941, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63681572939, loc:(*time.Location)(0x6c43b60)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-5b76ff8c4\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec 28 05:49:09.766: INFO: all replica sets need to contain the pod-template-hash label
Dec 28 05:49:09.766: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63681572939, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63681572939, loc:(*time.Location)(0x6c43b60)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63681572941, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63681572939, loc:(*time.Location)(0x6c43b60)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-5b76ff8c4\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec 28 05:49:11.587: INFO: all replica sets need to contain the pod-template-hash label
Dec 28 05:49:11.587: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63681572939, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63681572939, loc:(*time.Location)(0x6c43b60)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63681572941, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63681572939, loc:(*time.Location)(0x6c43b60)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-5b76ff8c4\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec 28 05:49:13.617: INFO: all replica sets need to contain the pod-template-hash label
Dec 28 05:49:13.618: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63681572939, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63681572939, loc:(*time.Location)(0x6c43b60)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63681572951, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63681572939, loc:(*time.Location)(0x6c43b60)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-5b76ff8c4\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec 28 05:49:15.575: INFO: all replica sets need to contain the pod-template-hash label
Dec 28 05:49:15.576: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63681572939, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63681572939, loc:(*time.Location)(0x6c43b60)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63681572951, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63681572939, loc:(*time.Location)(0x6c43b60)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-5b76ff8c4\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec 28 05:49:17.577: INFO: all replica sets need to contain the pod-template-hash label
Dec 28 05:49:17.577: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63681572939, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63681572939, loc:(*time.Location)(0x6c43b60)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63681572951, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63681572939, loc:(*time.Location)(0x6c43b60)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-5b76ff8c4\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec 28 05:49:19.575: INFO: all replica sets need to contain the pod-template-hash label
Dec 28 05:49:19.575: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63681572939, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63681572939, loc:(*time.Location)(0x6c43b60)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63681572951, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63681572939, loc:(*time.Location)(0x6c43b60)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-5b76ff8c4\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec 28 05:49:21.737: INFO: all replica sets need to contain the pod-template-hash label
Dec 28 05:49:21.737: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63681572939, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63681572939, loc:(*time.Location)(0x6c43b60)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63681572951, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63681572939, loc:(*time.Location)(0x6c43b60)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-5b76ff8c4\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec 28 05:49:23.854: INFO: 
Dec 28 05:49:23.855: INFO: Ensure that both old replica sets have no replicas
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Dec 28 05:49:24.033: INFO: Deployment "test-rollover-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment,GenerateName:,Namespace:e2e-tests-deployment-8xr7b,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-8xr7b/deployments/test-rollover-deployment,UID:45b37aff-0a64-11e9-a0ee-005056bc4922,ResourceVersion:535761,Generation:2,CreationTimestamp:2018-12-28 05:48:59 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:0,MaxSurge:1,},},MinReadySeconds:10,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[{Available True 2018-12-28 05:48:59 +0000 UTC 2018-12-28 05:48:59 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2018-12-28 05:49:22 +0000 UTC 2018-12-28 05:48:59 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-rollover-deployment-5b76ff8c4" has successfully progressed.}],ReadyReplicas:1,CollisionCount:nil,},}

Dec 28 05:49:24.041: INFO: New ReplicaSet "test-rollover-deployment-5b76ff8c4" of Deployment "test-rollover-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-5b76ff8c4,GenerateName:,Namespace:e2e-tests-deployment-8xr7b,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-8xr7b/replicasets/test-rollover-deployment-5b76ff8c4,UID:46fb933d-0a64-11e9-a0ee-005056bc4922,ResourceVersion:535751,Generation:2,CreationTimestamp:2018-12-28 05:49:01 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 5b76ff8c4,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment 45b37aff-0a64-11e9-a0ee-005056bc4922 0xc42153ad07 0xc42153ad08}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 5b76ff8c4,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 5b76ff8c4,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:2,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Dec 28 05:49:24.041: INFO: All old ReplicaSets of Deployment "test-rollover-deployment":
Dec 28 05:49:24.042: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-controller,GenerateName:,Namespace:e2e-tests-deployment-8xr7b,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-8xr7b/replicasets/test-rollover-controller,UID:3ddcdf22-0a64-11e9-a0ee-005056bc4922,ResourceVersion:535759,Generation:2,CreationTimestamp:2018-12-28 05:48:46 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod: nginx,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment 45b37aff-0a64-11e9-a0ee-005056bc4922 0xc42153ac2e 0xc42153ac2f}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Dec 28 05:49:24.042: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-6975f4fb87,GenerateName:,Namespace:e2e-tests-deployment-8xr7b,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-8xr7b/replicasets/test-rollover-deployment-6975f4fb87,UID:45c112ab-0a64-11e9-a0ee-005056bc4922,ResourceVersion:535702,Generation:2,CreationTimestamp:2018-12-28 05:48:59 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6975f4fb87,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment 45b37aff-0a64-11e9-a0ee-005056bc4922 0xc42153adc7 0xc42153adc8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 6975f4fb87,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6975f4fb87,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis-slave gcr.io/google_samples/gb-redisslave:nonexistent [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Dec 28 05:49:24.051: INFO: Pod "test-rollover-deployment-5b76ff8c4-hlngd" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-5b76ff8c4-hlngd,GenerateName:test-rollover-deployment-5b76ff8c4-,Namespace:e2e-tests-deployment-8xr7b,SelfLink:/api/v1/namespaces/e2e-tests-deployment-8xr7b/pods/test-rollover-deployment-5b76ff8c4-hlngd,UID:471638b7-0a64-11e9-a0ee-005056bc4922,ResourceVersion:535731,Generation:0,CreationTimestamp:2018-12-28 05:49:01 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 5b76ff8c4,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet test-rollover-deployment-5b76ff8c4 46fb933d-0a64-11e9-a0ee-005056bc4922 0xc42153be50 0xc42153be51}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-fqdj2 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-fqdj2,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-fqdj2 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.10.102.68-share,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc42153beb0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc42197c010}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-28 05:49:01 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-12-28 05:49:11 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2018-12-28 05:49:11 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-28 05:49:01 +0000 UTC  }],Message:,Reason:,HostIP:10.10.102.68,PodIP:10.168.194.182,StartTime:2018-12-28 05:49:01 +0000 UTC,ContainerStatuses:[{redis {nil ContainerStateRunning{StartedAt:2018-12-28 05:49:11 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/redis:1.0 docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830 docker://156f20668a759b5bc4e5e885cff9c663b6f9e7476a9b724f403b07e63c890c4b}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 28 05:49:24.052: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-8xr7b" for this suite.
Dec 28 05:49:32.094: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 05:49:32.270: INFO: namespace: e2e-tests-deployment-8xr7b, resource: bindings, ignored listing per whitelist
Dec 28 05:49:32.492: INFO: namespace e2e-tests-deployment-8xr7b deletion completed in 8.429496624s

• [SLOW TEST:46.743 seconds]
[sig-apps] Deployment
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  deployment should support rollover [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[k8s.io] Probing container 
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 28 05:49:32.492: INFO: >>> kubeConfig: /tmp/kubeconfig-994138694
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-exec in namespace e2e-tests-container-probe-p7jvs
Dec 28 05:49:42.928: INFO: Started pod liveness-exec in namespace e2e-tests-container-probe-p7jvs
STEP: checking the pod's current state and verifying that restartCount is present
Dec 28 05:49:42.934: INFO: Initial restart count of pod liveness-exec is 0
Dec 28 05:50:37.145: INFO: Restart count of pod e2e-tests-container-probe-p7jvs/liveness-exec is now 1 (54.211942884s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 28 05:50:37.172: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-p7jvs" for this suite.
Dec 28 05:50:45.261: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 05:50:45.315: INFO: namespace: e2e-tests-container-probe-p7jvs, resource: bindings, ignored listing per whitelist
Dec 28 05:50:45.535: INFO: namespace e2e-tests-container-probe-p7jvs deletion completed in 8.33102683s

• [SLOW TEST:73.042 seconds]
[k8s.io] Probing container
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 28 05:50:45.535: INFO: >>> kubeConfig: /tmp/kubeconfig-994138694
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-map-857eb461-0a64-11e9-8a07-628dff7095f4
STEP: Creating a pod to test consume secrets
Dec 28 05:50:46.609: INFO: Waiting up to 5m0s for pod "pod-secrets-858b17e3-0a64-11e9-8a07-628dff7095f4" in namespace "e2e-tests-secrets-bdzsk" to be "success or failure"
Dec 28 05:50:46.627: INFO: Pod "pod-secrets-858b17e3-0a64-11e9-8a07-628dff7095f4": Phase="Pending", Reason="", readiness=false. Elapsed: 17.809794ms
Dec 28 05:50:48.643: INFO: Pod "pod-secrets-858b17e3-0a64-11e9-8a07-628dff7095f4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.033634417s
Dec 28 05:50:50.652: INFO: Pod "pod-secrets-858b17e3-0a64-11e9-8a07-628dff7095f4": Phase="Pending", Reason="", readiness=false. Elapsed: 4.042816734s
Dec 28 05:50:52.676: INFO: Pod "pod-secrets-858b17e3-0a64-11e9-8a07-628dff7095f4": Phase="Pending", Reason="", readiness=false. Elapsed: 6.067158704s
Dec 28 05:50:54.726: INFO: Pod "pod-secrets-858b17e3-0a64-11e9-8a07-628dff7095f4": Phase="Pending", Reason="", readiness=false. Elapsed: 8.116562087s
Dec 28 05:50:56.732: INFO: Pod "pod-secrets-858b17e3-0a64-11e9-8a07-628dff7095f4": Phase="Pending", Reason="", readiness=false. Elapsed: 10.12327591s
Dec 28 05:50:58.757: INFO: Pod "pod-secrets-858b17e3-0a64-11e9-8a07-628dff7095f4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 12.14800341s
STEP: Saw pod success
Dec 28 05:50:58.757: INFO: Pod "pod-secrets-858b17e3-0a64-11e9-8a07-628dff7095f4" satisfied condition "success or failure"
Dec 28 05:50:58.762: INFO: Trying to get logs from node 10.10.102.68-share pod pod-secrets-858b17e3-0a64-11e9-8a07-628dff7095f4 container secret-volume-test: <nil>
STEP: delete the pod
Dec 28 05:50:58.819: INFO: Waiting for pod pod-secrets-858b17e3-0a64-11e9-8a07-628dff7095f4 to disappear
Dec 28 05:50:58.829: INFO: Pod pod-secrets-858b17e3-0a64-11e9-8a07-628dff7095f4 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 28 05:50:58.829: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-bdzsk" for this suite.
Dec 28 05:51:04.957: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 05:51:05.122: INFO: namespace: e2e-tests-secrets-bdzsk, resource: bindings, ignored listing per whitelist
Dec 28 05:51:05.433: INFO: namespace e2e-tests-secrets-bdzsk deletion completed in 6.5918602s

• [SLOW TEST:19.897 seconds]
[sig-storage] Secrets
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 28 05:51:05.434: INFO: >>> kubeConfig: /tmp/kubeconfig-994138694
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0777 on tmpfs
Dec 28 05:51:05.760: INFO: Waiting up to 5m0s for pod "pod-910079bc-0a64-11e9-8a07-628dff7095f4" in namespace "e2e-tests-emptydir-x59w4" to be "success or failure"
Dec 28 05:51:05.843: INFO: Pod "pod-910079bc-0a64-11e9-8a07-628dff7095f4": Phase="Pending", Reason="", readiness=false. Elapsed: 82.675966ms
Dec 28 05:51:07.850: INFO: Pod "pod-910079bc-0a64-11e9-8a07-628dff7095f4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.090002023s
Dec 28 05:51:09.857: INFO: Pod "pod-910079bc-0a64-11e9-8a07-628dff7095f4": Phase="Pending", Reason="", readiness=false. Elapsed: 4.097154056s
Dec 28 05:51:11.865: INFO: Pod "pod-910079bc-0a64-11e9-8a07-628dff7095f4": Phase="Pending", Reason="", readiness=false. Elapsed: 6.10458532s
Dec 28 05:51:13.872: INFO: Pod "pod-910079bc-0a64-11e9-8a07-628dff7095f4": Phase="Pending", Reason="", readiness=false. Elapsed: 8.11149167s
Dec 28 05:51:15.890: INFO: Pod "pod-910079bc-0a64-11e9-8a07-628dff7095f4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 10.13025804s
STEP: Saw pod success
Dec 28 05:51:15.890: INFO: Pod "pod-910079bc-0a64-11e9-8a07-628dff7095f4" satisfied condition "success or failure"
Dec 28 05:51:15.908: INFO: Trying to get logs from node 10.10.102.69-build pod pod-910079bc-0a64-11e9-8a07-628dff7095f4 container test-container: <nil>
STEP: delete the pod
Dec 28 05:51:15.986: INFO: Waiting for pod pod-910079bc-0a64-11e9-8a07-628dff7095f4 to disappear
Dec 28 05:51:15.995: INFO: Pod pod-910079bc-0a64-11e9-8a07-628dff7095f4 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 28 05:51:15.995: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-x59w4" for this suite.
Dec 28 05:51:22.040: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 05:51:22.153: INFO: namespace: e2e-tests-emptydir-x59w4, resource: bindings, ignored listing per whitelist
Dec 28 05:51:22.274: INFO: namespace e2e-tests-emptydir-x59w4 deletion completed in 6.26786466s

• [SLOW TEST:16.840 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 28 05:51:22.274: INFO: >>> kubeConfig: /tmp/kubeconfig-994138694
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:98
[It] should run and stop complex daemon [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Dec 28 05:51:22.571: INFO: Creating daemon "daemon-set" with a node selector
STEP: Initially, daemon pods should not be running on any nodes.
Dec 28 05:51:22.598: INFO: Number of nodes with available pods: 0
Dec 28 05:51:22.598: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Change node label to blue, check that daemon pod is launched.
Dec 28 05:51:22.741: INFO: Number of nodes with available pods: 0
Dec 28 05:51:22.741: INFO: Node 10.10.102.66-slave is running more than one daemon pod
Dec 28 05:51:23.818: INFO: Number of nodes with available pods: 0
Dec 28 05:51:23.818: INFO: Node 10.10.102.66-slave is running more than one daemon pod
Dec 28 05:51:24.748: INFO: Number of nodes with available pods: 0
Dec 28 05:51:24.748: INFO: Node 10.10.102.66-slave is running more than one daemon pod
Dec 28 05:51:25.749: INFO: Number of nodes with available pods: 0
Dec 28 05:51:25.749: INFO: Node 10.10.102.66-slave is running more than one daemon pod
Dec 28 05:51:26.824: INFO: Number of nodes with available pods: 0
Dec 28 05:51:26.824: INFO: Node 10.10.102.66-slave is running more than one daemon pod
Dec 28 05:51:27.758: INFO: Number of nodes with available pods: 0
Dec 28 05:51:27.758: INFO: Node 10.10.102.66-slave is running more than one daemon pod
Dec 28 05:51:28.793: INFO: Number of nodes with available pods: 0
Dec 28 05:51:28.793: INFO: Node 10.10.102.66-slave is running more than one daemon pod
Dec 28 05:51:29.749: INFO: Number of nodes with available pods: 0
Dec 28 05:51:29.749: INFO: Node 10.10.102.66-slave is running more than one daemon pod
Dec 28 05:51:30.749: INFO: Number of nodes with available pods: 0
Dec 28 05:51:30.749: INFO: Node 10.10.102.66-slave is running more than one daemon pod
Dec 28 05:51:31.747: INFO: Number of nodes with available pods: 0
Dec 28 05:51:31.747: INFO: Node 10.10.102.66-slave is running more than one daemon pod
Dec 28 05:51:32.750: INFO: Number of nodes with available pods: 1
Dec 28 05:51:32.750: INFO: Number of running nodes: 1, number of available pods: 1
STEP: Update the node label to green, and wait for daemons to be unscheduled
Dec 28 05:51:32.845: INFO: Number of nodes with available pods: 1
Dec 28 05:51:32.845: INFO: Number of running nodes: 0, number of available pods: 1
Dec 28 05:51:33.915: INFO: Number of nodes with available pods: 0
Dec 28 05:51:33.915: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Update DaemonSet node selector to green, and change its update strategy to RollingUpdate
Dec 28 05:51:33.959: INFO: Number of nodes with available pods: 0
Dec 28 05:51:33.959: INFO: Node 10.10.102.66-slave is running more than one daemon pod
Dec 28 05:51:34.967: INFO: Number of nodes with available pods: 0
Dec 28 05:51:34.967: INFO: Node 10.10.102.66-slave is running more than one daemon pod
Dec 28 05:51:35.968: INFO: Number of nodes with available pods: 0
Dec 28 05:51:35.968: INFO: Node 10.10.102.66-slave is running more than one daemon pod
Dec 28 05:51:36.967: INFO: Number of nodes with available pods: 0
Dec 28 05:51:36.967: INFO: Node 10.10.102.66-slave is running more than one daemon pod
Dec 28 05:51:37.967: INFO: Number of nodes with available pods: 0
Dec 28 05:51:37.967: INFO: Node 10.10.102.66-slave is running more than one daemon pod
Dec 28 05:51:38.966: INFO: Number of nodes with available pods: 0
Dec 28 05:51:38.966: INFO: Node 10.10.102.66-slave is running more than one daemon pod
Dec 28 05:51:39.966: INFO: Number of nodes with available pods: 0
Dec 28 05:51:39.966: INFO: Node 10.10.102.66-slave is running more than one daemon pod
Dec 28 05:51:40.966: INFO: Number of nodes with available pods: 0
Dec 28 05:51:40.966: INFO: Node 10.10.102.66-slave is running more than one daemon pod
Dec 28 05:51:41.967: INFO: Number of nodes with available pods: 0
Dec 28 05:51:41.967: INFO: Node 10.10.102.66-slave is running more than one daemon pod
Dec 28 05:51:42.967: INFO: Number of nodes with available pods: 0
Dec 28 05:51:42.967: INFO: Node 10.10.102.66-slave is running more than one daemon pod
Dec 28 05:51:43.998: INFO: Number of nodes with available pods: 0
Dec 28 05:51:43.998: INFO: Node 10.10.102.66-slave is running more than one daemon pod
Dec 28 05:51:44.967: INFO: Number of nodes with available pods: 0
Dec 28 05:51:44.967: INFO: Node 10.10.102.66-slave is running more than one daemon pod
Dec 28 05:51:45.969: INFO: Number of nodes with available pods: 0
Dec 28 05:51:45.969: INFO: Node 10.10.102.66-slave is running more than one daemon pod
Dec 28 05:51:46.966: INFO: Number of nodes with available pods: 0
Dec 28 05:51:46.967: INFO: Node 10.10.102.66-slave is running more than one daemon pod
Dec 28 05:51:47.966: INFO: Number of nodes with available pods: 0
Dec 28 05:51:47.966: INFO: Node 10.10.102.66-slave is running more than one daemon pod
Dec 28 05:51:48.985: INFO: Number of nodes with available pods: 0
Dec 28 05:51:48.985: INFO: Node 10.10.102.66-slave is running more than one daemon pod
Dec 28 05:51:49.967: INFO: Number of nodes with available pods: 0
Dec 28 05:51:49.967: INFO: Node 10.10.102.66-slave is running more than one daemon pod
Dec 28 05:51:50.966: INFO: Number of nodes with available pods: 0
Dec 28 05:51:50.966: INFO: Node 10.10.102.66-slave is running more than one daemon pod
Dec 28 05:51:51.966: INFO: Number of nodes with available pods: 0
Dec 28 05:51:51.966: INFO: Node 10.10.102.66-slave is running more than one daemon pod
Dec 28 05:51:52.967: INFO: Number of nodes with available pods: 0
Dec 28 05:51:52.967: INFO: Node 10.10.102.66-slave is running more than one daemon pod
Dec 28 05:51:53.967: INFO: Number of nodes with available pods: 0
Dec 28 05:51:53.967: INFO: Node 10.10.102.66-slave is running more than one daemon pod
Dec 28 05:51:54.967: INFO: Number of nodes with available pods: 0
Dec 28 05:51:54.967: INFO: Node 10.10.102.66-slave is running more than one daemon pod
Dec 28 05:51:55.967: INFO: Number of nodes with available pods: 0
Dec 28 05:51:55.967: INFO: Node 10.10.102.66-slave is running more than one daemon pod
Dec 28 05:51:56.967: INFO: Number of nodes with available pods: 0
Dec 28 05:51:56.967: INFO: Node 10.10.102.66-slave is running more than one daemon pod
Dec 28 05:51:57.967: INFO: Number of nodes with available pods: 0
Dec 28 05:51:57.967: INFO: Node 10.10.102.66-slave is running more than one daemon pod
Dec 28 05:51:58.967: INFO: Number of nodes with available pods: 0
Dec 28 05:51:58.967: INFO: Node 10.10.102.66-slave is running more than one daemon pod
Dec 28 05:51:59.968: INFO: Number of nodes with available pods: 0
Dec 28 05:51:59.968: INFO: Node 10.10.102.66-slave is running more than one daemon pod
Dec 28 05:52:00.968: INFO: Number of nodes with available pods: 0
Dec 28 05:52:00.968: INFO: Node 10.10.102.66-slave is running more than one daemon pod
Dec 28 05:52:01.966: INFO: Number of nodes with available pods: 0
Dec 28 05:52:01.966: INFO: Node 10.10.102.66-slave is running more than one daemon pod
Dec 28 05:52:02.968: INFO: Number of nodes with available pods: 0
Dec 28 05:52:02.968: INFO: Node 10.10.102.66-slave is running more than one daemon pod
Dec 28 05:52:04.048: INFO: Number of nodes with available pods: 0
Dec 28 05:52:04.048: INFO: Node 10.10.102.66-slave is running more than one daemon pod
Dec 28 05:52:04.968: INFO: Number of nodes with available pods: 0
Dec 28 05:52:04.968: INFO: Node 10.10.102.66-slave is running more than one daemon pod
Dec 28 05:52:05.967: INFO: Number of nodes with available pods: 0
Dec 28 05:52:05.967: INFO: Node 10.10.102.66-slave is running more than one daemon pod
Dec 28 05:52:06.967: INFO: Number of nodes with available pods: 0
Dec 28 05:52:06.967: INFO: Node 10.10.102.66-slave is running more than one daemon pod
Dec 28 05:52:07.967: INFO: Number of nodes with available pods: 0
Dec 28 05:52:07.967: INFO: Node 10.10.102.66-slave is running more than one daemon pod
Dec 28 05:52:08.967: INFO: Number of nodes with available pods: 0
Dec 28 05:52:08.967: INFO: Node 10.10.102.66-slave is running more than one daemon pod
Dec 28 05:52:09.974: INFO: Number of nodes with available pods: 0
Dec 28 05:52:09.974: INFO: Node 10.10.102.66-slave is running more than one daemon pod
Dec 28 05:52:10.967: INFO: Number of nodes with available pods: 0
Dec 28 05:52:10.967: INFO: Node 10.10.102.66-slave is running more than one daemon pod
Dec 28 05:52:12.023: INFO: Number of nodes with available pods: 0
Dec 28 05:52:12.024: INFO: Node 10.10.102.66-slave is running more than one daemon pod
Dec 28 05:52:12.967: INFO: Number of nodes with available pods: 0
Dec 28 05:52:12.967: INFO: Node 10.10.102.66-slave is running more than one daemon pod
Dec 28 05:52:14.025: INFO: Number of nodes with available pods: 0
Dec 28 05:52:14.026: INFO: Node 10.10.102.66-slave is running more than one daemon pod
Dec 28 05:52:14.966: INFO: Number of nodes with available pods: 0
Dec 28 05:52:14.966: INFO: Node 10.10.102.66-slave is running more than one daemon pod
Dec 28 05:52:15.967: INFO: Number of nodes with available pods: 0
Dec 28 05:52:15.967: INFO: Node 10.10.102.66-slave is running more than one daemon pod
Dec 28 05:52:16.966: INFO: Number of nodes with available pods: 0
Dec 28 05:52:16.966: INFO: Node 10.10.102.66-slave is running more than one daemon pod
Dec 28 05:52:17.969: INFO: Number of nodes with available pods: 0
Dec 28 05:52:17.969: INFO: Node 10.10.102.66-slave is running more than one daemon pod
Dec 28 05:52:18.967: INFO: Number of nodes with available pods: 0
Dec 28 05:52:18.967: INFO: Node 10.10.102.66-slave is running more than one daemon pod
Dec 28 05:52:20.022: INFO: Number of nodes with available pods: 1
Dec 28 05:52:20.022: INFO: Number of running nodes: 1, number of available pods: 1
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:64
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting {extensions DaemonSet} daemon-set in namespace e2e-tests-daemonsets-cjp6r, will wait for the garbage collector to delete the pods
Dec 28 05:52:20.100: INFO: Deleting {extensions DaemonSet} daemon-set took: 11.997866ms
Dec 28 05:52:20.301: INFO: Terminating {extensions DaemonSet} daemon-set pods took: 200.44873ms
Dec 28 05:53:01.409: INFO: Number of nodes with available pods: 0
Dec 28 05:53:01.409: INFO: Number of running nodes: 0, number of available pods: 0
Dec 28 05:53:01.414: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-cjp6r/daemonsets","resourceVersion":"536396"},"items":null}

Dec 28 05:53:01.420: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-cjp6r/pods","resourceVersion":"536396"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 28 05:53:01.568: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-cjp6r" for this suite.
Dec 28 05:53:07.628: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 05:53:07.715: INFO: namespace: e2e-tests-daemonsets-cjp6r, resource: bindings, ignored listing per whitelist
Dec 28 05:53:07.831: INFO: namespace e2e-tests-daemonsets-cjp6r deletion completed in 6.25389299s

• [SLOW TEST:105.557 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 28 05:53:07.831: INFO: >>> kubeConfig: /tmp/kubeconfig-994138694
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with configmap pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-configmap-jl4p
STEP: Creating a pod to test atomic-volume-subpath
Dec 28 05:53:08.115: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-jl4p" in namespace "e2e-tests-subpath-84f6v" to be "success or failure"
Dec 28 05:53:08.125: INFO: Pod "pod-subpath-test-configmap-jl4p": Phase="Pending", Reason="", readiness=false. Elapsed: 9.70182ms
Dec 28 05:53:10.133: INFO: Pod "pod-subpath-test-configmap-jl4p": Phase="Pending", Reason="", readiness=false. Elapsed: 2.018215487s
Dec 28 05:53:12.169: INFO: Pod "pod-subpath-test-configmap-jl4p": Phase="Pending", Reason="", readiness=false. Elapsed: 4.053649477s
Dec 28 05:53:14.176: INFO: Pod "pod-subpath-test-configmap-jl4p": Phase="Pending", Reason="", readiness=false. Elapsed: 6.061492087s
Dec 28 05:53:16.197: INFO: Pod "pod-subpath-test-configmap-jl4p": Phase="Pending", Reason="", readiness=false. Elapsed: 8.082273933s
Dec 28 05:53:18.205: INFO: Pod "pod-subpath-test-configmap-jl4p": Phase="Pending", Reason="", readiness=false. Elapsed: 10.09040584s
Dec 28 05:53:20.212: INFO: Pod "pod-subpath-test-configmap-jl4p": Phase="Pending", Reason="", readiness=false. Elapsed: 12.097414463s
Dec 28 05:53:22.220: INFO: Pod "pod-subpath-test-configmap-jl4p": Phase="Pending", Reason="", readiness=false. Elapsed: 14.105229837s
Dec 28 05:53:24.231: INFO: Pod "pod-subpath-test-configmap-jl4p": Phase="Running", Reason="", readiness=false. Elapsed: 16.116538627s
Dec 28 05:53:26.238: INFO: Pod "pod-subpath-test-configmap-jl4p": Phase="Running", Reason="", readiness=false. Elapsed: 18.123248763s
Dec 28 05:53:28.246: INFO: Pod "pod-subpath-test-configmap-jl4p": Phase="Running", Reason="", readiness=false. Elapsed: 20.13129952s
Dec 28 05:53:30.253: INFO: Pod "pod-subpath-test-configmap-jl4p": Phase="Running", Reason="", readiness=false. Elapsed: 22.138374633s
Dec 28 05:53:32.263: INFO: Pod "pod-subpath-test-configmap-jl4p": Phase="Running", Reason="", readiness=false. Elapsed: 24.147747007s
Dec 28 05:53:34.269: INFO: Pod "pod-subpath-test-configmap-jl4p": Phase="Running", Reason="", readiness=false. Elapsed: 26.15449498s
Dec 28 05:53:36.277: INFO: Pod "pod-subpath-test-configmap-jl4p": Phase="Running", Reason="", readiness=false. Elapsed: 28.16168714s
Dec 28 05:53:38.283: INFO: Pod "pod-subpath-test-configmap-jl4p": Phase="Running", Reason="", readiness=false. Elapsed: 30.168509867s
Dec 28 05:53:40.306: INFO: Pod "pod-subpath-test-configmap-jl4p": Phase="Running", Reason="", readiness=false. Elapsed: 32.19150324s
Dec 28 05:53:42.314: INFO: Pod "pod-subpath-test-configmap-jl4p": Phase="Succeeded", Reason="", readiness=false. Elapsed: 34.198715617s
STEP: Saw pod success
Dec 28 05:53:42.314: INFO: Pod "pod-subpath-test-configmap-jl4p" satisfied condition "success or failure"
Dec 28 05:53:42.318: INFO: Trying to get logs from node 10.10.102.68-share pod pod-subpath-test-configmap-jl4p container test-container-subpath-configmap-jl4p: <nil>
STEP: delete the pod
Dec 28 05:53:42.408: INFO: Waiting for pod pod-subpath-test-configmap-jl4p to disappear
Dec 28 05:53:42.437: INFO: Pod pod-subpath-test-configmap-jl4p no longer exists
STEP: Deleting pod pod-subpath-test-configmap-jl4p
Dec 28 05:53:42.438: INFO: Deleting pod "pod-subpath-test-configmap-jl4p" in namespace "e2e-tests-subpath-84f6v"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 28 05:53:42.448: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-84f6v" for this suite.
Dec 28 05:53:48.553: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 05:53:48.587: INFO: namespace: e2e-tests-subpath-84f6v, resource: bindings, ignored listing per whitelist
Dec 28 05:53:48.867: INFO: namespace e2e-tests-subpath-84f6v deletion completed in 6.405730553s

• [SLOW TEST:41.036 seconds]
[sig-storage] Subpath
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with configmap pod [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 28 05:53:48.867: INFO: >>> kubeConfig: /tmp/kubeconfig-994138694
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the rs
STEP: Gathering metrics
Dec 28 05:54:19.769: INFO: MetricsGrabber failed grab metrics. Skipping metrics gathering.
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 28 05:54:19.769: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-vz5j4" for this suite.
Dec 28 05:54:27.843: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 05:54:27.889: INFO: namespace: e2e-tests-gc-vz5j4, resource: bindings, ignored listing per whitelist
Dec 28 05:54:28.049: INFO: namespace e2e-tests-gc-vz5j4 deletion completed in 8.270874463s

• [SLOW TEST:39.182 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[k8s.io] Variable Expansion 
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 28 05:54:28.049: INFO: >>> kubeConfig: /tmp/kubeconfig-994138694
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test env composition
Dec 28 05:54:28.324: INFO: Waiting up to 5m0s for pod "var-expansion-09c0245a-0a65-11e9-8a07-628dff7095f4" in namespace "e2e-tests-var-expansion-tmm4b" to be "success or failure"
Dec 28 05:54:28.332: INFO: Pod "var-expansion-09c0245a-0a65-11e9-8a07-628dff7095f4": Phase="Pending", Reason="", readiness=false. Elapsed: 7.532867ms
Dec 28 05:54:30.340: INFO: Pod "var-expansion-09c0245a-0a65-11e9-8a07-628dff7095f4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014996777s
Dec 28 05:54:32.408: INFO: Pod "var-expansion-09c0245a-0a65-11e9-8a07-628dff7095f4": Phase="Pending", Reason="", readiness=false. Elapsed: 4.083729117s
Dec 28 05:54:34.415: INFO: Pod "var-expansion-09c0245a-0a65-11e9-8a07-628dff7095f4": Phase="Pending", Reason="", readiness=false. Elapsed: 6.090783947s
Dec 28 05:54:36.423: INFO: Pod "var-expansion-09c0245a-0a65-11e9-8a07-628dff7095f4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.098323903s
STEP: Saw pod success
Dec 28 05:54:36.423: INFO: Pod "var-expansion-09c0245a-0a65-11e9-8a07-628dff7095f4" satisfied condition "success or failure"
Dec 28 05:54:36.428: INFO: Trying to get logs from node 10.10.102.69-build pod var-expansion-09c0245a-0a65-11e9-8a07-628dff7095f4 container dapi-container: <nil>
STEP: delete the pod
Dec 28 05:54:36.530: INFO: Waiting for pod var-expansion-09c0245a-0a65-11e9-8a07-628dff7095f4 to disappear
Dec 28 05:54:36.539: INFO: Pod var-expansion-09c0245a-0a65-11e9-8a07-628dff7095f4 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 28 05:54:36.539: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-var-expansion-tmm4b" for this suite.
Dec 28 05:54:42.662: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 05:54:42.771: INFO: namespace: e2e-tests-var-expansion-tmm4b, resource: bindings, ignored listing per whitelist
Dec 28 05:54:42.856: INFO: namespace e2e-tests-var-expansion-tmm4b deletion completed in 6.28074149s

• [SLOW TEST:14.807 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Proxy server 
  should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 28 05:54:42.856: INFO: >>> kubeConfig: /tmp/kubeconfig-994138694
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Starting the proxy
Dec 28 05:54:43.106: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-994138694 proxy --unix-socket=/tmp/kubectl-proxy-unix428764397/test'
STEP: retrieving proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 28 05:54:43.327: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-d2zsg" for this suite.
Dec 28 05:54:49.367: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 05:54:49.394: INFO: namespace: e2e-tests-kubectl-d2zsg, resource: bindings, ignored listing per whitelist
Dec 28 05:54:49.596: INFO: namespace e2e-tests-kubectl-d2zsg deletion completed in 6.256415353s

• [SLOW TEST:6.740 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Proxy server
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should support --unix-socket=/path  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 28 05:54:49.597: INFO: >>> kubeConfig: /tmp/kubeconfig-994138694
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-zd7hc
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Dec 28 05:54:49.916: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Dec 28 05:55:28.261: INFO: ExecWithOptions {Command:[/bin/sh -c timeout -t 15 curl -g -q -s --connect-timeout 1 http://10.168.176.12:8080/hostName | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-zd7hc PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 28 05:55:28.261: INFO: >>> kubeConfig: /tmp/kubeconfig-994138694
Dec 28 05:55:28.600: INFO: Found all expected endpoints: [netserver-0]
Dec 28 05:55:28.608: INFO: ExecWithOptions {Command:[/bin/sh -c timeout -t 15 curl -g -q -s --connect-timeout 1 http://10.168.192.61:8080/hostName | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-zd7hc PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 28 05:55:28.609: INFO: >>> kubeConfig: /tmp/kubeconfig-994138694
Dec 28 05:55:28.779: INFO: Found all expected endpoints: [netserver-1]
Dec 28 05:55:28.786: INFO: ExecWithOptions {Command:[/bin/sh -c timeout -t 15 curl -g -q -s --connect-timeout 1 http://10.168.66.212:8080/hostName | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-zd7hc PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 28 05:55:28.786: INFO: >>> kubeConfig: /tmp/kubeconfig-994138694
Dec 28 05:55:28.980: INFO: Found all expected endpoints: [netserver-2]
Dec 28 05:55:29.018: INFO: ExecWithOptions {Command:[/bin/sh -c timeout -t 15 curl -g -q -s --connect-timeout 1 http://10.168.194.152:8080/hostName | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-zd7hc PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 28 05:55:29.018: INFO: >>> kubeConfig: /tmp/kubeconfig-994138694
Dec 28 05:55:29.186: INFO: Found all expected endpoints: [netserver-3]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 28 05:55:29.186: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-zd7hc" for this suite.
Dec 28 05:55:55.259: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 05:55:55.476: INFO: namespace: e2e-tests-pod-network-test-zd7hc, resource: bindings, ignored listing per whitelist
Dec 28 05:55:55.529: INFO: namespace e2e-tests-pod-network-test-zd7hc deletion completed in 26.331989253s

• [SLOW TEST:65.933 seconds]
[sig-network] Networking
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: http [NodeConformance] [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 28 05:55:55.530: INFO: >>> kubeConfig: /tmp/kubeconfig-994138694
STEP: Building a namespace api object, basename replicaset
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Dec 28 05:55:55.877: INFO: Creating ReplicaSet my-hostname-basic-3df25dba-0a65-11e9-8a07-628dff7095f4
Dec 28 05:55:55.928: INFO: Pod name my-hostname-basic-3df25dba-0a65-11e9-8a07-628dff7095f4: Found 0 pods out of 1
Dec 28 05:56:00.936: INFO: Pod name my-hostname-basic-3df25dba-0a65-11e9-8a07-628dff7095f4: Found 1 pods out of 1
Dec 28 05:56:00.936: INFO: Ensuring a pod for ReplicaSet "my-hostname-basic-3df25dba-0a65-11e9-8a07-628dff7095f4" is running
Dec 28 05:56:04.951: INFO: Pod "my-hostname-basic-3df25dba-0a65-11e9-8a07-628dff7095f4-mct5q" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2018-12-28 05:55:56 +0000 UTC Reason: Message:} {Type:Ready Status:False LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2018-12-28 05:55:56 +0000 UTC Reason:ContainersNotReady Message:containers with unready status: [my-hostname-basic-3df25dba-0a65-11e9-8a07-628dff7095f4]} {Type:ContainersReady Status:False LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2018-12-28 05:55:56 +0000 UTC Reason:ContainersNotReady Message:containers with unready status: [my-hostname-basic-3df25dba-0a65-11e9-8a07-628dff7095f4]} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2018-12-28 05:55:56 +0000 UTC Reason: Message:}])
Dec 28 05:56:04.952: INFO: Trying to dial the pod
Dec 28 05:56:09.974: INFO: Controller my-hostname-basic-3df25dba-0a65-11e9-8a07-628dff7095f4: Got expected result from replica 1 [my-hostname-basic-3df25dba-0a65-11e9-8a07-628dff7095f4-mct5q]: "my-hostname-basic-3df25dba-0a65-11e9-8a07-628dff7095f4-mct5q", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 28 05:56:09.975: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-replicaset-7zvxg" for this suite.
Dec 28 05:56:16.022: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 05:56:16.203: INFO: namespace: e2e-tests-replicaset-7zvxg, resource: bindings, ignored listing per whitelist
Dec 28 05:56:16.225: INFO: namespace e2e-tests-replicaset-7zvxg deletion completed in 6.241435833s

• [SLOW TEST:20.696 seconds]
[sig-apps] ReplicaSet
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-api-machinery] ConfigMap 
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 28 05:56:16.226: INFO: >>> kubeConfig: /tmp/kubeconfig-994138694
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap e2e-tests-configmap-bk8tm/configmap-test-4a36c619-0a65-11e9-8a07-628dff7095f4
STEP: Creating a pod to test consume configMaps
Dec 28 05:56:16.528: INFO: Waiting up to 5m0s for pod "pod-configmaps-4a37f9b7-0a65-11e9-8a07-628dff7095f4" in namespace "e2e-tests-configmap-bk8tm" to be "success or failure"
Dec 28 05:56:16.557: INFO: Pod "pod-configmaps-4a37f9b7-0a65-11e9-8a07-628dff7095f4": Phase="Pending", Reason="", readiness=false. Elapsed: 28.15191ms
Dec 28 05:56:18.634: INFO: Pod "pod-configmaps-4a37f9b7-0a65-11e9-8a07-628dff7095f4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.10584555s
Dec 28 05:56:20.641: INFO: Pod "pod-configmaps-4a37f9b7-0a65-11e9-8a07-628dff7095f4": Phase="Pending", Reason="", readiness=false. Elapsed: 4.112922877s
Dec 28 05:56:22.649: INFO: Pod "pod-configmaps-4a37f9b7-0a65-11e9-8a07-628dff7095f4": Phase="Pending", Reason="", readiness=false. Elapsed: 6.121010027s
Dec 28 05:56:24.657: INFO: Pod "pod-configmaps-4a37f9b7-0a65-11e9-8a07-628dff7095f4": Phase="Running", Reason="", readiness=true. Elapsed: 8.128089517s
Dec 28 05:56:26.680: INFO: Pod "pod-configmaps-4a37f9b7-0a65-11e9-8a07-628dff7095f4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 10.152038397s
STEP: Saw pod success
Dec 28 05:56:26.681: INFO: Pod "pod-configmaps-4a37f9b7-0a65-11e9-8a07-628dff7095f4" satisfied condition "success or failure"
Dec 28 05:56:26.689: INFO: Trying to get logs from node 10.10.102.69-build pod pod-configmaps-4a37f9b7-0a65-11e9-8a07-628dff7095f4 container env-test: <nil>
STEP: delete the pod
Dec 28 05:56:27.037: INFO: Waiting for pod pod-configmaps-4a37f9b7-0a65-11e9-8a07-628dff7095f4 to disappear
Dec 28 05:56:27.063: INFO: Pod pod-configmaps-4a37f9b7-0a65-11e9-8a07-628dff7095f4 no longer exists
[AfterEach] [sig-api-machinery] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 28 05:56:27.063: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-bk8tm" for this suite.
Dec 28 05:56:33.206: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 05:56:33.370: INFO: namespace: e2e-tests-configmap-bk8tm, resource: bindings, ignored listing per whitelist
Dec 28 05:56:33.530: INFO: namespace e2e-tests-configmap-bk8tm deletion completed in 6.45543393s

• [SLOW TEST:17.304 seconds]
[sig-api-machinery] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:30
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 28 05:56:33.530: INFO: >>> kubeConfig: /tmp/kubeconfig-994138694
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:98
[It] should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Dec 28 05:56:33.966: INFO: DaemonSet pods can't tolerate node 10.10.102.65-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 28 05:56:34.032: INFO: Number of nodes with available pods: 0
Dec 28 05:56:34.032: INFO: Node 10.10.102.66-slave is running more than one daemon pod
Dec 28 05:56:35.067: INFO: DaemonSet pods can't tolerate node 10.10.102.65-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 28 05:56:35.078: INFO: Number of nodes with available pods: 0
Dec 28 05:56:35.079: INFO: Node 10.10.102.66-slave is running more than one daemon pod
Dec 28 05:56:36.138: INFO: DaemonSet pods can't tolerate node 10.10.102.65-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 28 05:56:36.145: INFO: Number of nodes with available pods: 0
Dec 28 05:56:36.145: INFO: Node 10.10.102.66-slave is running more than one daemon pod
Dec 28 05:56:37.044: INFO: DaemonSet pods can't tolerate node 10.10.102.65-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 28 05:56:37.051: INFO: Number of nodes with available pods: 0
Dec 28 05:56:37.051: INFO: Node 10.10.102.66-slave is running more than one daemon pod
Dec 28 05:56:38.045: INFO: DaemonSet pods can't tolerate node 10.10.102.65-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 28 05:56:38.052: INFO: Number of nodes with available pods: 0
Dec 28 05:56:38.052: INFO: Node 10.10.102.66-slave is running more than one daemon pod
Dec 28 05:56:39.046: INFO: DaemonSet pods can't tolerate node 10.10.102.65-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 28 05:56:39.055: INFO: Number of nodes with available pods: 0
Dec 28 05:56:39.055: INFO: Node 10.10.102.66-slave is running more than one daemon pod
Dec 28 05:56:40.192: INFO: DaemonSet pods can't tolerate node 10.10.102.65-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 28 05:56:40.201: INFO: Number of nodes with available pods: 0
Dec 28 05:56:40.201: INFO: Node 10.10.102.66-slave is running more than one daemon pod
Dec 28 05:56:41.248: INFO: DaemonSet pods can't tolerate node 10.10.102.65-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 28 05:56:41.258: INFO: Number of nodes with available pods: 0
Dec 28 05:56:41.258: INFO: Node 10.10.102.66-slave is running more than one daemon pod
Dec 28 05:56:42.044: INFO: DaemonSet pods can't tolerate node 10.10.102.65-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 28 05:56:42.109: INFO: Number of nodes with available pods: 0
Dec 28 05:56:42.109: INFO: Node 10.10.102.66-slave is running more than one daemon pod
Dec 28 05:56:43.206: INFO: DaemonSet pods can't tolerate node 10.10.102.65-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 28 05:56:43.213: INFO: Number of nodes with available pods: 0
Dec 28 05:56:43.214: INFO: Node 10.10.102.66-slave is running more than one daemon pod
Dec 28 05:56:44.080: INFO: DaemonSet pods can't tolerate node 10.10.102.65-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 28 05:56:44.089: INFO: Number of nodes with available pods: 0
Dec 28 05:56:44.089: INFO: Node 10.10.102.66-slave is running more than one daemon pod
Dec 28 05:56:45.045: INFO: DaemonSet pods can't tolerate node 10.10.102.65-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 28 05:56:45.125: INFO: Number of nodes with available pods: 2
Dec 28 05:56:45.125: INFO: Node 10.10.102.68-share is running more than one daemon pod
Dec 28 05:56:46.045: INFO: DaemonSet pods can't tolerate node 10.10.102.65-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 28 05:56:46.051: INFO: Number of nodes with available pods: 4
Dec 28 05:56:46.052: INFO: Number of running nodes: 4, number of available pods: 4
STEP: Set a daemon pod's phase to 'Failed', check that the daemon pod is revived.
Dec 28 05:56:46.134: INFO: DaemonSet pods can't tolerate node 10.10.102.65-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 28 05:56:46.162: INFO: Number of nodes with available pods: 3
Dec 28 05:56:46.162: INFO: Node 10.10.102.67-slave is running more than one daemon pod
Dec 28 05:56:47.174: INFO: DaemonSet pods can't tolerate node 10.10.102.65-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 28 05:56:47.181: INFO: Number of nodes with available pods: 3
Dec 28 05:56:47.181: INFO: Node 10.10.102.67-slave is running more than one daemon pod
Dec 28 05:56:48.175: INFO: DaemonSet pods can't tolerate node 10.10.102.65-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 28 05:56:48.181: INFO: Number of nodes with available pods: 3
Dec 28 05:56:48.181: INFO: Node 10.10.102.67-slave is running more than one daemon pod
Dec 28 05:56:49.173: INFO: DaemonSet pods can't tolerate node 10.10.102.65-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 28 05:56:49.180: INFO: Number of nodes with available pods: 3
Dec 28 05:56:49.180: INFO: Node 10.10.102.67-slave is running more than one daemon pod
Dec 28 05:56:50.173: INFO: DaemonSet pods can't tolerate node 10.10.102.65-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 28 05:56:50.180: INFO: Number of nodes with available pods: 3
Dec 28 05:56:50.180: INFO: Node 10.10.102.67-slave is running more than one daemon pod
Dec 28 05:56:51.176: INFO: DaemonSet pods can't tolerate node 10.10.102.65-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 28 05:56:51.186: INFO: Number of nodes with available pods: 3
Dec 28 05:56:51.187: INFO: Node 10.10.102.67-slave is running more than one daemon pod
Dec 28 05:56:52.177: INFO: DaemonSet pods can't tolerate node 10.10.102.65-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 28 05:56:52.184: INFO: Number of nodes with available pods: 3
Dec 28 05:56:52.184: INFO: Node 10.10.102.67-slave is running more than one daemon pod
Dec 28 05:56:53.176: INFO: DaemonSet pods can't tolerate node 10.10.102.65-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 28 05:56:53.186: INFO: Number of nodes with available pods: 3
Dec 28 05:56:53.186: INFO: Node 10.10.102.67-slave is running more than one daemon pod
Dec 28 05:56:54.173: INFO: DaemonSet pods can't tolerate node 10.10.102.65-master with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 28 05:56:54.179: INFO: Number of nodes with available pods: 4
Dec 28 05:56:54.179: INFO: Number of running nodes: 4, number of available pods: 4
STEP: Wait for the failed daemon pod to be completely deleted.
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:64
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting {extensions DaemonSet} daemon-set in namespace e2e-tests-daemonsets-9gzk6, will wait for the garbage collector to delete the pods
Dec 28 05:56:54.261: INFO: Deleting {extensions DaemonSet} daemon-set took: 13.839616ms
Dec 28 05:56:54.462: INFO: Terminating {extensions DaemonSet} daemon-set pods took: 200.661904ms
Dec 28 05:57:33.730: INFO: Number of nodes with available pods: 0
Dec 28 05:57:33.730: INFO: Number of running nodes: 0, number of available pods: 0
Dec 28 05:57:33.735: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-9gzk6/daemonsets","resourceVersion":"537435"},"items":null}

Dec 28 05:57:33.740: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-9gzk6/pods","resourceVersion":"537435"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 28 05:57:33.773: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-9gzk6" for this suite.
Dec 28 05:57:41.808: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 05:57:41.898: INFO: namespace: e2e-tests-daemonsets-9gzk6, resource: bindings, ignored listing per whitelist
Dec 28 05:57:42.026: INFO: namespace e2e-tests-daemonsets-9gzk6 deletion completed in 8.24347911s

• [SLOW TEST:68.496 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 28 05:57:42.027: INFO: >>> kubeConfig: /tmp/kubeconfig-994138694
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0666 on node default medium
Dec 28 05:57:42.389: INFO: Waiting up to 5m0s for pod "pod-7d6c3dbf-0a65-11e9-8a07-628dff7095f4" in namespace "e2e-tests-emptydir-25gmz" to be "success or failure"
Dec 28 05:57:42.444: INFO: Pod "pod-7d6c3dbf-0a65-11e9-8a07-628dff7095f4": Phase="Pending", Reason="", readiness=false. Elapsed: 54.990213ms
Dec 28 05:57:44.476: INFO: Pod "pod-7d6c3dbf-0a65-11e9-8a07-628dff7095f4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.087112163s
Dec 28 05:57:46.573: INFO: Pod "pod-7d6c3dbf-0a65-11e9-8a07-628dff7095f4": Phase="Pending", Reason="", readiness=false. Elapsed: 4.184486686s
Dec 28 05:57:48.580: INFO: Pod "pod-7d6c3dbf-0a65-11e9-8a07-628dff7095f4": Phase="Pending", Reason="", readiness=false. Elapsed: 6.191554143s
Dec 28 05:57:50.613: INFO: Pod "pod-7d6c3dbf-0a65-11e9-8a07-628dff7095f4": Phase="Pending", Reason="", readiness=false. Elapsed: 8.223964556s
Dec 28 05:57:52.638: INFO: Pod "pod-7d6c3dbf-0a65-11e9-8a07-628dff7095f4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 10.24960115s
STEP: Saw pod success
Dec 28 05:57:52.638: INFO: Pod "pod-7d6c3dbf-0a65-11e9-8a07-628dff7095f4" satisfied condition "success or failure"
Dec 28 05:57:52.643: INFO: Trying to get logs from node 10.10.102.68-share pod pod-7d6c3dbf-0a65-11e9-8a07-628dff7095f4 container test-container: <nil>
STEP: delete the pod
Dec 28 05:57:52.755: INFO: Waiting for pod pod-7d6c3dbf-0a65-11e9-8a07-628dff7095f4 to disappear
Dec 28 05:57:52.770: INFO: Pod pod-7d6c3dbf-0a65-11e9-8a07-628dff7095f4 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 28 05:57:52.770: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-25gmz" for this suite.
Dec 28 05:57:58.919: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 05:57:59.003: INFO: namespace: e2e-tests-emptydir-25gmz, resource: bindings, ignored listing per whitelist
Dec 28 05:57:59.201: INFO: namespace e2e-tests-emptydir-25gmz deletion completed in 6.395161037s

• [SLOW TEST:17.174 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 28 05:57:59.201: INFO: >>> kubeConfig: /tmp/kubeconfig-994138694
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-map-879f869e-0a65-11e9-8a07-628dff7095f4
STEP: Creating a pod to test consume configMaps
Dec 28 05:57:59.564: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-87a9817b-0a65-11e9-8a07-628dff7095f4" in namespace "e2e-tests-projected-tqkst" to be "success or failure"
Dec 28 05:57:59.582: INFO: Pod "pod-projected-configmaps-87a9817b-0a65-11e9-8a07-628dff7095f4": Phase="Pending", Reason="", readiness=false. Elapsed: 17.124ms
Dec 28 05:58:01.590: INFO: Pod "pod-projected-configmaps-87a9817b-0a65-11e9-8a07-628dff7095f4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.025691906s
Dec 28 05:58:03.598: INFO: Pod "pod-projected-configmaps-87a9817b-0a65-11e9-8a07-628dff7095f4": Phase="Pending", Reason="", readiness=false. Elapsed: 4.034057943s
Dec 28 05:58:05.606: INFO: Pod "pod-projected-configmaps-87a9817b-0a65-11e9-8a07-628dff7095f4": Phase="Pending", Reason="", readiness=false. Elapsed: 6.041209813s
Dec 28 05:58:07.642: INFO: Pod "pod-projected-configmaps-87a9817b-0a65-11e9-8a07-628dff7095f4": Phase="Pending", Reason="", readiness=false. Elapsed: 8.077951013s
Dec 28 05:58:09.651: INFO: Pod "pod-projected-configmaps-87a9817b-0a65-11e9-8a07-628dff7095f4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 10.08675907s
STEP: Saw pod success
Dec 28 05:58:09.651: INFO: Pod "pod-projected-configmaps-87a9817b-0a65-11e9-8a07-628dff7095f4" satisfied condition "success or failure"
Dec 28 05:58:09.656: INFO: Trying to get logs from node 10.10.102.69-build pod pod-projected-configmaps-87a9817b-0a65-11e9-8a07-628dff7095f4 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Dec 28 05:58:09.791: INFO: Waiting for pod pod-projected-configmaps-87a9817b-0a65-11e9-8a07-628dff7095f4 to disappear
Dec 28 05:58:09.797: INFO: Pod pod-projected-configmaps-87a9817b-0a65-11e9-8a07-628dff7095f4 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 28 05:58:09.797: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-tqkst" for this suite.
Dec 28 05:58:15.861: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 05:58:15.921: INFO: namespace: e2e-tests-projected-tqkst, resource: bindings, ignored listing per whitelist
Dec 28 05:58:16.062: INFO: namespace e2e-tests-projected-tqkst deletion completed in 6.25428293s

• [SLOW TEST:16.861 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 28 05:58:16.063: INFO: >>> kubeConfig: /tmp/kubeconfig-994138694
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-map-91a787bb-0a65-11e9-8a07-628dff7095f4
STEP: Creating a pod to test consume secrets
Dec 28 05:58:16.378: INFO: Waiting up to 5m0s for pod "pod-secrets-91af3d70-0a65-11e9-8a07-628dff7095f4" in namespace "e2e-tests-secrets-vsn6h" to be "success or failure"
Dec 28 05:58:16.406: INFO: Pod "pod-secrets-91af3d70-0a65-11e9-8a07-628dff7095f4": Phase="Pending", Reason="", readiness=false. Elapsed: 26.973136ms
Dec 28 05:58:18.417: INFO: Pod "pod-secrets-91af3d70-0a65-11e9-8a07-628dff7095f4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.038039113s
Dec 28 05:58:20.424: INFO: Pod "pod-secrets-91af3d70-0a65-11e9-8a07-628dff7095f4": Phase="Pending", Reason="", readiness=false. Elapsed: 4.045026243s
Dec 28 05:58:22.431: INFO: Pod "pod-secrets-91af3d70-0a65-11e9-8a07-628dff7095f4": Phase="Pending", Reason="", readiness=false. Elapsed: 6.05205486s
Dec 28 05:58:24.438: INFO: Pod "pod-secrets-91af3d70-0a65-11e9-8a07-628dff7095f4": Phase="Pending", Reason="", readiness=false. Elapsed: 8.059031586s
Dec 28 05:58:26.684: INFO: Pod "pod-secrets-91af3d70-0a65-11e9-8a07-628dff7095f4": Phase="Pending", Reason="", readiness=false. Elapsed: 10.304995766s
Dec 28 05:58:28.693: INFO: Pod "pod-secrets-91af3d70-0a65-11e9-8a07-628dff7095f4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 12.314363513s
STEP: Saw pod success
Dec 28 05:58:28.693: INFO: Pod "pod-secrets-91af3d70-0a65-11e9-8a07-628dff7095f4" satisfied condition "success or failure"
Dec 28 05:58:28.698: INFO: Trying to get logs from node 10.10.102.68-share pod pod-secrets-91af3d70-0a65-11e9-8a07-628dff7095f4 container secret-volume-test: <nil>
STEP: delete the pod
Dec 28 05:58:28.789: INFO: Waiting for pod pod-secrets-91af3d70-0a65-11e9-8a07-628dff7095f4 to disappear
Dec 28 05:58:28.799: INFO: Pod pod-secrets-91af3d70-0a65-11e9-8a07-628dff7095f4 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 28 05:58:28.800: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-vsn6h" for this suite.
Dec 28 05:58:34.905: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 05:58:35.117: INFO: namespace: e2e-tests-secrets-vsn6h, resource: bindings, ignored listing per whitelist
Dec 28 05:58:35.160: INFO: namespace e2e-tests-secrets-vsn6h deletion completed in 6.343772357s

• [SLOW TEST:19.098 seconds]
[sig-storage] Secrets
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with secret pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 28 05:58:35.161: INFO: >>> kubeConfig: /tmp/kubeconfig-994138694
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with secret pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-secret-9rrl
STEP: Creating a pod to test atomic-volume-subpath
Dec 28 05:58:35.607: INFO: Waiting up to 5m0s for pod "pod-subpath-test-secret-9rrl" in namespace "e2e-tests-subpath-5f2gx" to be "success or failure"
Dec 28 05:58:35.675: INFO: Pod "pod-subpath-test-secret-9rrl": Phase="Pending", Reason="", readiness=false. Elapsed: 68.301397ms
Dec 28 05:58:37.682: INFO: Pod "pod-subpath-test-secret-9rrl": Phase="Pending", Reason="", readiness=false. Elapsed: 2.07474921s
Dec 28 05:58:39.690: INFO: Pod "pod-subpath-test-secret-9rrl": Phase="Pending", Reason="", readiness=false. Elapsed: 4.082313774s
Dec 28 05:58:41.813: INFO: Pod "pod-subpath-test-secret-9rrl": Phase="Pending", Reason="", readiness=false. Elapsed: 6.205474257s
Dec 28 05:58:43.891: INFO: Pod "pod-subpath-test-secret-9rrl": Phase="Pending", Reason="", readiness=false. Elapsed: 8.283955964s
Dec 28 05:58:45.944: INFO: Pod "pod-subpath-test-secret-9rrl": Phase="Pending", Reason="", readiness=false. Elapsed: 10.33672297s
Dec 28 05:58:47.951: INFO: Pod "pod-subpath-test-secret-9rrl": Phase="Pending", Reason="", readiness=false. Elapsed: 12.344121247s
Dec 28 05:58:49.958: INFO: Pod "pod-subpath-test-secret-9rrl": Phase="Pending", Reason="", readiness=false. Elapsed: 14.351019247s
Dec 28 05:58:52.001: INFO: Pod "pod-subpath-test-secret-9rrl": Phase="Pending", Reason="", readiness=false. Elapsed: 16.394046434s
Dec 28 05:58:54.073: INFO: Pod "pod-subpath-test-secret-9rrl": Phase="Running", Reason="", readiness=false. Elapsed: 18.465428554s
Dec 28 05:58:56.082: INFO: Pod "pod-subpath-test-secret-9rrl": Phase="Running", Reason="", readiness=false. Elapsed: 20.474469774s
Dec 28 05:58:58.090: INFO: Pod "pod-subpath-test-secret-9rrl": Phase="Running", Reason="", readiness=false. Elapsed: 22.4829361s
Dec 28 05:59:00.098: INFO: Pod "pod-subpath-test-secret-9rrl": Phase="Running", Reason="", readiness=false. Elapsed: 24.491167294s
Dec 28 05:59:02.108: INFO: Pod "pod-subpath-test-secret-9rrl": Phase="Running", Reason="", readiness=false. Elapsed: 26.50034482s
Dec 28 05:59:04.116: INFO: Pod "pod-subpath-test-secret-9rrl": Phase="Running", Reason="", readiness=false. Elapsed: 28.508496297s
Dec 28 05:59:06.124: INFO: Pod "pod-subpath-test-secret-9rrl": Phase="Running", Reason="", readiness=false. Elapsed: 30.516740844s
Dec 28 05:59:08.131: INFO: Pod "pod-subpath-test-secret-9rrl": Phase="Running", Reason="", readiness=false. Elapsed: 32.523512984s
Dec 28 05:59:10.139: INFO: Pod "pod-subpath-test-secret-9rrl": Phase="Running", Reason="", readiness=false. Elapsed: 34.532041967s
Dec 28 05:59:12.150: INFO: Pod "pod-subpath-test-secret-9rrl": Phase="Succeeded", Reason="", readiness=false. Elapsed: 36.54232339s
STEP: Saw pod success
Dec 28 05:59:12.150: INFO: Pod "pod-subpath-test-secret-9rrl" satisfied condition "success or failure"
Dec 28 05:59:12.157: INFO: Trying to get logs from node 10.10.102.69-build pod pod-subpath-test-secret-9rrl container test-container-subpath-secret-9rrl: <nil>
STEP: delete the pod
Dec 28 05:59:12.223: INFO: Waiting for pod pod-subpath-test-secret-9rrl to disappear
Dec 28 05:59:12.393: INFO: Pod pod-subpath-test-secret-9rrl no longer exists
STEP: Deleting pod pod-subpath-test-secret-9rrl
Dec 28 05:59:12.393: INFO: Deleting pod "pod-subpath-test-secret-9rrl" in namespace "e2e-tests-subpath-5f2gx"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 28 05:59:12.399: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-5f2gx" for this suite.
Dec 28 05:59:20.447: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 05:59:20.524: INFO: namespace: e2e-tests-subpath-5f2gx, resource: bindings, ignored listing per whitelist
Dec 28 05:59:20.790: INFO: namespace e2e-tests-subpath-5f2gx deletion completed in 8.37080569s

• [SLOW TEST:45.630 seconds]
[sig-storage] Subpath
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with secret pod [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Projected 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 28 05:59:20.791: INFO: >>> kubeConfig: /tmp/kubeconfig-994138694
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating the pod
Dec 28 05:59:31.780: INFO: Successfully updated pod "labelsupdateb85509c5-0a65-11e9-8a07-628dff7095f4"
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 28 05:59:35.869: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-njjq9" for this suite.
Dec 28 05:59:59.947: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 06:00:00.005: INFO: namespace: e2e-tests-projected-njjq9, resource: bindings, ignored listing per whitelist
Dec 28 06:00:00.173: INFO: namespace e2e-tests-projected-njjq9 deletion completed in 24.29473378s

• [SLOW TEST:39.382 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] Projected 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 28 06:00:00.173: INFO: >>> kubeConfig: /tmp/kubeconfig-994138694
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Dec 28 06:00:00.483: INFO: Waiting up to 5m0s for pod "downwardapi-volume-cfbc5542-0a65-11e9-8a07-628dff7095f4" in namespace "e2e-tests-projected-dxgsv" to be "success or failure"
Dec 28 06:00:00.522: INFO: Pod "downwardapi-volume-cfbc5542-0a65-11e9-8a07-628dff7095f4": Phase="Pending", Reason="", readiness=false. Elapsed: 38.581304ms
Dec 28 06:00:02.534: INFO: Pod "downwardapi-volume-cfbc5542-0a65-11e9-8a07-628dff7095f4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.05064188s
Dec 28 06:00:04.541: INFO: Pod "downwardapi-volume-cfbc5542-0a65-11e9-8a07-628dff7095f4": Phase="Pending", Reason="", readiness=false. Elapsed: 4.05745824s
Dec 28 06:00:06.548: INFO: Pod "downwardapi-volume-cfbc5542-0a65-11e9-8a07-628dff7095f4": Phase="Pending", Reason="", readiness=false. Elapsed: 6.06431849s
Dec 28 06:00:08.556: INFO: Pod "downwardapi-volume-cfbc5542-0a65-11e9-8a07-628dff7095f4": Phase="Pending", Reason="", readiness=false. Elapsed: 8.07269492s
Dec 28 06:00:10.563: INFO: Pod "downwardapi-volume-cfbc5542-0a65-11e9-8a07-628dff7095f4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 10.079976787s
STEP: Saw pod success
Dec 28 06:00:10.563: INFO: Pod "downwardapi-volume-cfbc5542-0a65-11e9-8a07-628dff7095f4" satisfied condition "success or failure"
Dec 28 06:00:10.568: INFO: Trying to get logs from node 10.10.102.68-share pod downwardapi-volume-cfbc5542-0a65-11e9-8a07-628dff7095f4 container client-container: <nil>
STEP: delete the pod
Dec 28 06:00:10.749: INFO: Waiting for pod downwardapi-volume-cfbc5542-0a65-11e9-8a07-628dff7095f4 to disappear
Dec 28 06:00:10.773: INFO: Pod downwardapi-volume-cfbc5542-0a65-11e9-8a07-628dff7095f4 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 28 06:00:10.773: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-dxgsv" for this suite.
Dec 28 06:00:16.968: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 06:00:16.990: INFO: namespace: e2e-tests-projected-dxgsv, resource: bindings, ignored listing per whitelist
Dec 28 06:00:17.189: INFO: namespace e2e-tests-projected-dxgsv deletion completed in 6.403725083s

• [SLOW TEST:17.016 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 28 06:00:17.189: INFO: >>> kubeConfig: /tmp/kubeconfig-994138694
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: modifying the configmap a second time
STEP: deleting the configmap
STEP: creating a watch on configmaps from the resource version returned by the first update
STEP: Expecting to observe notifications for all changes to the configmap after the first update
Dec 28 06:00:17.657: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-resource-version,GenerateName:,Namespace:e2e-tests-watch-v66fj,SelfLink:/api/v1/namespaces/e2e-tests-watch-v66fj/configmaps/e2e-watch-test-resource-version,UID:d9fbd4be-0a65-11e9-a0ee-005056bc4922,ResourceVersion:537994,Generation:0,CreationTimestamp:2018-12-28 06:00:17 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: from-resource-version,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Dec 28 06:00:17.657: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-resource-version,GenerateName:,Namespace:e2e-tests-watch-v66fj,SelfLink:/api/v1/namespaces/e2e-tests-watch-v66fj/configmaps/e2e-watch-test-resource-version,UID:d9fbd4be-0a65-11e9-a0ee-005056bc4922,ResourceVersion:537995,Generation:0,CreationTimestamp:2018-12-28 06:00:17 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: from-resource-version,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 28 06:00:17.657: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-v66fj" for this suite.
Dec 28 06:00:23.795: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 06:00:23.932: INFO: namespace: e2e-tests-watch-v66fj, resource: bindings, ignored listing per whitelist
Dec 28 06:00:24.178: INFO: namespace e2e-tests-watch-v66fj deletion completed in 6.498167817s

• [SLOW TEST:6.988 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 28 06:00:24.178: INFO: >>> kubeConfig: /tmp/kubeconfig-994138694
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-de1dbf5d-0a65-11e9-8a07-628dff7095f4
STEP: Creating a pod to test consume configMaps
Dec 28 06:00:24.746: INFO: Waiting up to 5m0s for pod "pod-configmaps-de2476c4-0a65-11e9-8a07-628dff7095f4" in namespace "e2e-tests-configmap-mbxpf" to be "success or failure"
Dec 28 06:00:24.786: INFO: Pod "pod-configmaps-de2476c4-0a65-11e9-8a07-628dff7095f4": Phase="Pending", Reason="", readiness=false. Elapsed: 40.449857ms
Dec 28 06:00:26.801: INFO: Pod "pod-configmaps-de2476c4-0a65-11e9-8a07-628dff7095f4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.05530735s
Dec 28 06:00:28.808: INFO: Pod "pod-configmaps-de2476c4-0a65-11e9-8a07-628dff7095f4": Phase="Pending", Reason="", readiness=false. Elapsed: 4.061938507s
Dec 28 06:00:30.815: INFO: Pod "pod-configmaps-de2476c4-0a65-11e9-8a07-628dff7095f4": Phase="Pending", Reason="", readiness=false. Elapsed: 6.0696185s
Dec 28 06:00:32.823: INFO: Pod "pod-configmaps-de2476c4-0a65-11e9-8a07-628dff7095f4": Phase="Pending", Reason="", readiness=false. Elapsed: 8.07698694s
Dec 28 06:00:34.895: INFO: Pod "pod-configmaps-de2476c4-0a65-11e9-8a07-628dff7095f4": Phase="Pending", Reason="", readiness=false. Elapsed: 10.149514327s
Dec 28 06:00:36.902: INFO: Pod "pod-configmaps-de2476c4-0a65-11e9-8a07-628dff7095f4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 12.156435117s
STEP: Saw pod success
Dec 28 06:00:36.902: INFO: Pod "pod-configmaps-de2476c4-0a65-11e9-8a07-628dff7095f4" satisfied condition "success or failure"
Dec 28 06:00:36.915: INFO: Trying to get logs from node 10.10.102.68-share pod pod-configmaps-de2476c4-0a65-11e9-8a07-628dff7095f4 container configmap-volume-test: <nil>
STEP: delete the pod
Dec 28 06:00:37.700: INFO: Waiting for pod pod-configmaps-de2476c4-0a65-11e9-8a07-628dff7095f4 to disappear
Dec 28 06:00:37.707: INFO: Pod pod-configmaps-de2476c4-0a65-11e9-8a07-628dff7095f4 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 28 06:00:37.707: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-mbxpf" for this suite.
Dec 28 06:00:43.763: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 06:00:43.821: INFO: namespace: e2e-tests-configmap-mbxpf, resource: bindings, ignored listing per whitelist
Dec 28 06:00:44.080: INFO: namespace e2e-tests-configmap-mbxpf deletion completed in 6.360313724s

• [SLOW TEST:19.902 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 28 06:00:44.081: INFO: >>> kubeConfig: /tmp/kubeconfig-994138694
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Dec 28 06:00:44.499: INFO: Pod name cleanup-pod: Found 0 pods out of 1
Dec 28 06:00:49.508: INFO: Pod name cleanup-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Dec 28 06:00:53.521: INFO: Creating deployment test-cleanup-deployment
STEP: Waiting for deployment test-cleanup-deployment history to be cleaned up
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Dec 28 06:00:53.564: INFO: Deployment "test-cleanup-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-deployment,GenerateName:,Namespace:e2e-tests-deployment-4tbzl,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-4tbzl/deployments/test-cleanup-deployment,UID:ef6effd8-0a65-11e9-a0ee-005056bc4922,ResourceVersion:538126,Generation:1,CreationTimestamp:2018-12-28 06:00:53 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*0,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:0,Replicas:0,UpdatedReplicas:0,AvailableReplicas:0,UnavailableReplicas:0,Conditions:[],ReadyReplicas:0,CollisionCount:nil,},}

Dec 28 06:00:53.580: INFO: New ReplicaSet of Deployment "test-cleanup-deployment" is nil.
Dec 28 06:00:53.580: INFO: All old ReplicaSets of Deployment "test-cleanup-deployment":
Dec 28 06:00:53.581: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-controller,GenerateName:,Namespace:e2e-tests-deployment-4tbzl,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-4tbzl/replicasets/test-cleanup-controller,UID:ea08707d-0a65-11e9-a0ee-005056bc4922,ResourceVersion:538127,Generation:1,CreationTimestamp:2018-12-28 06:00:44 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 Deployment test-cleanup-deployment ef6effd8-0a65-11e9-a0ee-005056bc4922 0xc422883187 0xc422883188}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Dec 28 06:00:53.598: INFO: Pod "test-cleanup-controller-vwlw5" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-controller-vwlw5,GenerateName:test-cleanup-controller-,Namespace:e2e-tests-deployment-4tbzl,SelfLink:/api/v1/namespaces/e2e-tests-deployment-4tbzl/pods/test-cleanup-controller-vwlw5,UID:ea0ece4d-0a65-11e9-a0ee-005056bc4922,ResourceVersion:538124,Generation:0,CreationTimestamp:2018-12-28 06:00:44 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet test-cleanup-controller ea08707d-0a65-11e9-a0ee-005056bc4922 0xc422883847 0xc422883848}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-x4wrr {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-x4wrr,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-x4wrr true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.10.102.69-build,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc4228838b0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc4228838d0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-28 06:00:45 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-12-28 06:00:53 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2018-12-28 06:00:53 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-28 06:00:44 +0000 UTC  }],Message:,Reason:,HostIP:10.10.102.69,PodIP:10.168.192.2,StartTime:2018-12-28 06:00:45 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2018-12-28 06:00:53 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:e3f77f7f4a6bb5e7820e013fa60b96602b34f5704e796cfd94b561ae73adcf96 docker://8ed7b167efa44a2bd71e31bd0477be6e6b0651667b5d381e9f4b075434e8ce05}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 28 06:00:53.598: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-4tbzl" for this suite.
Dec 28 06:01:01.732: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 06:01:01.862: INFO: namespace: e2e-tests-deployment-4tbzl, resource: bindings, ignored listing per whitelist
Dec 28 06:01:02.169: INFO: namespace e2e-tests-deployment-4tbzl deletion completed in 8.48245482s

• [SLOW TEST:18.088 seconds]
[sig-apps] Deployment
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 28 06:01:02.170: INFO: >>> kubeConfig: /tmp/kubeconfig-994138694
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-map-f4b88099-0a65-11e9-8a07-628dff7095f4
STEP: Creating a pod to test consume configMaps
Dec 28 06:01:02.619: INFO: Waiting up to 5m0s for pod "pod-configmaps-f4c407f4-0a65-11e9-8a07-628dff7095f4" in namespace "e2e-tests-configmap-nhl79" to be "success or failure"
Dec 28 06:01:02.647: INFO: Pod "pod-configmaps-f4c407f4-0a65-11e9-8a07-628dff7095f4": Phase="Pending", Reason="", readiness=false. Elapsed: 27.274196ms
Dec 28 06:01:04.654: INFO: Pod "pod-configmaps-f4c407f4-0a65-11e9-8a07-628dff7095f4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.034423826s
Dec 28 06:01:06.667: INFO: Pod "pod-configmaps-f4c407f4-0a65-11e9-8a07-628dff7095f4": Phase="Pending", Reason="", readiness=false. Elapsed: 4.047260136s
Dec 28 06:01:08.794: INFO: Pod "pod-configmaps-f4c407f4-0a65-11e9-8a07-628dff7095f4": Phase="Pending", Reason="", readiness=false. Elapsed: 6.17414793s
Dec 28 06:01:10.801: INFO: Pod "pod-configmaps-f4c407f4-0a65-11e9-8a07-628dff7095f4": Phase="Pending", Reason="", readiness=false. Elapsed: 8.181910563s
Dec 28 06:01:12.809: INFO: Pod "pod-configmaps-f4c407f4-0a65-11e9-8a07-628dff7095f4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 10.189453643s
STEP: Saw pod success
Dec 28 06:01:12.809: INFO: Pod "pod-configmaps-f4c407f4-0a65-11e9-8a07-628dff7095f4" satisfied condition "success or failure"
Dec 28 06:01:12.815: INFO: Trying to get logs from node 10.10.102.69-build pod pod-configmaps-f4c407f4-0a65-11e9-8a07-628dff7095f4 container configmap-volume-test: <nil>
STEP: delete the pod
Dec 28 06:01:12.904: INFO: Waiting for pod pod-configmaps-f4c407f4-0a65-11e9-8a07-628dff7095f4 to disappear
Dec 28 06:01:12.981: INFO: Pod pod-configmaps-f4c407f4-0a65-11e9-8a07-628dff7095f4 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 28 06:01:12.981: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-nhl79" for this suite.
Dec 28 06:01:21.082: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 06:01:21.177: INFO: namespace: e2e-tests-configmap-nhl79, resource: bindings, ignored listing per whitelist
Dec 28 06:01:21.304: INFO: namespace e2e-tests-configmap-nhl79 deletion completed in 8.312620914s

• [SLOW TEST:19.135 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 28 06:01:21.304: INFO: >>> kubeConfig: /tmp/kubeconfig-994138694
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:293
[It] should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a replication controller
Dec 28 06:01:21.569: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994138694 create -f - --namespace=e2e-tests-kubectl-2q4g4'
Dec 28 06:01:24.465: INFO: stderr: ""
Dec 28 06:01:24.465: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Dec 28 06:01:24.466: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994138694 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-2q4g4'
Dec 28 06:01:24.808: INFO: stderr: ""
Dec 28 06:01:24.808: INFO: stdout: "update-demo-nautilus-96tzm update-demo-nautilus-t487g "
Dec 28 06:01:24.808: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994138694 get pods update-demo-nautilus-96tzm -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-2q4g4'
Dec 28 06:01:25.144: INFO: stderr: ""
Dec 28 06:01:25.144: INFO: stdout: ""
Dec 28 06:01:25.144: INFO: update-demo-nautilus-96tzm is created but not running
Dec 28 06:01:30.166: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994138694 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-2q4g4'
Dec 28 06:01:30.538: INFO: stderr: ""
Dec 28 06:01:30.539: INFO: stdout: "update-demo-nautilus-96tzm update-demo-nautilus-t487g "
Dec 28 06:01:30.539: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994138694 get pods update-demo-nautilus-96tzm -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-2q4g4'
Dec 28 06:01:30.877: INFO: stderr: ""
Dec 28 06:01:30.877: INFO: stdout: ""
Dec 28 06:01:30.877: INFO: update-demo-nautilus-96tzm is created but not running
Dec 28 06:01:35.877: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994138694 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-2q4g4'
Dec 28 06:01:36.187: INFO: stderr: ""
Dec 28 06:01:36.187: INFO: stdout: "update-demo-nautilus-96tzm update-demo-nautilus-t487g "
Dec 28 06:01:36.187: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994138694 get pods update-demo-nautilus-96tzm -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-2q4g4'
Dec 28 06:01:36.531: INFO: stderr: ""
Dec 28 06:01:36.531: INFO: stdout: "true"
Dec 28 06:01:36.531: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994138694 get pods update-demo-nautilus-96tzm -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-2q4g4'
Dec 28 06:01:36.852: INFO: stderr: ""
Dec 28 06:01:36.852: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Dec 28 06:01:36.852: INFO: validating pod update-demo-nautilus-96tzm
Dec 28 06:01:36.904: INFO: got data: {
  "image": "nautilus.jpg"
}

Dec 28 06:01:36.904: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Dec 28 06:01:36.904: INFO: update-demo-nautilus-96tzm is verified up and running
Dec 28 06:01:36.904: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994138694 get pods update-demo-nautilus-t487g -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-2q4g4'
Dec 28 06:01:37.232: INFO: stderr: ""
Dec 28 06:01:37.232: INFO: stdout: "true"
Dec 28 06:01:37.233: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994138694 get pods update-demo-nautilus-t487g -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-2q4g4'
Dec 28 06:01:37.557: INFO: stderr: ""
Dec 28 06:01:37.558: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Dec 28 06:01:37.558: INFO: validating pod update-demo-nautilus-t487g
Dec 28 06:01:37.577: INFO: got data: {
  "image": "nautilus.jpg"
}

Dec 28 06:01:37.578: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Dec 28 06:01:37.578: INFO: update-demo-nautilus-t487g is verified up and running
STEP: using delete to clean up resources
Dec 28 06:01:37.578: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994138694 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-2q4g4'
Dec 28 06:01:37.872: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Dec 28 06:01:37.872: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Dec 28 06:01:37.873: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994138694 get rc,svc -l name=update-demo --no-headers --namespace=e2e-tests-kubectl-2q4g4'
Dec 28 06:01:38.190: INFO: stderr: "No resources found.\n"
Dec 28 06:01:38.190: INFO: stdout: ""
Dec 28 06:01:38.190: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994138694 get pods -l name=update-demo --namespace=e2e-tests-kubectl-2q4g4 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Dec 28 06:01:38.605: INFO: stderr: ""
Dec 28 06:01:38.605: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 28 06:01:38.605: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-2q4g4" for this suite.
Dec 28 06:01:46.658: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 06:01:46.869: INFO: namespace: e2e-tests-kubectl-2q4g4, resource: bindings, ignored listing per whitelist
Dec 28 06:01:46.897: INFO: namespace e2e-tests-kubectl-2q4g4 deletion completed in 8.28201228s

• [SLOW TEST:25.593 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Update Demo
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create and stop a replication controller  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 28 06:01:46.898: INFO: >>> kubeConfig: /tmp/kubeconfig-994138694
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test override command
Dec 28 06:01:47.346: INFO: Waiting up to 5m0s for pod "client-containers-0f6e5880-0a66-11e9-8a07-628dff7095f4" in namespace "e2e-tests-containers-nhnl5" to be "success or failure"
Dec 28 06:01:47.391: INFO: Pod "client-containers-0f6e5880-0a66-11e9-8a07-628dff7095f4": Phase="Pending", Reason="", readiness=false. Elapsed: 45.41474ms
Dec 28 06:01:49.399: INFO: Pod "client-containers-0f6e5880-0a66-11e9-8a07-628dff7095f4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.053042004s
Dec 28 06:01:51.407: INFO: Pod "client-containers-0f6e5880-0a66-11e9-8a07-628dff7095f4": Phase="Pending", Reason="", readiness=false. Elapsed: 4.061005694s
Dec 28 06:01:53.414: INFO: Pod "client-containers-0f6e5880-0a66-11e9-8a07-628dff7095f4": Phase="Pending", Reason="", readiness=false. Elapsed: 6.068491167s
Dec 28 06:01:55.421: INFO: Pod "client-containers-0f6e5880-0a66-11e9-8a07-628dff7095f4": Phase="Pending", Reason="", readiness=false. Elapsed: 8.074904994s
Dec 28 06:01:57.441: INFO: Pod "client-containers-0f6e5880-0a66-11e9-8a07-628dff7095f4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 10.095657587s
STEP: Saw pod success
Dec 28 06:01:57.442: INFO: Pod "client-containers-0f6e5880-0a66-11e9-8a07-628dff7095f4" satisfied condition "success or failure"
Dec 28 06:01:57.447: INFO: Trying to get logs from node 10.10.102.68-share pod client-containers-0f6e5880-0a66-11e9-8a07-628dff7095f4 container test-container: <nil>
STEP: delete the pod
Dec 28 06:01:57.598: INFO: Waiting for pod client-containers-0f6e5880-0a66-11e9-8a07-628dff7095f4 to disappear
Dec 28 06:01:57.610: INFO: Pod client-containers-0f6e5880-0a66-11e9-8a07-628dff7095f4 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 28 06:01:57.610: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-nhnl5" for this suite.
Dec 28 06:02:05.688: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 06:02:05.802: INFO: namespace: e2e-tests-containers-nhnl5, resource: bindings, ignored listing per whitelist
Dec 28 06:02:05.959: INFO: namespace e2e-tests-containers-nhnl5 deletion completed in 8.3369011s

• [SLOW TEST:19.062 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 28 06:02:05.960: INFO: >>> kubeConfig: /tmp/kubeconfig-994138694
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-map-1ac34ff5-0a66-11e9-8a07-628dff7095f4
STEP: Creating a pod to test consume secrets
Dec 28 06:02:06.392: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-1ac4832f-0a66-11e9-8a07-628dff7095f4" in namespace "e2e-tests-projected-5kb2k" to be "success or failure"
Dec 28 06:02:06.412: INFO: Pod "pod-projected-secrets-1ac4832f-0a66-11e9-8a07-628dff7095f4": Phase="Pending", Reason="", readiness=false. Elapsed: 20.485396ms
Dec 28 06:02:08.421: INFO: Pod "pod-projected-secrets-1ac4832f-0a66-11e9-8a07-628dff7095f4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.029518423s
Dec 28 06:02:10.430: INFO: Pod "pod-projected-secrets-1ac4832f-0a66-11e9-8a07-628dff7095f4": Phase="Pending", Reason="", readiness=false. Elapsed: 4.03778616s
Dec 28 06:02:12.478: INFO: Pod "pod-projected-secrets-1ac4832f-0a66-11e9-8a07-628dff7095f4": Phase="Pending", Reason="", readiness=false. Elapsed: 6.086534036s
Dec 28 06:02:14.486: INFO: Pod "pod-projected-secrets-1ac4832f-0a66-11e9-8a07-628dff7095f4": Phase="Pending", Reason="", readiness=false. Elapsed: 8.094496726s
Dec 28 06:02:16.494: INFO: Pod "pod-projected-secrets-1ac4832f-0a66-11e9-8a07-628dff7095f4": Phase="Running", Reason="", readiness=true. Elapsed: 10.10188605s
Dec 28 06:02:18.501: INFO: Pod "pod-projected-secrets-1ac4832f-0a66-11e9-8a07-628dff7095f4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 12.109008506s
STEP: Saw pod success
Dec 28 06:02:18.501: INFO: Pod "pod-projected-secrets-1ac4832f-0a66-11e9-8a07-628dff7095f4" satisfied condition "success or failure"
Dec 28 06:02:18.508: INFO: Trying to get logs from node 10.10.102.69-build pod pod-projected-secrets-1ac4832f-0a66-11e9-8a07-628dff7095f4 container projected-secret-volume-test: <nil>
STEP: delete the pod
Dec 28 06:02:18.917: INFO: Waiting for pod pod-projected-secrets-1ac4832f-0a66-11e9-8a07-628dff7095f4 to disappear
Dec 28 06:02:18.924: INFO: Pod pod-projected-secrets-1ac4832f-0a66-11e9-8a07-628dff7095f4 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 28 06:02:18.924: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-5kb2k" for this suite.
Dec 28 06:02:25.046: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 06:02:25.220: INFO: namespace: e2e-tests-projected-5kb2k, resource: bindings, ignored listing per whitelist
Dec 28 06:02:25.302: INFO: namespace e2e-tests-projected-5kb2k deletion completed in 6.363888314s

• [SLOW TEST:19.342 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 28 06:02:25.303: INFO: >>> kubeConfig: /tmp/kubeconfig-994138694
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating the pod
Dec 28 06:02:36.235: INFO: Successfully updated pod "labelsupdate263c0933-0a66-11e9-8a07-628dff7095f4"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 28 06:02:38.327: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-9xzpk" for this suite.
Dec 28 06:03:02.451: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 06:03:02.696: INFO: namespace: e2e-tests-downward-api-9xzpk, resource: bindings, ignored listing per whitelist
Dec 28 06:03:02.764: INFO: namespace e2e-tests-downward-api-9xzpk deletion completed in 24.42612331s

• [SLOW TEST:37.461 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 28 06:03:02.765: INFO: >>> kubeConfig: /tmp/kubeconfig-994138694
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Dec 28 06:03:03.060: INFO: Waiting up to 5m0s for pod "downwardapi-volume-3c8cd7ee-0a66-11e9-8a07-628dff7095f4" in namespace "e2e-tests-downward-api-q66dx" to be "success or failure"
Dec 28 06:03:03.136: INFO: Pod "downwardapi-volume-3c8cd7ee-0a66-11e9-8a07-628dff7095f4": Phase="Pending", Reason="", readiness=false. Elapsed: 76.538747ms
Dec 28 06:03:05.145: INFO: Pod "downwardapi-volume-3c8cd7ee-0a66-11e9-8a07-628dff7095f4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.084708447s
Dec 28 06:03:07.155: INFO: Pod "downwardapi-volume-3c8cd7ee-0a66-11e9-8a07-628dff7095f4": Phase="Pending", Reason="", readiness=false. Elapsed: 4.094673943s
Dec 28 06:03:09.163: INFO: Pod "downwardapi-volume-3c8cd7ee-0a66-11e9-8a07-628dff7095f4": Phase="Pending", Reason="", readiness=false. Elapsed: 6.10263963s
Dec 28 06:03:11.169: INFO: Pod "downwardapi-volume-3c8cd7ee-0a66-11e9-8a07-628dff7095f4": Phase="Pending", Reason="", readiness=false. Elapsed: 8.10954303s
Dec 28 06:03:13.230: INFO: Pod "downwardapi-volume-3c8cd7ee-0a66-11e9-8a07-628dff7095f4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 10.17038582s
STEP: Saw pod success
Dec 28 06:03:13.230: INFO: Pod "downwardapi-volume-3c8cd7ee-0a66-11e9-8a07-628dff7095f4" satisfied condition "success or failure"
Dec 28 06:03:13.237: INFO: Trying to get logs from node 10.10.102.69-build pod downwardapi-volume-3c8cd7ee-0a66-11e9-8a07-628dff7095f4 container client-container: <nil>
STEP: delete the pod
Dec 28 06:03:13.303: INFO: Waiting for pod downwardapi-volume-3c8cd7ee-0a66-11e9-8a07-628dff7095f4 to disappear
Dec 28 06:03:13.378: INFO: Pod downwardapi-volume-3c8cd7ee-0a66-11e9-8a07-628dff7095f4 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 28 06:03:13.378: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-q66dx" for this suite.
Dec 28 06:03:19.440: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 06:03:19.760: INFO: namespace: e2e-tests-downward-api-q66dx, resource: bindings, ignored listing per whitelist
Dec 28 06:03:20.014: INFO: namespace e2e-tests-downward-api-q66dx deletion completed in 6.62150342s

• [SLOW TEST:17.249 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 28 06:03:20.014: INFO: >>> kubeConfig: /tmp/kubeconfig-994138694
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Dec 28 06:03:20.383: INFO: Creating deployment "test-recreate-deployment"
Dec 28 06:03:20.397: INFO: Waiting deployment "test-recreate-deployment" to be updated to revision 1
Dec 28 06:03:20.429: INFO: new replicaset for deployment "test-recreate-deployment" is yet to be created
Dec 28 06:03:22.443: INFO: Waiting deployment "test-recreate-deployment" to complete
Dec 28 06:03:22.450: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63681573800, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63681573800, loc:(*time.Location)(0x6c43b60)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63681573800, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63681573800, loc:(*time.Location)(0x6c43b60)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-recreate-deployment-79f694ff59\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec 28 06:03:24.474: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63681573800, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63681573800, loc:(*time.Location)(0x6c43b60)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63681573800, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63681573800, loc:(*time.Location)(0x6c43b60)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-recreate-deployment-79f694ff59\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec 28 06:03:26.591: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63681573800, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63681573800, loc:(*time.Location)(0x6c43b60)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63681573800, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63681573800, loc:(*time.Location)(0x6c43b60)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-recreate-deployment-79f694ff59\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec 28 06:03:28.524: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63681573800, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63681573800, loc:(*time.Location)(0x6c43b60)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63681573800, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63681573800, loc:(*time.Location)(0x6c43b60)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-recreate-deployment-79f694ff59\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec 28 06:03:30.458: INFO: Triggering a new rollout for deployment "test-recreate-deployment"
Dec 28 06:03:30.470: INFO: Updating deployment test-recreate-deployment
Dec 28 06:03:30.470: INFO: Watching deployment "test-recreate-deployment" to verify that new pods will not run with olds pods
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Dec 28 06:03:31.054: INFO: Deployment "test-recreate-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment,GenerateName:,Namespace:e2e-tests-deployment-czdnj,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-czdnj/deployments/test-recreate-deployment,UID:46f74279-0a66-11e9-a0ee-005056bc4922,ResourceVersion:538781,Generation:2,CreationTimestamp:2018-12-28 06:03:20 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},Strategy:DeploymentStrategy{Type:Recreate,RollingUpdate:nil,},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:0,UnavailableReplicas:1,Conditions:[{Available False 2018-12-28 06:03:30 +0000 UTC 2018-12-28 06:03:30 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.} {Progressing True 2018-12-28 06:03:31 +0000 UTC 2018-12-28 06:03:20 +0000 UTC ReplicaSetUpdated ReplicaSet "test-recreate-deployment-7cf749666b" is progressing.}],ReadyReplicas:0,CollisionCount:nil,},}

Dec 28 06:03:31.061: INFO: New ReplicaSet "test-recreate-deployment-7cf749666b" of Deployment "test-recreate-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-7cf749666b,GenerateName:,Namespace:e2e-tests-deployment-czdnj,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-czdnj/replicasets/test-recreate-deployment-7cf749666b,UID:4d276aa9-0a66-11e9-a0ee-005056bc4922,ResourceVersion:538779,Generation:1,CreationTimestamp:2018-12-28 06:03:30 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 7cf749666b,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 1,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment test-recreate-deployment 46f74279-0a66-11e9-a0ee-005056bc4922 0xc422883987 0xc422883988}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 7cf749666b,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 7cf749666b,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Dec 28 06:03:31.062: INFO: All old ReplicaSets of Deployment "test-recreate-deployment":
Dec 28 06:03:31.062: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-79f694ff59,GenerateName:,Namespace:e2e-tests-deployment-czdnj,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-czdnj/replicasets/test-recreate-deployment-79f694ff59,UID:46fdadff-0a66-11e9-a0ee-005056bc4922,ResourceVersion:538770,Generation:2,CreationTimestamp:2018-12-28 06:03:20 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 79f694ff59,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 1,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-recreate-deployment 46f74279-0a66-11e9-a0ee-005056bc4922 0xc4228838b7 0xc4228838b8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 79f694ff59,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 79f694ff59,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Dec 28 06:03:31.245: INFO: Pod "test-recreate-deployment-7cf749666b-qlqww" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-7cf749666b-qlqww,GenerateName:test-recreate-deployment-7cf749666b-,Namespace:e2e-tests-deployment-czdnj,SelfLink:/api/v1/namespaces/e2e-tests-deployment-czdnj/pods/test-recreate-deployment-7cf749666b-qlqww,UID:4d28fe85-0a66-11e9-a0ee-005056bc4922,ResourceVersion:538782,Generation:0,CreationTimestamp:2018-12-28 06:03:30 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 7cf749666b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet test-recreate-deployment-7cf749666b 4d276aa9-0a66-11e9-a0ee-005056bc4922 0xc4220b6397 0xc4220b6398}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-g6f74 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-g6f74,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-g6f74 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.10.102.69-build,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc4220b6400} {node.kubernetes.io/unreachable Exists  NoExecute 0xc4220b6420}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-12-28 06:03:31 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-12-28 06:03:31 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-12-28 06:03:31 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-12-28 06:03:30 +0000 UTC  }],Message:,Reason:,HostIP:10.10.102.69,PodIP:,StartTime:2018-12-28 06:03:31 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 28 06:03:31.246: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-czdnj" for this suite.
Dec 28 06:03:39.309: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 06:03:39.462: INFO: namespace: e2e-tests-deployment-czdnj, resource: bindings, ignored listing per whitelist
Dec 28 06:03:39.523: INFO: namespace e2e-tests-deployment-czdnj deletion completed in 8.266246206s

• [SLOW TEST:19.509 seconds]
[sig-apps] Deployment
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 28 06:03:39.524: INFO: >>> kubeConfig: /tmp/kubeconfig-994138694
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0777 on tmpfs
Dec 28 06:03:39.809: INFO: Waiting up to 5m0s for pod "pod-5275fd23-0a66-11e9-8a07-628dff7095f4" in namespace "e2e-tests-emptydir-5xmlb" to be "success or failure"
Dec 28 06:03:39.882: INFO: Pod "pod-5275fd23-0a66-11e9-8a07-628dff7095f4": Phase="Pending", Reason="", readiness=false. Elapsed: 73.325433ms
Dec 28 06:03:41.888: INFO: Pod "pod-5275fd23-0a66-11e9-8a07-628dff7095f4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.07967197s
Dec 28 06:03:43.898: INFO: Pod "pod-5275fd23-0a66-11e9-8a07-628dff7095f4": Phase="Pending", Reason="", readiness=false. Elapsed: 4.088770073s
Dec 28 06:03:45.914: INFO: Pod "pod-5275fd23-0a66-11e9-8a07-628dff7095f4": Phase="Pending", Reason="", readiness=false. Elapsed: 6.105460503s
Dec 28 06:03:47.921: INFO: Pod "pod-5275fd23-0a66-11e9-8a07-628dff7095f4": Phase="Pending", Reason="", readiness=false. Elapsed: 8.11257005s
Dec 28 06:03:50.126: INFO: Pod "pod-5275fd23-0a66-11e9-8a07-628dff7095f4": Phase="Running", Reason="", readiness=true. Elapsed: 10.317388666s
Dec 28 06:03:52.192: INFO: Pod "pod-5275fd23-0a66-11e9-8a07-628dff7095f4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 12.383182563s
STEP: Saw pod success
Dec 28 06:03:52.192: INFO: Pod "pod-5275fd23-0a66-11e9-8a07-628dff7095f4" satisfied condition "success or failure"
Dec 28 06:03:52.198: INFO: Trying to get logs from node 10.10.102.68-share pod pod-5275fd23-0a66-11e9-8a07-628dff7095f4 container test-container: <nil>
STEP: delete the pod
Dec 28 06:03:52.254: INFO: Waiting for pod pod-5275fd23-0a66-11e9-8a07-628dff7095f4 to disappear
Dec 28 06:03:52.267: INFO: Pod pod-5275fd23-0a66-11e9-8a07-628dff7095f4 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 28 06:03:52.267: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-5xmlb" for this suite.
Dec 28 06:03:58.358: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 06:03:58.549: INFO: namespace: e2e-tests-emptydir-5xmlb, resource: bindings, ignored listing per whitelist
Dec 28 06:03:58.741: INFO: namespace e2e-tests-emptydir-5xmlb deletion completed in 6.46216229s

• [SLOW TEST:19.217 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Projected 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 28 06:03:58.742: INFO: >>> kubeConfig: /tmp/kubeconfig-994138694
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-5ded1911-0a66-11e9-8a07-628dff7095f4
STEP: Creating a pod to test consume configMaps
Dec 28 06:03:59.060: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-5dee2473-0a66-11e9-8a07-628dff7095f4" in namespace "e2e-tests-projected-z7lf2" to be "success or failure"
Dec 28 06:03:59.132: INFO: Pod "pod-projected-configmaps-5dee2473-0a66-11e9-8a07-628dff7095f4": Phase="Pending", Reason="", readiness=false. Elapsed: 71.898883ms
Dec 28 06:04:01.154: INFO: Pod "pod-projected-configmaps-5dee2473-0a66-11e9-8a07-628dff7095f4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.094097407s
Dec 28 06:04:03.162: INFO: Pod "pod-projected-configmaps-5dee2473-0a66-11e9-8a07-628dff7095f4": Phase="Pending", Reason="", readiness=false. Elapsed: 4.10210363s
Dec 28 06:04:05.169: INFO: Pod "pod-projected-configmaps-5dee2473-0a66-11e9-8a07-628dff7095f4": Phase="Pending", Reason="", readiness=false. Elapsed: 6.108881773s
Dec 28 06:04:07.175: INFO: Pod "pod-projected-configmaps-5dee2473-0a66-11e9-8a07-628dff7095f4": Phase="Pending", Reason="", readiness=false. Elapsed: 8.11562351s
Dec 28 06:04:09.183: INFO: Pod "pod-projected-configmaps-5dee2473-0a66-11e9-8a07-628dff7095f4": Phase="Running", Reason="", readiness=true. Elapsed: 10.123078707s
Dec 28 06:04:11.190: INFO: Pod "pod-projected-configmaps-5dee2473-0a66-11e9-8a07-628dff7095f4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 12.13007465s
STEP: Saw pod success
Dec 28 06:04:11.190: INFO: Pod "pod-projected-configmaps-5dee2473-0a66-11e9-8a07-628dff7095f4" satisfied condition "success or failure"
Dec 28 06:04:11.195: INFO: Trying to get logs from node 10.10.102.69-build pod pod-projected-configmaps-5dee2473-0a66-11e9-8a07-628dff7095f4 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Dec 28 06:04:11.844: INFO: Waiting for pod pod-projected-configmaps-5dee2473-0a66-11e9-8a07-628dff7095f4 to disappear
Dec 28 06:04:11.853: INFO: Pod pod-projected-configmaps-5dee2473-0a66-11e9-8a07-628dff7095f4 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 28 06:04:11.853: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-z7lf2" for this suite.
Dec 28 06:04:18.025: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 06:04:18.176: INFO: namespace: e2e-tests-projected-z7lf2, resource: bindings, ignored listing per whitelist
Dec 28 06:04:18.221: INFO: namespace e2e-tests-projected-z7lf2 deletion completed in 6.357622046s

• [SLOW TEST:19.480 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 28 06:04:18.222: INFO: >>> kubeConfig: /tmp/kubeconfig-994138694
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Dec 28 06:04:29.118: INFO: Successfully updated pod "pod-update-69800392-0a66-11e9-8a07-628dff7095f4"
STEP: verifying the updated pod is in kubernetes
Dec 28 06:04:29.137: INFO: Pod update OK
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 28 06:04:29.138: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-6ztzp" for this suite.
Dec 28 06:04:53.258: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 06:04:53.513: INFO: namespace: e2e-tests-pods-6ztzp, resource: bindings, ignored listing per whitelist
Dec 28 06:04:53.513: INFO: namespace e2e-tests-pods-6ztzp deletion completed in 24.326660923s

• [SLOW TEST:35.292 seconds]
[k8s.io] Pods
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 28 06:04:53.514: INFO: >>> kubeConfig: /tmp/kubeconfig-994138694
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-7ea10aac-0a66-11e9-8a07-628dff7095f4
STEP: Creating a pod to test consume configMaps
Dec 28 06:04:53.918: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-7ea2646f-0a66-11e9-8a07-628dff7095f4" in namespace "e2e-tests-projected-jx45d" to be "success or failure"
Dec 28 06:04:53.953: INFO: Pod "pod-projected-configmaps-7ea2646f-0a66-11e9-8a07-628dff7095f4": Phase="Pending", Reason="", readiness=false. Elapsed: 34.411366ms
Dec 28 06:04:55.959: INFO: Pod "pod-projected-configmaps-7ea2646f-0a66-11e9-8a07-628dff7095f4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.04115764s
Dec 28 06:04:57.966: INFO: Pod "pod-projected-configmaps-7ea2646f-0a66-11e9-8a07-628dff7095f4": Phase="Pending", Reason="", readiness=false. Elapsed: 4.047963763s
Dec 28 06:04:59.973: INFO: Pod "pod-projected-configmaps-7ea2646f-0a66-11e9-8a07-628dff7095f4": Phase="Pending", Reason="", readiness=false. Elapsed: 6.05515133s
Dec 28 06:05:01.986: INFO: Pod "pod-projected-configmaps-7ea2646f-0a66-11e9-8a07-628dff7095f4": Phase="Pending", Reason="", readiness=false. Elapsed: 8.068152386s
Dec 28 06:05:03.993: INFO: Pod "pod-projected-configmaps-7ea2646f-0a66-11e9-8a07-628dff7095f4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 10.07449718s
STEP: Saw pod success
Dec 28 06:05:03.993: INFO: Pod "pod-projected-configmaps-7ea2646f-0a66-11e9-8a07-628dff7095f4" satisfied condition "success or failure"
Dec 28 06:05:04.001: INFO: Trying to get logs from node 10.10.102.69-build pod pod-projected-configmaps-7ea2646f-0a66-11e9-8a07-628dff7095f4 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Dec 28 06:05:04.063: INFO: Waiting for pod pod-projected-configmaps-7ea2646f-0a66-11e9-8a07-628dff7095f4 to disappear
Dec 28 06:05:04.072: INFO: Pod pod-projected-configmaps-7ea2646f-0a66-11e9-8a07-628dff7095f4 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 28 06:05:04.072: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-jx45d" for this suite.
Dec 28 06:05:10.154: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 06:05:10.359: INFO: namespace: e2e-tests-projected-jx45d, resource: bindings, ignored listing per whitelist
Dec 28 06:05:10.404: INFO: namespace e2e-tests-projected-jx45d deletion completed in 6.32022401s

• [SLOW TEST:16.890 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 28 06:05:10.405: INFO: >>> kubeConfig: /tmp/kubeconfig-994138694
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-889f6369-0a66-11e9-8a07-628dff7095f4
STEP: Creating a pod to test consume configMaps
Dec 28 06:05:10.688: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-88a05f22-0a66-11e9-8a07-628dff7095f4" in namespace "e2e-tests-projected-gzh49" to be "success or failure"
Dec 28 06:05:10.753: INFO: Pod "pod-projected-configmaps-88a05f22-0a66-11e9-8a07-628dff7095f4": Phase="Pending", Reason="", readiness=false. Elapsed: 65.668987ms
Dec 28 06:05:12.764: INFO: Pod "pod-projected-configmaps-88a05f22-0a66-11e9-8a07-628dff7095f4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.07614078s
Dec 28 06:05:14.772: INFO: Pod "pod-projected-configmaps-88a05f22-0a66-11e9-8a07-628dff7095f4": Phase="Pending", Reason="", readiness=false. Elapsed: 4.084068107s
Dec 28 06:05:16.807: INFO: Pod "pod-projected-configmaps-88a05f22-0a66-11e9-8a07-628dff7095f4": Phase="Pending", Reason="", readiness=false. Elapsed: 6.119740344s
Dec 28 06:05:18.815: INFO: Pod "pod-projected-configmaps-88a05f22-0a66-11e9-8a07-628dff7095f4": Phase="Pending", Reason="", readiness=false. Elapsed: 8.127803144s
Dec 28 06:05:20.823: INFO: Pod "pod-projected-configmaps-88a05f22-0a66-11e9-8a07-628dff7095f4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 10.13540452s
STEP: Saw pod success
Dec 28 06:05:20.823: INFO: Pod "pod-projected-configmaps-88a05f22-0a66-11e9-8a07-628dff7095f4" satisfied condition "success or failure"
Dec 28 06:05:20.828: INFO: Trying to get logs from node 10.10.102.68-share pod pod-projected-configmaps-88a05f22-0a66-11e9-8a07-628dff7095f4 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Dec 28 06:05:20.890: INFO: Waiting for pod pod-projected-configmaps-88a05f22-0a66-11e9-8a07-628dff7095f4 to disappear
Dec 28 06:05:20.948: INFO: Pod pod-projected-configmaps-88a05f22-0a66-11e9-8a07-628dff7095f4 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 28 06:05:20.948: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-gzh49" for this suite.
Dec 28 06:05:27.115: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 06:05:27.322: INFO: namespace: e2e-tests-projected-gzh49, resource: bindings, ignored listing per whitelist
Dec 28 06:05:27.496: INFO: namespace e2e-tests-projected-gzh49 deletion completed in 6.53075299s

• [SLOW TEST:17.092 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 28 06:05:27.497: INFO: >>> kubeConfig: /tmp/kubeconfig-994138694
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name cm-test-opt-del-92ccb0ce-0a66-11e9-8a07-628dff7095f4
STEP: Creating configMap with name cm-test-opt-upd-92ccb192-0a66-11e9-8a07-628dff7095f4
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-92ccb0ce-0a66-11e9-8a07-628dff7095f4
STEP: Updating configmap cm-test-opt-upd-92ccb192-0a66-11e9-8a07-628dff7095f4
STEP: Creating configMap with name cm-test-opt-create-92ccb1e7-0a66-11e9-8a07-628dff7095f4
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 28 06:07:11.097: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-lrzvk" for this suite.
Dec 28 06:07:35.138: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 06:07:35.380: INFO: namespace: e2e-tests-configmap-lrzvk, resource: bindings, ignored listing per whitelist
Dec 28 06:07:35.385: INFO: namespace e2e-tests-configmap-lrzvk deletion completed in 24.277032s

• [SLOW TEST:127.889 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-apps] ReplicationController 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 28 06:07:35.386: INFO: >>> kubeConfig: /tmp/kubeconfig-994138694
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating replication controller my-hostname-basic-df0803ea-0a66-11e9-8a07-628dff7095f4
Dec 28 06:07:35.656: INFO: Pod name my-hostname-basic-df0803ea-0a66-11e9-8a07-628dff7095f4: Found 0 pods out of 1
Dec 28 06:07:40.664: INFO: Pod name my-hostname-basic-df0803ea-0a66-11e9-8a07-628dff7095f4: Found 1 pods out of 1
Dec 28 06:07:40.664: INFO: Ensuring all pods for ReplicationController "my-hostname-basic-df0803ea-0a66-11e9-8a07-628dff7095f4" are running
Dec 28 06:07:44.677: INFO: Pod "my-hostname-basic-df0803ea-0a66-11e9-8a07-628dff7095f4-q5hdn" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2018-12-28 06:07:35 +0000 UTC Reason: Message:} {Type:Ready Status:False LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2018-12-28 06:07:35 +0000 UTC Reason:ContainersNotReady Message:containers with unready status: [my-hostname-basic-df0803ea-0a66-11e9-8a07-628dff7095f4]} {Type:ContainersReady Status:False LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2018-12-28 06:07:35 +0000 UTC Reason:ContainersNotReady Message:containers with unready status: [my-hostname-basic-df0803ea-0a66-11e9-8a07-628dff7095f4]} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2018-12-28 06:07:35 +0000 UTC Reason: Message:}])
Dec 28 06:07:44.677: INFO: Trying to dial the pod
Dec 28 06:07:49.831: INFO: Controller my-hostname-basic-df0803ea-0a66-11e9-8a07-628dff7095f4: Got expected result from replica 1 [my-hostname-basic-df0803ea-0a66-11e9-8a07-628dff7095f4-q5hdn]: "my-hostname-basic-df0803ea-0a66-11e9-8a07-628dff7095f4-q5hdn", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 28 06:07:49.831: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-replication-controller-vn5kc" for this suite.
Dec 28 06:07:55.908: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 06:07:56.082: INFO: namespace: e2e-tests-replication-controller-vn5kc, resource: bindings, ignored listing per whitelist
Dec 28 06:07:56.151: INFO: namespace e2e-tests-replication-controller-vn5kc deletion completed in 6.307322337s

• [SLOW TEST:20.766 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 28 06:07:56.152: INFO: >>> kubeConfig: /tmp/kubeconfig-994138694
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:78
Dec 28 06:07:56.378: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Dec 28 06:07:56.431: INFO: Waiting for terminating namespaces to be deleted...
Dec 28 06:07:56.436: INFO: 
Logging pods the kubelet thinks is on node 10.10.102.66-slave before test
Dec 28 06:07:56.460: INFO: webpage-66948b5fd9-7r9xb from kube-system started at 2018-12-26 05:27:31 +0000 UTC (1 container statuses recorded)
Dec 28 06:07:56.460: INFO: 	Container hc ready: true, restart count 1
Dec 28 06:07:56.460: INFO: autoscale-controller-6b595cffcd-twj7w from kube-system started at 2018-12-27 09:21:23 +0000 UTC (1 container statuses recorded)
Dec 28 06:07:56.460: INFO: 	Container autoscale-controller ready: true, restart count 1
Dec 28 06:07:56.460: INFO: heapster-84bd55cd8b-ql8kq from kube-system started at 2018-12-26 05:26:32 +0000 UTC (1 container statuses recorded)
Dec 28 06:07:56.460: INFO: 	Container heapster ready: true, restart count 1
Dec 28 06:07:56.460: INFO: cluster-controller-dddf9d5b8-d9p54 from kube-system started at 2018-12-27 09:21:23 +0000 UTC (1 container statuses recorded)
Dec 28 06:07:56.461: INFO: 	Container cluster-controller ready: true, restart count 1
Dec 28 06:07:56.461: INFO: file-upload-75b89d597b-9r4wl from kube-system started at 2018-12-27 09:21:24 +0000 UTC (1 container statuses recorded)
Dec 28 06:07:56.461: INFO: 	Container file-upload ready: true, restart count 1
Dec 28 06:07:56.461: INFO: nginx-ingress-controller-vnpqb from kube-system started at 2018-12-26 05:28:21 +0000 UTC (1 container statuses recorded)
Dec 28 06:07:56.461: INFO: 	Container nginx-ingress-lb ready: true, restart count 1
Dec 28 06:07:56.461: INFO: api-mysql-67cc46668c-bnm4p from kube-system started at 2018-12-27 09:21:23 +0000 UTC (1 container statuses recorded)
Dec 28 06:07:56.461: INFO: 	Container mysql ready: true, restart count 1
Dec 28 06:07:56.461: INFO: sonobuoy-systemd-logs-daemon-set-3ac5f2aeec8e4908-b5jj8 from heptio-sonobuoy started at 2018-12-28 04:28:42 +0000 UTC (2 container statuses recorded)
Dec 28 06:07:56.461: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 1
Dec 28 06:07:56.461: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Dec 28 06:07:56.461: INFO: oam-api-f8fb98b46-ck8zq from kube-system started at 2018-12-26 05:27:51 +0000 UTC (1 container statuses recorded)
Dec 28 06:07:56.461: INFO: 	Container oam-api ready: true, restart count 1
Dec 28 06:07:56.461: INFO: api-redis-84cb4999bb-gvcl2 from kube-system started at 2018-12-27 09:21:23 +0000 UTC (1 container statuses recorded)
Dec 28 06:07:56.461: INFO: 	Container redis ready: true, restart count 1
Dec 28 06:07:56.461: INFO: monitoring-influxdb-6fc587d568-4vbxr from kube-system started at 2018-12-26 05:27:51 +0000 UTC (2 container statuses recorded)
Dec 28 06:07:56.461: INFO: 	Container influxdb ready: true, restart count 1
Dec 28 06:07:56.461: INFO: 	Container kapacitor ready: true, restart count 1
Dec 28 06:07:56.461: INFO: calico-node-67kmt from kube-system started at 2018-12-26 05:26:29 +0000 UTC (2 container statuses recorded)
Dec 28 06:07:56.461: INFO: 	Container calico-node ready: true, restart count 1
Dec 28 06:07:56.461: INFO: 	Container install-cni ready: true, restart count 1
Dec 28 06:07:56.461: INFO: fluentd-es-v1.22-v4v7d from kube-system started at 2018-12-26 07:34:43 +0000 UTC (1 container statuses recorded)
Dec 28 06:07:56.461: INFO: 	Container fluentd-es ready: true, restart count 1
Dec 28 06:07:56.461: INFO: elasticsearch-logging-7d54c5bbd-sjrzv from kube-system started at 2018-12-26 08:22:11 +0000 UTC (1 container statuses recorded)
Dec 28 06:07:56.461: INFO: 	Container elasticsearch-logging ready: true, restart count 1
Dec 28 06:07:56.461: INFO: kube-proxy-fwznq from kube-system started at 2018-12-26 05:27:26 +0000 UTC (1 container statuses recorded)
Dec 28 06:07:56.461: INFO: 	Container kube-proxy ready: true, restart count 1
Dec 28 06:07:56.461: INFO: webapi-848b7457ff-rpm9d from kube-system started at 2018-12-26 05:27:32 +0000 UTC (1 container statuses recorded)
Dec 28 06:07:56.461: INFO: 	Container webapi ready: true, restart count 1
Dec 28 06:07:56.461: INFO: 
Logging pods the kubelet thinks is on node 10.10.102.67-slave before test
Dec 28 06:07:56.478: INFO: sonobuoy-systemd-logs-daemon-set-3ac5f2aeec8e4908-vd5rl from heptio-sonobuoy started at 2018-12-28 04:41:57 +0000 UTC (2 container statuses recorded)
Dec 28 06:07:56.478: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 1
Dec 28 06:07:56.478: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Dec 28 06:07:56.478: INFO: kube-proxy-krwtq from kube-system started at 2018-12-26 05:28:31 +0000 UTC (1 container statuses recorded)
Dec 28 06:07:56.478: INFO: 	Container kube-proxy ready: true, restart count 2
Dec 28 06:07:56.478: INFO: nginx-ingress-controller-dqpcw from kube-system started at 2018-12-26 05:28:21 +0000 UTC (1 container statuses recorded)
Dec 28 06:07:56.478: INFO: 	Container nginx-ingress-lb ready: true, restart count 2
Dec 28 06:07:56.478: INFO: elasticsearch-logging-7d54c5bbd-lggjp from kube-system started at 2018-12-27 09:56:48 +0000 UTC (1 container statuses recorded)
Dec 28 06:07:56.478: INFO: 	Container elasticsearch-logging ready: true, restart count 1
Dec 28 06:07:56.478: INFO: oam-task-75fcbc8c6f-7lk67 from kube-system started at 2018-12-27 09:56:43 +0000 UTC (1 container statuses recorded)
Dec 28 06:07:56.478: INFO: 	Container oam-task ready: true, restart count 1
Dec 28 06:07:56.478: INFO: jenkins-85bb95f67b-p598t from kube-system started at 2018-12-27 09:56:43 +0000 UTC (1 container statuses recorded)
Dec 28 06:07:56.478: INFO: 	Container jenkins ready: true, restart count 1
Dec 28 06:07:56.478: INFO: fluentd-es-v1.22-5r2gg from kube-system started at 2018-12-26 07:34:44 +0000 UTC (1 container statuses recorded)
Dec 28 06:07:56.478: INFO: 	Container fluentd-es ready: true, restart count 2
Dec 28 06:07:56.478: INFO: calico-node-8kbvn from kube-system started at 2018-12-26 05:26:28 +0000 UTC (2 container statuses recorded)
Dec 28 06:07:56.478: INFO: 	Container calico-node ready: true, restart count 2
Dec 28 06:07:56.478: INFO: 	Container install-cni ready: true, restart count 2
Dec 28 06:07:56.478: INFO: 
Logging pods the kubelet thinks is on node 10.10.102.68-share before test
Dec 28 06:07:56.493: INFO: calico-node-l9kkx from kube-system started at 2018-12-26 05:26:29 +0000 UTC (2 container statuses recorded)
Dec 28 06:07:56.493: INFO: 	Container calico-node ready: true, restart count 2
Dec 28 06:07:56.493: INFO: 	Container install-cni ready: true, restart count 2
Dec 28 06:07:56.493: INFO: sonobuoy-e2e-job-efc254e3f08a4c61 from heptio-sonobuoy started at 2018-12-28 04:28:42 +0000 UTC (2 container statuses recorded)
Dec 28 06:07:56.493: INFO: 	Container e2e ready: true, restart count 0
Dec 28 06:07:56.493: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Dec 28 06:07:56.493: INFO: kube-proxy-x6fqp from kube-system started at 2018-12-26 05:27:17 +0000 UTC (1 container statuses recorded)
Dec 28 06:07:56.493: INFO: 	Container kube-proxy ready: true, restart count 4
Dec 28 06:07:56.493: INFO: fluentd-es-v1.22-bbfwn from kube-system started at 2018-12-26 07:34:44 +0000 UTC (1 container statuses recorded)
Dec 28 06:07:56.493: INFO: 	Container fluentd-es ready: true, restart count 2
Dec 28 06:07:56.493: INFO: sonobuoy-systemd-logs-daemon-set-3ac5f2aeec8e4908-nsbv9 from heptio-sonobuoy started at 2018-12-28 04:28:42 +0000 UTC (2 container statuses recorded)
Dec 28 06:07:56.493: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 1
Dec 28 06:07:56.493: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Dec 28 06:07:56.494: INFO: default-http-backend-77958d7c8c-stdqt from kube-system started at 2018-12-26 05:26:30 +0000 UTC (1 container statuses recorded)
Dec 28 06:07:56.494: INFO: 	Container default-http-backend ready: true, restart count 2
Dec 28 06:07:56.494: INFO: coredns-664589b88-4q6kf from kube-system started at 2018-12-26 05:26:30 +0000 UTC (1 container statuses recorded)
Dec 28 06:07:56.494: INFO: 	Container coredns ready: true, restart count 2
Dec 28 06:07:56.494: INFO: 
Logging pods the kubelet thinks is on node 10.10.102.69-build before test
Dec 28 06:07:56.508: INFO: calico-kube-controllers-5dd667cc5b-48bhs from kube-system started at 2018-12-26 05:26:29 +0000 UTC (1 container statuses recorded)
Dec 28 06:07:56.508: INFO: 	Container calico-kube-controllers ready: true, restart count 3
Dec 28 06:07:56.508: INFO: fluentd-es-v1.22-swx8q from kube-system started at 2018-12-26 07:34:44 +0000 UTC (1 container statuses recorded)
Dec 28 06:07:56.508: INFO: 	Container fluentd-es ready: true, restart count 2
Dec 28 06:07:56.508: INFO: sonobuoy-systemd-logs-daemon-set-3ac5f2aeec8e4908-jxfv4 from heptio-sonobuoy started at 2018-12-28 04:28:43 +0000 UTC (2 container statuses recorded)
Dec 28 06:07:56.508: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 1
Dec 28 06:07:56.508: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Dec 28 06:07:56.508: INFO: kube-proxy-kwmsc from kube-system started at 2018-12-26 05:27:15 +0000 UTC (1 container statuses recorded)
Dec 28 06:07:56.508: INFO: 	Container kube-proxy ready: true, restart count 3
Dec 28 06:07:56.508: INFO: coredns-664589b88-tmf5k from kube-system started at 2018-12-26 05:26:32 +0000 UTC (1 container statuses recorded)
Dec 28 06:07:56.508: INFO: 	Container coredns ready: true, restart count 2
Dec 28 06:07:56.508: INFO: sonobuoy from heptio-sonobuoy started at 2018-12-28 04:28:35 +0000 UTC (1 container statuses recorded)
Dec 28 06:07:56.509: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Dec 28 06:07:56.509: INFO: calico-node-lbbsm from kube-system started at 2018-12-26 05:26:32 +0000 UTC (2 container statuses recorded)
Dec 28 06:07:56.509: INFO: 	Container calico-node ready: true, restart count 3
Dec 28 06:07:56.509: INFO: 	Container install-cni ready: true, restart count 2
[It] validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Trying to schedule Pod with nonempty NodeSelector.
STEP: Considering event: 
Type = [Warning], Name = [restricted-pod.15746a246761256a], Reason = [FailedScheduling], Message = [0/5 nodes are available: 5 node(s) didn't match node selector.]
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 28 06:07:57.566: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-sched-pred-s5cr9" for this suite.
Dec 28 06:08:03.608: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 06:08:03.787: INFO: namespace: e2e-tests-sched-pred-s5cr9, resource: bindings, ignored listing per whitelist
Dec 28 06:08:03.838: INFO: namespace e2e-tests-sched-pred-s5cr9 deletion completed in 6.263408213s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:69

• [SLOW TEST:7.687 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 28 06:08:03.839: INFO: >>> kubeConfig: /tmp/kubeconfig-994138694
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Dec 28 06:08:20.438: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Dec 28 06:08:20.446: INFO: Pod pod-with-prestop-exec-hook still exists
Dec 28 06:08:22.447: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Dec 28 06:08:22.454: INFO: Pod pod-with-prestop-exec-hook still exists
Dec 28 06:08:24.446: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Dec 28 06:08:24.453: INFO: Pod pod-with-prestop-exec-hook still exists
Dec 28 06:08:26.447: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Dec 28 06:08:26.505: INFO: Pod pod-with-prestop-exec-hook still exists
Dec 28 06:08:28.447: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Dec 28 06:08:28.454: INFO: Pod pod-with-prestop-exec-hook still exists
Dec 28 06:08:30.447: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Dec 28 06:08:30.455: INFO: Pod pod-with-prestop-exec-hook still exists
Dec 28 06:08:32.447: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Dec 28 06:08:32.454: INFO: Pod pod-with-prestop-exec-hook still exists
Dec 28 06:08:34.447: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Dec 28 06:08:34.453: INFO: Pod pod-with-prestop-exec-hook still exists
Dec 28 06:08:36.447: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Dec 28 06:08:36.453: INFO: Pod pod-with-prestop-exec-hook still exists
Dec 28 06:08:38.447: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Dec 28 06:08:38.506: INFO: Pod pod-with-prestop-exec-hook still exists
Dec 28 06:08:40.447: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Dec 28 06:08:40.455: INFO: Pod pod-with-prestop-exec-hook still exists
Dec 28 06:08:42.446: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Dec 28 06:08:42.454: INFO: Pod pod-with-prestop-exec-hook still exists
Dec 28 06:08:44.446: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Dec 28 06:08:44.453: INFO: Pod pod-with-prestop-exec-hook still exists
Dec 28 06:08:46.446: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Dec 28 06:08:46.463: INFO: Pod pod-with-prestop-exec-hook still exists
Dec 28 06:08:48.446: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Dec 28 06:08:48.453: INFO: Pod pod-with-prestop-exec-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 28 06:08:48.473: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-lifecycle-hook-t26hx" for this suite.
Dec 28 06:09:12.513: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 06:09:12.551: INFO: namespace: e2e-tests-container-lifecycle-hook-t26hx, resource: bindings, ignored listing per whitelist
Dec 28 06:09:12.787: INFO: namespace e2e-tests-container-lifecycle-hook-t26hx deletion completed in 24.302059243s

• [SLOW TEST:68.948 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when create a pod with lifecycle hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute prestop exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-api-machinery] Downward API 
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 28 06:09:12.787: INFO: >>> kubeConfig: /tmp/kubeconfig-994138694
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Dec 28 06:09:13.057: INFO: Waiting up to 5m0s for pod "downward-api-19184bfd-0a67-11e9-8a07-628dff7095f4" in namespace "e2e-tests-downward-api-7mwgr" to be "success or failure"
Dec 28 06:09:13.068: INFO: Pod "downward-api-19184bfd-0a67-11e9-8a07-628dff7095f4": Phase="Pending", Reason="", readiness=false. Elapsed: 10.78237ms
Dec 28 06:09:15.076: INFO: Pod "downward-api-19184bfd-0a67-11e9-8a07-628dff7095f4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.018285423s
Dec 28 06:09:17.084: INFO: Pod "downward-api-19184bfd-0a67-11e9-8a07-628dff7095f4": Phase="Pending", Reason="", readiness=false. Elapsed: 4.027056023s
Dec 28 06:09:19.092: INFO: Pod "downward-api-19184bfd-0a67-11e9-8a07-628dff7095f4": Phase="Pending", Reason="", readiness=false. Elapsed: 6.034637627s
Dec 28 06:09:21.119: INFO: Pod "downward-api-19184bfd-0a67-11e9-8a07-628dff7095f4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.061348167s
STEP: Saw pod success
Dec 28 06:09:21.119: INFO: Pod "downward-api-19184bfd-0a67-11e9-8a07-628dff7095f4" satisfied condition "success or failure"
Dec 28 06:09:21.126: INFO: Trying to get logs from node 10.10.102.69-build pod downward-api-19184bfd-0a67-11e9-8a07-628dff7095f4 container dapi-container: <nil>
STEP: delete the pod
Dec 28 06:09:21.604: INFO: Waiting for pod downward-api-19184bfd-0a67-11e9-8a07-628dff7095f4 to disappear
Dec 28 06:09:21.617: INFO: Pod downward-api-19184bfd-0a67-11e9-8a07-628dff7095f4 no longer exists
[AfterEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 28 06:09:21.617: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-7mwgr" for this suite.
Dec 28 06:09:27.704: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 06:09:27.792: INFO: namespace: e2e-tests-downward-api-7mwgr, resource: bindings, ignored listing per whitelist
Dec 28 06:09:27.903: INFO: namespace e2e-tests-downward-api-7mwgr deletion completed in 6.23981771s

• [SLOW TEST:15.116 seconds]
[sig-api-machinery] Downward API
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 28 06:09:27.904: INFO: >>> kubeConfig: /tmp/kubeconfig-994138694
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-22189fad-0a67-11e9-8a07-628dff7095f4
STEP: Creating a pod to test consume secrets
Dec 28 06:09:28.170: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-2219f374-0a67-11e9-8a07-628dff7095f4" in namespace "e2e-tests-projected-74qmn" to be "success or failure"
Dec 28 06:09:28.224: INFO: Pod "pod-projected-secrets-2219f374-0a67-11e9-8a07-628dff7095f4": Phase="Pending", Reason="", readiness=false. Elapsed: 53.911933ms
Dec 28 06:09:30.230: INFO: Pod "pod-projected-secrets-2219f374-0a67-11e9-8a07-628dff7095f4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.0605356s
Dec 28 06:09:32.247: INFO: Pod "pod-projected-secrets-2219f374-0a67-11e9-8a07-628dff7095f4": Phase="Pending", Reason="", readiness=false. Elapsed: 4.076977356s
Dec 28 06:09:34.302: INFO: Pod "pod-projected-secrets-2219f374-0a67-11e9-8a07-628dff7095f4": Phase="Pending", Reason="", readiness=false. Elapsed: 6.13172837s
Dec 28 06:09:36.358: INFO: Pod "pod-projected-secrets-2219f374-0a67-11e9-8a07-628dff7095f4": Phase="Running", Reason="", readiness=true. Elapsed: 8.188351016s
Dec 28 06:09:38.366: INFO: Pod "pod-projected-secrets-2219f374-0a67-11e9-8a07-628dff7095f4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 10.195683506s
STEP: Saw pod success
Dec 28 06:09:38.366: INFO: Pod "pod-projected-secrets-2219f374-0a67-11e9-8a07-628dff7095f4" satisfied condition "success or failure"
Dec 28 06:09:38.372: INFO: Trying to get logs from node 10.10.102.68-share pod pod-projected-secrets-2219f374-0a67-11e9-8a07-628dff7095f4 container projected-secret-volume-test: <nil>
STEP: delete the pod
Dec 28 06:09:38.680: INFO: Waiting for pod pod-projected-secrets-2219f374-0a67-11e9-8a07-628dff7095f4 to disappear
Dec 28 06:09:38.697: INFO: Pod pod-projected-secrets-2219f374-0a67-11e9-8a07-628dff7095f4 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 28 06:09:38.697: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-74qmn" for this suite.
Dec 28 06:09:44.768: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 06:09:45.047: INFO: namespace: e2e-tests-projected-74qmn, resource: bindings, ignored listing per whitelist
Dec 28 06:09:45.057: INFO: namespace e2e-tests-projected-74qmn deletion completed in 6.344554593s

• [SLOW TEST:17.153 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 28 06:09:45.057: INFO: >>> kubeConfig: /tmp/kubeconfig-994138694
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:98
[It] should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Dec 28 06:09:45.319: INFO: Requires at least 2 nodes (not -1)
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:64
Dec 28 06:09:45.331: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-dx49p/daemonsets","resourceVersion":"539941"},"items":null}

Dec 28 06:09:45.336: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-dx49p/pods","resourceVersion":"539941"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 28 06:09:45.417: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-dx49p" for this suite.
Dec 28 06:09:51.491: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 06:09:51.571: INFO: namespace: e2e-tests-daemonsets-dx49p, resource: bindings, ignored listing per whitelist
Dec 28 06:09:51.690: INFO: namespace e2e-tests-daemonsets-dx49p deletion completed in 6.26340083s

S [SKIPPING] [6.633 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should rollback without unnecessary restarts [Conformance] [It]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699

  Dec 28 06:09:45.319: Requires at least 2 nodes (not -1)

  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/util.go:292
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Projected 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 28 06:09:51.691: INFO: >>> kubeConfig: /tmp/kubeconfig-994138694
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name s-test-opt-del-304067d7-0a67-11e9-8a07-628dff7095f4
STEP: Creating secret with name s-test-opt-upd-30406868-0a67-11e9-8a07-628dff7095f4
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-304067d7-0a67-11e9-8a07-628dff7095f4
STEP: Updating secret s-test-opt-upd-30406868-0a67-11e9-8a07-628dff7095f4
STEP: Creating secret with name s-test-opt-create-304068a4-0a67-11e9-8a07-628dff7095f4
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 28 06:11:22.962: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-pb8mm" for this suite.
Dec 28 06:11:47.009: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 06:11:47.141: INFO: namespace: e2e-tests-projected-pb8mm, resource: bindings, ignored listing per whitelist
Dec 28 06:11:47.257: INFO: namespace e2e-tests-projected-pb8mm deletion completed in 24.28153677s

• [SLOW TEST:115.566 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-network] Services 
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 28 06:11:47.258: INFO: >>> kubeConfig: /tmp/kubeconfig-994138694
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:83
[It] should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating service multi-endpoint-test in namespace e2e-tests-services-p9bjv
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-p9bjv to expose endpoints map[]
Dec 28 06:11:47.520: INFO: Get endpoints failed (16.296007ms elapsed, ignoring for 5s): endpoints "multi-endpoint-test" not found
Dec 28 06:11:48.527: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-p9bjv exposes endpoints map[] (1.0228056s elapsed)
STEP: Creating pod pod1 in namespace e2e-tests-services-p9bjv
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-p9bjv to expose endpoints map[pod1:[100]]
Dec 28 06:11:52.743: INFO: Unexpected endpoints: found map[], expected map[pod1:[100]] (4.20543352s elapsed, will retry)
Dec 28 06:11:55.791: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-p9bjv exposes endpoints map[pod1:[100]] (7.253416923s elapsed)
STEP: Creating pod pod2 in namespace e2e-tests-services-p9bjv
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-p9bjv to expose endpoints map[pod1:[100] pod2:[101]]
Dec 28 06:11:59.968: INFO: Unexpected endpoints: found map[75d87f5f-0a67-11e9-a0ee-005056bc4922:[100]], expected map[pod1:[100] pod2:[101]] (4.164643214s elapsed, will retry)
Dec 28 06:12:03.028: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-p9bjv exposes endpoints map[pod1:[100] pod2:[101]] (7.223877304s elapsed)
STEP: Deleting pod pod1 in namespace e2e-tests-services-p9bjv
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-p9bjv to expose endpoints map[pod2:[101]]
Dec 28 06:12:04.113: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-p9bjv exposes endpoints map[pod2:[101]] (1.07577951s elapsed)
STEP: Deleting pod pod2 in namespace e2e-tests-services-p9bjv
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-p9bjv to expose endpoints map[]
Dec 28 06:12:04.185: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-p9bjv exposes endpoints map[] (46.28929ms elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 28 06:12:04.298: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-services-p9bjv" for this suite.
Dec 28 06:12:28.393: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 06:12:28.802: INFO: namespace: e2e-tests-services-p9bjv, resource: bindings, ignored listing per whitelist
Dec 28 06:12:28.802: INFO: namespace e2e-tests-services-p9bjv deletion completed in 24.450296667s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:88

• [SLOW TEST:41.544 seconds]
[sig-network] Services
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-network] Services 
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 28 06:12:28.803: INFO: >>> kubeConfig: /tmp/kubeconfig-994138694
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:83
[It] should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating service endpoint-test2 in namespace e2e-tests-services-9m8nf
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-9m8nf to expose endpoints map[]
Dec 28 06:12:29.133: INFO: Get endpoints failed (5.742286ms elapsed, ignoring for 5s): endpoints "endpoint-test2" not found
Dec 28 06:12:30.204: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-9m8nf exposes endpoints map[] (1.076778656s elapsed)
STEP: Creating pod pod1 in namespace e2e-tests-services-9m8nf
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-9m8nf to expose endpoints map[pod1:[80]]
Dec 28 06:12:34.297: INFO: Unexpected endpoints: found map[], expected map[pod1:[80]] (4.077267156s elapsed, will retry)
Dec 28 06:12:37.334: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-9m8nf exposes endpoints map[pod1:[80]] (7.115040983s elapsed)
STEP: Creating pod pod2 in namespace e2e-tests-services-9m8nf
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-9m8nf to expose endpoints map[pod2:[80] pod1:[80]]
Dec 28 06:12:41.455: INFO: Unexpected endpoints: found map[8eb043a3-0a67-11e9-a0ee-005056bc4922:[80]], expected map[pod1:[80] pod2:[80]] (4.113839847s elapsed, will retry)
Dec 28 06:12:44.506: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-9m8nf exposes endpoints map[pod1:[80] pod2:[80]] (7.165415564s elapsed)
STEP: Deleting pod pod1 in namespace e2e-tests-services-9m8nf
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-9m8nf to expose endpoints map[pod2:[80]]
Dec 28 06:12:44.557: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-9m8nf exposes endpoints map[pod2:[80]] (36.915963ms elapsed)
STEP: Deleting pod pod2 in namespace e2e-tests-services-9m8nf
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-9m8nf to expose endpoints map[]
Dec 28 06:12:45.619: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-9m8nf exposes endpoints map[] (1.014759087s elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 28 06:12:45.758: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-services-9m8nf" for this suite.
Dec 28 06:12:51.974: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 06:12:52.114: INFO: namespace: e2e-tests-services-9m8nf, resource: bindings, ignored listing per whitelist
Dec 28 06:12:52.193: INFO: namespace e2e-tests-services-9m8nf deletion completed in 6.419073673s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:88

• [SLOW TEST:23.391 seconds]
[sig-network] Services
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[k8s.io] KubeletManagedEtcHosts 
  should test kubelet managed /etc/hosts file [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 28 06:12:52.194: INFO: >>> kubeConfig: /tmp/kubeconfig-994138694
STEP: Building a namespace api object, basename e2e-kubelet-etc-hosts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should test kubelet managed /etc/hosts file [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Setting up the test
STEP: Creating hostNetwork=false pod
STEP: Creating hostNetwork=true pod
STEP: Running the test
STEP: Verifying /etc/hosts of container is kubelet-managed for pod with hostNetwork=false
Dec 28 06:13:16.631: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-rqn5h PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 28 06:13:16.631: INFO: >>> kubeConfig: /tmp/kubeconfig-994138694
Dec 28 06:13:16.830: INFO: Exec stderr: ""
Dec 28 06:13:16.830: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-rqn5h PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 28 06:13:16.830: INFO: >>> kubeConfig: /tmp/kubeconfig-994138694
Dec 28 06:13:16.995: INFO: Exec stderr: ""
Dec 28 06:13:16.995: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-rqn5h PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 28 06:13:16.996: INFO: >>> kubeConfig: /tmp/kubeconfig-994138694
Dec 28 06:13:17.324: INFO: Exec stderr: ""
Dec 28 06:13:17.324: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-rqn5h PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 28 06:13:17.324: INFO: >>> kubeConfig: /tmp/kubeconfig-994138694
Dec 28 06:13:17.507: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts of container is not kubelet-managed since container specifies /etc/hosts mount
Dec 28 06:13:17.507: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-rqn5h PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 28 06:13:17.507: INFO: >>> kubeConfig: /tmp/kubeconfig-994138694
Dec 28 06:13:17.711: INFO: Exec stderr: ""
Dec 28 06:13:17.712: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-rqn5h PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 28 06:13:17.712: INFO: >>> kubeConfig: /tmp/kubeconfig-994138694
Dec 28 06:13:17.891: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts content of container is not kubelet-managed for pod with hostNetwork=true
Dec 28 06:13:17.891: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-rqn5h PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 28 06:13:17.891: INFO: >>> kubeConfig: /tmp/kubeconfig-994138694
Dec 28 06:13:18.054: INFO: Exec stderr: ""
Dec 28 06:13:18.054: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-rqn5h PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 28 06:13:18.054: INFO: >>> kubeConfig: /tmp/kubeconfig-994138694
Dec 28 06:13:18.202: INFO: Exec stderr: ""
Dec 28 06:13:18.202: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-rqn5h PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 28 06:13:18.202: INFO: >>> kubeConfig: /tmp/kubeconfig-994138694
Dec 28 06:13:18.444: INFO: Exec stderr: ""
Dec 28 06:13:18.444: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-rqn5h PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 28 06:13:18.444: INFO: >>> kubeConfig: /tmp/kubeconfig-994138694
Dec 28 06:13:18.594: INFO: Exec stderr: ""
[AfterEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 28 06:13:18.594: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-e2e-kubelet-etc-hosts-rqn5h" for this suite.
Dec 28 06:14:02.642: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 06:14:02.746: INFO: namespace: e2e-tests-e2e-kubelet-etc-hosts-rqn5h, resource: bindings, ignored listing per whitelist
Dec 28 06:14:02.891: INFO: namespace e2e-tests-e2e-kubelet-etc-hosts-rqn5h deletion completed in 44.28204074s

• [SLOW TEST:70.698 seconds]
[k8s.io] KubeletManagedEtcHosts
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should test kubelet managed /etc/hosts file [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 28 06:14:02.892: INFO: >>> kubeConfig: /tmp/kubeconfig-994138694
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-upd-c6039e20-0a67-11e9-8a07-628dff7095f4
STEP: Creating the pod
STEP: Waiting for pod with text data
STEP: Waiting for pod with binary data
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 28 06:14:17.376: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-2w6z4" for this suite.
Dec 28 06:14:41.412: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 06:14:41.519: INFO: namespace: e2e-tests-configmap-2w6z4, resource: bindings, ignored listing per whitelist
Dec 28 06:14:41.663: INFO: namespace e2e-tests-configmap-2w6z4 deletion completed in 24.276640947s

• [SLOW TEST:38.770 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[k8s.io] Probing container 
  should have monotonically increasing restart count [Slow][NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 28 06:14:41.663: INFO: >>> kubeConfig: /tmp/kubeconfig-994138694
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should have monotonically increasing restart count [Slow][NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-http in namespace e2e-tests-container-probe-x7v67
Dec 28 06:14:54.042: INFO: Started pod liveness-http in namespace e2e-tests-container-probe-x7v67
STEP: checking the pod's current state and verifying that restartCount is present
Dec 28 06:14:54.046: INFO: Initial restart count of pod liveness-http is 0
Dec 28 06:15:10.112: INFO: Restart count of pod e2e-tests-container-probe-x7v67/liveness-http is now 1 (16.066081403s elapsed)
Dec 28 06:15:30.199: INFO: Restart count of pod e2e-tests-container-probe-x7v67/liveness-http is now 2 (36.152450657s elapsed)
Dec 28 06:15:50.283: INFO: Restart count of pod e2e-tests-container-probe-x7v67/liveness-http is now 3 (56.236403117s elapsed)
Dec 28 06:16:10.426: INFO: Restart count of pod e2e-tests-container-probe-x7v67/liveness-http is now 4 (1m16.379262657s elapsed)
Dec 28 06:17:08.790: INFO: Restart count of pod e2e-tests-container-probe-x7v67/liveness-http is now 5 (2m14.74411064s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 28 06:17:08.858: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-x7v67" for this suite.
Dec 28 06:17:16.935: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 06:17:17.137: INFO: namespace: e2e-tests-container-probe-x7v67, resource: bindings, ignored listing per whitelist
Dec 28 06:17:17.143: INFO: namespace e2e-tests-container-probe-x7v67 deletion completed in 8.26171222s

• [SLOW TEST:155.481 seconds]
[k8s.io] Probing container
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should have monotonically increasing restart count [Slow][NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[k8s.io] Pods 
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 28 06:17:17.144: INFO: >>> kubeConfig: /tmp/kubeconfig-994138694
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Dec 28 06:17:27.672: INFO: Waiting up to 5m0s for pod "client-envvars-3fd8d73a-0a68-11e9-8a07-628dff7095f4" in namespace "e2e-tests-pods-fmgqg" to be "success or failure"
Dec 28 06:17:27.681: INFO: Pod "client-envvars-3fd8d73a-0a68-11e9-8a07-628dff7095f4": Phase="Pending", Reason="", readiness=false. Elapsed: 9.622267ms
Dec 28 06:17:29.690: INFO: Pod "client-envvars-3fd8d73a-0a68-11e9-8a07-628dff7095f4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.017960907s
Dec 28 06:17:31.697: INFO: Pod "client-envvars-3fd8d73a-0a68-11e9-8a07-628dff7095f4": Phase="Pending", Reason="", readiness=false. Elapsed: 4.024948837s
Dec 28 06:17:33.704: INFO: Pod "client-envvars-3fd8d73a-0a68-11e9-8a07-628dff7095f4": Phase="Pending", Reason="", readiness=false. Elapsed: 6.032132197s
Dec 28 06:17:35.713: INFO: Pod "client-envvars-3fd8d73a-0a68-11e9-8a07-628dff7095f4": Phase="Pending", Reason="", readiness=false. Elapsed: 8.041717897s
Dec 28 06:17:37.750: INFO: Pod "client-envvars-3fd8d73a-0a68-11e9-8a07-628dff7095f4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 10.078080957s
STEP: Saw pod success
Dec 28 06:17:37.750: INFO: Pod "client-envvars-3fd8d73a-0a68-11e9-8a07-628dff7095f4" satisfied condition "success or failure"
Dec 28 06:17:37.756: INFO: Trying to get logs from node 10.10.102.69-build pod client-envvars-3fd8d73a-0a68-11e9-8a07-628dff7095f4 container env3cont: <nil>
STEP: delete the pod
Dec 28 06:17:37.953: INFO: Waiting for pod client-envvars-3fd8d73a-0a68-11e9-8a07-628dff7095f4 to disappear
Dec 28 06:17:37.978: INFO: Pod client-envvars-3fd8d73a-0a68-11e9-8a07-628dff7095f4 no longer exists
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 28 06:17:37.979: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-fmgqg" for this suite.
Dec 28 06:18:34.219: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 06:18:34.273: INFO: namespace: e2e-tests-pods-fmgqg, resource: bindings, ignored listing per whitelist
Dec 28 06:18:34.491: INFO: namespace e2e-tests-pods-fmgqg deletion completed in 56.498159026s

• [SLOW TEST:77.347 seconds]
[k8s.io] Pods
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 28 06:18:34.491: INFO: >>> kubeConfig: /tmp/kubeconfig-994138694
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Dec 28 06:18:35.028: INFO: Waiting up to 5m0s for pod "downwardapi-volume-68089eec-0a68-11e9-8a07-628dff7095f4" in namespace "e2e-tests-downward-api-z8t8q" to be "success or failure"
Dec 28 06:18:35.149: INFO: Pod "downwardapi-volume-68089eec-0a68-11e9-8a07-628dff7095f4": Phase="Pending", Reason="", readiness=false. Elapsed: 121.282843ms
Dec 28 06:18:37.157: INFO: Pod "downwardapi-volume-68089eec-0a68-11e9-8a07-628dff7095f4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.128927923s
Dec 28 06:18:39.177: INFO: Pod "downwardapi-volume-68089eec-0a68-11e9-8a07-628dff7095f4": Phase="Pending", Reason="", readiness=false. Elapsed: 4.148514263s
Dec 28 06:18:41.184: INFO: Pod "downwardapi-volume-68089eec-0a68-11e9-8a07-628dff7095f4": Phase="Pending", Reason="", readiness=false. Elapsed: 6.155497666s
Dec 28 06:18:43.192: INFO: Pod "downwardapi-volume-68089eec-0a68-11e9-8a07-628dff7095f4": Phase="Pending", Reason="", readiness=false. Elapsed: 8.16351708s
Dec 28 06:18:45.218: INFO: Pod "downwardapi-volume-68089eec-0a68-11e9-8a07-628dff7095f4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 10.18945386s
STEP: Saw pod success
Dec 28 06:18:45.218: INFO: Pod "downwardapi-volume-68089eec-0a68-11e9-8a07-628dff7095f4" satisfied condition "success or failure"
Dec 28 06:18:45.226: INFO: Trying to get logs from node 10.10.102.68-share pod downwardapi-volume-68089eec-0a68-11e9-8a07-628dff7095f4 container client-container: <nil>
STEP: delete the pod
Dec 28 06:18:45.705: INFO: Waiting for pod downwardapi-volume-68089eec-0a68-11e9-8a07-628dff7095f4 to disappear
Dec 28 06:18:45.818: INFO: Pod downwardapi-volume-68089eec-0a68-11e9-8a07-628dff7095f4 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 28 06:18:45.818: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-z8t8q" for this suite.
Dec 28 06:18:51.858: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 06:18:51.883: INFO: namespace: e2e-tests-downward-api-z8t8q, resource: bindings, ignored listing per whitelist
Dec 28 06:18:52.247: INFO: namespace e2e-tests-downward-api-z8t8q deletion completed in 6.417205647s

• [SLOW TEST:17.756 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-api-machinery] Downward API 
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 28 06:18:52.248: INFO: >>> kubeConfig: /tmp/kubeconfig-994138694
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Dec 28 06:18:52.908: INFO: Waiting up to 5m0s for pod "downward-api-72af3d67-0a68-11e9-8a07-628dff7095f4" in namespace "e2e-tests-downward-api-vgjdk" to be "success or failure"
Dec 28 06:18:52.927: INFO: Pod "downward-api-72af3d67-0a68-11e9-8a07-628dff7095f4": Phase="Pending", Reason="", readiness=false. Elapsed: 19.261433ms
Dec 28 06:18:54.934: INFO: Pod "downward-api-72af3d67-0a68-11e9-8a07-628dff7095f4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.026333016s
Dec 28 06:18:56.947: INFO: Pod "downward-api-72af3d67-0a68-11e9-8a07-628dff7095f4": Phase="Pending", Reason="", readiness=false. Elapsed: 4.03953621s
Dec 28 06:18:58.993: INFO: Pod "downward-api-72af3d67-0a68-11e9-8a07-628dff7095f4": Phase="Pending", Reason="", readiness=false. Elapsed: 6.085779656s
Dec 28 06:19:01.001: INFO: Pod "downward-api-72af3d67-0a68-11e9-8a07-628dff7095f4": Phase="Pending", Reason="", readiness=false. Elapsed: 8.093556256s
Dec 28 06:19:03.008: INFO: Pod "downward-api-72af3d67-0a68-11e9-8a07-628dff7095f4": Phase="Pending", Reason="", readiness=false. Elapsed: 10.100056606s
Dec 28 06:19:05.015: INFO: Pod "downward-api-72af3d67-0a68-11e9-8a07-628dff7095f4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 12.107323473s
STEP: Saw pod success
Dec 28 06:19:05.015: INFO: Pod "downward-api-72af3d67-0a68-11e9-8a07-628dff7095f4" satisfied condition "success or failure"
Dec 28 06:19:05.020: INFO: Trying to get logs from node 10.10.102.68-share pod downward-api-72af3d67-0a68-11e9-8a07-628dff7095f4 container dapi-container: <nil>
STEP: delete the pod
Dec 28 06:19:05.136: INFO: Waiting for pod downward-api-72af3d67-0a68-11e9-8a07-628dff7095f4 to disappear
Dec 28 06:19:05.170: INFO: Pod downward-api-72af3d67-0a68-11e9-8a07-628dff7095f4 no longer exists
[AfterEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 28 06:19:05.170: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-vgjdk" for this suite.
Dec 28 06:19:11.387: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 06:19:11.776: INFO: namespace: e2e-tests-downward-api-vgjdk, resource: bindings, ignored listing per whitelist
Dec 28 06:19:11.804: INFO: namespace e2e-tests-downward-api-vgjdk deletion completed in 6.619074987s

• [SLOW TEST:19.556 seconds]
[sig-api-machinery] Downward API
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run rc 
  should create an rc from an image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 28 06:19:11.804: INFO: >>> kubeConfig: /tmp/kubeconfig-994138694
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Kubectl run rc
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1246
[It] should create an rc from an image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Dec 28 06:19:12.203: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994138694 run e2e-test-nginx-rc --image=docker.io/library/nginx:1.14-alpine --generator=run/v1 --namespace=e2e-tests-kubectl-2lrq5'
Dec 28 06:19:14.853: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl create instead.\n"
Dec 28 06:19:14.853: INFO: stdout: "replicationcontroller/e2e-test-nginx-rc created\n"
STEP: verifying the rc e2e-test-nginx-rc was created
STEP: verifying the pod controlled by rc e2e-test-nginx-rc was created
STEP: confirm that you can get logs from an rc
Dec 28 06:19:16.899: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [e2e-test-nginx-rc-hpq5v]
Dec 28 06:19:16.899: INFO: Waiting up to 5m0s for pod "e2e-test-nginx-rc-hpq5v" in namespace "e2e-tests-kubectl-2lrq5" to be "running and ready"
Dec 28 06:19:16.904: INFO: Pod "e2e-test-nginx-rc-hpq5v": Phase="Pending", Reason="", readiness=false. Elapsed: 5.248993ms
Dec 28 06:19:18.952: INFO: Pod "e2e-test-nginx-rc-hpq5v": Phase="Pending", Reason="", readiness=false. Elapsed: 2.05279323s
Dec 28 06:19:21.069: INFO: Pod "e2e-test-nginx-rc-hpq5v": Phase="Pending", Reason="", readiness=false. Elapsed: 4.170525397s
Dec 28 06:19:23.077: INFO: Pod "e2e-test-nginx-rc-hpq5v": Phase="Pending", Reason="", readiness=false. Elapsed: 6.177961287s
Dec 28 06:19:25.084: INFO: Pod "e2e-test-nginx-rc-hpq5v": Phase="Running", Reason="", readiness=true. Elapsed: 8.184881927s
Dec 28 06:19:25.084: INFO: Pod "e2e-test-nginx-rc-hpq5v" satisfied condition "running and ready"
Dec 28 06:19:25.084: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [e2e-test-nginx-rc-hpq5v]
Dec 28 06:19:25.084: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994138694 logs rc/e2e-test-nginx-rc --namespace=e2e-tests-kubectl-2lrq5'
Dec 28 06:19:25.527: INFO: stderr: ""
Dec 28 06:19:25.527: INFO: stdout: ""
[AfterEach] [k8s.io] Kubectl run rc
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1251
Dec 28 06:19:25.527: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994138694 delete rc e2e-test-nginx-rc --namespace=e2e-tests-kubectl-2lrq5'
Dec 28 06:19:25.888: INFO: stderr: ""
Dec 28 06:19:25.888: INFO: stdout: "replicationcontroller \"e2e-test-nginx-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 28 06:19:25.888: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-2lrq5" for this suite.
Dec 28 06:19:49.949: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 06:19:50.162: INFO: namespace: e2e-tests-kubectl-2lrq5, resource: bindings, ignored listing per whitelist
Dec 28 06:19:50.207: INFO: namespace e2e-tests-kubectl-2lrq5 deletion completed in 24.308194943s

• [SLOW TEST:38.403 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run rc
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create an rc from an image  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 28 06:19:50.208: INFO: >>> kubeConfig: /tmp/kubeconfig-994138694
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:78
Dec 28 06:19:50.529: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Dec 28 06:19:50.638: INFO: Waiting for terminating namespaces to be deleted...
Dec 28 06:19:50.643: INFO: 
Logging pods the kubelet thinks is on node 10.10.102.66-slave before test
Dec 28 06:19:50.663: INFO: elasticsearch-logging-7d54c5bbd-sjrzv from kube-system started at 2018-12-26 08:22:11 +0000 UTC (1 container statuses recorded)
Dec 28 06:19:50.663: INFO: 	Container elasticsearch-logging ready: true, restart count 1
Dec 28 06:19:50.663: INFO: kube-proxy-fwznq from kube-system started at 2018-12-26 05:27:26 +0000 UTC (1 container statuses recorded)
Dec 28 06:19:50.663: INFO: 	Container kube-proxy ready: true, restart count 1
Dec 28 06:19:50.663: INFO: webapi-848b7457ff-rpm9d from kube-system started at 2018-12-26 05:27:32 +0000 UTC (1 container statuses recorded)
Dec 28 06:19:50.663: INFO: 	Container webapi ready: true, restart count 1
Dec 28 06:19:50.663: INFO: monitoring-influxdb-6fc587d568-4vbxr from kube-system started at 2018-12-26 05:27:51 +0000 UTC (2 container statuses recorded)
Dec 28 06:19:50.663: INFO: 	Container influxdb ready: true, restart count 1
Dec 28 06:19:50.663: INFO: 	Container kapacitor ready: true, restart count 1
Dec 28 06:19:50.663: INFO: calico-node-67kmt from kube-system started at 2018-12-26 05:26:29 +0000 UTC (2 container statuses recorded)
Dec 28 06:19:50.663: INFO: 	Container calico-node ready: true, restart count 1
Dec 28 06:19:50.663: INFO: 	Container install-cni ready: true, restart count 1
Dec 28 06:19:50.663: INFO: fluentd-es-v1.22-v4v7d from kube-system started at 2018-12-26 07:34:43 +0000 UTC (1 container statuses recorded)
Dec 28 06:19:50.663: INFO: 	Container fluentd-es ready: true, restart count 1
Dec 28 06:19:50.663: INFO: heapster-84bd55cd8b-ql8kq from kube-system started at 2018-12-26 05:26:32 +0000 UTC (1 container statuses recorded)
Dec 28 06:19:50.663: INFO: 	Container heapster ready: true, restart count 1
Dec 28 06:19:50.663: INFO: cluster-controller-dddf9d5b8-d9p54 from kube-system started at 2018-12-27 09:21:23 +0000 UTC (1 container statuses recorded)
Dec 28 06:19:50.663: INFO: 	Container cluster-controller ready: true, restart count 1
Dec 28 06:19:50.663: INFO: file-upload-75b89d597b-9r4wl from kube-system started at 2018-12-27 09:21:24 +0000 UTC (1 container statuses recorded)
Dec 28 06:19:50.663: INFO: 	Container file-upload ready: true, restart count 1
Dec 28 06:19:50.663: INFO: webpage-66948b5fd9-7r9xb from kube-system started at 2018-12-26 05:27:31 +0000 UTC (1 container statuses recorded)
Dec 28 06:19:50.663: INFO: 	Container hc ready: true, restart count 1
Dec 28 06:19:50.663: INFO: autoscale-controller-6b595cffcd-twj7w from kube-system started at 2018-12-27 09:21:23 +0000 UTC (1 container statuses recorded)
Dec 28 06:19:50.663: INFO: 	Container autoscale-controller ready: true, restart count 1
Dec 28 06:19:50.663: INFO: sonobuoy-systemd-logs-daemon-set-3ac5f2aeec8e4908-b5jj8 from heptio-sonobuoy started at 2018-12-28 04:28:42 +0000 UTC (2 container statuses recorded)
Dec 28 06:19:50.663: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 1
Dec 28 06:19:50.663: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Dec 28 06:19:50.663: INFO: nginx-ingress-controller-vnpqb from kube-system started at 2018-12-26 05:28:21 +0000 UTC (1 container statuses recorded)
Dec 28 06:19:50.663: INFO: 	Container nginx-ingress-lb ready: true, restart count 1
Dec 28 06:19:50.663: INFO: api-mysql-67cc46668c-bnm4p from kube-system started at 2018-12-27 09:21:23 +0000 UTC (1 container statuses recorded)
Dec 28 06:19:50.663: INFO: 	Container mysql ready: true, restart count 1
Dec 28 06:19:50.663: INFO: oam-api-f8fb98b46-ck8zq from kube-system started at 2018-12-26 05:27:51 +0000 UTC (1 container statuses recorded)
Dec 28 06:19:50.663: INFO: 	Container oam-api ready: true, restart count 1
Dec 28 06:19:50.663: INFO: api-redis-84cb4999bb-gvcl2 from kube-system started at 2018-12-27 09:21:23 +0000 UTC (1 container statuses recorded)
Dec 28 06:19:50.663: INFO: 	Container redis ready: true, restart count 1
Dec 28 06:19:50.663: INFO: 
Logging pods the kubelet thinks is on node 10.10.102.67-slave before test
Dec 28 06:19:50.682: INFO: kube-proxy-krwtq from kube-system started at 2018-12-26 05:28:31 +0000 UTC (1 container statuses recorded)
Dec 28 06:19:50.682: INFO: 	Container kube-proxy ready: true, restart count 2
Dec 28 06:19:50.682: INFO: sonobuoy-systemd-logs-daemon-set-3ac5f2aeec8e4908-vd5rl from heptio-sonobuoy started at 2018-12-28 04:41:57 +0000 UTC (2 container statuses recorded)
Dec 28 06:19:50.682: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 1
Dec 28 06:19:50.682: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Dec 28 06:19:50.682: INFO: jenkins-85bb95f67b-p598t from kube-system started at 2018-12-27 09:56:43 +0000 UTC (1 container statuses recorded)
Dec 28 06:19:50.682: INFO: 	Container jenkins ready: true, restart count 1
Dec 28 06:19:50.682: INFO: nginx-ingress-controller-dqpcw from kube-system started at 2018-12-26 05:28:21 +0000 UTC (1 container statuses recorded)
Dec 28 06:19:50.682: INFO: 	Container nginx-ingress-lb ready: true, restart count 2
Dec 28 06:19:50.682: INFO: elasticsearch-logging-7d54c5bbd-lggjp from kube-system started at 2018-12-27 09:56:48 +0000 UTC (1 container statuses recorded)
Dec 28 06:19:50.682: INFO: 	Container elasticsearch-logging ready: true, restart count 1
Dec 28 06:19:50.682: INFO: oam-task-75fcbc8c6f-7lk67 from kube-system started at 2018-12-27 09:56:43 +0000 UTC (1 container statuses recorded)
Dec 28 06:19:50.682: INFO: 	Container oam-task ready: true, restart count 1
Dec 28 06:19:50.682: INFO: fluentd-es-v1.22-5r2gg from kube-system started at 2018-12-26 07:34:44 +0000 UTC (1 container statuses recorded)
Dec 28 06:19:50.682: INFO: 	Container fluentd-es ready: true, restart count 2
Dec 28 06:19:50.682: INFO: calico-node-8kbvn from kube-system started at 2018-12-26 05:26:28 +0000 UTC (2 container statuses recorded)
Dec 28 06:19:50.682: INFO: 	Container calico-node ready: true, restart count 2
Dec 28 06:19:50.683: INFO: 	Container install-cni ready: true, restart count 2
Dec 28 06:19:50.683: INFO: 
Logging pods the kubelet thinks is on node 10.10.102.68-share before test
Dec 28 06:19:50.701: INFO: sonobuoy-e2e-job-efc254e3f08a4c61 from heptio-sonobuoy started at 2018-12-28 04:28:42 +0000 UTC (2 container statuses recorded)
Dec 28 06:19:50.701: INFO: 	Container e2e ready: true, restart count 0
Dec 28 06:19:50.701: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Dec 28 06:19:50.701: INFO: calico-node-l9kkx from kube-system started at 2018-12-26 05:26:29 +0000 UTC (2 container statuses recorded)
Dec 28 06:19:50.701: INFO: 	Container calico-node ready: true, restart count 2
Dec 28 06:19:50.701: INFO: 	Container install-cni ready: true, restart count 2
Dec 28 06:19:50.701: INFO: default-http-backend-77958d7c8c-stdqt from kube-system started at 2018-12-26 05:26:30 +0000 UTC (1 container statuses recorded)
Dec 28 06:19:50.701: INFO: 	Container default-http-backend ready: true, restart count 2
Dec 28 06:19:50.701: INFO: kube-proxy-x6fqp from kube-system started at 2018-12-26 05:27:17 +0000 UTC (1 container statuses recorded)
Dec 28 06:19:50.701: INFO: 	Container kube-proxy ready: true, restart count 4
Dec 28 06:19:50.701: INFO: fluentd-es-v1.22-bbfwn from kube-system started at 2018-12-26 07:34:44 +0000 UTC (1 container statuses recorded)
Dec 28 06:19:50.701: INFO: 	Container fluentd-es ready: true, restart count 2
Dec 28 06:19:50.701: INFO: sonobuoy-systemd-logs-daemon-set-3ac5f2aeec8e4908-nsbv9 from heptio-sonobuoy started at 2018-12-28 04:28:42 +0000 UTC (2 container statuses recorded)
Dec 28 06:19:50.701: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 1
Dec 28 06:19:50.701: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Dec 28 06:19:50.701: INFO: coredns-664589b88-4q6kf from kube-system started at 2018-12-26 05:26:30 +0000 UTC (1 container statuses recorded)
Dec 28 06:19:50.701: INFO: 	Container coredns ready: true, restart count 2
Dec 28 06:19:50.701: INFO: 
Logging pods the kubelet thinks is on node 10.10.102.69-build before test
Dec 28 06:19:50.718: INFO: sonobuoy-systemd-logs-daemon-set-3ac5f2aeec8e4908-jxfv4 from heptio-sonobuoy started at 2018-12-28 04:28:43 +0000 UTC (2 container statuses recorded)
Dec 28 06:19:50.718: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 1
Dec 28 06:19:50.718: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Dec 28 06:19:50.718: INFO: kube-proxy-kwmsc from kube-system started at 2018-12-26 05:27:15 +0000 UTC (1 container statuses recorded)
Dec 28 06:19:50.718: INFO: 	Container kube-proxy ready: true, restart count 3
Dec 28 06:19:50.718: INFO: sonobuoy from heptio-sonobuoy started at 2018-12-28 04:28:35 +0000 UTC (1 container statuses recorded)
Dec 28 06:19:50.718: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Dec 28 06:19:50.718: INFO: calico-node-lbbsm from kube-system started at 2018-12-26 05:26:32 +0000 UTC (2 container statuses recorded)
Dec 28 06:19:50.718: INFO: 	Container calico-node ready: true, restart count 3
Dec 28 06:19:50.718: INFO: 	Container install-cni ready: true, restart count 2
Dec 28 06:19:50.718: INFO: coredns-664589b88-tmf5k from kube-system started at 2018-12-26 05:26:32 +0000 UTC (1 container statuses recorded)
Dec 28 06:19:50.718: INFO: 	Container coredns ready: true, restart count 2
Dec 28 06:19:50.718: INFO: fluentd-es-v1.22-swx8q from kube-system started at 2018-12-26 07:34:44 +0000 UTC (1 container statuses recorded)
Dec 28 06:19:50.718: INFO: 	Container fluentd-es ready: true, restart count 2
Dec 28 06:19:50.718: INFO: calico-kube-controllers-5dd667cc5b-48bhs from kube-system started at 2018-12-26 05:26:29 +0000 UTC (1 container statuses recorded)
Dec 28 06:19:50.718: INFO: 	Container calico-kube-controllers ready: true, restart count 3
[It] validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: verifying the node has the label node 10.10.102.66-slave
STEP: verifying the node has the label node 10.10.102.67-slave
STEP: verifying the node has the label node 10.10.102.68-share
STEP: verifying the node has the label node 10.10.102.69-build
Dec 28 06:19:51.009: INFO: Pod sonobuoy requesting resource cpu=0m on Node 10.10.102.69-build
Dec 28 06:19:51.009: INFO: Pod sonobuoy-e2e-job-efc254e3f08a4c61 requesting resource cpu=0m on Node 10.10.102.68-share
Dec 28 06:19:51.009: INFO: Pod sonobuoy-systemd-logs-daemon-set-3ac5f2aeec8e4908-b5jj8 requesting resource cpu=0m on Node 10.10.102.66-slave
Dec 28 06:19:51.009: INFO: Pod sonobuoy-systemd-logs-daemon-set-3ac5f2aeec8e4908-jxfv4 requesting resource cpu=0m on Node 10.10.102.69-build
Dec 28 06:19:51.009: INFO: Pod sonobuoy-systemd-logs-daemon-set-3ac5f2aeec8e4908-nsbv9 requesting resource cpu=0m on Node 10.10.102.68-share
Dec 28 06:19:51.009: INFO: Pod sonobuoy-systemd-logs-daemon-set-3ac5f2aeec8e4908-vd5rl requesting resource cpu=0m on Node 10.10.102.67-slave
Dec 28 06:19:51.009: INFO: Pod api-mysql-67cc46668c-bnm4p requesting resource cpu=200m on Node 10.10.102.66-slave
Dec 28 06:19:51.009: INFO: Pod api-redis-84cb4999bb-gvcl2 requesting resource cpu=100m on Node 10.10.102.66-slave
Dec 28 06:19:51.009: INFO: Pod autoscale-controller-6b595cffcd-twj7w requesting resource cpu=0m on Node 10.10.102.66-slave
Dec 28 06:19:51.009: INFO: Pod calico-kube-controllers-5dd667cc5b-48bhs requesting resource cpu=0m on Node 10.10.102.69-build
Dec 28 06:19:51.009: INFO: Pod calico-node-67kmt requesting resource cpu=250m on Node 10.10.102.66-slave
Dec 28 06:19:51.009: INFO: Pod calico-node-8kbvn requesting resource cpu=250m on Node 10.10.102.67-slave
Dec 28 06:19:51.009: INFO: Pod calico-node-l9kkx requesting resource cpu=250m on Node 10.10.102.68-share
Dec 28 06:19:51.009: INFO: Pod calico-node-lbbsm requesting resource cpu=250m on Node 10.10.102.69-build
Dec 28 06:19:51.009: INFO: Pod cluster-controller-dddf9d5b8-d9p54 requesting resource cpu=0m on Node 10.10.102.66-slave
Dec 28 06:19:51.009: INFO: Pod coredns-664589b88-4q6kf requesting resource cpu=100m on Node 10.10.102.68-share
Dec 28 06:19:51.009: INFO: Pod coredns-664589b88-tmf5k requesting resource cpu=100m on Node 10.10.102.69-build
Dec 28 06:19:51.009: INFO: Pod default-http-backend-77958d7c8c-stdqt requesting resource cpu=10m on Node 10.10.102.68-share
Dec 28 06:19:51.009: INFO: Pod elasticsearch-logging-7d54c5bbd-lggjp requesting resource cpu=1000m on Node 10.10.102.67-slave
Dec 28 06:19:51.009: INFO: Pod elasticsearch-logging-7d54c5bbd-sjrzv requesting resource cpu=1000m on Node 10.10.102.66-slave
Dec 28 06:19:51.009: INFO: Pod file-upload-75b89d597b-9r4wl requesting resource cpu=100m on Node 10.10.102.66-slave
Dec 28 06:19:51.009: INFO: Pod fluentd-es-v1.22-5r2gg requesting resource cpu=200m on Node 10.10.102.67-slave
Dec 28 06:19:51.009: INFO: Pod fluentd-es-v1.22-bbfwn requesting resource cpu=200m on Node 10.10.102.68-share
Dec 28 06:19:51.009: INFO: Pod fluentd-es-v1.22-swx8q requesting resource cpu=200m on Node 10.10.102.69-build
Dec 28 06:19:51.009: INFO: Pod fluentd-es-v1.22-v4v7d requesting resource cpu=200m on Node 10.10.102.66-slave
Dec 28 06:19:51.009: INFO: Pod heapster-84bd55cd8b-ql8kq requesting resource cpu=100m on Node 10.10.102.66-slave
Dec 28 06:19:51.009: INFO: Pod jenkins-85bb95f67b-p598t requesting resource cpu=500m on Node 10.10.102.67-slave
Dec 28 06:19:51.009: INFO: Pod kube-proxy-fwznq requesting resource cpu=0m on Node 10.10.102.66-slave
Dec 28 06:19:51.009: INFO: Pod kube-proxy-krwtq requesting resource cpu=0m on Node 10.10.102.67-slave
Dec 28 06:19:51.009: INFO: Pod kube-proxy-kwmsc requesting resource cpu=0m on Node 10.10.102.69-build
Dec 28 06:19:51.009: INFO: Pod kube-proxy-x6fqp requesting resource cpu=0m on Node 10.10.102.68-share
Dec 28 06:19:51.009: INFO: Pod monitoring-influxdb-6fc587d568-4vbxr requesting resource cpu=500m on Node 10.10.102.66-slave
Dec 28 06:19:51.009: INFO: Pod nginx-ingress-controller-dqpcw requesting resource cpu=0m on Node 10.10.102.67-slave
Dec 28 06:19:51.009: INFO: Pod nginx-ingress-controller-vnpqb requesting resource cpu=0m on Node 10.10.102.66-slave
Dec 28 06:19:51.009: INFO: Pod oam-api-f8fb98b46-ck8zq requesting resource cpu=200m on Node 10.10.102.66-slave
Dec 28 06:19:51.009: INFO: Pod oam-task-75fcbc8c6f-7lk67 requesting resource cpu=200m on Node 10.10.102.67-slave
Dec 28 06:19:51.009: INFO: Pod webapi-848b7457ff-rpm9d requesting resource cpu=500m on Node 10.10.102.66-slave
Dec 28 06:19:51.009: INFO: Pod webpage-66948b5fd9-7r9xb requesting resource cpu=500m on Node 10.10.102.66-slave
STEP: Starting Pods to consume most of the cluster CPU.
STEP: Creating another pod that requires unavailable amount of CPU.
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-955a1fae-0a68-11e9-8a07-628dff7095f4.15746acac5da3105], Reason = [Scheduled], Message = [Successfully assigned e2e-tests-sched-pred-9fwlb/filler-pod-955a1fae-0a68-11e9-8a07-628dff7095f4 to 10.10.102.66-slave]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-955a1fae-0a68-11e9-8a07-628dff7095f4.15746acc3c46bdb9], Reason = [Pulling], Message = [pulling image "k8s.gcr.io/pause:3.1"]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-955a1fae-0a68-11e9-8a07-628dff7095f4.15746acd6bd54b5a], Reason = [Pulled], Message = [Successfully pulled image "k8s.gcr.io/pause:3.1"]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-955a1fae-0a68-11e9-8a07-628dff7095f4.15746ace22d749de], Reason = [Created], Message = [Created container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-955a1fae-0a68-11e9-8a07-628dff7095f4.15746ace4f8a4e93], Reason = [Started], Message = [Started container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-955c950e-0a68-11e9-8a07-628dff7095f4.15746acac746f156], Reason = [Scheduled], Message = [Successfully assigned e2e-tests-sched-pred-9fwlb/filler-pod-955c950e-0a68-11e9-8a07-628dff7095f4 to 10.10.102.67-slave]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-955c950e-0a68-11e9-8a07-628dff7095f4.15746b854348b79f], Reason = [Pulling], Message = [pulling image "k8s.gcr.io/pause:3.1"]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-955c950e-0a68-11e9-8a07-628dff7095f4.15746b86791ea2f1], Reason = [Pulled], Message = [Successfully pulled image "k8s.gcr.io/pause:3.1"]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-955c950e-0a68-11e9-8a07-628dff7095f4.15746b8726228b46], Reason = [Created], Message = [Created container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-955c950e-0a68-11e9-8a07-628dff7095f4.15746b8756faa976], Reason = [Started], Message = [Started container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-956a9469-0a68-11e9-8a07-628dff7095f4.15746acad1317aca], Reason = [Scheduled], Message = [Successfully assigned e2e-tests-sched-pred-9fwlb/filler-pod-956a9469-0a68-11e9-8a07-628dff7095f4 to 10.10.102.68-share]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-956a9469-0a68-11e9-8a07-628dff7095f4.15746acc5ca67642], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-956a9469-0a68-11e9-8a07-628dff7095f4.15746acd203276b0], Reason = [Created], Message = [Created container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-956a9469-0a68-11e9-8a07-628dff7095f4.15746acd70a0ef4c], Reason = [Started], Message = [Started container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-956cfac0-0a68-11e9-8a07-628dff7095f4.15746acad455c591], Reason = [Scheduled], Message = [Successfully assigned e2e-tests-sched-pred-9fwlb/filler-pod-956cfac0-0a68-11e9-8a07-628dff7095f4 to 10.10.102.69-build]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-956cfac0-0a68-11e9-8a07-628dff7095f4.15746acc8ef8af57], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-956cfac0-0a68-11e9-8a07-628dff7095f4.15746acd5aecdd3e], Reason = [Created], Message = [Created container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-956cfac0-0a68-11e9-8a07-628dff7095f4.15746acd962d1691], Reason = [Started], Message = [Started container]
STEP: Considering event: 
Type = [Warning], Name = [additional-pod.15746ace922ce925], Reason = [FailedScheduling], Message = [0/5 nodes are available: 1 node(s) had taints that the pod didn't tolerate, 4 Insufficient cpu.]
STEP: removing the label node off the node 10.10.102.66-slave
STEP: verifying the node doesn't have the label node
STEP: removing the label node off the node 10.10.102.67-slave
STEP: verifying the node doesn't have the label node
STEP: removing the label node off the node 10.10.102.68-share
STEP: verifying the node doesn't have the label node
STEP: removing the label node off the node 10.10.102.69-build
STEP: verifying the node doesn't have the label node
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 28 06:20:08.792: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-sched-pred-9fwlb" for this suite.
Dec 28 06:20:16.949: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 06:20:17.514: INFO: namespace: e2e-tests-sched-pred-9fwlb, resource: bindings, ignored listing per whitelist
Dec 28 06:20:17.803: INFO: namespace e2e-tests-sched-pred-9fwlb deletion completed in 9.000058747s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:69

• [SLOW TEST:27.596 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 28 06:20:17.804: INFO: >>> kubeConfig: /tmp/kubeconfig-994138694
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Dec 28 06:20:18.227: INFO: Waiting up to 5m0s for pod "downwardapi-volume-a58a011c-0a68-11e9-8a07-628dff7095f4" in namespace "e2e-tests-projected-f894g" to be "success or failure"
Dec 28 06:20:18.296: INFO: Pod "downwardapi-volume-a58a011c-0a68-11e9-8a07-628dff7095f4": Phase="Pending", Reason="", readiness=false. Elapsed: 68.05615ms
Dec 28 06:20:20.354: INFO: Pod "downwardapi-volume-a58a011c-0a68-11e9-8a07-628dff7095f4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.126641713s
Dec 28 06:20:22.362: INFO: Pod "downwardapi-volume-a58a011c-0a68-11e9-8a07-628dff7095f4": Phase="Pending", Reason="", readiness=false. Elapsed: 4.13422467s
Dec 28 06:20:24.369: INFO: Pod "downwardapi-volume-a58a011c-0a68-11e9-8a07-628dff7095f4": Phase="Pending", Reason="", readiness=false. Elapsed: 6.14136197s
Dec 28 06:20:26.422: INFO: Pod "downwardapi-volume-a58a011c-0a68-11e9-8a07-628dff7095f4": Phase="Pending", Reason="", readiness=false. Elapsed: 8.194579187s
Dec 28 06:20:28.445: INFO: Pod "downwardapi-volume-a58a011c-0a68-11e9-8a07-628dff7095f4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 10.21746107s
STEP: Saw pod success
Dec 28 06:20:28.445: INFO: Pod "downwardapi-volume-a58a011c-0a68-11e9-8a07-628dff7095f4" satisfied condition "success or failure"
Dec 28 06:20:28.452: INFO: Trying to get logs from node 10.10.102.69-build pod downwardapi-volume-a58a011c-0a68-11e9-8a07-628dff7095f4 container client-container: <nil>
STEP: delete the pod
Dec 28 06:20:29.075: INFO: Waiting for pod downwardapi-volume-a58a011c-0a68-11e9-8a07-628dff7095f4 to disappear
Dec 28 06:20:29.096: INFO: Pod downwardapi-volume-a58a011c-0a68-11e9-8a07-628dff7095f4 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 28 06:20:29.097: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-f894g" for this suite.
Dec 28 06:20:35.146: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 06:20:35.262: INFO: namespace: e2e-tests-projected-f894g, resource: bindings, ignored listing per whitelist
Dec 28 06:20:35.415: INFO: namespace e2e-tests-projected-f894g deletion completed in 6.307251164s

• [SLOW TEST:17.611 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] HostPath 
  should give a volume the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 28 06:20:35.416: INFO: >>> kubeConfig: /tmp/kubeconfig-994138694
STEP: Building a namespace api object, basename hostpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:37
[It] should give a volume the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test hostPath mode
Dec 28 06:20:35.662: INFO: Waiting up to 5m0s for pod "pod-host-path-test" in namespace "e2e-tests-hostpath-svl2j" to be "success or failure"
Dec 28 06:20:35.688: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 25.936263ms
Dec 28 06:20:37.697: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 2.034906943s
Dec 28 06:20:39.724: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 4.061560177s
Dec 28 06:20:41.733: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 6.070138117s
Dec 28 06:20:43.739: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 8.077092893s
Dec 28 06:20:45.747: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 10.085027187s
Dec 28 06:20:47.756: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 12.093289297s
Dec 28 06:20:49.813: INFO: Pod "pod-host-path-test": Phase="Succeeded", Reason="", readiness=false. Elapsed: 14.150309943s
STEP: Saw pod success
Dec 28 06:20:49.813: INFO: Pod "pod-host-path-test" satisfied condition "success or failure"
Dec 28 06:20:49.818: INFO: Trying to get logs from node 10.10.102.68-share pod pod-host-path-test container test-container-1: <nil>
STEP: delete the pod
Dec 28 06:20:49.913: INFO: Waiting for pod pod-host-path-test to disappear
Dec 28 06:20:50.031: INFO: Pod pod-host-path-test no longer exists
[AfterEach] [sig-storage] HostPath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 28 06:20:50.031: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-hostpath-svl2j" for this suite.
Dec 28 06:20:58.131: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 06:20:58.188: INFO: namespace: e2e-tests-hostpath-svl2j, resource: bindings, ignored listing per whitelist
Dec 28 06:20:58.355: INFO: namespace e2e-tests-hostpath-svl2j deletion completed in 8.282393696s

• [SLOW TEST:22.940 seconds]
[sig-storage] HostPath
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:34
  should give a volume the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 28 06:20:58.356: INFO: >>> kubeConfig: /tmp/kubeconfig-994138694
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-bdad5216-0a68-11e9-8a07-628dff7095f4
STEP: Creating a pod to test consume secrets
Dec 28 06:20:58.767: INFO: Waiting up to 5m0s for pod "pod-secrets-bdb196fe-0a68-11e9-8a07-628dff7095f4" in namespace "e2e-tests-secrets-k4dfq" to be "success or failure"
Dec 28 06:20:58.794: INFO: Pod "pod-secrets-bdb196fe-0a68-11e9-8a07-628dff7095f4": Phase="Pending", Reason="", readiness=false. Elapsed: 27.054703ms
Dec 28 06:21:00.819: INFO: Pod "pod-secrets-bdb196fe-0a68-11e9-8a07-628dff7095f4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.051790086s
Dec 28 06:21:02.847: INFO: Pod "pod-secrets-bdb196fe-0a68-11e9-8a07-628dff7095f4": Phase="Pending", Reason="", readiness=false. Elapsed: 4.08046919s
Dec 28 06:21:04.854: INFO: Pod "pod-secrets-bdb196fe-0a68-11e9-8a07-628dff7095f4": Phase="Pending", Reason="", readiness=false. Elapsed: 6.086935323s
Dec 28 06:21:06.871: INFO: Pod "pod-secrets-bdb196fe-0a68-11e9-8a07-628dff7095f4": Phase="Pending", Reason="", readiness=false. Elapsed: 8.104483733s
Dec 28 06:21:08.880: INFO: Pod "pod-secrets-bdb196fe-0a68-11e9-8a07-628dff7095f4": Phase="Running", Reason="", readiness=true. Elapsed: 10.11340656s
Dec 28 06:21:11.013: INFO: Pod "pod-secrets-bdb196fe-0a68-11e9-8a07-628dff7095f4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 12.246210473s
STEP: Saw pod success
Dec 28 06:21:11.013: INFO: Pod "pod-secrets-bdb196fe-0a68-11e9-8a07-628dff7095f4" satisfied condition "success or failure"
Dec 28 06:21:11.020: INFO: Trying to get logs from node 10.10.102.69-build pod pod-secrets-bdb196fe-0a68-11e9-8a07-628dff7095f4 container secret-volume-test: <nil>
STEP: delete the pod
Dec 28 06:21:11.177: INFO: Waiting for pod pod-secrets-bdb196fe-0a68-11e9-8a07-628dff7095f4 to disappear
Dec 28 06:21:11.296: INFO: Pod pod-secrets-bdb196fe-0a68-11e9-8a07-628dff7095f4 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 28 06:21:11.297: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-k4dfq" for this suite.
Dec 28 06:21:19.499: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 06:21:19.566: INFO: namespace: e2e-tests-secrets-k4dfq, resource: bindings, ignored listing per whitelist
Dec 28 06:21:19.831: INFO: namespace e2e-tests-secrets-k4dfq deletion completed in 8.52251556s

• [SLOW TEST:21.476 seconds]
[sig-storage] Secrets
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run --rm job 
  should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 28 06:21:19.832: INFO: >>> kubeConfig: /tmp/kubeconfig-994138694
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: executing a command with run --rm and attach with stdin
Dec 28 06:21:20.131: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994138694 --namespace=e2e-tests-kubectl-458wg run e2e-test-rm-busybox-job --image=docker.io/library/busybox:1.29 --rm=true --generator=job/v1 --restart=OnFailure --attach=true --stdin -- sh -c cat && echo 'stdin closed''
Dec 28 06:21:30.879: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl create instead.\nIf you don't see a command prompt, try pressing enter.\n"
Dec 28 06:21:30.879: INFO: stdout: "abcd1234stdin closed\njob.batch \"e2e-test-rm-busybox-job\" deleted\n"
STEP: verifying the job e2e-test-rm-busybox-job was deleted
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 28 06:21:32.891: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-458wg" for this suite.
Dec 28 06:21:38.988: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 06:21:39.205: INFO: namespace: e2e-tests-kubectl-458wg, resource: bindings, ignored listing per whitelist
Dec 28 06:21:39.229: INFO: namespace e2e-tests-kubectl-458wg deletion completed in 6.326623214s

• [SLOW TEST:19.397 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run --rm job
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create a job from an image, then delete the job  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 28 06:21:39.230: INFO: >>> kubeConfig: /tmp/kubeconfig-994138694
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Dec 28 06:21:59.733: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Dec 28 06:21:59.746: INFO: Pod pod-with-poststart-http-hook still exists
Dec 28 06:22:01.746: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Dec 28 06:22:01.754: INFO: Pod pod-with-poststart-http-hook still exists
Dec 28 06:22:03.746: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Dec 28 06:22:03.754: INFO: Pod pod-with-poststart-http-hook still exists
Dec 28 06:22:05.746: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Dec 28 06:22:05.754: INFO: Pod pod-with-poststart-http-hook still exists
Dec 28 06:22:07.746: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Dec 28 06:22:07.754: INFO: Pod pod-with-poststart-http-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 28 06:22:07.754: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-lifecycle-hook-6p248" for this suite.
Dec 28 06:22:31.797: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 06:22:32.330: INFO: namespace: e2e-tests-container-lifecycle-hook-6p248, resource: bindings, ignored listing per whitelist
Dec 28 06:22:32.330: INFO: namespace e2e-tests-container-lifecycle-hook-6p248 deletion completed in 24.56414607s

• [SLOW TEST:53.101 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when create a pod with lifecycle hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute poststart http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run default 
  should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 28 06:22:32.331: INFO: >>> kubeConfig: /tmp/kubeconfig-994138694
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Kubectl run default
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1210
[It] should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Dec 28 06:22:33.042: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994138694 run e2e-test-nginx-deployment --image=docker.io/library/nginx:1.14-alpine --namespace=e2e-tests-kubectl-w2n24'
Dec 28 06:22:33.358: INFO: stderr: "kubectl run --generator=deployment/apps.v1beta1 is DEPRECATED and will be removed in a future version. Use kubectl create instead.\n"
Dec 28 06:22:33.359: INFO: stdout: "deployment.apps/e2e-test-nginx-deployment created\n"
STEP: verifying the pod controlled by e2e-test-nginx-deployment gets created
[AfterEach] [k8s.io] Kubectl run default
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1216
Dec 28 06:22:35.379: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994138694 delete deployment e2e-test-nginx-deployment --namespace=e2e-tests-kubectl-w2n24'
Dec 28 06:22:35.766: INFO: stderr: ""
Dec 28 06:22:35.766: INFO: stdout: "deployment.extensions \"e2e-test-nginx-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 28 06:22:35.766: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-w2n24" for this suite.
Dec 28 06:22:41.923: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 06:22:42.130: INFO: namespace: e2e-tests-kubectl-w2n24, resource: bindings, ignored listing per whitelist
Dec 28 06:22:42.291: INFO: namespace e2e-tests-kubectl-w2n24 deletion completed in 6.481432124s

• [SLOW TEST:9.961 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run default
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create an rc or deployment from an image  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 28 06:22:42.292: INFO: >>> kubeConfig: /tmp/kubeconfig-994138694
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0644 on node default medium
Dec 28 06:22:42.644: INFO: Waiting up to 5m0s for pod "pod-fba58eb8-0a68-11e9-8a07-628dff7095f4" in namespace "e2e-tests-emptydir-64zc5" to be "success or failure"
Dec 28 06:22:42.754: INFO: Pod "pod-fba58eb8-0a68-11e9-8a07-628dff7095f4": Phase="Pending", Reason="", readiness=false. Elapsed: 109.98946ms
Dec 28 06:22:44.762: INFO: Pod "pod-fba58eb8-0a68-11e9-8a07-628dff7095f4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.11796888s
Dec 28 06:22:46.769: INFO: Pod "pod-fba58eb8-0a68-11e9-8a07-628dff7095f4": Phase="Pending", Reason="", readiness=false. Elapsed: 4.125611747s
Dec 28 06:22:48.839: INFO: Pod "pod-fba58eb8-0a68-11e9-8a07-628dff7095f4": Phase="Pending", Reason="", readiness=false. Elapsed: 6.195086304s
Dec 28 06:22:50.847: INFO: Pod "pod-fba58eb8-0a68-11e9-8a07-628dff7095f4": Phase="Pending", Reason="", readiness=false. Elapsed: 8.203083744s
Dec 28 06:22:52.919: INFO: Pod "pod-fba58eb8-0a68-11e9-8a07-628dff7095f4": Phase="Pending", Reason="", readiness=false. Elapsed: 10.275063327s
Dec 28 06:22:54.926: INFO: Pod "pod-fba58eb8-0a68-11e9-8a07-628dff7095f4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 12.282458114s
STEP: Saw pod success
Dec 28 06:22:54.926: INFO: Pod "pod-fba58eb8-0a68-11e9-8a07-628dff7095f4" satisfied condition "success or failure"
Dec 28 06:22:54.932: INFO: Trying to get logs from node 10.10.102.68-share pod pod-fba58eb8-0a68-11e9-8a07-628dff7095f4 container test-container: <nil>
STEP: delete the pod
Dec 28 06:22:55.020: INFO: Waiting for pod pod-fba58eb8-0a68-11e9-8a07-628dff7095f4 to disappear
Dec 28 06:22:55.057: INFO: Pod pod-fba58eb8-0a68-11e9-8a07-628dff7095f4 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 28 06:22:55.057: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-64zc5" for this suite.
Dec 28 06:23:03.110: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 06:23:03.189: INFO: namespace: e2e-tests-emptydir-64zc5, resource: bindings, ignored listing per whitelist
Dec 28 06:23:03.384: INFO: namespace e2e-tests-emptydir-64zc5 deletion completed in 8.312968723s

• [SLOW TEST:21.092 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[k8s.io] [sig-node] PreStop 
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 28 06:23:03.385: INFO: >>> kubeConfig: /tmp/kubeconfig-994138694
STEP: Building a namespace api object, basename prestop
STEP: Waiting for a default service account to be provisioned in namespace
[It] should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating server pod server in namespace e2e-tests-prestop-gxklq
STEP: Waiting for pods to come up.
STEP: Creating tester pod tester in namespace e2e-tests-prestop-gxklq
STEP: Deleting pre-stop pod
Dec 28 06:23:28.758: INFO: Saw: {
	"Hostname": "server",
	"Sent": null,
	"Received": {
		"prestop": 1
	},
	"Errors": null,
	"Log": [
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up."
	],
	"StillContactingPeers": true
}
STEP: Deleting the server pod
[AfterEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 28 06:23:28.774: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-prestop-gxklq" for this suite.
Dec 28 06:24:08.970: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 06:24:09.022: INFO: namespace: e2e-tests-prestop-gxklq, resource: bindings, ignored listing per whitelist
Dec 28 06:24:09.183: INFO: namespace e2e-tests-prestop-gxklq deletion completed in 40.39397217s

• [SLOW TEST:65.798 seconds]
[k8s.io] [sig-node] PreStop
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run job 
  should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 28 06:24:09.183: INFO: >>> kubeConfig: /tmp/kubeconfig-994138694
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Kubectl run job
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1402
[It] should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Dec 28 06:24:09.478: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994138694 run e2e-test-nginx-job --restart=OnFailure --generator=job/v1 --image=docker.io/library/nginx:1.14-alpine --namespace=e2e-tests-kubectl-ccxfd'
Dec 28 06:24:09.814: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl create instead.\n"
Dec 28 06:24:09.814: INFO: stdout: "job.batch/e2e-test-nginx-job created\n"
STEP: verifying the job e2e-test-nginx-job was created
[AfterEach] [k8s.io] Kubectl run job
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1407
Dec 28 06:24:09.857: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994138694 delete jobs e2e-test-nginx-job --namespace=e2e-tests-kubectl-ccxfd'
Dec 28 06:24:10.189: INFO: stderr: ""
Dec 28 06:24:10.190: INFO: stdout: "job.batch \"e2e-test-nginx-job\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 28 06:24:10.190: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-ccxfd" for this suite.
Dec 28 06:24:34.298: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 06:24:34.449: INFO: namespace: e2e-tests-kubectl-ccxfd, resource: bindings, ignored listing per whitelist
Dec 28 06:24:34.557: INFO: namespace e2e-tests-kubectl-ccxfd deletion completed in 24.354337743s

• [SLOW TEST:25.374 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run job
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create a job from an image when restart is OnFailure  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with projected pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 28 06:24:34.557: INFO: >>> kubeConfig: /tmp/kubeconfig-994138694
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with projected pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-projected-2fls
STEP: Creating a pod to test atomic-volume-subpath
Dec 28 06:24:34.940: INFO: Waiting up to 5m0s for pod "pod-subpath-test-projected-2fls" in namespace "e2e-tests-subpath-lq2w2" to be "success or failure"
Dec 28 06:24:34.948: INFO: Pod "pod-subpath-test-projected-2fls": Phase="Pending", Reason="", readiness=false. Elapsed: 8.376543ms
Dec 28 06:24:36.957: INFO: Pod "pod-subpath-test-projected-2fls": Phase="Pending", Reason="", readiness=false. Elapsed: 2.017265053s
Dec 28 06:24:38.964: INFO: Pod "pod-subpath-test-projected-2fls": Phase="Pending", Reason="", readiness=false. Elapsed: 4.024289243s
Dec 28 06:24:40.972: INFO: Pod "pod-subpath-test-projected-2fls": Phase="Pending", Reason="", readiness=false. Elapsed: 6.03215967s
Dec 28 06:24:42.982: INFO: Pod "pod-subpath-test-projected-2fls": Phase="Pending", Reason="", readiness=false. Elapsed: 8.041726853s
Dec 28 06:24:44.990: INFO: Pod "pod-subpath-test-projected-2fls": Phase="Pending", Reason="", readiness=false. Elapsed: 10.050039213s
Dec 28 06:24:46.998: INFO: Pod "pod-subpath-test-projected-2fls": Phase="Pending", Reason="", readiness=false. Elapsed: 12.057863006s
Dec 28 06:24:49.007: INFO: Pod "pod-subpath-test-projected-2fls": Phase="Pending", Reason="", readiness=false. Elapsed: 14.06664883s
Dec 28 06:24:51.015: INFO: Pod "pod-subpath-test-projected-2fls": Phase="Pending", Reason="", readiness=false. Elapsed: 16.074760603s
Dec 28 06:24:53.023: INFO: Pod "pod-subpath-test-projected-2fls": Phase="Pending", Reason="", readiness=false. Elapsed: 18.08279239s
Dec 28 06:24:55.030: INFO: Pod "pod-subpath-test-projected-2fls": Phase="Running", Reason="", readiness=false. Elapsed: 20.090384333s
Dec 28 06:24:57.038: INFO: Pod "pod-subpath-test-projected-2fls": Phase="Running", Reason="", readiness=false. Elapsed: 22.098375063s
Dec 28 06:24:59.047: INFO: Pod "pod-subpath-test-projected-2fls": Phase="Running", Reason="", readiness=false. Elapsed: 24.10715798s
Dec 28 06:25:01.055: INFO: Pod "pod-subpath-test-projected-2fls": Phase="Running", Reason="", readiness=false. Elapsed: 26.11542786s
Dec 28 06:25:03.063: INFO: Pod "pod-subpath-test-projected-2fls": Phase="Running", Reason="", readiness=false. Elapsed: 28.123207293s
Dec 28 06:25:05.070: INFO: Pod "pod-subpath-test-projected-2fls": Phase="Running", Reason="", readiness=false. Elapsed: 30.130261743s
Dec 28 06:25:07.079: INFO: Pod "pod-subpath-test-projected-2fls": Phase="Running", Reason="", readiness=false. Elapsed: 32.139099443s
Dec 28 06:25:09.115: INFO: Pod "pod-subpath-test-projected-2fls": Phase="Running", Reason="", readiness=false. Elapsed: 34.175203253s
Dec 28 06:25:11.124: INFO: Pod "pod-subpath-test-projected-2fls": Phase="Succeeded", Reason="", readiness=false. Elapsed: 36.183733433s
STEP: Saw pod success
Dec 28 06:25:11.124: INFO: Pod "pod-subpath-test-projected-2fls" satisfied condition "success or failure"
Dec 28 06:25:11.131: INFO: Trying to get logs from node 10.10.102.68-share pod pod-subpath-test-projected-2fls container test-container-subpath-projected-2fls: <nil>
STEP: delete the pod
Dec 28 06:25:11.206: INFO: Waiting for pod pod-subpath-test-projected-2fls to disappear
Dec 28 06:25:11.222: INFO: Pod pod-subpath-test-projected-2fls no longer exists
STEP: Deleting pod pod-subpath-test-projected-2fls
Dec 28 06:25:11.222: INFO: Deleting pod "pod-subpath-test-projected-2fls" in namespace "e2e-tests-subpath-lq2w2"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 28 06:25:11.228: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-lq2w2" for this suite.
Dec 28 06:25:19.324: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 06:25:19.457: INFO: namespace: e2e-tests-subpath-lq2w2, resource: bindings, ignored listing per whitelist
Dec 28 06:25:19.536: INFO: namespace e2e-tests-subpath-lq2w2 deletion completed in 8.297453677s

• [SLOW TEST:44.978 seconds]
[sig-storage] Subpath
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with projected pod [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-network] Service endpoints latency 
  should not be very high  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 28 06:25:19.536: INFO: >>> kubeConfig: /tmp/kubeconfig-994138694
STEP: Building a namespace api object, basename svc-latency
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be very high  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating replication controller svc-latency-rc in namespace e2e-tests-svc-latency-pjrlx
I1228 06:25:19.934699      14 runners.go:180] Created replication controller with name: svc-latency-rc, namespace: e2e-tests-svc-latency-pjrlx, replica count: 1
I1228 06:25:20.985685      14 runners.go:180] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1228 06:25:21.986166      14 runners.go:180] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1228 06:25:22.986564      14 runners.go:180] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1228 06:25:23.987092      14 runners.go:180] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1228 06:25:24.987499      14 runners.go:180] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1228 06:25:25.988073      14 runners.go:180] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1228 06:25:26.989006      14 runners.go:180] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1228 06:25:27.989457      14 runners.go:180] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1228 06:25:28.998137      14 runners.go:180] svc-latency-rc Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Dec 28 06:25:29.236: INFO: Created: latency-svc-g9sxq
Dec 28 06:25:29.337: INFO: Got endpoints: latency-svc-g9sxq [239.14105ms]
Dec 28 06:25:29.527: INFO: Created: latency-svc-fgbb5
Dec 28 06:25:29.539: INFO: Got endpoints: latency-svc-fgbb5 [200.476593ms]
Dec 28 06:25:29.801: INFO: Created: latency-svc-852mn
Dec 28 06:25:29.827: INFO: Got endpoints: latency-svc-852mn [489.703607ms]
Dec 28 06:25:29.868: INFO: Created: latency-svc-hjv4l
Dec 28 06:25:29.874: INFO: Got endpoints: latency-svc-hjv4l [535.17575ms]
Dec 28 06:25:29.976: INFO: Created: latency-svc-mslfj
Dec 28 06:25:29.989: INFO: Got endpoints: latency-svc-mslfj [650.091606ms]
Dec 28 06:25:30.075: INFO: Created: latency-svc-5x5rc
Dec 28 06:25:30.158: INFO: Got endpoints: latency-svc-5x5rc [818.904563ms]
Dec 28 06:25:30.214: INFO: Created: latency-svc-wqgp2
Dec 28 06:25:30.264: INFO: Got endpoints: latency-svc-wqgp2 [924.447187ms]
Dec 28 06:25:30.578: INFO: Created: latency-svc-qdwcm
Dec 28 06:25:30.608: INFO: Got endpoints: latency-svc-qdwcm [1.268999467s]
Dec 28 06:25:30.863: INFO: Created: latency-svc-lkbll
Dec 28 06:25:30.876: INFO: Got endpoints: latency-svc-lkbll [1.536842133s]
Dec 28 06:25:30.954: INFO: Created: latency-svc-wj2bl
Dec 28 06:25:31.116: INFO: Got endpoints: latency-svc-wj2bl [1.776664383s]
Dec 28 06:25:31.202: INFO: Created: latency-svc-rz2cb
Dec 28 06:25:31.281: INFO: Got endpoints: latency-svc-rz2cb [1.940922987s]
Dec 28 06:25:31.372: INFO: Created: latency-svc-dbg4h
Dec 28 06:25:31.449: INFO: Got endpoints: latency-svc-dbg4h [2.108957944s]
Dec 28 06:25:31.524: INFO: Created: latency-svc-zfbwv
Dec 28 06:25:31.685: INFO: Got endpoints: latency-svc-zfbwv [2.34505887s]
Dec 28 06:25:31.701: INFO: Created: latency-svc-qcz7w
Dec 28 06:25:31.727: INFO: Got endpoints: latency-svc-qcz7w [2.38698397s]
Dec 28 06:25:31.777: INFO: Created: latency-svc-f6d9d
Dec 28 06:25:31.891: INFO: Got endpoints: latency-svc-f6d9d [2.550977573s]
Dec 28 06:25:31.918: INFO: Created: latency-svc-q5fhz
Dec 28 06:25:31.960: INFO: Got endpoints: latency-svc-q5fhz [2.61962876s]
Dec 28 06:25:32.162: INFO: Created: latency-svc-q2r76
Dec 28 06:25:32.167: INFO: Got endpoints: latency-svc-q2r76 [2.628375017s]
Dec 28 06:25:32.228: INFO: Created: latency-svc-l2qgg
Dec 28 06:25:32.359: INFO: Got endpoints: latency-svc-l2qgg [2.53139398s]
Dec 28 06:25:32.387: INFO: Created: latency-svc-ld5ps
Dec 28 06:25:32.410: INFO: Got endpoints: latency-svc-ld5ps [2.536132607s]
Dec 28 06:25:32.679: INFO: Created: latency-svc-wr9r8
Dec 28 06:25:32.685: INFO: Got endpoints: latency-svc-wr9r8 [2.695132193s]
Dec 28 06:25:32.769: INFO: Created: latency-svc-m69zz
Dec 28 06:25:32.885: INFO: Got endpoints: latency-svc-m69zz [2.727297073s]
Dec 28 06:25:32.897: INFO: Created: latency-svc-rs2vj
Dec 28 06:25:32.919: INFO: Got endpoints: latency-svc-rs2vj [2.655088956s]
Dec 28 06:25:33.087: INFO: Created: latency-svc-b8b8m
Dec 28 06:25:33.092: INFO: Got endpoints: latency-svc-b8b8m [2.48387545s]
Dec 28 06:25:33.153: INFO: Created: latency-svc-br4x5
Dec 28 06:25:33.175: INFO: Got endpoints: latency-svc-br4x5 [2.298073087s]
Dec 28 06:25:33.310: INFO: Created: latency-svc-7tkch
Dec 28 06:25:33.321: INFO: Got endpoints: latency-svc-7tkch [2.20418938s]
Dec 28 06:25:33.380: INFO: Created: latency-svc-nv8xm
Dec 28 06:25:33.395: INFO: Got endpoints: latency-svc-nv8xm [2.114499466s]
Dec 28 06:25:33.522: INFO: Created: latency-svc-9lvqk
Dec 28 06:25:33.545: INFO: Got endpoints: latency-svc-9lvqk [2.096626563s]
Dec 28 06:25:33.589: INFO: Created: latency-svc-vtgxk
Dec 28 06:25:33.603: INFO: Got endpoints: latency-svc-vtgxk [1.917189543s]
Dec 28 06:25:33.837: INFO: Created: latency-svc-hfdx6
Dec 28 06:25:33.862: INFO: Got endpoints: latency-svc-hfdx6 [2.13429029s]
Dec 28 06:25:33.899: INFO: Created: latency-svc-g7g5p
Dec 28 06:25:33.923: INFO: Got endpoints: latency-svc-g7g5p [2.031362203s]
Dec 28 06:25:34.084: INFO: Created: latency-svc-fflrq
Dec 28 06:25:34.087: INFO: Got endpoints: latency-svc-fflrq [2.12636116s]
Dec 28 06:25:34.159: INFO: Created: latency-svc-7nfs6
Dec 28 06:25:34.161: INFO: Got endpoints: latency-svc-7nfs6 [1.99381018s]
Dec 28 06:25:34.234: INFO: Created: latency-svc-xvjst
Dec 28 06:25:34.275: INFO: Got endpoints: latency-svc-xvjst [1.916318223s]
Dec 28 06:25:34.509: INFO: Created: latency-svc-qtwnj
Dec 28 06:25:34.519: INFO: Got endpoints: latency-svc-qtwnj [2.10824586s]
Dec 28 06:25:34.656: INFO: Created: latency-svc-5mjjc
Dec 28 06:25:34.665: INFO: Got endpoints: latency-svc-5mjjc [1.98081559s]
Dec 28 06:25:34.746: INFO: Created: latency-svc-jl5wp
Dec 28 06:25:34.852: INFO: Got endpoints: latency-svc-jl5wp [1.96625696s]
Dec 28 06:25:34.866: INFO: Created: latency-svc-x4p44
Dec 28 06:25:34.920: INFO: Got endpoints: latency-svc-x4p44 [1.999951346s]
Dec 28 06:25:35.059: INFO: Created: latency-svc-vmr2m
Dec 28 06:25:35.072: INFO: Got endpoints: latency-svc-vmr2m [1.978948724s]
Dec 28 06:25:35.249: INFO: Created: latency-svc-mhl2b
Dec 28 06:25:35.256: INFO: Got endpoints: latency-svc-mhl2b [2.081132497s]
Dec 28 06:25:35.419: INFO: Created: latency-svc-9r7f8
Dec 28 06:25:35.434: INFO: Got endpoints: latency-svc-9r7f8 [2.11359262s]
Dec 28 06:25:35.625: INFO: Created: latency-svc-cz6tl
Dec 28 06:25:35.683: INFO: Got endpoints: latency-svc-cz6tl [2.287015113s]
Dec 28 06:25:35.684: INFO: Created: latency-svc-ln9kx
Dec 28 06:25:35.699: INFO: Got endpoints: latency-svc-ln9kx [2.153902717s]
Dec 28 06:25:35.874: INFO: Created: latency-svc-5z4rk
Dec 28 06:25:35.886: INFO: Got endpoints: latency-svc-5z4rk [2.28313177s]
Dec 28 06:25:36.047: INFO: Created: latency-svc-nl5ct
Dec 28 06:25:36.067: INFO: Got endpoints: latency-svc-nl5ct [2.20514533s]
Dec 28 06:25:36.136: INFO: Created: latency-svc-6g247
Dec 28 06:25:36.302: INFO: Got endpoints: latency-svc-6g247 [2.37899735s]
Dec 28 06:25:36.320: INFO: Created: latency-svc-c98q7
Dec 28 06:25:36.379: INFO: Got endpoints: latency-svc-c98q7 [2.292079726s]
Dec 28 06:25:36.492: INFO: Created: latency-svc-fwz2w
Dec 28 06:25:36.506: INFO: Got endpoints: latency-svc-fwz2w [2.345134837s]
Dec 28 06:25:36.664: INFO: Created: latency-svc-9pbxq
Dec 28 06:25:36.673: INFO: Got endpoints: latency-svc-9pbxq [2.397661333s]
Dec 28 06:25:36.719: INFO: Created: latency-svc-2svpz
Dec 28 06:25:36.735: INFO: Got endpoints: latency-svc-2svpz [2.215817256s]
Dec 28 06:25:36.830: INFO: Created: latency-svc-4kdwb
Dec 28 06:25:36.843: INFO: Got endpoints: latency-svc-4kdwb [2.177085197s]
Dec 28 06:25:36.890: INFO: Created: latency-svc-8d6rc
Dec 28 06:25:36.906: INFO: Got endpoints: latency-svc-8d6rc [2.054201646s]
Dec 28 06:25:37.032: INFO: Created: latency-svc-n9zfl
Dec 28 06:25:37.048: INFO: Got endpoints: latency-svc-n9zfl [2.128467667s]
Dec 28 06:25:37.126: INFO: Created: latency-svc-zvp8t
Dec 28 06:25:37.194: INFO: Got endpoints: latency-svc-zvp8t [2.12200335s]
Dec 28 06:25:37.205: INFO: Created: latency-svc-5xsnz
Dec 28 06:25:37.229: INFO: Got endpoints: latency-svc-5xsnz [1.973209257s]
Dec 28 06:25:37.406: INFO: Created: latency-svc-q5t2t
Dec 28 06:25:37.424: INFO: Got endpoints: latency-svc-q5t2t [1.98914368s]
Dec 28 06:25:37.494: INFO: Created: latency-svc-bxzg6
Dec 28 06:25:37.622: INFO: Got endpoints: latency-svc-bxzg6 [1.939571814s]
Dec 28 06:25:37.646: INFO: Created: latency-svc-zk2k4
Dec 28 06:25:37.665: INFO: Got endpoints: latency-svc-zk2k4 [1.965838337s]
Dec 28 06:25:37.835: INFO: Created: latency-svc-qchnk
Dec 28 06:25:37.837: INFO: Got endpoints: latency-svc-qchnk [1.951555806s]
Dec 28 06:25:38.031: INFO: Created: latency-svc-d8lxb
Dec 28 06:25:38.048: INFO: Got endpoints: latency-svc-d8lxb [1.98122252s]
Dec 28 06:25:38.192: INFO: Created: latency-svc-jntx2
Dec 28 06:25:38.202: INFO: Got endpoints: latency-svc-jntx2 [1.900020866s]
Dec 28 06:25:38.351: INFO: Created: latency-svc-6rrx2
Dec 28 06:25:38.366: INFO: Got endpoints: latency-svc-6rrx2 [1.987404816s]
Dec 28 06:25:38.522: INFO: Created: latency-svc-7x2mh
Dec 28 06:25:38.530: INFO: Got endpoints: latency-svc-7x2mh [2.023889787s]
Dec 28 06:25:38.615: INFO: Created: latency-svc-q4zj5
Dec 28 06:25:38.670: INFO: Got endpoints: latency-svc-q4zj5 [1.996225373s]
Dec 28 06:25:38.713: INFO: Created: latency-svc-bbt75
Dec 28 06:25:38.743: INFO: Got endpoints: latency-svc-bbt75 [2.00864923s]
Dec 28 06:25:38.859: INFO: Created: latency-svc-v6mbt
Dec 28 06:25:38.870: INFO: Got endpoints: latency-svc-v6mbt [2.026999857s]
Dec 28 06:25:38.937: INFO: Created: latency-svc-rsv2q
Dec 28 06:25:39.072: INFO: Got endpoints: latency-svc-rsv2q [2.165537827s]
Dec 28 06:25:39.086: INFO: Created: latency-svc-9wxjf
Dec 28 06:25:39.104: INFO: Got endpoints: latency-svc-9wxjf [2.055499913s]
Dec 28 06:25:39.289: INFO: Created: latency-svc-kjjdr
Dec 28 06:25:39.305: INFO: Got endpoints: latency-svc-kjjdr [2.11111549s]
Dec 28 06:25:39.380: INFO: Created: latency-svc-gcq5j
Dec 28 06:25:39.524: INFO: Got endpoints: latency-svc-gcq5j [2.29459504s]
Dec 28 06:25:39.585: INFO: Created: latency-svc-tbmhp
Dec 28 06:25:39.835: INFO: Got endpoints: latency-svc-tbmhp [2.41103011s]
Dec 28 06:25:39.855: INFO: Created: latency-svc-6f8hr
Dec 28 06:25:39.867: INFO: Got endpoints: latency-svc-6f8hr [2.244962994s]
Dec 28 06:25:39.931: INFO: Created: latency-svc-nswk6
Dec 28 06:25:40.071: INFO: Got endpoints: latency-svc-nswk6 [2.405937873s]
Dec 28 06:25:40.084: INFO: Created: latency-svc-qslj9
Dec 28 06:25:40.111: INFO: Got endpoints: latency-svc-qslj9 [2.27342169s]
Dec 28 06:25:40.328: INFO: Created: latency-svc-zsf82
Dec 28 06:25:40.400: INFO: Got endpoints: latency-svc-zsf82 [2.351033774s]
Dec 28 06:25:40.557: INFO: Created: latency-svc-qbwq2
Dec 28 06:25:40.600: INFO: Got endpoints: latency-svc-qbwq2 [2.39791311s]
Dec 28 06:25:40.646: INFO: Created: latency-svc-9wksx
Dec 28 06:25:40.773: INFO: Got endpoints: latency-svc-9wksx [2.406114423s]
Dec 28 06:25:40.792: INFO: Created: latency-svc-tcwl9
Dec 28 06:25:40.819: INFO: Got endpoints: latency-svc-tcwl9 [2.28846828s]
Dec 28 06:25:40.959: INFO: Created: latency-svc-tgkfl
Dec 28 06:25:40.977: INFO: Got endpoints: latency-svc-tgkfl [2.30781462s]
Dec 28 06:25:41.214: INFO: Created: latency-svc-4bgxb
Dec 28 06:25:41.245: INFO: Got endpoints: latency-svc-4bgxb [2.501075124s]
Dec 28 06:25:41.282: INFO: Created: latency-svc-rg9g7
Dec 28 06:25:41.417: INFO: Got endpoints: latency-svc-rg9g7 [2.54712057s]
Dec 28 06:25:41.431: INFO: Created: latency-svc-vq6pv
Dec 28 06:25:41.445: INFO: Got endpoints: latency-svc-vq6pv [2.373602394s]
Dec 28 06:25:41.722: INFO: Created: latency-svc-sf5mb
Dec 28 06:25:41.734: INFO: Got endpoints: latency-svc-sf5mb [2.630534147s]
Dec 28 06:25:41.962: INFO: Created: latency-svc-2fbc5
Dec 28 06:25:42.139: INFO: Got endpoints: latency-svc-2fbc5 [2.83384204s]
Dec 28 06:25:42.171: INFO: Created: latency-svc-g8tsz
Dec 28 06:25:42.187: INFO: Got endpoints: latency-svc-g8tsz [2.66332587s]
Dec 28 06:25:42.362: INFO: Created: latency-svc-hkjhr
Dec 28 06:25:42.383: INFO: Got endpoints: latency-svc-hkjhr [2.548597553s]
Dec 28 06:25:42.587: INFO: Created: latency-svc-9djj4
Dec 28 06:25:42.600: INFO: Got endpoints: latency-svc-9djj4 [2.73238756s]
Dec 28 06:25:42.742: INFO: Created: latency-svc-pwbtn
Dec 28 06:25:42.759: INFO: Got endpoints: latency-svc-pwbtn [2.687840517s]
Dec 28 06:25:42.918: INFO: Created: latency-svc-btl26
Dec 28 06:25:42.937: INFO: Got endpoints: latency-svc-btl26 [2.82629291s]
Dec 28 06:25:43.167: INFO: Created: latency-svc-2pdjx
Dec 28 06:25:43.214: INFO: Got endpoints: latency-svc-2pdjx [2.813839897s]
Dec 28 06:25:43.369: INFO: Created: latency-svc-vkjjx
Dec 28 06:25:43.447: INFO: Got endpoints: latency-svc-vkjjx [2.846563946s]
Dec 28 06:25:43.524: INFO: Created: latency-svc-gqqv8
Dec 28 06:25:43.535: INFO: Got endpoints: latency-svc-gqqv8 [2.761907114s]
Dec 28 06:25:43.728: INFO: Created: latency-svc-554j6
Dec 28 06:25:43.735: INFO: Got endpoints: latency-svc-554j6 [2.91559198s]
Dec 28 06:25:43.894: INFO: Created: latency-svc-dp85x
Dec 28 06:25:43.901: INFO: Got endpoints: latency-svc-dp85x [2.923714343s]
Dec 28 06:25:43.986: INFO: Created: latency-svc-s4n9r
Dec 28 06:25:44.067: INFO: Got endpoints: latency-svc-s4n9r [2.82279957s]
Dec 28 06:25:44.081: INFO: Created: latency-svc-d6t8m
Dec 28 06:25:44.142: INFO: Got endpoints: latency-svc-d6t8m [2.72477094s]
Dec 28 06:25:44.300: INFO: Created: latency-svc-bzlzp
Dec 28 06:25:44.306: INFO: Got endpoints: latency-svc-bzlzp [2.860156483s]
Dec 28 06:25:44.544: INFO: Created: latency-svc-96nhm
Dec 28 06:25:44.544: INFO: Got endpoints: latency-svc-96nhm [2.809622807s]
Dec 28 06:25:44.734: INFO: Created: latency-svc-5ffpz
Dec 28 06:25:44.768: INFO: Got endpoints: latency-svc-5ffpz [2.628865147s]
Dec 28 06:25:44.959: INFO: Created: latency-svc-x84mb
Dec 28 06:25:44.977: INFO: Got endpoints: latency-svc-x84mb [2.789257144s]
Dec 28 06:25:45.176: INFO: Created: latency-svc-gdr8s
Dec 28 06:25:45.199: INFO: Got endpoints: latency-svc-gdr8s [2.81580192s]
Dec 28 06:25:45.483: INFO: Created: latency-svc-pzmcc
Dec 28 06:25:45.532: INFO: Got endpoints: latency-svc-pzmcc [2.932319513s]
Dec 28 06:25:45.577: INFO: Created: latency-svc-2nxcm
Dec 28 06:25:45.644: INFO: Got endpoints: latency-svc-2nxcm [2.884869644s]
Dec 28 06:25:45.709: INFO: Created: latency-svc-bh98x
Dec 28 06:25:45.720: INFO: Got endpoints: latency-svc-bh98x [2.782327524s]
Dec 28 06:25:45.873: INFO: Created: latency-svc-4htpm
Dec 28 06:25:45.890: INFO: Got endpoints: latency-svc-4htpm [2.67591978s]
Dec 28 06:25:46.113: INFO: Created: latency-svc-ph4kv
Dec 28 06:25:46.124: INFO: Got endpoints: latency-svc-ph4kv [2.677766516s]
Dec 28 06:25:46.273: INFO: Created: latency-svc-bk2jh
Dec 28 06:25:46.289: INFO: Got endpoints: latency-svc-bk2jh [2.754108656s]
Dec 28 06:25:46.343: INFO: Created: latency-svc-lct22
Dec 28 06:25:46.352: INFO: Got endpoints: latency-svc-lct22 [2.616948176s]
Dec 28 06:25:46.526: INFO: Created: latency-svc-9s6bs
Dec 28 06:25:46.537: INFO: Got endpoints: latency-svc-9s6bs [2.63548442s]
Dec 28 06:25:46.597: INFO: Created: latency-svc-f7w5t
Dec 28 06:25:46.605: INFO: Got endpoints: latency-svc-f7w5t [2.537312444s]
Dec 28 06:25:46.722: INFO: Created: latency-svc-4xr54
Dec 28 06:25:46.723: INFO: Got endpoints: latency-svc-4xr54 [2.580696357s]
Dec 28 06:25:46.952: INFO: Created: latency-svc-k9dc4
Dec 28 06:25:46.952: INFO: Created: latency-svc-tdnft
Dec 28 06:25:46.962: INFO: Got endpoints: latency-svc-tdnft [2.417824153s]
Dec 28 06:25:46.962: INFO: Got endpoints: latency-svc-k9dc4 [2.656453517s]
Dec 28 06:25:47.147: INFO: Created: latency-svc-628rq
Dec 28 06:25:47.147: INFO: Got endpoints: latency-svc-628rq [2.379642144s]
Dec 28 06:25:47.224: INFO: Created: latency-svc-tt8q4
Dec 28 06:25:47.322: INFO: Got endpoints: latency-svc-tt8q4 [2.34573044s]
Dec 28 06:25:47.385: INFO: Created: latency-svc-bp6jn
Dec 28 06:25:47.501: INFO: Got endpoints: latency-svc-bp6jn [2.301076617s]
Dec 28 06:25:47.582: INFO: Created: latency-svc-szlh9
Dec 28 06:25:47.688: INFO: Got endpoints: latency-svc-szlh9 [2.155708987s]
Dec 28 06:25:47.919: INFO: Created: latency-svc-5vfch
Dec 28 06:25:47.941: INFO: Got endpoints: latency-svc-5vfch [2.296049677s]
Dec 28 06:25:48.112: INFO: Created: latency-svc-9d6sk
Dec 28 06:25:48.150: INFO: Got endpoints: latency-svc-9d6sk [2.429496557s]
Dec 28 06:25:48.379: INFO: Created: latency-svc-8n6c8
Dec 28 06:25:48.380: INFO: Got endpoints: latency-svc-8n6c8 [2.48983125s]
Dec 28 06:25:48.516: INFO: Created: latency-svc-p7djd
Dec 28 06:25:48.583: INFO: Got endpoints: latency-svc-p7djd [2.458910477s]
Dec 28 06:25:48.718: INFO: Created: latency-svc-mhjf8
Dec 28 06:25:48.734: INFO: Got endpoints: latency-svc-mhjf8 [2.444706317s]
Dec 28 06:25:48.957: INFO: Created: latency-svc-vq2kh
Dec 28 06:25:48.971: INFO: Got endpoints: latency-svc-vq2kh [2.618692817s]
Dec 28 06:25:49.156: INFO: Created: latency-svc-65xxm
Dec 28 06:25:49.185: INFO: Got endpoints: latency-svc-65xxm [2.647002096s]
Dec 28 06:25:49.364: INFO: Created: latency-svc-mf5wq
Dec 28 06:25:49.377: INFO: Got endpoints: latency-svc-mf5wq [2.772576257s]
Dec 28 06:25:49.447: INFO: Created: latency-svc-4xm8z
Dec 28 06:25:49.463: INFO: Got endpoints: latency-svc-4xm8z [2.73987747s]
Dec 28 06:25:49.598: INFO: Created: latency-svc-cwvr5
Dec 28 06:25:49.628: INFO: Got endpoints: latency-svc-cwvr5 [2.66620028s]
Dec 28 06:25:49.765: INFO: Created: latency-svc-mjfz7
Dec 28 06:25:49.848: INFO: Created: latency-svc-nxmqx
Dec 28 06:25:49.857: INFO: Got endpoints: latency-svc-mjfz7 [2.89481417s]
Dec 28 06:25:49.957: INFO: Got endpoints: latency-svc-nxmqx [2.809265926s]
Dec 28 06:25:49.969: INFO: Created: latency-svc-zx2qh
Dec 28 06:25:50.000: INFO: Got endpoints: latency-svc-zx2qh [2.677389137s]
Dec 28 06:25:50.269: INFO: Created: latency-svc-bkvgf
Dec 28 06:25:50.346: INFO: Got endpoints: latency-svc-bkvgf [2.84561282s]
Dec 28 06:25:50.402: INFO: Created: latency-svc-lsq45
Dec 28 06:25:50.402: INFO: Got endpoints: latency-svc-lsq45 [2.714134834s]
Dec 28 06:25:50.625: INFO: Created: latency-svc-zwb8t
Dec 28 06:25:50.642: INFO: Got endpoints: latency-svc-zwb8t [2.701489507s]
Dec 28 06:25:50.764: INFO: Created: latency-svc-zg27d
Dec 28 06:25:50.794: INFO: Got endpoints: latency-svc-zg27d [2.644555997s]
Dec 28 06:25:50.918: INFO: Created: latency-svc-wwj7j
Dec 28 06:25:50.928: INFO: Got endpoints: latency-svc-wwj7j [2.548091426s]
Dec 28 06:25:51.004: INFO: Created: latency-svc-26j4v
Dec 28 06:25:51.123: INFO: Got endpoints: latency-svc-26j4v [2.539283506s]
Dec 28 06:25:51.184: INFO: Created: latency-svc-hm9nx
Dec 28 06:25:51.202: INFO: Got endpoints: latency-svc-hm9nx [2.468560507s]
Dec 28 06:25:51.367: INFO: Created: latency-svc-gzmfm
Dec 28 06:25:51.376: INFO: Got endpoints: latency-svc-gzmfm [2.405854757s]
Dec 28 06:25:51.517: INFO: Created: latency-svc-mnvc7
Dec 28 06:25:51.538: INFO: Got endpoints: latency-svc-mnvc7 [2.353051317s]
Dec 28 06:25:51.690: INFO: Created: latency-svc-t2qx9
Dec 28 06:25:51.705: INFO: Got endpoints: latency-svc-t2qx9 [2.327785247s]
Dec 28 06:25:51.886: INFO: Created: latency-svc-z25fc
Dec 28 06:25:51.896: INFO: Got endpoints: latency-svc-z25fc [2.43280159s]
Dec 28 06:25:51.971: INFO: Created: latency-svc-twqlh
Dec 28 06:25:51.982: INFO: Got endpoints: latency-svc-twqlh [2.353799254s]
Dec 28 06:25:52.105: INFO: Created: latency-svc-4n7zz
Dec 28 06:25:52.112: INFO: Got endpoints: latency-svc-4n7zz [2.254712934s]
Dec 28 06:25:52.293: INFO: Created: latency-svc-rq2lk
Dec 28 06:25:52.312: INFO: Got endpoints: latency-svc-rq2lk [2.355071013s]
Dec 28 06:25:52.486: INFO: Created: latency-svc-jx4nj
Dec 28 06:25:52.489: INFO: Got endpoints: latency-svc-jx4nj [2.488435174s]
Dec 28 06:25:52.555: INFO: Created: latency-svc-r7n57
Dec 28 06:25:52.566: INFO: Got endpoints: latency-svc-r7n57 [2.219275597s]
Dec 28 06:25:52.646: INFO: Created: latency-svc-6pftz
Dec 28 06:25:52.662: INFO: Got endpoints: latency-svc-6pftz [2.26013985s]
Dec 28 06:25:52.735: INFO: Created: latency-svc-6d4db
Dec 28 06:25:52.866: INFO: Got endpoints: latency-svc-6d4db [2.22395379s]
Dec 28 06:25:52.873: INFO: Created: latency-svc-85p9l
Dec 28 06:25:52.885: INFO: Got endpoints: latency-svc-85p9l [2.090258127s]
Dec 28 06:25:53.033: INFO: Created: latency-svc-ww294
Dec 28 06:25:53.055: INFO: Got endpoints: latency-svc-ww294 [2.127090837s]
Dec 28 06:25:53.124: INFO: Created: latency-svc-55hh4
Dec 28 06:25:53.290: INFO: Got endpoints: latency-svc-55hh4 [2.166840057s]
Dec 28 06:25:53.314: INFO: Created: latency-svc-5xn7j
Dec 28 06:25:53.322: INFO: Got endpoints: latency-svc-5xn7j [2.119917437s]
Dec 28 06:25:53.487: INFO: Created: latency-svc-gn8dm
Dec 28 06:25:53.511: INFO: Got endpoints: latency-svc-gn8dm [2.134420643s]
Dec 28 06:25:53.822: INFO: Created: latency-svc-qrnjw
Dec 28 06:25:53.841: INFO: Got endpoints: latency-svc-qrnjw [2.30139834s]
Dec 28 06:25:53.973: INFO: Created: latency-svc-hp87d
Dec 28 06:25:54.196: INFO: Got endpoints: latency-svc-hp87d [2.49044345s]
Dec 28 06:25:54.237: INFO: Created: latency-svc-spbp5
Dec 28 06:25:54.289: INFO: Got endpoints: latency-svc-spbp5 [2.392160327s]
Dec 28 06:25:54.373: INFO: Created: latency-svc-v75dc
Dec 28 06:25:54.381: INFO: Got endpoints: latency-svc-v75dc [184.445114ms]
Dec 28 06:25:54.449: INFO: Created: latency-svc-phpzn
Dec 28 06:25:54.641: INFO: Got endpoints: latency-svc-phpzn [2.65846166s]
Dec 28 06:25:54.642: INFO: Created: latency-svc-jmjfm
Dec 28 06:25:54.659: INFO: Got endpoints: latency-svc-jmjfm [2.54660409s]
Dec 28 06:25:54.736: INFO: Created: latency-svc-qqhhz
Dec 28 06:25:54.830: INFO: Got endpoints: latency-svc-qqhhz [2.517374106s]
Dec 28 06:25:54.845: INFO: Created: latency-svc-89ts7
Dec 28 06:25:54.890: INFO: Got endpoints: latency-svc-89ts7 [2.40131989s]
Dec 28 06:25:55.001: INFO: Created: latency-svc-nwxhn
Dec 28 06:25:55.010: INFO: Got endpoints: latency-svc-nwxhn [2.444674786s]
Dec 28 06:25:55.178: INFO: Created: latency-svc-b9pgg
Dec 28 06:25:55.189: INFO: Got endpoints: latency-svc-b9pgg [2.52614247s]
Dec 28 06:25:55.401: INFO: Created: latency-svc-x6tnn
Dec 28 06:25:55.401: INFO: Got endpoints: latency-svc-x6tnn [2.5345259s]
Dec 28 06:25:55.499: INFO: Created: latency-svc-cdp2w
Dec 28 06:25:55.516: INFO: Got endpoints: latency-svc-cdp2w [2.630646546s]
Dec 28 06:25:55.586: INFO: Created: latency-svc-c6wq8
Dec 28 06:25:55.599: INFO: Got endpoints: latency-svc-c6wq8 [2.544441567s]
Dec 28 06:25:55.694: INFO: Created: latency-svc-d5qzd
Dec 28 06:25:55.728: INFO: Got endpoints: latency-svc-d5qzd [2.437755256s]
Dec 28 06:25:55.856: INFO: Created: latency-svc-khwd9
Dec 28 06:25:55.893: INFO: Got endpoints: latency-svc-khwd9 [2.570913154s]
Dec 28 06:25:56.148: INFO: Created: latency-svc-8xt6m
Dec 28 06:25:56.148: INFO: Got endpoints: latency-svc-8xt6m [2.63664455s]
Dec 28 06:25:56.202: INFO: Created: latency-svc-2n7b5
Dec 28 06:25:56.283: INFO: Got endpoints: latency-svc-2n7b5 [2.441891597s]
Dec 28 06:25:56.287: INFO: Created: latency-svc-dmtjr
Dec 28 06:25:56.306: INFO: Got endpoints: latency-svc-dmtjr [2.01722364s]
Dec 28 06:25:56.467: INFO: Created: latency-svc-ccdj5
Dec 28 06:25:56.481: INFO: Got endpoints: latency-svc-ccdj5 [2.09948894s]
Dec 28 06:25:56.707: INFO: Created: latency-svc-6wxps
Dec 28 06:25:56.764: INFO: Got endpoints: latency-svc-6wxps [2.123104026s]
Dec 28 06:25:56.876: INFO: Created: latency-svc-wphsd
Dec 28 06:25:56.886: INFO: Got endpoints: latency-svc-wphsd [2.226921723s]
Dec 28 06:25:57.243: INFO: Created: latency-svc-blgnp
Dec 28 06:25:57.254: INFO: Got endpoints: latency-svc-blgnp [2.42333858s]
Dec 28 06:25:57.504: INFO: Created: latency-svc-9wc9l
Dec 28 06:25:57.512: INFO: Got endpoints: latency-svc-9wc9l [2.62117819s]
Dec 28 06:25:57.601: INFO: Created: latency-svc-djdvv
Dec 28 06:25:57.707: INFO: Got endpoints: latency-svc-djdvv [2.6961083s]
Dec 28 06:25:57.727: INFO: Created: latency-svc-bqtrd
Dec 28 06:25:57.759: INFO: Got endpoints: latency-svc-bqtrd [2.570150264s]
Dec 28 06:25:57.986: INFO: Created: latency-svc-6mkrn
Dec 28 06:25:58.013: INFO: Got endpoints: latency-svc-6mkrn [2.611798373s]
Dec 28 06:25:58.174: INFO: Created: latency-svc-mnmgd
Dec 28 06:25:58.216: INFO: Got endpoints: latency-svc-mnmgd [2.700743277s]
Dec 28 06:25:58.384: INFO: Created: latency-svc-cwwnj
Dec 28 06:25:58.415: INFO: Got endpoints: latency-svc-cwwnj [2.815178487s]
Dec 28 06:25:58.539: INFO: Created: latency-svc-rv6kh
Dec 28 06:25:58.554: INFO: Got endpoints: latency-svc-rv6kh [2.826134613s]
Dec 28 06:25:58.760: INFO: Created: latency-svc-s4q92
Dec 28 06:25:58.794: INFO: Got endpoints: latency-svc-s4q92 [2.900477064s]
Dec 28 06:25:58.919: INFO: Created: latency-svc-gz5df
Dec 28 06:25:58.928: INFO: Got endpoints: latency-svc-gz5df [2.78003918s]
Dec 28 06:25:59.114: INFO: Created: latency-svc-r45rw
Dec 28 06:25:59.158: INFO: Got endpoints: latency-svc-r45rw [2.874897634s]
Dec 28 06:25:59.258: INFO: Created: latency-svc-k92wr
Dec 28 06:25:59.274: INFO: Got endpoints: latency-svc-k92wr [2.967790113s]
Dec 28 06:25:59.506: INFO: Created: latency-svc-q9ctm
Dec 28 06:25:59.525: INFO: Got endpoints: latency-svc-q9ctm [3.04375265s]
Dec 28 06:25:59.731: INFO: Created: latency-svc-9nlc6
Dec 28 06:25:59.889: INFO: Created: latency-svc-kqc2k
Dec 28 06:25:59.935: INFO: Got endpoints: latency-svc-9nlc6 [3.17012044s]
Dec 28 06:25:59.967: INFO: Got endpoints: latency-svc-kqc2k [3.081483893s]
Dec 28 06:26:00.080: INFO: Created: latency-svc-x2zrn
Dec 28 06:26:00.094: INFO: Got endpoints: latency-svc-x2zrn [2.840778114s]
Dec 28 06:26:00.378: INFO: Created: latency-svc-2kpcz
Dec 28 06:26:00.413: INFO: Got endpoints: latency-svc-2kpcz [2.900829206s]
Dec 28 06:26:00.630: INFO: Created: latency-svc-bl7cs
Dec 28 06:26:00.730: INFO: Got endpoints: latency-svc-bl7cs [3.023133007s]
Dec 28 06:26:00.765: INFO: Created: latency-svc-6qm5f
Dec 28 06:26:00.829: INFO: Got endpoints: latency-svc-6qm5f [3.065043937s]
Dec 28 06:26:01.003: INFO: Created: latency-svc-vr552
Dec 28 06:26:01.194: INFO: Got endpoints: latency-svc-vr552 [3.180810667s]
Dec 28 06:26:01.199: INFO: Created: latency-svc-hx2wd
Dec 28 06:26:01.238: INFO: Got endpoints: latency-svc-hx2wd [3.021101173s]
Dec 28 06:26:01.533: INFO: Created: latency-svc-88n6x
Dec 28 06:26:01.551: INFO: Got endpoints: latency-svc-88n6x [3.13474812s]
Dec 28 06:26:01.733: INFO: Created: latency-svc-n6kdd
Dec 28 06:26:01.748: INFO: Got endpoints: latency-svc-n6kdd [3.193566784s]
Dec 28 06:26:01.828: INFO: Created: latency-svc-2wd5h
Dec 28 06:26:01.942: INFO: Got endpoints: latency-svc-2wd5h [3.14862989s]
Dec 28 06:26:02.010: INFO: Created: latency-svc-cssw9
Dec 28 06:26:02.152: INFO: Got endpoints: latency-svc-cssw9 [3.224300317s]
Dec 28 06:26:02.347: INFO: Created: latency-svc-9cxhj
Dec 28 06:26:02.364: INFO: Got endpoints: latency-svc-9cxhj [3.206137174s]
Dec 28 06:26:02.624: INFO: Created: latency-svc-mt9bm
Dec 28 06:26:02.640: INFO: Got endpoints: latency-svc-mt9bm [3.365924407s]
Dec 28 06:26:02.822: INFO: Created: latency-svc-m42dm
Dec 28 06:26:02.829: INFO: Got endpoints: latency-svc-m42dm [3.304777726s]
Dec 28 06:26:02.830: INFO: Latencies: [184.445114ms 200.476593ms 489.703607ms 535.17575ms 650.091606ms 818.904563ms 924.447187ms 1.268999467s 1.536842133s 1.776664383s 1.900020866s 1.916318223s 1.917189543s 1.939571814s 1.940922987s 1.951555806s 1.965838337s 1.96625696s 1.973209257s 1.978948724s 1.98081559s 1.98122252s 1.987404816s 1.98914368s 1.99381018s 1.996225373s 1.999951346s 2.00864923s 2.01722364s 2.023889787s 2.026999857s 2.031362203s 2.054201646s 2.055499913s 2.081132497s 2.090258127s 2.096626563s 2.09948894s 2.10824586s 2.108957944s 2.11111549s 2.11359262s 2.114499466s 2.119917437s 2.12200335s 2.123104026s 2.12636116s 2.127090837s 2.128467667s 2.13429029s 2.134420643s 2.153902717s 2.155708987s 2.165537827s 2.166840057s 2.177085197s 2.20418938s 2.20514533s 2.215817256s 2.219275597s 2.22395379s 2.226921723s 2.244962994s 2.254712934s 2.26013985s 2.27342169s 2.28313177s 2.287015113s 2.28846828s 2.292079726s 2.29459504s 2.296049677s 2.298073087s 2.301076617s 2.30139834s 2.30781462s 2.327785247s 2.34505887s 2.345134837s 2.34573044s 2.351033774s 2.353051317s 2.353799254s 2.355071013s 2.373602394s 2.37899735s 2.379642144s 2.38698397s 2.392160327s 2.397661333s 2.39791311s 2.40131989s 2.405854757s 2.405937873s 2.406114423s 2.41103011s 2.417824153s 2.42333858s 2.429496557s 2.43280159s 2.437755256s 2.441891597s 2.444674786s 2.444706317s 2.458910477s 2.468560507s 2.48387545s 2.488435174s 2.48983125s 2.49044345s 2.501075124s 2.517374106s 2.52614247s 2.53139398s 2.5345259s 2.536132607s 2.537312444s 2.539283506s 2.544441567s 2.54660409s 2.54712057s 2.548091426s 2.548597553s 2.550977573s 2.570150264s 2.570913154s 2.580696357s 2.611798373s 2.616948176s 2.618692817s 2.61962876s 2.62117819s 2.628375017s 2.628865147s 2.630534147s 2.630646546s 2.63548442s 2.63664455s 2.644555997s 2.647002096s 2.655088956s 2.656453517s 2.65846166s 2.66332587s 2.66620028s 2.67591978s 2.677389137s 2.677766516s 2.687840517s 2.695132193s 2.6961083s 2.700743277s 2.701489507s 2.714134834s 2.72477094s 2.727297073s 2.73238756s 2.73987747s 2.754108656s 2.761907114s 2.772576257s 2.78003918s 2.782327524s 2.789257144s 2.809265926s 2.809622807s 2.813839897s 2.815178487s 2.81580192s 2.82279957s 2.826134613s 2.82629291s 2.83384204s 2.840778114s 2.84561282s 2.846563946s 2.860156483s 2.874897634s 2.884869644s 2.89481417s 2.900477064s 2.900829206s 2.91559198s 2.923714343s 2.932319513s 2.967790113s 3.021101173s 3.023133007s 3.04375265s 3.065043937s 3.081483893s 3.13474812s 3.14862989s 3.17012044s 3.180810667s 3.193566784s 3.206137174s 3.224300317s 3.304777726s 3.365924407s]
Dec 28 06:26:02.832: INFO: 50 %ile: 2.437755256s
Dec 28 06:26:02.832: INFO: 90 %ile: 2.900477064s
Dec 28 06:26:02.832: INFO: 99 %ile: 3.304777726s
Dec 28 06:26:02.832: INFO: Total sample count: 200
[AfterEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 28 06:26:02.832: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-svc-latency-pjrlx" for this suite.
Dec 28 06:27:03.012: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 06:27:03.184: INFO: namespace: e2e-tests-svc-latency-pjrlx, resource: bindings, ignored listing per whitelist
Dec 28 06:27:03.231: INFO: namespace e2e-tests-svc-latency-pjrlx deletion completed in 1m0.342291984s

• [SLOW TEST:103.696 seconds]
[sig-network] Service endpoints latency
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should not be very high  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 28 06:27:03.232: INFO: >>> kubeConfig: /tmp/kubeconfig-994138694
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Dec 28 06:27:03.672: INFO: Waiting up to 5m0s for pod "downwardapi-volume-973ac028-0a69-11e9-8a07-628dff7095f4" in namespace "e2e-tests-downward-api-9d7k9" to be "success or failure"
Dec 28 06:27:03.717: INFO: Pod "downwardapi-volume-973ac028-0a69-11e9-8a07-628dff7095f4": Phase="Pending", Reason="", readiness=false. Elapsed: 44.494383ms
Dec 28 06:27:05.725: INFO: Pod "downwardapi-volume-973ac028-0a69-11e9-8a07-628dff7095f4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.05283126s
Dec 28 06:27:07.732: INFO: Pod "downwardapi-volume-973ac028-0a69-11e9-8a07-628dff7095f4": Phase="Pending", Reason="", readiness=false. Elapsed: 4.059859773s
Dec 28 06:27:09.739: INFO: Pod "downwardapi-volume-973ac028-0a69-11e9-8a07-628dff7095f4": Phase="Pending", Reason="", readiness=false. Elapsed: 6.066566857s
Dec 28 06:27:11.747: INFO: Pod "downwardapi-volume-973ac028-0a69-11e9-8a07-628dff7095f4": Phase="Pending", Reason="", readiness=false. Elapsed: 8.074181497s
Dec 28 06:27:13.813: INFO: Pod "downwardapi-volume-973ac028-0a69-11e9-8a07-628dff7095f4": Phase="Running", Reason="", readiness=true. Elapsed: 10.140488653s
Dec 28 06:27:15.821: INFO: Pod "downwardapi-volume-973ac028-0a69-11e9-8a07-628dff7095f4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 12.148215513s
STEP: Saw pod success
Dec 28 06:27:15.821: INFO: Pod "downwardapi-volume-973ac028-0a69-11e9-8a07-628dff7095f4" satisfied condition "success or failure"
Dec 28 06:27:15.826: INFO: Trying to get logs from node 10.10.102.68-share pod downwardapi-volume-973ac028-0a69-11e9-8a07-628dff7095f4 container client-container: <nil>
STEP: delete the pod
Dec 28 06:27:15.880: INFO: Waiting for pod downwardapi-volume-973ac028-0a69-11e9-8a07-628dff7095f4 to disappear
Dec 28 06:27:15.899: INFO: Pod downwardapi-volume-973ac028-0a69-11e9-8a07-628dff7095f4 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 28 06:27:15.899: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-9d7k9" for this suite.
Dec 28 06:27:21.994: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 06:27:22.355: INFO: namespace: e2e-tests-downward-api-9d7k9, resource: bindings, ignored listing per whitelist
Dec 28 06:27:22.380: INFO: namespace e2e-tests-downward-api-9d7k9 deletion completed in 6.468260194s

• [SLOW TEST:19.148 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 28 06:27:22.380: INFO: >>> kubeConfig: /tmp/kubeconfig-994138694
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Dec 28 06:27:22.816: INFO: Waiting up to 5m0s for pod "downwardapi-volume-a2a4114d-0a69-11e9-8a07-628dff7095f4" in namespace "e2e-tests-downward-api-9gxtv" to be "success or failure"
Dec 28 06:27:22.842: INFO: Pod "downwardapi-volume-a2a4114d-0a69-11e9-8a07-628dff7095f4": Phase="Pending", Reason="", readiness=false. Elapsed: 26.554514ms
Dec 28 06:27:24.850: INFO: Pod "downwardapi-volume-a2a4114d-0a69-11e9-8a07-628dff7095f4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.034516227s
Dec 28 06:27:26.906: INFO: Pod "downwardapi-volume-a2a4114d-0a69-11e9-8a07-628dff7095f4": Phase="Pending", Reason="", readiness=false. Elapsed: 4.090486197s
Dec 28 06:27:28.915: INFO: Pod "downwardapi-volume-a2a4114d-0a69-11e9-8a07-628dff7095f4": Phase="Pending", Reason="", readiness=false. Elapsed: 6.098772267s
Dec 28 06:27:30.930: INFO: Pod "downwardapi-volume-a2a4114d-0a69-11e9-8a07-628dff7095f4": Phase="Pending", Reason="", readiness=false. Elapsed: 8.11429791s
Dec 28 06:27:32.941: INFO: Pod "downwardapi-volume-a2a4114d-0a69-11e9-8a07-628dff7095f4": Phase="Pending", Reason="", readiness=false. Elapsed: 10.12467721s
Dec 28 06:27:34.948: INFO: Pod "downwardapi-volume-a2a4114d-0a69-11e9-8a07-628dff7095f4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 12.132593167s
STEP: Saw pod success
Dec 28 06:27:34.949: INFO: Pod "downwardapi-volume-a2a4114d-0a69-11e9-8a07-628dff7095f4" satisfied condition "success or failure"
Dec 28 06:27:34.954: INFO: Trying to get logs from node 10.10.102.69-build pod downwardapi-volume-a2a4114d-0a69-11e9-8a07-628dff7095f4 container client-container: <nil>
STEP: delete the pod
Dec 28 06:27:35.015: INFO: Waiting for pod downwardapi-volume-a2a4114d-0a69-11e9-8a07-628dff7095f4 to disappear
Dec 28 06:27:35.095: INFO: Pod downwardapi-volume-a2a4114d-0a69-11e9-8a07-628dff7095f4 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 28 06:27:35.095: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-9gxtv" for this suite.
Dec 28 06:27:41.146: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 06:27:41.172: INFO: namespace: e2e-tests-downward-api-9gxtv, resource: bindings, ignored listing per whitelist
Dec 28 06:27:41.358: INFO: namespace e2e-tests-downward-api-9gxtv deletion completed in 6.253852123s

• [SLOW TEST:18.978 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 28 06:27:41.359: INFO: >>> kubeConfig: /tmp/kubeconfig-994138694
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-ade7e60b-0a69-11e9-8a07-628dff7095f4
STEP: Creating a pod to test consume configMaps
Dec 28 06:27:41.743: INFO: Waiting up to 5m0s for pod "pod-configmaps-adebd24d-0a69-11e9-8a07-628dff7095f4" in namespace "e2e-tests-configmap-gnc7s" to be "success or failure"
Dec 28 06:27:41.797: INFO: Pod "pod-configmaps-adebd24d-0a69-11e9-8a07-628dff7095f4": Phase="Pending", Reason="", readiness=false. Elapsed: 54.23826ms
Dec 28 06:27:43.804: INFO: Pod "pod-configmaps-adebd24d-0a69-11e9-8a07-628dff7095f4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.061175674s
Dec 28 06:27:45.813: INFO: Pod "pod-configmaps-adebd24d-0a69-11e9-8a07-628dff7095f4": Phase="Pending", Reason="", readiness=false. Elapsed: 4.07007209s
Dec 28 06:27:47.821: INFO: Pod "pod-configmaps-adebd24d-0a69-11e9-8a07-628dff7095f4": Phase="Pending", Reason="", readiness=false. Elapsed: 6.07793154s
Dec 28 06:27:49.828: INFO: Pod "pod-configmaps-adebd24d-0a69-11e9-8a07-628dff7095f4": Phase="Pending", Reason="", readiness=false. Elapsed: 8.085501324s
Dec 28 06:27:51.835: INFO: Pod "pod-configmaps-adebd24d-0a69-11e9-8a07-628dff7095f4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 10.092592534s
STEP: Saw pod success
Dec 28 06:27:51.835: INFO: Pod "pod-configmaps-adebd24d-0a69-11e9-8a07-628dff7095f4" satisfied condition "success or failure"
Dec 28 06:27:51.840: INFO: Trying to get logs from node 10.10.102.68-share pod pod-configmaps-adebd24d-0a69-11e9-8a07-628dff7095f4 container configmap-volume-test: <nil>
STEP: delete the pod
Dec 28 06:27:51.923: INFO: Waiting for pod pod-configmaps-adebd24d-0a69-11e9-8a07-628dff7095f4 to disappear
Dec 28 06:27:51.957: INFO: Pod pod-configmaps-adebd24d-0a69-11e9-8a07-628dff7095f4 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 28 06:27:51.957: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-gnc7s" for this suite.
Dec 28 06:28:00.143: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 06:28:00.280: INFO: namespace: e2e-tests-configmap-gnc7s, resource: bindings, ignored listing per whitelist
Dec 28 06:28:00.380: INFO: namespace e2e-tests-configmap-gnc7s deletion completed in 8.341225826s

• [SLOW TEST:19.021 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-api-machinery] Secrets 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 28 06:28:00.380: INFO: >>> kubeConfig: /tmp/kubeconfig-994138694
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating secret e2e-tests-secrets-9gd8j/secret-test-b9435b4c-0a69-11e9-8a07-628dff7095f4
STEP: Creating a pod to test consume secrets
Dec 28 06:28:00.797: INFO: Waiting up to 5m0s for pod "pod-configmaps-b9450389-0a69-11e9-8a07-628dff7095f4" in namespace "e2e-tests-secrets-9gd8j" to be "success or failure"
Dec 28 06:28:00.823: INFO: Pod "pod-configmaps-b9450389-0a69-11e9-8a07-628dff7095f4": Phase="Pending", Reason="", readiness=false. Elapsed: 25.8124ms
Dec 28 06:28:02.830: INFO: Pod "pod-configmaps-b9450389-0a69-11e9-8a07-628dff7095f4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.03268616s
Dec 28 06:28:04.837: INFO: Pod "pod-configmaps-b9450389-0a69-11e9-8a07-628dff7095f4": Phase="Pending", Reason="", readiness=false. Elapsed: 4.040510177s
Dec 28 06:28:06.865: INFO: Pod "pod-configmaps-b9450389-0a69-11e9-8a07-628dff7095f4": Phase="Pending", Reason="", readiness=false. Elapsed: 6.067741317s
Dec 28 06:28:08.871: INFO: Pod "pod-configmaps-b9450389-0a69-11e9-8a07-628dff7095f4": Phase="Pending", Reason="", readiness=false. Elapsed: 8.074574943s
Dec 28 06:28:10.879: INFO: Pod "pod-configmaps-b9450389-0a69-11e9-8a07-628dff7095f4": Phase="Pending", Reason="", readiness=false. Elapsed: 10.0818017s
Dec 28 06:28:12.885: INFO: Pod "pod-configmaps-b9450389-0a69-11e9-8a07-628dff7095f4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 12.087933013s
STEP: Saw pod success
Dec 28 06:28:12.885: INFO: Pod "pod-configmaps-b9450389-0a69-11e9-8a07-628dff7095f4" satisfied condition "success or failure"
Dec 28 06:28:12.891: INFO: Trying to get logs from node 10.10.102.69-build pod pod-configmaps-b9450389-0a69-11e9-8a07-628dff7095f4 container env-test: <nil>
STEP: delete the pod
Dec 28 06:28:13.258: INFO: Waiting for pod pod-configmaps-b9450389-0a69-11e9-8a07-628dff7095f4 to disappear
Dec 28 06:28:13.278: INFO: Pod pod-configmaps-b9450389-0a69-11e9-8a07-628dff7095f4 no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 28 06:28:13.278: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-9gd8j" for this suite.
Dec 28 06:28:19.431: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 06:28:19.690: INFO: namespace: e2e-tests-secrets-9gd8j, resource: bindings, ignored listing per whitelist
Dec 28 06:28:19.765: INFO: namespace e2e-tests-secrets-9gd8j deletion completed in 6.474842633s

• [SLOW TEST:19.385 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:31
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 28 06:28:19.765: INFO: >>> kubeConfig: /tmp/kubeconfig-994138694
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Dec 28 06:28:40.270: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Dec 28 06:28:40.325: INFO: Pod pod-with-prestop-http-hook still exists
Dec 28 06:28:42.326: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Dec 28 06:28:42.364: INFO: Pod pod-with-prestop-http-hook still exists
Dec 28 06:28:44.326: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Dec 28 06:28:44.333: INFO: Pod pod-with-prestop-http-hook still exists
Dec 28 06:28:46.326: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Dec 28 06:28:46.333: INFO: Pod pod-with-prestop-http-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 28 06:28:46.353: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-lifecycle-hook-sqv4p" for this suite.
Dec 28 06:29:10.505: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 06:29:10.699: INFO: namespace: e2e-tests-container-lifecycle-hook-sqv4p, resource: bindings, ignored listing per whitelist
Dec 28 06:29:10.850: INFO: namespace e2e-tests-container-lifecycle-hook-sqv4p deletion completed in 24.48613884s

• [SLOW TEST:51.084 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when create a pod with lifecycle hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute prestop http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Projected 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 28 06:29:10.850: INFO: >>> kubeConfig: /tmp/kubeconfig-994138694
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating the pod
Dec 28 06:29:32.107: INFO: Successfully updated pod "annotationupdatee3539a17-0a69-11e9-8a07-628dff7095f4"
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 28 06:29:34.225: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-nk2tp" for this suite.
Dec 28 06:29:58.276: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 06:29:58.349: INFO: namespace: e2e-tests-projected-nk2tp, resource: bindings, ignored listing per whitelist
Dec 28 06:29:58.492: INFO: namespace e2e-tests-projected-nk2tp deletion completed in 24.25808203s

• [SLOW TEST:47.642 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 28 06:29:58.493: INFO: >>> kubeConfig: /tmp/kubeconfig-994138694
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-n2wqc
[It] Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Looking for a node to schedule stateful set and pod
STEP: Creating pod with conflicting port in namespace e2e-tests-statefulset-n2wqc
STEP: Creating statefulset with conflicting port in namespace e2e-tests-statefulset-n2wqc
STEP: Waiting until pod test-pod will start running in namespace e2e-tests-statefulset-n2wqc
STEP: Waiting until stateful pod ss-0 will be recreated and deleted at least once in namespace e2e-tests-statefulset-n2wqc
Dec 28 06:30:11.362: INFO: Observed stateful pod in namespace: e2e-tests-statefulset-n2wqc, name: ss-0, uid: 01848856-0a6a-11e9-a0ee-005056bc4922, status phase: Failed. Waiting for statefulset controller to delete.
Dec 28 06:30:11.371: INFO: Observed stateful pod in namespace: e2e-tests-statefulset-n2wqc, name: ss-0, uid: 01848856-0a6a-11e9-a0ee-005056bc4922, status phase: Failed. Waiting for statefulset controller to delete.
Dec 28 06:30:11.422: INFO: Observed delete event for stateful pod ss-0 in namespace e2e-tests-statefulset-n2wqc
STEP: Removing pod with conflicting port in namespace e2e-tests-statefulset-n2wqc
STEP: Waiting when stateful pod ss-0 will be recreated in namespace e2e-tests-statefulset-n2wqc and will be in running state
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Dec 28 06:30:33.881: INFO: Deleting all statefulset in ns e2e-tests-statefulset-n2wqc
Dec 28 06:30:33.886: INFO: Scaling statefulset ss to 0
Dec 28 06:30:44.111: INFO: Waiting for statefulset status.replicas updated to 0
Dec 28 06:30:44.116: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 28 06:30:44.175: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-n2wqc" for this suite.
Dec 28 06:30:52.312: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 06:30:52.357: INFO: namespace: e2e-tests-statefulset-n2wqc, resource: bindings, ignored listing per whitelist
Dec 28 06:30:52.533: INFO: namespace e2e-tests-statefulset-n2wqc deletion completed in 8.28605633s

• [SLOW TEST:54.040 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    Should recreate evicted statefulset [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 28 06:30:52.534: INFO: >>> kubeConfig: /tmp/kubeconfig-994138694
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:293
[It] should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the initial replication controller
Dec 28 06:30:52.872: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994138694 create -f - --namespace=e2e-tests-kubectl-mbx7l'
Dec 28 06:30:56.239: INFO: stderr: ""
Dec 28 06:30:56.239: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Dec 28 06:30:56.239: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994138694 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-mbx7l'
Dec 28 06:30:56.547: INFO: stderr: ""
Dec 28 06:30:56.547: INFO: stdout: "update-demo-nautilus-6dcr7 update-demo-nautilus-v9q85 "
Dec 28 06:30:56.547: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994138694 get pods update-demo-nautilus-6dcr7 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-mbx7l'
Dec 28 06:30:56.828: INFO: stderr: ""
Dec 28 06:30:56.828: INFO: stdout: ""
Dec 28 06:30:56.828: INFO: update-demo-nautilus-6dcr7 is created but not running
Dec 28 06:31:01.828: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994138694 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-mbx7l'
Dec 28 06:31:02.196: INFO: stderr: ""
Dec 28 06:31:02.196: INFO: stdout: "update-demo-nautilus-6dcr7 update-demo-nautilus-v9q85 "
Dec 28 06:31:02.196: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994138694 get pods update-demo-nautilus-6dcr7 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-mbx7l'
Dec 28 06:31:02.598: INFO: stderr: ""
Dec 28 06:31:02.598: INFO: stdout: ""
Dec 28 06:31:02.598: INFO: update-demo-nautilus-6dcr7 is created but not running
Dec 28 06:31:07.599: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994138694 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-mbx7l'
Dec 28 06:31:07.939: INFO: stderr: ""
Dec 28 06:31:07.939: INFO: stdout: "update-demo-nautilus-6dcr7 update-demo-nautilus-v9q85 "
Dec 28 06:31:07.940: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994138694 get pods update-demo-nautilus-6dcr7 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-mbx7l'
Dec 28 06:31:08.462: INFO: stderr: ""
Dec 28 06:31:08.462: INFO: stdout: ""
Dec 28 06:31:08.462: INFO: update-demo-nautilus-6dcr7 is created but not running
Dec 28 06:31:13.463: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994138694 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-mbx7l'
Dec 28 06:31:13.767: INFO: stderr: ""
Dec 28 06:31:13.767: INFO: stdout: "update-demo-nautilus-6dcr7 update-demo-nautilus-v9q85 "
Dec 28 06:31:13.767: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994138694 get pods update-demo-nautilus-6dcr7 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-mbx7l'
Dec 28 06:31:14.042: INFO: stderr: ""
Dec 28 06:31:14.042: INFO: stdout: "true"
Dec 28 06:31:14.042: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994138694 get pods update-demo-nautilus-6dcr7 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-mbx7l'
Dec 28 06:31:14.331: INFO: stderr: ""
Dec 28 06:31:14.331: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Dec 28 06:31:14.331: INFO: validating pod update-demo-nautilus-6dcr7
Dec 28 06:31:14.350: INFO: got data: {
  "image": "nautilus.jpg"
}

Dec 28 06:31:14.350: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Dec 28 06:31:14.350: INFO: update-demo-nautilus-6dcr7 is verified up and running
Dec 28 06:31:14.350: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994138694 get pods update-demo-nautilus-v9q85 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-mbx7l'
Dec 28 06:31:14.623: INFO: stderr: ""
Dec 28 06:31:14.623: INFO: stdout: "true"
Dec 28 06:31:14.623: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994138694 get pods update-demo-nautilus-v9q85 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-mbx7l'
Dec 28 06:31:14.925: INFO: stderr: ""
Dec 28 06:31:14.925: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Dec 28 06:31:14.925: INFO: validating pod update-demo-nautilus-v9q85
Dec 28 06:31:14.943: INFO: got data: {
  "image": "nautilus.jpg"
}

Dec 28 06:31:14.943: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Dec 28 06:31:14.943: INFO: update-demo-nautilus-v9q85 is verified up and running
STEP: rolling-update to new replication controller
Dec 28 06:31:14.947: INFO: scanned /root for discovery docs: <nil>
Dec 28 06:31:14.947: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994138694 rolling-update update-demo-nautilus --update-period=1s -f - --namespace=e2e-tests-kubectl-mbx7l'
Dec 28 06:31:47.112: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Dec 28 06:31:47.112: INFO: stdout: "Created update-demo-kitten\nScaling up update-demo-kitten from 0 to 2, scaling down update-demo-nautilus from 2 to 0 (keep 2 pods available, don't exceed 3 pods)\nScaling update-demo-kitten up to 1\nScaling update-demo-nautilus down to 1\nScaling update-demo-kitten up to 2\nScaling update-demo-nautilus down to 0\nUpdate succeeded. Deleting old controller: update-demo-nautilus\nRenaming update-demo-kitten to update-demo-nautilus\nreplicationcontroller/update-demo-nautilus rolling updated\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Dec 28 06:31:47.112: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994138694 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-mbx7l'
Dec 28 06:31:47.430: INFO: stderr: ""
Dec 28 06:31:47.430: INFO: stdout: "update-demo-kitten-7t8g4 update-demo-kitten-gp4hr update-demo-nautilus-6dcr7 "
STEP: Replicas for name=update-demo: expected=2 actual=3
Dec 28 06:31:52.430: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994138694 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-mbx7l'
Dec 28 06:31:52.745: INFO: stderr: ""
Dec 28 06:31:52.745: INFO: stdout: "update-demo-kitten-7t8g4 update-demo-kitten-gp4hr "
Dec 28 06:31:52.745: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994138694 get pods update-demo-kitten-7t8g4 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-mbx7l'
Dec 28 06:31:53.011: INFO: stderr: ""
Dec 28 06:31:53.011: INFO: stdout: "true"
Dec 28 06:31:53.012: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994138694 get pods update-demo-kitten-7t8g4 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-mbx7l'
Dec 28 06:31:53.274: INFO: stderr: ""
Dec 28 06:31:53.274: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
Dec 28 06:31:53.274: INFO: validating pod update-demo-kitten-7t8g4
Dec 28 06:31:53.299: INFO: got data: {
  "image": "kitten.jpg"
}

Dec 28 06:31:53.299: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Dec 28 06:31:53.299: INFO: update-demo-kitten-7t8g4 is verified up and running
Dec 28 06:31:53.299: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994138694 get pods update-demo-kitten-gp4hr -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-mbx7l'
Dec 28 06:31:53.641: INFO: stderr: ""
Dec 28 06:31:53.641: INFO: stdout: "true"
Dec 28 06:31:53.641: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-994138694 get pods update-demo-kitten-gp4hr -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-mbx7l'
Dec 28 06:31:53.923: INFO: stderr: ""
Dec 28 06:31:53.924: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
Dec 28 06:31:53.924: INFO: validating pod update-demo-kitten-gp4hr
Dec 28 06:31:53.935: INFO: got data: {
  "image": "kitten.jpg"
}

Dec 28 06:31:53.936: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Dec 28 06:31:53.936: INFO: update-demo-kitten-gp4hr is verified up and running
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 28 06:31:53.936: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-mbx7l" for this suite.
Dec 28 06:32:18.006: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 06:32:18.209: INFO: namespace: e2e-tests-kubectl-mbx7l, resource: bindings, ignored listing per whitelist
Dec 28 06:32:18.221: INFO: namespace e2e-tests-kubectl-mbx7l deletion completed in 24.274493767s

• [SLOW TEST:85.687 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Update Demo
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should do a rolling update of a replication controller  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 28 06:32:18.221: INFO: >>> kubeConfig: /tmp/kubeconfig-994138694
STEP: Building a namespace api object, basename namespaces
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a test namespace
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a pod in the namespace
STEP: Waiting for the pod to have running status
STEP: Creating an uninitialized pod in the namespace
Dec 28 06:32:28.637: INFO: error from create uninitialized namespace: <nil>
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Verifying there are no pods in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 28 06:32:53.933: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-namespaces-rt5vs" for this suite.
Dec 28 06:32:59.972: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 06:33:00.097: INFO: namespace: e2e-tests-namespaces-rt5vs, resource: bindings, ignored listing per whitelist
Dec 28 06:33:00.186: INFO: namespace e2e-tests-namespaces-rt5vs deletion completed in 6.23892072s
STEP: Destroying namespace "e2e-tests-nsdeletetest-hsqkf" for this suite.
Dec 28 06:33:00.191: INFO: Namespace e2e-tests-nsdeletetest-hsqkf was already deleted
STEP: Destroying namespace "e2e-tests-nsdeletetest-vh8pj" for this suite.
Dec 28 06:33:06.253: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 06:33:06.516: INFO: namespace: e2e-tests-nsdeletetest-vh8pj, resource: bindings, ignored listing per whitelist
Dec 28 06:33:06.521: INFO: namespace e2e-tests-nsdeletetest-vh8pj deletion completed in 6.330404317s

• [SLOW TEST:48.300 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 28 06:33:06.522: INFO: >>> kubeConfig: /tmp/kubeconfig-994138694
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0666 on tmpfs
Dec 28 06:33:06.814: INFO: Waiting up to 5m0s for pod "pod-6fad4c11-0a6a-11e9-8a07-628dff7095f4" in namespace "e2e-tests-emptydir-n7vp8" to be "success or failure"
Dec 28 06:33:06.843: INFO: Pod "pod-6fad4c11-0a6a-11e9-8a07-628dff7095f4": Phase="Pending", Reason="", readiness=false. Elapsed: 29.619554ms
Dec 28 06:33:08.852: INFO: Pod "pod-6fad4c11-0a6a-11e9-8a07-628dff7095f4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.038069494s
Dec 28 06:33:10.861: INFO: Pod "pod-6fad4c11-0a6a-11e9-8a07-628dff7095f4": Phase="Pending", Reason="", readiness=false. Elapsed: 4.047627637s
Dec 28 06:33:12.869: INFO: Pod "pod-6fad4c11-0a6a-11e9-8a07-628dff7095f4": Phase="Pending", Reason="", readiness=false. Elapsed: 6.05503762s
Dec 28 06:33:14.876: INFO: Pod "pod-6fad4c11-0a6a-11e9-8a07-628dff7095f4": Phase="Running", Reason="", readiness=true. Elapsed: 8.06245368s
Dec 28 06:33:16.884: INFO: Pod "pod-6fad4c11-0a6a-11e9-8a07-628dff7095f4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 10.070369444s
STEP: Saw pod success
Dec 28 06:33:16.884: INFO: Pod "pod-6fad4c11-0a6a-11e9-8a07-628dff7095f4" satisfied condition "success or failure"
Dec 28 06:33:16.889: INFO: Trying to get logs from node 10.10.102.69-build pod pod-6fad4c11-0a6a-11e9-8a07-628dff7095f4 container test-container: <nil>
STEP: delete the pod
Dec 28 06:33:17.160: INFO: Waiting for pod pod-6fad4c11-0a6a-11e9-8a07-628dff7095f4 to disappear
Dec 28 06:33:17.195: INFO: Pod pod-6fad4c11-0a6a-11e9-8a07-628dff7095f4 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 28 06:33:17.195: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-n7vp8" for this suite.
Dec 28 06:33:23.322: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 06:33:23.366: INFO: namespace: e2e-tests-emptydir-n7vp8, resource: bindings, ignored listing per whitelist
Dec 28 06:33:23.540: INFO: namespace e2e-tests-emptydir-n7vp8 deletion completed in 6.264868367s

• [SLOW TEST:17.019 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] Projected 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 28 06:33:23.540: INFO: >>> kubeConfig: /tmp/kubeconfig-994138694
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Dec 28 06:33:23.780: INFO: Waiting up to 5m0s for pod "downwardapi-volume-79cb0b74-0a6a-11e9-8a07-628dff7095f4" in namespace "e2e-tests-projected-2f9x9" to be "success or failure"
Dec 28 06:33:23.792: INFO: Pod "downwardapi-volume-79cb0b74-0a6a-11e9-8a07-628dff7095f4": Phase="Pending", Reason="", readiness=false. Elapsed: 12.740974ms
Dec 28 06:33:25.802: INFO: Pod "downwardapi-volume-79cb0b74-0a6a-11e9-8a07-628dff7095f4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.021966234s
Dec 28 06:33:27.810: INFO: Pod "downwardapi-volume-79cb0b74-0a6a-11e9-8a07-628dff7095f4": Phase="Pending", Reason="", readiness=false. Elapsed: 4.02987212s
Dec 28 06:33:29.818: INFO: Pod "downwardapi-volume-79cb0b74-0a6a-11e9-8a07-628dff7095f4": Phase="Pending", Reason="", readiness=false. Elapsed: 6.038649997s
Dec 28 06:33:31.826: INFO: Pod "downwardapi-volume-79cb0b74-0a6a-11e9-8a07-628dff7095f4": Phase="Running", Reason="", readiness=true. Elapsed: 8.046029484s
Dec 28 06:33:33.833: INFO: Pod "downwardapi-volume-79cb0b74-0a6a-11e9-8a07-628dff7095f4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 10.05308033s
STEP: Saw pod success
Dec 28 06:33:33.833: INFO: Pod "downwardapi-volume-79cb0b74-0a6a-11e9-8a07-628dff7095f4" satisfied condition "success or failure"
Dec 28 06:33:33.838: INFO: Trying to get logs from node 10.10.102.68-share pod downwardapi-volume-79cb0b74-0a6a-11e9-8a07-628dff7095f4 container client-container: <nil>
STEP: delete the pod
Dec 28 06:33:33.964: INFO: Waiting for pod downwardapi-volume-79cb0b74-0a6a-11e9-8a07-628dff7095f4 to disappear
Dec 28 06:33:33.970: INFO: Pod downwardapi-volume-79cb0b74-0a6a-11e9-8a07-628dff7095f4 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 28 06:33:33.970: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-2f9x9" for this suite.
Dec 28 06:33:40.136: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 06:33:40.333: INFO: namespace: e2e-tests-projected-2f9x9, resource: bindings, ignored listing per whitelist
Dec 28 06:33:40.346: INFO: namespace e2e-tests-projected-2f9x9 deletion completed in 6.365426903s

• [SLOW TEST:16.805 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 28 06:33:40.346: INFO: >>> kubeConfig: /tmp/kubeconfig-994138694
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
Dec 28 06:33:40.679: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 28 06:33:56.106: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-init-container-ppp7j" for this suite.
Dec 28 06:34:14.171: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 06:34:14.350: INFO: namespace: e2e-tests-init-container-ppp7j, resource: bindings, ignored listing per whitelist
Dec 28 06:34:14.448: INFO: namespace e2e-tests-init-container-ppp7j deletion completed in 18.323556003s

• [SLOW TEST:34.102 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] Projected 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Dec 28 06:34:14.448: INFO: >>> kubeConfig: /tmp/kubeconfig-994138694
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name cm-test-opt-del-9828cb65-0a6a-11e9-8a07-628dff7095f4
STEP: Creating configMap with name cm-test-opt-upd-9828cd64-0a6a-11e9-8a07-628dff7095f4
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-9828cb65-0a6a-11e9-8a07-628dff7095f4
STEP: Updating configmap cm-test-opt-upd-9828cd64-0a6a-11e9-8a07-628dff7095f4
STEP: Creating configMap with name cm-test-opt-create-9828cda0-0a6a-11e9-8a07-628dff7095f4
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Dec 28 06:35:56.019: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-wvqd6" for this suite.
Dec 28 06:36:20.169: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 28 06:36:20.237: INFO: namespace: e2e-tests-projected-wvqd6, resource: bindings, ignored listing per whitelist
Dec 28 06:36:20.529: INFO: namespace e2e-tests-projected-wvqd6 deletion completed in 24.497822103s

• [SLOW TEST:126.082 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSDec 28 06:36:20.530: INFO: Running AfterSuite actions on all node
Dec 28 06:36:20.551: INFO: Running AfterSuite actions on node 1
Dec 28 06:36:20.551: INFO: Skipping dumping logs from cluster

Ran 187 of 1814 Specs in 7629.346 seconds
SUCCESS! -- 187 Passed | 0 Failed | 0 Pending | 1627 Skipped PASS

Ginkgo ran 1 suite in 2h7m19.072092164s
Test Suite Passed
