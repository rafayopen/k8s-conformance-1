Nov  8 16:14:31.459: INFO: Overriding default scale value of zero to 1
Nov  8 16:14:31.459: INFO: Overriding default milliseconds value of zero to 5000
Running Suite: Kubernetes e2e suite
===================================
Random Seed: 1541693671 - Will randomize all specs
Will run 188 of 1814 specs

Nov  8 16:14:32.072: INFO: >>> kubeConfig: /tmp/kubeconfig-235977939
Nov  8 16:14:32.074: INFO: Waiting up to 30m0s for all (but 0) nodes to be schedulable
Nov  8 16:14:32.084: INFO: Waiting up to 10m0s for all pods (need at least 0) in namespace 'kube-system' to be running and ready
Nov  8 16:14:32.113: INFO: 12 / 12 pods in namespace 'kube-system' are running and ready (0 seconds elapsed)
Nov  8 16:14:32.113: INFO: expected 2 pod replicas in namespace 'kube-system', 2 are Running and Ready.
Nov  8 16:14:32.113: INFO: Waiting up to 5m0s for all daemonsets in namespace 'kube-system' to start
Nov  8 16:14:32.119: INFO: 3 / 3 pods ready in namespace 'kube-system' in daemonset 'calico-node' (0 seconds elapsed)
Nov  8 16:14:32.119: INFO: 3 / 3 pods ready in namespace 'kube-system' in daemonset 'kube-proxy' (0 seconds elapsed)
Nov  8 16:14:32.119: INFO: e2e test version: v1.12.2-heptio.1
Nov  8 16:14:32.120: INFO: kube-apiserver version: v1.12.2-heptio.1
SSSSS
------------------------------
[k8s.io] Probing container 
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  8 16:14:32.120: INFO: >>> kubeConfig: /tmp/kubeconfig-235977939
STEP: Building a namespace api object, basename container-probe
Nov  8 16:14:32.175: INFO: No PodSecurityPolicies found; assuming PodSecurityPolicy is disabled.
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Nov  8 16:15:04.185: INFO: Container started at 2018-11-08 16:14:39 +0000 UTC, pod became ready at 2018-11-08 16:15:02 +0000 UTC
[AfterEach] [k8s.io] Probing container
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  8 16:15:04.185: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-8qmfq" for this suite.
Nov  8 16:15:26.193: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  8 16:15:26.239: INFO: namespace: e2e-tests-container-probe-8qmfq, resource: bindings, ignored listing per whitelist
Nov  8 16:15:26.246: INFO: namespace e2e-tests-container-probe-8qmfq deletion completed in 22.05962315s

• [SLOW TEST:54.126 seconds]
[k8s.io] Probing container
/go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run deployment 
  should create a deployment from an image  [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  8 16:15:26.247: INFO: >>> kubeConfig: /tmp/kubeconfig-235977939
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Kubectl run deployment
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1347
[It] should create a deployment from an image  [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Nov  8 16:15:26.284: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-235977939 run e2e-test-nginx-deployment --image=docker.io/library/nginx:1.14-alpine --generator=deployment/v1beta1 --namespace=e2e-tests-kubectl-xtn7n'
Nov  8 16:15:26.560: INFO: stderr: "kubectl run --generator=deployment/v1beta1 is DEPRECATED and will be removed in a future version. Use kubectl create instead.\n"
Nov  8 16:15:26.560: INFO: stdout: "deployment.extensions/e2e-test-nginx-deployment created\n"
STEP: verifying the deployment e2e-test-nginx-deployment was created
STEP: verifying the pod controlled by deployment e2e-test-nginx-deployment was created
[AfterEach] [k8s.io] Kubectl run deployment
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1352
Nov  8 16:15:30.567: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-235977939 delete deployment e2e-test-nginx-deployment --namespace=e2e-tests-kubectl-xtn7n'
Nov  8 16:15:30.631: INFO: stderr: ""
Nov  8 16:15:30.631: INFO: stdout: "deployment.extensions \"e2e-test-nginx-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  8 16:15:30.631: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-xtn7n" for this suite.
Nov  8 16:15:36.640: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  8 16:15:36.668: INFO: namespace: e2e-tests-kubectl-xtn7n, resource: bindings, ignored listing per whitelist
Nov  8 16:15:36.700: INFO: namespace e2e-tests-kubectl-xtn7n deletion completed in 6.066283497s

• [SLOW TEST:10.453 seconds]
[sig-cli] Kubectl client
/go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run deployment
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create a deployment from an image  [Conformance]
    /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  8 16:15:36.700: INFO: >>> kubeConfig: /tmp/kubeconfig-235977939
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Nov  8 16:15:36.747: INFO: Waiting up to 5m0s for pod "downwardapi-volume-86d0e2e9-e371-11e8-b0fd-0e97e856486a" in namespace "e2e-tests-projected-zqhmf" to be "success or failure"
Nov  8 16:15:36.749: INFO: Pod "downwardapi-volume-86d0e2e9-e371-11e8-b0fd-0e97e856486a": Phase="Pending", Reason="", readiness=false. Elapsed: 1.677894ms
Nov  8 16:15:38.751: INFO: Pod "downwardapi-volume-86d0e2e9-e371-11e8-b0fd-0e97e856486a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.003754152s
STEP: Saw pod success
Nov  8 16:15:38.751: INFO: Pod "downwardapi-volume-86d0e2e9-e371-11e8-b0fd-0e97e856486a" satisfied condition "success or failure"
Nov  8 16:15:38.752: INFO: Trying to get logs from node ip-10-0-100-224.ec2.internal pod downwardapi-volume-86d0e2e9-e371-11e8-b0fd-0e97e856486a container client-container: <nil>
STEP: delete the pod
Nov  8 16:15:38.771: INFO: Waiting for pod downwardapi-volume-86d0e2e9-e371-11e8-b0fd-0e97e856486a to disappear
Nov  8 16:15:38.772: INFO: Pod downwardapi-volume-86d0e2e9-e371-11e8-b0fd-0e97e856486a no longer exists
[AfterEach] [sig-storage] Projected
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  8 16:15:38.773: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-zqhmf" for this suite.
Nov  8 16:15:44.779: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  8 16:15:44.795: INFO: namespace: e2e-tests-projected-zqhmf, resource: bindings, ignored listing per whitelist
Nov  8 16:15:44.833: INFO: namespace e2e-tests-projected-zqhmf deletion completed in 6.058356766s

• [SLOW TEST:8.133 seconds]
[sig-storage] Projected
/go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should provide container's cpu limit [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-api-machinery] Downward API 
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Downward API
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  8 16:15:44.833: INFO: >>> kubeConfig: /tmp/kubeconfig-235977939
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod UID as env vars [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Nov  8 16:15:44.872: INFO: Waiting up to 5m0s for pod "downward-api-8ba8a382-e371-11e8-b0fd-0e97e856486a" in namespace "e2e-tests-downward-api-cl8c5" to be "success or failure"
Nov  8 16:15:44.873: INFO: Pod "downward-api-8ba8a382-e371-11e8-b0fd-0e97e856486a": Phase="Pending", Reason="", readiness=false. Elapsed: 1.39511ms
Nov  8 16:15:46.875: INFO: Pod "downward-api-8ba8a382-e371-11e8-b0fd-0e97e856486a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.003194171s
STEP: Saw pod success
Nov  8 16:15:46.875: INFO: Pod "downward-api-8ba8a382-e371-11e8-b0fd-0e97e856486a" satisfied condition "success or failure"
Nov  8 16:15:46.877: INFO: Trying to get logs from node ip-10-0-100-224.ec2.internal pod downward-api-8ba8a382-e371-11e8-b0fd-0e97e856486a container dapi-container: <nil>
STEP: delete the pod
Nov  8 16:15:46.888: INFO: Waiting for pod downward-api-8ba8a382-e371-11e8-b0fd-0e97e856486a to disappear
Nov  8 16:15:46.892: INFO: Pod downward-api-8ba8a382-e371-11e8-b0fd-0e97e856486a no longer exists
[AfterEach] [sig-api-machinery] Downward API
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  8 16:15:46.892: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-cl8c5" for this suite.
Nov  8 16:15:52.899: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  8 16:15:52.904: INFO: namespace: e2e-tests-downward-api-cl8c5, resource: bindings, ignored listing per whitelist
Nov  8 16:15:52.953: INFO: namespace e2e-tests-downward-api-cl8c5 deletion completed in 6.058985458s

• [SLOW TEST:8.120 seconds]
[sig-api-machinery] Downward API
/go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  8 16:15:52.953: INFO: >>> kubeConfig: /tmp/kubeconfig-235977939
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
Nov  8 16:15:52.991: INFO: PodSpec: initContainers in spec.initContainers
Nov  8 16:16:38.972: INFO: init container has failed twice: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-init-907ff894-e371-11e8-b0fd-0e97e856486a", GenerateName:"", Namespace:"e2e-tests-init-container-7c29b", SelfLink:"/api/v1/namespaces/e2e-tests-init-container-7c29b/pods/pod-init-907ff894-e371-11e8-b0fd-0e97e856486a", UID:"90803d2f-e371-11e8-a466-0a0beb0244cc", ResourceVersion:"6931", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63677290552, loc:(*time.Location)(0x6c10bc0)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"991556837"}, Annotations:map[string]string{"cni.projectcalico.org/podIP":"192.168.1.8/32"}, OwnerReferences:[]v1.OwnerReference(nil), Initializers:(*v1.Initializers)(nil), Finalizers:[]string(nil), ClusterName:""}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"default-token-fzlvf", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(0xc420f20900), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil)}}}, InitContainers:[]v1.Container{v1.Container{Name:"init1", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/false"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-fzlvf", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}, v1.Container{Name:"init2", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/true"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-fzlvf", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, Containers:[]v1.Container{v1.Container{Name:"run1", Image:"k8s.gcr.io/pause:3.1", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}, Requests:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-fzlvf", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc420fbfeb8), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"ip-10-0-100-224.ec2.internal", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc420e58d80), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc420fbff30)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc420fbff50)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc420fbff58), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil)}, Status:v1.PodStatus{Phase:"Pending", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63677290553, loc:(*time.Location)(0x6c10bc0)}}, Reason:"ContainersNotInitialized", Message:"containers with incomplete status: [init1 init2]"}, v1.PodCondition{Type:"Ready", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63677290553, loc:(*time.Location)(0x6c10bc0)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"ContainersReady", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63677290553, loc:(*time.Location)(0x6c10bc0)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63677290552, loc:(*time.Location)(0x6c10bc0)}}, Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"10.0.100.224", PodIP:"192.168.1.8", StartTime:(*v1.Time)(0xc421448b80), InitContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"init1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc42272fe30)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc42272fea0)}, Ready:false, RestartCount:3, Image:"busybox:1.29", ImageID:"docker-pullable://busybox@sha256:2a03a6059f21e150ae84b0973863609494aad70f0a80eaeb64bddd8d92465812", ContainerID:"docker://e2d928113a75a1354755333f9bc636757e709282fd2f376c9e469588b744634a"}, v1.ContainerStatus{Name:"init2", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc421448bc0), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"docker.io/library/busybox:1.29", ImageID:"", ContainerID:""}}, ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"run1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc421448ba0), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"k8s.gcr.io/pause:3.1", ImageID:"", ContainerID:""}}, QOSClass:"Guaranteed"}}
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  8 16:16:38.972: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-init-container-7c29b" for this suite.
Nov  8 16:17:00.980: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  8 16:17:01.005: INFO: namespace: e2e-tests-init-container-7c29b, resource: bindings, ignored listing per whitelist
Nov  8 16:17:01.033: INFO: namespace e2e-tests-init-container-7c29b deletion completed in 22.05826103s

• [SLOW TEST:68.080 seconds]
[k8s.io] InitContainer [NodeConformance]
/go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-api-machinery] Watchers 
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Watchers
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  8 16:17:01.033: INFO: >>> kubeConfig: /tmp/kubeconfig-235977939
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a watch on configmaps with a certain label
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: changing the label value of the configmap
STEP: Expecting to observe a delete notification for the watched object
Nov  8 16:17:01.079: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-97wqv,SelfLink:/api/v1/namespaces/e2e-tests-watch-97wqv/configmaps/e2e-watch-test-label-changed,UID:b914579e-e371-11e8-a466-0a0beb0244cc,ResourceVersion:6982,Generation:0,CreationTimestamp:2018-11-08 16:17:01 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Nov  8 16:17:01.079: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-97wqv,SelfLink:/api/v1/namespaces/e2e-tests-watch-97wqv/configmaps/e2e-watch-test-label-changed,UID:b914579e-e371-11e8-a466-0a0beb0244cc,ResourceVersion:6983,Generation:0,CreationTimestamp:2018-11-08 16:17:01 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Nov  8 16:17:01.079: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-97wqv,SelfLink:/api/v1/namespaces/e2e-tests-watch-97wqv/configmaps/e2e-watch-test-label-changed,UID:b914579e-e371-11e8-a466-0a0beb0244cc,ResourceVersion:6984,Generation:0,CreationTimestamp:2018-11-08 16:17:01 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time
STEP: Expecting not to observe a notification because the object no longer meets the selector's requirements
STEP: changing the label value of the configmap back
STEP: modifying the configmap a third time
STEP: deleting the configmap
STEP: Expecting to observe an add notification for the watched object when the label value was restored
Nov  8 16:17:11.090: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-97wqv,SelfLink:/api/v1/namespaces/e2e-tests-watch-97wqv/configmaps/e2e-watch-test-label-changed,UID:b914579e-e371-11e8-a466-0a0beb0244cc,ResourceVersion:7000,Generation:0,CreationTimestamp:2018-11-08 16:17:01 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Nov  8 16:17:11.090: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-97wqv,SelfLink:/api/v1/namespaces/e2e-tests-watch-97wqv/configmaps/e2e-watch-test-label-changed,UID:b914579e-e371-11e8-a466-0a0beb0244cc,ResourceVersion:7001,Generation:0,CreationTimestamp:2018-11-08 16:17:01 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
Nov  8 16:17:11.090: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-97wqv,SelfLink:/api/v1/namespaces/e2e-tests-watch-97wqv/configmaps/e2e-watch-test-label-changed,UID:b914579e-e371-11e8-a466-0a0beb0244cc,ResourceVersion:7002,Generation:0,CreationTimestamp:2018-11-08 16:17:01 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  8 16:17:11.090: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-97wqv" for this suite.
Nov  8 16:17:17.097: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  8 16:17:17.110: INFO: namespace: e2e-tests-watch-97wqv, resource: bindings, ignored listing per whitelist
Nov  8 16:17:17.153: INFO: namespace e2e-tests-watch-97wqv deletion completed in 6.061650567s

• [SLOW TEST:16.121 seconds]
[sig-api-machinery] Watchers
/go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Guestbook application 
  should create and stop a working application  [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  8 16:17:17.153: INFO: >>> kubeConfig: /tmp/kubeconfig-235977939
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should create and stop a working application  [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating all guestbook components
Nov  8 16:17:17.195: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-slave
  labels:
    app: redis
    role: slave
    tier: backend
spec:
  ports:
  - port: 6379
  selector:
    app: redis
    role: slave
    tier: backend

Nov  8 16:17:17.195: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-235977939 create -f - --namespace=e2e-tests-kubectl-9s7wv'
Nov  8 16:17:17.355: INFO: stderr: ""
Nov  8 16:17:17.355: INFO: stdout: "service/redis-slave created\n"
Nov  8 16:17:17.355: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-master
  labels:
    app: redis
    role: master
    tier: backend
spec:
  ports:
  - port: 6379
    targetPort: 6379
  selector:
    app: redis
    role: master
    tier: backend

Nov  8 16:17:17.355: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-235977939 create -f - --namespace=e2e-tests-kubectl-9s7wv'
Nov  8 16:17:17.491: INFO: stderr: ""
Nov  8 16:17:17.491: INFO: stdout: "service/redis-master created\n"
Nov  8 16:17:17.491: INFO: apiVersion: v1
kind: Service
metadata:
  name: frontend
  labels:
    app: guestbook
    tier: frontend
spec:
  # if your cluster supports it, uncomment the following to automatically create
  # an external load-balanced IP for the frontend service.
  # type: LoadBalancer
  ports:
  - port: 80
  selector:
    app: guestbook
    tier: frontend

Nov  8 16:17:17.491: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-235977939 create -f - --namespace=e2e-tests-kubectl-9s7wv'
Nov  8 16:17:17.770: INFO: stderr: ""
Nov  8 16:17:17.770: INFO: stdout: "service/frontend created\n"
Nov  8 16:17:17.770: INFO: apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: frontend
spec:
  replicas: 3
  template:
    metadata:
      labels:
        app: guestbook
        tier: frontend
    spec:
      containers:
      - name: php-redis
        image: gcr.io/google-samples/gb-frontend:v6
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access environment variables to find service host
          # info, comment out the 'value: dns' line above, and uncomment the
          # line below:
          # value: env
        ports:
        - containerPort: 80

Nov  8 16:17:17.770: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-235977939 create -f - --namespace=e2e-tests-kubectl-9s7wv'
Nov  8 16:17:17.904: INFO: stderr: ""
Nov  8 16:17:17.905: INFO: stdout: "deployment.extensions/frontend created\n"
Nov  8 16:17:17.905: INFO: apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: redis-master
spec:
  replicas: 1
  template:
    metadata:
      labels:
        app: redis
        role: master
        tier: backend
    spec:
      containers:
      - name: master
        image: gcr.io/kubernetes-e2e-test-images/redis:1.0
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        ports:
        - containerPort: 6379

Nov  8 16:17:17.905: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-235977939 create -f - --namespace=e2e-tests-kubectl-9s7wv'
Nov  8 16:17:18.038: INFO: stderr: ""
Nov  8 16:17:18.038: INFO: stdout: "deployment.extensions/redis-master created\n"
Nov  8 16:17:18.038: INFO: apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: redis-slave
spec:
  replicas: 2
  template:
    metadata:
      labels:
        app: redis
        role: slave
        tier: backend
    spec:
      containers:
      - name: slave
        image: gcr.io/google-samples/gb-redisslave:v3
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access an environment variable to find the master
          # service's host, comment out the 'value: dns' line above, and
          # uncomment the line below:
          # value: env
        ports:
        - containerPort: 6379

Nov  8 16:17:18.038: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-235977939 create -f - --namespace=e2e-tests-kubectl-9s7wv'
Nov  8 16:17:18.172: INFO: stderr: ""
Nov  8 16:17:18.172: INFO: stdout: "deployment.extensions/redis-slave created\n"
STEP: validating guestbook app
Nov  8 16:17:18.172: INFO: Waiting for all frontend pods to be Running.
Nov  8 16:17:33.223: INFO: Waiting for frontend to serve content.
Nov  8 16:17:33.232: INFO: Trying to add a new entry to the guestbook.
Nov  8 16:17:33.240: INFO: Verifying that added entry can be retrieved.
Nov  8 16:17:33.247: INFO: Failed to get response from guestbook. err: <nil>, response: {"data": ""}
STEP: using delete to clean up resources
Nov  8 16:17:38.256: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-235977939 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-9s7wv'
Nov  8 16:17:38.327: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Nov  8 16:17:38.327: INFO: stdout: "service \"redis-slave\" force deleted\n"
STEP: using delete to clean up resources
Nov  8 16:17:38.327: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-235977939 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-9s7wv'
Nov  8 16:17:38.411: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Nov  8 16:17:38.411: INFO: stdout: "service \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
Nov  8 16:17:38.411: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-235977939 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-9s7wv'
Nov  8 16:17:38.488: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Nov  8 16:17:38.489: INFO: stdout: "service \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Nov  8 16:17:38.489: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-235977939 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-9s7wv'
Nov  8 16:17:38.564: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Nov  8 16:17:38.564: INFO: stdout: "deployment.extensions \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Nov  8 16:17:38.564: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-235977939 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-9s7wv'
Nov  8 16:17:38.639: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Nov  8 16:17:38.639: INFO: stdout: "deployment.extensions \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
Nov  8 16:17:38.639: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-235977939 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-9s7wv'
Nov  8 16:17:38.718: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Nov  8 16:17:38.718: INFO: stdout: "deployment.extensions \"redis-slave\" force deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  8 16:17:38.718: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-9s7wv" for this suite.
Nov  8 16:18:22.729: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  8 16:18:22.754: INFO: namespace: e2e-tests-kubectl-9s7wv, resource: bindings, ignored listing per whitelist
Nov  8 16:18:22.782: INFO: namespace e2e-tests-kubectl-9s7wv deletion completed in 44.061932157s

• [SLOW TEST:65.629 seconds]
[sig-cli] Kubectl client
/go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Guestbook application
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create and stop a working application  [Conformance]
    /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if not matching  [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  8 16:18:22.782: INFO: >>> kubeConfig: /tmp/kubeconfig-235977939
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:78
Nov  8 16:18:22.819: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Nov  8 16:18:22.822: INFO: Waiting for terminating namespaces to be deleted...
Nov  8 16:18:22.824: INFO: 
Logging pods the kubelet thinks is on node ip-10-0-100-224.ec2.internal before test
Nov  8 16:18:22.827: INFO: coredns-58b9b74789-5dxgw from kube-system started at 2018-11-08 15:08:16 +0000 UTC (1 container statuses recorded)
Nov  8 16:18:22.827: INFO: 	Container coredns ready: true, restart count 0
Nov  8 16:18:22.827: INFO: coredns-58b9b74789-j5cfk from kube-system started at 2018-11-08 15:08:16 +0000 UTC (1 container statuses recorded)
Nov  8 16:18:22.827: INFO: 	Container coredns ready: true, restart count 0
Nov  8 16:18:22.827: INFO: sonobuoy-systemd-logs-daemon-set-0aa241421f524e19-hj57d from heptio-sonobuoy started at 2018-11-08 16:14:30 +0000 UTC (2 container statuses recorded)
Nov  8 16:18:22.827: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 0
Nov  8 16:18:22.827: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Nov  8 16:18:22.827: INFO: calico-node-v8sh8 from kube-system started at 2018-11-08 15:08:16 +0000 UTC (2 container statuses recorded)
Nov  8 16:18:22.827: INFO: 	Container calico-node ready: true, restart count 0
Nov  8 16:18:22.827: INFO: 	Container install-cni ready: true, restart count 0
Nov  8 16:18:22.827: INFO: kube-proxy-5cl7l from kube-system started at 2018-11-08 15:08:16 +0000 UTC (1 container statuses recorded)
Nov  8 16:18:22.827: INFO: 	Container kube-proxy ready: true, restart count 0
Nov  8 16:18:22.827: INFO: 
Logging pods the kubelet thinks is on node ip-10-0-100-254.ec2.internal before test
Nov  8 16:18:22.831: INFO: sonobuoy from heptio-sonobuoy started at 2018-11-08 16:14:27 +0000 UTC (1 container statuses recorded)
Nov  8 16:18:22.831: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Nov  8 16:18:22.831: INFO: sonobuoy-e2e-job-25912574a04a48fb from heptio-sonobuoy started at 2018-11-08 16:14:30 +0000 UTC (2 container statuses recorded)
Nov  8 16:18:22.831: INFO: 	Container e2e ready: true, restart count 0
Nov  8 16:18:22.831: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Nov  8 16:18:22.831: INFO: sonobuoy-systemd-logs-daemon-set-0aa241421f524e19-7g4zn from heptio-sonobuoy started at 2018-11-08 16:14:30 +0000 UTC (2 container statuses recorded)
Nov  8 16:18:22.831: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 0
Nov  8 16:18:22.831: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Nov  8 16:18:22.831: INFO: calico-node-664xs from kube-system started at 2018-11-08 15:08:18 +0000 UTC (2 container statuses recorded)
Nov  8 16:18:22.831: INFO: 	Container calico-node ready: true, restart count 0
Nov  8 16:18:22.831: INFO: 	Container install-cni ready: true, restart count 0
Nov  8 16:18:22.831: INFO: kube-proxy-b44s9 from kube-system started at 2018-11-08 15:08:18 +0000 UTC (1 container statuses recorded)
Nov  8 16:18:22.831: INFO: 	Container kube-proxy ready: true, restart count 0
[It] validates that NodeSelector is respected if not matching  [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Trying to schedule Pod with nonempty NodeSelector.
STEP: Considering event: 
Type = [Warning], Name = [restricted-pod.1565326fb731ad97], Reason = [FailedScheduling], Message = [0/3 nodes are available: 3 node(s) didn't match node selector.]
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  8 16:18:23.842: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-sched-pred-r86kb" for this suite.
Nov  8 16:18:29.849: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  8 16:18:29.898: INFO: namespace: e2e-tests-sched-pred-r86kb, resource: bindings, ignored listing per whitelist
Nov  8 16:18:29.900: INFO: namespace e2e-tests-sched-pred-r86kb deletion completed in 6.05698586s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:69

• [SLOW TEST:7.118 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates that NodeSelector is respected if not matching  [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl patch 
  should add annotations for pods in rc  [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  8 16:18:29.901: INFO: >>> kubeConfig: /tmp/kubeconfig-235977939
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should add annotations for pods in rc  [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating Redis RC
Nov  8 16:18:29.937: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-235977939 create -f - --namespace=e2e-tests-kubectl-2kpp7'
Nov  8 16:18:30.082: INFO: stderr: ""
Nov  8 16:18:30.082: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
Nov  8 16:18:31.085: INFO: Selector matched 1 pods for map[app:redis]
Nov  8 16:18:31.085: INFO: Found 0 / 1
Nov  8 16:18:32.084: INFO: Selector matched 1 pods for map[app:redis]
Nov  8 16:18:32.084: INFO: Found 1 / 1
Nov  8 16:18:32.084: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
STEP: patching all pods
Nov  8 16:18:32.086: INFO: Selector matched 1 pods for map[app:redis]
Nov  8 16:18:32.086: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Nov  8 16:18:32.086: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-235977939 patch pod redis-master-p8xg4 --namespace=e2e-tests-kubectl-2kpp7 -p {"metadata":{"annotations":{"x":"y"}}}'
Nov  8 16:18:32.154: INFO: stderr: ""
Nov  8 16:18:32.154: INFO: stdout: "pod/redis-master-p8xg4 patched\n"
STEP: checking annotations
Nov  8 16:18:32.155: INFO: Selector matched 1 pods for map[app:redis]
Nov  8 16:18:32.155: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
[AfterEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  8 16:18:32.155: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-2kpp7" for this suite.
Nov  8 16:18:54.162: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  8 16:18:54.179: INFO: namespace: e2e-tests-kubectl-2kpp7, resource: bindings, ignored listing per whitelist
Nov  8 16:18:54.216: INFO: namespace e2e-tests-kubectl-2kpp7 deletion completed in 22.058763173s

• [SLOW TEST:24.315 seconds]
[sig-cli] Kubectl client
/go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl patch
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should add annotations for pods in rc  [Conformance]
    /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should update annotations on modification [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  8 16:18:54.216: INFO: >>> kubeConfig: /tmp/kubeconfig-235977939
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should update annotations on modification [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating the pod
Nov  8 16:18:56.772: INFO: Successfully updated pod "annotationupdatefc8a5974-e371-11e8-b0fd-0e97e856486a"
[AfterEach] [sig-storage] Downward API volume
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  8 16:19:00.786: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-zkrjq" for this suite.
Nov  8 16:19:22.795: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  8 16:19:22.827: INFO: namespace: e2e-tests-downward-api-zkrjq, resource: bindings, ignored listing per whitelist
Nov  8 16:19:22.850: INFO: namespace e2e-tests-downward-api-zkrjq deletion completed in 22.059735447s

• [SLOW TEST:28.634 seconds]
[sig-storage] Downward API volume
/go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should update annotations on modification [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl cluster-info 
  should check if Kubernetes master services is included in cluster-info  [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  8 16:19:22.850: INFO: >>> kubeConfig: /tmp/kubeconfig-235977939
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should check if Kubernetes master services is included in cluster-info  [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: validating cluster-info
Nov  8 16:19:22.887: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-235977939 cluster-info'
Nov  8 16:19:22.948: INFO: stderr: ""
Nov  8 16:19:22.948: INFO: stdout: "\x1b[0;32mKubernetes master\x1b[0m is running at \x1b[0;33mhttps://10.96.0.1:443\x1b[0m\n\x1b[0;32mKubeDNS\x1b[0m is running at \x1b[0;33mhttps://10.96.0.1:443/api/v1/namespaces/kube-system/services/kube-dns:dns/proxy\x1b[0m\n\nTo further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.\n"
[AfterEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  8 16:19:22.948: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-8jdmj" for this suite.
Nov  8 16:19:28.955: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  8 16:19:28.990: INFO: namespace: e2e-tests-kubectl-8jdmj, resource: bindings, ignored listing per whitelist
Nov  8 16:19:29.007: INFO: namespace e2e-tests-kubectl-8jdmj deletion completed in 6.056827801s

• [SLOW TEST:6.157 seconds]
[sig-cli] Kubectl client
/go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl cluster-info
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should check if Kubernetes master services is included in cluster-info  [Conformance]
    /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  8 16:19:29.007: INFO: >>> kubeConfig: /tmp/kubeconfig-235977939
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [k8s.io] Probing container
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  8 16:20:29.046: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-dgxt2" for this suite.
Nov  8 16:20:51.055: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  8 16:20:51.072: INFO: namespace: e2e-tests-container-probe-dgxt2, resource: bindings, ignored listing per whitelist
Nov  8 16:20:51.108: INFO: namespace e2e-tests-container-probe-dgxt2 deletion completed in 22.059779385s

• [SLOW TEST:82.101 seconds]
[k8s.io] Probing container
/go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should support rollover [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  8 16:20:51.108: INFO: >>> kubeConfig: /tmp/kubeconfig-235977939
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should support rollover [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Nov  8 16:20:51.149: INFO: Pod name rollover-pod: Found 0 pods out of 1
Nov  8 16:20:56.151: INFO: Pod name rollover-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Nov  8 16:20:56.151: INFO: Waiting for pods owned by replica set "test-rollover-controller" to become ready
Nov  8 16:20:58.153: INFO: Creating deployment "test-rollover-deployment"
Nov  8 16:20:58.157: INFO: Make sure deployment "test-rollover-deployment" performs scaling operations
Nov  8 16:21:00.160: INFO: Check revision of new replica set for deployment "test-rollover-deployment"
Nov  8 16:21:00.163: INFO: Ensure that both replica sets have 1 created replica
Nov  8 16:21:00.166: INFO: Rollover old replica sets for deployment "test-rollover-deployment" with new image update
Nov  8 16:21:00.169: INFO: Updating deployment test-rollover-deployment
Nov  8 16:21:00.169: INFO: Wait deployment "test-rollover-deployment" to be observed by the deployment controller
Nov  8 16:21:02.172: INFO: Wait for revision update of deployment "test-rollover-deployment" to 2
Nov  8 16:21:02.175: INFO: Make sure deployment "test-rollover-deployment" is complete
Nov  8 16:21:02.178: INFO: all replica sets need to contain the pod-template-hash label
Nov  8 16:21:02.178: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63677290858, loc:(*time.Location)(0x6c10bc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63677290858, loc:(*time.Location)(0x6c10bc0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63677290861, loc:(*time.Location)(0x6c10bc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63677290858, loc:(*time.Location)(0x6c10bc0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-5b76ff8c4\" is progressing."}}, CollisionCount:(*int32)(nil)}
Nov  8 16:21:04.182: INFO: all replica sets need to contain the pod-template-hash label
Nov  8 16:21:04.182: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63677290858, loc:(*time.Location)(0x6c10bc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63677290858, loc:(*time.Location)(0x6c10bc0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63677290861, loc:(*time.Location)(0x6c10bc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63677290858, loc:(*time.Location)(0x6c10bc0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-5b76ff8c4\" is progressing."}}, CollisionCount:(*int32)(nil)}
Nov  8 16:21:06.182: INFO: all replica sets need to contain the pod-template-hash label
Nov  8 16:21:06.182: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63677290858, loc:(*time.Location)(0x6c10bc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63677290858, loc:(*time.Location)(0x6c10bc0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63677290861, loc:(*time.Location)(0x6c10bc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63677290858, loc:(*time.Location)(0x6c10bc0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-5b76ff8c4\" is progressing."}}, CollisionCount:(*int32)(nil)}
Nov  8 16:21:08.182: INFO: all replica sets need to contain the pod-template-hash label
Nov  8 16:21:08.182: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63677290858, loc:(*time.Location)(0x6c10bc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63677290858, loc:(*time.Location)(0x6c10bc0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63677290861, loc:(*time.Location)(0x6c10bc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63677290858, loc:(*time.Location)(0x6c10bc0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-5b76ff8c4\" is progressing."}}, CollisionCount:(*int32)(nil)}
Nov  8 16:21:10.182: INFO: all replica sets need to contain the pod-template-hash label
Nov  8 16:21:10.182: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63677290858, loc:(*time.Location)(0x6c10bc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63677290858, loc:(*time.Location)(0x6c10bc0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63677290861, loc:(*time.Location)(0x6c10bc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63677290858, loc:(*time.Location)(0x6c10bc0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-5b76ff8c4\" is progressing."}}, CollisionCount:(*int32)(nil)}
Nov  8 16:21:12.182: INFO: 
Nov  8 16:21:12.182: INFO: Ensure that both old replica sets have no replicas
[AfterEach] [sig-apps] Deployment
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Nov  8 16:21:12.186: INFO: Deployment "test-rollover-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment,GenerateName:,Namespace:e2e-tests-deployment-tr2ws,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-tr2ws/deployments/test-rollover-deployment,UID:46641a0a-e372-11e8-a466-0a0beb0244cc,ResourceVersion:7756,Generation:2,CreationTimestamp:2018-11-08 16:20:58 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:0,MaxSurge:1,},},MinReadySeconds:10,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[{Available True 2018-11-08 16:20:58 +0000 UTC 2018-11-08 16:20:58 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2018-11-08 16:21:11 +0000 UTC 2018-11-08 16:20:58 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-rollover-deployment-5b76ff8c4" has successfully progressed.}],ReadyReplicas:1,CollisionCount:nil,},}

Nov  8 16:21:12.188: INFO: New ReplicaSet "test-rollover-deployment-5b76ff8c4" of Deployment "test-rollover-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-5b76ff8c4,GenerateName:,Namespace:e2e-tests-deployment-tr2ws,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-tr2ws/replicasets/test-rollover-deployment-5b76ff8c4,UID:4797cf31-e372-11e8-a466-0a0beb0244cc,ResourceVersion:7747,Generation:2,CreationTimestamp:2018-11-08 16:21:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 5b76ff8c4,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment 46641a0a-e372-11e8-a466-0a0beb0244cc 0xc422556227 0xc422556228}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 5b76ff8c4,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 5b76ff8c4,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:2,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Nov  8 16:21:12.188: INFO: All old ReplicaSets of Deployment "test-rollover-deployment":
Nov  8 16:21:12.188: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-controller,GenerateName:,Namespace:e2e-tests-deployment-tr2ws,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-tr2ws/replicasets/test-rollover-controller,UID:4236d208-e372-11e8-a466-0a0beb0244cc,ResourceVersion:7755,Generation:2,CreationTimestamp:2018-11-08 16:20:51 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod: nginx,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment 46641a0a-e372-11e8-a466-0a0beb0244cc 0xc422556167 0xc422556168}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Nov  8 16:21:12.188: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-6975f4fb87,GenerateName:,Namespace:e2e-tests-deployment-tr2ws,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-tr2ws/replicasets/test-rollover-deployment-6975f4fb87,UID:4665a1b0-e372-11e8-a466-0a0beb0244cc,ResourceVersion:7719,Generation:2,CreationTimestamp:2018-11-08 16:20:58 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6975f4fb87,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment 46641a0a-e372-11e8-a466-0a0beb0244cc 0xc4225562e7 0xc4225562e8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 6975f4fb87,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6975f4fb87,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis-slave gcr.io/google_samples/gb-redisslave:nonexistent [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Nov  8 16:21:12.189: INFO: Pod "test-rollover-deployment-5b76ff8c4-kzlqr" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-5b76ff8c4-kzlqr,GenerateName:test-rollover-deployment-5b76ff8c4-,Namespace:e2e-tests-deployment-tr2ws,SelfLink:/api/v1/namespaces/e2e-tests-deployment-tr2ws/pods/test-rollover-deployment-5b76ff8c4-kzlqr,UID:4799b2c5-e372-11e8-a466-0a0beb0244cc,ResourceVersion:7730,Generation:0,CreationTimestamp:2018-11-08 16:21:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 5b76ff8c4,},Annotations:map[string]string{cni.projectcalico.org/podIP: 192.168.1.18/32,},OwnerReferences:[{apps/v1 ReplicaSet test-rollover-deployment-5b76ff8c4 4797cf31-e372-11e8-a466-0a0beb0244cc 0xc422556dc0 0xc422556dc1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-hnzlf {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-hnzlf,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-hnzlf true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-100-224.ec2.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc422556e20} {node.kubernetes.io/unreachable Exists  NoExecute 0xc422556e40}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-11-08 16:21:00 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-11-08 16:21:01 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2018-11-08 16:21:01 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-11-08 16:21:00 +0000 UTC  }],Message:,Reason:,HostIP:10.0.100.224,PodIP:192.168.1.18,StartTime:2018-11-08 16:21:00 +0000 UTC,ContainerStatuses:[{redis {nil ContainerStateRunning{StartedAt:2018-11-08 16:21:00 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/redis:1.0 docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830 docker://9dfdabf0775ee83cdfc03bf3ddfdd92b6c44daee08671c4a47ba8e1d9c457c03}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  8 16:21:12.189: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-tr2ws" for this suite.
Nov  8 16:21:18.196: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  8 16:21:18.231: INFO: namespace: e2e-tests-deployment-tr2ws, resource: bindings, ignored listing per whitelist
Nov  8 16:21:18.249: INFO: namespace e2e-tests-deployment-tr2ws deletion completed in 6.058061874s

• [SLOW TEST:27.141 seconds]
[sig-apps] Deployment
/go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  deployment should support rollover [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl rolling-update 
  should support rolling-update to same image  [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  8 16:21:18.249: INFO: >>> kubeConfig: /tmp/kubeconfig-235977939
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Kubectl rolling-update
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1306
[It] should support rolling-update to same image  [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Nov  8 16:21:18.287: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-235977939 run e2e-test-nginx-rc --image=docker.io/library/nginx:1.14-alpine --generator=run/v1 --namespace=e2e-tests-kubectl-p2rnz'
Nov  8 16:21:18.355: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl create instead.\n"
Nov  8 16:21:18.355: INFO: stdout: "replicationcontroller/e2e-test-nginx-rc created\n"
STEP: verifying the rc e2e-test-nginx-rc was created
Nov  8 16:21:18.360: INFO: Waiting for rc e2e-test-nginx-rc to stabilize, generation 1 observed generation 1 spec.replicas 1 status.replicas 0
STEP: rolling-update to same image controller
Nov  8 16:21:18.365: INFO: scanned /root for discovery docs: <nil>
Nov  8 16:21:18.365: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-235977939 rolling-update e2e-test-nginx-rc --update-period=1s --image=docker.io/library/nginx:1.14-alpine --image-pull-policy=IfNotPresent --namespace=e2e-tests-kubectl-p2rnz'
Nov  8 16:21:34.080: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Nov  8 16:21:34.080: INFO: stdout: "Created e2e-test-nginx-rc-a296bb830e6c87b66758aaf8b7d09cd3\nScaling up e2e-test-nginx-rc-a296bb830e6c87b66758aaf8b7d09cd3 from 0 to 1, scaling down e2e-test-nginx-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-nginx-rc-a296bb830e6c87b66758aaf8b7d09cd3 up to 1\nScaling e2e-test-nginx-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-nginx-rc\nRenaming e2e-test-nginx-rc-a296bb830e6c87b66758aaf8b7d09cd3 to e2e-test-nginx-rc\nreplicationcontroller/e2e-test-nginx-rc rolling updated\n"
Nov  8 16:21:34.080: INFO: stdout: "Created e2e-test-nginx-rc-a296bb830e6c87b66758aaf8b7d09cd3\nScaling up e2e-test-nginx-rc-a296bb830e6c87b66758aaf8b7d09cd3 from 0 to 1, scaling down e2e-test-nginx-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-nginx-rc-a296bb830e6c87b66758aaf8b7d09cd3 up to 1\nScaling e2e-test-nginx-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-nginx-rc\nRenaming e2e-test-nginx-rc-a296bb830e6c87b66758aaf8b7d09cd3 to e2e-test-nginx-rc\nreplicationcontroller/e2e-test-nginx-rc rolling updated\n"
STEP: waiting for all containers in run=e2e-test-nginx-rc pods to come up.
Nov  8 16:21:34.080: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-235977939 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l run=e2e-test-nginx-rc --namespace=e2e-tests-kubectl-p2rnz'
Nov  8 16:21:34.145: INFO: stderr: ""
Nov  8 16:21:34.145: INFO: stdout: "e2e-test-nginx-rc-a296bb830e6c87b66758aaf8b7d09cd3-gsvm6 "
Nov  8 16:21:34.145: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-235977939 get pods e2e-test-nginx-rc-a296bb830e6c87b66758aaf8b7d09cd3-gsvm6 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "e2e-test-nginx-rc") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-p2rnz'
Nov  8 16:21:34.205: INFO: stderr: ""
Nov  8 16:21:34.205: INFO: stdout: "true"
Nov  8 16:21:34.205: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-235977939 get pods e2e-test-nginx-rc-a296bb830e6c87b66758aaf8b7d09cd3-gsvm6 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "e2e-test-nginx-rc"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-p2rnz'
Nov  8 16:21:34.264: INFO: stderr: ""
Nov  8 16:21:34.264: INFO: stdout: "nginx:1.14-alpine"
Nov  8 16:21:34.264: INFO: e2e-test-nginx-rc-a296bb830e6c87b66758aaf8b7d09cd3-gsvm6 is verified up and running
[AfterEach] [k8s.io] Kubectl rolling-update
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1312
Nov  8 16:21:34.264: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-235977939 delete rc e2e-test-nginx-rc --namespace=e2e-tests-kubectl-p2rnz'
Nov  8 16:21:34.327: INFO: stderr: ""
Nov  8 16:21:34.328: INFO: stdout: "replicationcontroller \"e2e-test-nginx-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  8 16:21:34.328: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-p2rnz" for this suite.
Nov  8 16:21:56.336: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  8 16:21:56.388: INFO: namespace: e2e-tests-kubectl-p2rnz, resource: bindings, ignored listing per whitelist
Nov  8 16:21:56.391: INFO: namespace e2e-tests-kubectl-p2rnz deletion completed in 22.061126922s

• [SLOW TEST:38.142 seconds]
[sig-cli] Kubectl client
/go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl rolling-update
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should support rolling-update to same image  [Conformance]
    /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet 
  should serve a basic image on each replica with a public image  [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] ReplicaSet
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  8 16:21:56.392: INFO: >>> kubeConfig: /tmp/kubeconfig-235977939
STEP: Building a namespace api object, basename replicaset
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Nov  8 16:21:56.429: INFO: Creating ReplicaSet my-hostname-basic-69202159-e372-11e8-b0fd-0e97e856486a
Nov  8 16:21:56.432: INFO: Pod name my-hostname-basic-69202159-e372-11e8-b0fd-0e97e856486a: Found 0 pods out of 1
Nov  8 16:22:01.434: INFO: Pod name my-hostname-basic-69202159-e372-11e8-b0fd-0e97e856486a: Found 1 pods out of 1
Nov  8 16:22:01.434: INFO: Ensuring a pod for ReplicaSet "my-hostname-basic-69202159-e372-11e8-b0fd-0e97e856486a" is running
Nov  8 16:22:01.436: INFO: Pod "my-hostname-basic-69202159-e372-11e8-b0fd-0e97e856486a-7zs8g" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2018-11-08 16:21:56 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2018-11-08 16:21:58 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2018-11-08 16:21:58 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2018-11-08 16:21:56 +0000 UTC Reason: Message:}])
Nov  8 16:22:01.436: INFO: Trying to dial the pod
Nov  8 16:22:06.442: INFO: Controller my-hostname-basic-69202159-e372-11e8-b0fd-0e97e856486a: Got expected result from replica 1 [my-hostname-basic-69202159-e372-11e8-b0fd-0e97e856486a-7zs8g]: "my-hostname-basic-69202159-e372-11e8-b0fd-0e97e856486a-7zs8g", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicaSet
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  8 16:22:06.442: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-replicaset-fl2t2" for this suite.
Nov  8 16:22:12.449: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  8 16:22:12.455: INFO: namespace: e2e-tests-replicaset-fl2t2, resource: bindings, ignored listing per whitelist
Nov  8 16:22:12.502: INFO: namespace e2e-tests-replicaset-fl2t2 deletion completed in 6.058368353s

• [SLOW TEST:16.111 seconds]
[sig-apps] ReplicaSet
/go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should serve a basic image on each replica with a public image  [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl api-versions 
  should check if v1 is in available api versions  [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  8 16:22:12.502: INFO: >>> kubeConfig: /tmp/kubeconfig-235977939
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should check if v1 is in available api versions  [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: validating api versions
Nov  8 16:22:12.541: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-235977939 api-versions'
Nov  8 16:22:12.604: INFO: stderr: ""
Nov  8 16:22:12.604: INFO: stdout: "admissionregistration.k8s.io/v1beta1\napiextensions.k8s.io/v1beta1\napiregistration.k8s.io/v1\napiregistration.k8s.io/v1beta1\napps/v1\napps/v1beta1\napps/v1beta2\nark.heptio.com/v1\nauthentication.k8s.io/v1\nauthentication.k8s.io/v1beta1\nauthorization.k8s.io/v1\nauthorization.k8s.io/v1beta1\nautoscaling/v1\nautoscaling/v2beta1\nautoscaling/v2beta2\nbatch/v1\nbatch/v1beta1\ncertificates.k8s.io/v1beta1\ncoordination.k8s.io/v1beta1\ncrd.projectcalico.org/v1\nevents.k8s.io/v1beta1\nextensions/v1beta1\nnetworking.k8s.io/v1\npolicy/v1beta1\nrbac.authorization.k8s.io/v1\nrbac.authorization.k8s.io/v1beta1\nscheduling.k8s.io/v1beta1\nstorage.k8s.io/v1\nstorage.k8s.io/v1beta1\nv1\n"
[AfterEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  8 16:22:12.604: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-b5nct" for this suite.
Nov  8 16:22:18.617: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  8 16:22:18.627: INFO: namespace: e2e-tests-kubectl-b5nct, resource: bindings, ignored listing per whitelist
Nov  8 16:22:18.669: INFO: namespace e2e-tests-kubectl-b5nct deletion completed in 6.063539341s

• [SLOW TEST:6.167 seconds]
[sig-cli] Kubectl client
/go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl api-versions
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should check if v1 is in available api versions  [Conformance]
    /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  8 16:22:18.669: INFO: >>> kubeConfig: /tmp/kubeconfig-235977939
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-76673b3f-e372-11e8-b0fd-0e97e856486a
STEP: Creating a pod to test consume configMaps
Nov  8 16:22:18.709: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-76677b8d-e372-11e8-b0fd-0e97e856486a" in namespace "e2e-tests-projected-s5rqg" to be "success or failure"
Nov  8 16:22:18.712: INFO: Pod "pod-projected-configmaps-76677b8d-e372-11e8-b0fd-0e97e856486a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.707028ms
Nov  8 16:22:20.714: INFO: Pod "pod-projected-configmaps-76677b8d-e372-11e8-b0fd-0e97e856486a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004673217s
STEP: Saw pod success
Nov  8 16:22:20.714: INFO: Pod "pod-projected-configmaps-76677b8d-e372-11e8-b0fd-0e97e856486a" satisfied condition "success or failure"
Nov  8 16:22:20.715: INFO: Trying to get logs from node ip-10-0-100-224.ec2.internal pod pod-projected-configmaps-76677b8d-e372-11e8-b0fd-0e97e856486a container projected-configmap-volume-test: <nil>
STEP: delete the pod
Nov  8 16:22:20.726: INFO: Waiting for pod pod-projected-configmaps-76677b8d-e372-11e8-b0fd-0e97e856486a to disappear
Nov  8 16:22:20.727: INFO: Pod pod-projected-configmaps-76677b8d-e372-11e8-b0fd-0e97e856486a no longer exists
[AfterEach] [sig-storage] Projected
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  8 16:22:20.727: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-s5rqg" for this suite.
Nov  8 16:22:26.734: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  8 16:22:26.753: INFO: namespace: e2e-tests-projected-s5rqg, resource: bindings, ignored listing per whitelist
Nov  8 16:22:26.793: INFO: namespace e2e-tests-projected-s5rqg deletion completed in 6.06366617s

• [SLOW TEST:8.123 seconds]
[sig-storage] Projected
/go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl logs 
  should be able to retrieve and filter logs  [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  8 16:22:26.793: INFO: >>> kubeConfig: /tmp/kubeconfig-235977939
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Kubectl logs
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1083
STEP: creating an rc
Nov  8 16:22:26.831: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-235977939 create -f - --namespace=e2e-tests-kubectl-jrv88'
Nov  8 16:22:26.965: INFO: stderr: ""
Nov  8 16:22:26.965: INFO: stdout: "replicationcontroller/redis-master created\n"
[It] should be able to retrieve and filter logs  [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Waiting for Redis master to start.
Nov  8 16:22:27.967: INFO: Selector matched 1 pods for map[app:redis]
Nov  8 16:22:27.967: INFO: Found 1 / 1
Nov  8 16:22:27.967: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Nov  8 16:22:27.968: INFO: Selector matched 1 pods for map[app:redis]
Nov  8 16:22:27.968: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
STEP: checking for a matching strings
Nov  8 16:22:27.968: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-235977939 logs redis-master-dbp8c redis-master --namespace=e2e-tests-kubectl-jrv88'
Nov  8 16:22:28.037: INFO: stderr: ""
Nov  8 16:22:28.037: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 08 Nov 16:22:27.758 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 08 Nov 16:22:27.758 # Server started, Redis version 3.2.12\n1:M 08 Nov 16:22:27.758 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 08 Nov 16:22:27.758 * The server is now ready to accept connections on port 6379\n"
STEP: limiting log lines
Nov  8 16:22:28.037: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-235977939 log redis-master-dbp8c redis-master --namespace=e2e-tests-kubectl-jrv88 --tail=1'
Nov  8 16:22:28.104: INFO: stderr: ""
Nov  8 16:22:28.104: INFO: stdout: "1:M 08 Nov 16:22:27.758 * The server is now ready to accept connections on port 6379\n"
STEP: limiting log bytes
Nov  8 16:22:28.105: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-235977939 log redis-master-dbp8c redis-master --namespace=e2e-tests-kubectl-jrv88 --limit-bytes=1'
Nov  8 16:22:28.171: INFO: stderr: ""
Nov  8 16:22:28.171: INFO: stdout: " "
STEP: exposing timestamps
Nov  8 16:22:28.171: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-235977939 log redis-master-dbp8c redis-master --namespace=e2e-tests-kubectl-jrv88 --tail=1 --timestamps'
Nov  8 16:22:28.238: INFO: stderr: ""
Nov  8 16:22:28.238: INFO: stdout: "2018-11-08T16:22:27.759101506Z 1:M 08 Nov 16:22:27.758 * The server is now ready to accept connections on port 6379\n"
STEP: restricting to a time range
Nov  8 16:22:30.738: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-235977939 log redis-master-dbp8c redis-master --namespace=e2e-tests-kubectl-jrv88 --since=1s'
Nov  8 16:22:30.810: INFO: stderr: ""
Nov  8 16:22:30.810: INFO: stdout: ""
Nov  8 16:22:30.810: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-235977939 log redis-master-dbp8c redis-master --namespace=e2e-tests-kubectl-jrv88 --since=24h'
Nov  8 16:22:30.880: INFO: stderr: ""
Nov  8 16:22:30.880: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 08 Nov 16:22:27.758 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 08 Nov 16:22:27.758 # Server started, Redis version 3.2.12\n1:M 08 Nov 16:22:27.758 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 08 Nov 16:22:27.758 * The server is now ready to accept connections on port 6379\n"
[AfterEach] [k8s.io] Kubectl logs
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1088
STEP: using delete to clean up resources
Nov  8 16:22:30.880: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-235977939 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-jrv88'
Nov  8 16:22:30.939: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Nov  8 16:22:30.939: INFO: stdout: "replicationcontroller \"redis-master\" force deleted\n"
Nov  8 16:22:30.939: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-235977939 get rc,svc -l name=nginx --no-headers --namespace=e2e-tests-kubectl-jrv88'
Nov  8 16:22:31.003: INFO: stderr: "No resources found.\n"
Nov  8 16:22:31.003: INFO: stdout: ""
Nov  8 16:22:31.003: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-235977939 get pods -l name=nginx --namespace=e2e-tests-kubectl-jrv88 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Nov  8 16:22:31.062: INFO: stderr: ""
Nov  8 16:22:31.062: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  8 16:22:31.062: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-jrv88" for this suite.
Nov  8 16:22:37.069: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  8 16:22:37.116: INFO: namespace: e2e-tests-kubectl-jrv88, resource: bindings, ignored listing per whitelist
Nov  8 16:22:37.121: INFO: namespace e2e-tests-kubectl-jrv88 deletion completed in 6.057524578s

• [SLOW TEST:10.328 seconds]
[sig-cli] Kubectl client
/go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl logs
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should be able to retrieve and filter logs  [Conformance]
    /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should scale a replication controller  [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  8 16:22:37.121: INFO: >>> kubeConfig: /tmp/kubeconfig-235977939
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Update Demo
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:293
[It] should scale a replication controller  [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a replication controller
Nov  8 16:22:37.159: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-235977939 create -f - --namespace=e2e-tests-kubectl-r8kvq'
Nov  8 16:22:37.286: INFO: stderr: ""
Nov  8 16:22:37.286: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Nov  8 16:22:37.286: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-235977939 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-r8kvq'
Nov  8 16:22:37.356: INFO: stderr: ""
Nov  8 16:22:37.356: INFO: stdout: "update-demo-nautilus-8wmhf update-demo-nautilus-zfhqg "
Nov  8 16:22:37.356: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-235977939 get pods update-demo-nautilus-8wmhf -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-r8kvq'
Nov  8 16:22:37.417: INFO: stderr: ""
Nov  8 16:22:37.417: INFO: stdout: ""
Nov  8 16:22:37.417: INFO: update-demo-nautilus-8wmhf is created but not running
Nov  8 16:22:42.417: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-235977939 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-r8kvq'
Nov  8 16:22:42.480: INFO: stderr: ""
Nov  8 16:22:42.480: INFO: stdout: "update-demo-nautilus-8wmhf update-demo-nautilus-zfhqg "
Nov  8 16:22:42.480: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-235977939 get pods update-demo-nautilus-8wmhf -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-r8kvq'
Nov  8 16:22:42.540: INFO: stderr: ""
Nov  8 16:22:42.540: INFO: stdout: "true"
Nov  8 16:22:42.540: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-235977939 get pods update-demo-nautilus-8wmhf -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-r8kvq'
Nov  8 16:22:42.600: INFO: stderr: ""
Nov  8 16:22:42.600: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Nov  8 16:22:42.600: INFO: validating pod update-demo-nautilus-8wmhf
Nov  8 16:22:42.603: INFO: got data: {
  "image": "nautilus.jpg"
}

Nov  8 16:22:42.603: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Nov  8 16:22:42.603: INFO: update-demo-nautilus-8wmhf is verified up and running
Nov  8 16:22:42.603: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-235977939 get pods update-demo-nautilus-zfhqg -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-r8kvq'
Nov  8 16:22:42.666: INFO: stderr: ""
Nov  8 16:22:42.666: INFO: stdout: "true"
Nov  8 16:22:42.666: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-235977939 get pods update-demo-nautilus-zfhqg -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-r8kvq'
Nov  8 16:22:42.726: INFO: stderr: ""
Nov  8 16:22:42.726: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Nov  8 16:22:42.726: INFO: validating pod update-demo-nautilus-zfhqg
Nov  8 16:22:42.728: INFO: got data: {
  "image": "nautilus.jpg"
}

Nov  8 16:22:42.728: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Nov  8 16:22:42.728: INFO: update-demo-nautilus-zfhqg is verified up and running
STEP: scaling down the replication controller
Nov  8 16:22:42.729: INFO: scanned /root for discovery docs: <nil>
Nov  8 16:22:42.729: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-235977939 scale rc update-demo-nautilus --replicas=1 --timeout=5m --namespace=e2e-tests-kubectl-r8kvq'
Nov  8 16:22:43.804: INFO: stderr: ""
Nov  8 16:22:43.804: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Nov  8 16:22:43.804: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-235977939 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-r8kvq'
Nov  8 16:22:43.870: INFO: stderr: ""
Nov  8 16:22:43.870: INFO: stdout: "update-demo-nautilus-8wmhf update-demo-nautilus-zfhqg "
STEP: Replicas for name=update-demo: expected=1 actual=2
Nov  8 16:22:48.870: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-235977939 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-r8kvq'
Nov  8 16:22:48.931: INFO: stderr: ""
Nov  8 16:22:48.931: INFO: stdout: "update-demo-nautilus-8wmhf "
Nov  8 16:22:48.931: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-235977939 get pods update-demo-nautilus-8wmhf -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-r8kvq'
Nov  8 16:22:48.990: INFO: stderr: ""
Nov  8 16:22:48.990: INFO: stdout: "true"
Nov  8 16:22:48.990: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-235977939 get pods update-demo-nautilus-8wmhf -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-r8kvq'
Nov  8 16:22:49.049: INFO: stderr: ""
Nov  8 16:22:49.049: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Nov  8 16:22:49.049: INFO: validating pod update-demo-nautilus-8wmhf
Nov  8 16:22:49.051: INFO: got data: {
  "image": "nautilus.jpg"
}

Nov  8 16:22:49.051: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Nov  8 16:22:49.051: INFO: update-demo-nautilus-8wmhf is verified up and running
STEP: scaling up the replication controller
Nov  8 16:22:49.052: INFO: scanned /root for discovery docs: <nil>
Nov  8 16:22:49.052: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-235977939 scale rc update-demo-nautilus --replicas=2 --timeout=5m --namespace=e2e-tests-kubectl-r8kvq'
Nov  8 16:22:50.129: INFO: stderr: ""
Nov  8 16:22:50.129: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Nov  8 16:22:50.129: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-235977939 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-r8kvq'
Nov  8 16:22:50.193: INFO: stderr: ""
Nov  8 16:22:50.193: INFO: stdout: "update-demo-nautilus-8wmhf update-demo-nautilus-zbv59 "
Nov  8 16:22:50.193: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-235977939 get pods update-demo-nautilus-8wmhf -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-r8kvq'
Nov  8 16:22:50.253: INFO: stderr: ""
Nov  8 16:22:50.253: INFO: stdout: "true"
Nov  8 16:22:50.253: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-235977939 get pods update-demo-nautilus-8wmhf -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-r8kvq'
Nov  8 16:22:50.312: INFO: stderr: ""
Nov  8 16:22:50.312: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Nov  8 16:22:50.312: INFO: validating pod update-demo-nautilus-8wmhf
Nov  8 16:22:50.314: INFO: got data: {
  "image": "nautilus.jpg"
}

Nov  8 16:22:50.314: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Nov  8 16:22:50.314: INFO: update-demo-nautilus-8wmhf is verified up and running
Nov  8 16:22:50.315: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-235977939 get pods update-demo-nautilus-zbv59 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-r8kvq'
Nov  8 16:22:50.373: INFO: stderr: ""
Nov  8 16:22:50.373: INFO: stdout: "true"
Nov  8 16:22:50.373: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-235977939 get pods update-demo-nautilus-zbv59 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-r8kvq'
Nov  8 16:22:50.432: INFO: stderr: ""
Nov  8 16:22:50.432: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Nov  8 16:22:50.432: INFO: validating pod update-demo-nautilus-zbv59
Nov  8 16:22:50.434: INFO: got data: {
  "image": "nautilus.jpg"
}

Nov  8 16:22:50.434: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Nov  8 16:22:50.434: INFO: update-demo-nautilus-zbv59 is verified up and running
STEP: using delete to clean up resources
Nov  8 16:22:50.435: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-235977939 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-r8kvq'
Nov  8 16:22:50.495: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Nov  8 16:22:50.496: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Nov  8 16:22:50.496: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-235977939 get rc,svc -l name=update-demo --no-headers --namespace=e2e-tests-kubectl-r8kvq'
Nov  8 16:22:50.561: INFO: stderr: "No resources found.\n"
Nov  8 16:22:50.561: INFO: stdout: ""
Nov  8 16:22:50.561: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-235977939 get pods -l name=update-demo --namespace=e2e-tests-kubectl-r8kvq -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Nov  8 16:22:50.636: INFO: stderr: ""
Nov  8 16:22:50.636: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  8 16:22:50.636: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-r8kvq" for this suite.
Nov  8 16:23:12.643: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  8 16:23:12.697: INFO: namespace: e2e-tests-kubectl-r8kvq, resource: bindings, ignored listing per whitelist
Nov  8 16:23:12.699: INFO: namespace e2e-tests-kubectl-r8kvq deletion completed in 22.061317317s

• [SLOW TEST:35.578 seconds]
[sig-cli] Kubectl client
/go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Update Demo
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should scale a replication controller  [Conformance]
    /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] Projected 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  8 16:23:12.699: INFO: >>> kubeConfig: /tmp/kubeconfig-235977939
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Nov  8 16:23:12.740: INFO: Waiting up to 5m0s for pod "downwardapi-volume-969bdd1b-e372-11e8-b0fd-0e97e856486a" in namespace "e2e-tests-projected-p2rxv" to be "success or failure"
Nov  8 16:23:12.741: INFO: Pod "downwardapi-volume-969bdd1b-e372-11e8-b0fd-0e97e856486a": Phase="Pending", Reason="", readiness=false. Elapsed: 1.527001ms
Nov  8 16:23:14.743: INFO: Pod "downwardapi-volume-969bdd1b-e372-11e8-b0fd-0e97e856486a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.003630271s
STEP: Saw pod success
Nov  8 16:23:14.743: INFO: Pod "downwardapi-volume-969bdd1b-e372-11e8-b0fd-0e97e856486a" satisfied condition "success or failure"
Nov  8 16:23:14.745: INFO: Trying to get logs from node ip-10-0-100-224.ec2.internal pod downwardapi-volume-969bdd1b-e372-11e8-b0fd-0e97e856486a container client-container: <nil>
STEP: delete the pod
Nov  8 16:23:14.754: INFO: Waiting for pod downwardapi-volume-969bdd1b-e372-11e8-b0fd-0e97e856486a to disappear
Nov  8 16:23:14.755: INFO: Pod downwardapi-volume-969bdd1b-e372-11e8-b0fd-0e97e856486a no longer exists
[AfterEach] [sig-storage] Projected
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  8 16:23:14.755: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-p2rxv" for this suite.
Nov  8 16:23:20.763: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  8 16:23:20.804: INFO: namespace: e2e-tests-projected-p2rxv, resource: bindings, ignored listing per whitelist
Nov  8 16:23:20.816: INFO: namespace e2e-tests-projected-p2rxv deletion completed in 6.058996033s

• [SLOW TEST:8.117 seconds]
[sig-storage] Projected
/go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Projected 
  should set DefaultMode on files [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  8 16:23:20.816: INFO: >>> kubeConfig: /tmp/kubeconfig-235977939
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should set DefaultMode on files [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Nov  8 16:23:20.855: INFO: Waiting up to 5m0s for pod "downwardapi-volume-9b722aa8-e372-11e8-b0fd-0e97e856486a" in namespace "e2e-tests-projected-kvg64" to be "success or failure"
Nov  8 16:23:20.857: INFO: Pod "downwardapi-volume-9b722aa8-e372-11e8-b0fd-0e97e856486a": Phase="Pending", Reason="", readiness=false. Elapsed: 1.532909ms
Nov  8 16:23:22.859: INFO: Pod "downwardapi-volume-9b722aa8-e372-11e8-b0fd-0e97e856486a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.003346129s
STEP: Saw pod success
Nov  8 16:23:22.859: INFO: Pod "downwardapi-volume-9b722aa8-e372-11e8-b0fd-0e97e856486a" satisfied condition "success or failure"
Nov  8 16:23:22.860: INFO: Trying to get logs from node ip-10-0-100-224.ec2.internal pod downwardapi-volume-9b722aa8-e372-11e8-b0fd-0e97e856486a container client-container: <nil>
STEP: delete the pod
Nov  8 16:23:22.868: INFO: Waiting for pod downwardapi-volume-9b722aa8-e372-11e8-b0fd-0e97e856486a to disappear
Nov  8 16:23:22.870: INFO: Pod downwardapi-volume-9b722aa8-e372-11e8-b0fd-0e97e856486a no longer exists
[AfterEach] [sig-storage] Projected
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  8 16:23:22.870: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-kvg64" for this suite.
Nov  8 16:23:28.877: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  8 16:23:28.897: INFO: namespace: e2e-tests-projected-kvg64, resource: bindings, ignored listing per whitelist
Nov  8 16:23:28.930: INFO: namespace e2e-tests-projected-kvg64 deletion completed in 6.058142291s

• [SLOW TEST:8.114 seconds]
[sig-storage] Projected
/go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should set DefaultMode on files [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-api-machinery] Downward API 
  should provide host IP as an env var [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Downward API
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  8 16:23:28.930: INFO: >>> kubeConfig: /tmp/kubeconfig-235977939
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide host IP as an env var [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Nov  8 16:23:28.974: INFO: Waiting up to 5m0s for pod "downward-api-a048a7a2-e372-11e8-b0fd-0e97e856486a" in namespace "e2e-tests-downward-api-sqf7g" to be "success or failure"
Nov  8 16:23:28.975: INFO: Pod "downward-api-a048a7a2-e372-11e8-b0fd-0e97e856486a": Phase="Pending", Reason="", readiness=false. Elapsed: 1.559569ms
Nov  8 16:23:30.978: INFO: Pod "downward-api-a048a7a2-e372-11e8-b0fd-0e97e856486a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.003704104s
STEP: Saw pod success
Nov  8 16:23:30.978: INFO: Pod "downward-api-a048a7a2-e372-11e8-b0fd-0e97e856486a" satisfied condition "success or failure"
Nov  8 16:23:30.979: INFO: Trying to get logs from node ip-10-0-100-224.ec2.internal pod downward-api-a048a7a2-e372-11e8-b0fd-0e97e856486a container dapi-container: <nil>
STEP: delete the pod
Nov  8 16:23:30.988: INFO: Waiting for pod downward-api-a048a7a2-e372-11e8-b0fd-0e97e856486a to disappear
Nov  8 16:23:30.990: INFO: Pod downward-api-a048a7a2-e372-11e8-b0fd-0e97e856486a no longer exists
[AfterEach] [sig-api-machinery] Downward API
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  8 16:23:30.990: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-sqf7g" for this suite.
Nov  8 16:23:36.997: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  8 16:23:37.044: INFO: namespace: e2e-tests-downward-api-sqf7g, resource: bindings, ignored listing per whitelist
Nov  8 16:23:37.050: INFO: namespace e2e-tests-downward-api-sqf7g deletion completed in 6.057984845s

• [SLOW TEST:8.120 seconds]
[sig-api-machinery] Downward API
/go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide host IP as an env var [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  8 16:23:37.050: INFO: >>> kubeConfig: /tmp/kubeconfig-235977939
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Nov  8 16:23:37.089: INFO: Waiting up to 5m0s for pod "downwardapi-volume-a51f3912-e372-11e8-b0fd-0e97e856486a" in namespace "e2e-tests-downward-api-d4kpz" to be "success or failure"
Nov  8 16:23:37.094: INFO: Pod "downwardapi-volume-a51f3912-e372-11e8-b0fd-0e97e856486a": Phase="Pending", Reason="", readiness=false. Elapsed: 4.579397ms
Nov  8 16:23:39.096: INFO: Pod "downwardapi-volume-a51f3912-e372-11e8-b0fd-0e97e856486a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006432076s
STEP: Saw pod success
Nov  8 16:23:39.096: INFO: Pod "downwardapi-volume-a51f3912-e372-11e8-b0fd-0e97e856486a" satisfied condition "success or failure"
Nov  8 16:23:39.097: INFO: Trying to get logs from node ip-10-0-100-224.ec2.internal pod downwardapi-volume-a51f3912-e372-11e8-b0fd-0e97e856486a container client-container: <nil>
STEP: delete the pod
Nov  8 16:23:39.107: INFO: Waiting for pod downwardapi-volume-a51f3912-e372-11e8-b0fd-0e97e856486a to disappear
Nov  8 16:23:39.108: INFO: Pod downwardapi-volume-a51f3912-e372-11e8-b0fd-0e97e856486a no longer exists
[AfterEach] [sig-storage] Downward API volume
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  8 16:23:39.108: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-d4kpz" for this suite.
Nov  8 16:23:45.115: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  8 16:23:45.122: INFO: namespace: e2e-tests-downward-api-d4kpz, resource: bindings, ignored listing per whitelist
Nov  8 16:23:45.167: INFO: namespace e2e-tests-downward-api-d4kpz deletion completed in 6.057065569s

• [SLOW TEST:8.118 seconds]
[sig-storage] Downward API volume
/go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's cpu limit [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform rolling updates and roll backs of template modifications [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  8 16:23:45.168: INFO: >>> kubeConfig: /tmp/kubeconfig-235977939
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-zcm8h
[It] should perform rolling updates and roll backs of template modifications [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a new StatefulSet
Nov  8 16:23:45.214: INFO: Found 0 stateful pods, waiting for 3
Nov  8 16:23:55.216: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Nov  8 16:23:55.216: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Nov  8 16:23:55.216: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
Nov  8 16:23:55.221: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-235977939 exec --namespace=e2e-tests-statefulset-zcm8h ss2-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Nov  8 16:23:55.355: INFO: stderr: ""
Nov  8 16:23:55.355: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Nov  8 16:23:55.355: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss2-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

STEP: Updating StatefulSet template: update image from docker.io/library/nginx:1.14-alpine to docker.io/library/nginx:1.15-alpine
Nov  8 16:24:05.376: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Updating Pods in reverse ordinal order
Nov  8 16:24:15.386: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-235977939 exec --namespace=e2e-tests-statefulset-zcm8h ss2-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Nov  8 16:24:15.516: INFO: stderr: ""
Nov  8 16:24:15.516: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Nov  8 16:24:15.516: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss2-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Nov  8 16:24:25.527: INFO: Waiting for StatefulSet e2e-tests-statefulset-zcm8h/ss2 to complete update
Nov  8 16:24:25.527: INFO: Waiting for Pod e2e-tests-statefulset-zcm8h/ss2-0 to have revision ss2-c79899b9 update revision ss2-787997d666
Nov  8 16:24:25.527: INFO: Waiting for Pod e2e-tests-statefulset-zcm8h/ss2-1 to have revision ss2-c79899b9 update revision ss2-787997d666
Nov  8 16:24:25.527: INFO: Waiting for Pod e2e-tests-statefulset-zcm8h/ss2-2 to have revision ss2-c79899b9 update revision ss2-787997d666
Nov  8 16:24:35.530: INFO: Waiting for StatefulSet e2e-tests-statefulset-zcm8h/ss2 to complete update
Nov  8 16:24:35.530: INFO: Waiting for Pod e2e-tests-statefulset-zcm8h/ss2-0 to have revision ss2-c79899b9 update revision ss2-787997d666
Nov  8 16:24:45.530: INFO: Waiting for StatefulSet e2e-tests-statefulset-zcm8h/ss2 to complete update
Nov  8 16:24:45.530: INFO: Waiting for Pod e2e-tests-statefulset-zcm8h/ss2-0 to have revision ss2-c79899b9 update revision ss2-787997d666
STEP: Rolling back to a previous revision
Nov  8 16:24:55.531: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-235977939 exec --namespace=e2e-tests-statefulset-zcm8h ss2-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Nov  8 16:24:55.665: INFO: stderr: ""
Nov  8 16:24:55.665: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Nov  8 16:24:55.665: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss2-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Nov  8 16:25:05.686: INFO: Updating stateful set ss2
STEP: Rolling back update in reverse ordinal order
Nov  8 16:25:15.694: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-235977939 exec --namespace=e2e-tests-statefulset-zcm8h ss2-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Nov  8 16:25:15.824: INFO: stderr: ""
Nov  8 16:25:15.824: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Nov  8 16:25:15.824: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss2-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Nov  8 16:25:25.834: INFO: Waiting for StatefulSet e2e-tests-statefulset-zcm8h/ss2 to complete update
Nov  8 16:25:25.834: INFO: Waiting for Pod e2e-tests-statefulset-zcm8h/ss2-0 to have revision ss2-787997d666 update revision ss2-c79899b9
Nov  8 16:25:25.834: INFO: Waiting for Pod e2e-tests-statefulset-zcm8h/ss2-1 to have revision ss2-787997d666 update revision ss2-c79899b9
Nov  8 16:25:25.834: INFO: Waiting for Pod e2e-tests-statefulset-zcm8h/ss2-2 to have revision ss2-787997d666 update revision ss2-c79899b9
Nov  8 16:25:35.838: INFO: Waiting for StatefulSet e2e-tests-statefulset-zcm8h/ss2 to complete update
Nov  8 16:25:35.838: INFO: Waiting for Pod e2e-tests-statefulset-zcm8h/ss2-0 to have revision ss2-787997d666 update revision ss2-c79899b9
Nov  8 16:25:35.838: INFO: Waiting for Pod e2e-tests-statefulset-zcm8h/ss2-1 to have revision ss2-787997d666 update revision ss2-c79899b9
Nov  8 16:25:45.838: INFO: Waiting for StatefulSet e2e-tests-statefulset-zcm8h/ss2 to complete update
Nov  8 16:25:45.838: INFO: Waiting for Pod e2e-tests-statefulset-zcm8h/ss2-0 to have revision ss2-787997d666 update revision ss2-c79899b9
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Nov  8 16:25:55.838: INFO: Deleting all statefulset in ns e2e-tests-statefulset-zcm8h
Nov  8 16:25:55.839: INFO: Scaling statefulset ss2 to 0
Nov  8 16:26:25.846: INFO: Waiting for statefulset status.replicas updated to 0
Nov  8 16:26:25.848: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  8 16:26:25.856: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-zcm8h" for this suite.
Nov  8 16:26:31.865: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  8 16:26:31.883: INFO: namespace: e2e-tests-statefulset-zcm8h, resource: bindings, ignored listing per whitelist
Nov  8 16:26:31.919: INFO: namespace e2e-tests-statefulset-zcm8h deletion completed in 6.060734105s

• [SLOW TEST:166.751 seconds]
[sig-apps] StatefulSet
/go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should perform rolling updates and roll backs of template modifications [Conformance]
    /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[k8s.io] KubeletManagedEtcHosts 
  should test kubelet managed /etc/hosts file [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] KubeletManagedEtcHosts
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  8 16:26:31.919: INFO: >>> kubeConfig: /tmp/kubeconfig-235977939
STEP: Building a namespace api object, basename e2e-kubelet-etc-hosts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should test kubelet managed /etc/hosts file [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Setting up the test
STEP: Creating hostNetwork=false pod
STEP: Creating hostNetwork=true pod
STEP: Running the test
STEP: Verifying /etc/hosts of container is kubelet-managed for pod with hostNetwork=false
Nov  8 16:26:39.979: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-n78dm PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Nov  8 16:26:39.979: INFO: >>> kubeConfig: /tmp/kubeconfig-235977939
Nov  8 16:26:40.053: INFO: Exec stderr: ""
Nov  8 16:26:40.053: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-n78dm PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Nov  8 16:26:40.053: INFO: >>> kubeConfig: /tmp/kubeconfig-235977939
Nov  8 16:26:40.111: INFO: Exec stderr: ""
Nov  8 16:26:40.111: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-n78dm PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Nov  8 16:26:40.111: INFO: >>> kubeConfig: /tmp/kubeconfig-235977939
Nov  8 16:26:40.168: INFO: Exec stderr: ""
Nov  8 16:26:40.168: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-n78dm PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Nov  8 16:26:40.168: INFO: >>> kubeConfig: /tmp/kubeconfig-235977939
Nov  8 16:26:40.239: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts of container is not kubelet-managed since container specifies /etc/hosts mount
Nov  8 16:26:40.239: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-n78dm PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Nov  8 16:26:40.239: INFO: >>> kubeConfig: /tmp/kubeconfig-235977939
Nov  8 16:26:40.310: INFO: Exec stderr: ""
Nov  8 16:26:40.310: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-n78dm PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Nov  8 16:26:40.310: INFO: >>> kubeConfig: /tmp/kubeconfig-235977939
Nov  8 16:26:40.386: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts content of container is not kubelet-managed for pod with hostNetwork=true
Nov  8 16:26:40.386: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-n78dm PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Nov  8 16:26:40.386: INFO: >>> kubeConfig: /tmp/kubeconfig-235977939
Nov  8 16:26:40.442: INFO: Exec stderr: ""
Nov  8 16:26:40.442: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-n78dm PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Nov  8 16:26:40.442: INFO: >>> kubeConfig: /tmp/kubeconfig-235977939
Nov  8 16:26:40.512: INFO: Exec stderr: ""
Nov  8 16:26:40.512: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-n78dm PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Nov  8 16:26:40.512: INFO: >>> kubeConfig: /tmp/kubeconfig-235977939
Nov  8 16:26:40.598: INFO: Exec stderr: ""
Nov  8 16:26:40.598: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-n78dm PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Nov  8 16:26:40.598: INFO: >>> kubeConfig: /tmp/kubeconfig-235977939
Nov  8 16:26:40.668: INFO: Exec stderr: ""
[AfterEach] [k8s.io] KubeletManagedEtcHosts
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  8 16:26:40.668: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-e2e-kubelet-etc-hosts-n78dm" for this suite.
Nov  8 16:27:30.676: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  8 16:27:30.717: INFO: namespace: e2e-tests-e2e-kubelet-etc-hosts-n78dm, resource: bindings, ignored listing per whitelist
Nov  8 16:27:30.732: INFO: namespace e2e-tests-e2e-kubelet-etc-hosts-n78dm deletion completed in 50.06183988s

• [SLOW TEST:58.813 seconds]
[k8s.io] KubeletManagedEtcHosts
/go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should test kubelet managed /etc/hosts file [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected 
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  8 16:27:30.732: INFO: >>> kubeConfig: /tmp/kubeconfig-235977939
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-projected-all-test-volume-30686951-e373-11e8-b0fd-0e97e856486a
STEP: Creating secret with name secret-projected-all-test-volume-3068693b-e373-11e8-b0fd-0e97e856486a
STEP: Creating a pod to test Check all projections for projected volume plugin
Nov  8 16:27:30.774: INFO: Waiting up to 5m0s for pod "projected-volume-30686912-e373-11e8-b0fd-0e97e856486a" in namespace "e2e-tests-projected-zrdht" to be "success or failure"
Nov  8 16:27:30.777: INFO: Pod "projected-volume-30686912-e373-11e8-b0fd-0e97e856486a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.837526ms
Nov  8 16:27:32.779: INFO: Pod "projected-volume-30686912-e373-11e8-b0fd-0e97e856486a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005019945s
STEP: Saw pod success
Nov  8 16:27:32.780: INFO: Pod "projected-volume-30686912-e373-11e8-b0fd-0e97e856486a" satisfied condition "success or failure"
Nov  8 16:27:32.781: INFO: Trying to get logs from node ip-10-0-100-224.ec2.internal pod projected-volume-30686912-e373-11e8-b0fd-0e97e856486a container projected-all-volume-test: <nil>
STEP: delete the pod
Nov  8 16:27:32.792: INFO: Waiting for pod projected-volume-30686912-e373-11e8-b0fd-0e97e856486a to disappear
Nov  8 16:27:32.794: INFO: Pod projected-volume-30686912-e373-11e8-b0fd-0e97e856486a no longer exists
[AfterEach] [sig-storage] Projected
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  8 16:27:32.794: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-zrdht" for this suite.
Nov  8 16:27:38.801: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  8 16:27:38.829: INFO: namespace: e2e-tests-projected-zrdht, resource: bindings, ignored listing per whitelist
Nov  8 16:27:38.854: INFO: namespace e2e-tests-projected-zrdht deletion completed in 6.058809399s

• [SLOW TEST:8.122 seconds]
[sig-storage] Projected
/go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory limit [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  8 16:27:38.854: INFO: >>> kubeConfig: /tmp/kubeconfig-235977939
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Nov  8 16:27:38.893: INFO: Waiting up to 5m0s for pod "downwardapi-volume-353fb374-e373-11e8-b0fd-0e97e856486a" in namespace "e2e-tests-downward-api-4km88" to be "success or failure"
Nov  8 16:27:38.899: INFO: Pod "downwardapi-volume-353fb374-e373-11e8-b0fd-0e97e856486a": Phase="Pending", Reason="", readiness=false. Elapsed: 5.301204ms
Nov  8 16:27:40.901: INFO: Pod "downwardapi-volume-353fb374-e373-11e8-b0fd-0e97e856486a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007304731s
STEP: Saw pod success
Nov  8 16:27:40.901: INFO: Pod "downwardapi-volume-353fb374-e373-11e8-b0fd-0e97e856486a" satisfied condition "success or failure"
Nov  8 16:27:40.902: INFO: Trying to get logs from node ip-10-0-100-224.ec2.internal pod downwardapi-volume-353fb374-e373-11e8-b0fd-0e97e856486a container client-container: <nil>
STEP: delete the pod
Nov  8 16:27:40.911: INFO: Waiting for pod downwardapi-volume-353fb374-e373-11e8-b0fd-0e97e856486a to disappear
Nov  8 16:27:40.913: INFO: Pod downwardapi-volume-353fb374-e373-11e8-b0fd-0e97e856486a no longer exists
[AfterEach] [sig-storage] Downward API volume
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  8 16:27:40.913: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-4km88" for this suite.
Nov  8 16:27:46.920: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  8 16:27:46.929: INFO: namespace: e2e-tests-downward-api-4km88, resource: bindings, ignored listing per whitelist
Nov  8 16:27:46.972: INFO: namespace e2e-tests-downward-api-4km88 deletion completed in 6.057359125s

• [SLOW TEST:8.118 seconds]
[sig-storage] Downward API volume
/go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's memory limit [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  8 16:27:46.972: INFO: >>> kubeConfig: /tmp/kubeconfig-235977939
STEP: Building a namespace api object, basename namespaces
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all pods are removed when a namespace is deleted [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a test namespace
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a pod in the namespace
STEP: Waiting for the pod to have running status
STEP: Creating an uninitialized pod in the namespace
Nov  8 16:27:49.033: INFO: error from create uninitialized namespace: <nil>
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Verifying there are no pods in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  8 16:28:13.056: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-namespaces-sjfvk" for this suite.
Nov  8 16:28:19.063: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  8 16:28:19.076: INFO: namespace: e2e-tests-namespaces-sjfvk, resource: bindings, ignored listing per whitelist
Nov  8 16:28:19.115: INFO: namespace e2e-tests-namespaces-sjfvk deletion completed in 6.057899937s
STEP: Destroying namespace "e2e-tests-nsdeletetest-dfxpl" for this suite.
Nov  8 16:28:19.117: INFO: Namespace e2e-tests-nsdeletetest-dfxpl was already deleted
STEP: Destroying namespace "e2e-tests-nsdeletetest-8m6rf" for this suite.
Nov  8 16:28:25.122: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  8 16:28:25.163: INFO: namespace: e2e-tests-nsdeletetest-8m6rf, resource: bindings, ignored listing per whitelist
Nov  8 16:28:25.175: INFO: namespace e2e-tests-nsdeletetest-8m6rf deletion completed in 6.058547409s

• [SLOW TEST:38.203 seconds]
[sig-api-machinery] Namespaces [Serial]
/go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart http hook properly [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  8 16:28:25.175: INFO: >>> kubeConfig: /tmp/kubeconfig-235977939
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart http hook properly [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Nov  8 16:28:29.235: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Nov  8 16:28:29.236: INFO: Pod pod-with-poststart-http-hook still exists
Nov  8 16:28:31.237: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Nov  8 16:28:31.238: INFO: Pod pod-with-poststart-http-hook still exists
Nov  8 16:28:33.237: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Nov  8 16:28:33.239: INFO: Pod pod-with-poststart-http-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  8 16:28:33.239: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-lifecycle-hook-6s4lm" for this suite.
Nov  8 16:28:55.247: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  8 16:28:55.265: INFO: namespace: e2e-tests-container-lifecycle-hook-6s4lm, resource: bindings, ignored listing per whitelist
Nov  8 16:28:55.301: INFO: namespace e2e-tests-container-lifecycle-hook-6s4lm deletion completed in 22.060298649s

• [SLOW TEST:30.126 seconds]
[k8s.io] Container Lifecycle Hook
/go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when create a pod with lifecycle hook
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute poststart http hook properly [NodeConformance] [Conformance]
    /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  8 16:28:55.301: INFO: >>> kubeConfig: /tmp/kubeconfig-235977939
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-map-62d178b1-e373-11e8-b0fd-0e97e856486a
STEP: Creating a pod to test consume secrets
Nov  8 16:28:55.347: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-62d1aea9-e373-11e8-b0fd-0e97e856486a" in namespace "e2e-tests-projected-jhgtp" to be "success or failure"
Nov  8 16:28:55.350: INFO: Pod "pod-projected-secrets-62d1aea9-e373-11e8-b0fd-0e97e856486a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.292137ms
Nov  8 16:28:57.352: INFO: Pod "pod-projected-secrets-62d1aea9-e373-11e8-b0fd-0e97e856486a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00464896s
STEP: Saw pod success
Nov  8 16:28:57.352: INFO: Pod "pod-projected-secrets-62d1aea9-e373-11e8-b0fd-0e97e856486a" satisfied condition "success or failure"
Nov  8 16:28:57.354: INFO: Trying to get logs from node ip-10-0-100-224.ec2.internal pod pod-projected-secrets-62d1aea9-e373-11e8-b0fd-0e97e856486a container projected-secret-volume-test: <nil>
STEP: delete the pod
Nov  8 16:28:57.364: INFO: Waiting for pod pod-projected-secrets-62d1aea9-e373-11e8-b0fd-0e97e856486a to disappear
Nov  8 16:28:57.365: INFO: Pod pod-projected-secrets-62d1aea9-e373-11e8-b0fd-0e97e856486a no longer exists
[AfterEach] [sig-storage] Projected
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  8 16:28:57.365: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-jhgtp" for this suite.
Nov  8 16:29:03.373: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  8 16:29:03.406: INFO: namespace: e2e-tests-projected-jhgtp, resource: bindings, ignored listing per whitelist
Nov  8 16:29:03.426: INFO: namespace e2e-tests-projected-jhgtp deletion completed in 6.059206061s

• [SLOW TEST:8.125 seconds]
[sig-storage] Projected
/go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  8 16:29:03.426: INFO: >>> kubeConfig: /tmp/kubeconfig-235977939
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Nov  8 16:29:03.471: INFO: Creating simple daemon set daemon-set
STEP: Check that daemon pods launch on every node of the cluster.
Nov  8 16:29:03.475: INFO: DaemonSet pods can't tolerate node ip-10-0-0-20.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov  8 16:29:03.476: INFO: Number of nodes with available pods: 0
Nov  8 16:29:03.476: INFO: Node ip-10-0-100-224.ec2.internal is running more than one daemon pod
Nov  8 16:29:04.479: INFO: DaemonSet pods can't tolerate node ip-10-0-0-20.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov  8 16:29:04.480: INFO: Number of nodes with available pods: 0
Nov  8 16:29:04.480: INFO: Node ip-10-0-100-224.ec2.internal is running more than one daemon pod
Nov  8 16:29:05.479: INFO: DaemonSet pods can't tolerate node ip-10-0-0-20.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov  8 16:29:05.480: INFO: Number of nodes with available pods: 2
Nov  8 16:29:05.480: INFO: Number of running nodes: 2, number of available pods: 2
STEP: Update daemon pods image.
STEP: Check that daemon pods images are updated.
Nov  8 16:29:05.494: INFO: Wrong image for pod: daemon-set-9rnpg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov  8 16:29:05.494: INFO: Wrong image for pod: daemon-set-v4knr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov  8 16:29:05.496: INFO: DaemonSet pods can't tolerate node ip-10-0-0-20.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov  8 16:29:06.498: INFO: Wrong image for pod: daemon-set-9rnpg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov  8 16:29:06.498: INFO: Wrong image for pod: daemon-set-v4knr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov  8 16:29:06.500: INFO: DaemonSet pods can't tolerate node ip-10-0-0-20.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov  8 16:29:07.498: INFO: Wrong image for pod: daemon-set-9rnpg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov  8 16:29:07.498: INFO: Wrong image for pod: daemon-set-v4knr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov  8 16:29:07.500: INFO: DaemonSet pods can't tolerate node ip-10-0-0-20.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov  8 16:29:08.498: INFO: Wrong image for pod: daemon-set-9rnpg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov  8 16:29:08.498: INFO: Wrong image for pod: daemon-set-v4knr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov  8 16:29:08.500: INFO: DaemonSet pods can't tolerate node ip-10-0-0-20.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov  8 16:29:09.498: INFO: Wrong image for pod: daemon-set-9rnpg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov  8 16:29:09.498: INFO: Wrong image for pod: daemon-set-v4knr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov  8 16:29:09.500: INFO: DaemonSet pods can't tolerate node ip-10-0-0-20.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov  8 16:29:10.498: INFO: Wrong image for pod: daemon-set-9rnpg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov  8 16:29:10.498: INFO: Wrong image for pod: daemon-set-v4knr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov  8 16:29:10.500: INFO: DaemonSet pods can't tolerate node ip-10-0-0-20.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov  8 16:29:11.498: INFO: Wrong image for pod: daemon-set-9rnpg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov  8 16:29:11.498: INFO: Wrong image for pod: daemon-set-v4knr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov  8 16:29:11.500: INFO: DaemonSet pods can't tolerate node ip-10-0-0-20.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov  8 16:29:12.498: INFO: Wrong image for pod: daemon-set-9rnpg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov  8 16:29:12.498: INFO: Wrong image for pod: daemon-set-v4knr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov  8 16:29:12.500: INFO: DaemonSet pods can't tolerate node ip-10-0-0-20.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov  8 16:29:13.498: INFO: Wrong image for pod: daemon-set-9rnpg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov  8 16:29:13.498: INFO: Wrong image for pod: daemon-set-v4knr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov  8 16:29:13.500: INFO: DaemonSet pods can't tolerate node ip-10-0-0-20.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov  8 16:29:14.498: INFO: Wrong image for pod: daemon-set-9rnpg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov  8 16:29:14.498: INFO: Wrong image for pod: daemon-set-v4knr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov  8 16:29:14.500: INFO: DaemonSet pods can't tolerate node ip-10-0-0-20.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov  8 16:29:15.498: INFO: Wrong image for pod: daemon-set-9rnpg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov  8 16:29:15.498: INFO: Wrong image for pod: daemon-set-v4knr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov  8 16:29:15.500: INFO: DaemonSet pods can't tolerate node ip-10-0-0-20.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov  8 16:29:16.498: INFO: Wrong image for pod: daemon-set-9rnpg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov  8 16:29:16.498: INFO: Wrong image for pod: daemon-set-v4knr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov  8 16:29:16.500: INFO: DaemonSet pods can't tolerate node ip-10-0-0-20.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov  8 16:29:17.498: INFO: Wrong image for pod: daemon-set-9rnpg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov  8 16:29:17.498: INFO: Wrong image for pod: daemon-set-v4knr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov  8 16:29:17.500: INFO: DaemonSet pods can't tolerate node ip-10-0-0-20.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov  8 16:29:18.498: INFO: Wrong image for pod: daemon-set-9rnpg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov  8 16:29:18.498: INFO: Wrong image for pod: daemon-set-v4knr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov  8 16:29:18.500: INFO: DaemonSet pods can't tolerate node ip-10-0-0-20.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov  8 16:29:19.498: INFO: Wrong image for pod: daemon-set-9rnpg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov  8 16:29:19.498: INFO: Wrong image for pod: daemon-set-v4knr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov  8 16:29:19.500: INFO: DaemonSet pods can't tolerate node ip-10-0-0-20.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov  8 16:29:20.498: INFO: Wrong image for pod: daemon-set-9rnpg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov  8 16:29:20.498: INFO: Wrong image for pod: daemon-set-v4knr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov  8 16:29:20.500: INFO: DaemonSet pods can't tolerate node ip-10-0-0-20.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov  8 16:29:21.498: INFO: Wrong image for pod: daemon-set-9rnpg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov  8 16:29:21.498: INFO: Wrong image for pod: daemon-set-v4knr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov  8 16:29:21.500: INFO: DaemonSet pods can't tolerate node ip-10-0-0-20.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov  8 16:29:22.498: INFO: Wrong image for pod: daemon-set-9rnpg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov  8 16:29:22.498: INFO: Wrong image for pod: daemon-set-v4knr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov  8 16:29:22.500: INFO: DaemonSet pods can't tolerate node ip-10-0-0-20.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov  8 16:29:23.498: INFO: Wrong image for pod: daemon-set-9rnpg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov  8 16:29:23.498: INFO: Wrong image for pod: daemon-set-v4knr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov  8 16:29:23.500: INFO: DaemonSet pods can't tolerate node ip-10-0-0-20.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov  8 16:29:24.498: INFO: Wrong image for pod: daemon-set-9rnpg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov  8 16:29:24.498: INFO: Wrong image for pod: daemon-set-v4knr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov  8 16:29:24.500: INFO: DaemonSet pods can't tolerate node ip-10-0-0-20.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov  8 16:29:25.498: INFO: Wrong image for pod: daemon-set-9rnpg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov  8 16:29:25.498: INFO: Wrong image for pod: daemon-set-v4knr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov  8 16:29:25.500: INFO: DaemonSet pods can't tolerate node ip-10-0-0-20.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov  8 16:29:26.498: INFO: Wrong image for pod: daemon-set-9rnpg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov  8 16:29:26.498: INFO: Wrong image for pod: daemon-set-v4knr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov  8 16:29:26.499: INFO: DaemonSet pods can't tolerate node ip-10-0-0-20.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov  8 16:29:27.498: INFO: Wrong image for pod: daemon-set-9rnpg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov  8 16:29:27.498: INFO: Wrong image for pod: daemon-set-v4knr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov  8 16:29:27.500: INFO: DaemonSet pods can't tolerate node ip-10-0-0-20.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov  8 16:29:28.498: INFO: Wrong image for pod: daemon-set-9rnpg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov  8 16:29:28.498: INFO: Wrong image for pod: daemon-set-v4knr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov  8 16:29:28.500: INFO: DaemonSet pods can't tolerate node ip-10-0-0-20.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov  8 16:29:29.498: INFO: Wrong image for pod: daemon-set-9rnpg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov  8 16:29:29.498: INFO: Wrong image for pod: daemon-set-v4knr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov  8 16:29:29.500: INFO: DaemonSet pods can't tolerate node ip-10-0-0-20.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov  8 16:29:30.498: INFO: Wrong image for pod: daemon-set-9rnpg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov  8 16:29:30.498: INFO: Wrong image for pod: daemon-set-v4knr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov  8 16:29:30.500: INFO: DaemonSet pods can't tolerate node ip-10-0-0-20.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov  8 16:29:31.498: INFO: Wrong image for pod: daemon-set-9rnpg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov  8 16:29:31.498: INFO: Wrong image for pod: daemon-set-v4knr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov  8 16:29:31.500: INFO: DaemonSet pods can't tolerate node ip-10-0-0-20.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov  8 16:29:32.498: INFO: Wrong image for pod: daemon-set-9rnpg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov  8 16:29:32.498: INFO: Wrong image for pod: daemon-set-v4knr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov  8 16:29:32.500: INFO: DaemonSet pods can't tolerate node ip-10-0-0-20.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov  8 16:29:33.498: INFO: Wrong image for pod: daemon-set-9rnpg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov  8 16:29:33.498: INFO: Wrong image for pod: daemon-set-v4knr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov  8 16:29:33.500: INFO: DaemonSet pods can't tolerate node ip-10-0-0-20.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov  8 16:29:34.498: INFO: Wrong image for pod: daemon-set-9rnpg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov  8 16:29:34.498: INFO: Wrong image for pod: daemon-set-v4knr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov  8 16:29:34.500: INFO: DaemonSet pods can't tolerate node ip-10-0-0-20.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov  8 16:29:35.498: INFO: Wrong image for pod: daemon-set-9rnpg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov  8 16:29:35.498: INFO: Wrong image for pod: daemon-set-v4knr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov  8 16:29:35.500: INFO: DaemonSet pods can't tolerate node ip-10-0-0-20.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov  8 16:29:36.498: INFO: Wrong image for pod: daemon-set-9rnpg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov  8 16:29:36.498: INFO: Wrong image for pod: daemon-set-v4knr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov  8 16:29:36.500: INFO: DaemonSet pods can't tolerate node ip-10-0-0-20.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov  8 16:29:37.500: INFO: Wrong image for pod: daemon-set-9rnpg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov  8 16:29:37.500: INFO: Wrong image for pod: daemon-set-v4knr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov  8 16:29:37.503: INFO: DaemonSet pods can't tolerate node ip-10-0-0-20.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov  8 16:29:38.498: INFO: Wrong image for pod: daemon-set-9rnpg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov  8 16:29:38.498: INFO: Pod daemon-set-9rnpg is not available
Nov  8 16:29:38.498: INFO: Wrong image for pod: daemon-set-v4knr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov  8 16:29:38.500: INFO: DaemonSet pods can't tolerate node ip-10-0-0-20.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov  8 16:29:39.498: INFO: Wrong image for pod: daemon-set-9rnpg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov  8 16:29:39.498: INFO: Pod daemon-set-9rnpg is not available
Nov  8 16:29:39.498: INFO: Wrong image for pod: daemon-set-v4knr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov  8 16:29:39.500: INFO: DaemonSet pods can't tolerate node ip-10-0-0-20.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov  8 16:29:40.498: INFO: Wrong image for pod: daemon-set-9rnpg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov  8 16:29:40.498: INFO: Pod daemon-set-9rnpg is not available
Nov  8 16:29:40.498: INFO: Wrong image for pod: daemon-set-v4knr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov  8 16:29:40.500: INFO: DaemonSet pods can't tolerate node ip-10-0-0-20.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov  8 16:29:41.498: INFO: Wrong image for pod: daemon-set-9rnpg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov  8 16:29:41.498: INFO: Pod daemon-set-9rnpg is not available
Nov  8 16:29:41.498: INFO: Wrong image for pod: daemon-set-v4knr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov  8 16:29:41.500: INFO: DaemonSet pods can't tolerate node ip-10-0-0-20.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov  8 16:29:42.498: INFO: Wrong image for pod: daemon-set-9rnpg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov  8 16:29:42.498: INFO: Pod daemon-set-9rnpg is not available
Nov  8 16:29:42.498: INFO: Wrong image for pod: daemon-set-v4knr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov  8 16:29:42.500: INFO: DaemonSet pods can't tolerate node ip-10-0-0-20.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov  8 16:29:43.498: INFO: Wrong image for pod: daemon-set-9rnpg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov  8 16:29:43.498: INFO: Pod daemon-set-9rnpg is not available
Nov  8 16:29:43.498: INFO: Wrong image for pod: daemon-set-v4knr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov  8 16:29:43.500: INFO: DaemonSet pods can't tolerate node ip-10-0-0-20.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov  8 16:29:44.498: INFO: Wrong image for pod: daemon-set-9rnpg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov  8 16:29:44.498: INFO: Pod daemon-set-9rnpg is not available
Nov  8 16:29:44.498: INFO: Wrong image for pod: daemon-set-v4knr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov  8 16:29:44.500: INFO: DaemonSet pods can't tolerate node ip-10-0-0-20.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov  8 16:29:45.498: INFO: Wrong image for pod: daemon-set-9rnpg. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov  8 16:29:45.498: INFO: Pod daemon-set-9rnpg is not available
Nov  8 16:29:45.498: INFO: Wrong image for pod: daemon-set-v4knr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov  8 16:29:45.500: INFO: DaemonSet pods can't tolerate node ip-10-0-0-20.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov  8 16:29:46.498: INFO: Pod daemon-set-j4xhl is not available
Nov  8 16:29:46.498: INFO: Wrong image for pod: daemon-set-v4knr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov  8 16:29:46.499: INFO: DaemonSet pods can't tolerate node ip-10-0-0-20.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov  8 16:29:47.498: INFO: Wrong image for pod: daemon-set-v4knr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov  8 16:29:47.500: INFO: DaemonSet pods can't tolerate node ip-10-0-0-20.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov  8 16:29:48.498: INFO: Wrong image for pod: daemon-set-v4knr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov  8 16:29:48.500: INFO: DaemonSet pods can't tolerate node ip-10-0-0-20.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov  8 16:29:49.498: INFO: Wrong image for pod: daemon-set-v4knr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov  8 16:29:49.500: INFO: DaemonSet pods can't tolerate node ip-10-0-0-20.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov  8 16:29:50.498: INFO: Wrong image for pod: daemon-set-v4knr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov  8 16:29:50.500: INFO: DaemonSet pods can't tolerate node ip-10-0-0-20.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov  8 16:29:51.498: INFO: Wrong image for pod: daemon-set-v4knr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov  8 16:29:51.500: INFO: DaemonSet pods can't tolerate node ip-10-0-0-20.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov  8 16:29:52.498: INFO: Wrong image for pod: daemon-set-v4knr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov  8 16:29:52.500: INFO: DaemonSet pods can't tolerate node ip-10-0-0-20.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov  8 16:29:53.498: INFO: Wrong image for pod: daemon-set-v4knr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov  8 16:29:53.500: INFO: DaemonSet pods can't tolerate node ip-10-0-0-20.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov  8 16:29:54.498: INFO: Wrong image for pod: daemon-set-v4knr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov  8 16:29:54.500: INFO: DaemonSet pods can't tolerate node ip-10-0-0-20.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov  8 16:29:55.498: INFO: Wrong image for pod: daemon-set-v4knr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov  8 16:29:55.500: INFO: DaemonSet pods can't tolerate node ip-10-0-0-20.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov  8 16:29:56.498: INFO: Wrong image for pod: daemon-set-v4knr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov  8 16:29:56.500: INFO: DaemonSet pods can't tolerate node ip-10-0-0-20.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov  8 16:29:57.498: INFO: Wrong image for pod: daemon-set-v4knr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov  8 16:29:57.500: INFO: DaemonSet pods can't tolerate node ip-10-0-0-20.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov  8 16:29:58.498: INFO: Wrong image for pod: daemon-set-v4knr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov  8 16:29:58.500: INFO: DaemonSet pods can't tolerate node ip-10-0-0-20.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov  8 16:29:59.501: INFO: Wrong image for pod: daemon-set-v4knr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov  8 16:29:59.503: INFO: DaemonSet pods can't tolerate node ip-10-0-0-20.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov  8 16:30:00.498: INFO: Wrong image for pod: daemon-set-v4knr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov  8 16:30:00.500: INFO: DaemonSet pods can't tolerate node ip-10-0-0-20.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov  8 16:30:01.498: INFO: Wrong image for pod: daemon-set-v4knr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov  8 16:30:01.500: INFO: DaemonSet pods can't tolerate node ip-10-0-0-20.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov  8 16:30:02.498: INFO: Wrong image for pod: daemon-set-v4knr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov  8 16:30:02.500: INFO: DaemonSet pods can't tolerate node ip-10-0-0-20.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov  8 16:30:03.498: INFO: Wrong image for pod: daemon-set-v4knr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov  8 16:30:03.500: INFO: DaemonSet pods can't tolerate node ip-10-0-0-20.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov  8 16:30:04.498: INFO: Wrong image for pod: daemon-set-v4knr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov  8 16:30:04.500: INFO: DaemonSet pods can't tolerate node ip-10-0-0-20.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov  8 16:30:05.498: INFO: Wrong image for pod: daemon-set-v4knr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov  8 16:30:05.500: INFO: DaemonSet pods can't tolerate node ip-10-0-0-20.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov  8 16:30:06.498: INFO: Wrong image for pod: daemon-set-v4knr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov  8 16:30:06.500: INFO: DaemonSet pods can't tolerate node ip-10-0-0-20.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov  8 16:30:07.498: INFO: Wrong image for pod: daemon-set-v4knr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov  8 16:30:07.500: INFO: DaemonSet pods can't tolerate node ip-10-0-0-20.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov  8 16:30:08.498: INFO: Wrong image for pod: daemon-set-v4knr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov  8 16:30:08.500: INFO: DaemonSet pods can't tolerate node ip-10-0-0-20.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov  8 16:30:09.503: INFO: Wrong image for pod: daemon-set-v4knr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov  8 16:30:09.508: INFO: DaemonSet pods can't tolerate node ip-10-0-0-20.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov  8 16:30:10.498: INFO: Wrong image for pod: daemon-set-v4knr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov  8 16:30:10.500: INFO: DaemonSet pods can't tolerate node ip-10-0-0-20.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov  8 16:30:11.498: INFO: Wrong image for pod: daemon-set-v4knr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov  8 16:30:11.500: INFO: DaemonSet pods can't tolerate node ip-10-0-0-20.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov  8 16:30:12.498: INFO: Wrong image for pod: daemon-set-v4knr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov  8 16:30:12.501: INFO: DaemonSet pods can't tolerate node ip-10-0-0-20.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov  8 16:30:13.498: INFO: Wrong image for pod: daemon-set-v4knr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov  8 16:30:13.500: INFO: DaemonSet pods can't tolerate node ip-10-0-0-20.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov  8 16:30:14.498: INFO: Wrong image for pod: daemon-set-v4knr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov  8 16:30:14.500: INFO: DaemonSet pods can't tolerate node ip-10-0-0-20.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov  8 16:30:15.498: INFO: Wrong image for pod: daemon-set-v4knr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov  8 16:30:15.501: INFO: DaemonSet pods can't tolerate node ip-10-0-0-20.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov  8 16:30:16.498: INFO: Wrong image for pod: daemon-set-v4knr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov  8 16:30:16.499: INFO: DaemonSet pods can't tolerate node ip-10-0-0-20.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov  8 16:30:17.498: INFO: Wrong image for pod: daemon-set-v4knr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov  8 16:30:17.498: INFO: Pod daemon-set-v4knr is not available
Nov  8 16:30:17.500: INFO: DaemonSet pods can't tolerate node ip-10-0-0-20.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov  8 16:30:18.498: INFO: Wrong image for pod: daemon-set-v4knr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov  8 16:30:18.498: INFO: Pod daemon-set-v4knr is not available
Nov  8 16:30:18.500: INFO: DaemonSet pods can't tolerate node ip-10-0-0-20.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov  8 16:30:19.498: INFO: Wrong image for pod: daemon-set-v4knr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov  8 16:30:19.498: INFO: Pod daemon-set-v4knr is not available
Nov  8 16:30:19.500: INFO: DaemonSet pods can't tolerate node ip-10-0-0-20.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov  8 16:30:20.498: INFO: Wrong image for pod: daemon-set-v4knr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov  8 16:30:20.498: INFO: Pod daemon-set-v4knr is not available
Nov  8 16:30:20.500: INFO: DaemonSet pods can't tolerate node ip-10-0-0-20.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov  8 16:30:21.498: INFO: Wrong image for pod: daemon-set-v4knr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov  8 16:30:21.498: INFO: Pod daemon-set-v4knr is not available
Nov  8 16:30:21.500: INFO: DaemonSet pods can't tolerate node ip-10-0-0-20.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov  8 16:30:22.498: INFO: Wrong image for pod: daemon-set-v4knr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov  8 16:30:22.498: INFO: Pod daemon-set-v4knr is not available
Nov  8 16:30:22.500: INFO: DaemonSet pods can't tolerate node ip-10-0-0-20.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov  8 16:30:23.498: INFO: Wrong image for pod: daemon-set-v4knr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov  8 16:30:23.498: INFO: Pod daemon-set-v4knr is not available
Nov  8 16:30:23.500: INFO: DaemonSet pods can't tolerate node ip-10-0-0-20.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov  8 16:30:24.498: INFO: Wrong image for pod: daemon-set-v4knr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov  8 16:30:24.498: INFO: Pod daemon-set-v4knr is not available
Nov  8 16:30:24.500: INFO: DaemonSet pods can't tolerate node ip-10-0-0-20.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov  8 16:30:25.498: INFO: Wrong image for pod: daemon-set-v4knr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov  8 16:30:25.498: INFO: Pod daemon-set-v4knr is not available
Nov  8 16:30:25.500: INFO: DaemonSet pods can't tolerate node ip-10-0-0-20.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov  8 16:30:26.498: INFO: Wrong image for pod: daemon-set-v4knr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov  8 16:30:26.498: INFO: Pod daemon-set-v4knr is not available
Nov  8 16:30:26.499: INFO: DaemonSet pods can't tolerate node ip-10-0-0-20.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov  8 16:30:27.498: INFO: Wrong image for pod: daemon-set-v4knr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov  8 16:30:27.498: INFO: Pod daemon-set-v4knr is not available
Nov  8 16:30:27.500: INFO: DaemonSet pods can't tolerate node ip-10-0-0-20.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov  8 16:30:28.498: INFO: Wrong image for pod: daemon-set-v4knr. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Nov  8 16:30:28.498: INFO: Pod daemon-set-v4knr is not available
Nov  8 16:30:28.500: INFO: DaemonSet pods can't tolerate node ip-10-0-0-20.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov  8 16:30:29.498: INFO: Pod daemon-set-w5spk is not available
Nov  8 16:30:29.500: INFO: DaemonSet pods can't tolerate node ip-10-0-0-20.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
STEP: Check that daemon pods are still running on every node of the cluster.
Nov  8 16:30:29.502: INFO: DaemonSet pods can't tolerate node ip-10-0-0-20.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov  8 16:30:29.503: INFO: Number of nodes with available pods: 1
Nov  8 16:30:29.503: INFO: Node ip-10-0-100-254.ec2.internal is running more than one daemon pod
Nov  8 16:30:30.506: INFO: DaemonSet pods can't tolerate node ip-10-0-0-20.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov  8 16:30:30.508: INFO: Number of nodes with available pods: 1
Nov  8 16:30:30.508: INFO: Node ip-10-0-100-254.ec2.internal is running more than one daemon pod
Nov  8 16:30:31.506: INFO: DaemonSet pods can't tolerate node ip-10-0-0-20.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov  8 16:30:31.508: INFO: Number of nodes with available pods: 1
Nov  8 16:30:31.508: INFO: Node ip-10-0-100-254.ec2.internal is running more than one daemon pod
Nov  8 16:30:32.506: INFO: DaemonSet pods can't tolerate node ip-10-0-0-20.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov  8 16:30:32.507: INFO: Number of nodes with available pods: 2
Nov  8 16:30:32.507: INFO: Number of running nodes: 2, number of available pods: 2
[AfterEach] [sig-apps] Daemon set [Serial]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting {extensions DaemonSet} daemon-set in namespace e2e-tests-daemonsets-c4dqp, will wait for the garbage collector to delete the pods
Nov  8 16:30:32.569: INFO: Deleting {extensions DaemonSet} daemon-set took: 2.97677ms
Nov  8 16:30:32.670: INFO: Terminating {extensions DaemonSet} daemon-set pods took: 100.150593ms
Nov  8 16:30:38.671: INFO: Number of nodes with available pods: 0
Nov  8 16:30:38.671: INFO: Number of running nodes: 0, number of available pods: 0
Nov  8 16:30:38.673: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-c4dqp/daemonsets","resourceVersion":"9660"},"items":null}

Nov  8 16:30:38.674: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-c4dqp/pods","resourceVersion":"9660"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  8 16:30:38.679: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-c4dqp" for this suite.
Nov  8 16:30:44.686: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  8 16:30:44.704: INFO: namespace: e2e-tests-daemonsets-c4dqp, resource: bindings, ignored listing per whitelist
Nov  8 16:30:44.739: INFO: namespace e2e-tests-daemonsets-c4dqp deletion completed in 6.058160886s

• [SLOW TEST:101.312 seconds]
[sig-apps] Daemon set [Serial]
/go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl replace 
  should update a single-container pod's image  [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  8 16:30:44.739: INFO: >>> kubeConfig: /tmp/kubeconfig-235977939
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Kubectl replace
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1511
[It] should update a single-container pod's image  [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Nov  8 16:30:44.776: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-235977939 run e2e-test-nginx-pod --generator=run-pod/v1 --image=docker.io/library/nginx:1.14-alpine --labels=run=e2e-test-nginx-pod --namespace=e2e-tests-kubectl-g2dzf'
Nov  8 16:30:45.011: INFO: stderr: ""
Nov  8 16:30:45.011: INFO: stdout: "pod/e2e-test-nginx-pod created\n"
STEP: verifying the pod e2e-test-nginx-pod is running
STEP: verifying the pod e2e-test-nginx-pod was created
Nov  8 16:30:50.062: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-235977939 get pod e2e-test-nginx-pod --namespace=e2e-tests-kubectl-g2dzf -o json'
Nov  8 16:30:50.121: INFO: stderr: ""
Nov  8 16:30:50.121: INFO: stdout: "{\n    \"apiVersion\": \"v1\",\n    \"kind\": \"Pod\",\n    \"metadata\": {\n        \"annotations\": {\n            \"cni.projectcalico.org/podIP\": \"192.168.1.45/32\"\n        },\n        \"creationTimestamp\": \"2018-11-08T16:30:45Z\",\n        \"labels\": {\n            \"run\": \"e2e-test-nginx-pod\"\n        },\n        \"name\": \"e2e-test-nginx-pod\",\n        \"namespace\": \"e2e-tests-kubectl-g2dzf\",\n        \"resourceVersion\": \"9718\",\n        \"selfLink\": \"/api/v1/namespaces/e2e-tests-kubectl-g2dzf/pods/e2e-test-nginx-pod\",\n        \"uid\": \"a42e8081-e373-11e8-a466-0a0beb0244cc\"\n    },\n    \"spec\": {\n        \"containers\": [\n            {\n                \"image\": \"docker.io/library/nginx:1.14-alpine\",\n                \"imagePullPolicy\": \"IfNotPresent\",\n                \"name\": \"e2e-test-nginx-pod\",\n                \"resources\": {},\n                \"terminationMessagePath\": \"/dev/termination-log\",\n                \"terminationMessagePolicy\": \"File\",\n                \"volumeMounts\": [\n                    {\n                        \"mountPath\": \"/var/run/secrets/kubernetes.io/serviceaccount\",\n                        \"name\": \"default-token-gbtrb\",\n                        \"readOnly\": true\n                    }\n                ]\n            }\n        ],\n        \"dnsPolicy\": \"ClusterFirst\",\n        \"nodeName\": \"ip-10-0-100-224.ec2.internal\",\n        \"priority\": 0,\n        \"restartPolicy\": \"Always\",\n        \"schedulerName\": \"default-scheduler\",\n        \"securityContext\": {},\n        \"serviceAccount\": \"default\",\n        \"serviceAccountName\": \"default\",\n        \"terminationGracePeriodSeconds\": 30,\n        \"tolerations\": [\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/not-ready\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            },\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/unreachable\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            }\n        ],\n        \"volumes\": [\n            {\n                \"name\": \"default-token-gbtrb\",\n                \"secret\": {\n                    \"defaultMode\": 420,\n                    \"secretName\": \"default-token-gbtrb\"\n                }\n            }\n        ]\n    },\n    \"status\": {\n        \"conditions\": [\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2018-11-08T16:30:45Z\",\n                \"status\": \"True\",\n                \"type\": \"Initialized\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2018-11-08T16:30:46Z\",\n                \"status\": \"True\",\n                \"type\": \"Ready\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2018-11-08T16:30:46Z\",\n                \"status\": \"True\",\n                \"type\": \"ContainersReady\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2018-11-08T16:30:45Z\",\n                \"status\": \"True\",\n                \"type\": \"PodScheduled\"\n            }\n        ],\n        \"containerStatuses\": [\n            {\n                \"containerID\": \"docker://f09bd8dd358ad55ca56a0c5b8fcfb412e44556ff17d3ee6793fa549e234efd01\",\n                \"image\": \"nginx:1.14-alpine\",\n                \"imageID\": \"docker-pullable://nginx@sha256:75cf17cdf89cbd8da65c83050ebdab1026b98cf217442d6a1f2a8892f47967d7\",\n                \"lastState\": {},\n                \"name\": \"e2e-test-nginx-pod\",\n                \"ready\": true,\n                \"restartCount\": 0,\n                \"state\": {\n                    \"running\": {\n                        \"startedAt\": \"2018-11-08T16:30:45Z\"\n                    }\n                }\n            }\n        ],\n        \"hostIP\": \"10.0.100.224\",\n        \"phase\": \"Running\",\n        \"podIP\": \"192.168.1.45\",\n        \"qosClass\": \"BestEffort\",\n        \"startTime\": \"2018-11-08T16:30:45Z\"\n    }\n}\n"
STEP: replace the image in the pod
Nov  8 16:30:50.121: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-235977939 replace -f - --namespace=e2e-tests-kubectl-g2dzf'
Nov  8 16:30:50.253: INFO: stderr: ""
Nov  8 16:30:50.253: INFO: stdout: "pod/e2e-test-nginx-pod replaced\n"
STEP: verifying the pod e2e-test-nginx-pod has the right image docker.io/library/busybox:1.29
[AfterEach] [k8s.io] Kubectl replace
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1516
Nov  8 16:30:50.254: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-235977939 delete pods e2e-test-nginx-pod --namespace=e2e-tests-kubectl-g2dzf'
Nov  8 16:30:52.422: INFO: stderr: ""
Nov  8 16:30:52.422: INFO: stdout: "pod \"e2e-test-nginx-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  8 16:30:52.422: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-g2dzf" for this suite.
Nov  8 16:30:58.430: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  8 16:30:58.477: INFO: namespace: e2e-tests-kubectl-g2dzf, resource: bindings, ignored listing per whitelist
Nov  8 16:30:58.482: INFO: namespace e2e-tests-kubectl-g2dzf deletion completed in 6.057265497s

• [SLOW TEST:13.743 seconds]
[sig-cli] Kubectl client
/go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl replace
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should update a single-container pod's image  [Conformance]
    /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[k8s.io] Variable Expansion 
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Variable Expansion
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  8 16:30:58.482: INFO: >>> kubeConfig: /tmp/kubeconfig-235977939
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test env composition
Nov  8 16:30:58.523: INFO: Waiting up to 5m0s for pod "var-expansion-ac3cc133-e373-11e8-b0fd-0e97e856486a" in namespace "e2e-tests-var-expansion-95xr8" to be "success or failure"
Nov  8 16:30:58.524: INFO: Pod "var-expansion-ac3cc133-e373-11e8-b0fd-0e97e856486a": Phase="Pending", Reason="", readiness=false. Elapsed: 1.685225ms
Nov  8 16:31:00.526: INFO: Pod "var-expansion-ac3cc133-e373-11e8-b0fd-0e97e856486a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00372215s
STEP: Saw pod success
Nov  8 16:31:00.526: INFO: Pod "var-expansion-ac3cc133-e373-11e8-b0fd-0e97e856486a" satisfied condition "success or failure"
Nov  8 16:31:00.528: INFO: Trying to get logs from node ip-10-0-100-224.ec2.internal pod var-expansion-ac3cc133-e373-11e8-b0fd-0e97e856486a container dapi-container: <nil>
STEP: delete the pod
Nov  8 16:31:00.538: INFO: Waiting for pod var-expansion-ac3cc133-e373-11e8-b0fd-0e97e856486a to disappear
Nov  8 16:31:00.539: INFO: Pod var-expansion-ac3cc133-e373-11e8-b0fd-0e97e856486a no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  8 16:31:00.539: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-var-expansion-95xr8" for this suite.
Nov  8 16:31:06.546: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  8 16:31:06.563: INFO: namespace: e2e-tests-var-expansion-95xr8, resource: bindings, ignored listing per whitelist
Nov  8 16:31:06.600: INFO: namespace e2e-tests-var-expansion-95xr8 deletion completed in 6.05870028s

• [SLOW TEST:8.118 seconds]
[k8s.io] Variable Expansion
/go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  8 16:31:06.600: INFO: >>> kubeConfig: /tmp/kubeconfig-235977939
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: Gathering metrics
Nov  8 16:31:12.650: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  8 16:31:12.650: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-hqxw4" for this suite.
Nov  8 16:31:18.658: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  8 16:31:18.680: INFO: namespace: e2e-tests-gc-hqxw4, resource: bindings, ignored listing per whitelist
Nov  8 16:31:18.711: INFO: namespace e2e-tests-gc-hqxw4 deletion completed in 6.059156303s

• [SLOW TEST:12.111 seconds]
[sig-api-machinery] Garbage collector
/go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-network] DNS 
  should provide DNS for the cluster  [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] DNS
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  8 16:31:18.711: INFO: >>> kubeConfig: /tmp/kubeconfig-235977939
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for the cluster  [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(dig +notcp +noall +answer +search kubernetes.default A)" && echo OK > /results/wheezy_udp@kubernetes.default;test -n "$$(dig +tcp +noall +answer +search kubernetes.default A)" && echo OK > /results/wheezy_tcp@kubernetes.default;test -n "$$(dig +notcp +noall +answer +search kubernetes.default.svc A)" && echo OK > /results/wheezy_udp@kubernetes.default.svc;test -n "$$(dig +tcp +noall +answer +search kubernetes.default.svc A)" && echo OK > /results/wheezy_tcp@kubernetes.default.svc;test -n "$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && echo OK > /results/wheezy_udp@kubernetes.default.svc.cluster.local;test -n "$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && echo OK > /results/wheezy_tcp@kubernetes.default.svc.cluster.local;test -n "$$(getent hosts dns-querier-1.dns-test-service.e2e-tests-dns-h7mm4.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-1.dns-test-service.e2e-tests-dns-h7mm4.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/wheezy_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-h7mm4.pod.cluster.local"}');test -n "$$(dig +notcp +noall +answer +search $${podARec} A)" && echo OK > /results/wheezy_udp@PodARecord;test -n "$$(dig +tcp +noall +answer +search $${podARec} A)" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(dig +notcp +noall +answer +search kubernetes.default A)" && echo OK > /results/jessie_udp@kubernetes.default;test -n "$$(dig +tcp +noall +answer +search kubernetes.default A)" && echo OK > /results/jessie_tcp@kubernetes.default;test -n "$$(dig +notcp +noall +answer +search kubernetes.default.svc A)" && echo OK > /results/jessie_udp@kubernetes.default.svc;test -n "$$(dig +tcp +noall +answer +search kubernetes.default.svc A)" && echo OK > /results/jessie_tcp@kubernetes.default.svc;test -n "$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && echo OK > /results/jessie_udp@kubernetes.default.svc.cluster.local;test -n "$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && echo OK > /results/jessie_tcp@kubernetes.default.svc.cluster.local;test -n "$$(getent hosts dns-querier-1.dns-test-service.e2e-tests-dns-h7mm4.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-1.dns-test-service.e2e-tests-dns-h7mm4.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/jessie_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-h7mm4.pod.cluster.local"}');test -n "$$(dig +notcp +noall +answer +search $${podARec} A)" && echo OK > /results/jessie_udp@PodARecord;test -n "$$(dig +tcp +noall +answer +search $${podARec} A)" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Nov  8 16:31:38.799: INFO: DNS probes using e2e-tests-dns-h7mm4/dns-test-b84c557a-e373-11e8-b0fd-0e97e856486a succeeded

STEP: deleting the pod
[AfterEach] [sig-network] DNS
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  8 16:31:38.804: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-dns-h7mm4" for this suite.
Nov  8 16:31:44.811: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  8 16:31:44.845: INFO: namespace: e2e-tests-dns-h7mm4, resource: bindings, ignored listing per whitelist
Nov  8 16:31:44.864: INFO: namespace e2e-tests-dns-h7mm4 deletion completed in 6.05768671s

• [SLOW TEST:26.153 seconds]
[sig-network] DNS
/go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide DNS for the cluster  [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-api-machinery] Watchers 
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Watchers
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  8 16:31:44.864: INFO: >>> kubeConfig: /tmp/kubeconfig-235977939
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a watch on configmaps
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: closing the watch once it receives two notifications
Nov  8 16:31:44.906: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-qjg7j,SelfLink:/api/v1/namespaces/e2e-tests-watch-qjg7j/configmaps/e2e-watch-test-watch-closed,UID:c7e22b34-e373-11e8-a466-0a0beb0244cc,ResourceVersion:10122,Generation:0,CreationTimestamp:2018-11-08 16:31:44 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Nov  8 16:31:44.907: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-qjg7j,SelfLink:/api/v1/namespaces/e2e-tests-watch-qjg7j/configmaps/e2e-watch-test-watch-closed,UID:c7e22b34-e373-11e8-a466-0a0beb0244cc,ResourceVersion:10123,Generation:0,CreationTimestamp:2018-11-08 16:31:44 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time, while the watch is closed
STEP: creating a new watch on configmaps from the last resource version observed by the first watch
STEP: deleting the configmap
STEP: Expecting to observe notifications for all changes to the configmap since the first watch closed
Nov  8 16:31:44.912: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-qjg7j,SelfLink:/api/v1/namespaces/e2e-tests-watch-qjg7j/configmaps/e2e-watch-test-watch-closed,UID:c7e22b34-e373-11e8-a466-0a0beb0244cc,ResourceVersion:10124,Generation:0,CreationTimestamp:2018-11-08 16:31:44 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Nov  8 16:31:44.913: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-qjg7j,SelfLink:/api/v1/namespaces/e2e-tests-watch-qjg7j/configmaps/e2e-watch-test-watch-closed,UID:c7e22b34-e373-11e8-a466-0a0beb0244cc,ResourceVersion:10125,Generation:0,CreationTimestamp:2018-11-08 16:31:44 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  8 16:31:44.913: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-qjg7j" for this suite.
Nov  8 16:31:50.920: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  8 16:31:50.969: INFO: namespace: e2e-tests-watch-qjg7j, resource: bindings, ignored listing per whitelist
Nov  8 16:31:50.972: INFO: namespace e2e-tests-watch-qjg7j deletion completed in 6.057957s

• [SLOW TEST:6.109 seconds]
[sig-api-machinery] Watchers
/go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[k8s.io] Pods 
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  8 16:31:50.973: INFO: >>> kubeConfig: /tmp/kubeconfig-235977939
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Nov  8 16:31:53.524: INFO: Successfully updated pod "pod-update-activedeadlineseconds-cb860e33-e373-11e8-b0fd-0e97e856486a"
Nov  8 16:31:53.524: INFO: Waiting up to 5m0s for pod "pod-update-activedeadlineseconds-cb860e33-e373-11e8-b0fd-0e97e856486a" in namespace "e2e-tests-pods-8gkp5" to be "terminated due to deadline exceeded"
Nov  8 16:31:53.526: INFO: Pod "pod-update-activedeadlineseconds-cb860e33-e373-11e8-b0fd-0e97e856486a": Phase="Running", Reason="", readiness=true. Elapsed: 1.404176ms
Nov  8 16:31:55.528: INFO: Pod "pod-update-activedeadlineseconds-cb860e33-e373-11e8-b0fd-0e97e856486a": Phase="Running", Reason="", readiness=true. Elapsed: 2.003419788s
Nov  8 16:31:57.530: INFO: Pod "pod-update-activedeadlineseconds-cb860e33-e373-11e8-b0fd-0e97e856486a": Phase="Failed", Reason="DeadlineExceeded", readiness=false. Elapsed: 4.00548129s
Nov  8 16:31:57.530: INFO: Pod "pod-update-activedeadlineseconds-cb860e33-e373-11e8-b0fd-0e97e856486a" satisfied condition "terminated due to deadline exceeded"
[AfterEach] [k8s.io] Pods
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  8 16:31:57.530: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-8gkp5" for this suite.
Nov  8 16:32:03.542: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  8 16:32:03.591: INFO: namespace: e2e-tests-pods-8gkp5, resource: bindings, ignored listing per whitelist
Nov  8 16:32:03.596: INFO: namespace e2e-tests-pods-8gkp5 deletion completed in 6.063817837s

• [SLOW TEST:12.624 seconds]
[k8s.io] Pods
/go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  8 16:32:03.597: INFO: >>> kubeConfig: /tmp/kubeconfig-235977939
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-map-d30c8d8e-e373-11e8-b0fd-0e97e856486a
STEP: Creating a pod to test consume configMaps
Nov  8 16:32:03.639: INFO: Waiting up to 5m0s for pod "pod-configmaps-d30cc76d-e373-11e8-b0fd-0e97e856486a" in namespace "e2e-tests-configmap-fxxv5" to be "success or failure"
Nov  8 16:32:03.641: INFO: Pod "pod-configmaps-d30cc76d-e373-11e8-b0fd-0e97e856486a": Phase="Pending", Reason="", readiness=false. Elapsed: 1.291736ms
Nov  8 16:32:05.643: INFO: Pod "pod-configmaps-d30cc76d-e373-11e8-b0fd-0e97e856486a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.003421198s
STEP: Saw pod success
Nov  8 16:32:05.643: INFO: Pod "pod-configmaps-d30cc76d-e373-11e8-b0fd-0e97e856486a" satisfied condition "success or failure"
Nov  8 16:32:05.644: INFO: Trying to get logs from node ip-10-0-100-224.ec2.internal pod pod-configmaps-d30cc76d-e373-11e8-b0fd-0e97e856486a container configmap-volume-test: <nil>
STEP: delete the pod
Nov  8 16:32:05.654: INFO: Waiting for pod pod-configmaps-d30cc76d-e373-11e8-b0fd-0e97e856486a to disappear
Nov  8 16:32:05.655: INFO: Pod pod-configmaps-d30cc76d-e373-11e8-b0fd-0e97e856486a no longer exists
[AfterEach] [sig-storage] ConfigMap
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  8 16:32:05.655: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-fxxv5" for this suite.
Nov  8 16:32:11.663: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  8 16:32:11.672: INFO: namespace: e2e-tests-configmap-fxxv5, resource: bindings, ignored listing per whitelist
Nov  8 16:32:11.719: INFO: namespace e2e-tests-configmap-fxxv5 deletion completed in 6.061938144s

• [SLOW TEST:8.123 seconds]
[sig-storage] ConfigMap
/go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl expose 
  should create services for rc  [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  8 16:32:11.719: INFO: >>> kubeConfig: /tmp/kubeconfig-235977939
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should create services for rc  [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating Redis RC
Nov  8 16:32:11.756: INFO: namespace e2e-tests-kubectl-h56ws
Nov  8 16:32:11.756: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-235977939 create -f - --namespace=e2e-tests-kubectl-h56ws'
Nov  8 16:32:11.886: INFO: stderr: ""
Nov  8 16:32:11.886: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
Nov  8 16:32:12.888: INFO: Selector matched 1 pods for map[app:redis]
Nov  8 16:32:12.888: INFO: Found 0 / 1
Nov  8 16:32:13.888: INFO: Selector matched 1 pods for map[app:redis]
Nov  8 16:32:13.888: INFO: Found 1 / 1
Nov  8 16:32:13.888: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Nov  8 16:32:13.890: INFO: Selector matched 1 pods for map[app:redis]
Nov  8 16:32:13.890: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Nov  8 16:32:13.890: INFO: wait on redis-master startup in e2e-tests-kubectl-h56ws 
Nov  8 16:32:13.890: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-235977939 logs redis-master-zcp5j redis-master --namespace=e2e-tests-kubectl-h56ws'
Nov  8 16:32:13.969: INFO: stderr: ""
Nov  8 16:32:13.969: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 08 Nov 16:32:12.639 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 08 Nov 16:32:12.639 # Server started, Redis version 3.2.12\n1:M 08 Nov 16:32:12.639 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 08 Nov 16:32:12.639 * The server is now ready to accept connections on port 6379\n"
STEP: exposing RC
Nov  8 16:32:13.969: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-235977939 expose rc redis-master --name=rm2 --port=1234 --target-port=6379 --namespace=e2e-tests-kubectl-h56ws'
Nov  8 16:32:14.043: INFO: stderr: ""
Nov  8 16:32:14.043: INFO: stdout: "service/rm2 exposed\n"
Nov  8 16:32:14.045: INFO: Service rm2 in namespace e2e-tests-kubectl-h56ws found.
STEP: exposing service
Nov  8 16:32:16.048: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-235977939 expose service rm2 --name=rm3 --port=2345 --target-port=6379 --namespace=e2e-tests-kubectl-h56ws'
Nov  8 16:32:16.120: INFO: stderr: ""
Nov  8 16:32:16.121: INFO: stdout: "service/rm3 exposed\n"
Nov  8 16:32:16.124: INFO: Service rm3 in namespace e2e-tests-kubectl-h56ws found.
[AfterEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  8 16:32:18.128: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-h56ws" for this suite.
Nov  8 16:32:40.136: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  8 16:32:40.182: INFO: namespace: e2e-tests-kubectl-h56ws, resource: bindings, ignored listing per whitelist
Nov  8 16:32:40.193: INFO: namespace e2e-tests-kubectl-h56ws deletion completed in 22.062620395s

• [SLOW TEST:28.473 seconds]
[sig-cli] Kubectl client
/go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl expose
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create services for rc  [Conformance]
    /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run pod 
  should create a pod from an image when restart is Never  [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  8 16:32:40.193: INFO: >>> kubeConfig: /tmp/kubeconfig-235977939
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Kubectl run pod
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1475
[It] should create a pod from an image when restart is Never  [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Nov  8 16:32:40.232: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-235977939 run e2e-test-nginx-pod --restart=Never --generator=run-pod/v1 --image=docker.io/library/nginx:1.14-alpine --namespace=e2e-tests-kubectl-k9mfz'
Nov  8 16:32:40.300: INFO: stderr: ""
Nov  8 16:32:40.300: INFO: stdout: "pod/e2e-test-nginx-pod created\n"
STEP: verifying the pod e2e-test-nginx-pod was created
[AfterEach] [k8s.io] Kubectl run pod
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1480
Nov  8 16:32:40.302: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-235977939 delete pods e2e-test-nginx-pod --namespace=e2e-tests-kubectl-k9mfz'
Nov  8 16:32:46.081: INFO: stderr: ""
Nov  8 16:32:46.081: INFO: stdout: "pod \"e2e-test-nginx-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  8 16:32:46.081: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-k9mfz" for this suite.
Nov  8 16:32:52.089: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  8 16:32:52.093: INFO: namespace: e2e-tests-kubectl-k9mfz, resource: bindings, ignored listing per whitelist
Nov  8 16:32:52.141: INFO: namespace e2e-tests-kubectl-k9mfz deletion completed in 6.056989668s

• [SLOW TEST:11.948 seconds]
[sig-cli] Kubectl client
/go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run pod
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create a pod from an image when restart is Never  [Conformance]
    /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run job 
  should create a job from an image when restart is OnFailure  [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  8 16:32:52.141: INFO: >>> kubeConfig: /tmp/kubeconfig-235977939
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Kubectl run job
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1402
[It] should create a job from an image when restart is OnFailure  [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Nov  8 16:32:52.179: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-235977939 run e2e-test-nginx-job --restart=OnFailure --generator=job/v1 --image=docker.io/library/nginx:1.14-alpine --namespace=e2e-tests-kubectl-5t4b8'
Nov  8 16:32:52.247: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl create instead.\n"
Nov  8 16:32:52.247: INFO: stdout: "job.batch/e2e-test-nginx-job created\n"
STEP: verifying the job e2e-test-nginx-job was created
[AfterEach] [k8s.io] Kubectl run job
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1407
Nov  8 16:32:52.250: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-235977939 delete jobs e2e-test-nginx-job --namespace=e2e-tests-kubectl-5t4b8'
Nov  8 16:32:52.313: INFO: stderr: ""
Nov  8 16:32:52.313: INFO: stdout: "job.batch \"e2e-test-nginx-job\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  8 16:32:52.313: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-5t4b8" for this suite.
Nov  8 16:32:58.321: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  8 16:32:58.345: INFO: namespace: e2e-tests-kubectl-5t4b8, resource: bindings, ignored listing per whitelist
Nov  8 16:32:58.375: INFO: namespace e2e-tests-kubectl-5t4b8 deletion completed in 6.06105095s

• [SLOW TEST:6.235 seconds]
[sig-cli] Kubectl client
/go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run job
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create a job from an image when restart is OnFailure  [Conformance]
    /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Projected 
  should provide podname only [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  8 16:32:58.376: INFO: >>> kubeConfig: /tmp/kubeconfig-235977939
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should provide podname only [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Nov  8 16:32:58.413: INFO: Waiting up to 5m0s for pod "downwardapi-volume-f3b29027-e373-11e8-b0fd-0e97e856486a" in namespace "e2e-tests-projected-54gqq" to be "success or failure"
Nov  8 16:32:58.414: INFO: Pod "downwardapi-volume-f3b29027-e373-11e8-b0fd-0e97e856486a": Phase="Pending", Reason="", readiness=false. Elapsed: 1.371771ms
Nov  8 16:33:00.416: INFO: Pod "downwardapi-volume-f3b29027-e373-11e8-b0fd-0e97e856486a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.003103797s
STEP: Saw pod success
Nov  8 16:33:00.416: INFO: Pod "downwardapi-volume-f3b29027-e373-11e8-b0fd-0e97e856486a" satisfied condition "success or failure"
Nov  8 16:33:00.418: INFO: Trying to get logs from node ip-10-0-100-224.ec2.internal pod downwardapi-volume-f3b29027-e373-11e8-b0fd-0e97e856486a container client-container: <nil>
STEP: delete the pod
Nov  8 16:33:00.427: INFO: Waiting for pod downwardapi-volume-f3b29027-e373-11e8-b0fd-0e97e856486a to disappear
Nov  8 16:33:00.428: INFO: Pod downwardapi-volume-f3b29027-e373-11e8-b0fd-0e97e856486a no longer exists
[AfterEach] [sig-storage] Projected
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  8 16:33:00.429: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-54gqq" for this suite.
Nov  8 16:33:06.436: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  8 16:33:06.459: INFO: namespace: e2e-tests-projected-54gqq, resource: bindings, ignored listing per whitelist
Nov  8 16:33:06.488: INFO: namespace e2e-tests-projected-54gqq deletion completed in 6.058007522s

• [SLOW TEST:8.113 seconds]
[sig-storage] Projected
/go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should provide podname only [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop exec hook properly [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  8 16:33:06.489: INFO: >>> kubeConfig: /tmp/kubeconfig-235977939
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop exec hook properly [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Nov  8 16:33:10.542: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Nov  8 16:33:10.544: INFO: Pod pod-with-prestop-exec-hook still exists
Nov  8 16:33:12.544: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Nov  8 16:33:12.546: INFO: Pod pod-with-prestop-exec-hook still exists
Nov  8 16:33:14.544: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Nov  8 16:33:14.546: INFO: Pod pod-with-prestop-exec-hook still exists
Nov  8 16:33:16.544: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Nov  8 16:33:16.546: INFO: Pod pod-with-prestop-exec-hook still exists
Nov  8 16:33:18.544: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Nov  8 16:33:18.546: INFO: Pod pod-with-prestop-exec-hook still exists
Nov  8 16:33:20.544: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Nov  8 16:33:20.546: INFO: Pod pod-with-prestop-exec-hook still exists
Nov  8 16:33:22.544: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Nov  8 16:33:22.546: INFO: Pod pod-with-prestop-exec-hook still exists
Nov  8 16:33:24.544: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Nov  8 16:33:24.546: INFO: Pod pod-with-prestop-exec-hook still exists
Nov  8 16:33:26.544: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Nov  8 16:33:26.546: INFO: Pod pod-with-prestop-exec-hook still exists
Nov  8 16:33:28.544: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Nov  8 16:33:28.546: INFO: Pod pod-with-prestop-exec-hook still exists
Nov  8 16:33:30.544: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Nov  8 16:33:30.546: INFO: Pod pod-with-prestop-exec-hook still exists
Nov  8 16:33:32.544: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Nov  8 16:33:32.546: INFO: Pod pod-with-prestop-exec-hook still exists
Nov  8 16:33:34.544: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Nov  8 16:33:34.546: INFO: Pod pod-with-prestop-exec-hook still exists
Nov  8 16:33:36.544: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Nov  8 16:33:36.546: INFO: Pod pod-with-prestop-exec-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  8 16:33:36.550: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-lifecycle-hook-8djmb" for this suite.
Nov  8 16:33:58.557: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  8 16:33:58.578: INFO: namespace: e2e-tests-container-lifecycle-hook-8djmb, resource: bindings, ignored listing per whitelist
Nov  8 16:33:58.611: INFO: namespace e2e-tests-container-lifecycle-hook-8djmb deletion completed in 22.058985542s

• [SLOW TEST:52.123 seconds]
[k8s.io] Container Lifecycle Hook
/go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when create a pod with lifecycle hook
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute prestop exec hook properly [NodeConformance] [Conformance]
    /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  8 16:33:58.611: INFO: >>> kubeConfig: /tmp/kubeconfig-235977939
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-179a33c7-e374-11e8-b0fd-0e97e856486a
STEP: Creating a pod to test consume secrets
Nov  8 16:33:58.653: INFO: Waiting up to 5m0s for pod "pod-secrets-179a7424-e374-11e8-b0fd-0e97e856486a" in namespace "e2e-tests-secrets-qdhjg" to be "success or failure"
Nov  8 16:33:58.654: INFO: Pod "pod-secrets-179a7424-e374-11e8-b0fd-0e97e856486a": Phase="Pending", Reason="", readiness=false. Elapsed: 1.312822ms
Nov  8 16:34:00.656: INFO: Pod "pod-secrets-179a7424-e374-11e8-b0fd-0e97e856486a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.003157545s
STEP: Saw pod success
Nov  8 16:34:00.656: INFO: Pod "pod-secrets-179a7424-e374-11e8-b0fd-0e97e856486a" satisfied condition "success or failure"
Nov  8 16:34:00.658: INFO: Trying to get logs from node ip-10-0-100-224.ec2.internal pod pod-secrets-179a7424-e374-11e8-b0fd-0e97e856486a container secret-volume-test: <nil>
STEP: delete the pod
Nov  8 16:34:00.670: INFO: Waiting for pod pod-secrets-179a7424-e374-11e8-b0fd-0e97e856486a to disappear
Nov  8 16:34:00.671: INFO: Pod pod-secrets-179a7424-e374-11e8-b0fd-0e97e856486a no longer exists
[AfterEach] [sig-storage] Secrets
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  8 16:34:00.671: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-qdhjg" for this suite.
Nov  8 16:34:06.678: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  8 16:34:06.703: INFO: namespace: e2e-tests-secrets-qdhjg, resource: bindings, ignored listing per whitelist
Nov  8 16:34:06.731: INFO: namespace e2e-tests-secrets-qdhjg deletion completed in 6.057859627s

• [SLOW TEST:8.120 seconds]
[sig-storage] Secrets
/go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-apps] Deployment 
  deployment should support proportional scaling [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  8 16:34:06.731: INFO: >>> kubeConfig: /tmp/kubeconfig-235977939
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should support proportional scaling [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Nov  8 16:34:06.768: INFO: Creating deployment "nginx-deployment"
Nov  8 16:34:06.770: INFO: Waiting for observed generation 1
Nov  8 16:34:08.773: INFO: Waiting for all required pods to come up
Nov  8 16:34:08.776: INFO: Pod name nginx: Found 10 pods out of 10
STEP: ensuring each pod is running
Nov  8 16:34:10.780: INFO: Waiting for deployment "nginx-deployment" to complete
Nov  8 16:34:10.783: INFO: Updating deployment "nginx-deployment" with a non-existent image
Nov  8 16:34:10.787: INFO: Updating deployment nginx-deployment
Nov  8 16:34:10.787: INFO: Waiting for observed generation 2
Nov  8 16:34:12.790: INFO: Waiting for the first rollout's replicaset to have .status.availableReplicas = 8
Nov  8 16:34:12.792: INFO: Waiting for the first rollout's replicaset to have .spec.replicas = 8
Nov  8 16:34:12.793: INFO: Waiting for the first rollout's replicaset of deployment "nginx-deployment" to have desired number of replicas
Nov  8 16:34:12.797: INFO: Verifying that the second rollout's replicaset has .status.availableReplicas = 0
Nov  8 16:34:12.797: INFO: Waiting for the second rollout's replicaset to have .spec.replicas = 5
Nov  8 16:34:12.798: INFO: Waiting for the second rollout's replicaset of deployment "nginx-deployment" to have desired number of replicas
Nov  8 16:34:12.801: INFO: Verifying that deployment "nginx-deployment" has minimum required number of available replicas
Nov  8 16:34:12.801: INFO: Scaling up the deployment "nginx-deployment" from 10 to 30
Nov  8 16:34:12.805: INFO: Updating deployment nginx-deployment
Nov  8 16:34:12.805: INFO: Waiting for the replicasets of deployment "nginx-deployment" to have desired number of replicas
Nov  8 16:34:12.809: INFO: Verifying that first rollout's replicaset has .spec.replicas = 20
Nov  8 16:34:12.812: INFO: Verifying that second rollout's replicaset has .spec.replicas = 13
[AfterEach] [sig-apps] Deployment
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Nov  8 16:34:12.829: INFO: Deployment "nginx-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment,GenerateName:,Namespace:e2e-tests-deployment-s6w4q,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-s6w4q/deployments/nginx-deployment,UID:1c714c7e-e374-11e8-a466-0a0beb0244cc,ResourceVersion:10814,Generation:3,CreationTimestamp:2018-11-08 16:34:06 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*30,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:2,MaxSurge:3,},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:3,Replicas:13,UpdatedReplicas:5,AvailableReplicas:8,UnavailableReplicas:25,Conditions:[{Progressing True 2018-11-08 16:34:10 +0000 UTC 2018-11-08 16:34:06 +0000 UTC ReplicaSetUpdated ReplicaSet "nginx-deployment-7dc8f79789" is progressing.} {Available False 2018-11-08 16:34:12 +0000 UTC 2018-11-08 16:34:12 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}],ReadyReplicas:8,CollisionCount:nil,},}

Nov  8 16:34:12.836: INFO: New ReplicaSet "nginx-deployment-7dc8f79789" of Deployment "nginx-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789,GenerateName:,Namespace:e2e-tests-deployment-s6w4q,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-s6w4q/replicasets/nginx-deployment-7dc8f79789,UID:1ed68197-e374-11e8-a466-0a0beb0244cc,ResourceVersion:10799,Generation:3,CreationTimestamp:2018-11-08 16:34:10 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 30,deployment.kubernetes.io/max-replicas: 33,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment nginx-deployment 1c714c7e-e374-11e8-a466-0a0beb0244cc 0xc422598117 0xc422598118}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*13,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:5,FullyLabeledReplicas:5,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Nov  8 16:34:12.836: INFO: All old ReplicaSets of Deployment "nginx-deployment":
Nov  8 16:34:12.836: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b,GenerateName:,Namespace:e2e-tests-deployment-s6w4q,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-s6w4q/replicasets/nginx-deployment-7f9675fb8b,UID:1c71eb08-e374-11e8-a466-0a0beb0244cc,ResourceVersion:10798,Generation:3,CreationTimestamp:2018-11-08 16:34:06 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 30,deployment.kubernetes.io/max-replicas: 33,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment nginx-deployment 1c714c7e-e374-11e8-a466-0a0beb0244cc 0xc4225981d7 0xc4225981d8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*20,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:8,FullyLabeledReplicas:8,ObservedGeneration:2,ReadyReplicas:8,AvailableReplicas:8,Conditions:[],},}
Nov  8 16:34:12.860: INFO: Pod "nginx-deployment-7dc8f79789-6srjl" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-6srjl,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-s6w4q,SelfLink:/api/v1/namespaces/e2e-tests-deployment-s6w4q/pods/nginx-deployment-7dc8f79789-6srjl,UID:200b88af-e374-11e8-a466-0a0beb0244cc,ResourceVersion:10808,Generation:0,CreationTimestamp:2018-11-08 16:34:12 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 1ed68197-e374-11e8-a466-0a0beb0244cc 0xc4220585f7 0xc4220585f8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-qdt6t {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-qdt6t,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-qdt6t true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-100-224.ec2.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc422058660} {node.kubernetes.io/unreachable Exists  NoExecute 0xc422058680}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-11-08 16:34:12 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Nov  8 16:34:12.860: INFO: Pod "nginx-deployment-7dc8f79789-86fq5" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-86fq5,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-s6w4q,SelfLink:/api/v1/namespaces/e2e-tests-deployment-s6w4q/pods/nginx-deployment-7dc8f79789-86fq5,UID:1ed7ebaf-e374-11e8-a466-0a0beb0244cc,ResourceVersion:10772,Generation:0,CreationTimestamp:2018-11-08 16:34:10 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{cni.projectcalico.org/podIP: 192.168.2.26/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 1ed68197-e374-11e8-a466-0a0beb0244cc 0xc422058700 0xc422058701}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-qdt6t {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-qdt6t,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-qdt6t true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-100-254.ec2.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc422058770} {node.kubernetes.io/unreachable Exists  NoExecute 0xc422058790}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-11-08 16:34:10 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-11-08 16:34:10 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-11-08 16:34:10 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-11-08 16:34:10 +0000 UTC  }],Message:,Reason:,HostIP:10.0.100.254,PodIP:,StartTime:2018-11-08 16:34:10 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Nov  8 16:34:12.860: INFO: Pod "nginx-deployment-7dc8f79789-8hcjq" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-8hcjq,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-s6w4q,SelfLink:/api/v1/namespaces/e2e-tests-deployment-s6w4q/pods/nginx-deployment-7dc8f79789-8hcjq,UID:200e5a0e-e374-11e8-a466-0a0beb0244cc,ResourceVersion:10845,Generation:0,CreationTimestamp:2018-11-08 16:34:12 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 1ed68197-e374-11e8-a466-0a0beb0244cc 0xc422058850 0xc422058851}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-qdt6t {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-qdt6t,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-qdt6t true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-100-254.ec2.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc4220588c0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc4220588e0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-11-08 16:34:12 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Nov  8 16:34:12.861: INFO: Pod "nginx-deployment-7dc8f79789-cjhkx" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-cjhkx,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-s6w4q,SelfLink:/api/v1/namespaces/e2e-tests-deployment-s6w4q/pods/nginx-deployment-7dc8f79789-cjhkx,UID:201088db-e374-11e8-a466-0a0beb0244cc,ResourceVersion:10840,Generation:0,CreationTimestamp:2018-11-08 16:34:12 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 1ed68197-e374-11e8-a466-0a0beb0244cc 0xc422058950 0xc422058951}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-qdt6t {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-qdt6t,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-qdt6t true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc4220589c0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc4220589e0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Nov  8 16:34:12.861: INFO: Pod "nginx-deployment-7dc8f79789-ckns7" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-ckns7,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-s6w4q,SelfLink:/api/v1/namespaces/e2e-tests-deployment-s6w4q/pods/nginx-deployment-7dc8f79789-ckns7,UID:1ed7fa05-e374-11e8-a466-0a0beb0244cc,ResourceVersion:10789,Generation:0,CreationTimestamp:2018-11-08 16:34:10 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{cni.projectcalico.org/podIP: 192.168.1.65/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 1ed68197-e374-11e8-a466-0a0beb0244cc 0xc422058a47 0xc422058a48}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-qdt6t {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-qdt6t,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-qdt6t true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-100-224.ec2.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc422058ab0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc422058ad0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-11-08 16:34:10 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-11-08 16:34:10 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-11-08 16:34:10 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-11-08 16:34:10 +0000 UTC  }],Message:,Reason:,HostIP:10.0.100.224,PodIP:192.168.1.65,StartTime:2018-11-08 16:34:10 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = Error response from daemon: manifest for nginx:404 not found,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Nov  8 16:34:12.861: INFO: Pod "nginx-deployment-7dc8f79789-cpwhk" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-cpwhk,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-s6w4q,SelfLink:/api/v1/namespaces/e2e-tests-deployment-s6w4q/pods/nginx-deployment-7dc8f79789-cpwhk,UID:1edc8911-e374-11e8-a466-0a0beb0244cc,ResourceVersion:10777,Generation:0,CreationTimestamp:2018-11-08 16:34:10 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{cni.projectcalico.org/podIP: 192.168.2.28/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 1ed68197-e374-11e8-a466-0a0beb0244cc 0xc422058bc0 0xc422058bc1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-qdt6t {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-qdt6t,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-qdt6t true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-100-254.ec2.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc422058c30} {node.kubernetes.io/unreachable Exists  NoExecute 0xc422058c50}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-11-08 16:34:10 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-11-08 16:34:10 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-11-08 16:34:10 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-11-08 16:34:10 +0000 UTC  }],Message:,Reason:,HostIP:10.0.100.254,PodIP:,StartTime:2018-11-08 16:34:10 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Nov  8 16:34:12.861: INFO: Pod "nginx-deployment-7dc8f79789-cv7jz" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-cv7jz,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-s6w4q,SelfLink:/api/v1/namespaces/e2e-tests-deployment-s6w4q/pods/nginx-deployment-7dc8f79789-cv7jz,UID:200e504e-e374-11e8-a466-0a0beb0244cc,ResourceVersion:10841,Generation:0,CreationTimestamp:2018-11-08 16:34:12 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 1ed68197-e374-11e8-a466-0a0beb0244cc 0xc422058d20 0xc422058d21}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-qdt6t {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-qdt6t,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-qdt6t true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-100-224.ec2.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc422058d90} {node.kubernetes.io/unreachable Exists  NoExecute 0xc422058db0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-11-08 16:34:12 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Nov  8 16:34:12.861: INFO: Pod "nginx-deployment-7dc8f79789-gsxvr" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-gsxvr,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-s6w4q,SelfLink:/api/v1/namespaces/e2e-tests-deployment-s6w4q/pods/nginx-deployment-7dc8f79789-gsxvr,UID:200c20e0-e374-11e8-a466-0a0beb0244cc,ResourceVersion:10828,Generation:0,CreationTimestamp:2018-11-08 16:34:12 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 1ed68197-e374-11e8-a466-0a0beb0244cc 0xc422058e20 0xc422058e21}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-qdt6t {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-qdt6t,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-qdt6t true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-100-254.ec2.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc422058ea0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc422058ec0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-11-08 16:34:12 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Nov  8 16:34:12.861: INFO: Pod "nginx-deployment-7dc8f79789-hnsdj" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-hnsdj,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-s6w4q,SelfLink:/api/v1/namespaces/e2e-tests-deployment-s6w4q/pods/nginx-deployment-7dc8f79789-hnsdj,UID:200e6404-e374-11e8-a466-0a0beb0244cc,ResourceVersion:10848,Generation:0,CreationTimestamp:2018-11-08 16:34:12 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 1ed68197-e374-11e8-a466-0a0beb0244cc 0xc422058f30 0xc422058f31}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-qdt6t {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-qdt6t,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-qdt6t true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-100-224.ec2.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc422058fb0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc422058fd0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-11-08 16:34:12 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Nov  8 16:34:12.862: INFO: Pod "nginx-deployment-7dc8f79789-j8rvk" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-j8rvk,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-s6w4q,SelfLink:/api/v1/namespaces/e2e-tests-deployment-s6w4q/pods/nginx-deployment-7dc8f79789-j8rvk,UID:1ed6eedd-e374-11e8-a466-0a0beb0244cc,ResourceVersion:10793,Generation:0,CreationTimestamp:2018-11-08 16:34:10 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{cni.projectcalico.org/podIP: 192.168.1.64/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 1ed68197-e374-11e8-a466-0a0beb0244cc 0xc422059060 0xc422059061}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-qdt6t {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-qdt6t,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-qdt6t true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-100-224.ec2.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc422059160} {node.kubernetes.io/unreachable Exists  NoExecute 0xc422059180}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-11-08 16:34:10 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-11-08 16:34:10 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-11-08 16:34:10 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-11-08 16:34:10 +0000 UTC  }],Message:,Reason:,HostIP:10.0.100.224,PodIP:192.168.1.64,StartTime:2018-11-08 16:34:10 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = Error response from daemon: manifest for nginx:404 not found,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Nov  8 16:34:12.862: INFO: Pod "nginx-deployment-7dc8f79789-kbvkb" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-kbvkb,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-s6w4q,SelfLink:/api/v1/namespaces/e2e-tests-deployment-s6w4q/pods/nginx-deployment-7dc8f79789-kbvkb,UID:1edc0b7f-e374-11e8-a466-0a0beb0244cc,ResourceVersion:10774,Generation:0,CreationTimestamp:2018-11-08 16:34:10 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{cni.projectcalico.org/podIP: 192.168.2.27/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 1ed68197-e374-11e8-a466-0a0beb0244cc 0xc422059280 0xc422059281}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-qdt6t {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-qdt6t,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-qdt6t true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-100-254.ec2.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc4220595c0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc4220595e0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-11-08 16:34:10 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-11-08 16:34:10 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-11-08 16:34:10 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-11-08 16:34:10 +0000 UTC  }],Message:,Reason:,HostIP:10.0.100.254,PodIP:,StartTime:2018-11-08 16:34:10 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Nov  8 16:34:12.862: INFO: Pod "nginx-deployment-7dc8f79789-l48rq" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-l48rq,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-s6w4q,SelfLink:/api/v1/namespaces/e2e-tests-deployment-s6w4q/pods/nginx-deployment-7dc8f79789-l48rq,UID:200dff22-e374-11e8-a466-0a0beb0244cc,ResourceVersion:10837,Generation:0,CreationTimestamp:2018-11-08 16:34:12 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 1ed68197-e374-11e8-a466-0a0beb0244cc 0xc4220596b0 0xc4220596b1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-qdt6t {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-qdt6t,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-qdt6t true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-100-224.ec2.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc4220598d0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc4220598f0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-11-08 16:34:12 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Nov  8 16:34:12.862: INFO: Pod "nginx-deployment-7dc8f79789-zcxx5" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-zcxx5,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-s6w4q,SelfLink:/api/v1/namespaces/e2e-tests-deployment-s6w4q/pods/nginx-deployment-7dc8f79789-zcxx5,UID:200c0f01-e374-11e8-a466-0a0beb0244cc,ResourceVersion:10819,Generation:0,CreationTimestamp:2018-11-08 16:34:12 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 1ed68197-e374-11e8-a466-0a0beb0244cc 0xc422059970 0xc422059971}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-qdt6t {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-qdt6t,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-qdt6t true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-100-224.ec2.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc422059a50} {node.kubernetes.io/unreachable Exists  NoExecute 0xc422059a70}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-11-08 16:34:12 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Nov  8 16:34:12.862: INFO: Pod "nginx-deployment-7f9675fb8b-5znv7" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-5znv7,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-s6w4q,SelfLink:/api/v1/namespaces/e2e-tests-deployment-s6w4q/pods/nginx-deployment-7f9675fb8b-5znv7,UID:1c7355d9-e374-11e8-a466-0a0beb0244cc,ResourceVersion:10699,Generation:0,CreationTimestamp:2018-11-08 16:34:06 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{cni.projectcalico.org/podIP: 192.168.1.60/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 1c71eb08-e374-11e8-a466-0a0beb0244cc 0xc422059b00 0xc422059b01}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-qdt6t {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-qdt6t,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-qdt6t true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-100-224.ec2.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc422059b60} {node.kubernetes.io/unreachable Exists  NoExecute 0xc422059b90}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-11-08 16:34:06 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-11-08 16:34:08 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2018-11-08 16:34:08 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-11-08 16:34:06 +0000 UTC  }],Message:,Reason:,HostIP:10.0.100.224,PodIP:192.168.1.60,StartTime:2018-11-08 16:34:06 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2018-11-08 16:34:07 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:75cf17cdf89cbd8da65c83050ebdab1026b98cf217442d6a1f2a8892f47967d7 docker://3099c852470eb21dc57d7c3d05673a0233b8692a8b280a65d70f5e1e9f212e4b}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Nov  8 16:34:12.862: INFO: Pod "nginx-deployment-7f9675fb8b-765pv" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-765pv,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-s6w4q,SelfLink:/api/v1/namespaces/e2e-tests-deployment-s6w4q/pods/nginx-deployment-7f9675fb8b-765pv,UID:1c756b32-e374-11e8-a466-0a0beb0244cc,ResourceVersion:10705,Generation:0,CreationTimestamp:2018-11-08 16:34:06 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{cni.projectcalico.org/podIP: 192.168.1.61/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 1c71eb08-e374-11e8-a466-0a0beb0244cc 0xc422059c97 0xc422059c98}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-qdt6t {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-qdt6t,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-qdt6t true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-100-224.ec2.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc422059d70} {node.kubernetes.io/unreachable Exists  NoExecute 0xc422059d90}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-11-08 16:34:06 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-11-08 16:34:08 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2018-11-08 16:34:08 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-11-08 16:34:06 +0000 UTC  }],Message:,Reason:,HostIP:10.0.100.224,PodIP:192.168.1.61,StartTime:2018-11-08 16:34:06 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2018-11-08 16:34:07 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:75cf17cdf89cbd8da65c83050ebdab1026b98cf217442d6a1f2a8892f47967d7 docker://dca7d4a03769fd63f0e5ab940ec2e616c2ec4f9bedd2d6469aef972b3b5bd275}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Nov  8 16:34:12.863: INFO: Pod "nginx-deployment-7f9675fb8b-922gd" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-922gd,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-s6w4q,SelfLink:/api/v1/namespaces/e2e-tests-deployment-s6w4q/pods/nginx-deployment-7f9675fb8b-922gd,UID:200e328e-e374-11e8-a466-0a0beb0244cc,ResourceVersion:10842,Generation:0,CreationTimestamp:2018-11-08 16:34:12 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 1c71eb08-e374-11e8-a466-0a0beb0244cc 0xc422059e67 0xc422059e68}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-qdt6t {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-qdt6t,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-qdt6t true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-100-254.ec2.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc422059ed0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc422059f00}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-11-08 16:34:12 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Nov  8 16:34:12.863: INFO: Pod "nginx-deployment-7f9675fb8b-95dv7" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-95dv7,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-s6w4q,SelfLink:/api/v1/namespaces/e2e-tests-deployment-s6w4q/pods/nginx-deployment-7f9675fb8b-95dv7,UID:1c75529d-e374-11e8-a466-0a0beb0244cc,ResourceVersion:10696,Generation:0,CreationTimestamp:2018-11-08 16:34:06 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{cni.projectcalico.org/podIP: 192.168.1.62/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 1c71eb08-e374-11e8-a466-0a0beb0244cc 0xc422059fe0 0xc422059fe1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-qdt6t {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-qdt6t,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-qdt6t true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-100-224.ec2.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc421a00040} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421a00060}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-11-08 16:34:06 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-11-08 16:34:08 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2018-11-08 16:34:08 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-11-08 16:34:06 +0000 UTC  }],Message:,Reason:,HostIP:10.0.100.224,PodIP:192.168.1.62,StartTime:2018-11-08 16:34:06 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2018-11-08 16:34:07 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:75cf17cdf89cbd8da65c83050ebdab1026b98cf217442d6a1f2a8892f47967d7 docker://9e686311098e6c0981fd0c94bc2ee44246c0c129fa7b5f690e94528b1bac381c}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Nov  8 16:34:12.863: INFO: Pod "nginx-deployment-7f9675fb8b-9g444" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-9g444,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-s6w4q,SelfLink:/api/v1/namespaces/e2e-tests-deployment-s6w4q/pods/nginx-deployment-7f9675fb8b-9g444,UID:200e790f-e374-11e8-a466-0a0beb0244cc,ResourceVersion:10843,Generation:0,CreationTimestamp:2018-11-08 16:34:12 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 1c71eb08-e374-11e8-a466-0a0beb0244cc 0xc421a00127 0xc421a00128}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-qdt6t {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-qdt6t,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-qdt6t true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-100-254.ec2.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc421a00190} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421a001b0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-11-08 16:34:12 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Nov  8 16:34:12.863: INFO: Pod "nginx-deployment-7f9675fb8b-cv6df" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-cv6df,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-s6w4q,SelfLink:/api/v1/namespaces/e2e-tests-deployment-s6w4q/pods/nginx-deployment-7f9675fb8b-cv6df,UID:200cd8ff-e374-11e8-a466-0a0beb0244cc,ResourceVersion:10832,Generation:0,CreationTimestamp:2018-11-08 16:34:12 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 1c71eb08-e374-11e8-a466-0a0beb0244cc 0xc421a00220 0xc421a00221}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-qdt6t {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-qdt6t,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-qdt6t true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-100-224.ec2.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc421a00280} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421a002a0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-11-08 16:34:12 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Nov  8 16:34:12.864: INFO: Pod "nginx-deployment-7f9675fb8b-dbv4c" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-dbv4c,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-s6w4q,SelfLink:/api/v1/namespaces/e2e-tests-deployment-s6w4q/pods/nginx-deployment-7f9675fb8b-dbv4c,UID:200e82ab-e374-11e8-a466-0a0beb0244cc,ResourceVersion:10844,Generation:0,CreationTimestamp:2018-11-08 16:34:12 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 1c71eb08-e374-11e8-a466-0a0beb0244cc 0xc421a00310 0xc421a00311}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-qdt6t {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-qdt6t,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-qdt6t true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-100-224.ec2.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc421a00370} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421a00390}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-11-08 16:34:12 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Nov  8 16:34:12.864: INFO: Pod "nginx-deployment-7f9675fb8b-dd2wn" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-dd2wn,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-s6w4q,SelfLink:/api/v1/namespaces/e2e-tests-deployment-s6w4q/pods/nginx-deployment-7f9675fb8b-dd2wn,UID:1c7453b5-e374-11e8-a466-0a0beb0244cc,ResourceVersion:10684,Generation:0,CreationTimestamp:2018-11-08 16:34:06 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{cni.projectcalico.org/podIP: 192.168.2.23/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 1c71eb08-e374-11e8-a466-0a0beb0244cc 0xc421a00430 0xc421a00431}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-qdt6t {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-qdt6t,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-qdt6t true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-100-254.ec2.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc421a00490} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421a004b0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-11-08 16:34:06 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-11-08 16:34:08 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2018-11-08 16:34:08 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-11-08 16:34:06 +0000 UTC  }],Message:,Reason:,HostIP:10.0.100.254,PodIP:192.168.2.23,StartTime:2018-11-08 16:34:06 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2018-11-08 16:34:07 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:75cf17cdf89cbd8da65c83050ebdab1026b98cf217442d6a1f2a8892f47967d7 docker://4164a0cd2a8ffb7e7e0581714703863365e6fa2001b3272e1277a6dd74050174}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Nov  8 16:34:12.864: INFO: Pod "nginx-deployment-7f9675fb8b-fdrfj" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-fdrfj,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-s6w4q,SelfLink:/api/v1/namespaces/e2e-tests-deployment-s6w4q/pods/nginx-deployment-7f9675fb8b-fdrfj,UID:200d00d1-e374-11e8-a466-0a0beb0244cc,ResourceVersion:10825,Generation:0,CreationTimestamp:2018-11-08 16:34:12 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 1c71eb08-e374-11e8-a466-0a0beb0244cc 0xc421a00577 0xc421a00578}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-qdt6t {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-qdt6t,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-qdt6t true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-100-224.ec2.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc421a005f0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421a00610}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-11-08 16:34:12 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Nov  8 16:34:12.864: INFO: Pod "nginx-deployment-7f9675fb8b-g4tbm" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-g4tbm,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-s6w4q,SelfLink:/api/v1/namespaces/e2e-tests-deployment-s6w4q/pods/nginx-deployment-7f9675fb8b-g4tbm,UID:200abe7f-e374-11e8-a466-0a0beb0244cc,ResourceVersion:10829,Generation:0,CreationTimestamp:2018-11-08 16:34:12 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 1c71eb08-e374-11e8-a466-0a0beb0244cc 0xc421a00680 0xc421a00681}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-qdt6t {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-qdt6t,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-qdt6t true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-100-254.ec2.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc421a006e0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421a00700}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-11-08 16:34:12 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-11-08 16:34:12 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-11-08 16:34:12 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-11-08 16:34:12 +0000 UTC  }],Message:,Reason:,HostIP:10.0.100.254,PodIP:,StartTime:2018-11-08 16:34:12 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Nov  8 16:34:12.864: INFO: Pod "nginx-deployment-7f9675fb8b-jn4zx" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-jn4zx,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-s6w4q,SelfLink:/api/v1/namespaces/e2e-tests-deployment-s6w4q/pods/nginx-deployment-7f9675fb8b-jn4zx,UID:200cf36e-e374-11e8-a466-0a0beb0244cc,ResourceVersion:10830,Generation:0,CreationTimestamp:2018-11-08 16:34:12 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 1c71eb08-e374-11e8-a466-0a0beb0244cc 0xc421a007c7 0xc421a007c8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-qdt6t {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-qdt6t,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-qdt6t true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-100-254.ec2.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc421a00830} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421a00850}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-11-08 16:34:12 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Nov  8 16:34:12.865: INFO: Pod "nginx-deployment-7f9675fb8b-l6s77" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-l6s77,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-s6w4q,SelfLink:/api/v1/namespaces/e2e-tests-deployment-s6w4q/pods/nginx-deployment-7f9675fb8b-l6s77,UID:200e6ec9-e374-11e8-a466-0a0beb0244cc,ResourceVersion:10846,Generation:0,CreationTimestamp:2018-11-08 16:34:12 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 1c71eb08-e374-11e8-a466-0a0beb0244cc 0xc421a008c0 0xc421a008c1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-qdt6t {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-qdt6t,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-qdt6t true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-100-224.ec2.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc421a00920} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421a00940}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-11-08 16:34:12 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Nov  8 16:34:12.865: INFO: Pod "nginx-deployment-7f9675fb8b-mbdr6" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-mbdr6,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-s6w4q,SelfLink:/api/v1/namespaces/e2e-tests-deployment-s6w4q/pods/nginx-deployment-7f9675fb8b-mbdr6,UID:1c74514d-e374-11e8-a466-0a0beb0244cc,ResourceVersion:10708,Generation:0,CreationTimestamp:2018-11-08 16:34:06 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{cni.projectcalico.org/podIP: 192.168.1.63/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 1c71eb08-e374-11e8-a466-0a0beb0244cc 0xc421a009d0 0xc421a009d1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-qdt6t {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-qdt6t,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-qdt6t true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-100-224.ec2.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc421a00a30} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421a00a50}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-11-08 16:34:06 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-11-08 16:34:08 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2018-11-08 16:34:08 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-11-08 16:34:06 +0000 UTC  }],Message:,Reason:,HostIP:10.0.100.224,PodIP:192.168.1.63,StartTime:2018-11-08 16:34:06 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2018-11-08 16:34:07 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:75cf17cdf89cbd8da65c83050ebdab1026b98cf217442d6a1f2a8892f47967d7 docker://d72ececf833d240ba75307d935133c2eb23b7b346608ae2a59372ac8d15f637a}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Nov  8 16:34:12.865: INFO: Pod "nginx-deployment-7f9675fb8b-mtvcf" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-mtvcf,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-s6w4q,SelfLink:/api/v1/namespaces/e2e-tests-deployment-s6w4q/pods/nginx-deployment-7f9675fb8b-mtvcf,UID:200bad75-e374-11e8-a466-0a0beb0244cc,ResourceVersion:10812,Generation:0,CreationTimestamp:2018-11-08 16:34:12 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 1c71eb08-e374-11e8-a466-0a0beb0244cc 0xc421a00b17 0xc421a00b18}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-qdt6t {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-qdt6t,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-qdt6t true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-100-224.ec2.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc421a00b90} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421a00bb0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-11-08 16:34:12 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Nov  8 16:34:12.865: INFO: Pod "nginx-deployment-7f9675fb8b-nbs88" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-nbs88,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-s6w4q,SelfLink:/api/v1/namespaces/e2e-tests-deployment-s6w4q/pods/nginx-deployment-7f9675fb8b-nbs88,UID:1c7447ad-e374-11e8-a466-0a0beb0244cc,ResourceVersion:10692,Generation:0,CreationTimestamp:2018-11-08 16:34:06 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{cni.projectcalico.org/podIP: 192.168.2.22/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 1c71eb08-e374-11e8-a466-0a0beb0244cc 0xc421a00c30 0xc421a00c31}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-qdt6t {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-qdt6t,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-qdt6t true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-100-254.ec2.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc421a00c90} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421a00cb0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-11-08 16:34:06 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-11-08 16:34:08 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2018-11-08 16:34:08 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-11-08 16:34:06 +0000 UTC  }],Message:,Reason:,HostIP:10.0.100.254,PodIP:192.168.2.22,StartTime:2018-11-08 16:34:06 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2018-11-08 16:34:07 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:75cf17cdf89cbd8da65c83050ebdab1026b98cf217442d6a1f2a8892f47967d7 docker://408e26049bd90413b57564d0dbd2d5213440e8b57c729b428c093f47413c1a10}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Nov  8 16:34:12.866: INFO: Pod "nginx-deployment-7f9675fb8b-qg6f6" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-qg6f6,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-s6w4q,SelfLink:/api/v1/namespaces/e2e-tests-deployment-s6w4q/pods/nginx-deployment-7f9675fb8b-qg6f6,UID:200e42e9-e374-11e8-a466-0a0beb0244cc,ResourceVersion:10847,Generation:0,CreationTimestamp:2018-11-08 16:34:12 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 1c71eb08-e374-11e8-a466-0a0beb0244cc 0xc421a00d77 0xc421a00d78}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-qdt6t {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-qdt6t,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-qdt6t true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-100-254.ec2.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc421a00df0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421a00e10}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-11-08 16:34:12 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Nov  8 16:34:12.866: INFO: Pod "nginx-deployment-7f9675fb8b-rs2np" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-rs2np,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-s6w4q,SelfLink:/api/v1/namespaces/e2e-tests-deployment-s6w4q/pods/nginx-deployment-7f9675fb8b-rs2np,UID:200bbbf7-e374-11e8-a466-0a0beb0244cc,ResourceVersion:10813,Generation:0,CreationTimestamp:2018-11-08 16:34:12 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 1c71eb08-e374-11e8-a466-0a0beb0244cc 0xc421a010b0 0xc421a010b1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-qdt6t {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-qdt6t,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-qdt6t true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-100-254.ec2.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc421a01110} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421a01150}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-11-08 16:34:12 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Nov  8 16:34:12.866: INFO: Pod "nginx-deployment-7f9675fb8b-tlttb" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-tlttb,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-s6w4q,SelfLink:/api/v1/namespaces/e2e-tests-deployment-s6w4q/pods/nginx-deployment-7f9675fb8b-tlttb,UID:1c72dc53-e374-11e8-a466-0a0beb0244cc,ResourceVersion:10702,Generation:0,CreationTimestamp:2018-11-08 16:34:06 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{cni.projectcalico.org/podIP: 192.168.1.59/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 1c71eb08-e374-11e8-a466-0a0beb0244cc 0xc421a014e0 0xc421a014e1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-qdt6t {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-qdt6t,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-qdt6t true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-100-224.ec2.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc421a01540} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421a01560}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-11-08 16:34:06 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-11-08 16:34:08 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2018-11-08 16:34:08 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-11-08 16:34:06 +0000 UTC  }],Message:,Reason:,HostIP:10.0.100.224,PodIP:192.168.1.59,StartTime:2018-11-08 16:34:06 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2018-11-08 16:34:07 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:75cf17cdf89cbd8da65c83050ebdab1026b98cf217442d6a1f2a8892f47967d7 docker://bcc519dc97fce66c3fec87cff0f26f287f615ffa6428c32c5f510d98c995ac68}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Nov  8 16:34:12.866: INFO: Pod "nginx-deployment-7f9675fb8b-wlg58" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-wlg58,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-s6w4q,SelfLink:/api/v1/namespaces/e2e-tests-deployment-s6w4q/pods/nginx-deployment-7f9675fb8b-wlg58,UID:1c755ee7-e374-11e8-a466-0a0beb0244cc,ResourceVersion:10676,Generation:0,CreationTimestamp:2018-11-08 16:34:06 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{cni.projectcalico.org/podIP: 192.168.2.24/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 1c71eb08-e374-11e8-a466-0a0beb0244cc 0xc421a01657 0xc421a01658}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-qdt6t {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-qdt6t,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-qdt6t true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-100-254.ec2.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc421a01700} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421a01720}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-11-08 16:34:06 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-11-08 16:34:07 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2018-11-08 16:34:07 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-11-08 16:34:06 +0000 UTC  }],Message:,Reason:,HostIP:10.0.100.254,PodIP:192.168.2.24,StartTime:2018-11-08 16:34:06 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2018-11-08 16:34:07 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:75cf17cdf89cbd8da65c83050ebdab1026b98cf217442d6a1f2a8892f47967d7 docker://d3d73b8e7b2e3d665120545293d4cf2dfbaff322171534585195e7dc08db5343}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Nov  8 16:34:12.868: INFO: Pod "nginx-deployment-7f9675fb8b-xvr6v" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-xvr6v,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-s6w4q,SelfLink:/api/v1/namespaces/e2e-tests-deployment-s6w4q/pods/nginx-deployment-7f9675fb8b-xvr6v,UID:200d0c9e-e374-11e8-a466-0a0beb0244cc,ResourceVersion:10831,Generation:0,CreationTimestamp:2018-11-08 16:34:12 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 1c71eb08-e374-11e8-a466-0a0beb0244cc 0xc421a017f7 0xc421a017f8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-qdt6t {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-qdt6t,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-qdt6t true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-100-254.ec2.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc421a018f0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421a01910}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-11-08 16:34:12 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  8 16:34:12.868: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-s6w4q" for this suite.
Nov  8 16:34:18.883: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  8 16:34:18.916: INFO: namespace: e2e-tests-deployment-s6w4q, resource: bindings, ignored listing per whitelist
Nov  8 16:34:18.942: INFO: namespace e2e-tests-deployment-s6w4q deletion completed in 6.069903097s

• [SLOW TEST:12.210 seconds]
[sig-apps] Deployment
/go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  deployment should support proportional scaling [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  8 16:34:18.942: INFO: >>> kubeConfig: /tmp/kubeconfig-235977939
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-map-23ba2c28-e374-11e8-b0fd-0e97e856486a
STEP: Creating a pod to test consume configMaps
Nov  8 16:34:18.995: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-23ba6867-e374-11e8-b0fd-0e97e856486a" in namespace "e2e-tests-projected-jd5g7" to be "success or failure"
Nov  8 16:34:18.996: INFO: Pod "pod-projected-configmaps-23ba6867-e374-11e8-b0fd-0e97e856486a": Phase="Pending", Reason="", readiness=false. Elapsed: 1.307357ms
Nov  8 16:34:20.998: INFO: Pod "pod-projected-configmaps-23ba6867-e374-11e8-b0fd-0e97e856486a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.002894306s
Nov  8 16:34:23.000: INFO: Pod "pod-projected-configmaps-23ba6867-e374-11e8-b0fd-0e97e856486a": Phase="Pending", Reason="", readiness=false. Elapsed: 4.004502325s
Nov  8 16:34:25.001: INFO: Pod "pod-projected-configmaps-23ba6867-e374-11e8-b0fd-0e97e856486a": Phase="Pending", Reason="", readiness=false. Elapsed: 6.006214305s
Nov  8 16:34:27.003: INFO: Pod "pod-projected-configmaps-23ba6867-e374-11e8-b0fd-0e97e856486a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.007936656s
STEP: Saw pod success
Nov  8 16:34:27.003: INFO: Pod "pod-projected-configmaps-23ba6867-e374-11e8-b0fd-0e97e856486a" satisfied condition "success or failure"
Nov  8 16:34:27.005: INFO: Trying to get logs from node ip-10-0-100-224.ec2.internal pod pod-projected-configmaps-23ba6867-e374-11e8-b0fd-0e97e856486a container projected-configmap-volume-test: <nil>
STEP: delete the pod
Nov  8 16:34:27.018: INFO: Waiting for pod pod-projected-configmaps-23ba6867-e374-11e8-b0fd-0e97e856486a to disappear
Nov  8 16:34:27.020: INFO: Pod pod-projected-configmaps-23ba6867-e374-11e8-b0fd-0e97e856486a no longer exists
[AfterEach] [sig-storage] Projected
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  8 16:34:27.020: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-jd5g7" for this suite.
Nov  8 16:34:33.027: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  8 16:34:33.058: INFO: namespace: e2e-tests-projected-jd5g7, resource: bindings, ignored listing per whitelist
Nov  8 16:34:33.080: INFO: namespace e2e-tests-projected-jd5g7 deletion completed in 6.058170753s

• [SLOW TEST:14.138 seconds]
[sig-storage] Projected
/go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[k8s.io] Pods 
  should get a host IP [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  8 16:34:33.080: INFO: >>> kubeConfig: /tmp/kubeconfig-235977939
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should get a host IP [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating pod
Nov  8 16:34:35.130: INFO: Pod pod-hostip-2c25e512-e374-11e8-b0fd-0e97e856486a has hostIP: 10.0.100.224
[AfterEach] [k8s.io] Pods
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  8 16:34:35.130: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-4c7qr" for this suite.
Nov  8 16:34:57.137: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  8 16:34:57.178: INFO: namespace: e2e-tests-pods-4c7qr, resource: bindings, ignored listing per whitelist
Nov  8 16:34:57.188: INFO: namespace e2e-tests-pods-4c7qr deletion completed in 22.056560101s

• [SLOW TEST:24.109 seconds]
[k8s.io] Pods
/go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should get a host IP [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run default 
  should create an rc or deployment from an image  [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  8 16:34:57.189: INFO: >>> kubeConfig: /tmp/kubeconfig-235977939
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Kubectl run default
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1210
[It] should create an rc or deployment from an image  [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Nov  8 16:34:57.226: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-235977939 run e2e-test-nginx-deployment --image=docker.io/library/nginx:1.14-alpine --namespace=e2e-tests-kubectl-5995z'
Nov  8 16:34:57.291: INFO: stderr: "kubectl run --generator=deployment/apps.v1beta1 is DEPRECATED and will be removed in a future version. Use kubectl create instead.\n"
Nov  8 16:34:57.291: INFO: stdout: "deployment.apps/e2e-test-nginx-deployment created\n"
STEP: verifying the pod controlled by e2e-test-nginx-deployment gets created
[AfterEach] [k8s.io] Kubectl run default
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1216
Nov  8 16:34:59.297: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-235977939 delete deployment e2e-test-nginx-deployment --namespace=e2e-tests-kubectl-5995z'
Nov  8 16:34:59.364: INFO: stderr: ""
Nov  8 16:34:59.364: INFO: stdout: "deployment.extensions \"e2e-test-nginx-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  8 16:34:59.364: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-5995z" for this suite.
Nov  8 16:35:05.373: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  8 16:35:05.422: INFO: namespace: e2e-tests-kubectl-5995z, resource: bindings, ignored listing per whitelist
Nov  8 16:35:05.425: INFO: namespace e2e-tests-kubectl-5995z deletion completed in 6.058160372s

• [SLOW TEST:8.237 seconds]
[sig-cli] Kubectl client
/go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run default
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create an rc or deployment from an image  [Conformance]
    /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-api-machinery] Downward API 
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Downward API
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  8 16:35:05.425: INFO: >>> kubeConfig: /tmp/kubeconfig-235977939
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Nov  8 16:35:05.463: INFO: Waiting up to 5m0s for pod "downward-api-3f6ccfae-e374-11e8-b0fd-0e97e856486a" in namespace "e2e-tests-downward-api-m7f5r" to be "success or failure"
Nov  8 16:35:05.465: INFO: Pod "downward-api-3f6ccfae-e374-11e8-b0fd-0e97e856486a": Phase="Pending", Reason="", readiness=false. Elapsed: 1.905011ms
Nov  8 16:35:07.467: INFO: Pod "downward-api-3f6ccfae-e374-11e8-b0fd-0e97e856486a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.003965952s
STEP: Saw pod success
Nov  8 16:35:07.467: INFO: Pod "downward-api-3f6ccfae-e374-11e8-b0fd-0e97e856486a" satisfied condition "success or failure"
Nov  8 16:35:07.468: INFO: Trying to get logs from node ip-10-0-100-224.ec2.internal pod downward-api-3f6ccfae-e374-11e8-b0fd-0e97e856486a container dapi-container: <nil>
STEP: delete the pod
Nov  8 16:35:07.478: INFO: Waiting for pod downward-api-3f6ccfae-e374-11e8-b0fd-0e97e856486a to disappear
Nov  8 16:35:07.479: INFO: Pod downward-api-3f6ccfae-e374-11e8-b0fd-0e97e856486a no longer exists
[AfterEach] [sig-api-machinery] Downward API
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  8 16:35:07.479: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-m7f5r" for this suite.
Nov  8 16:35:13.487: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  8 16:35:13.495: INFO: namespace: e2e-tests-downward-api-m7f5r, resource: bindings, ignored listing per whitelist
Nov  8 16:35:13.541: INFO: namespace e2e-tests-downward-api-m7f5r deletion completed in 6.059260839s

• [SLOW TEST:8.115 seconds]
[sig-api-machinery] Downward API
/go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-network] Services 
  should serve a basic endpoint from pods  [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Services
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  8 16:35:13.541: INFO: >>> kubeConfig: /tmp/kubeconfig-235977939
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:83
[It] should serve a basic endpoint from pods  [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating service endpoint-test2 in namespace e2e-tests-services-rpjtn
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-rpjtn to expose endpoints map[]
Nov  8 16:35:13.596: INFO: Get endpoints failed (1.974989ms elapsed, ignoring for 5s): endpoints "endpoint-test2" not found
Nov  8 16:35:14.598: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-rpjtn exposes endpoints map[] (1.004147889s elapsed)
STEP: Creating pod pod1 in namespace e2e-tests-services-rpjtn
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-rpjtn to expose endpoints map[pod1:[80]]
Nov  8 16:35:16.618: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-rpjtn exposes endpoints map[pod1:[80]] (2.015921351s elapsed)
STEP: Creating pod pod2 in namespace e2e-tests-services-rpjtn
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-rpjtn to expose endpoints map[pod1:[80] pod2:[80]]
Nov  8 16:35:19.639: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-rpjtn exposes endpoints map[pod1:[80] pod2:[80]] (3.018187937s elapsed)
STEP: Deleting pod pod1 in namespace e2e-tests-services-rpjtn
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-rpjtn to expose endpoints map[pod2:[80]]
Nov  8 16:35:20.647: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-rpjtn exposes endpoints map[pod2:[80]] (1.005968208s elapsed)
STEP: Deleting pod pod2 in namespace e2e-tests-services-rpjtn
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-rpjtn to expose endpoints map[]
Nov  8 16:35:21.655: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-rpjtn exposes endpoints map[] (1.005248899s elapsed)
[AfterEach] [sig-network] Services
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  8 16:35:21.664: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-services-rpjtn" for this suite.
Nov  8 16:35:27.673: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  8 16:35:27.691: INFO: namespace: e2e-tests-services-rpjtn, resource: bindings, ignored listing per whitelist
Nov  8 16:35:27.727: INFO: namespace e2e-tests-services-rpjtn deletion completed in 6.060012774s
[AfterEach] [sig-network] Services
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:88

• [SLOW TEST:14.186 seconds]
[sig-network] Services
/go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should serve a basic endpoint from pods  [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run rc 
  should create an rc from an image  [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  8 16:35:27.727: INFO: >>> kubeConfig: /tmp/kubeconfig-235977939
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Kubectl run rc
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1246
[It] should create an rc from an image  [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Nov  8 16:35:27.765: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-235977939 run e2e-test-nginx-rc --image=docker.io/library/nginx:1.14-alpine --generator=run/v1 --namespace=e2e-tests-kubectl-z228z'
Nov  8 16:35:27.832: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl create instead.\n"
Nov  8 16:35:27.832: INFO: stdout: "replicationcontroller/e2e-test-nginx-rc created\n"
STEP: verifying the rc e2e-test-nginx-rc was created
STEP: verifying the pod controlled by rc e2e-test-nginx-rc was created
STEP: confirm that you can get logs from an rc
Nov  8 16:35:27.836: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [e2e-test-nginx-rc-cf452]
Nov  8 16:35:27.836: INFO: Waiting up to 5m0s for pod "e2e-test-nginx-rc-cf452" in namespace "e2e-tests-kubectl-z228z" to be "running and ready"
Nov  8 16:35:27.840: INFO: Pod "e2e-test-nginx-rc-cf452": Phase="Pending", Reason="", readiness=false. Elapsed: 3.301547ms
Nov  8 16:35:29.842: INFO: Pod "e2e-test-nginx-rc-cf452": Phase="Running", Reason="", readiness=true. Elapsed: 2.005360014s
Nov  8 16:35:29.842: INFO: Pod "e2e-test-nginx-rc-cf452" satisfied condition "running and ready"
Nov  8 16:35:29.842: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [e2e-test-nginx-rc-cf452]
Nov  8 16:35:29.842: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-235977939 logs rc/e2e-test-nginx-rc --namespace=e2e-tests-kubectl-z228z'
Nov  8 16:35:29.917: INFO: stderr: ""
Nov  8 16:35:29.917: INFO: stdout: ""
[AfterEach] [k8s.io] Kubectl run rc
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1251
Nov  8 16:35:29.917: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-235977939 delete rc e2e-test-nginx-rc --namespace=e2e-tests-kubectl-z228z'
Nov  8 16:35:29.980: INFO: stderr: ""
Nov  8 16:35:29.981: INFO: stdout: "replicationcontroller \"e2e-test-nginx-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  8 16:35:29.981: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-z228z" for this suite.
Nov  8 16:35:35.989: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  8 16:35:36.020: INFO: namespace: e2e-tests-kubectl-z228z, resource: bindings, ignored listing per whitelist
Nov  8 16:35:36.042: INFO: namespace e2e-tests-kubectl-z228z deletion completed in 6.059362109s

• [SLOW TEST:8.315 seconds]
[sig-cli] Kubectl client
/go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run rc
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create an rc from an image  [Conformance]
    /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  8 16:35:36.042: INFO: >>> kubeConfig: /tmp/kubeconfig-235977939
STEP: Building a namespace api object, basename namespaces
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all services are removed when a namespace is deleted [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a test namespace
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a service in the namespace
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Verifying there is no service in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  8 16:35:42.118: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-namespaces-ggm8p" for this suite.
Nov  8 16:35:48.125: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  8 16:35:48.174: INFO: namespace: e2e-tests-namespaces-ggm8p, resource: bindings, ignored listing per whitelist
Nov  8 16:35:48.178: INFO: namespace e2e-tests-namespaces-ggm8p deletion completed in 6.058366104s
STEP: Destroying namespace "e2e-tests-nsdeletetest-khmpk" for this suite.
Nov  8 16:35:48.180: INFO: Namespace e2e-tests-nsdeletetest-khmpk was already deleted
STEP: Destroying namespace "e2e-tests-nsdeletetest-8s7dl" for this suite.
Nov  8 16:35:54.185: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  8 16:35:54.212: INFO: namespace: e2e-tests-nsdeletetest-8s7dl, resource: bindings, ignored listing per whitelist
Nov  8 16:35:54.237: INFO: namespace e2e-tests-nsdeletetest-8s7dl deletion completed in 6.056870882s

• [SLOW TEST:18.194 seconds]
[sig-api-machinery] Namespaces [Serial]
/go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  8 16:35:54.237: INFO: >>> kubeConfig: /tmp/kubeconfig-235977939
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-5c857d35-e374-11e8-b0fd-0e97e856486a
STEP: Creating a pod to test consume secrets
Nov  8 16:35:54.280: INFO: Waiting up to 5m0s for pod "pod-secrets-5c85b9b8-e374-11e8-b0fd-0e97e856486a" in namespace "e2e-tests-secrets-cm226" to be "success or failure"
Nov  8 16:35:54.282: INFO: Pod "pod-secrets-5c85b9b8-e374-11e8-b0fd-0e97e856486a": Phase="Pending", Reason="", readiness=false. Elapsed: 1.404812ms
Nov  8 16:35:56.284: INFO: Pod "pod-secrets-5c85b9b8-e374-11e8-b0fd-0e97e856486a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.003460102s
STEP: Saw pod success
Nov  8 16:35:56.284: INFO: Pod "pod-secrets-5c85b9b8-e374-11e8-b0fd-0e97e856486a" satisfied condition "success or failure"
Nov  8 16:35:56.285: INFO: Trying to get logs from node ip-10-0-100-224.ec2.internal pod pod-secrets-5c85b9b8-e374-11e8-b0fd-0e97e856486a container secret-volume-test: <nil>
STEP: delete the pod
Nov  8 16:35:56.298: INFO: Waiting for pod pod-secrets-5c85b9b8-e374-11e8-b0fd-0e97e856486a to disappear
Nov  8 16:35:56.299: INFO: Pod pod-secrets-5c85b9b8-e374-11e8-b0fd-0e97e856486a no longer exists
[AfterEach] [sig-storage] Secrets
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  8 16:35:56.299: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-cm226" for this suite.
Nov  8 16:36:02.306: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  8 16:36:02.329: INFO: namespace: e2e-tests-secrets-cm226, resource: bindings, ignored listing per whitelist
Nov  8 16:36:02.363: INFO: namespace e2e-tests-secrets-cm226 deletion completed in 6.061970966s

• [SLOW TEST:8.126 seconds]
[sig-storage] Secrets
/go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform canary updates and phased rolling updates of template modifications [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  8 16:36:02.363: INFO: >>> kubeConfig: /tmp/kubeconfig-235977939
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-rgm4f
[It] should perform canary updates and phased rolling updates of template modifications [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a new StaefulSet
Nov  8 16:36:02.405: INFO: Found 0 stateful pods, waiting for 3
Nov  8 16:36:12.410: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Nov  8 16:36:12.410: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Nov  8 16:36:12.410: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Updating stateful set template: update image from docker.io/library/nginx:1.14-alpine to docker.io/library/nginx:1.15-alpine
Nov  8 16:36:12.430: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Not applying an update when the partition is greater than the number of replicas
STEP: Performing a canary update
Nov  8 16:36:22.451: INFO: Updating stateful set ss2
Nov  8 16:36:22.454: INFO: Waiting for Pod e2e-tests-statefulset-rgm4f/ss2-2 to have revision ss2-c79899b9 update revision ss2-787997d666
STEP: Restoring Pods to the correct revision when they are deleted
Nov  8 16:36:32.478: INFO: Found 2 stateful pods, waiting for 3
Nov  8 16:36:42.480: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Nov  8 16:36:42.480: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Nov  8 16:36:42.480: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Performing a phased rolling update
Nov  8 16:36:42.497: INFO: Updating stateful set ss2
Nov  8 16:36:42.500: INFO: Waiting for Pod e2e-tests-statefulset-rgm4f/ss2-1 to have revision ss2-c79899b9 update revision ss2-787997d666
Nov  8 16:36:52.517: INFO: Updating stateful set ss2
Nov  8 16:36:52.521: INFO: Waiting for StatefulSet e2e-tests-statefulset-rgm4f/ss2 to complete update
Nov  8 16:36:52.521: INFO: Waiting for Pod e2e-tests-statefulset-rgm4f/ss2-0 to have revision ss2-c79899b9 update revision ss2-787997d666
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Nov  8 16:37:02.525: INFO: Deleting all statefulset in ns e2e-tests-statefulset-rgm4f
Nov  8 16:37:02.526: INFO: Scaling statefulset ss2 to 0
Nov  8 16:37:12.533: INFO: Waiting for statefulset status.replicas updated to 0
Nov  8 16:37:12.535: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  8 16:37:12.541: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-rgm4f" for this suite.
Nov  8 16:37:18.550: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  8 16:37:18.564: INFO: namespace: e2e-tests-statefulset-rgm4f, resource: bindings, ignored listing per whitelist
Nov  8 16:37:18.604: INFO: namespace e2e-tests-statefulset-rgm4f deletion completed in 6.060068982s

• [SLOW TEST:76.241 seconds]
[sig-apps] StatefulSet
/go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should perform canary updates and phased rolling updates of template modifications [Conformance]
    /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] ConfigMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  8 16:37:18.604: INFO: >>> kubeConfig: /tmp/kubeconfig-235977939
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name cm-test-opt-del-8ecef6e8-e374-11e8-b0fd-0e97e856486a
STEP: Creating configMap with name cm-test-opt-upd-8ecef786-e374-11e8-b0fd-0e97e856486a
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-8ecef6e8-e374-11e8-b0fd-0e97e856486a
STEP: Updating configmap cm-test-opt-upd-8ecef786-e374-11e8-b0fd-0e97e856486a
STEP: Creating configMap with name cm-test-opt-create-8ecef7a0-e374-11e8-b0fd-0e97e856486a
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  8 16:37:24.697: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-nzdrr" for this suite.
Nov  8 16:37:46.704: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  8 16:37:46.709: INFO: namespace: e2e-tests-configmap-nzdrr, resource: bindings, ignored listing per whitelist
Nov  8 16:37:46.758: INFO: namespace e2e-tests-configmap-nzdrr deletion completed in 22.059470456s

• [SLOW TEST:28.154 seconds]
[sig-storage] ConfigMap
/go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,default) [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  8 16:37:46.758: INFO: >>> kubeConfig: /tmp/kubeconfig-235977939
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,default) [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0666 on node default medium
Nov  8 16:37:46.799: INFO: Waiting up to 5m0s for pod "pod-9f96ca1e-e374-11e8-b0fd-0e97e856486a" in namespace "e2e-tests-emptydir-xfs7w" to be "success or failure"
Nov  8 16:37:46.801: INFO: Pod "pod-9f96ca1e-e374-11e8-b0fd-0e97e856486a": Phase="Pending", Reason="", readiness=false. Elapsed: 1.531016ms
Nov  8 16:37:48.803: INFO: Pod "pod-9f96ca1e-e374-11e8-b0fd-0e97e856486a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.003619645s
STEP: Saw pod success
Nov  8 16:37:48.803: INFO: Pod "pod-9f96ca1e-e374-11e8-b0fd-0e97e856486a" satisfied condition "success or failure"
Nov  8 16:37:48.805: INFO: Trying to get logs from node ip-10-0-100-224.ec2.internal pod pod-9f96ca1e-e374-11e8-b0fd-0e97e856486a container test-container: <nil>
STEP: delete the pod
Nov  8 16:37:48.814: INFO: Waiting for pod pod-9f96ca1e-e374-11e8-b0fd-0e97e856486a to disappear
Nov  8 16:37:48.815: INFO: Pod pod-9f96ca1e-e374-11e8-b0fd-0e97e856486a no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  8 16:37:48.815: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-xfs7w" for this suite.
Nov  8 16:37:54.824: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  8 16:37:54.851: INFO: namespace: e2e-tests-emptydir-xfs7w, resource: bindings, ignored listing per whitelist
Nov  8 16:37:54.878: INFO: namespace e2e-tests-emptydir-xfs7w deletion completed in 6.060625027s

• [SLOW TEST:8.119 seconds]
[sig-storage] EmptyDir volumes
/go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0666,default) [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts 
  should allow opting out of API token automount  [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-auth] ServiceAccounts
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  8 16:37:54.878: INFO: >>> kubeConfig: /tmp/kubeconfig-235977939
STEP: Building a namespace api object, basename svcaccounts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow opting out of API token automount  [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: getting the auto-created API token
Nov  8 16:37:55.424: INFO: created pod pod-service-account-defaultsa
Nov  8 16:37:55.424: INFO: pod pod-service-account-defaultsa service account token volume mount: true
Nov  8 16:37:55.426: INFO: created pod pod-service-account-mountsa
Nov  8 16:37:55.426: INFO: pod pod-service-account-mountsa service account token volume mount: true
Nov  8 16:37:55.431: INFO: created pod pod-service-account-nomountsa
Nov  8 16:37:55.431: INFO: pod pod-service-account-nomountsa service account token volume mount: false
Nov  8 16:37:55.436: INFO: created pod pod-service-account-defaultsa-mountspec
Nov  8 16:37:55.436: INFO: pod pod-service-account-defaultsa-mountspec service account token volume mount: true
Nov  8 16:37:55.440: INFO: created pod pod-service-account-mountsa-mountspec
Nov  8 16:37:55.440: INFO: pod pod-service-account-mountsa-mountspec service account token volume mount: true
Nov  8 16:37:55.442: INFO: created pod pod-service-account-nomountsa-mountspec
Nov  8 16:37:55.442: INFO: pod pod-service-account-nomountsa-mountspec service account token volume mount: true
Nov  8 16:37:55.445: INFO: created pod pod-service-account-defaultsa-nomountspec
Nov  8 16:37:55.445: INFO: pod pod-service-account-defaultsa-nomountspec service account token volume mount: false
Nov  8 16:37:55.451: INFO: created pod pod-service-account-mountsa-nomountspec
Nov  8 16:37:55.451: INFO: pod pod-service-account-mountsa-nomountspec service account token volume mount: false
Nov  8 16:37:55.455: INFO: created pod pod-service-account-nomountsa-nomountspec
Nov  8 16:37:55.455: INFO: pod pod-service-account-nomountsa-nomountspec service account token volume mount: false
[AfterEach] [sig-auth] ServiceAccounts
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  8 16:37:55.455: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-svcaccounts-w7gfp" for this suite.
Nov  8 16:38:01.466: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  8 16:38:01.472: INFO: namespace: e2e-tests-svcaccounts-w7gfp, resource: bindings, ignored listing per whitelist
Nov  8 16:38:01.519: INFO: namespace e2e-tests-svcaccounts-w7gfp deletion completed in 6.062597924s

• [SLOW TEST:6.641 seconds]
[sig-auth] ServiceAccounts
/go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:22
  should allow opting out of API token automount  [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should do a rolling update of a replication controller  [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  8 16:38:01.520: INFO: >>> kubeConfig: /tmp/kubeconfig-235977939
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Update Demo
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:293
[It] should do a rolling update of a replication controller  [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the initial replication controller
Nov  8 16:38:01.559: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-235977939 create -f - --namespace=e2e-tests-kubectl-9sx8j'
Nov  8 16:38:01.700: INFO: stderr: ""
Nov  8 16:38:01.700: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Nov  8 16:38:01.700: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-235977939 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-9sx8j'
Nov  8 16:38:01.772: INFO: stderr: ""
Nov  8 16:38:01.772: INFO: stdout: "update-demo-nautilus-82dxl update-demo-nautilus-c7pnl "
Nov  8 16:38:01.772: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-235977939 get pods update-demo-nautilus-82dxl -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-9sx8j'
Nov  8 16:38:01.832: INFO: stderr: ""
Nov  8 16:38:01.832: INFO: stdout: ""
Nov  8 16:38:01.832: INFO: update-demo-nautilus-82dxl is created but not running
Nov  8 16:38:06.833: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-235977939 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-9sx8j'
Nov  8 16:38:06.894: INFO: stderr: ""
Nov  8 16:38:06.894: INFO: stdout: "update-demo-nautilus-82dxl update-demo-nautilus-c7pnl "
Nov  8 16:38:06.894: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-235977939 get pods update-demo-nautilus-82dxl -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-9sx8j'
Nov  8 16:38:06.954: INFO: stderr: ""
Nov  8 16:38:06.954: INFO: stdout: "true"
Nov  8 16:38:06.954: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-235977939 get pods update-demo-nautilus-82dxl -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-9sx8j'
Nov  8 16:38:07.015: INFO: stderr: ""
Nov  8 16:38:07.015: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Nov  8 16:38:07.015: INFO: validating pod update-demo-nautilus-82dxl
Nov  8 16:38:07.017: INFO: got data: {
  "image": "nautilus.jpg"
}

Nov  8 16:38:07.017: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Nov  8 16:38:07.017: INFO: update-demo-nautilus-82dxl is verified up and running
Nov  8 16:38:07.017: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-235977939 get pods update-demo-nautilus-c7pnl -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-9sx8j'
Nov  8 16:38:07.084: INFO: stderr: ""
Nov  8 16:38:07.084: INFO: stdout: "true"
Nov  8 16:38:07.084: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-235977939 get pods update-demo-nautilus-c7pnl -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-9sx8j'
Nov  8 16:38:07.143: INFO: stderr: ""
Nov  8 16:38:07.143: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Nov  8 16:38:07.143: INFO: validating pod update-demo-nautilus-c7pnl
Nov  8 16:38:07.146: INFO: got data: {
  "image": "nautilus.jpg"
}

Nov  8 16:38:07.146: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Nov  8 16:38:07.146: INFO: update-demo-nautilus-c7pnl is verified up and running
STEP: rolling-update to new replication controller
Nov  8 16:38:07.147: INFO: scanned /root for discovery docs: <nil>
Nov  8 16:38:07.147: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-235977939 rolling-update update-demo-nautilus --update-period=1s -f - --namespace=e2e-tests-kubectl-9sx8j'
Nov  8 16:38:29.372: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Nov  8 16:38:29.372: INFO: stdout: "Created update-demo-kitten\nScaling up update-demo-kitten from 0 to 2, scaling down update-demo-nautilus from 2 to 0 (keep 2 pods available, don't exceed 3 pods)\nScaling update-demo-kitten up to 1\nScaling update-demo-nautilus down to 1\nScaling update-demo-kitten up to 2\nScaling update-demo-nautilus down to 0\nUpdate succeeded. Deleting old controller: update-demo-nautilus\nRenaming update-demo-kitten to update-demo-nautilus\nreplicationcontroller/update-demo-nautilus rolling updated\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Nov  8 16:38:29.372: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-235977939 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-9sx8j'
Nov  8 16:38:29.436: INFO: stderr: ""
Nov  8 16:38:29.436: INFO: stdout: "update-demo-kitten-9897d update-demo-kitten-dln56 "
Nov  8 16:38:29.436: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-235977939 get pods update-demo-kitten-9897d -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-9sx8j'
Nov  8 16:38:29.495: INFO: stderr: ""
Nov  8 16:38:29.495: INFO: stdout: "true"
Nov  8 16:38:29.495: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-235977939 get pods update-demo-kitten-9897d -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-9sx8j'
Nov  8 16:38:29.555: INFO: stderr: ""
Nov  8 16:38:29.555: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
Nov  8 16:38:29.555: INFO: validating pod update-demo-kitten-9897d
Nov  8 16:38:29.558: INFO: got data: {
  "image": "kitten.jpg"
}

Nov  8 16:38:29.558: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Nov  8 16:38:29.558: INFO: update-demo-kitten-9897d is verified up and running
Nov  8 16:38:29.558: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-235977939 get pods update-demo-kitten-dln56 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-9sx8j'
Nov  8 16:38:29.618: INFO: stderr: ""
Nov  8 16:38:29.618: INFO: stdout: "true"
Nov  8 16:38:29.618: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-235977939 get pods update-demo-kitten-dln56 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-9sx8j'
Nov  8 16:38:29.678: INFO: stderr: ""
Nov  8 16:38:29.678: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
Nov  8 16:38:29.678: INFO: validating pod update-demo-kitten-dln56
Nov  8 16:38:29.680: INFO: got data: {
  "image": "kitten.jpg"
}

Nov  8 16:38:29.680: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Nov  8 16:38:29.680: INFO: update-demo-kitten-dln56 is verified up and running
[AfterEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  8 16:38:29.680: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-9sx8j" for this suite.
Nov  8 16:38:51.688: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  8 16:38:51.723: INFO: namespace: e2e-tests-kubectl-9sx8j, resource: bindings, ignored listing per whitelist
Nov  8 16:38:51.744: INFO: namespace e2e-tests-kubectl-9sx8j deletion completed in 22.061727246s

• [SLOW TEST:50.225 seconds]
[sig-cli] Kubectl client
/go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Update Demo
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should do a rolling update of a replication controller  [Conformance]
    /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  8 16:38:51.745: INFO: >>> kubeConfig: /tmp/kubeconfig-235977939
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-c652ce3f-e374-11e8-b0fd-0e97e856486a
STEP: Creating a pod to test consume configMaps
Nov  8 16:38:51.786: INFO: Waiting up to 5m0s for pod "pod-configmaps-c65308fd-e374-11e8-b0fd-0e97e856486a" in namespace "e2e-tests-configmap-jb2gx" to be "success or failure"
Nov  8 16:38:51.789: INFO: Pod "pod-configmaps-c65308fd-e374-11e8-b0fd-0e97e856486a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.250834ms
Nov  8 16:38:53.791: INFO: Pod "pod-configmaps-c65308fd-e374-11e8-b0fd-0e97e856486a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004374887s
STEP: Saw pod success
Nov  8 16:38:53.791: INFO: Pod "pod-configmaps-c65308fd-e374-11e8-b0fd-0e97e856486a" satisfied condition "success or failure"
Nov  8 16:38:53.792: INFO: Trying to get logs from node ip-10-0-100-224.ec2.internal pod pod-configmaps-c65308fd-e374-11e8-b0fd-0e97e856486a container configmap-volume-test: <nil>
STEP: delete the pod
Nov  8 16:38:53.802: INFO: Waiting for pod pod-configmaps-c65308fd-e374-11e8-b0fd-0e97e856486a to disappear
Nov  8 16:38:53.809: INFO: Pod pod-configmaps-c65308fd-e374-11e8-b0fd-0e97e856486a no longer exists
[AfterEach] [sig-storage] ConfigMap
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  8 16:38:53.809: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-jb2gx" for this suite.
Nov  8 16:38:59.817: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  8 16:38:59.861: INFO: namespace: e2e-tests-configmap-jb2gx, resource: bindings, ignored listing per whitelist
Nov  8 16:38:59.872: INFO: namespace e2e-tests-configmap-jb2gx deletion completed in 6.060867483s

• [SLOW TEST:8.128 seconds]
[sig-storage] ConfigMap
/go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Projected 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  8 16:38:59.872: INFO: >>> kubeConfig: /tmp/kubeconfig-235977939
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Nov  8 16:38:59.913: INFO: Waiting up to 5m0s for pod "downwardapi-volume-cb2aeb2f-e374-11e8-b0fd-0e97e856486a" in namespace "e2e-tests-projected-pb7bl" to be "success or failure"
Nov  8 16:38:59.915: INFO: Pod "downwardapi-volume-cb2aeb2f-e374-11e8-b0fd-0e97e856486a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.282141ms
Nov  8 16:39:01.917: INFO: Pod "downwardapi-volume-cb2aeb2f-e374-11e8-b0fd-0e97e856486a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004300092s
STEP: Saw pod success
Nov  8 16:39:01.917: INFO: Pod "downwardapi-volume-cb2aeb2f-e374-11e8-b0fd-0e97e856486a" satisfied condition "success or failure"
Nov  8 16:39:01.919: INFO: Trying to get logs from node ip-10-0-100-224.ec2.internal pod downwardapi-volume-cb2aeb2f-e374-11e8-b0fd-0e97e856486a container client-container: <nil>
STEP: delete the pod
Nov  8 16:39:01.928: INFO: Waiting for pod downwardapi-volume-cb2aeb2f-e374-11e8-b0fd-0e97e856486a to disappear
Nov  8 16:39:01.929: INFO: Pod downwardapi-volume-cb2aeb2f-e374-11e8-b0fd-0e97e856486a no longer exists
[AfterEach] [sig-storage] Projected
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  8 16:39:01.929: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-pb7bl" for this suite.
Nov  8 16:39:07.937: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  8 16:39:07.945: INFO: namespace: e2e-tests-projected-pb7bl, resource: bindings, ignored listing per whitelist
Nov  8 16:39:07.991: INFO: namespace e2e-tests-projected-pb7bl deletion completed in 6.059647562s

• [SLOW TEST:8.119 seconds]
[sig-storage] Projected
/go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] version v1
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  8 16:39:07.991: INFO: >>> kubeConfig: /tmp/kubeconfig-235977939
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Nov  8 16:39:08.033: INFO: (0) /api/v1/nodes/ip-10-0-100-224.ec2.internal:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 2.960053ms)
Nov  8 16:39:08.035: INFO: (1) /api/v1/nodes/ip-10-0-100-224.ec2.internal:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 2.078571ms)
Nov  8 16:39:08.037: INFO: (2) /api/v1/nodes/ip-10-0-100-224.ec2.internal:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 1.945208ms)
Nov  8 16:39:08.039: INFO: (3) /api/v1/nodes/ip-10-0-100-224.ec2.internal:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 1.916121ms)
Nov  8 16:39:08.041: INFO: (4) /api/v1/nodes/ip-10-0-100-224.ec2.internal:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 1.919565ms)
Nov  8 16:39:08.043: INFO: (5) /api/v1/nodes/ip-10-0-100-224.ec2.internal:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 1.899188ms)
Nov  8 16:39:08.045: INFO: (6) /api/v1/nodes/ip-10-0-100-224.ec2.internal:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 1.842422ms)
Nov  8 16:39:08.047: INFO: (7) /api/v1/nodes/ip-10-0-100-224.ec2.internal:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 1.857721ms)
Nov  8 16:39:08.049: INFO: (8) /api/v1/nodes/ip-10-0-100-224.ec2.internal:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 1.885001ms)
Nov  8 16:39:08.051: INFO: (9) /api/v1/nodes/ip-10-0-100-224.ec2.internal:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 1.804517ms)
Nov  8 16:39:08.052: INFO: (10) /api/v1/nodes/ip-10-0-100-224.ec2.internal:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 1.839232ms)
Nov  8 16:39:08.054: INFO: (11) /api/v1/nodes/ip-10-0-100-224.ec2.internal:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 1.871491ms)
Nov  8 16:39:08.056: INFO: (12) /api/v1/nodes/ip-10-0-100-224.ec2.internal:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 1.871886ms)
Nov  8 16:39:08.058: INFO: (13) /api/v1/nodes/ip-10-0-100-224.ec2.internal:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 1.824154ms)
Nov  8 16:39:08.060: INFO: (14) /api/v1/nodes/ip-10-0-100-224.ec2.internal:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 1.962182ms)
Nov  8 16:39:08.062: INFO: (15) /api/v1/nodes/ip-10-0-100-224.ec2.internal:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 1.888766ms)
Nov  8 16:39:08.064: INFO: (16) /api/v1/nodes/ip-10-0-100-224.ec2.internal:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 1.944991ms)
Nov  8 16:39:08.066: INFO: (17) /api/v1/nodes/ip-10-0-100-224.ec2.internal:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 1.91068ms)
Nov  8 16:39:08.068: INFO: (18) /api/v1/nodes/ip-10-0-100-224.ec2.internal:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 1.847894ms)
Nov  8 16:39:08.070: INFO: (19) /api/v1/nodes/ip-10-0-100-224.ec2.internal:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 1.908731ms)
[AfterEach] version v1
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  8 16:39:08.070: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-proxy-lwb7f" for this suite.
Nov  8 16:39:14.077: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  8 16:39:14.108: INFO: namespace: e2e-tests-proxy-lwb7f, resource: bindings, ignored listing per whitelist
Nov  8 16:39:14.132: INFO: namespace e2e-tests-proxy-lwb7f deletion completed in 6.060735479s

• [SLOW TEST:6.141 seconds]
[sig-network] Proxy
/go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
    /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,default) [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  8 16:39:14.132: INFO: >>> kubeConfig: /tmp/kubeconfig-235977939
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,default) [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0644 on node default medium
Nov  8 16:39:14.172: INFO: Waiting up to 5m0s for pod "pod-d3aad9df-e374-11e8-b0fd-0e97e856486a" in namespace "e2e-tests-emptydir-tjkbk" to be "success or failure"
Nov  8 16:39:14.174: INFO: Pod "pod-d3aad9df-e374-11e8-b0fd-0e97e856486a": Phase="Pending", Reason="", readiness=false. Elapsed: 1.854644ms
Nov  8 16:39:16.176: INFO: Pod "pod-d3aad9df-e374-11e8-b0fd-0e97e856486a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.003984868s
STEP: Saw pod success
Nov  8 16:39:16.176: INFO: Pod "pod-d3aad9df-e374-11e8-b0fd-0e97e856486a" satisfied condition "success or failure"
Nov  8 16:39:16.178: INFO: Trying to get logs from node ip-10-0-100-224.ec2.internal pod pod-d3aad9df-e374-11e8-b0fd-0e97e856486a container test-container: <nil>
STEP: delete the pod
Nov  8 16:39:16.187: INFO: Waiting for pod pod-d3aad9df-e374-11e8-b0fd-0e97e856486a to disappear
Nov  8 16:39:16.188: INFO: Pod pod-d3aad9df-e374-11e8-b0fd-0e97e856486a no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  8 16:39:16.188: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-tjkbk" for this suite.
Nov  8 16:39:22.196: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  8 16:39:22.221: INFO: namespace: e2e-tests-emptydir-tjkbk, resource: bindings, ignored listing per whitelist
Nov  8 16:39:22.249: INFO: namespace e2e-tests-emptydir-tjkbk deletion completed in 6.058580555s

• [SLOW TEST:8.116 seconds]
[sig-storage] EmptyDir volumes
/go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0644,default) [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop complex daemon [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  8 16:39:22.249: INFO: >>> kubeConfig: /tmp/kubeconfig-235977939
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should run and stop complex daemon [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Nov  8 16:39:22.294: INFO: Creating daemon "daemon-set" with a node selector
STEP: Initially, daemon pods should not be running on any nodes.
Nov  8 16:39:22.298: INFO: Number of nodes with available pods: 0
Nov  8 16:39:22.298: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Change node label to blue, check that daemon pod is launched.
Nov  8 16:39:22.309: INFO: Number of nodes with available pods: 0
Nov  8 16:39:22.309: INFO: Node ip-10-0-100-224.ec2.internal is running more than one daemon pod
Nov  8 16:39:23.311: INFO: Number of nodes with available pods: 1
Nov  8 16:39:23.311: INFO: Number of running nodes: 1, number of available pods: 1
STEP: Update the node label to green, and wait for daemons to be unscheduled
Nov  8 16:39:23.320: INFO: Number of nodes with available pods: 1
Nov  8 16:39:23.320: INFO: Number of running nodes: 0, number of available pods: 1
Nov  8 16:39:24.321: INFO: Number of nodes with available pods: 0
Nov  8 16:39:24.321: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Update DaemonSet node selector to green, and change its update strategy to RollingUpdate
Nov  8 16:39:24.326: INFO: Number of nodes with available pods: 0
Nov  8 16:39:24.326: INFO: Node ip-10-0-100-224.ec2.internal is running more than one daemon pod
Nov  8 16:39:25.328: INFO: Number of nodes with available pods: 0
Nov  8 16:39:25.328: INFO: Node ip-10-0-100-224.ec2.internal is running more than one daemon pod
Nov  8 16:39:26.328: INFO: Number of nodes with available pods: 0
Nov  8 16:39:26.328: INFO: Node ip-10-0-100-224.ec2.internal is running more than one daemon pod
Nov  8 16:39:27.328: INFO: Number of nodes with available pods: 0
Nov  8 16:39:27.328: INFO: Node ip-10-0-100-224.ec2.internal is running more than one daemon pod
Nov  8 16:39:28.328: INFO: Number of nodes with available pods: 0
Nov  8 16:39:28.328: INFO: Node ip-10-0-100-224.ec2.internal is running more than one daemon pod
Nov  8 16:39:29.328: INFO: Number of nodes with available pods: 0
Nov  8 16:39:29.328: INFO: Node ip-10-0-100-224.ec2.internal is running more than one daemon pod
Nov  8 16:39:30.328: INFO: Number of nodes with available pods: 0
Nov  8 16:39:30.328: INFO: Node ip-10-0-100-224.ec2.internal is running more than one daemon pod
Nov  8 16:39:31.328: INFO: Number of nodes with available pods: 0
Nov  8 16:39:31.328: INFO: Node ip-10-0-100-224.ec2.internal is running more than one daemon pod
Nov  8 16:39:32.328: INFO: Number of nodes with available pods: 0
Nov  8 16:39:32.328: INFO: Node ip-10-0-100-224.ec2.internal is running more than one daemon pod
Nov  8 16:39:33.328: INFO: Number of nodes with available pods: 0
Nov  8 16:39:33.328: INFO: Node ip-10-0-100-224.ec2.internal is running more than one daemon pod
Nov  8 16:39:34.328: INFO: Number of nodes with available pods: 0
Nov  8 16:39:34.328: INFO: Node ip-10-0-100-224.ec2.internal is running more than one daemon pod
Nov  8 16:39:35.328: INFO: Number of nodes with available pods: 0
Nov  8 16:39:35.328: INFO: Node ip-10-0-100-224.ec2.internal is running more than one daemon pod
Nov  8 16:39:36.328: INFO: Number of nodes with available pods: 0
Nov  8 16:39:36.328: INFO: Node ip-10-0-100-224.ec2.internal is running more than one daemon pod
Nov  8 16:39:37.328: INFO: Number of nodes with available pods: 0
Nov  8 16:39:37.328: INFO: Node ip-10-0-100-224.ec2.internal is running more than one daemon pod
Nov  8 16:39:38.328: INFO: Number of nodes with available pods: 0
Nov  8 16:39:38.328: INFO: Node ip-10-0-100-224.ec2.internal is running more than one daemon pod
Nov  8 16:39:39.328: INFO: Number of nodes with available pods: 0
Nov  8 16:39:39.328: INFO: Node ip-10-0-100-224.ec2.internal is running more than one daemon pod
Nov  8 16:39:40.328: INFO: Number of nodes with available pods: 0
Nov  8 16:39:40.328: INFO: Node ip-10-0-100-224.ec2.internal is running more than one daemon pod
Nov  8 16:39:41.327: INFO: Number of nodes with available pods: 0
Nov  8 16:39:41.327: INFO: Node ip-10-0-100-224.ec2.internal is running more than one daemon pod
Nov  8 16:39:42.328: INFO: Number of nodes with available pods: 0
Nov  8 16:39:42.328: INFO: Node ip-10-0-100-224.ec2.internal is running more than one daemon pod
Nov  8 16:39:43.328: INFO: Number of nodes with available pods: 0
Nov  8 16:39:43.328: INFO: Node ip-10-0-100-224.ec2.internal is running more than one daemon pod
Nov  8 16:39:44.328: INFO: Number of nodes with available pods: 0
Nov  8 16:39:44.328: INFO: Node ip-10-0-100-224.ec2.internal is running more than one daemon pod
Nov  8 16:39:45.327: INFO: Number of nodes with available pods: 0
Nov  8 16:39:45.328: INFO: Node ip-10-0-100-224.ec2.internal is running more than one daemon pod
Nov  8 16:39:46.328: INFO: Number of nodes with available pods: 0
Nov  8 16:39:46.328: INFO: Node ip-10-0-100-224.ec2.internal is running more than one daemon pod
Nov  8 16:39:47.328: INFO: Number of nodes with available pods: 0
Nov  8 16:39:47.328: INFO: Node ip-10-0-100-224.ec2.internal is running more than one daemon pod
Nov  8 16:39:48.328: INFO: Number of nodes with available pods: 0
Nov  8 16:39:48.328: INFO: Node ip-10-0-100-224.ec2.internal is running more than one daemon pod
Nov  8 16:39:49.328: INFO: Number of nodes with available pods: 0
Nov  8 16:39:49.328: INFO: Node ip-10-0-100-224.ec2.internal is running more than one daemon pod
Nov  8 16:39:50.328: INFO: Number of nodes with available pods: 0
Nov  8 16:39:50.328: INFO: Node ip-10-0-100-224.ec2.internal is running more than one daemon pod
Nov  8 16:39:51.328: INFO: Number of nodes with available pods: 0
Nov  8 16:39:51.328: INFO: Node ip-10-0-100-224.ec2.internal is running more than one daemon pod
Nov  8 16:39:52.328: INFO: Number of nodes with available pods: 0
Nov  8 16:39:52.328: INFO: Node ip-10-0-100-224.ec2.internal is running more than one daemon pod
Nov  8 16:39:53.328: INFO: Number of nodes with available pods: 0
Nov  8 16:39:53.328: INFO: Node ip-10-0-100-224.ec2.internal is running more than one daemon pod
Nov  8 16:39:54.328: INFO: Number of nodes with available pods: 0
Nov  8 16:39:54.328: INFO: Node ip-10-0-100-224.ec2.internal is running more than one daemon pod
Nov  8 16:39:55.328: INFO: Number of nodes with available pods: 0
Nov  8 16:39:55.328: INFO: Node ip-10-0-100-224.ec2.internal is running more than one daemon pod
Nov  8 16:39:56.328: INFO: Number of nodes with available pods: 0
Nov  8 16:39:56.328: INFO: Node ip-10-0-100-224.ec2.internal is running more than one daemon pod
Nov  8 16:39:57.328: INFO: Number of nodes with available pods: 0
Nov  8 16:39:57.328: INFO: Node ip-10-0-100-224.ec2.internal is running more than one daemon pod
Nov  8 16:39:58.328: INFO: Number of nodes with available pods: 0
Nov  8 16:39:58.328: INFO: Node ip-10-0-100-224.ec2.internal is running more than one daemon pod
Nov  8 16:39:59.328: INFO: Number of nodes with available pods: 0
Nov  8 16:39:59.328: INFO: Node ip-10-0-100-224.ec2.internal is running more than one daemon pod
Nov  8 16:40:00.328: INFO: Number of nodes with available pods: 0
Nov  8 16:40:00.328: INFO: Node ip-10-0-100-224.ec2.internal is running more than one daemon pod
Nov  8 16:40:01.328: INFO: Number of nodes with available pods: 0
Nov  8 16:40:01.328: INFO: Node ip-10-0-100-224.ec2.internal is running more than one daemon pod
Nov  8 16:40:02.328: INFO: Number of nodes with available pods: 0
Nov  8 16:40:02.328: INFO: Node ip-10-0-100-224.ec2.internal is running more than one daemon pod
Nov  8 16:40:03.328: INFO: Number of nodes with available pods: 0
Nov  8 16:40:03.328: INFO: Node ip-10-0-100-224.ec2.internal is running more than one daemon pod
Nov  8 16:40:04.328: INFO: Number of nodes with available pods: 0
Nov  8 16:40:04.328: INFO: Node ip-10-0-100-224.ec2.internal is running more than one daemon pod
Nov  8 16:40:05.328: INFO: Number of nodes with available pods: 0
Nov  8 16:40:05.328: INFO: Node ip-10-0-100-224.ec2.internal is running more than one daemon pod
Nov  8 16:40:06.328: INFO: Number of nodes with available pods: 0
Nov  8 16:40:06.328: INFO: Node ip-10-0-100-224.ec2.internal is running more than one daemon pod
Nov  8 16:40:07.328: INFO: Number of nodes with available pods: 0
Nov  8 16:40:07.328: INFO: Node ip-10-0-100-224.ec2.internal is running more than one daemon pod
Nov  8 16:40:08.328: INFO: Number of nodes with available pods: 1
Nov  8 16:40:08.328: INFO: Number of running nodes: 1, number of available pods: 1
[AfterEach] [sig-apps] Daemon set [Serial]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting {extensions DaemonSet} daemon-set in namespace e2e-tests-daemonsets-nxwm5, will wait for the garbage collector to delete the pods
Nov  8 16:40:08.385: INFO: Deleting {extensions DaemonSet} daemon-set took: 2.787068ms
Nov  8 16:40:08.485: INFO: Terminating {extensions DaemonSet} daemon-set pods took: 100.137912ms
Nov  8 16:40:46.087: INFO: Number of nodes with available pods: 0
Nov  8 16:40:46.087: INFO: Number of running nodes: 0, number of available pods: 0
Nov  8 16:40:46.088: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-nxwm5/daemonsets","resourceVersion":"12657"},"items":null}

Nov  8 16:40:46.090: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-nxwm5/pods","resourceVersion":"12657"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  8 16:40:46.098: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-nxwm5" for this suite.
Nov  8 16:40:52.105: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  8 16:40:52.157: INFO: namespace: e2e-tests-daemonsets-nxwm5, resource: bindings, ignored listing per whitelist
Nov  8 16:40:52.159: INFO: namespace e2e-tests-daemonsets-nxwm5 deletion completed in 6.058929352s

• [SLOW TEST:89.910 seconds]
[sig-apps] Daemon set [Serial]
/go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should run and stop complex daemon [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: udp [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Networking
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  8 16:40:52.159: INFO: >>> kubeConfig: /tmp/kubeconfig-235977939
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: udp [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-z2ft6
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Nov  8 16:40:52.204: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Nov  8 16:41:08.236: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://192.168.1.107:8080/dial?request=hostName&protocol=udp&host=192.168.2.48&port=8081&tries=1'] Namespace:e2e-tests-pod-network-test-z2ft6 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Nov  8 16:41:08.236: INFO: >>> kubeConfig: /tmp/kubeconfig-235977939
Nov  8 16:41:08.308: INFO: Waiting for endpoints: map[]
Nov  8 16:41:08.310: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://192.168.1.107:8080/dial?request=hostName&protocol=udp&host=192.168.1.106&port=8081&tries=1'] Namespace:e2e-tests-pod-network-test-z2ft6 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Nov  8 16:41:08.310: INFO: >>> kubeConfig: /tmp/kubeconfig-235977939
Nov  8 16:41:08.366: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  8 16:41:08.366: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-z2ft6" for this suite.
Nov  8 16:41:30.374: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  8 16:41:30.402: INFO: namespace: e2e-tests-pod-network-test-z2ft6, resource: bindings, ignored listing per whitelist
Nov  8 16:41:30.427: INFO: namespace e2e-tests-pod-network-test-z2ft6 deletion completed in 22.0589913s

• [SLOW TEST:38.268 seconds]
[sig-network] Networking
/go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: udp [NodeConformance] [Conformance]
    /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete pods created by rc when not orphaning [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  8 16:41:30.427: INFO: >>> kubeConfig: /tmp/kubeconfig-235977939
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete pods created by rc when not orphaning [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the rc
STEP: delete the rc
STEP: wait for all pods to be garbage collected
STEP: Gathering metrics
Nov  8 16:41:40.479: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  8 16:41:40.479: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-jns96" for this suite.
Nov  8 16:41:46.486: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  8 16:41:46.492: INFO: namespace: e2e-tests-gc-jns96, resource: bindings, ignored listing per whitelist
Nov  8 16:41:46.542: INFO: namespace e2e-tests-gc-jns96 deletion completed in 6.061987106s

• [SLOW TEST:16.115 seconds]
[sig-api-machinery] Garbage collector
/go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should delete pods created by rc when not orphaning [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-apps] Deployment 
  deployment should delete old replica sets [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  8 16:41:46.543: INFO: >>> kubeConfig: /tmp/kubeconfig-235977939
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should delete old replica sets [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Nov  8 16:41:46.584: INFO: Pod name cleanup-pod: Found 0 pods out of 1
Nov  8 16:41:51.586: INFO: Pod name cleanup-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Nov  8 16:41:51.586: INFO: Creating deployment test-cleanup-deployment
STEP: Waiting for deployment test-cleanup-deployment history to be cleaned up
[AfterEach] [sig-apps] Deployment
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Nov  8 16:41:51.595: INFO: Deployment "test-cleanup-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-deployment,GenerateName:,Namespace:e2e-tests-deployment-dmdtw,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-dmdtw/deployments/test-cleanup-deployment,UID:317f360a-e375-11e8-a466-0a0beb0244cc,ResourceVersion:12913,Generation:1,CreationTimestamp:2018-11-08 16:41:51 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*0,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:0,Replicas:0,UpdatedReplicas:0,AvailableReplicas:0,UnavailableReplicas:0,Conditions:[],ReadyReplicas:0,CollisionCount:nil,},}

Nov  8 16:41:51.596: INFO: New ReplicaSet of Deployment "test-cleanup-deployment" is nil.
Nov  8 16:41:51.596: INFO: All old ReplicaSets of Deployment "test-cleanup-deployment":
Nov  8 16:41:51.597: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-controller,GenerateName:,Namespace:e2e-tests-deployment-dmdtw,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-dmdtw/replicasets/test-cleanup-controller,UID:2e83107d-e375-11e8-a466-0a0beb0244cc,ResourceVersion:12914,Generation:1,CreationTimestamp:2018-11-08 16:41:46 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 Deployment test-cleanup-deployment 317f360a-e375-11e8-a466-0a0beb0244cc 0xc420f62667 0xc420f62668}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Nov  8 16:41:51.599: INFO: Pod "test-cleanup-controller-d4dsq" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-controller-d4dsq,GenerateName:test-cleanup-controller-,Namespace:e2e-tests-deployment-dmdtw,SelfLink:/api/v1/namespaces/e2e-tests-deployment-dmdtw/pods/test-cleanup-controller-d4dsq,UID:2e83c7a1-e375-11e8-a466-0a0beb0244cc,ResourceVersion:12906,Generation:0,CreationTimestamp:2018-11-08 16:41:46 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod: nginx,},Annotations:map[string]string{cni.projectcalico.org/podIP: 192.168.1.109/32,},OwnerReferences:[{apps/v1 ReplicaSet test-cleanup-controller 2e83107d-e375-11e8-a466-0a0beb0244cc 0xc420f62c67 0xc420f62c68}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-t5vn4 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-t5vn4,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-t5vn4 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-100-224.ec2.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc420f62d60} {node.kubernetes.io/unreachable Exists  NoExecute 0xc420f62d80}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-11-08 16:41:46 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-11-08 16:41:47 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2018-11-08 16:41:47 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-11-08 16:41:46 +0000 UTC  }],Message:,Reason:,HostIP:10.0.100.224,PodIP:192.168.1.109,StartTime:2018-11-08 16:41:46 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2018-11-08 16:41:47 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:75cf17cdf89cbd8da65c83050ebdab1026b98cf217442d6a1f2a8892f47967d7 docker://2574e80f7167c022933aa4fb7a93fe279cec6ddf9770be4bad724e5a069d3e50}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  8 16:41:51.599: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-dmdtw" for this suite.
Nov  8 16:41:57.613: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  8 16:41:57.645: INFO: namespace: e2e-tests-deployment-dmdtw, resource: bindings, ignored listing per whitelist
Nov  8 16:41:57.666: INFO: namespace e2e-tests-deployment-dmdtw deletion completed in 6.062790103s

• [SLOW TEST:11.124 seconds]
[sig-apps] Deployment
/go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  deployment should delete old replica sets [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[k8s.io] [sig-node] Pods Extended [k8s.io] Pods Set QOS Class 
  should be submitted and removed  [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] [sig-node] Pods Extended
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  8 16:41:57.666: INFO: >>> kubeConfig: /tmp/kubeconfig-235977939
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods Set QOS Class
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pods.go:204
[It] should be submitted and removed  [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying QOS class is set on the pod
[AfterEach] [k8s.io] [sig-node] Pods Extended
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  8 16:41:57.708: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-87jmh" for this suite.
Nov  8 16:42:19.716: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  8 16:42:19.728: INFO: namespace: e2e-tests-pods-87jmh, resource: bindings, ignored listing per whitelist
Nov  8 16:42:19.768: INFO: namespace e2e-tests-pods-87jmh deletion completed in 22.057451758s

• [SLOW TEST:22.102 seconds]
[k8s.io] [sig-node] Pods Extended
/go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  [k8s.io] Pods Set QOS Class
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should be submitted and removed  [Conformance]
    /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-api-machinery] ConfigMap 
  should be consumable via environment variable [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] ConfigMap
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  8 16:42:19.769: INFO: >>> kubeConfig: /tmp/kubeconfig-235977939
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via environment variable [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap e2e-tests-configmap-vb4fn/configmap-test-4250ad38-e375-11e8-b0fd-0e97e856486a
STEP: Creating a pod to test consume configMaps
Nov  8 16:42:19.810: INFO: Waiting up to 5m0s for pod "pod-configmaps-4250f3a4-e375-11e8-b0fd-0e97e856486a" in namespace "e2e-tests-configmap-vb4fn" to be "success or failure"
Nov  8 16:42:19.811: INFO: Pod "pod-configmaps-4250f3a4-e375-11e8-b0fd-0e97e856486a": Phase="Pending", Reason="", readiness=false. Elapsed: 1.233467ms
Nov  8 16:42:21.813: INFO: Pod "pod-configmaps-4250f3a4-e375-11e8-b0fd-0e97e856486a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.003337294s
STEP: Saw pod success
Nov  8 16:42:21.813: INFO: Pod "pod-configmaps-4250f3a4-e375-11e8-b0fd-0e97e856486a" satisfied condition "success or failure"
Nov  8 16:42:21.815: INFO: Trying to get logs from node ip-10-0-100-224.ec2.internal pod pod-configmaps-4250f3a4-e375-11e8-b0fd-0e97e856486a container env-test: <nil>
STEP: delete the pod
Nov  8 16:42:21.824: INFO: Waiting for pod pod-configmaps-4250f3a4-e375-11e8-b0fd-0e97e856486a to disappear
Nov  8 16:42:21.825: INFO: Pod pod-configmaps-4250f3a4-e375-11e8-b0fd-0e97e856486a no longer exists
[AfterEach] [sig-api-machinery] ConfigMap
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  8 16:42:21.825: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-vb4fn" for this suite.
Nov  8 16:42:27.832: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  8 16:42:27.840: INFO: namespace: e2e-tests-configmap-vb4fn, resource: bindings, ignored listing per whitelist
Nov  8 16:42:27.886: INFO: namespace e2e-tests-configmap-vb4fn deletion completed in 6.059045874s

• [SLOW TEST:8.117 seconds]
[sig-api-machinery] ConfigMap
/go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:30
  should be consumable via environment variable [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Variable Expansion
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  8 16:42:27.886: INFO: >>> kubeConfig: /tmp/kubeconfig-235977939
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's args [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test substitution in container's args
Nov  8 16:42:27.925: INFO: Waiting up to 5m0s for pod "var-expansion-472737f0-e375-11e8-b0fd-0e97e856486a" in namespace "e2e-tests-var-expansion-sxd87" to be "success or failure"
Nov  8 16:42:27.927: INFO: Pod "var-expansion-472737f0-e375-11e8-b0fd-0e97e856486a": Phase="Pending", Reason="", readiness=false. Elapsed: 1.422182ms
Nov  8 16:42:29.928: INFO: Pod "var-expansion-472737f0-e375-11e8-b0fd-0e97e856486a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00332382s
STEP: Saw pod success
Nov  8 16:42:29.928: INFO: Pod "var-expansion-472737f0-e375-11e8-b0fd-0e97e856486a" satisfied condition "success or failure"
Nov  8 16:42:29.930: INFO: Trying to get logs from node ip-10-0-100-224.ec2.internal pod var-expansion-472737f0-e375-11e8-b0fd-0e97e856486a container dapi-container: <nil>
STEP: delete the pod
Nov  8 16:42:29.940: INFO: Waiting for pod var-expansion-472737f0-e375-11e8-b0fd-0e97e856486a to disappear
Nov  8 16:42:29.941: INFO: Pod var-expansion-472737f0-e375-11e8-b0fd-0e97e856486a no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  8 16:42:29.941: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-var-expansion-sxd87" for this suite.
Nov  8 16:42:35.949: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  8 16:42:35.985: INFO: namespace: e2e-tests-var-expansion-sxd87, resource: bindings, ignored listing per whitelist
Nov  8 16:42:36.005: INFO: namespace e2e-tests-var-expansion-sxd87 deletion completed in 6.061371243s

• [SLOW TEST:8.119 seconds]
[k8s.io] Variable Expansion
/go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  8 16:42:36.005: INFO: >>> kubeConfig: /tmp/kubeconfig-235977939
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-map-4bfe19b3-e375-11e8-b0fd-0e97e856486a
STEP: Creating a pod to test consume configMaps
Nov  8 16:42:36.046: INFO: Waiting up to 5m0s for pod "pod-configmaps-4bfe5a45-e375-11e8-b0fd-0e97e856486a" in namespace "e2e-tests-configmap-rnp24" to be "success or failure"
Nov  8 16:42:36.048: INFO: Pod "pod-configmaps-4bfe5a45-e375-11e8-b0fd-0e97e856486a": Phase="Pending", Reason="", readiness=false. Elapsed: 1.483785ms
Nov  8 16:42:38.050: INFO: Pod "pod-configmaps-4bfe5a45-e375-11e8-b0fd-0e97e856486a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.003567567s
STEP: Saw pod success
Nov  8 16:42:38.050: INFO: Pod "pod-configmaps-4bfe5a45-e375-11e8-b0fd-0e97e856486a" satisfied condition "success or failure"
Nov  8 16:42:38.051: INFO: Trying to get logs from node ip-10-0-100-224.ec2.internal pod pod-configmaps-4bfe5a45-e375-11e8-b0fd-0e97e856486a container configmap-volume-test: <nil>
STEP: delete the pod
Nov  8 16:42:38.062: INFO: Waiting for pod pod-configmaps-4bfe5a45-e375-11e8-b0fd-0e97e856486a to disappear
Nov  8 16:42:38.063: INFO: Pod pod-configmaps-4bfe5a45-e375-11e8-b0fd-0e97e856486a no longer exists
[AfterEach] [sig-storage] ConfigMap
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  8 16:42:38.063: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-rnp24" for this suite.
Nov  8 16:42:44.070: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  8 16:42:44.109: INFO: namespace: e2e-tests-configmap-rnp24, resource: bindings, ignored listing per whitelist
Nov  8 16:42:44.123: INFO: namespace e2e-tests-configmap-rnp24 deletion completed in 6.057786239s

• [SLOW TEST:8.118 seconds]
[sig-storage] ConfigMap
/go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  8 16:42:44.123: INFO: >>> kubeConfig: /tmp/kubeconfig-235977939
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-wrj7q
[It] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Initializing watcher for selector baz=blah,foo=bar
STEP: Creating stateful set ss in namespace e2e-tests-statefulset-wrj7q
STEP: Waiting until all stateful set ss replicas will be running in namespace e2e-tests-statefulset-wrj7q
Nov  8 16:42:44.172: INFO: Found 0 stateful pods, waiting for 1
Nov  8 16:42:54.174: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will halt with unhealthy stateful pod
Nov  8 16:42:54.176: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-235977939 exec --namespace=e2e-tests-statefulset-wrj7q ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Nov  8 16:42:54.307: INFO: stderr: ""
Nov  8 16:42:54.307: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Nov  8 16:42:54.307: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Nov  8 16:42:54.308: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Nov  8 16:43:04.311: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Nov  8 16:43:04.311: INFO: Waiting for statefulset status.replicas updated to 0
Nov  8 16:43:04.317: INFO: Verifying statefulset ss doesn't scale past 1 for another 9.999999808s
Nov  8 16:43:05.320: INFO: Verifying statefulset ss doesn't scale past 1 for another 8.998340986s
Nov  8 16:43:06.322: INFO: Verifying statefulset ss doesn't scale past 1 for another 7.995922212s
Nov  8 16:43:07.324: INFO: Verifying statefulset ss doesn't scale past 1 for another 6.993694919s
Nov  8 16:43:08.327: INFO: Verifying statefulset ss doesn't scale past 1 for another 5.991420277s
Nov  8 16:43:09.329: INFO: Verifying statefulset ss doesn't scale past 1 for another 4.989112522s
Nov  8 16:43:10.331: INFO: Verifying statefulset ss doesn't scale past 1 for another 3.986876463s
Nov  8 16:43:11.333: INFO: Verifying statefulset ss doesn't scale past 1 for another 2.984661907s
Nov  8 16:43:12.335: INFO: Verifying statefulset ss doesn't scale past 1 for another 1.982375849s
Nov  8 16:43:13.338: INFO: Verifying statefulset ss doesn't scale past 1 for another 980.182091ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace e2e-tests-statefulset-wrj7q
Nov  8 16:43:14.340: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-235977939 exec --namespace=e2e-tests-statefulset-wrj7q ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Nov  8 16:43:14.473: INFO: stderr: ""
Nov  8 16:43:14.473: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Nov  8 16:43:14.473: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Nov  8 16:43:14.475: INFO: Found 1 stateful pods, waiting for 3
Nov  8 16:43:24.477: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Nov  8 16:43:24.477: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Nov  8 16:43:24.477: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Verifying that stateful set ss was scaled up in order
STEP: Scale down will halt with unhealthy stateful pod
Nov  8 16:43:24.480: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-235977939 exec --namespace=e2e-tests-statefulset-wrj7q ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Nov  8 16:43:24.629: INFO: stderr: ""
Nov  8 16:43:24.629: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Nov  8 16:43:24.629: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Nov  8 16:43:24.630: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-235977939 exec --namespace=e2e-tests-statefulset-wrj7q ss-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Nov  8 16:43:24.760: INFO: stderr: ""
Nov  8 16:43:24.760: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Nov  8 16:43:24.760: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Nov  8 16:43:24.760: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-235977939 exec --namespace=e2e-tests-statefulset-wrj7q ss-2 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Nov  8 16:43:24.888: INFO: stderr: ""
Nov  8 16:43:24.888: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Nov  8 16:43:24.888: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-2: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Nov  8 16:43:24.888: INFO: Waiting for statefulset status.replicas updated to 0
Nov  8 16:43:24.890: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 3
Nov  8 16:43:34.894: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Nov  8 16:43:34.894: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Nov  8 16:43:34.894: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Nov  8 16:43:34.899: INFO: Verifying statefulset ss doesn't scale past 3 for another 9.999999802s
Nov  8 16:43:35.901: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.997836156s
Nov  8 16:43:36.904: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.995642577s
Nov  8 16:43:37.906: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.993331754s
Nov  8 16:43:38.908: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.991179695s
Nov  8 16:43:39.910: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.988882056s
Nov  8 16:43:40.913: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.986703546s
Nov  8 16:43:41.915: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.984421301s
Nov  8 16:43:42.917: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.982350094s
Nov  8 16:43:43.919: INFO: Verifying statefulset ss doesn't scale past 3 for another 979.897736ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacee2e-tests-statefulset-wrj7q
Nov  8 16:43:44.922: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-235977939 exec --namespace=e2e-tests-statefulset-wrj7q ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Nov  8 16:43:45.054: INFO: stderr: ""
Nov  8 16:43:45.054: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Nov  8 16:43:45.054: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Nov  8 16:43:45.054: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-235977939 exec --namespace=e2e-tests-statefulset-wrj7q ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Nov  8 16:43:45.186: INFO: stderr: ""
Nov  8 16:43:45.186: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Nov  8 16:43:45.186: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Nov  8 16:43:45.186: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-235977939 exec --namespace=e2e-tests-statefulset-wrj7q ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Nov  8 16:43:45.306: INFO: stderr: ""
Nov  8 16:43:45.306: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Nov  8 16:43:45.306: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-2: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Nov  8 16:43:45.306: INFO: Scaling statefulset ss to 0
STEP: Verifying that stateful set ss was scaled down in reverse order
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Nov  8 16:44:15.314: INFO: Deleting all statefulset in ns e2e-tests-statefulset-wrj7q
Nov  8 16:44:15.316: INFO: Scaling statefulset ss to 0
Nov  8 16:44:15.320: INFO: Waiting for statefulset status.replicas updated to 0
Nov  8 16:44:15.322: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  8 16:44:15.328: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-wrj7q" for this suite.
Nov  8 16:44:21.336: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  8 16:44:21.351: INFO: namespace: e2e-tests-statefulset-wrj7q, resource: bindings, ignored listing per whitelist
Nov  8 16:44:21.388: INFO: namespace e2e-tests-statefulset-wrj7q deletion completed in 6.05818415s

• [SLOW TEST:97.265 seconds]
[sig-apps] StatefulSet
/go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
    /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-api-machinery] Garbage collector 
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  8 16:44:21.388: INFO: >>> kubeConfig: /tmp/kubeconfig-235977939
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the rc1
STEP: create the rc2
STEP: set half of pods created by rc simpletest-rc-to-be-deleted to have rc simpletest-rc-to-stay as owner as well
STEP: delete the rc simpletest-rc-to-be-deleted
STEP: wait for the rc to be deleted
STEP: Gathering metrics
Nov  8 16:44:31.456: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  8 16:44:31.456: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-9g5xf" for this suite.
Nov  8 16:44:37.463: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  8 16:44:37.486: INFO: namespace: e2e-tests-gc-9g5xf, resource: bindings, ignored listing per whitelist
Nov  8 16:44:37.519: INFO: namespace e2e-tests-gc-9g5xf deletion completed in 6.060885177s

• [SLOW TEST:16.130 seconds]
[sig-api-machinery] Garbage collector
/go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should create and stop a replication controller  [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  8 16:44:37.519: INFO: >>> kubeConfig: /tmp/kubeconfig-235977939
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Update Demo
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:293
[It] should create and stop a replication controller  [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a replication controller
Nov  8 16:44:37.562: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-235977939 create -f - --namespace=e2e-tests-kubectl-jtfqh'
Nov  8 16:44:37.868: INFO: stderr: ""
Nov  8 16:44:37.868: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Nov  8 16:44:37.868: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-235977939 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-jtfqh'
Nov  8 16:44:37.939: INFO: stderr: ""
Nov  8 16:44:37.939: INFO: stdout: "update-demo-nautilus-8l4nd update-demo-nautilus-t8mrf "
Nov  8 16:44:37.939: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-235977939 get pods update-demo-nautilus-8l4nd -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-jtfqh'
Nov  8 16:44:38.000: INFO: stderr: ""
Nov  8 16:44:38.000: INFO: stdout: ""
Nov  8 16:44:38.000: INFO: update-demo-nautilus-8l4nd is created but not running
Nov  8 16:44:43.000: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-235977939 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-jtfqh'
Nov  8 16:44:43.064: INFO: stderr: ""
Nov  8 16:44:43.064: INFO: stdout: "update-demo-nautilus-8l4nd update-demo-nautilus-t8mrf "
Nov  8 16:44:43.064: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-235977939 get pods update-demo-nautilus-8l4nd -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-jtfqh'
Nov  8 16:44:43.124: INFO: stderr: ""
Nov  8 16:44:43.124: INFO: stdout: "true"
Nov  8 16:44:43.124: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-235977939 get pods update-demo-nautilus-8l4nd -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-jtfqh'
Nov  8 16:44:43.183: INFO: stderr: ""
Nov  8 16:44:43.183: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Nov  8 16:44:43.183: INFO: validating pod update-demo-nautilus-8l4nd
Nov  8 16:44:43.185: INFO: got data: {
  "image": "nautilus.jpg"
}

Nov  8 16:44:43.185: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Nov  8 16:44:43.185: INFO: update-demo-nautilus-8l4nd is verified up and running
Nov  8 16:44:43.185: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-235977939 get pods update-demo-nautilus-t8mrf -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-jtfqh'
Nov  8 16:44:43.245: INFO: stderr: ""
Nov  8 16:44:43.245: INFO: stdout: "true"
Nov  8 16:44:43.245: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-235977939 get pods update-demo-nautilus-t8mrf -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-jtfqh'
Nov  8 16:44:43.305: INFO: stderr: ""
Nov  8 16:44:43.305: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Nov  8 16:44:43.305: INFO: validating pod update-demo-nautilus-t8mrf
Nov  8 16:44:43.307: INFO: got data: {
  "image": "nautilus.jpg"
}

Nov  8 16:44:43.307: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Nov  8 16:44:43.307: INFO: update-demo-nautilus-t8mrf is verified up and running
STEP: using delete to clean up resources
Nov  8 16:44:43.307: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-235977939 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-jtfqh'
Nov  8 16:44:43.370: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Nov  8 16:44:43.370: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Nov  8 16:44:43.370: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-235977939 get rc,svc -l name=update-demo --no-headers --namespace=e2e-tests-kubectl-jtfqh'
Nov  8 16:44:43.459: INFO: stderr: "No resources found.\n"
Nov  8 16:44:43.459: INFO: stdout: ""
Nov  8 16:44:43.459: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-235977939 get pods -l name=update-demo --namespace=e2e-tests-kubectl-jtfqh -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Nov  8 16:44:43.541: INFO: stderr: ""
Nov  8 16:44:43.541: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  8 16:44:43.541: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-jtfqh" for this suite.
Nov  8 16:44:49.551: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  8 16:44:49.589: INFO: namespace: e2e-tests-kubectl-jtfqh, resource: bindings, ignored listing per whitelist
Nov  8 16:44:49.603: INFO: namespace e2e-tests-kubectl-jtfqh deletion completed in 6.059201846s

• [SLOW TEST:12.085 seconds]
[sig-cli] Kubectl client
/go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Update Demo
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create and stop a replication controller  [Conformance]
    /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod with mountPath of existing file [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  8 16:44:49.603: INFO: >>> kubeConfig: /tmp/kubeconfig-235977939
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with configmap pod with mountPath of existing file [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-configmap-m6l7
STEP: Creating a pod to test atomic-volume-subpath
Nov  8 16:44:49.646: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-m6l7" in namespace "e2e-tests-subpath-wzhpj" to be "success or failure"
Nov  8 16:44:49.648: INFO: Pod "pod-subpath-test-configmap-m6l7": Phase="Pending", Reason="", readiness=false. Elapsed: 1.434297ms
Nov  8 16:44:51.650: INFO: Pod "pod-subpath-test-configmap-m6l7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00331746s
Nov  8 16:44:53.652: INFO: Pod "pod-subpath-test-configmap-m6l7": Phase="Running", Reason="", readiness=false. Elapsed: 4.005412732s
Nov  8 16:44:55.654: INFO: Pod "pod-subpath-test-configmap-m6l7": Phase="Running", Reason="", readiness=false. Elapsed: 6.007540803s
Nov  8 16:44:57.656: INFO: Pod "pod-subpath-test-configmap-m6l7": Phase="Running", Reason="", readiness=false. Elapsed: 8.009558536s
Nov  8 16:44:59.658: INFO: Pod "pod-subpath-test-configmap-m6l7": Phase="Running", Reason="", readiness=false. Elapsed: 10.0116869s
Nov  8 16:45:01.660: INFO: Pod "pod-subpath-test-configmap-m6l7": Phase="Running", Reason="", readiness=false. Elapsed: 12.013894737s
Nov  8 16:45:03.663: INFO: Pod "pod-subpath-test-configmap-m6l7": Phase="Running", Reason="", readiness=false. Elapsed: 14.016106457s
Nov  8 16:45:05.665: INFO: Pod "pod-subpath-test-configmap-m6l7": Phase="Running", Reason="", readiness=false. Elapsed: 16.018310994s
Nov  8 16:45:07.667: INFO: Pod "pod-subpath-test-configmap-m6l7": Phase="Running", Reason="", readiness=false. Elapsed: 18.020371547s
Nov  8 16:45:09.669: INFO: Pod "pod-subpath-test-configmap-m6l7": Phase="Running", Reason="", readiness=false. Elapsed: 20.022401355s
Nov  8 16:45:11.671: INFO: Pod "pod-subpath-test-configmap-m6l7": Phase="Running", Reason="", readiness=false. Elapsed: 22.024608598s
Nov  8 16:45:13.673: INFO: Pod "pod-subpath-test-configmap-m6l7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.02653072s
STEP: Saw pod success
Nov  8 16:45:13.673: INFO: Pod "pod-subpath-test-configmap-m6l7" satisfied condition "success or failure"
Nov  8 16:45:13.675: INFO: Trying to get logs from node ip-10-0-100-224.ec2.internal pod pod-subpath-test-configmap-m6l7 container test-container-subpath-configmap-m6l7: <nil>
STEP: delete the pod
Nov  8 16:45:13.685: INFO: Waiting for pod pod-subpath-test-configmap-m6l7 to disappear
Nov  8 16:45:13.687: INFO: Pod pod-subpath-test-configmap-m6l7 no longer exists
STEP: Deleting pod pod-subpath-test-configmap-m6l7
Nov  8 16:45:13.687: INFO: Deleting pod "pod-subpath-test-configmap-m6l7" in namespace "e2e-tests-subpath-wzhpj"
[AfterEach] [sig-storage] Subpath
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  8 16:45:13.688: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-wzhpj" for this suite.
Nov  8 16:45:19.695: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  8 16:45:19.720: INFO: namespace: e2e-tests-subpath-wzhpj, resource: bindings, ignored listing per whitelist
Nov  8 16:45:19.748: INFO: namespace e2e-tests-subpath-wzhpj deletion completed in 6.058138246s

• [SLOW TEST:30.145 seconds]
[sig-storage] Subpath
/go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with configmap pod with mountPath of existing file [Conformance]
    /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected 
  should provide container's memory request [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  8 16:45:19.749: INFO: >>> kubeConfig: /tmp/kubeconfig-235977939
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should provide container's memory request [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Nov  8 16:45:19.790: INFO: Waiting up to 5m0s for pod "downwardapi-volume-ad97af17-e375-11e8-b0fd-0e97e856486a" in namespace "e2e-tests-projected-52v8c" to be "success or failure"
Nov  8 16:45:19.792: INFO: Pod "downwardapi-volume-ad97af17-e375-11e8-b0fd-0e97e856486a": Phase="Pending", Reason="", readiness=false. Elapsed: 1.766672ms
Nov  8 16:45:21.794: INFO: Pod "downwardapi-volume-ad97af17-e375-11e8-b0fd-0e97e856486a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.003530621s
STEP: Saw pod success
Nov  8 16:45:21.794: INFO: Pod "downwardapi-volume-ad97af17-e375-11e8-b0fd-0e97e856486a" satisfied condition "success or failure"
Nov  8 16:45:21.795: INFO: Trying to get logs from node ip-10-0-100-224.ec2.internal pod downwardapi-volume-ad97af17-e375-11e8-b0fd-0e97e856486a container client-container: <nil>
STEP: delete the pod
Nov  8 16:45:21.804: INFO: Waiting for pod downwardapi-volume-ad97af17-e375-11e8-b0fd-0e97e856486a to disappear
Nov  8 16:45:21.805: INFO: Pod downwardapi-volume-ad97af17-e375-11e8-b0fd-0e97e856486a no longer exists
[AfterEach] [sig-storage] Projected
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  8 16:45:21.805: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-52v8c" for this suite.
Nov  8 16:45:27.812: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  8 16:45:27.855: INFO: namespace: e2e-tests-projected-52v8c, resource: bindings, ignored listing per whitelist
Nov  8 16:45:27.865: INFO: namespace e2e-tests-projected-52v8c deletion completed in 6.058173425s

• [SLOW TEST:8.117 seconds]
[sig-storage] Projected
/go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should provide container's memory request [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Secrets 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  8 16:45:27.865: INFO: >>> kubeConfig: /tmp/kubeconfig-235977939
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name s-test-opt-del-b26e1c3a-e375-11e8-b0fd-0e97e856486a
STEP: Creating secret with name s-test-opt-upd-b26e1c64-e375-11e8-b0fd-0e97e856486a
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-b26e1c3a-e375-11e8-b0fd-0e97e856486a
STEP: Updating secret s-test-opt-upd-b26e1c64-e375-11e8-b0fd-0e97e856486a
STEP: Creating secret with name s-test-opt-create-b26e1c81-e375-11e8-b0fd-0e97e856486a
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Secrets
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  8 16:45:31.948: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-56knq" for this suite.
Nov  8 16:45:53.955: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  8 16:45:53.983: INFO: namespace: e2e-tests-secrets-56knq, resource: bindings, ignored listing per whitelist
Nov  8 16:45:54.007: INFO: namespace e2e-tests-secrets-56knq deletion completed in 22.057570538s

• [SLOW TEST:26.142 seconds]
[sig-storage] Secrets
/go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with secret pod [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  8 16:45:54.007: INFO: >>> kubeConfig: /tmp/kubeconfig-235977939
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with secret pod [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-secret-dkm6
STEP: Creating a pod to test atomic-volume-subpath
Nov  8 16:45:54.050: INFO: Waiting up to 5m0s for pod "pod-subpath-test-secret-dkm6" in namespace "e2e-tests-subpath-vl7pm" to be "success or failure"
Nov  8 16:45:54.052: INFO: Pod "pod-subpath-test-secret-dkm6": Phase="Pending", Reason="", readiness=false. Elapsed: 1.501919ms
Nov  8 16:45:56.054: INFO: Pod "pod-subpath-test-secret-dkm6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.003530435s
Nov  8 16:45:58.056: INFO: Pod "pod-subpath-test-secret-dkm6": Phase="Running", Reason="", readiness=false. Elapsed: 4.00564549s
Nov  8 16:46:00.058: INFO: Pod "pod-subpath-test-secret-dkm6": Phase="Running", Reason="", readiness=false. Elapsed: 6.007471036s
Nov  8 16:46:02.060: INFO: Pod "pod-subpath-test-secret-dkm6": Phase="Running", Reason="", readiness=false. Elapsed: 8.009723369s
Nov  8 16:46:04.062: INFO: Pod "pod-subpath-test-secret-dkm6": Phase="Running", Reason="", readiness=false. Elapsed: 10.011869109s
Nov  8 16:46:06.064: INFO: Pod "pod-subpath-test-secret-dkm6": Phase="Running", Reason="", readiness=false. Elapsed: 12.014017967s
Nov  8 16:46:08.066: INFO: Pod "pod-subpath-test-secret-dkm6": Phase="Running", Reason="", readiness=false. Elapsed: 14.016109779s
Nov  8 16:46:10.068: INFO: Pod "pod-subpath-test-secret-dkm6": Phase="Running", Reason="", readiness=false. Elapsed: 16.018162745s
Nov  8 16:46:12.070: INFO: Pod "pod-subpath-test-secret-dkm6": Phase="Running", Reason="", readiness=false. Elapsed: 18.020200036s
Nov  8 16:46:14.073: INFO: Pod "pod-subpath-test-secret-dkm6": Phase="Running", Reason="", readiness=false. Elapsed: 20.022273206s
Nov  8 16:46:16.075: INFO: Pod "pod-subpath-test-secret-dkm6": Phase="Running", Reason="", readiness=false. Elapsed: 22.024307837s
Nov  8 16:46:18.077: INFO: Pod "pod-subpath-test-secret-dkm6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.026382269s
STEP: Saw pod success
Nov  8 16:46:18.077: INFO: Pod "pod-subpath-test-secret-dkm6" satisfied condition "success or failure"
Nov  8 16:46:18.078: INFO: Trying to get logs from node ip-10-0-100-224.ec2.internal pod pod-subpath-test-secret-dkm6 container test-container-subpath-secret-dkm6: <nil>
STEP: delete the pod
Nov  8 16:46:18.089: INFO: Waiting for pod pod-subpath-test-secret-dkm6 to disappear
Nov  8 16:46:18.090: INFO: Pod pod-subpath-test-secret-dkm6 no longer exists
STEP: Deleting pod pod-subpath-test-secret-dkm6
Nov  8 16:46:18.090: INFO: Deleting pod "pod-subpath-test-secret-dkm6" in namespace "e2e-tests-subpath-vl7pm"
[AfterEach] [sig-storage] Subpath
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  8 16:46:18.091: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-vl7pm" for this suite.
Nov  8 16:46:24.099: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  8 16:46:24.105: INFO: namespace: e2e-tests-subpath-vl7pm, resource: bindings, ignored listing per whitelist
Nov  8 16:46:24.153: INFO: namespace e2e-tests-subpath-vl7pm deletion completed in 6.058616816s

• [SLOW TEST:30.145 seconds]
[sig-storage] Subpath
/go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with secret pod [Conformance]
    /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] ConfigMap 
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  8 16:46:24.153: INFO: >>> kubeConfig: /tmp/kubeconfig-235977939
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] binary data should be reflected in volume [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-upd-d3fb1e0d-e375-11e8-b0fd-0e97e856486a
STEP: Creating the pod
STEP: Waiting for pod with text data
STEP: Waiting for pod with binary data
[AfterEach] [sig-storage] ConfigMap
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  8 16:46:26.217: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-p29h6" for this suite.
Nov  8 16:46:48.225: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  8 16:46:48.239: INFO: namespace: e2e-tests-configmap-p29h6, resource: bindings, ignored listing per whitelist
Nov  8 16:46:48.278: INFO: namespace e2e-tests-configmap-p29h6 deletion completed in 22.058426464s

• [SLOW TEST:24.125 seconds]
[sig-storage] ConfigMap
/go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  8 16:46:48.278: INFO: >>> kubeConfig: /tmp/kubeconfig-235977939
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-e25c83fa-e375-11e8-b0fd-0e97e856486a
STEP: Creating a pod to test consume secrets
Nov  8 16:46:48.324: INFO: Waiting up to 5m0s for pod "pod-secrets-e25cbd4c-e375-11e8-b0fd-0e97e856486a" in namespace "e2e-tests-secrets-2rg7n" to be "success or failure"
Nov  8 16:46:48.325: INFO: Pod "pod-secrets-e25cbd4c-e375-11e8-b0fd-0e97e856486a": Phase="Pending", Reason="", readiness=false. Elapsed: 1.254148ms
Nov  8 16:46:50.327: INFO: Pod "pod-secrets-e25cbd4c-e375-11e8-b0fd-0e97e856486a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.003062907s
STEP: Saw pod success
Nov  8 16:46:50.327: INFO: Pod "pod-secrets-e25cbd4c-e375-11e8-b0fd-0e97e856486a" satisfied condition "success or failure"
Nov  8 16:46:50.328: INFO: Trying to get logs from node ip-10-0-100-224.ec2.internal pod pod-secrets-e25cbd4c-e375-11e8-b0fd-0e97e856486a container secret-volume-test: <nil>
STEP: delete the pod
Nov  8 16:46:50.337: INFO: Waiting for pod pod-secrets-e25cbd4c-e375-11e8-b0fd-0e97e856486a to disappear
Nov  8 16:46:50.339: INFO: Pod pod-secrets-e25cbd4c-e375-11e8-b0fd-0e97e856486a no longer exists
[AfterEach] [sig-storage] Secrets
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  8 16:46:50.339: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-2rg7n" for this suite.
Nov  8 16:46:56.346: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  8 16:46:56.368: INFO: namespace: e2e-tests-secrets-2rg7n, resource: bindings, ignored listing per whitelist
Nov  8 16:46:56.399: INFO: namespace e2e-tests-secrets-2rg7n deletion completed in 6.058901621s

• [SLOW TEST:8.122 seconds]
[sig-storage] Secrets
/go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-api-machinery] Watchers 
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Watchers
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  8 16:46:56.400: INFO: >>> kubeConfig: /tmp/kubeconfig-235977939
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe add, update, and delete watch notifications on configmaps [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a watch on configmaps with label A
STEP: creating a watch on configmaps with label B
STEP: creating a watch on configmaps with label A or B
STEP: creating a configmap with label A and ensuring the correct watchers observe the notification
Nov  8 16:46:56.440: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-qslnx,SelfLink:/api/v1/namespaces/e2e-tests-watch-qslnx/configmaps/e2e-watch-test-configmap-a,UID:e733b70a-e375-11e8-a466-0a0beb0244cc,ResourceVersion:14190,Generation:0,CreationTimestamp:2018-11-08 16:46:56 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Nov  8 16:46:56.440: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-qslnx,SelfLink:/api/v1/namespaces/e2e-tests-watch-qslnx/configmaps/e2e-watch-test-configmap-a,UID:e733b70a-e375-11e8-a466-0a0beb0244cc,ResourceVersion:14190,Generation:0,CreationTimestamp:2018-11-08 16:46:56 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: modifying configmap A and ensuring the correct watchers observe the notification
Nov  8 16:47:06.444: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-qslnx,SelfLink:/api/v1/namespaces/e2e-tests-watch-qslnx/configmaps/e2e-watch-test-configmap-a,UID:e733b70a-e375-11e8-a466-0a0beb0244cc,ResourceVersion:14205,Generation:0,CreationTimestamp:2018-11-08 16:46:56 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Nov  8 16:47:06.444: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-qslnx,SelfLink:/api/v1/namespaces/e2e-tests-watch-qslnx/configmaps/e2e-watch-test-configmap-a,UID:e733b70a-e375-11e8-a466-0a0beb0244cc,ResourceVersion:14205,Generation:0,CreationTimestamp:2018-11-08 16:46:56 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying configmap A again and ensuring the correct watchers observe the notification
Nov  8 16:47:16.449: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-qslnx,SelfLink:/api/v1/namespaces/e2e-tests-watch-qslnx/configmaps/e2e-watch-test-configmap-a,UID:e733b70a-e375-11e8-a466-0a0beb0244cc,ResourceVersion:14220,Generation:0,CreationTimestamp:2018-11-08 16:46:56 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Nov  8 16:47:16.449: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-qslnx,SelfLink:/api/v1/namespaces/e2e-tests-watch-qslnx/configmaps/e2e-watch-test-configmap-a,UID:e733b70a-e375-11e8-a466-0a0beb0244cc,ResourceVersion:14220,Generation:0,CreationTimestamp:2018-11-08 16:46:56 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: deleting configmap A and ensuring the correct watchers observe the notification
Nov  8 16:47:26.452: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-qslnx,SelfLink:/api/v1/namespaces/e2e-tests-watch-qslnx/configmaps/e2e-watch-test-configmap-a,UID:e733b70a-e375-11e8-a466-0a0beb0244cc,ResourceVersion:14235,Generation:0,CreationTimestamp:2018-11-08 16:46:56 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Nov  8 16:47:26.452: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-qslnx,SelfLink:/api/v1/namespaces/e2e-tests-watch-qslnx/configmaps/e2e-watch-test-configmap-a,UID:e733b70a-e375-11e8-a466-0a0beb0244cc,ResourceVersion:14235,Generation:0,CreationTimestamp:2018-11-08 16:46:56 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: creating a configmap with label B and ensuring the correct watchers observe the notification
Nov  8 16:47:36.456: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-qslnx,SelfLink:/api/v1/namespaces/e2e-tests-watch-qslnx/configmaps/e2e-watch-test-configmap-b,UID:ff0d653f-e375-11e8-a466-0a0beb0244cc,ResourceVersion:14250,Generation:0,CreationTimestamp:2018-11-08 16:47:36 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Nov  8 16:47:36.456: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-qslnx,SelfLink:/api/v1/namespaces/e2e-tests-watch-qslnx/configmaps/e2e-watch-test-configmap-b,UID:ff0d653f-e375-11e8-a466-0a0beb0244cc,ResourceVersion:14250,Generation:0,CreationTimestamp:2018-11-08 16:47:36 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: deleting configmap B and ensuring the correct watchers observe the notification
Nov  8 16:47:46.459: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-qslnx,SelfLink:/api/v1/namespaces/e2e-tests-watch-qslnx/configmaps/e2e-watch-test-configmap-b,UID:ff0d653f-e375-11e8-a466-0a0beb0244cc,ResourceVersion:14266,Generation:0,CreationTimestamp:2018-11-08 16:47:36 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Nov  8 16:47:46.459: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-qslnx,SelfLink:/api/v1/namespaces/e2e-tests-watch-qslnx/configmaps/e2e-watch-test-configmap-b,UID:ff0d653f-e375-11e8-a466-0a0beb0244cc,ResourceVersion:14266,Generation:0,CreationTimestamp:2018-11-08 16:47:36 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  8 16:47:56.459: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-qslnx" for this suite.
Nov  8 16:48:02.468: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  8 16:48:02.476: INFO: namespace: e2e-tests-watch-qslnx, resource: bindings, ignored listing per whitelist
Nov  8 16:48:02.522: INFO: namespace e2e-tests-watch-qslnx deletion completed in 6.059741256s

• [SLOW TEST:66.122 seconds]
[sig-api-machinery] Watchers
/go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[k8s.io] Probing container 
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  8 16:48:02.522: INFO: >>> kubeConfig: /tmp/kubeconfig-235977939
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-http in namespace e2e-tests-container-probe-gwfzv
Nov  8 16:48:06.567: INFO: Started pod liveness-http in namespace e2e-tests-container-probe-gwfzv
STEP: checking the pod's current state and verifying that restartCount is present
Nov  8 16:48:06.568: INFO: Initial restart count of pod liveness-http is 0
Nov  8 16:48:22.594: INFO: Restart count of pod e2e-tests-container-probe-gwfzv/liveness-http is now 1 (16.025503932s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  8 16:48:22.598: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-gwfzv" for this suite.
Nov  8 16:48:28.606: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  8 16:48:28.616: INFO: namespace: e2e-tests-container-probe-gwfzv, resource: bindings, ignored listing per whitelist
Nov  8 16:48:28.659: INFO: namespace e2e-tests-container-probe-gwfzv deletion completed in 6.058629172s

• [SLOW TEST:26.137 seconds]
[k8s.io] Probing container
/go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl describe 
  should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  8 16:48:28.659: INFO: >>> kubeConfig: /tmp/kubeconfig-235977939
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Nov  8 16:48:28.698: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-235977939 version --client'
Nov  8 16:48:28.748: INFO: stderr: ""
Nov  8 16:48:28.748: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"12+\", GitVersion:\"v1.12.2-heptio.1\", GitCommit:\"066ecbf74983f77692028c559a35725ce74122a4\", GitTreeState:\"clean\", BuildDate:\"2018-10-30T16:02:00Z\", GoVersion:\"go1.10.4\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
Nov  8 16:48:28.750: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-235977939 create -f - --namespace=e2e-tests-kubectl-lxljf'
Nov  8 16:48:28.882: INFO: stderr: ""
Nov  8 16:48:28.882: INFO: stdout: "replicationcontroller/redis-master created\n"
Nov  8 16:48:28.882: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-235977939 create -f - --namespace=e2e-tests-kubectl-lxljf'
Nov  8 16:48:29.016: INFO: stderr: ""
Nov  8 16:48:29.016: INFO: stdout: "service/redis-master created\n"
STEP: Waiting for Redis master to start.
Nov  8 16:48:30.018: INFO: Selector matched 1 pods for map[app:redis]
Nov  8 16:48:30.018: INFO: Found 1 / 1
Nov  8 16:48:30.018: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Nov  8 16:48:30.020: INFO: Selector matched 1 pods for map[app:redis]
Nov  8 16:48:30.020: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Nov  8 16:48:30.020: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-235977939 describe pod redis-master-v684v --namespace=e2e-tests-kubectl-lxljf'
Nov  8 16:48:30.091: INFO: stderr: ""
Nov  8 16:48:30.091: INFO: stdout: "Name:               redis-master-v684v\nNamespace:          e2e-tests-kubectl-lxljf\nPriority:           0\nPriorityClassName:  <none>\nNode:               ip-10-0-100-224.ec2.internal/10.0.100.224\nStart Time:         Thu, 08 Nov 2018 16:48:28 +0000\nLabels:             app=redis\n                    role=master\nAnnotations:        cni.projectcalico.org/podIP: 192.168.1.129/32\nStatus:             Running\nIP:                 192.168.1.129\nControlled By:      ReplicationController/redis-master\nContainers:\n  redis-master:\n    Container ID:   docker://2f8f1ecec1f8bf385ab725677a59884d24a6627d2313b46c2fa8ec8115cba41f\n    Image:          gcr.io/kubernetes-e2e-test-images/redis:1.0\n    Image ID:       docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830\n    Port:           6379/TCP\n    Host Port:      0/TCP\n    State:          Running\n      Started:      Thu, 08 Nov 2018 16:48:29 +0000\n    Ready:          True\n    Restart Count:  0\n    Environment:    <none>\n    Mounts:\n      /var/run/secrets/kubernetes.io/serviceaccount from default-token-9qnfv (ro)\nConditions:\n  Type              Status\n  Initialized       True \n  Ready             True \n  ContainersReady   True \n  PodScheduled      True \nVolumes:\n  default-token-9qnfv:\n    Type:        Secret (a volume populated by a Secret)\n    SecretName:  default-token-9qnfv\n    Optional:    false\nQoS Class:       BestEffort\nNode-Selectors:  <none>\nTolerations:     node.kubernetes.io/not-ready:NoExecute for 300s\n                 node.kubernetes.io/unreachable:NoExecute for 300s\nEvents:\n  Type    Reason     Age   From                                   Message\n  ----    ------     ----  ----                                   -------\n  Normal  Scheduled  2s    default-scheduler                      Successfully assigned e2e-tests-kubectl-lxljf/redis-master-v684v to ip-10-0-100-224.ec2.internal\n  Normal  Pulled     1s    kubelet, ip-10-0-100-224.ec2.internal  Container image \"gcr.io/kubernetes-e2e-test-images/redis:1.0\" already present on machine\n  Normal  Created    1s    kubelet, ip-10-0-100-224.ec2.internal  Created container\n  Normal  Started    1s    kubelet, ip-10-0-100-224.ec2.internal  Started container\n"
Nov  8 16:48:30.091: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-235977939 describe rc redis-master --namespace=e2e-tests-kubectl-lxljf'
Nov  8 16:48:30.166: INFO: stderr: ""
Nov  8 16:48:30.166: INFO: stdout: "Name:         redis-master\nNamespace:    e2e-tests-kubectl-lxljf\nSelector:     app=redis,role=master\nLabels:       app=redis\n              role=master\nAnnotations:  <none>\nReplicas:     1 current / 1 desired\nPods Status:  1 Running / 0 Waiting / 0 Succeeded / 0 Failed\nPod Template:\n  Labels:  app=redis\n           role=master\n  Containers:\n   redis-master:\n    Image:        gcr.io/kubernetes-e2e-test-images/redis:1.0\n    Port:         6379/TCP\n    Host Port:    0/TCP\n    Environment:  <none>\n    Mounts:       <none>\n  Volumes:        <none>\nEvents:\n  Type    Reason            Age   From                    Message\n  ----    ------            ----  ----                    -------\n  Normal  SuccessfulCreate  2s    replication-controller  Created pod: redis-master-v684v\n"
Nov  8 16:48:30.166: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-235977939 describe service redis-master --namespace=e2e-tests-kubectl-lxljf'
Nov  8 16:48:30.235: INFO: stderr: ""
Nov  8 16:48:30.235: INFO: stdout: "Name:              redis-master\nNamespace:         e2e-tests-kubectl-lxljf\nLabels:            app=redis\n                   role=master\nAnnotations:       <none>\nSelector:          app=redis,role=master\nType:              ClusterIP\nIP:                10.103.224.209\nPort:              <unset>  6379/TCP\nTargetPort:        redis-server/TCP\nEndpoints:         192.168.1.129:6379\nSession Affinity:  None\nEvents:            <none>\n"
Nov  8 16:48:30.237: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-235977939 describe node ip-10-0-0-20.ec2.internal'
Nov  8 16:48:30.314: INFO: stderr: ""
Nov  8 16:48:30.314: INFO: stdout: "Name:               ip-10-0-0-20.ec2.internal\nRoles:              master\nLabels:             beta.kubernetes.io/arch=amd64\n                    beta.kubernetes.io/instance-type=m5.xlarge\n                    beta.kubernetes.io/os=linux\n                    failure-domain.beta.kubernetes.io/region=us-east-1\n                    failure-domain.beta.kubernetes.io/zone=us-east-1a\n                    kubernetes.io/hostname=ip-10-0-0-20.ec2.internal\n                    node-role.kubernetes.io/master=\nAnnotations:        kubeadm.alpha.kubernetes.io/cri-socket: /var/run/dockershim.sock\n                    node.alpha.kubernetes.io/ttl: 0\n                    projectcalico.org/IPv4Address: 10.0.0.20/24\n                    volumes.kubernetes.io/controller-managed-attach-detach: true\nCreationTimestamp:  Thu, 08 Nov 2018 15:07:50 +0000\nTaints:             node-role.kubernetes.io/master:NoSchedule\nUnschedulable:      false\nConditions:\n  Type             Status  LastHeartbeatTime                 LastTransitionTime                Reason                       Message\n  ----             ------  -----------------                 ------------------                ------                       -------\n  OutOfDisk        False   Thu, 08 Nov 2018 16:48:24 +0000   Thu, 08 Nov 2018 15:07:43 +0000   KubeletHasSufficientDisk     kubelet has sufficient disk space available\n  MemoryPressure   False   Thu, 08 Nov 2018 16:48:24 +0000   Thu, 08 Nov 2018 15:07:43 +0000   KubeletHasSufficientMemory   kubelet has sufficient memory available\n  DiskPressure     False   Thu, 08 Nov 2018 16:48:24 +0000   Thu, 08 Nov 2018 15:07:43 +0000   KubeletHasNoDiskPressure     kubelet has no disk pressure\n  PIDPressure      False   Thu, 08 Nov 2018 16:48:24 +0000   Thu, 08 Nov 2018 15:07:43 +0000   KubeletHasSufficientPID      kubelet has sufficient PID available\n  Ready            True    Thu, 08 Nov 2018 16:48:24 +0000   Thu, 08 Nov 2018 15:08:20 +0000   KubeletReady                 kubelet is posting ready status. AppArmor enabled\nAddresses:\n  InternalIP:   10.0.0.20\n  ExternalIP:   54.146.27.152\n  InternalDNS:  ip-10-0-0-20.ec2.internal\n  Hostname:     ip-10-0-0-20.ec2.internal\n  ExternalDNS:  ec2-54-146-27-152.compute-1.amazonaws.com\nCapacity:\n attachable-volumes-aws-ebs:  25\n cpu:                         4\n ephemeral-storage:           20263528Ki\n hugepages-1Gi:               0\n hugepages-2Mi:               0\n memory:                      15957688Ki\n pods:                        110\nAllocatable:\n attachable-volumes-aws-ebs:  25\n cpu:                         4\n ephemeral-storage:           18674867374\n hugepages-1Gi:               0\n hugepages-2Mi:               0\n memory:                      15855288Ki\n pods:                        110\nSystem Info:\n Machine ID:                 ec2cfa8e68200a789305921c0833d98c\n System UUID:                EC2CFA8E-6820-0A78-9305-921C0833D98C\n Boot ID:                    9e60cb9c-8620-4b21-bf90-e76b2bc66a31\n Kernel Version:             4.4.0-1066-aws\n OS Image:                   Ubuntu 16.04.5 LTS\n Operating System:           linux\n Architecture:               amd64\n Container Runtime Version:  docker://17.3.2\n Kubelet Version:            v1.12.2-heptio.1\n Kube-Proxy Version:         v1.12.2-heptio.1\nPodCIDR:                     192.168.0.0/24\nProviderID:                  aws:///us-east-1a/i-02c2f2ed9a210817e\nNon-terminated Pods:         (7 in total)\n  Namespace                  Name                                                       CPU Requests  CPU Limits  Memory Requests  Memory Limits\n  ---------                  ----                                                       ------------  ----------  ---------------  -------------\n  heptio-sonobuoy            sonobuoy-systemd-logs-daemon-set-0aa241421f524e19-h7hdn    0 (0%)        0 (0%)      0 (0%)           0 (0%)\n  kube-system                calico-node-2k85b                                          250m (6%)     0 (0%)      0 (0%)           0 (0%)\n  kube-system                etcd-ip-10-0-0-20.ec2.internal                             0 (0%)        0 (0%)      0 (0%)           0 (0%)\n  kube-system                kube-apiserver-ip-10-0-0-20.ec2.internal                   250m (6%)     0 (0%)      0 (0%)           0 (0%)\n  kube-system                kube-controller-manager-ip-10-0-0-20.ec2.internal          200m (5%)     0 (0%)      0 (0%)           0 (0%)\n  kube-system                kube-proxy-qg78s                                           0 (0%)        0 (0%)      0 (0%)           0 (0%)\n  kube-system                kube-scheduler-ip-10-0-0-20.ec2.internal                   100m (2%)     0 (0%)      0 (0%)           0 (0%)\nAllocated resources:\n  (Total limits may be over 100 percent, i.e., overcommitted.)\n  Resource                    Requests    Limits\n  --------                    --------    ------\n  cpu                         800m (20%)  0 (0%)\n  memory                      0 (0%)      0 (0%)\n  attachable-volumes-aws-ebs  0           0\nEvents:                       <none>\n"
Nov  8 16:48:30.314: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-235977939 describe namespace e2e-tests-kubectl-lxljf'
Nov  8 16:48:30.382: INFO: stderr: ""
Nov  8 16:48:30.382: INFO: stdout: "Name:         e2e-tests-kubectl-lxljf\nLabels:       e2e-framework=kubectl\n              e2e-run=5fdf3c5a-e371-11e8-b0fd-0e97e856486a\nAnnotations:  <none>\nStatus:       Active\n\nNo resource quota.\n\nNo resource limits.\n"
[AfterEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  8 16:48:30.382: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-lxljf" for this suite.
Nov  8 16:48:52.389: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  8 16:48:52.404: INFO: namespace: e2e-tests-kubectl-lxljf, resource: bindings, ignored listing per whitelist
Nov  8 16:48:52.444: INFO: namespace e2e-tests-kubectl-lxljf deletion completed in 22.059804276s

• [SLOW TEST:23.785 seconds]
[sig-cli] Kubectl client
/go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl describe
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should check if kubectl describe prints relevant information for rc and pods  [Conformance]
    /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  8 16:48:52.444: INFO: >>> kubeConfig: /tmp/kubeconfig-235977939
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the rs
STEP: Gathering metrics
Nov  8 16:49:23.001: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  8 16:49:23.001: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-lsgzk" for this suite.
Nov  8 16:49:29.009: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  8 16:49:29.052: INFO: namespace: e2e-tests-gc-lsgzk, resource: bindings, ignored listing per whitelist
Nov  8 16:49:29.062: INFO: namespace e2e-tests-gc-lsgzk deletion completed in 6.058440583s

• [SLOW TEST:36.618 seconds]
[sig-api-machinery] Garbage collector
/go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Should recreate evicted statefulset [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  8 16:49:29.062: INFO: >>> kubeConfig: /tmp/kubeconfig-235977939
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-2qzzk
[It] Should recreate evicted statefulset [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Looking for a node to schedule stateful set and pod
STEP: Creating pod with conflicting port in namespace e2e-tests-statefulset-2qzzk
STEP: Creating statefulset with conflicting port in namespace e2e-tests-statefulset-2qzzk
STEP: Waiting until pod test-pod will start running in namespace e2e-tests-statefulset-2qzzk
STEP: Waiting until stateful pod ss-0 will be recreated and deleted at least once in namespace e2e-tests-statefulset-2qzzk
Nov  8 16:49:31.116: INFO: Observed stateful pod in namespace: e2e-tests-statefulset-2qzzk, name: ss-0, uid: 430a5079-e376-11e8-a466-0a0beb0244cc, status phase: Pending. Waiting for statefulset controller to delete.
Nov  8 16:49:31.511: INFO: Observed stateful pod in namespace: e2e-tests-statefulset-2qzzk, name: ss-0, uid: 430a5079-e376-11e8-a466-0a0beb0244cc, status phase: Failed. Waiting for statefulset controller to delete.
Nov  8 16:49:31.515: INFO: Observed stateful pod in namespace: e2e-tests-statefulset-2qzzk, name: ss-0, uid: 430a5079-e376-11e8-a466-0a0beb0244cc, status phase: Failed. Waiting for statefulset controller to delete.
Nov  8 16:49:31.517: INFO: Observed delete event for stateful pod ss-0 in namespace e2e-tests-statefulset-2qzzk
STEP: Removing pod with conflicting port in namespace e2e-tests-statefulset-2qzzk
STEP: Waiting when stateful pod ss-0 will be recreated in namespace e2e-tests-statefulset-2qzzk and will be in running state
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Nov  8 16:49:35.531: INFO: Deleting all statefulset in ns e2e-tests-statefulset-2qzzk
Nov  8 16:49:35.534: INFO: Scaling statefulset ss to 0
Nov  8 16:49:55.541: INFO: Waiting for statefulset status.replicas updated to 0
Nov  8 16:49:55.543: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  8 16:49:55.549: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-2qzzk" for this suite.
Nov  8 16:50:01.558: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  8 16:50:01.589: INFO: namespace: e2e-tests-statefulset-2qzzk, resource: bindings, ignored listing per whitelist
Nov  8 16:50:01.612: INFO: namespace e2e-tests-statefulset-2qzzk deletion completed in 6.060278813s

• [SLOW TEST:32.550 seconds]
[sig-apps] StatefulSet
/go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    Should recreate evicted statefulset [Conformance]
    /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-apps] Deployment 
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  8 16:50:01.612: INFO: >>> kubeConfig: /tmp/kubeconfig-235977939
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] RecreateDeployment should delete old pods and create new ones [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Nov  8 16:50:01.650: INFO: Creating deployment "test-recreate-deployment"
Nov  8 16:50:01.652: INFO: Waiting deployment "test-recreate-deployment" to be updated to revision 1
Nov  8 16:50:01.655: INFO: new replicaset for deployment "test-recreate-deployment" is yet to be created
Nov  8 16:50:03.658: INFO: Waiting deployment "test-recreate-deployment" to complete
Nov  8 16:50:03.660: INFO: Triggering a new rollout for deployment "test-recreate-deployment"
Nov  8 16:50:03.663: INFO: Updating deployment test-recreate-deployment
Nov  8 16:50:03.663: INFO: Watching deployment "test-recreate-deployment" to verify that new pods will not run with olds pods
[AfterEach] [sig-apps] Deployment
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Nov  8 16:50:03.700: INFO: Deployment "test-recreate-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment,GenerateName:,Namespace:e2e-tests-deployment-prgt4,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-prgt4/deployments/test-recreate-deployment,UID:5598b5de-e376-11e8-a466-0a0beb0244cc,ResourceVersion:14770,Generation:2,CreationTimestamp:2018-11-08 16:50:01 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},Strategy:DeploymentStrategy{Type:Recreate,RollingUpdate:nil,},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:0,UnavailableReplicas:1,Conditions:[{Available False 2018-11-08 16:50:03 +0000 UTC 2018-11-08 16:50:03 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.} {Progressing True 2018-11-08 16:50:03 +0000 UTC 2018-11-08 16:50:01 +0000 UTC ReplicaSetUpdated ReplicaSet "test-recreate-deployment-7cf749666b" is progressing.}],ReadyReplicas:0,CollisionCount:nil,},}

Nov  8 16:50:03.704: INFO: New ReplicaSet "test-recreate-deployment-7cf749666b" of Deployment "test-recreate-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-7cf749666b,GenerateName:,Namespace:e2e-tests-deployment-prgt4,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-prgt4/replicasets/test-recreate-deployment-7cf749666b,UID:56cedd10-e376-11e8-a466-0a0beb0244cc,ResourceVersion:14769,Generation:1,CreationTimestamp:2018-11-08 16:50:03 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 7cf749666b,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 1,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment test-recreate-deployment 5598b5de-e376-11e8-a466-0a0beb0244cc 0xc421ef7df7 0xc421ef7df8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 7cf749666b,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 7cf749666b,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Nov  8 16:50:03.704: INFO: All old ReplicaSets of Deployment "test-recreate-deployment":
Nov  8 16:50:03.704: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-79f694ff59,GenerateName:,Namespace:e2e-tests-deployment-prgt4,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-prgt4/replicasets/test-recreate-deployment-79f694ff59,UID:55996384-e376-11e8-a466-0a0beb0244cc,ResourceVersion:14759,Generation:2,CreationTimestamp:2018-11-08 16:50:01 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 79f694ff59,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 1,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-recreate-deployment 5598b5de-e376-11e8-a466-0a0beb0244cc 0xc421ef7d37 0xc421ef7d38}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 79f694ff59,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 79f694ff59,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Nov  8 16:50:03.706: INFO: Pod "test-recreate-deployment-7cf749666b-zmhsh" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-7cf749666b-zmhsh,GenerateName:test-recreate-deployment-7cf749666b-,Namespace:e2e-tests-deployment-prgt4,SelfLink:/api/v1/namespaces/e2e-tests-deployment-prgt4/pods/test-recreate-deployment-7cf749666b-zmhsh,UID:56cf32c7-e376-11e8-a466-0a0beb0244cc,ResourceVersion:14771,Generation:0,CreationTimestamp:2018-11-08 16:50:03 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 7cf749666b,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet test-recreate-deployment-7cf749666b 56cedd10-e376-11e8-a466-0a0beb0244cc 0xc421d86687 0xc421d86688}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-d5zpk {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-d5zpk,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-d5zpk true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-100-224.ec2.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc421d866f0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421d86710}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-11-08 16:50:03 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-11-08 16:50:03 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-11-08 16:50:03 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-11-08 16:50:03 +0000 UTC  }],Message:,Reason:,HostIP:10.0.100.224,PodIP:,StartTime:2018-11-08 16:50:03 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  8 16:50:03.706: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-prgt4" for this suite.
Nov  8 16:50:09.713: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  8 16:50:09.749: INFO: namespace: e2e-tests-deployment-prgt4, resource: bindings, ignored listing per whitelist
Nov  8 16:50:09.766: INFO: namespace e2e-tests-deployment-prgt4 deletion completed in 6.058293436s

• [SLOW TEST:8.154 seconds]
[sig-apps] Deployment
/go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan pods created by rc if delete options say so [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  8 16:50:09.766: INFO: >>> kubeConfig: /tmp/kubeconfig-235977939
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan pods created by rc if delete options say so [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the pods
STEP: Gathering metrics
Nov  8 16:50:49.817: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  8 16:50:49.817: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-8j4tr" for this suite.
Nov  8 16:50:55.824: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  8 16:50:55.858: INFO: namespace: e2e-tests-gc-8j4tr, resource: bindings, ignored listing per whitelist
Nov  8 16:50:55.878: INFO: namespace e2e-tests-gc-8j4tr deletion completed in 6.058701929s

• [SLOW TEST:46.111 seconds]
[sig-api-machinery] Garbage collector
/go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should orphan pods created by rc if delete options say so [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart exec hook properly [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  8 16:50:55.878: INFO: >>> kubeConfig: /tmp/kubeconfig-235977939
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart exec hook properly [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Nov  8 16:50:59.941: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Nov  8 16:50:59.942: INFO: Pod pod-with-poststart-exec-hook still exists
Nov  8 16:51:01.943: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Nov  8 16:51:01.945: INFO: Pod pod-with-poststart-exec-hook still exists
Nov  8 16:51:03.943: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Nov  8 16:51:03.945: INFO: Pod pod-with-poststart-exec-hook still exists
Nov  8 16:51:05.943: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Nov  8 16:51:05.945: INFO: Pod pod-with-poststart-exec-hook still exists
Nov  8 16:51:07.943: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Nov  8 16:51:07.945: INFO: Pod pod-with-poststart-exec-hook still exists
Nov  8 16:51:09.943: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Nov  8 16:51:09.945: INFO: Pod pod-with-poststart-exec-hook still exists
Nov  8 16:51:11.943: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Nov  8 16:51:11.945: INFO: Pod pod-with-poststart-exec-hook still exists
Nov  8 16:51:13.943: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Nov  8 16:51:13.945: INFO: Pod pod-with-poststart-exec-hook still exists
Nov  8 16:51:15.943: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Nov  8 16:51:15.945: INFO: Pod pod-with-poststart-exec-hook still exists
Nov  8 16:51:17.943: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Nov  8 16:51:17.945: INFO: Pod pod-with-poststart-exec-hook still exists
Nov  8 16:51:19.943: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Nov  8 16:51:19.945: INFO: Pod pod-with-poststart-exec-hook still exists
Nov  8 16:51:21.943: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Nov  8 16:51:21.945: INFO: Pod pod-with-poststart-exec-hook still exists
Nov  8 16:51:23.943: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Nov  8 16:51:23.945: INFO: Pod pod-with-poststart-exec-hook still exists
Nov  8 16:51:25.943: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Nov  8 16:51:25.945: INFO: Pod pod-with-poststart-exec-hook still exists
Nov  8 16:51:27.943: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Nov  8 16:51:27.945: INFO: Pod pod-with-poststart-exec-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  8 16:51:27.945: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-lifecycle-hook-jm6zl" for this suite.
Nov  8 16:51:49.953: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  8 16:51:49.967: INFO: namespace: e2e-tests-container-lifecycle-hook-jm6zl, resource: bindings, ignored listing per whitelist
Nov  8 16:51:50.006: INFO: namespace e2e-tests-container-lifecycle-hook-jm6zl deletion completed in 22.058977786s

• [SLOW TEST:54.128 seconds]
[k8s.io] Container Lifecycle Hook
/go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when create a pod with lifecycle hook
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute poststart exec hook properly [NodeConformance] [Conformance]
    /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Projected 
  should update annotations on modification [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  8 16:51:50.006: INFO: >>> kubeConfig: /tmp/kubeconfig-235977939
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should update annotations on modification [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating the pod
Nov  8 16:51:52.568: INFO: Successfully updated pod "annotationupdate9634d84a-e376-11e8-b0fd-0e97e856486a"
[AfterEach] [sig-storage] Projected
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  8 16:51:56.583: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-cg2d4" for this suite.
Nov  8 16:52:18.591: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  8 16:52:18.624: INFO: namespace: e2e-tests-projected-cg2d4, resource: bindings, ignored listing per whitelist
Nov  8 16:52:18.645: INFO: namespace e2e-tests-projected-cg2d4 deletion completed in 22.06017591s

• [SLOW TEST:28.639 seconds]
[sig-storage] Projected
/go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should update annotations on modification [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[k8s.io] Probing container 
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  8 16:52:18.645: INFO: >>> kubeConfig: /tmp/kubeconfig-235977939
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-exec in namespace e2e-tests-container-probe-mxpld
Nov  8 16:52:20.690: INFO: Started pod liveness-exec in namespace e2e-tests-container-probe-mxpld
STEP: checking the pod's current state and verifying that restartCount is present
Nov  8 16:52:20.691: INFO: Initial restart count of pod liveness-exec is 0
Nov  8 16:53:06.742: INFO: Restart count of pod e2e-tests-container-probe-mxpld/liveness-exec is now 1 (46.050171985s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  8 16:53:06.747: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-mxpld" for this suite.
Nov  8 16:53:12.755: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  8 16:53:12.804: INFO: namespace: e2e-tests-container-probe-mxpld, resource: bindings, ignored listing per whitelist
Nov  8 16:53:12.810: INFO: namespace e2e-tests-container-probe-mxpld deletion completed in 6.061033654s

• [SLOW TEST:54.165 seconds]
[k8s.io] Probing container
/go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,default) [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  8 16:53:12.810: INFO: >>> kubeConfig: /tmp/kubeconfig-235977939
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,default) [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0777 on node default medium
Nov  8 16:53:12.853: INFO: Waiting up to 5m0s for pod "pod-c78f45a6-e376-11e8-b0fd-0e97e856486a" in namespace "e2e-tests-emptydir-wmt2d" to be "success or failure"
Nov  8 16:53:12.854: INFO: Pod "pod-c78f45a6-e376-11e8-b0fd-0e97e856486a": Phase="Pending", Reason="", readiness=false. Elapsed: 1.281228ms
Nov  8 16:53:14.856: INFO: Pod "pod-c78f45a6-e376-11e8-b0fd-0e97e856486a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.003051414s
STEP: Saw pod success
Nov  8 16:53:14.856: INFO: Pod "pod-c78f45a6-e376-11e8-b0fd-0e97e856486a" satisfied condition "success or failure"
Nov  8 16:53:14.857: INFO: Trying to get logs from node ip-10-0-100-224.ec2.internal pod pod-c78f45a6-e376-11e8-b0fd-0e97e856486a container test-container: <nil>
STEP: delete the pod
Nov  8 16:53:14.867: INFO: Waiting for pod pod-c78f45a6-e376-11e8-b0fd-0e97e856486a to disappear
Nov  8 16:53:14.868: INFO: Pod pod-c78f45a6-e376-11e8-b0fd-0e97e856486a no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  8 16:53:14.868: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-wmt2d" for this suite.
Nov  8 16:53:20.877: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  8 16:53:20.897: INFO: namespace: e2e-tests-emptydir-wmt2d, resource: bindings, ignored listing per whitelist
Nov  8 16:53:20.930: INFO: namespace e2e-tests-emptydir-wmt2d deletion completed in 6.059490384s

• [SLOW TEST:8.120 seconds]
[sig-storage] EmptyDir volumes
/go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0777,default) [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on tmpfs should have the correct mode [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  8 16:53:20.931: INFO: >>> kubeConfig: /tmp/kubeconfig-235977939
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on tmpfs should have the correct mode [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir volume type on tmpfs
Nov  8 16:53:20.970: INFO: Waiting up to 5m0s for pod "pod-cc65f4e5-e376-11e8-b0fd-0e97e856486a" in namespace "e2e-tests-emptydir-pj4tw" to be "success or failure"
Nov  8 16:53:20.972: INFO: Pod "pod-cc65f4e5-e376-11e8-b0fd-0e97e856486a": Phase="Pending", Reason="", readiness=false. Elapsed: 1.843041ms
Nov  8 16:53:22.974: INFO: Pod "pod-cc65f4e5-e376-11e8-b0fd-0e97e856486a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.003889285s
STEP: Saw pod success
Nov  8 16:53:22.974: INFO: Pod "pod-cc65f4e5-e376-11e8-b0fd-0e97e856486a" satisfied condition "success or failure"
Nov  8 16:53:22.975: INFO: Trying to get logs from node ip-10-0-100-224.ec2.internal pod pod-cc65f4e5-e376-11e8-b0fd-0e97e856486a container test-container: <nil>
STEP: delete the pod
Nov  8 16:53:22.985: INFO: Waiting for pod pod-cc65f4e5-e376-11e8-b0fd-0e97e856486a to disappear
Nov  8 16:53:22.987: INFO: Pod pod-cc65f4e5-e376-11e8-b0fd-0e97e856486a no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  8 16:53:22.987: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-pj4tw" for this suite.
Nov  8 16:53:28.995: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  8 16:53:29.001: INFO: namespace: e2e-tests-emptydir-pj4tw, resource: bindings, ignored listing per whitelist
Nov  8 16:53:29.048: INFO: namespace e2e-tests-emptydir-pj4tw deletion completed in 6.057742199s

• [SLOW TEST:8.118 seconds]
[sig-storage] EmptyDir volumes
/go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  volume on tmpfs should have the correct mode [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Downward API 
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Downward API
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  8 16:53:29.048: INFO: >>> kubeConfig: /tmp/kubeconfig-235977939
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Nov  8 16:53:29.089: INFO: Waiting up to 5m0s for pod "downward-api-d13cc22e-e376-11e8-b0fd-0e97e856486a" in namespace "e2e-tests-downward-api-qrwbx" to be "success or failure"
Nov  8 16:53:29.091: INFO: Pod "downward-api-d13cc22e-e376-11e8-b0fd-0e97e856486a": Phase="Pending", Reason="", readiness=false. Elapsed: 1.489897ms
Nov  8 16:53:31.093: INFO: Pod "downward-api-d13cc22e-e376-11e8-b0fd-0e97e856486a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.003417194s
STEP: Saw pod success
Nov  8 16:53:31.093: INFO: Pod "downward-api-d13cc22e-e376-11e8-b0fd-0e97e856486a" satisfied condition "success or failure"
Nov  8 16:53:31.094: INFO: Trying to get logs from node ip-10-0-100-224.ec2.internal pod downward-api-d13cc22e-e376-11e8-b0fd-0e97e856486a container dapi-container: <nil>
STEP: delete the pod
Nov  8 16:53:31.106: INFO: Waiting for pod downward-api-d13cc22e-e376-11e8-b0fd-0e97e856486a to disappear
Nov  8 16:53:31.107: INFO: Pod downward-api-d13cc22e-e376-11e8-b0fd-0e97e856486a no longer exists
[AfterEach] [sig-api-machinery] Downward API
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  8 16:53:31.107: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-qrwbx" for this suite.
Nov  8 16:53:37.115: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  8 16:53:37.131: INFO: namespace: e2e-tests-downward-api-qrwbx, resource: bindings, ignored listing per whitelist
Nov  8 16:53:37.168: INFO: namespace e2e-tests-downward-api-qrwbx deletion completed in 6.058604469s

• [SLOW TEST:8.120 seconds]
[sig-api-machinery] Downward API
/go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartAlways pod [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  8 16:53:37.168: INFO: >>> kubeConfig: /tmp/kubeconfig-235977939
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should invoke init containers on a RestartAlways pod [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
Nov  8 16:53:37.203: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  8 16:53:40.258: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-init-container-l7v62" for this suite.
Nov  8 16:54:02.266: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  8 16:54:02.301: INFO: namespace: e2e-tests-init-container-l7v62, resource: bindings, ignored listing per whitelist
Nov  8 16:54:02.318: INFO: namespace e2e-tests-init-container-l7v62 deletion completed in 22.05761519s

• [SLOW TEST:25.150 seconds]
[k8s.io] InitContainer [NodeConformance]
/go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should invoke init containers on a RestartAlways pod [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-api-machinery] Secrets 
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Secrets
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  8 16:54:02.318: INFO: >>> kubeConfig: /tmp/kubeconfig-235977939
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in env vars [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-e5118f4f-e376-11e8-b0fd-0e97e856486a
STEP: Creating a pod to test consume secrets
Nov  8 16:54:02.362: INFO: Waiting up to 5m0s for pod "pod-secrets-e511cb14-e376-11e8-b0fd-0e97e856486a" in namespace "e2e-tests-secrets-qt4z8" to be "success or failure"
Nov  8 16:54:02.363: INFO: Pod "pod-secrets-e511cb14-e376-11e8-b0fd-0e97e856486a": Phase="Pending", Reason="", readiness=false. Elapsed: 1.329788ms
Nov  8 16:54:04.365: INFO: Pod "pod-secrets-e511cb14-e376-11e8-b0fd-0e97e856486a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.003251968s
STEP: Saw pod success
Nov  8 16:54:04.365: INFO: Pod "pod-secrets-e511cb14-e376-11e8-b0fd-0e97e856486a" satisfied condition "success or failure"
Nov  8 16:54:04.366: INFO: Trying to get logs from node ip-10-0-100-224.ec2.internal pod pod-secrets-e511cb14-e376-11e8-b0fd-0e97e856486a container secret-env-test: <nil>
STEP: delete the pod
Nov  8 16:54:04.379: INFO: Waiting for pod pod-secrets-e511cb14-e376-11e8-b0fd-0e97e856486a to disappear
Nov  8 16:54:04.380: INFO: Pod pod-secrets-e511cb14-e376-11e8-b0fd-0e97e856486a no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  8 16:54:04.380: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-qt4z8" for this suite.
Nov  8 16:54:10.387: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  8 16:54:10.424: INFO: namespace: e2e-tests-secrets-qt4z8, resource: bindings, ignored listing per whitelist
Nov  8 16:54:10.443: INFO: namespace e2e-tests-secrets-qt4z8 deletion completed in 6.061105089s

• [SLOW TEST:8.125 seconds]
[sig-api-machinery] Secrets
/go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:31
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-apps] Deployment 
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  8 16:54:10.443: INFO: >>> kubeConfig: /tmp/kubeconfig-235977939
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Nov  8 16:54:10.480: INFO: Creating replica set "test-rolling-update-controller" (going to be adopted)
Nov  8 16:54:10.484: INFO: Pod name sample-pod: Found 0 pods out of 1
Nov  8 16:54:15.486: INFO: Pod name sample-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Nov  8 16:54:15.486: INFO: Creating deployment "test-rolling-update-deployment"
Nov  8 16:54:15.488: INFO: Ensuring deployment "test-rolling-update-deployment" gets the next revision from the one the adopted replica set "test-rolling-update-controller" has
Nov  8 16:54:15.492: INFO: new replicaset for deployment "test-rolling-update-deployment" is yet to be created
Nov  8 16:54:17.495: INFO: Ensuring status for deployment "test-rolling-update-deployment" is the expected
Nov  8 16:54:17.496: INFO: Ensuring deployment "test-rolling-update-deployment" has one old replica set (the one it adopted)
[AfterEach] [sig-apps] Deployment
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Nov  8 16:54:17.500: INFO: Deployment "test-rolling-update-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment,GenerateName:,Namespace:e2e-tests-deployment-7rf74,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-7rf74/deployments/test-rolling-update-deployment,UID:ece50df8-e376-11e8-a466-0a0beb0244cc,ResourceVersion:15655,Generation:1,CreationTimestamp:2018-11-08 16:54:15 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,},Annotations:map[string]string{deployment.kubernetes.io/revision: 3546343826724305833,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[{Available True 2018-11-08 16:54:15 +0000 UTC 2018-11-08 16:54:15 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2018-11-08 16:54:16 +0000 UTC 2018-11-08 16:54:15 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-rolling-update-deployment-65b7695dcf" has successfully progressed.}],ReadyReplicas:1,CollisionCount:nil,},}

Nov  8 16:54:17.502: INFO: New ReplicaSet "test-rolling-update-deployment-65b7695dcf" of Deployment "test-rolling-update-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment-65b7695dcf,GenerateName:,Namespace:e2e-tests-deployment-7rf74,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-7rf74/replicasets/test-rolling-update-deployment-65b7695dcf,UID:ece65d26-e376-11e8-a466-0a0beb0244cc,ResourceVersion:15646,Generation:1,CreationTimestamp:2018-11-08 16:54:15 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 65b7695dcf,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 3546343826724305833,},OwnerReferences:[{apps/v1 Deployment test-rolling-update-deployment ece50df8-e376-11e8-a466-0a0beb0244cc 0xc421a912c7 0xc421a912c8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod-template-hash: 65b7695dcf,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 65b7695dcf,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Nov  8 16:54:17.502: INFO: All old ReplicaSets of Deployment "test-rolling-update-deployment":
Nov  8 16:54:17.502: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-controller,GenerateName:,Namespace:e2e-tests-deployment-7rf74,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-7rf74/replicasets/test-rolling-update-controller,UID:e9e9322b-e376-11e8-a466-0a0beb0244cc,ResourceVersion:15654,Generation:2,CreationTimestamp:2018-11-08 16:54:10 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod: nginx,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 3546343826724305832,},OwnerReferences:[{apps/v1 Deployment test-rolling-update-deployment ece50df8-e376-11e8-a466-0a0beb0244cc 0xc421a911ee 0xc421a911ef}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Nov  8 16:54:17.504: INFO: Pod "test-rolling-update-deployment-65b7695dcf-clcjc" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment-65b7695dcf-clcjc,GenerateName:test-rolling-update-deployment-65b7695dcf-,Namespace:e2e-tests-deployment-7rf74,SelfLink:/api/v1/namespaces/e2e-tests-deployment-7rf74/pods/test-rolling-update-deployment-65b7695dcf-clcjc,UID:ece6a99c-e376-11e8-a466-0a0beb0244cc,ResourceVersion:15645,Generation:0,CreationTimestamp:2018-11-08 16:54:15 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 65b7695dcf,},Annotations:map[string]string{cni.projectcalico.org/podIP: 192.168.1.150/32,},OwnerReferences:[{apps/v1 ReplicaSet test-rolling-update-deployment-65b7695dcf ece65d26-e376-11e8-a466-0a0beb0244cc 0xc421a755e7 0xc421a755e8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-bklt9 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-bklt9,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-bklt9 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-100-224.ec2.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc421a75650} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421a75670}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-11-08 16:54:15 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-11-08 16:54:16 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2018-11-08 16:54:16 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-11-08 16:54:15 +0000 UTC  }],Message:,Reason:,HostIP:10.0.100.224,PodIP:192.168.1.150,StartTime:2018-11-08 16:54:15 +0000 UTC,ContainerStatuses:[{redis {nil ContainerStateRunning{StartedAt:2018-11-08 16:54:16 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/redis:1.0 docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830 docker://5978caec972b4d49c0b81ee2a2caf320a06c4140ca96c303b0c11489c23c740a}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  8 16:54:17.504: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-7rf74" for this suite.
Nov  8 16:54:23.512: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  8 16:54:23.559: INFO: namespace: e2e-tests-deployment-7rf74, resource: bindings, ignored listing per whitelist
Nov  8 16:54:23.566: INFO: namespace e2e-tests-deployment-7rf74 deletion completed in 6.060020223s

• [SLOW TEST:13.122 seconds]
[sig-apps] Deployment
/go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: udp [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Networking
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  8 16:54:23.566: INFO: >>> kubeConfig: /tmp/kubeconfig-235977939
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: udp [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-q5hmv
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Nov  8 16:54:23.603: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Nov  8 16:54:41.636: INFO: ExecWithOptions {Command:[/bin/sh -c echo 'hostName' | timeout -t 2 nc -w 1 -u 192.168.1.151 8081 | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-q5hmv PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Nov  8 16:54:41.636: INFO: >>> kubeConfig: /tmp/kubeconfig-235977939
Nov  8 16:54:42.733: INFO: Found all expected endpoints: [netserver-0]
Nov  8 16:54:42.735: INFO: ExecWithOptions {Command:[/bin/sh -c echo 'hostName' | timeout -t 2 nc -w 1 -u 192.168.2.64 8081 | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-q5hmv PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Nov  8 16:54:42.735: INFO: >>> kubeConfig: /tmp/kubeconfig-235977939
Nov  8 16:54:43.789: INFO: Found all expected endpoints: [netserver-1]
[AfterEach] [sig-network] Networking
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  8 16:54:43.790: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-q5hmv" for this suite.
Nov  8 16:55:05.798: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  8 16:55:05.812: INFO: namespace: e2e-tests-pod-network-test-q5hmv, resource: bindings, ignored listing per whitelist
Nov  8 16:55:05.851: INFO: namespace e2e-tests-pod-network-test-q5hmv deletion completed in 22.059496853s

• [SLOW TEST:42.286 seconds]
[sig-network] Networking
/go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: udp [NodeConformance] [Conformance]
    /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,default) [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  8 16:55:05.852: INFO: >>> kubeConfig: /tmp/kubeconfig-235977939
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,default) [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0777 on node default medium
Nov  8 16:55:05.892: INFO: Waiting up to 5m0s for pod "pod-0aefc23b-e377-11e8-b0fd-0e97e856486a" in namespace "e2e-tests-emptydir-gz8hp" to be "success or failure"
Nov  8 16:55:05.894: INFO: Pod "pod-0aefc23b-e377-11e8-b0fd-0e97e856486a": Phase="Pending", Reason="", readiness=false. Elapsed: 1.597377ms
Nov  8 16:55:07.896: INFO: Pod "pod-0aefc23b-e377-11e8-b0fd-0e97e856486a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.003699259s
STEP: Saw pod success
Nov  8 16:55:07.896: INFO: Pod "pod-0aefc23b-e377-11e8-b0fd-0e97e856486a" satisfied condition "success or failure"
Nov  8 16:55:07.897: INFO: Trying to get logs from node ip-10-0-100-224.ec2.internal pod pod-0aefc23b-e377-11e8-b0fd-0e97e856486a container test-container: <nil>
STEP: delete the pod
Nov  8 16:55:07.907: INFO: Waiting for pod pod-0aefc23b-e377-11e8-b0fd-0e97e856486a to disappear
Nov  8 16:55:07.908: INFO: Pod pod-0aefc23b-e377-11e8-b0fd-0e97e856486a no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  8 16:55:07.908: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-gz8hp" for this suite.
Nov  8 16:55:13.915: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  8 16:55:13.945: INFO: namespace: e2e-tests-emptydir-gz8hp, resource: bindings, ignored listing per whitelist
Nov  8 16:55:13.969: INFO: namespace e2e-tests-emptydir-gz8hp deletion completed in 6.058367905s

• [SLOW TEST:8.117 seconds]
[sig-storage] EmptyDir volumes
/go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0777,default) [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected 
  should update labels on modification [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  8 16:55:13.969: INFO: >>> kubeConfig: /tmp/kubeconfig-235977939
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should update labels on modification [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating the pod
Nov  8 16:55:16.521: INFO: Successfully updated pod "labelsupdate0fc6042a-e377-11e8-b0fd-0e97e856486a"
[AfterEach] [sig-storage] Projected
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  8 16:55:20.536: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-w4dsv" for this suite.
Nov  8 16:55:42.544: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  8 16:55:42.574: INFO: namespace: e2e-tests-projected-w4dsv, resource: bindings, ignored listing per whitelist
Nov  8 16:55:42.599: INFO: namespace e2e-tests-projected-w4dsv deletion completed in 22.060795437s

• [SLOW TEST:28.630 seconds]
[sig-storage] Projected
/go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should update labels on modification [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-api-machinery] ConfigMap 
  should be consumable via the environment [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] ConfigMap
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  8 16:55:42.599: INFO: >>> kubeConfig: /tmp/kubeconfig-235977939
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap e2e-tests-configmap-56qjb/configmap-test-20d74020-e377-11e8-b0fd-0e97e856486a
STEP: Creating a pod to test consume configMaps
Nov  8 16:55:42.643: INFO: Waiting up to 5m0s for pod "pod-configmaps-20d77cd2-e377-11e8-b0fd-0e97e856486a" in namespace "e2e-tests-configmap-56qjb" to be "success or failure"
Nov  8 16:55:42.645: INFO: Pod "pod-configmaps-20d77cd2-e377-11e8-b0fd-0e97e856486a": Phase="Pending", Reason="", readiness=false. Elapsed: 1.917596ms
Nov  8 16:55:44.647: INFO: Pod "pod-configmaps-20d77cd2-e377-11e8-b0fd-0e97e856486a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004035466s
STEP: Saw pod success
Nov  8 16:55:44.647: INFO: Pod "pod-configmaps-20d77cd2-e377-11e8-b0fd-0e97e856486a" satisfied condition "success or failure"
Nov  8 16:55:44.648: INFO: Trying to get logs from node ip-10-0-100-224.ec2.internal pod pod-configmaps-20d77cd2-e377-11e8-b0fd-0e97e856486a container env-test: <nil>
STEP: delete the pod
Nov  8 16:55:44.658: INFO: Waiting for pod pod-configmaps-20d77cd2-e377-11e8-b0fd-0e97e856486a to disappear
Nov  8 16:55:44.659: INFO: Pod pod-configmaps-20d77cd2-e377-11e8-b0fd-0e97e856486a no longer exists
[AfterEach] [sig-api-machinery] ConfigMap
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  8 16:55:44.659: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-56qjb" for this suite.
Nov  8 16:55:50.666: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  8 16:55:50.691: INFO: namespace: e2e-tests-configmap-56qjb, resource: bindings, ignored listing per whitelist
Nov  8 16:55:50.726: INFO: namespace e2e-tests-configmap-56qjb deletion completed in 6.064642228s

• [SLOW TEST:8.126 seconds]
[sig-api-machinery] ConfigMap
/go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:30
  should be consumable via the environment [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide podname only [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  8 16:55:50.726: INFO: >>> kubeConfig: /tmp/kubeconfig-235977939
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide podname only [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Nov  8 16:55:50.766: INFO: Waiting up to 5m0s for pod "downwardapi-volume-25aeeeb6-e377-11e8-b0fd-0e97e856486a" in namespace "e2e-tests-downward-api-dvthq" to be "success or failure"
Nov  8 16:55:50.768: INFO: Pod "downwardapi-volume-25aeeeb6-e377-11e8-b0fd-0e97e856486a": Phase="Pending", Reason="", readiness=false. Elapsed: 1.297121ms
Nov  8 16:55:52.770: INFO: Pod "downwardapi-volume-25aeeeb6-e377-11e8-b0fd-0e97e856486a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.003377493s
STEP: Saw pod success
Nov  8 16:55:52.770: INFO: Pod "downwardapi-volume-25aeeeb6-e377-11e8-b0fd-0e97e856486a" satisfied condition "success or failure"
Nov  8 16:55:52.771: INFO: Trying to get logs from node ip-10-0-100-224.ec2.internal pod downwardapi-volume-25aeeeb6-e377-11e8-b0fd-0e97e856486a container client-container: <nil>
STEP: delete the pod
Nov  8 16:55:52.781: INFO: Waiting for pod downwardapi-volume-25aeeeb6-e377-11e8-b0fd-0e97e856486a to disappear
Nov  8 16:55:52.783: INFO: Pod downwardapi-volume-25aeeeb6-e377-11e8-b0fd-0e97e856486a no longer exists
[AfterEach] [sig-storage] Downward API volume
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  8 16:55:52.783: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-dvthq" for this suite.
Nov  8 16:55:58.792: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  8 16:55:58.827: INFO: namespace: e2e-tests-downward-api-dvthq, resource: bindings, ignored listing per whitelist
Nov  8 16:55:58.845: INFO: namespace e2e-tests-downward-api-dvthq deletion completed in 6.060722277s

• [SLOW TEST:8.119 seconds]
[sig-storage] Downward API volume
/go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide podname only [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  8 16:55:58.845: INFO: >>> kubeConfig: /tmp/kubeconfig-235977939
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-map-2a8618bf-e377-11e8-b0fd-0e97e856486a
STEP: Creating a pod to test consume secrets
Nov  8 16:55:58.891: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-2a867f45-e377-11e8-b0fd-0e97e856486a" in namespace "e2e-tests-projected-9zbgh" to be "success or failure"
Nov  8 16:55:58.893: INFO: Pod "pod-projected-secrets-2a867f45-e377-11e8-b0fd-0e97e856486a": Phase="Pending", Reason="", readiness=false. Elapsed: 1.540204ms
Nov  8 16:56:00.895: INFO: Pod "pod-projected-secrets-2a867f45-e377-11e8-b0fd-0e97e856486a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00356365s
STEP: Saw pod success
Nov  8 16:56:00.895: INFO: Pod "pod-projected-secrets-2a867f45-e377-11e8-b0fd-0e97e856486a" satisfied condition "success or failure"
Nov  8 16:56:00.896: INFO: Trying to get logs from node ip-10-0-100-224.ec2.internal pod pod-projected-secrets-2a867f45-e377-11e8-b0fd-0e97e856486a container projected-secret-volume-test: <nil>
STEP: delete the pod
Nov  8 16:56:00.910: INFO: Waiting for pod pod-projected-secrets-2a867f45-e377-11e8-b0fd-0e97e856486a to disappear
Nov  8 16:56:00.912: INFO: Pod pod-projected-secrets-2a867f45-e377-11e8-b0fd-0e97e856486a no longer exists
[AfterEach] [sig-storage] Projected
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  8 16:56:00.913: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-9zbgh" for this suite.
Nov  8 16:56:06.920: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  8 16:56:06.943: INFO: namespace: e2e-tests-projected-9zbgh, resource: bindings, ignored listing per whitelist
Nov  8 16:56:06.973: INFO: namespace e2e-tests-projected-9zbgh deletion completed in 6.058657294s

• [SLOW TEST:8.128 seconds]
[sig-storage] Projected
/go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on default medium should have the correct mode [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  8 16:56:06.973: INFO: >>> kubeConfig: /tmp/kubeconfig-235977939
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on default medium should have the correct mode [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir volume type on node default medium
Nov  8 16:56:07.014: INFO: Waiting up to 5m0s for pod "pod-2f5e1c14-e377-11e8-b0fd-0e97e856486a" in namespace "e2e-tests-emptydir-6pnh5" to be "success or failure"
Nov  8 16:56:07.015: INFO: Pod "pod-2f5e1c14-e377-11e8-b0fd-0e97e856486a": Phase="Pending", Reason="", readiness=false. Elapsed: 1.279986ms
Nov  8 16:56:09.017: INFO: Pod "pod-2f5e1c14-e377-11e8-b0fd-0e97e856486a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.003264308s
STEP: Saw pod success
Nov  8 16:56:09.017: INFO: Pod "pod-2f5e1c14-e377-11e8-b0fd-0e97e856486a" satisfied condition "success or failure"
Nov  8 16:56:09.018: INFO: Trying to get logs from node ip-10-0-100-224.ec2.internal pod pod-2f5e1c14-e377-11e8-b0fd-0e97e856486a container test-container: <nil>
STEP: delete the pod
Nov  8 16:56:09.027: INFO: Waiting for pod pod-2f5e1c14-e377-11e8-b0fd-0e97e856486a to disappear
Nov  8 16:56:09.029: INFO: Pod pod-2f5e1c14-e377-11e8-b0fd-0e97e856486a no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  8 16:56:09.029: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-6pnh5" for this suite.
Nov  8 16:56:15.036: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  8 16:56:15.047: INFO: namespace: e2e-tests-emptydir-6pnh5, resource: bindings, ignored listing per whitelist
Nov  8 16:56:15.089: INFO: namespace e2e-tests-emptydir-6pnh5 deletion completed in 6.05829356s

• [SLOW TEST:8.115 seconds]
[sig-storage] EmptyDir volumes
/go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  volume on default medium should have the correct mode [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-storage] Secrets 
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  8 16:56:15.089: INFO: >>> kubeConfig: /tmp/kubeconfig-235977939
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-34348dd0-e377-11e8-b0fd-0e97e856486a
STEP: Creating a pod to test consume secrets
Nov  8 16:56:15.145: INFO: Waiting up to 5m0s for pod "pod-secrets-3436f023-e377-11e8-b0fd-0e97e856486a" in namespace "e2e-tests-secrets-9476l" to be "success or failure"
Nov  8 16:56:15.147: INFO: Pod "pod-secrets-3436f023-e377-11e8-b0fd-0e97e856486a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.069881ms
Nov  8 16:56:17.149: INFO: Pod "pod-secrets-3436f023-e377-11e8-b0fd-0e97e856486a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004208329s
STEP: Saw pod success
Nov  8 16:56:17.149: INFO: Pod "pod-secrets-3436f023-e377-11e8-b0fd-0e97e856486a" satisfied condition "success or failure"
Nov  8 16:56:17.151: INFO: Trying to get logs from node ip-10-0-100-224.ec2.internal pod pod-secrets-3436f023-e377-11e8-b0fd-0e97e856486a container secret-volume-test: <nil>
STEP: delete the pod
Nov  8 16:56:17.160: INFO: Waiting for pod pod-secrets-3436f023-e377-11e8-b0fd-0e97e856486a to disappear
Nov  8 16:56:17.161: INFO: Pod pod-secrets-3436f023-e377-11e8-b0fd-0e97e856486a no longer exists
[AfterEach] [sig-storage] Secrets
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  8 16:56:17.162: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-9476l" for this suite.
Nov  8 16:56:23.169: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  8 16:56:23.198: INFO: namespace: e2e-tests-secrets-9476l, resource: bindings, ignored listing per whitelist
Nov  8 16:56:23.227: INFO: namespace e2e-tests-secrets-9476l deletion completed in 6.063586681s
STEP: Destroying namespace "e2e-tests-secret-namespace-smbt6" for this suite.
Nov  8 16:56:29.232: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  8 16:56:29.275: INFO: namespace: e2e-tests-secret-namespace-smbt6, resource: bindings, ignored listing per whitelist
Nov  8 16:56:29.284: INFO: namespace e2e-tests-secret-namespace-smbt6 deletion completed in 6.056459597s

• [SLOW TEST:14.195 seconds]
[sig-storage] Secrets
/go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] HostPath 
  should give a volume the correct mode [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] HostPath
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  8 16:56:29.284: INFO: >>> kubeConfig: /tmp/kubeconfig-235977939
STEP: Building a namespace api object, basename hostpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] HostPath
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:37
[It] should give a volume the correct mode [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test hostPath mode
Nov  8 16:56:29.324: INFO: Waiting up to 5m0s for pod "pod-host-path-test" in namespace "e2e-tests-hostpath-jnbvl" to be "success or failure"
Nov  8 16:56:29.326: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 1.676757ms
Nov  8 16:56:31.328: INFO: Pod "pod-host-path-test": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.003736714s
STEP: Saw pod success
Nov  8 16:56:31.328: INFO: Pod "pod-host-path-test" satisfied condition "success or failure"
Nov  8 16:56:31.329: INFO: Trying to get logs from node ip-10-0-100-224.ec2.internal pod pod-host-path-test container test-container-1: <nil>
STEP: delete the pod
Nov  8 16:56:31.339: INFO: Waiting for pod pod-host-path-test to disappear
Nov  8 16:56:31.340: INFO: Pod pod-host-path-test no longer exists
[AfterEach] [sig-storage] HostPath
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  8 16:56:31.340: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-hostpath-jnbvl" for this suite.
Nov  8 16:56:37.349: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  8 16:56:37.356: INFO: namespace: e2e-tests-hostpath-jnbvl, resource: bindings, ignored listing per whitelist
Nov  8 16:56:37.404: INFO: namespace e2e-tests-hostpath-jnbvl deletion completed in 6.060500199s

• [SLOW TEST:8.120 seconds]
[sig-storage] HostPath
/go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:34
  should give a volume the correct mode [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[k8s.io] Pods 
  should contain environment variables for services [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  8 16:56:37.404: INFO: >>> kubeConfig: /tmp/kubeconfig-235977939
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should contain environment variables for services [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Nov  8 16:56:39.468: INFO: Waiting up to 5m0s for pod "client-envvars-42b6387d-e377-11e8-b0fd-0e97e856486a" in namespace "e2e-tests-pods-8678m" to be "success or failure"
Nov  8 16:56:39.471: INFO: Pod "client-envvars-42b6387d-e377-11e8-b0fd-0e97e856486a": Phase="Pending", Reason="", readiness=false. Elapsed: 3.732732ms
Nov  8 16:56:41.473: INFO: Pod "client-envvars-42b6387d-e377-11e8-b0fd-0e97e856486a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005675521s
STEP: Saw pod success
Nov  8 16:56:41.473: INFO: Pod "client-envvars-42b6387d-e377-11e8-b0fd-0e97e856486a" satisfied condition "success or failure"
Nov  8 16:56:41.475: INFO: Trying to get logs from node ip-10-0-100-224.ec2.internal pod client-envvars-42b6387d-e377-11e8-b0fd-0e97e856486a container env3cont: <nil>
STEP: delete the pod
Nov  8 16:56:41.490: INFO: Waiting for pod client-envvars-42b6387d-e377-11e8-b0fd-0e97e856486a to disappear
Nov  8 16:56:41.491: INFO: Pod client-envvars-42b6387d-e377-11e8-b0fd-0e97e856486a no longer exists
[AfterEach] [k8s.io] Pods
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  8 16:56:41.491: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-8678m" for this suite.
Nov  8 16:57:19.499: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  8 16:57:19.541: INFO: namespace: e2e-tests-pods-8678m, resource: bindings, ignored listing per whitelist
Nov  8 16:57:19.552: INFO: namespace e2e-tests-pods-8678m deletion completed in 38.058546169s

• [SLOW TEST:42.148 seconds]
[k8s.io] Pods
/go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should contain environment variables for services [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  8 16:57:19.552: INFO: >>> kubeConfig: /tmp/kubeconfig-235977939
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Nov  8 16:57:19.593: INFO: Waiting up to 5m0s for pod "downwardapi-volume-5aa0de26-e377-11e8-b0fd-0e97e856486a" in namespace "e2e-tests-downward-api-zzkgg" to be "success or failure"
Nov  8 16:57:19.594: INFO: Pod "downwardapi-volume-5aa0de26-e377-11e8-b0fd-0e97e856486a": Phase="Pending", Reason="", readiness=false. Elapsed: 1.507024ms
Nov  8 16:57:21.596: INFO: Pod "downwardapi-volume-5aa0de26-e377-11e8-b0fd-0e97e856486a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.003544818s
STEP: Saw pod success
Nov  8 16:57:21.596: INFO: Pod "downwardapi-volume-5aa0de26-e377-11e8-b0fd-0e97e856486a" satisfied condition "success or failure"
Nov  8 16:57:21.598: INFO: Trying to get logs from node ip-10-0-100-224.ec2.internal pod downwardapi-volume-5aa0de26-e377-11e8-b0fd-0e97e856486a container client-container: <nil>
STEP: delete the pod
Nov  8 16:57:21.607: INFO: Waiting for pod downwardapi-volume-5aa0de26-e377-11e8-b0fd-0e97e856486a to disappear
Nov  8 16:57:21.608: INFO: Pod downwardapi-volume-5aa0de26-e377-11e8-b0fd-0e97e856486a no longer exists
[AfterEach] [sig-storage] Downward API volume
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  8 16:57:21.608: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-zzkgg" for this suite.
Nov  8 16:57:27.615: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  8 16:57:27.661: INFO: namespace: e2e-tests-downward-api-zzkgg, resource: bindings, ignored listing per whitelist
Nov  8 16:57:27.672: INFO: namespace e2e-tests-downward-api-zzkgg deletion completed in 6.0618194s

• [SLOW TEST:8.120 seconds]
[sig-storage] Downward API volume
/go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy through a service and a pod  [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] version v1
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  8 16:57:27.672: INFO: >>> kubeConfig: /tmp/kubeconfig-235977939
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy through a service and a pod  [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: starting an echo server on multiple ports
STEP: creating replication controller proxy-service-wwb8w in namespace e2e-tests-proxy-z9zhh
Nov  8 16:57:39.770: INFO: setup took 12.062220309s, starting test cases
STEP: running 16 cases, 20 attempts per case, 320 total attempts
Nov  8 16:57:39.775: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-z9zhh/pods/http:proxy-service-wwb8w-8zpkb:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-z9zhh/pods/http:proxy-service-wwb8w-8zpkb:1080/proxy/... (200; 4.472057ms)
Nov  8 16:57:39.775: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-z9zhh/pods/proxy-service-wwb8w-8zpkb:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-z9zhh/pods/proxy-service-wwb8w-8zpkb:1080/proxy/rewri... (200; 4.583339ms)
Nov  8 16:57:39.775: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-z9zhh/pods/proxy-service-wwb8w-8zpkb:162/proxy/: bar (200; 4.768388ms)
Nov  8 16:57:39.775: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-z9zhh/pods/proxy-service-wwb8w-8zpkb/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-z9zhh/pods/proxy-service-wwb8w-8zpkb/proxy/rewriteme"... (200; 4.676717ms)
Nov  8 16:57:39.775: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-z9zhh/pods/proxy-service-wwb8w-8zpkb:160/proxy/: foo (200; 5.04597ms)
Nov  8 16:57:39.775: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-z9zhh/pods/http:proxy-service-wwb8w-8zpkb:162/proxy/: bar (200; 5.013689ms)
Nov  8 16:57:39.775: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-z9zhh/pods/http:proxy-service-wwb8w-8zpkb:160/proxy/: foo (200; 5.294932ms)
Nov  8 16:57:39.779: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-z9zhh/services/proxy-service-wwb8w:portname1/proxy/: foo (200; 9.158634ms)
Nov  8 16:57:39.779: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-z9zhh/services/http:proxy-service-wwb8w:portname1/proxy/: foo (200; 9.157911ms)
Nov  8 16:57:39.779: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-z9zhh/services/proxy-service-wwb8w:portname2/proxy/: bar (200; 9.32443ms)
Nov  8 16:57:39.780: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-z9zhh/pods/https:proxy-service-wwb8w-8zpkb:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-z9zhh/pods/https:proxy-service-wwb8w-8zpkb:443/proxy/... (200; 9.97527ms)
Nov  8 16:57:39.780: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-z9zhh/pods/https:proxy-service-wwb8w-8zpkb:462/proxy/: tls qux (200; 9.969126ms)
Nov  8 16:57:39.780: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-z9zhh/services/http:proxy-service-wwb8w:portname2/proxy/: bar (200; 10.137609ms)
Nov  8 16:57:39.782: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-z9zhh/services/https:proxy-service-wwb8w:tlsportname1/proxy/: tls baz (200; 11.795285ms)
Nov  8 16:57:39.783: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-z9zhh/pods/https:proxy-service-wwb8w-8zpkb:460/proxy/: tls baz (200; 12.814104ms)
Nov  8 16:57:39.783: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-z9zhh/services/https:proxy-service-wwb8w:tlsportname2/proxy/: tls qux (200; 13.522932ms)
Nov  8 16:57:39.787: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-z9zhh/pods/http:proxy-service-wwb8w-8zpkb:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-z9zhh/pods/http:proxy-service-wwb8w-8zpkb:1080/proxy/... (200; 3.298433ms)
Nov  8 16:57:39.787: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-z9zhh/pods/proxy-service-wwb8w-8zpkb:160/proxy/: foo (200; 3.127555ms)
Nov  8 16:57:39.787: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-z9zhh/pods/proxy-service-wwb8w-8zpkb:162/proxy/: bar (200; 3.223696ms)
Nov  8 16:57:39.787: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-z9zhh/pods/http:proxy-service-wwb8w-8zpkb:160/proxy/: foo (200; 2.936855ms)
Nov  8 16:57:39.787: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-z9zhh/pods/http:proxy-service-wwb8w-8zpkb:162/proxy/: bar (200; 3.230551ms)
Nov  8 16:57:39.787: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-z9zhh/pods/proxy-service-wwb8w-8zpkb/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-z9zhh/pods/proxy-service-wwb8w-8zpkb/proxy/rewriteme"... (200; 3.573195ms)
Nov  8 16:57:39.788: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-z9zhh/services/https:proxy-service-wwb8w:tlsportname2/proxy/: tls qux (200; 4.384846ms)
Nov  8 16:57:39.788: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-z9zhh/services/https:proxy-service-wwb8w:tlsportname1/proxy/: tls baz (200; 4.1631ms)
Nov  8 16:57:39.788: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-z9zhh/services/http:proxy-service-wwb8w:portname2/proxy/: bar (200; 4.646999ms)
Nov  8 16:57:39.788: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-z9zhh/services/http:proxy-service-wwb8w:portname1/proxy/: foo (200; 4.220386ms)
Nov  8 16:57:39.788: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-z9zhh/pods/https:proxy-service-wwb8w-8zpkb:460/proxy/: tls baz (200; 4.390784ms)
Nov  8 16:57:39.788: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-z9zhh/services/proxy-service-wwb8w:portname1/proxy/: foo (200; 4.274451ms)
Nov  8 16:57:39.788: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-z9zhh/pods/proxy-service-wwb8w-8zpkb:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-z9zhh/pods/proxy-service-wwb8w-8zpkb:1080/proxy/rewri... (200; 4.111099ms)
Nov  8 16:57:39.788: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-z9zhh/pods/https:proxy-service-wwb8w-8zpkb:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-z9zhh/pods/https:proxy-service-wwb8w-8zpkb:443/proxy/... (200; 4.222144ms)
Nov  8 16:57:39.788: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-z9zhh/pods/https:proxy-service-wwb8w-8zpkb:462/proxy/: tls qux (200; 4.490455ms)
Nov  8 16:57:39.788: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-z9zhh/services/proxy-service-wwb8w:portname2/proxy/: bar (200; 4.224283ms)
Nov  8 16:57:39.791: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-z9zhh/pods/proxy-service-wwb8w-8zpkb:160/proxy/: foo (200; 2.115528ms)
Nov  8 16:57:39.792: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-z9zhh/pods/proxy-service-wwb8w-8zpkb:162/proxy/: bar (200; 2.657167ms)
Nov  8 16:57:39.792: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-z9zhh/pods/https:proxy-service-wwb8w-8zpkb:460/proxy/: tls baz (200; 3.378122ms)
Nov  8 16:57:39.792: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-z9zhh/pods/http:proxy-service-wwb8w-8zpkb:160/proxy/: foo (200; 3.216199ms)
Nov  8 16:57:39.792: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-z9zhh/pods/https:proxy-service-wwb8w-8zpkb:462/proxy/: tls qux (200; 3.372556ms)
Nov  8 16:57:39.792: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-z9zhh/pods/proxy-service-wwb8w-8zpkb/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-z9zhh/pods/proxy-service-wwb8w-8zpkb/proxy/rewriteme"... (200; 3.489663ms)
Nov  8 16:57:39.793: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-z9zhh/services/proxy-service-wwb8w:portname2/proxy/: bar (200; 4.161846ms)
Nov  8 16:57:39.794: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-z9zhh/services/http:proxy-service-wwb8w:portname1/proxy/: foo (200; 5.001844ms)
Nov  8 16:57:39.794: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-z9zhh/services/https:proxy-service-wwb8w:tlsportname1/proxy/: tls baz (200; 5.315373ms)
Nov  8 16:57:39.794: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-z9zhh/pods/proxy-service-wwb8w-8zpkb:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-z9zhh/pods/proxy-service-wwb8w-8zpkb:1080/proxy/rewri... (200; 5.100131ms)
Nov  8 16:57:39.794: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-z9zhh/pods/http:proxy-service-wwb8w-8zpkb:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-z9zhh/pods/http:proxy-service-wwb8w-8zpkb:1080/proxy/... (200; 5.397438ms)
Nov  8 16:57:39.794: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-z9zhh/services/https:proxy-service-wwb8w:tlsportname2/proxy/: tls qux (200; 5.809238ms)
Nov  8 16:57:39.794: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-z9zhh/services/http:proxy-service-wwb8w:portname2/proxy/: bar (200; 5.357055ms)
Nov  8 16:57:39.794: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-z9zhh/pods/http:proxy-service-wwb8w-8zpkb:162/proxy/: bar (200; 5.532119ms)
Nov  8 16:57:39.795: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-z9zhh/services/proxy-service-wwb8w:portname1/proxy/: foo (200; 5.771022ms)
Nov  8 16:57:39.795: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-z9zhh/pods/https:proxy-service-wwb8w-8zpkb:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-z9zhh/pods/https:proxy-service-wwb8w-8zpkb:443/proxy/... (200; 5.81378ms)
Nov  8 16:57:39.798: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-z9zhh/pods/proxy-service-wwb8w-8zpkb:162/proxy/: bar (200; 3.368114ms)
Nov  8 16:57:39.799: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-z9zhh/pods/proxy-service-wwb8w-8zpkb:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-z9zhh/pods/proxy-service-wwb8w-8zpkb:1080/proxy/rewri... (200; 3.613162ms)
Nov  8 16:57:39.799: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-z9zhh/pods/proxy-service-wwb8w-8zpkb:160/proxy/: foo (200; 3.86248ms)
Nov  8 16:57:39.799: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-z9zhh/pods/proxy-service-wwb8w-8zpkb/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-z9zhh/pods/proxy-service-wwb8w-8zpkb/proxy/rewriteme"... (200; 4.672805ms)
Nov  8 16:57:39.800: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-z9zhh/services/https:proxy-service-wwb8w:tlsportname2/proxy/: tls qux (200; 4.528358ms)
Nov  8 16:57:39.800: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-z9zhh/pods/https:proxy-service-wwb8w-8zpkb:460/proxy/: tls baz (200; 4.76801ms)
Nov  8 16:57:39.800: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-z9zhh/pods/http:proxy-service-wwb8w-8zpkb:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-z9zhh/pods/http:proxy-service-wwb8w-8zpkb:1080/proxy/... (200; 4.769405ms)
Nov  8 16:57:39.800: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-z9zhh/pods/http:proxy-service-wwb8w-8zpkb:160/proxy/: foo (200; 4.835034ms)
Nov  8 16:57:39.800: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-z9zhh/services/https:proxy-service-wwb8w:tlsportname1/proxy/: tls baz (200; 5.036085ms)
Nov  8 16:57:39.800: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-z9zhh/services/proxy-service-wwb8w:portname2/proxy/: bar (200; 5.214335ms)
Nov  8 16:57:39.800: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-z9zhh/pods/https:proxy-service-wwb8w-8zpkb:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-z9zhh/pods/https:proxy-service-wwb8w-8zpkb:443/proxy/... (200; 5.40494ms)
Nov  8 16:57:39.800: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-z9zhh/services/proxy-service-wwb8w:portname1/proxy/: foo (200; 5.497497ms)
Nov  8 16:57:39.800: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-z9zhh/pods/https:proxy-service-wwb8w-8zpkb:462/proxy/: tls qux (200; 5.60337ms)
Nov  8 16:57:39.800: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-z9zhh/services/http:proxy-service-wwb8w:portname1/proxy/: foo (200; 5.521221ms)
Nov  8 16:57:39.800: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-z9zhh/pods/http:proxy-service-wwb8w-8zpkb:162/proxy/: bar (200; 5.476997ms)
Nov  8 16:57:39.801: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-z9zhh/services/http:proxy-service-wwb8w:portname2/proxy/: bar (200; 5.682766ms)
Nov  8 16:57:39.804: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-z9zhh/pods/proxy-service-wwb8w-8zpkb:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-z9zhh/pods/proxy-service-wwb8w-8zpkb:1080/proxy/rewri... (200; 2.947828ms)
Nov  8 16:57:39.804: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-z9zhh/pods/proxy-service-wwb8w-8zpkb:162/proxy/: bar (200; 3.468338ms)
Nov  8 16:57:39.804: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-z9zhh/pods/https:proxy-service-wwb8w-8zpkb:460/proxy/: tls baz (200; 3.401104ms)
Nov  8 16:57:39.804: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-z9zhh/pods/proxy-service-wwb8w-8zpkb/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-z9zhh/pods/proxy-service-wwb8w-8zpkb/proxy/rewriteme"... (200; 3.73159ms)
Nov  8 16:57:39.804: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-z9zhh/pods/http:proxy-service-wwb8w-8zpkb:162/proxy/: bar (200; 3.441522ms)
Nov  8 16:57:39.804: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-z9zhh/pods/https:proxy-service-wwb8w-8zpkb:462/proxy/: tls qux (200; 3.649936ms)
Nov  8 16:57:39.805: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-z9zhh/pods/https:proxy-service-wwb8w-8zpkb:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-z9zhh/pods/https:proxy-service-wwb8w-8zpkb:443/proxy/... (200; 3.924725ms)
Nov  8 16:57:39.805: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-z9zhh/pods/http:proxy-service-wwb8w-8zpkb:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-z9zhh/pods/http:proxy-service-wwb8w-8zpkb:1080/proxy/... (200; 4.249915ms)
Nov  8 16:57:39.805: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-z9zhh/pods/http:proxy-service-wwb8w-8zpkb:160/proxy/: foo (200; 4.265013ms)
Nov  8 16:57:39.805: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-z9zhh/services/proxy-service-wwb8w:portname2/proxy/: bar (200; 4.476858ms)
Nov  8 16:57:39.805: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-z9zhh/pods/proxy-service-wwb8w-8zpkb:160/proxy/: foo (200; 4.269697ms)
Nov  8 16:57:39.805: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-z9zhh/services/http:proxy-service-wwb8w:portname2/proxy/: bar (200; 4.346004ms)
Nov  8 16:57:39.805: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-z9zhh/services/proxy-service-wwb8w:portname1/proxy/: foo (200; 4.776851ms)
Nov  8 16:57:39.806: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-z9zhh/services/https:proxy-service-wwb8w:tlsportname2/proxy/: tls qux (200; 5.073896ms)
Nov  8 16:57:39.806: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-z9zhh/services/https:proxy-service-wwb8w:tlsportname1/proxy/: tls baz (200; 4.921715ms)
Nov  8 16:57:39.806: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-z9zhh/services/http:proxy-service-wwb8w:portname1/proxy/: foo (200; 4.990345ms)
Nov  8 16:57:39.809: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-z9zhh/pods/http:proxy-service-wwb8w-8zpkb:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-z9zhh/pods/http:proxy-service-wwb8w-8zpkb:1080/proxy/... (200; 3.464604ms)
Nov  8 16:57:39.810: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-z9zhh/pods/https:proxy-service-wwb8w-8zpkb:460/proxy/: tls baz (200; 3.718697ms)
Nov  8 16:57:39.810: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-z9zhh/pods/https:proxy-service-wwb8w-8zpkb:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-z9zhh/pods/https:proxy-service-wwb8w-8zpkb:443/proxy/... (200; 3.818968ms)
Nov  8 16:57:39.810: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-z9zhh/pods/proxy-service-wwb8w-8zpkb:160/proxy/: foo (200; 3.719445ms)
Nov  8 16:57:39.810: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-z9zhh/pods/https:proxy-service-wwb8w-8zpkb:462/proxy/: tls qux (200; 3.738713ms)
Nov  8 16:57:39.811: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-z9zhh/pods/proxy-service-wwb8w-8zpkb:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-z9zhh/pods/proxy-service-wwb8w-8zpkb:1080/proxy/rewri... (200; 5.385015ms)
Nov  8 16:57:39.811: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-z9zhh/pods/proxy-service-wwb8w-8zpkb/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-z9zhh/pods/proxy-service-wwb8w-8zpkb/proxy/rewriteme"... (200; 5.379087ms)
Nov  8 16:57:39.811: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-z9zhh/services/https:proxy-service-wwb8w:tlsportname1/proxy/: tls baz (200; 5.687726ms)
Nov  8 16:57:39.812: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-z9zhh/pods/proxy-service-wwb8w-8zpkb:162/proxy/: bar (200; 5.716979ms)
Nov  8 16:57:39.812: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-z9zhh/pods/http:proxy-service-wwb8w-8zpkb:160/proxy/: foo (200; 5.732548ms)
Nov  8 16:57:39.812: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-z9zhh/pods/http:proxy-service-wwb8w-8zpkb:162/proxy/: bar (200; 5.778882ms)
Nov  8 16:57:39.812: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-z9zhh/services/https:proxy-service-wwb8w:tlsportname2/proxy/: tls qux (200; 5.957913ms)
Nov  8 16:57:39.812: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-z9zhh/services/http:proxy-service-wwb8w:portname1/proxy/: foo (200; 6.0589ms)
Nov  8 16:57:39.812: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-z9zhh/services/proxy-service-wwb8w:portname1/proxy/: foo (200; 6.150346ms)
Nov  8 16:57:39.812: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-z9zhh/services/http:proxy-service-wwb8w:portname2/proxy/: bar (200; 6.304869ms)
Nov  8 16:57:39.812: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-z9zhh/services/proxy-service-wwb8w:portname2/proxy/: bar (200; 6.163947ms)
Nov  8 16:57:39.815: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-z9zhh/pods/https:proxy-service-wwb8w-8zpkb:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-z9zhh/pods/https:proxy-service-wwb8w-8zpkb:443/proxy/... (200; 3.235934ms)
Nov  8 16:57:39.816: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-z9zhh/pods/proxy-service-wwb8w-8zpkb/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-z9zhh/pods/proxy-service-wwb8w-8zpkb/proxy/rewriteme"... (200; 3.969499ms)
Nov  8 16:57:39.816: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-z9zhh/pods/http:proxy-service-wwb8w-8zpkb:160/proxy/: foo (200; 3.647596ms)
Nov  8 16:57:39.817: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-z9zhh/pods/http:proxy-service-wwb8w-8zpkb:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-z9zhh/pods/http:proxy-service-wwb8w-8zpkb:1080/proxy/... (200; 3.720091ms)
Nov  8 16:57:39.817: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-z9zhh/pods/http:proxy-service-wwb8w-8zpkb:162/proxy/: bar (200; 3.679189ms)
Nov  8 16:57:39.817: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-z9zhh/pods/proxy-service-wwb8w-8zpkb:160/proxy/: foo (200; 4.24241ms)
Nov  8 16:57:39.817: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-z9zhh/pods/proxy-service-wwb8w-8zpkb:162/proxy/: bar (200; 4.217752ms)
Nov  8 16:57:39.817: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-z9zhh/pods/https:proxy-service-wwb8w-8zpkb:462/proxy/: tls qux (200; 4.022981ms)
Nov  8 16:57:39.817: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-z9zhh/pods/https:proxy-service-wwb8w-8zpkb:460/proxy/: tls baz (200; 4.116241ms)
Nov  8 16:57:39.817: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-z9zhh/pods/proxy-service-wwb8w-8zpkb:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-z9zhh/pods/proxy-service-wwb8w-8zpkb:1080/proxy/rewri... (200; 4.013238ms)
Nov  8 16:57:39.818: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-z9zhh/services/proxy-service-wwb8w:portname1/proxy/: foo (200; 5.891647ms)
Nov  8 16:57:39.818: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-z9zhh/services/https:proxy-service-wwb8w:tlsportname1/proxy/: tls baz (200; 5.805177ms)
Nov  8 16:57:39.818: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-z9zhh/services/http:proxy-service-wwb8w:portname1/proxy/: foo (200; 5.86531ms)
Nov  8 16:57:39.818: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-z9zhh/services/https:proxy-service-wwb8w:tlsportname2/proxy/: tls qux (200; 6.002583ms)
Nov  8 16:57:39.818: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-z9zhh/services/proxy-service-wwb8w:portname2/proxy/: bar (200; 5.720856ms)
Nov  8 16:57:39.818: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-z9zhh/services/http:proxy-service-wwb8w:portname2/proxy/: bar (200; 6.2123ms)
Nov  8 16:57:39.822: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-z9zhh/pods/proxy-service-wwb8w-8zpkb:162/proxy/: bar (200; 3.345073ms)
Nov  8 16:57:39.822: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-z9zhh/pods/https:proxy-service-wwb8w-8zpkb:462/proxy/: tls qux (200; 3.42312ms)
Nov  8 16:57:39.822: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-z9zhh/pods/proxy-service-wwb8w-8zpkb/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-z9zhh/pods/proxy-service-wwb8w-8zpkb/proxy/rewriteme"... (200; 3.857379ms)
Nov  8 16:57:39.823: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-z9zhh/pods/proxy-service-wwb8w-8zpkb:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-z9zhh/pods/proxy-service-wwb8w-8zpkb:1080/proxy/rewri... (200; 4.135029ms)
Nov  8 16:57:39.823: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-z9zhh/services/https:proxy-service-wwb8w:tlsportname2/proxy/: tls qux (200; 4.041905ms)
Nov  8 16:57:39.823: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-z9zhh/pods/https:proxy-service-wwb8w-8zpkb:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-z9zhh/pods/https:proxy-service-wwb8w-8zpkb:443/proxy/... (200; 3.952423ms)
Nov  8 16:57:39.823: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-z9zhh/pods/https:proxy-service-wwb8w-8zpkb:460/proxy/: tls baz (200; 4.099163ms)
Nov  8 16:57:39.823: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-z9zhh/services/http:proxy-service-wwb8w:portname2/proxy/: bar (200; 4.2695ms)
Nov  8 16:57:39.823: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-z9zhh/services/proxy-service-wwb8w:portname1/proxy/: foo (200; 4.178607ms)
Nov  8 16:57:39.823: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-z9zhh/pods/proxy-service-wwb8w-8zpkb:160/proxy/: foo (200; 4.604413ms)
Nov  8 16:57:39.823: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-z9zhh/pods/http:proxy-service-wwb8w-8zpkb:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-z9zhh/pods/http:proxy-service-wwb8w-8zpkb:1080/proxy/... (200; 4.645846ms)
Nov  8 16:57:39.823: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-z9zhh/pods/http:proxy-service-wwb8w-8zpkb:162/proxy/: bar (200; 4.785576ms)
Nov  8 16:57:39.823: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-z9zhh/pods/http:proxy-service-wwb8w-8zpkb:160/proxy/: foo (200; 4.728227ms)
Nov  8 16:57:39.824: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-z9zhh/services/http:proxy-service-wwb8w:portname1/proxy/: foo (200; 4.940568ms)
Nov  8 16:57:39.824: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-z9zhh/services/proxy-service-wwb8w:portname2/proxy/: bar (200; 5.104158ms)
Nov  8 16:57:39.824: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-z9zhh/services/https:proxy-service-wwb8w:tlsportname1/proxy/: tls baz (200; 4.92555ms)
Nov  8 16:57:39.826: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-z9zhh/pods/http:proxy-service-wwb8w-8zpkb:160/proxy/: foo (200; 2.34734ms)
Nov  8 16:57:39.827: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-z9zhh/services/http:proxy-service-wwb8w:portname1/proxy/: foo (200; 3.714999ms)
Nov  8 16:57:39.827: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-z9zhh/pods/proxy-service-wwb8w-8zpkb:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-z9zhh/pods/proxy-service-wwb8w-8zpkb:1080/proxy/rewri... (200; 3.431165ms)
Nov  8 16:57:39.828: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-z9zhh/pods/http:proxy-service-wwb8w-8zpkb:162/proxy/: bar (200; 3.738757ms)
Nov  8 16:57:39.828: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-z9zhh/pods/proxy-service-wwb8w-8zpkb:160/proxy/: foo (200; 3.509713ms)
Nov  8 16:57:39.828: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-z9zhh/pods/https:proxy-service-wwb8w-8zpkb:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-z9zhh/pods/https:proxy-service-wwb8w-8zpkb:443/proxy/... (200; 3.9701ms)
Nov  8 16:57:39.828: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-z9zhh/pods/proxy-service-wwb8w-8zpkb:162/proxy/: bar (200; 3.799025ms)
Nov  8 16:57:39.828: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-z9zhh/pods/proxy-service-wwb8w-8zpkb/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-z9zhh/pods/proxy-service-wwb8w-8zpkb/proxy/rewriteme"... (200; 3.745213ms)
Nov  8 16:57:39.828: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-z9zhh/services/http:proxy-service-wwb8w:portname2/proxy/: bar (200; 4.36136ms)
Nov  8 16:57:39.829: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-z9zhh/pods/https:proxy-service-wwb8w-8zpkb:460/proxy/: tls baz (200; 4.324913ms)
Nov  8 16:57:39.829: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-z9zhh/services/proxy-service-wwb8w:portname2/proxy/: bar (200; 4.814679ms)
Nov  8 16:57:39.829: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-z9zhh/services/https:proxy-service-wwb8w:tlsportname1/proxy/: tls baz (200; 4.471583ms)
Nov  8 16:57:39.829: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-z9zhh/pods/http:proxy-service-wwb8w-8zpkb:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-z9zhh/pods/http:proxy-service-wwb8w-8zpkb:1080/proxy/... (200; 5.08291ms)
Nov  8 16:57:39.829: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-z9zhh/services/https:proxy-service-wwb8w:tlsportname2/proxy/: tls qux (200; 4.71902ms)
Nov  8 16:57:39.829: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-z9zhh/pods/https:proxy-service-wwb8w-8zpkb:462/proxy/: tls qux (200; 4.532845ms)
Nov  8 16:57:39.830: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-z9zhh/services/proxy-service-wwb8w:portname1/proxy/: foo (200; 5.151516ms)
Nov  8 16:57:39.832: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-z9zhh/pods/https:proxy-service-wwb8w-8zpkb:460/proxy/: tls baz (200; 2.71147ms)
Nov  8 16:57:39.833: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-z9zhh/pods/http:proxy-service-wwb8w-8zpkb:160/proxy/: foo (200; 2.680441ms)
Nov  8 16:57:39.834: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-z9zhh/services/http:proxy-service-wwb8w:portname2/proxy/: bar (200; 4.535925ms)
Nov  8 16:57:39.835: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-z9zhh/pods/https:proxy-service-wwb8w-8zpkb:462/proxy/: tls qux (200; 4.754981ms)
Nov  8 16:57:39.835: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-z9zhh/pods/http:proxy-service-wwb8w-8zpkb:162/proxy/: bar (200; 4.660003ms)
Nov  8 16:57:39.835: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-z9zhh/pods/proxy-service-wwb8w-8zpkb:160/proxy/: foo (200; 4.829229ms)
Nov  8 16:57:39.835: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-z9zhh/pods/http:proxy-service-wwb8w-8zpkb:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-z9zhh/pods/http:proxy-service-wwb8w-8zpkb:1080/proxy/... (200; 4.746478ms)
Nov  8 16:57:39.835: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-z9zhh/pods/proxy-service-wwb8w-8zpkb:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-z9zhh/pods/proxy-service-wwb8w-8zpkb:1080/proxy/rewri... (200; 4.734544ms)
Nov  8 16:57:39.835: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-z9zhh/services/http:proxy-service-wwb8w:portname1/proxy/: foo (200; 4.989729ms)
Nov  8 16:57:39.835: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-z9zhh/pods/proxy-service-wwb8w-8zpkb:162/proxy/: bar (200; 4.742838ms)
Nov  8 16:57:39.835: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-z9zhh/pods/https:proxy-service-wwb8w-8zpkb:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-z9zhh/pods/https:proxy-service-wwb8w-8zpkb:443/proxy/... (200; 4.883183ms)
Nov  8 16:57:39.835: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-z9zhh/pods/proxy-service-wwb8w-8zpkb/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-z9zhh/pods/proxy-service-wwb8w-8zpkb/proxy/rewriteme"... (200; 4.925124ms)
Nov  8 16:57:39.835: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-z9zhh/services/proxy-service-wwb8w:portname1/proxy/: foo (200; 5.127335ms)
Nov  8 16:57:39.835: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-z9zhh/services/proxy-service-wwb8w:portname2/proxy/: bar (200; 5.369154ms)
Nov  8 16:57:39.835: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-z9zhh/services/https:proxy-service-wwb8w:tlsportname2/proxy/: tls qux (200; 5.543148ms)
Nov  8 16:57:39.836: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-z9zhh/services/https:proxy-service-wwb8w:tlsportname1/proxy/: tls baz (200; 6.572761ms)
Nov  8 16:57:39.839: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-z9zhh/pods/https:proxy-service-wwb8w-8zpkb:460/proxy/: tls baz (200; 2.233403ms)
Nov  8 16:57:39.839: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-z9zhh/pods/https:proxy-service-wwb8w-8zpkb:462/proxy/: tls qux (200; 2.30553ms)
Nov  8 16:57:39.840: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-z9zhh/pods/proxy-service-wwb8w-8zpkb:160/proxy/: foo (200; 2.947405ms)
Nov  8 16:57:39.840: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-z9zhh/pods/http:proxy-service-wwb8w-8zpkb:162/proxy/: bar (200; 3.061159ms)
Nov  8 16:57:39.840: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-z9zhh/pods/proxy-service-wwb8w-8zpkb:162/proxy/: bar (200; 2.93773ms)
Nov  8 16:57:39.840: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-z9zhh/pods/https:proxy-service-wwb8w-8zpkb:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-z9zhh/pods/https:proxy-service-wwb8w-8zpkb:443/proxy/... (200; 3.051676ms)
Nov  8 16:57:39.841: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-z9zhh/services/https:proxy-service-wwb8w:tlsportname2/proxy/: tls qux (200; 5.111016ms)
Nov  8 16:57:39.842: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-z9zhh/pods/proxy-service-wwb8w-8zpkb/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-z9zhh/pods/proxy-service-wwb8w-8zpkb/proxy/rewriteme"... (200; 4.479531ms)
Nov  8 16:57:39.842: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-z9zhh/pods/http:proxy-service-wwb8w-8zpkb:160/proxy/: foo (200; 4.769156ms)
Nov  8 16:57:39.842: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-z9zhh/pods/proxy-service-wwb8w-8zpkb:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-z9zhh/pods/proxy-service-wwb8w-8zpkb:1080/proxy/rewri... (200; 4.865431ms)
Nov  8 16:57:39.842: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-z9zhh/services/http:proxy-service-wwb8w:portname1/proxy/: foo (200; 5.114331ms)
Nov  8 16:57:39.842: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-z9zhh/pods/http:proxy-service-wwb8w-8zpkb:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-z9zhh/pods/http:proxy-service-wwb8w-8zpkb:1080/proxy/... (200; 5.500069ms)
Nov  8 16:57:39.843: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-z9zhh/services/proxy-service-wwb8w:portname1/proxy/: foo (200; 6.470719ms)
Nov  8 16:57:39.843: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-z9zhh/services/proxy-service-wwb8w:portname2/proxy/: bar (200; 6.289284ms)
Nov  8 16:57:39.843: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-z9zhh/services/https:proxy-service-wwb8w:tlsportname1/proxy/: tls baz (200; 6.681236ms)
Nov  8 16:57:39.843: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-z9zhh/services/http:proxy-service-wwb8w:portname2/proxy/: bar (200; 6.211564ms)
Nov  8 16:57:39.853: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-z9zhh/pods/http:proxy-service-wwb8w-8zpkb:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-z9zhh/pods/http:proxy-service-wwb8w-8zpkb:1080/proxy/... (200; 9.602089ms)
Nov  8 16:57:39.854: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-z9zhh/services/https:proxy-service-wwb8w:tlsportname2/proxy/: tls qux (200; 10.793173ms)
Nov  8 16:57:39.855: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-z9zhh/services/http:proxy-service-wwb8w:portname2/proxy/: bar (200; 11.10977ms)
Nov  8 16:57:39.855: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-z9zhh/services/proxy-service-wwb8w:portname1/proxy/: foo (200; 11.245421ms)
Nov  8 16:57:39.855: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-z9zhh/services/http:proxy-service-wwb8w:portname1/proxy/: foo (200; 11.275254ms)
Nov  8 16:57:39.855: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-z9zhh/pods/https:proxy-service-wwb8w-8zpkb:460/proxy/: tls baz (200; 11.013968ms)
Nov  8 16:57:39.855: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-z9zhh/pods/proxy-service-wwb8w-8zpkb:162/proxy/: bar (200; 11.633635ms)
Nov  8 16:57:39.855: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-z9zhh/services/https:proxy-service-wwb8w:tlsportname1/proxy/: tls baz (200; 11.494496ms)
Nov  8 16:57:39.855: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-z9zhh/pods/proxy-service-wwb8w-8zpkb:160/proxy/: foo (200; 11.664563ms)
Nov  8 16:57:39.855: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-z9zhh/pods/http:proxy-service-wwb8w-8zpkb:162/proxy/: bar (200; 11.635468ms)
Nov  8 16:57:39.855: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-z9zhh/pods/http:proxy-service-wwb8w-8zpkb:160/proxy/: foo (200; 11.745203ms)
Nov  8 16:57:39.855: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-z9zhh/services/proxy-service-wwb8w:portname2/proxy/: bar (200; 11.699796ms)
Nov  8 16:57:39.855: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-z9zhh/pods/proxy-service-wwb8w-8zpkb/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-z9zhh/pods/proxy-service-wwb8w-8zpkb/proxy/rewriteme"... (200; 11.705965ms)
Nov  8 16:57:39.855: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-z9zhh/pods/proxy-service-wwb8w-8zpkb:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-z9zhh/pods/proxy-service-wwb8w-8zpkb:1080/proxy/rewri... (200; 11.836814ms)
Nov  8 16:57:39.856: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-z9zhh/pods/https:proxy-service-wwb8w-8zpkb:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-z9zhh/pods/https:proxy-service-wwb8w-8zpkb:443/proxy/... (200; 11.972627ms)
Nov  8 16:57:39.856: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-z9zhh/pods/https:proxy-service-wwb8w-8zpkb:462/proxy/: tls qux (200; 12.283332ms)
Nov  8 16:57:39.859: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-z9zhh/pods/proxy-service-wwb8w-8zpkb:160/proxy/: foo (200; 2.98107ms)
Nov  8 16:57:39.859: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-z9zhh/pods/proxy-service-wwb8w-8zpkb:162/proxy/: bar (200; 2.978338ms)
Nov  8 16:57:39.859: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-z9zhh/pods/proxy-service-wwb8w-8zpkb/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-z9zhh/pods/proxy-service-wwb8w-8zpkb/proxy/rewriteme"... (200; 2.954921ms)
Nov  8 16:57:39.859: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-z9zhh/pods/https:proxy-service-wwb8w-8zpkb:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-z9zhh/pods/https:proxy-service-wwb8w-8zpkb:443/proxy/... (200; 3.740675ms)
Nov  8 16:57:39.860: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-z9zhh/pods/http:proxy-service-wwb8w-8zpkb:160/proxy/: foo (200; 3.811509ms)
Nov  8 16:57:39.860: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-z9zhh/pods/proxy-service-wwb8w-8zpkb:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-z9zhh/pods/proxy-service-wwb8w-8zpkb:1080/proxy/rewri... (200; 3.960394ms)
Nov  8 16:57:39.860: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-z9zhh/pods/https:proxy-service-wwb8w-8zpkb:460/proxy/: tls baz (200; 4.217717ms)
Nov  8 16:57:39.860: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-z9zhh/services/http:proxy-service-wwb8w:portname1/proxy/: foo (200; 4.480477ms)
Nov  8 16:57:39.861: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-z9zhh/pods/http:proxy-service-wwb8w-8zpkb:162/proxy/: bar (200; 4.291909ms)
Nov  8 16:57:39.861: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-z9zhh/pods/http:proxy-service-wwb8w-8zpkb:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-z9zhh/pods/http:proxy-service-wwb8w-8zpkb:1080/proxy/... (200; 4.395172ms)
Nov  8 16:57:39.861: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-z9zhh/services/https:proxy-service-wwb8w:tlsportname1/proxy/: tls baz (200; 4.640122ms)
Nov  8 16:57:39.861: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-z9zhh/services/proxy-service-wwb8w:portname2/proxy/: bar (200; 4.539556ms)
Nov  8 16:57:39.861: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-z9zhh/pods/https:proxy-service-wwb8w-8zpkb:462/proxy/: tls qux (200; 4.595459ms)
Nov  8 16:57:39.861: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-z9zhh/services/https:proxy-service-wwb8w:tlsportname2/proxy/: tls qux (200; 4.844448ms)
Nov  8 16:57:39.861: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-z9zhh/services/http:proxy-service-wwb8w:portname2/proxy/: bar (200; 4.988632ms)
Nov  8 16:57:39.861: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-z9zhh/services/proxy-service-wwb8w:portname1/proxy/: foo (200; 5.314669ms)
Nov  8 16:57:39.865: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-z9zhh/pods/proxy-service-wwb8w-8zpkb:162/proxy/: bar (200; 3.790848ms)
Nov  8 16:57:39.866: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-z9zhh/services/http:proxy-service-wwb8w:portname2/proxy/: bar (200; 3.851709ms)
Nov  8 16:57:39.866: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-z9zhh/services/proxy-service-wwb8w:portname1/proxy/: foo (200; 4.462189ms)
Nov  8 16:57:39.867: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-z9zhh/services/https:proxy-service-wwb8w:tlsportname2/proxy/: tls qux (200; 5.33169ms)
Nov  8 16:57:39.867: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-z9zhh/services/http:proxy-service-wwb8w:portname1/proxy/: foo (200; 5.219239ms)
Nov  8 16:57:39.867: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-z9zhh/pods/https:proxy-service-wwb8w-8zpkb:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-z9zhh/pods/https:proxy-service-wwb8w-8zpkb:443/proxy/... (200; 4.775574ms)
Nov  8 16:57:39.867: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-z9zhh/pods/proxy-service-wwb8w-8zpkb/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-z9zhh/pods/proxy-service-wwb8w-8zpkb/proxy/rewriteme"... (200; 5.439741ms)
Nov  8 16:57:39.867: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-z9zhh/pods/proxy-service-wwb8w-8zpkb:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-z9zhh/pods/proxy-service-wwb8w-8zpkb:1080/proxy/rewri... (200; 5.120509ms)
Nov  8 16:57:39.867: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-z9zhh/services/https:proxy-service-wwb8w:tlsportname1/proxy/: tls baz (200; 5.341443ms)
Nov  8 16:57:39.867: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-z9zhh/pods/http:proxy-service-wwb8w-8zpkb:160/proxy/: foo (200; 5.041651ms)
Nov  8 16:57:39.867: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-z9zhh/services/proxy-service-wwb8w:portname2/proxy/: bar (200; 5.240506ms)
Nov  8 16:57:39.867: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-z9zhh/pods/http:proxy-service-wwb8w-8zpkb:162/proxy/: bar (200; 5.075578ms)
Nov  8 16:57:39.867: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-z9zhh/pods/http:proxy-service-wwb8w-8zpkb:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-z9zhh/pods/http:proxy-service-wwb8w-8zpkb:1080/proxy/... (200; 5.261633ms)
Nov  8 16:57:39.867: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-z9zhh/pods/proxy-service-wwb8w-8zpkb:160/proxy/: foo (200; 4.981801ms)
Nov  8 16:57:39.867: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-z9zhh/pods/https:proxy-service-wwb8w-8zpkb:462/proxy/: tls qux (200; 5.416732ms)
Nov  8 16:57:39.867: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-z9zhh/pods/https:proxy-service-wwb8w-8zpkb:460/proxy/: tls baz (200; 5.487807ms)
Nov  8 16:57:39.883: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-z9zhh/pods/proxy-service-wwb8w-8zpkb/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-z9zhh/pods/proxy-service-wwb8w-8zpkb/proxy/rewriteme"... (200; 16.060428ms)
Nov  8 16:57:39.883: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-z9zhh/pods/https:proxy-service-wwb8w-8zpkb:462/proxy/: tls qux (200; 15.89472ms)
Nov  8 16:57:39.883: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-z9zhh/pods/http:proxy-service-wwb8w-8zpkb:162/proxy/: bar (200; 15.779422ms)
Nov  8 16:57:39.883: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-z9zhh/pods/proxy-service-wwb8w-8zpkb:162/proxy/: bar (200; 15.719739ms)
Nov  8 16:57:39.883: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-z9zhh/pods/http:proxy-service-wwb8w-8zpkb:160/proxy/: foo (200; 15.821801ms)
Nov  8 16:57:39.883: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-z9zhh/pods/proxy-service-wwb8w-8zpkb:160/proxy/: foo (200; 15.70233ms)
Nov  8 16:57:39.883: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-z9zhh/pods/http:proxy-service-wwb8w-8zpkb:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-z9zhh/pods/http:proxy-service-wwb8w-8zpkb:1080/proxy/... (200; 16.074875ms)
Nov  8 16:57:39.883: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-z9zhh/pods/https:proxy-service-wwb8w-8zpkb:460/proxy/: tls baz (200; 15.952877ms)
Nov  8 16:57:39.883: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-z9zhh/pods/https:proxy-service-wwb8w-8zpkb:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-z9zhh/pods/https:proxy-service-wwb8w-8zpkb:443/proxy/... (200; 15.789435ms)
Nov  8 16:57:39.884: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-z9zhh/services/https:proxy-service-wwb8w:tlsportname1/proxy/: tls baz (200; 16.363713ms)
Nov  8 16:57:39.884: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-z9zhh/services/https:proxy-service-wwb8w:tlsportname2/proxy/: tls qux (200; 16.476382ms)
Nov  8 16:57:39.884: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-z9zhh/services/http:proxy-service-wwb8w:portname1/proxy/: foo (200; 16.827361ms)
Nov  8 16:57:39.884: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-z9zhh/services/proxy-service-wwb8w:portname1/proxy/: foo (200; 17.14814ms)
Nov  8 16:57:39.884: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-z9zhh/pods/proxy-service-wwb8w-8zpkb:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-z9zhh/pods/proxy-service-wwb8w-8zpkb:1080/proxy/rewri... (200; 16.967022ms)
Nov  8 16:57:39.925: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-z9zhh/services/proxy-service-wwb8w:portname2/proxy/: bar (200; 57.665932ms)
Nov  8 16:57:39.925: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-z9zhh/services/http:proxy-service-wwb8w:portname2/proxy/: bar (200; 57.532194ms)
Nov  8 16:57:39.929: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-z9zhh/pods/http:proxy-service-wwb8w-8zpkb:162/proxy/: bar (200; 3.805115ms)
Nov  8 16:57:39.929: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-z9zhh/pods/proxy-service-wwb8w-8zpkb:160/proxy/: foo (200; 4.226526ms)
Nov  8 16:57:39.929: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-z9zhh/services/https:proxy-service-wwb8w:tlsportname1/proxy/: tls baz (200; 4.469158ms)
Nov  8 16:57:39.930: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-z9zhh/services/http:proxy-service-wwb8w:portname2/proxy/: bar (200; 4.520099ms)
Nov  8 16:57:39.930: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-z9zhh/pods/http:proxy-service-wwb8w-8zpkb:160/proxy/: foo (200; 4.415142ms)
Nov  8 16:57:39.930: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-z9zhh/pods/proxy-service-wwb8w-8zpkb:162/proxy/: bar (200; 4.55084ms)
Nov  8 16:57:39.931: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-z9zhh/pods/http:proxy-service-wwb8w-8zpkb:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-z9zhh/pods/http:proxy-service-wwb8w-8zpkb:1080/proxy/... (200; 5.707744ms)
Nov  8 16:57:39.931: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-z9zhh/pods/https:proxy-service-wwb8w-8zpkb:460/proxy/: tls baz (200; 6.355739ms)
Nov  8 16:57:39.931: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-z9zhh/pods/proxy-service-wwb8w-8zpkb/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-z9zhh/pods/proxy-service-wwb8w-8zpkb/proxy/rewriteme"... (200; 6.218655ms)
Nov  8 16:57:39.931: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-z9zhh/pods/https:proxy-service-wwb8w-8zpkb:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-z9zhh/pods/https:proxy-service-wwb8w-8zpkb:443/proxy/... (200; 6.291089ms)
Nov  8 16:57:39.932: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-z9zhh/pods/https:proxy-service-wwb8w-8zpkb:462/proxy/: tls qux (200; 6.567753ms)
Nov  8 16:57:39.932: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-z9zhh/pods/proxy-service-wwb8w-8zpkb:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-z9zhh/pods/proxy-service-wwb8w-8zpkb:1080/proxy/rewri... (200; 6.645338ms)
Nov  8 16:57:39.932: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-z9zhh/services/https:proxy-service-wwb8w:tlsportname2/proxy/: tls qux (200; 6.556908ms)
Nov  8 16:57:39.932: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-z9zhh/services/proxy-service-wwb8w:portname1/proxy/: foo (200; 6.61452ms)
Nov  8 16:57:39.940: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-z9zhh/services/http:proxy-service-wwb8w:portname1/proxy/: foo (200; 14.632744ms)
Nov  8 16:57:39.940: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-z9zhh/services/proxy-service-wwb8w:portname2/proxy/: bar (200; 15.046749ms)
Nov  8 16:57:39.944: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-z9zhh/pods/proxy-service-wwb8w-8zpkb:162/proxy/: bar (200; 3.378087ms)
Nov  8 16:57:39.944: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-z9zhh/pods/proxy-service-wwb8w-8zpkb:160/proxy/: foo (200; 3.615085ms)
Nov  8 16:57:39.945: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-z9zhh/services/http:proxy-service-wwb8w:portname1/proxy/: foo (200; 4.450912ms)
Nov  8 16:57:39.945: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-z9zhh/services/proxy-service-wwb8w:portname1/proxy/: foo (200; 4.419202ms)
Nov  8 16:57:39.945: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-z9zhh/pods/proxy-service-wwb8w-8zpkb:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-z9zhh/pods/proxy-service-wwb8w-8zpkb:1080/proxy/rewri... (200; 4.395262ms)
Nov  8 16:57:39.945: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-z9zhh/services/proxy-service-wwb8w:portname2/proxy/: bar (200; 5.004948ms)
Nov  8 16:57:39.945: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-z9zhh/services/https:proxy-service-wwb8w:tlsportname1/proxy/: tls baz (200; 4.662907ms)
Nov  8 16:57:39.945: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-z9zhh/services/https:proxy-service-wwb8w:tlsportname2/proxy/: tls qux (200; 4.829977ms)
Nov  8 16:57:39.945: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-z9zhh/services/http:proxy-service-wwb8w:portname2/proxy/: bar (200; 5.022756ms)
Nov  8 16:57:39.945: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-z9zhh/pods/http:proxy-service-wwb8w-8zpkb:160/proxy/: foo (200; 4.543958ms)
Nov  8 16:57:39.946: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-z9zhh/pods/proxy-service-wwb8w-8zpkb/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-z9zhh/pods/proxy-service-wwb8w-8zpkb/proxy/rewriteme"... (200; 5.199454ms)
Nov  8 16:57:39.946: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-z9zhh/pods/http:proxy-service-wwb8w-8zpkb:162/proxy/: bar (200; 4.701204ms)
Nov  8 16:57:39.946: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-z9zhh/pods/https:proxy-service-wwb8w-8zpkb:462/proxy/: tls qux (200; 5.215726ms)
Nov  8 16:57:39.946: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-z9zhh/pods/https:proxy-service-wwb8w-8zpkb:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-z9zhh/pods/https:proxy-service-wwb8w-8zpkb:443/proxy/... (200; 4.923775ms)
Nov  8 16:57:39.946: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-z9zhh/pods/https:proxy-service-wwb8w-8zpkb:460/proxy/: tls baz (200; 5.291242ms)
Nov  8 16:57:39.946: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-z9zhh/pods/http:proxy-service-wwb8w-8zpkb:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-z9zhh/pods/http:proxy-service-wwb8w-8zpkb:1080/proxy/... (200; 5.111403ms)
Nov  8 16:57:39.949: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-z9zhh/pods/http:proxy-service-wwb8w-8zpkb:160/proxy/: foo (200; 2.930758ms)
Nov  8 16:57:39.949: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-z9zhh/pods/proxy-service-wwb8w-8zpkb:160/proxy/: foo (200; 3.149567ms)
Nov  8 16:57:39.949: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-z9zhh/pods/http:proxy-service-wwb8w-8zpkb:162/proxy/: bar (200; 3.318937ms)
Nov  8 16:57:39.950: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-z9zhh/pods/proxy-service-wwb8w-8zpkb:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-z9zhh/pods/proxy-service-wwb8w-8zpkb:1080/proxy/rewri... (200; 3.432943ms)
Nov  8 16:57:39.950: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-z9zhh/pods/proxy-service-wwb8w-8zpkb:162/proxy/: bar (200; 3.778055ms)
Nov  8 16:57:39.950: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-z9zhh/pods/https:proxy-service-wwb8w-8zpkb:460/proxy/: tls baz (200; 3.76329ms)
Nov  8 16:57:39.950: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-z9zhh/services/http:proxy-service-wwb8w:portname1/proxy/: foo (200; 4.174194ms)
Nov  8 16:57:39.950: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-z9zhh/pods/proxy-service-wwb8w-8zpkb/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-z9zhh/pods/proxy-service-wwb8w-8zpkb/proxy/rewriteme"... (200; 4.223259ms)
Nov  8 16:57:39.950: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-z9zhh/services/http:proxy-service-wwb8w:portname2/proxy/: bar (200; 4.304999ms)
Nov  8 16:57:39.951: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-z9zhh/services/proxy-service-wwb8w:portname1/proxy/: foo (200; 4.427249ms)
Nov  8 16:57:39.951: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-z9zhh/pods/http:proxy-service-wwb8w-8zpkb:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-z9zhh/pods/http:proxy-service-wwb8w-8zpkb:1080/proxy/... (200; 4.46539ms)
Nov  8 16:57:39.951: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-z9zhh/pods/https:proxy-service-wwb8w-8zpkb:462/proxy/: tls qux (200; 4.454313ms)
Nov  8 16:57:39.951: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-z9zhh/services/proxy-service-wwb8w:portname2/proxy/: bar (200; 4.651195ms)
Nov  8 16:57:39.951: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-z9zhh/services/https:proxy-service-wwb8w:tlsportname1/proxy/: tls baz (200; 4.517762ms)
Nov  8 16:57:39.951: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-z9zhh/pods/https:proxy-service-wwb8w-8zpkb:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-z9zhh/pods/https:proxy-service-wwb8w-8zpkb:443/proxy/... (200; 4.610134ms)
Nov  8 16:57:39.951: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-z9zhh/services/https:proxy-service-wwb8w:tlsportname2/proxy/: tls qux (200; 4.662567ms)
Nov  8 16:57:39.955: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-z9zhh/pods/proxy-service-wwb8w-8zpkb/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-z9zhh/pods/proxy-service-wwb8w-8zpkb/proxy/rewriteme"... (200; 4.168017ms)
Nov  8 16:57:39.955: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-z9zhh/pods/https:proxy-service-wwb8w-8zpkb:462/proxy/: tls qux (200; 4.112251ms)
Nov  8 16:57:39.955: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-z9zhh/pods/http:proxy-service-wwb8w-8zpkb:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-z9zhh/pods/http:proxy-service-wwb8w-8zpkb:1080/proxy/... (200; 4.336258ms)
Nov  8 16:57:39.955: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-z9zhh/pods/http:proxy-service-wwb8w-8zpkb:162/proxy/: bar (200; 4.273317ms)
Nov  8 16:57:39.955: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-z9zhh/pods/https:proxy-service-wwb8w-8zpkb:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-z9zhh/pods/https:proxy-service-wwb8w-8zpkb:443/proxy/... (200; 4.317015ms)
Nov  8 16:57:39.955: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-z9zhh/services/https:proxy-service-wwb8w:tlsportname2/proxy/: tls qux (200; 4.193863ms)
Nov  8 16:57:39.955: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-z9zhh/pods/http:proxy-service-wwb8w-8zpkb:160/proxy/: foo (200; 4.576733ms)
Nov  8 16:57:39.955: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-z9zhh/pods/proxy-service-wwb8w-8zpkb:162/proxy/: bar (200; 4.3404ms)
Nov  8 16:57:39.955: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-z9zhh/pods/proxy-service-wwb8w-8zpkb:160/proxy/: foo (200; 4.493576ms)
Nov  8 16:57:39.955: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-z9zhh/services/proxy-service-wwb8w:portname1/proxy/: foo (200; 4.708194ms)
Nov  8 16:57:39.956: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-z9zhh/services/proxy-service-wwb8w:portname2/proxy/: bar (200; 4.672391ms)
Nov  8 16:57:39.956: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-z9zhh/services/http:proxy-service-wwb8w:portname1/proxy/: foo (200; 4.965922ms)
Nov  8 16:57:39.956: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-z9zhh/services/https:proxy-service-wwb8w:tlsportname1/proxy/: tls baz (200; 5.082332ms)
Nov  8 16:57:39.956: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-z9zhh/pods/https:proxy-service-wwb8w-8zpkb:460/proxy/: tls baz (200; 5.421854ms)
Nov  8 16:57:39.956: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-z9zhh/services/http:proxy-service-wwb8w:portname2/proxy/: bar (200; 5.467709ms)
Nov  8 16:57:39.957: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-z9zhh/pods/proxy-service-wwb8w-8zpkb:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-z9zhh/pods/proxy-service-wwb8w-8zpkb:1080/proxy/rewri... (200; 5.606082ms)
Nov  8 16:57:39.959: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-z9zhh/pods/proxy-service-wwb8w-8zpkb:162/proxy/: bar (200; 2.464488ms)
Nov  8 16:57:39.960: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-z9zhh/pods/proxy-service-wwb8w-8zpkb/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-z9zhh/pods/proxy-service-wwb8w-8zpkb/proxy/rewriteme"... (200; 2.797067ms)
Nov  8 16:57:39.960: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-z9zhh/pods/https:proxy-service-wwb8w-8zpkb:462/proxy/: tls qux (200; 2.757691ms)
Nov  8 16:57:39.960: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-z9zhh/pods/http:proxy-service-wwb8w-8zpkb:162/proxy/: bar (200; 2.649521ms)
Nov  8 16:57:39.960: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-z9zhh/pods/https:proxy-service-wwb8w-8zpkb:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-z9zhh/pods/https:proxy-service-wwb8w-8zpkb:443/proxy/... (200; 2.621912ms)
Nov  8 16:57:39.960: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-z9zhh/pods/http:proxy-service-wwb8w-8zpkb:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-z9zhh/pods/http:proxy-service-wwb8w-8zpkb:1080/proxy/... (200; 3.052621ms)
Nov  8 16:57:39.960: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-z9zhh/pods/proxy-service-wwb8w-8zpkb:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-z9zhh/pods/proxy-service-wwb8w-8zpkb:1080/proxy/rewri... (200; 3.104724ms)
Nov  8 16:57:39.960: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-z9zhh/pods/https:proxy-service-wwb8w-8zpkb:460/proxy/: tls baz (200; 3.291571ms)
Nov  8 16:57:39.961: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-z9zhh/pods/http:proxy-service-wwb8w-8zpkb:160/proxy/: foo (200; 3.777917ms)
Nov  8 16:57:39.961: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-z9zhh/pods/proxy-service-wwb8w-8zpkb:160/proxy/: foo (200; 3.730494ms)
Nov  8 16:57:39.962: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-z9zhh/services/proxy-service-wwb8w:portname1/proxy/: foo (200; 5.245653ms)
Nov  8 16:57:39.963: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-z9zhh/services/proxy-service-wwb8w:portname2/proxy/: bar (200; 6.406534ms)
Nov  8 16:57:39.964: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-z9zhh/services/http:proxy-service-wwb8w:portname2/proxy/: bar (200; 6.274878ms)
Nov  8 16:57:39.964: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-z9zhh/services/https:proxy-service-wwb8w:tlsportname1/proxy/: tls baz (200; 6.623009ms)
Nov  8 16:57:39.964: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-z9zhh/services/http:proxy-service-wwb8w:portname1/proxy/: foo (200; 6.634193ms)
Nov  8 16:57:39.964: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-z9zhh/services/https:proxy-service-wwb8w:tlsportname2/proxy/: tls qux (200; 6.832503ms)
STEP: deleting { ReplicationController} proxy-service-wwb8w in namespace e2e-tests-proxy-z9zhh, will wait for the garbage collector to delete the pods
Nov  8 16:57:40.018: INFO: Deleting { ReplicationController} proxy-service-wwb8w took: 2.843775ms
Nov  8 16:57:40.118: INFO: Terminating { ReplicationController} proxy-service-wwb8w pods took: 100.129377ms
[AfterEach] version v1
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  8 16:57:46.118: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-proxy-z9zhh" for this suite.
Nov  8 16:57:52.126: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  8 16:57:52.156: INFO: namespace: e2e-tests-proxy-z9zhh, resource: bindings, ignored listing per whitelist
Nov  8 16:57:52.179: INFO: namespace e2e-tests-proxy-z9zhh deletion completed in 6.058046497s

• [SLOW TEST:24.507 seconds]
[sig-network] Proxy
/go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy through a service and a pod  [Conformance]
    /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  8 16:57:52.179: INFO: >>> kubeConfig: /tmp/kubeconfig-235977939
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-map-6e135daf-e377-11e8-b0fd-0e97e856486a
STEP: Creating a pod to test consume configMaps
Nov  8 16:57:52.221: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-6e1396c8-e377-11e8-b0fd-0e97e856486a" in namespace "e2e-tests-projected-gztml" to be "success or failure"
Nov  8 16:57:52.223: INFO: Pod "pod-projected-configmaps-6e1396c8-e377-11e8-b0fd-0e97e856486a": Phase="Pending", Reason="", readiness=false. Elapsed: 1.520456ms
Nov  8 16:57:54.225: INFO: Pod "pod-projected-configmaps-6e1396c8-e377-11e8-b0fd-0e97e856486a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.003582657s
STEP: Saw pod success
Nov  8 16:57:54.225: INFO: Pod "pod-projected-configmaps-6e1396c8-e377-11e8-b0fd-0e97e856486a" satisfied condition "success or failure"
Nov  8 16:57:54.226: INFO: Trying to get logs from node ip-10-0-100-224.ec2.internal pod pod-projected-configmaps-6e1396c8-e377-11e8-b0fd-0e97e856486a container projected-configmap-volume-test: <nil>
STEP: delete the pod
Nov  8 16:57:54.235: INFO: Waiting for pod pod-projected-configmaps-6e1396c8-e377-11e8-b0fd-0e97e856486a to disappear
Nov  8 16:57:54.238: INFO: Pod pod-projected-configmaps-6e1396c8-e377-11e8-b0fd-0e97e856486a no longer exists
[AfterEach] [sig-storage] Projected
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  8 16:57:54.238: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-gztml" for this suite.
Nov  8 16:58:00.245: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  8 16:58:00.286: INFO: namespace: e2e-tests-projected-gztml, resource: bindings, ignored listing per whitelist
Nov  8 16:58:00.298: INFO: namespace e2e-tests-projected-gztml deletion completed in 6.058527281s

• [SLOW TEST:8.119 seconds]
[sig-storage] Projected
/go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-apps] ReplicationController 
  should serve a basic image on each replica with a public image  [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] ReplicationController
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  8 16:58:00.298: INFO: >>> kubeConfig: /tmp/kubeconfig-235977939
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating replication controller my-hostname-basic-72e9c40d-e377-11e8-b0fd-0e97e856486a
Nov  8 16:58:00.337: INFO: Pod name my-hostname-basic-72e9c40d-e377-11e8-b0fd-0e97e856486a: Found 0 pods out of 1
Nov  8 16:58:05.339: INFO: Pod name my-hostname-basic-72e9c40d-e377-11e8-b0fd-0e97e856486a: Found 1 pods out of 1
Nov  8 16:58:05.339: INFO: Ensuring all pods for ReplicationController "my-hostname-basic-72e9c40d-e377-11e8-b0fd-0e97e856486a" are running
Nov  8 16:58:05.341: INFO: Pod "my-hostname-basic-72e9c40d-e377-11e8-b0fd-0e97e856486a-vnfb4" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2018-11-08 16:58:00 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2018-11-08 16:58:01 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2018-11-08 16:58:01 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2018-11-08 16:58:00 +0000 UTC Reason: Message:}])
Nov  8 16:58:05.341: INFO: Trying to dial the pod
Nov  8 16:58:10.347: INFO: Controller my-hostname-basic-72e9c40d-e377-11e8-b0fd-0e97e856486a: Got expected result from replica 1 [my-hostname-basic-72e9c40d-e377-11e8-b0fd-0e97e856486a-vnfb4]: "my-hostname-basic-72e9c40d-e377-11e8-b0fd-0e97e856486a-vnfb4", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicationController
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  8 16:58:10.347: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-replication-controller-tbbb7" for this suite.
Nov  8 16:58:16.354: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  8 16:58:16.409: INFO: namespace: e2e-tests-replication-controller-tbbb7, resource: bindings, ignored listing per whitelist
Nov  8 16:58:16.412: INFO: namespace e2e-tests-replication-controller-tbbb7 deletion completed in 6.063229589s

• [SLOW TEST:16.114 seconds]
[sig-apps] ReplicationController
/go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should serve a basic image on each replica with a public image  [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should be updated [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  8 16:58:16.412: INFO: >>> kubeConfig: /tmp/kubeconfig-235977939
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should be updated [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Nov  8 16:58:18.963: INFO: Successfully updated pod "pod-update-7c84f3a3-e377-11e8-b0fd-0e97e856486a"
STEP: verifying the updated pod is in kubernetes
Nov  8 16:58:18.967: INFO: Pod update OK
[AfterEach] [k8s.io] Pods
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  8 16:58:18.967: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-mlmlc" for this suite.
Nov  8 16:58:40.975: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  8 16:58:41.013: INFO: namespace: e2e-tests-pods-mlmlc, resource: bindings, ignored listing per whitelist
Nov  8 16:58:41.027: INFO: namespace e2e-tests-pods-mlmlc deletion completed in 22.057947493s

• [SLOW TEST:24.615 seconds]
[k8s.io] Pods
/go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be updated [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  8 16:58:41.027: INFO: >>> kubeConfig: /tmp/kubeconfig-235977939
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-map-8b315aa0-e377-11e8-b0fd-0e97e856486a
STEP: Creating a pod to test consume secrets
Nov  8 16:58:41.072: INFO: Waiting up to 5m0s for pod "pod-secrets-8b3195fe-e377-11e8-b0fd-0e97e856486a" in namespace "e2e-tests-secrets-522k7" to be "success or failure"
Nov  8 16:58:41.073: INFO: Pod "pod-secrets-8b3195fe-e377-11e8-b0fd-0e97e856486a": Phase="Pending", Reason="", readiness=false. Elapsed: 1.665635ms
Nov  8 16:58:43.075: INFO: Pod "pod-secrets-8b3195fe-e377-11e8-b0fd-0e97e856486a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.003637369s
STEP: Saw pod success
Nov  8 16:58:43.075: INFO: Pod "pod-secrets-8b3195fe-e377-11e8-b0fd-0e97e856486a" satisfied condition "success or failure"
Nov  8 16:58:43.077: INFO: Trying to get logs from node ip-10-0-100-224.ec2.internal pod pod-secrets-8b3195fe-e377-11e8-b0fd-0e97e856486a container secret-volume-test: <nil>
STEP: delete the pod
Nov  8 16:58:43.087: INFO: Waiting for pod pod-secrets-8b3195fe-e377-11e8-b0fd-0e97e856486a to disappear
Nov  8 16:58:43.088: INFO: Pod pod-secrets-8b3195fe-e377-11e8-b0fd-0e97e856486a no longer exists
[AfterEach] [sig-storage] Secrets
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  8 16:58:43.088: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-522k7" for this suite.
Nov  8 16:58:49.095: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  8 16:58:49.137: INFO: namespace: e2e-tests-secrets-522k7, resource: bindings, ignored listing per whitelist
Nov  8 16:58:49.148: INFO: namespace e2e-tests-secrets-522k7 deletion completed in 6.058336096s

• [SLOW TEST:8.121 seconds]
[sig-storage] Secrets
/go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  8 16:58:49.148: INFO: >>> kubeConfig: /tmp/kubeconfig-235977939
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with configmap pod [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-configmap-nb2x
STEP: Creating a pod to test atomic-volume-subpath
Nov  8 16:58:49.191: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-nb2x" in namespace "e2e-tests-subpath-fbh59" to be "success or failure"
Nov  8 16:58:49.194: INFO: Pod "pod-subpath-test-configmap-nb2x": Phase="Pending", Reason="", readiness=false. Elapsed: 2.863408ms
Nov  8 16:58:51.196: INFO: Pod "pod-subpath-test-configmap-nb2x": Phase="Pending", Reason="", readiness=false. Elapsed: 2.004844939s
Nov  8 16:58:53.198: INFO: Pod "pod-subpath-test-configmap-nb2x": Phase="Running", Reason="", readiness=false. Elapsed: 4.006694248s
Nov  8 16:58:55.200: INFO: Pod "pod-subpath-test-configmap-nb2x": Phase="Running", Reason="", readiness=false. Elapsed: 6.008781469s
Nov  8 16:58:57.202: INFO: Pod "pod-subpath-test-configmap-nb2x": Phase="Running", Reason="", readiness=false. Elapsed: 8.010913735s
Nov  8 16:58:59.204: INFO: Pod "pod-subpath-test-configmap-nb2x": Phase="Running", Reason="", readiness=false. Elapsed: 10.01306252s
Nov  8 16:59:01.206: INFO: Pod "pod-subpath-test-configmap-nb2x": Phase="Running", Reason="", readiness=false. Elapsed: 12.015107823s
Nov  8 16:59:03.208: INFO: Pod "pod-subpath-test-configmap-nb2x": Phase="Running", Reason="", readiness=false. Elapsed: 14.017134469s
Nov  8 16:59:05.210: INFO: Pod "pod-subpath-test-configmap-nb2x": Phase="Running", Reason="", readiness=false. Elapsed: 16.019223455s
Nov  8 16:59:07.212: INFO: Pod "pod-subpath-test-configmap-nb2x": Phase="Running", Reason="", readiness=false. Elapsed: 18.021346904s
Nov  8 16:59:09.214: INFO: Pod "pod-subpath-test-configmap-nb2x": Phase="Running", Reason="", readiness=false. Elapsed: 20.023513223s
Nov  8 16:59:11.217: INFO: Pod "pod-subpath-test-configmap-nb2x": Phase="Running", Reason="", readiness=false. Elapsed: 22.025648814s
Nov  8 16:59:13.218: INFO: Pod "pod-subpath-test-configmap-nb2x": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.027557107s
STEP: Saw pod success
Nov  8 16:59:13.218: INFO: Pod "pod-subpath-test-configmap-nb2x" satisfied condition "success or failure"
Nov  8 16:59:13.220: INFO: Trying to get logs from node ip-10-0-100-224.ec2.internal pod pod-subpath-test-configmap-nb2x container test-container-subpath-configmap-nb2x: <nil>
STEP: delete the pod
Nov  8 16:59:13.230: INFO: Waiting for pod pod-subpath-test-configmap-nb2x to disappear
Nov  8 16:59:13.231: INFO: Pod pod-subpath-test-configmap-nb2x no longer exists
STEP: Deleting pod pod-subpath-test-configmap-nb2x
Nov  8 16:59:13.231: INFO: Deleting pod "pod-subpath-test-configmap-nb2x" in namespace "e2e-tests-subpath-fbh59"
[AfterEach] [sig-storage] Subpath
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  8 16:59:13.232: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-fbh59" for this suite.
Nov  8 16:59:19.240: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  8 16:59:19.288: INFO: namespace: e2e-tests-subpath-fbh59, resource: bindings, ignored listing per whitelist
Nov  8 16:59:19.293: INFO: namespace e2e-tests-subpath-fbh59 deletion completed in 6.058807633s

• [SLOW TEST:30.145 seconds]
[sig-storage] Subpath
/go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with configmap pod [Conformance]
    /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[k8s.io] [sig-node] Events 
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] [sig-node] Events
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  8 16:59:19.293: INFO: >>> kubeConfig: /tmp/kubeconfig-235977939
STEP: Building a namespace api object, basename events
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: retrieving the pod
Nov  8 16:59:21.340: INFO: &Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:send-events-a1ffc9ff-e377-11e8-b0fd-0e97e856486a,GenerateName:,Namespace:e2e-tests-events-5jtbt,SelfLink:/api/v1/namespaces/e2e-tests-events-5jtbt/pods/send-events-a1ffc9ff-e377-11e8-b0fd-0e97e856486a,UID:a2002dd5-e377-11e8-a466-0a0beb0244cc,ResourceVersion:16693,Generation:0,CreationTimestamp:2018-11-08 16:59:19 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: foo,time: 330879063,},Annotations:map[string]string{cni.projectcalico.org/podIP: 192.168.1.170/32,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-czvb4 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-czvb4,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{p gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1 [] []  [{ 0 80 TCP }] [] [] {map[] map[]} [{default-token-czvb4 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*30,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-100-224.ec2.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc421c4dff0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc4221a0010}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-11-08 16:59:19 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2018-11-08 16:59:20 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2018-11-08 16:59:20 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-11-08 16:59:19 +0000 UTC  }],Message:,Reason:,HostIP:10.0.100.224,PodIP:192.168.1.170,StartTime:2018-11-08 16:59:19 +0000 UTC,ContainerStatuses:[{p {nil ContainerStateRunning{StartedAt:2018-11-08 16:59:20 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1 docker-pullable://gcr.io/kubernetes-e2e-test-images/serve-hostname@sha256:bab70473a6d8ef65a22625dc9a1b0f0452e811530fdbe77e4408523460177ff1 docker://bc26e3f197c5c9442a10496181fec95127b5730ee12a335516e955eeedbeda6e}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}

STEP: checking for scheduler event about the pod
Nov  8 16:59:23.342: INFO: Saw scheduler event for our pod.
STEP: checking for kubelet event about the pod
Nov  8 16:59:25.344: INFO: Saw kubelet event for our pod.
STEP: deleting the pod
[AfterEach] [k8s.io] [sig-node] Events
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  8 16:59:25.346: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-events-5jtbt" for this suite.
Nov  8 17:00:07.356: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  8 17:00:07.373: INFO: namespace: e2e-tests-events-5jtbt, resource: bindings, ignored listing per whitelist
Nov  8 17:00:07.409: INFO: namespace e2e-tests-events-5jtbt deletion completed in 42.057945174s

• [SLOW TEST:48.116 seconds]
[k8s.io] [sig-node] Events
/go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Proxy server 
  should support proxy with --port 0  [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  8 17:00:07.409: INFO: >>> kubeConfig: /tmp/kubeconfig-235977939
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should support proxy with --port 0  [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: starting the proxy server
Nov  8 17:00:07.449: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-235977939 proxy -p 0 --disable-filter'
STEP: curling proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  8 17:00:07.505: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-bhw2c" for this suite.
Nov  8 17:00:13.513: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  8 17:00:13.530: INFO: namespace: e2e-tests-kubectl-bhw2c, resource: bindings, ignored listing per whitelist
Nov  8 17:00:13.566: INFO: namespace e2e-tests-kubectl-bhw2c deletion completed in 6.059306962s

• [SLOW TEST:6.157 seconds]
[sig-cli] Kubectl client
/go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Proxy server
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should support proxy with --port 0  [Conformance]
    /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,tmpfs) [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  8 17:00:13.566: INFO: >>> kubeConfig: /tmp/kubeconfig-235977939
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,tmpfs) [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0644 on tmpfs
Nov  8 17:00:13.609: INFO: Waiting up to 5m0s for pod "pod-c258fb40-e377-11e8-b0fd-0e97e856486a" in namespace "e2e-tests-emptydir-m8zhh" to be "success or failure"
Nov  8 17:00:13.611: INFO: Pod "pod-c258fb40-e377-11e8-b0fd-0e97e856486a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.41224ms
Nov  8 17:00:15.613: INFO: Pod "pod-c258fb40-e377-11e8-b0fd-0e97e856486a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004329257s
STEP: Saw pod success
Nov  8 17:00:15.613: INFO: Pod "pod-c258fb40-e377-11e8-b0fd-0e97e856486a" satisfied condition "success or failure"
Nov  8 17:00:15.615: INFO: Trying to get logs from node ip-10-0-100-224.ec2.internal pod pod-c258fb40-e377-11e8-b0fd-0e97e856486a container test-container: <nil>
STEP: delete the pod
Nov  8 17:00:15.625: INFO: Waiting for pod pod-c258fb40-e377-11e8-b0fd-0e97e856486a to disappear
Nov  8 17:00:15.626: INFO: Pod pod-c258fb40-e377-11e8-b0fd-0e97e856486a no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  8 17:00:15.626: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-m8zhh" for this suite.
Nov  8 17:00:21.634: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  8 17:00:21.677: INFO: namespace: e2e-tests-emptydir-m8zhh, resource: bindings, ignored listing per whitelist
Nov  8 17:00:21.689: INFO: namespace e2e-tests-emptydir-m8zhh deletion completed in 6.061200923s

• [SLOW TEST:8.123 seconds]
[sig-storage] EmptyDir volumes
/go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0644,tmpfs) [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Burst scaling should run to completion even with unhealthy pods [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  8 17:00:21.689: INFO: >>> kubeConfig: /tmp/kubeconfig-235977939
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-tcbpr
[It] Burst scaling should run to completion even with unhealthy pods [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating stateful set ss in namespace e2e-tests-statefulset-tcbpr
STEP: Waiting until all stateful set ss replicas will be running in namespace e2e-tests-statefulset-tcbpr
Nov  8 17:00:21.740: INFO: Found 0 stateful pods, waiting for 1
Nov  8 17:00:31.742: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will not halt with unhealthy stateful pod
Nov  8 17:00:31.744: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-235977939 exec --namespace=e2e-tests-statefulset-tcbpr ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Nov  8 17:00:31.877: INFO: stderr: ""
Nov  8 17:00:31.877: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Nov  8 17:00:31.877: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Nov  8 17:00:31.879: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Nov  8 17:00:41.881: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Nov  8 17:00:41.881: INFO: Waiting for statefulset status.replicas updated to 0
Nov  8 17:00:41.888: INFO: POD   NODE                          PHASE    GRACE  CONDITIONS
Nov  8 17:00:41.888: INFO: ss-0  ip-10-0-100-224.ec2.internal  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-11-08 17:00:21 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-11-08 17:00:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-11-08 17:00:32 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-11-08 17:00:21 +0000 UTC  }]
Nov  8 17:00:41.888: INFO: 
Nov  8 17:00:41.888: INFO: StatefulSet ss has not reached scale 3, at 1
Nov  8 17:00:42.889: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.997831071s
Nov  8 17:00:43.892: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.996042108s
Nov  8 17:00:44.894: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.99370745s
Nov  8 17:00:45.896: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.991377361s
Nov  8 17:00:46.899: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.989116782s
Nov  8 17:00:47.901: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.986782266s
Nov  8 17:00:48.903: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.984596077s
Nov  8 17:00:49.906: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.982177706s
Nov  8 17:00:50.908: INFO: Verifying statefulset ss doesn't scale past 3 for another 979.922449ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace e2e-tests-statefulset-tcbpr
Nov  8 17:00:51.910: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-235977939 exec --namespace=e2e-tests-statefulset-tcbpr ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Nov  8 17:00:52.041: INFO: stderr: ""
Nov  8 17:00:52.041: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Nov  8 17:00:52.041: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Nov  8 17:00:52.041: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-235977939 exec --namespace=e2e-tests-statefulset-tcbpr ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Nov  8 17:00:52.174: INFO: stderr: "mv: can't rename '/tmp/index.html': No such file or directory\n"
Nov  8 17:00:52.174: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Nov  8 17:00:52.174: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Nov  8 17:00:52.174: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-235977939 exec --namespace=e2e-tests-statefulset-tcbpr ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Nov  8 17:00:52.321: INFO: stderr: "mv: can't rename '/tmp/index.html': No such file or directory\n"
Nov  8 17:00:52.321: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Nov  8 17:00:52.321: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-2: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Nov  8 17:00:52.323: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Nov  8 17:00:52.323: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Nov  8 17:00:52.323: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Scale down will not halt with unhealthy stateful pod
Nov  8 17:00:52.324: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-235977939 exec --namespace=e2e-tests-statefulset-tcbpr ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Nov  8 17:00:52.454: INFO: stderr: ""
Nov  8 17:00:52.454: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Nov  8 17:00:52.454: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Nov  8 17:00:52.454: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-235977939 exec --namespace=e2e-tests-statefulset-tcbpr ss-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Nov  8 17:00:52.591: INFO: stderr: ""
Nov  8 17:00:52.591: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Nov  8 17:00:52.591: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Nov  8 17:00:52.591: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-235977939 exec --namespace=e2e-tests-statefulset-tcbpr ss-2 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Nov  8 17:00:52.727: INFO: stderr: ""
Nov  8 17:00:52.727: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Nov  8 17:00:52.727: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-2: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Nov  8 17:00:52.727: INFO: Waiting for statefulset status.replicas updated to 0
Nov  8 17:00:52.729: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 3
Nov  8 17:01:02.733: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Nov  8 17:01:02.733: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Nov  8 17:01:02.733: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Nov  8 17:01:02.739: INFO: POD   NODE                          PHASE    GRACE  CONDITIONS
Nov  8 17:01:02.739: INFO: ss-0  ip-10-0-100-224.ec2.internal  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-11-08 17:00:21 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-11-08 17:00:53 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-11-08 17:00:53 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-11-08 17:00:21 +0000 UTC  }]
Nov  8 17:01:02.739: INFO: ss-1  ip-10-0-100-254.ec2.internal  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-11-08 17:00:41 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-11-08 17:00:53 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-11-08 17:00:53 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-11-08 17:00:41 +0000 UTC  }]
Nov  8 17:01:02.739: INFO: ss-2  ip-10-0-100-224.ec2.internal  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-11-08 17:00:41 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-11-08 17:00:53 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-11-08 17:00:53 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-11-08 17:00:41 +0000 UTC  }]
Nov  8 17:01:02.739: INFO: 
Nov  8 17:01:02.739: INFO: StatefulSet ss has not reached scale 0, at 3
Nov  8 17:01:03.741: INFO: POD   NODE                          PHASE    GRACE  CONDITIONS
Nov  8 17:01:03.741: INFO: ss-0  ip-10-0-100-224.ec2.internal  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-11-08 17:00:21 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-11-08 17:00:53 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-11-08 17:00:53 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-11-08 17:00:21 +0000 UTC  }]
Nov  8 17:01:03.741: INFO: ss-1  ip-10-0-100-254.ec2.internal  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-11-08 17:00:41 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-11-08 17:00:53 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-11-08 17:00:53 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-11-08 17:00:41 +0000 UTC  }]
Nov  8 17:01:03.741: INFO: ss-2  ip-10-0-100-224.ec2.internal  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-11-08 17:00:41 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-11-08 17:00:53 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-11-08 17:00:53 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-11-08 17:00:41 +0000 UTC  }]
Nov  8 17:01:03.741: INFO: 
Nov  8 17:01:03.741: INFO: StatefulSet ss has not reached scale 0, at 3
Nov  8 17:01:04.744: INFO: POD   NODE                          PHASE    GRACE  CONDITIONS
Nov  8 17:01:04.744: INFO: ss-1  ip-10-0-100-254.ec2.internal  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2018-11-08 17:00:41 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2018-11-08 17:00:53 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2018-11-08 17:00:53 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2018-11-08 17:00:41 +0000 UTC  }]
Nov  8 17:01:04.744: INFO: 
Nov  8 17:01:04.744: INFO: StatefulSet ss has not reached scale 0, at 1
Nov  8 17:01:05.746: INFO: Verifying statefulset ss doesn't scale past 0 for another 6.993211192s
Nov  8 17:01:06.748: INFO: Verifying statefulset ss doesn't scale past 0 for another 5.991111086s
Nov  8 17:01:07.750: INFO: Verifying statefulset ss doesn't scale past 0 for another 4.989089234s
Nov  8 17:01:08.752: INFO: Verifying statefulset ss doesn't scale past 0 for another 3.987055416s
Nov  8 17:01:09.754: INFO: Verifying statefulset ss doesn't scale past 0 for another 2.985006463s
Nov  8 17:01:10.756: INFO: Verifying statefulset ss doesn't scale past 0 for another 1.982875288s
Nov  8 17:01:11.758: INFO: Verifying statefulset ss doesn't scale past 0 for another 980.830853ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacee2e-tests-statefulset-tcbpr
Nov  8 17:01:12.760: INFO: Scaling statefulset ss to 0
Nov  8 17:01:12.765: INFO: Waiting for statefulset status.replicas updated to 0
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Nov  8 17:01:12.766: INFO: Deleting all statefulset in ns e2e-tests-statefulset-tcbpr
Nov  8 17:01:12.767: INFO: Scaling statefulset ss to 0
Nov  8 17:01:12.772: INFO: Waiting for statefulset status.replicas updated to 0
Nov  8 17:01:12.773: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  8 17:01:12.778: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-tcbpr" for this suite.
Nov  8 17:01:18.786: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  8 17:01:18.822: INFO: namespace: e2e-tests-statefulset-tcbpr, resource: bindings, ignored listing per whitelist
Nov  8 17:01:18.839: INFO: namespace e2e-tests-statefulset-tcbpr deletion completed in 6.058262089s

• [SLOW TEST:57.149 seconds]
[sig-apps] StatefulSet
/go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    Burst scaling should run to completion even with unhealthy pods [Conformance]
    /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop simple daemon [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  8 17:01:18.839: INFO: >>> kubeConfig: /tmp/kubeconfig-235977939
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should run and stop simple daemon [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Nov  8 17:01:18.888: INFO: DaemonSet pods can't tolerate node ip-10-0-0-20.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov  8 17:01:18.889: INFO: Number of nodes with available pods: 0
Nov  8 17:01:18.889: INFO: Node ip-10-0-100-224.ec2.internal is running more than one daemon pod
Nov  8 17:01:19.892: INFO: DaemonSet pods can't tolerate node ip-10-0-0-20.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov  8 17:01:19.893: INFO: Number of nodes with available pods: 0
Nov  8 17:01:19.893: INFO: Node ip-10-0-100-224.ec2.internal is running more than one daemon pod
Nov  8 17:01:20.892: INFO: DaemonSet pods can't tolerate node ip-10-0-0-20.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov  8 17:01:20.893: INFO: Number of nodes with available pods: 2
Nov  8 17:01:20.893: INFO: Number of running nodes: 2, number of available pods: 2
STEP: Stop a daemon pod, check that the daemon pod is revived.
Nov  8 17:01:20.901: INFO: DaemonSet pods can't tolerate node ip-10-0-0-20.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov  8 17:01:20.902: INFO: Number of nodes with available pods: 1
Nov  8 17:01:20.902: INFO: Node ip-10-0-100-224.ec2.internal is running more than one daemon pod
Nov  8 17:01:21.904: INFO: DaemonSet pods can't tolerate node ip-10-0-0-20.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov  8 17:01:21.906: INFO: Number of nodes with available pods: 1
Nov  8 17:01:21.906: INFO: Node ip-10-0-100-224.ec2.internal is running more than one daemon pod
Nov  8 17:01:22.904: INFO: DaemonSet pods can't tolerate node ip-10-0-0-20.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov  8 17:01:22.906: INFO: Number of nodes with available pods: 1
Nov  8 17:01:22.906: INFO: Node ip-10-0-100-224.ec2.internal is running more than one daemon pod
Nov  8 17:01:23.905: INFO: DaemonSet pods can't tolerate node ip-10-0-0-20.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov  8 17:01:23.906: INFO: Number of nodes with available pods: 1
Nov  8 17:01:23.906: INFO: Node ip-10-0-100-224.ec2.internal is running more than one daemon pod
Nov  8 17:01:24.904: INFO: DaemonSet pods can't tolerate node ip-10-0-0-20.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov  8 17:01:24.906: INFO: Number of nodes with available pods: 1
Nov  8 17:01:24.906: INFO: Node ip-10-0-100-224.ec2.internal is running more than one daemon pod
Nov  8 17:01:25.904: INFO: DaemonSet pods can't tolerate node ip-10-0-0-20.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov  8 17:01:25.906: INFO: Number of nodes with available pods: 1
Nov  8 17:01:25.906: INFO: Node ip-10-0-100-224.ec2.internal is running more than one daemon pod
Nov  8 17:01:26.905: INFO: DaemonSet pods can't tolerate node ip-10-0-0-20.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov  8 17:01:26.906: INFO: Number of nodes with available pods: 1
Nov  8 17:01:26.906: INFO: Node ip-10-0-100-224.ec2.internal is running more than one daemon pod
Nov  8 17:01:27.904: INFO: DaemonSet pods can't tolerate node ip-10-0-0-20.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov  8 17:01:27.906: INFO: Number of nodes with available pods: 1
Nov  8 17:01:27.906: INFO: Node ip-10-0-100-224.ec2.internal is running more than one daemon pod
Nov  8 17:01:28.905: INFO: DaemonSet pods can't tolerate node ip-10-0-0-20.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov  8 17:01:28.906: INFO: Number of nodes with available pods: 1
Nov  8 17:01:28.906: INFO: Node ip-10-0-100-224.ec2.internal is running more than one daemon pod
Nov  8 17:01:29.904: INFO: DaemonSet pods can't tolerate node ip-10-0-0-20.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov  8 17:01:29.906: INFO: Number of nodes with available pods: 1
Nov  8 17:01:29.906: INFO: Node ip-10-0-100-224.ec2.internal is running more than one daemon pod
Nov  8 17:01:30.904: INFO: DaemonSet pods can't tolerate node ip-10-0-0-20.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov  8 17:01:30.906: INFO: Number of nodes with available pods: 1
Nov  8 17:01:30.906: INFO: Node ip-10-0-100-224.ec2.internal is running more than one daemon pod
Nov  8 17:01:31.904: INFO: DaemonSet pods can't tolerate node ip-10-0-0-20.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov  8 17:01:31.906: INFO: Number of nodes with available pods: 1
Nov  8 17:01:31.906: INFO: Node ip-10-0-100-224.ec2.internal is running more than one daemon pod
Nov  8 17:01:32.905: INFO: DaemonSet pods can't tolerate node ip-10-0-0-20.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov  8 17:01:32.906: INFO: Number of nodes with available pods: 1
Nov  8 17:01:32.906: INFO: Node ip-10-0-100-224.ec2.internal is running more than one daemon pod
Nov  8 17:01:33.904: INFO: DaemonSet pods can't tolerate node ip-10-0-0-20.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov  8 17:01:33.906: INFO: Number of nodes with available pods: 1
Nov  8 17:01:33.906: INFO: Node ip-10-0-100-224.ec2.internal is running more than one daemon pod
Nov  8 17:01:34.905: INFO: DaemonSet pods can't tolerate node ip-10-0-0-20.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov  8 17:01:34.906: INFO: Number of nodes with available pods: 1
Nov  8 17:01:34.906: INFO: Node ip-10-0-100-224.ec2.internal is running more than one daemon pod
Nov  8 17:01:35.904: INFO: DaemonSet pods can't tolerate node ip-10-0-0-20.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov  8 17:01:35.906: INFO: Number of nodes with available pods: 1
Nov  8 17:01:35.906: INFO: Node ip-10-0-100-224.ec2.internal is running more than one daemon pod
Nov  8 17:01:36.904: INFO: DaemonSet pods can't tolerate node ip-10-0-0-20.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov  8 17:01:36.906: INFO: Number of nodes with available pods: 1
Nov  8 17:01:36.906: INFO: Node ip-10-0-100-224.ec2.internal is running more than one daemon pod
Nov  8 17:01:37.904: INFO: DaemonSet pods can't tolerate node ip-10-0-0-20.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov  8 17:01:37.906: INFO: Number of nodes with available pods: 1
Nov  8 17:01:37.906: INFO: Node ip-10-0-100-224.ec2.internal is running more than one daemon pod
Nov  8 17:01:38.905: INFO: DaemonSet pods can't tolerate node ip-10-0-0-20.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov  8 17:01:38.906: INFO: Number of nodes with available pods: 1
Nov  8 17:01:38.906: INFO: Node ip-10-0-100-224.ec2.internal is running more than one daemon pod
Nov  8 17:01:39.904: INFO: DaemonSet pods can't tolerate node ip-10-0-0-20.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov  8 17:01:39.906: INFO: Number of nodes with available pods: 1
Nov  8 17:01:39.906: INFO: Node ip-10-0-100-224.ec2.internal is running more than one daemon pod
Nov  8 17:01:40.904: INFO: DaemonSet pods can't tolerate node ip-10-0-0-20.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov  8 17:01:40.906: INFO: Number of nodes with available pods: 1
Nov  8 17:01:40.906: INFO: Node ip-10-0-100-224.ec2.internal is running more than one daemon pod
Nov  8 17:01:41.904: INFO: DaemonSet pods can't tolerate node ip-10-0-0-20.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov  8 17:01:41.906: INFO: Number of nodes with available pods: 1
Nov  8 17:01:41.906: INFO: Node ip-10-0-100-224.ec2.internal is running more than one daemon pod
Nov  8 17:01:42.904: INFO: DaemonSet pods can't tolerate node ip-10-0-0-20.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov  8 17:01:42.906: INFO: Number of nodes with available pods: 1
Nov  8 17:01:42.906: INFO: Node ip-10-0-100-224.ec2.internal is running more than one daemon pod
Nov  8 17:01:43.904: INFO: DaemonSet pods can't tolerate node ip-10-0-0-20.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov  8 17:01:43.906: INFO: Number of nodes with available pods: 1
Nov  8 17:01:43.906: INFO: Node ip-10-0-100-224.ec2.internal is running more than one daemon pod
Nov  8 17:01:44.905: INFO: DaemonSet pods can't tolerate node ip-10-0-0-20.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov  8 17:01:44.906: INFO: Number of nodes with available pods: 1
Nov  8 17:01:44.906: INFO: Node ip-10-0-100-224.ec2.internal is running more than one daemon pod
Nov  8 17:01:45.904: INFO: DaemonSet pods can't tolerate node ip-10-0-0-20.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov  8 17:01:45.906: INFO: Number of nodes with available pods: 1
Nov  8 17:01:45.906: INFO: Node ip-10-0-100-224.ec2.internal is running more than one daemon pod
Nov  8 17:01:46.904: INFO: DaemonSet pods can't tolerate node ip-10-0-0-20.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov  8 17:01:46.906: INFO: Number of nodes with available pods: 1
Nov  8 17:01:46.906: INFO: Node ip-10-0-100-224.ec2.internal is running more than one daemon pod
Nov  8 17:01:47.905: INFO: DaemonSet pods can't tolerate node ip-10-0-0-20.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov  8 17:01:47.906: INFO: Number of nodes with available pods: 1
Nov  8 17:01:47.906: INFO: Node ip-10-0-100-224.ec2.internal is running more than one daemon pod
Nov  8 17:01:48.904: INFO: DaemonSet pods can't tolerate node ip-10-0-0-20.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov  8 17:01:48.906: INFO: Number of nodes with available pods: 1
Nov  8 17:01:48.906: INFO: Node ip-10-0-100-224.ec2.internal is running more than one daemon pod
Nov  8 17:01:49.904: INFO: DaemonSet pods can't tolerate node ip-10-0-0-20.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov  8 17:01:49.906: INFO: Number of nodes with available pods: 1
Nov  8 17:01:49.906: INFO: Node ip-10-0-100-224.ec2.internal is running more than one daemon pod
Nov  8 17:01:50.904: INFO: DaemonSet pods can't tolerate node ip-10-0-0-20.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov  8 17:01:50.906: INFO: Number of nodes with available pods: 1
Nov  8 17:01:50.906: INFO: Node ip-10-0-100-224.ec2.internal is running more than one daemon pod
Nov  8 17:01:51.904: INFO: DaemonSet pods can't tolerate node ip-10-0-0-20.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov  8 17:01:51.906: INFO: Number of nodes with available pods: 1
Nov  8 17:01:51.906: INFO: Node ip-10-0-100-224.ec2.internal is running more than one daemon pod
Nov  8 17:01:52.904: INFO: DaemonSet pods can't tolerate node ip-10-0-0-20.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov  8 17:01:52.906: INFO: Number of nodes with available pods: 1
Nov  8 17:01:52.906: INFO: Node ip-10-0-100-224.ec2.internal is running more than one daemon pod
Nov  8 17:01:53.904: INFO: DaemonSet pods can't tolerate node ip-10-0-0-20.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov  8 17:01:53.906: INFO: Number of nodes with available pods: 1
Nov  8 17:01:53.906: INFO: Node ip-10-0-100-224.ec2.internal is running more than one daemon pod
Nov  8 17:01:54.905: INFO: DaemonSet pods can't tolerate node ip-10-0-0-20.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov  8 17:01:54.906: INFO: Number of nodes with available pods: 1
Nov  8 17:01:54.906: INFO: Node ip-10-0-100-224.ec2.internal is running more than one daemon pod
Nov  8 17:01:55.905: INFO: DaemonSet pods can't tolerate node ip-10-0-0-20.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov  8 17:01:55.906: INFO: Number of nodes with available pods: 2
Nov  8 17:01:55.906: INFO: Number of running nodes: 2, number of available pods: 2
[AfterEach] [sig-apps] Daemon set [Serial]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting {extensions DaemonSet} daemon-set in namespace e2e-tests-daemonsets-bxf7s, will wait for the garbage collector to delete the pods
Nov  8 17:01:55.963: INFO: Deleting {extensions DaemonSet} daemon-set took: 3.188973ms
Nov  8 17:01:56.063: INFO: Terminating {extensions DaemonSet} daemon-set pods took: 100.14156ms
Nov  8 17:02:38.664: INFO: Number of nodes with available pods: 0
Nov  8 17:02:38.664: INFO: Number of running nodes: 0, number of available pods: 0
Nov  8 17:02:38.666: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-bxf7s/daemonsets","resourceVersion":"17246"},"items":null}

Nov  8 17:02:38.667: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-bxf7s/pods","resourceVersion":"17246"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  8 17:02:38.672: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-bxf7s" for this suite.
Nov  8 17:02:44.678: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  8 17:02:44.697: INFO: namespace: e2e-tests-daemonsets-bxf7s, resource: bindings, ignored listing per whitelist
Nov  8 17:02:44.730: INFO: namespace e2e-tests-daemonsets-bxf7s deletion completed in 6.056585864s

• [SLOW TEST:85.891 seconds]
[sig-apps] Daemon set [Serial]
/go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should run and stop simple daemon [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] Projected 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  8 17:02:44.730: INFO: >>> kubeConfig: /tmp/kubeconfig-235977939
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with configMap that has name projected-configmap-test-upd-1c737a38-e378-11e8-b0fd-0e97e856486a
STEP: Creating the pod
STEP: Updating configmap projected-configmap-test-upd-1c737a38-e378-11e8-b0fd-0e97e856486a
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  8 17:02:48.796: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-8jjzq" for this suite.
Nov  8 17:03:10.804: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  8 17:03:10.824: INFO: namespace: e2e-tests-projected-8jjzq, resource: bindings, ignored listing per whitelist
Nov  8 17:03:10.858: INFO: namespace e2e-tests-projected-8jjzq deletion completed in 22.059096188s

• [SLOW TEST:26.128 seconds]
[sig-storage] Projected
/go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  updates should be reflected in volume [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  8 17:03:10.858: INFO: >>> kubeConfig: /tmp/kubeconfig-235977939
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Nov  8 17:03:10.900: INFO: Waiting up to 5m0s for pod "downwardapi-volume-2c060a93-e378-11e8-b0fd-0e97e856486a" in namespace "e2e-tests-downward-api-gmgpz" to be "success or failure"
Nov  8 17:03:10.902: INFO: Pod "downwardapi-volume-2c060a93-e378-11e8-b0fd-0e97e856486a": Phase="Pending", Reason="", readiness=false. Elapsed: 1.656301ms
Nov  8 17:03:12.904: INFO: Pod "downwardapi-volume-2c060a93-e378-11e8-b0fd-0e97e856486a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.003523785s
STEP: Saw pod success
Nov  8 17:03:12.904: INFO: Pod "downwardapi-volume-2c060a93-e378-11e8-b0fd-0e97e856486a" satisfied condition "success or failure"
Nov  8 17:03:12.905: INFO: Trying to get logs from node ip-10-0-100-224.ec2.internal pod downwardapi-volume-2c060a93-e378-11e8-b0fd-0e97e856486a container client-container: <nil>
STEP: delete the pod
Nov  8 17:03:12.914: INFO: Waiting for pod downwardapi-volume-2c060a93-e378-11e8-b0fd-0e97e856486a to disappear
Nov  8 17:03:12.916: INFO: Pod downwardapi-volume-2c060a93-e378-11e8-b0fd-0e97e856486a no longer exists
[AfterEach] [sig-storage] Downward API volume
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  8 17:03:12.916: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-gmgpz" for this suite.
Nov  8 17:03:18.923: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  8 17:03:18.971: INFO: namespace: e2e-tests-downward-api-gmgpz, resource: bindings, ignored listing per whitelist
Nov  8 17:03:18.977: INFO: namespace e2e-tests-downward-api-gmgpz deletion completed in 6.058581415s

• [SLOW TEST:8.119 seconds]
[sig-storage] Downward API volume
/go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu request [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  8 17:03:18.977: INFO: >>> kubeConfig: /tmp/kubeconfig-235977939
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Nov  8 17:03:19.016: INFO: Waiting up to 5m0s for pod "downwardapi-volume-30dc7582-e378-11e8-b0fd-0e97e856486a" in namespace "e2e-tests-downward-api-wn4zx" to be "success or failure"
Nov  8 17:03:19.017: INFO: Pod "downwardapi-volume-30dc7582-e378-11e8-b0fd-0e97e856486a": Phase="Pending", Reason="", readiness=false. Elapsed: 1.367981ms
Nov  8 17:03:21.019: INFO: Pod "downwardapi-volume-30dc7582-e378-11e8-b0fd-0e97e856486a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.003244164s
STEP: Saw pod success
Nov  8 17:03:21.019: INFO: Pod "downwardapi-volume-30dc7582-e378-11e8-b0fd-0e97e856486a" satisfied condition "success or failure"
Nov  8 17:03:21.021: INFO: Trying to get logs from node ip-10-0-100-224.ec2.internal pod downwardapi-volume-30dc7582-e378-11e8-b0fd-0e97e856486a container client-container: <nil>
STEP: delete the pod
Nov  8 17:03:21.030: INFO: Waiting for pod downwardapi-volume-30dc7582-e378-11e8-b0fd-0e97e856486a to disappear
Nov  8 17:03:21.032: INFO: Pod downwardapi-volume-30dc7582-e378-11e8-b0fd-0e97e856486a no longer exists
[AfterEach] [sig-storage] Downward API volume
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  8 17:03:21.032: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-wn4zx" for this suite.
Nov  8 17:03:27.039: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  8 17:03:27.062: INFO: namespace: e2e-tests-downward-api-wn4zx, resource: bindings, ignored listing per whitelist
Nov  8 17:03:27.095: INFO: namespace e2e-tests-downward-api-wn4zx deletion completed in 6.060510178s

• [SLOW TEST:8.118 seconds]
[sig-storage] Downward API volume
/go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's cpu request [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-api-machinery] Watchers 
  should be able to start watching from a specific resource version [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Watchers
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  8 17:03:27.095: INFO: >>> kubeConfig: /tmp/kubeconfig-235977939
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to start watching from a specific resource version [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: modifying the configmap a second time
STEP: deleting the configmap
STEP: creating a watch on configmaps from the resource version returned by the first update
STEP: Expecting to observe notifications for all changes to the configmap after the first update
Nov  8 17:03:27.144: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-resource-version,GenerateName:,Namespace:e2e-tests-watch-mk8vx,SelfLink:/api/v1/namespaces/e2e-tests-watch-mk8vx/configmaps/e2e-watch-test-resource-version,UID:35b3dad1-e378-11e8-a466-0a0beb0244cc,ResourceVersion:17424,Generation:0,CreationTimestamp:2018-11-08 17:03:27 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: from-resource-version,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Nov  8 17:03:27.144: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-resource-version,GenerateName:,Namespace:e2e-tests-watch-mk8vx,SelfLink:/api/v1/namespaces/e2e-tests-watch-mk8vx/configmaps/e2e-watch-test-resource-version,UID:35b3dad1-e378-11e8-a466-0a0beb0244cc,ResourceVersion:17425,Generation:0,CreationTimestamp:2018-11-08 17:03:27 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: from-resource-version,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  8 17:03:27.144: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-mk8vx" for this suite.
Nov  8 17:03:33.151: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  8 17:03:33.171: INFO: namespace: e2e-tests-watch-mk8vx, resource: bindings, ignored listing per whitelist
Nov  8 17:03:33.205: INFO: namespace e2e-tests-watch-mk8vx deletion completed in 6.059684663s

• [SLOW TEST:6.111 seconds]
[sig-api-machinery] Watchers
/go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should be able to start watching from a specific resource version [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  8 17:03:33.205: INFO: >>> kubeConfig: /tmp/kubeconfig-235977939
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-3957bdd8-e378-11e8-b0fd-0e97e856486a
STEP: Creating a pod to test consume configMaps
Nov  8 17:03:33.247: INFO: Waiting up to 5m0s for pod "pod-configmaps-3957fb13-e378-11e8-b0fd-0e97e856486a" in namespace "e2e-tests-configmap-9pjll" to be "success or failure"
Nov  8 17:03:33.249: INFO: Pod "pod-configmaps-3957fb13-e378-11e8-b0fd-0e97e856486a": Phase="Pending", Reason="", readiness=false. Elapsed: 1.974112ms
Nov  8 17:03:35.251: INFO: Pod "pod-configmaps-3957fb13-e378-11e8-b0fd-0e97e856486a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.0041275s
STEP: Saw pod success
Nov  8 17:03:35.251: INFO: Pod "pod-configmaps-3957fb13-e378-11e8-b0fd-0e97e856486a" satisfied condition "success or failure"
Nov  8 17:03:35.253: INFO: Trying to get logs from node ip-10-0-100-224.ec2.internal pod pod-configmaps-3957fb13-e378-11e8-b0fd-0e97e856486a container configmap-volume-test: <nil>
STEP: delete the pod
Nov  8 17:03:35.263: INFO: Waiting for pod pod-configmaps-3957fb13-e378-11e8-b0fd-0e97e856486a to disappear
Nov  8 17:03:35.264: INFO: Pod pod-configmaps-3957fb13-e378-11e8-b0fd-0e97e856486a no longer exists
[AfterEach] [sig-storage] ConfigMap
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  8 17:03:35.264: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-9pjll" for this suite.
Nov  8 17:03:41.272: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  8 17:03:41.303: INFO: namespace: e2e-tests-configmap-9pjll, resource: bindings, ignored listing per whitelist
Nov  8 17:03:41.328: INFO: namespace e2e-tests-configmap-9pjll deletion completed in 6.061833721s

• [SLOW TEST:8.123 seconds]
[sig-storage] ConfigMap
/go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  8 17:03:41.329: INFO: >>> kubeConfig: /tmp/kubeconfig-235977939
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-3e307895-e378-11e8-b0fd-0e97e856486a
STEP: Creating a pod to test consume secrets
Nov  8 17:03:41.378: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-3e30b26c-e378-11e8-b0fd-0e97e856486a" in namespace "e2e-tests-projected-dwhrl" to be "success or failure"
Nov  8 17:03:41.380: INFO: Pod "pod-projected-secrets-3e30b26c-e378-11e8-b0fd-0e97e856486a": Phase="Pending", Reason="", readiness=false. Elapsed: 1.756117ms
Nov  8 17:03:43.383: INFO: Pod "pod-projected-secrets-3e30b26c-e378-11e8-b0fd-0e97e856486a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004169054s
STEP: Saw pod success
Nov  8 17:03:43.383: INFO: Pod "pod-projected-secrets-3e30b26c-e378-11e8-b0fd-0e97e856486a" satisfied condition "success or failure"
Nov  8 17:03:43.384: INFO: Trying to get logs from node ip-10-0-100-224.ec2.internal pod pod-projected-secrets-3e30b26c-e378-11e8-b0fd-0e97e856486a container projected-secret-volume-test: <nil>
STEP: delete the pod
Nov  8 17:03:43.393: INFO: Waiting for pod pod-projected-secrets-3e30b26c-e378-11e8-b0fd-0e97e856486a to disappear
Nov  8 17:03:43.395: INFO: Pod pod-projected-secrets-3e30b26c-e378-11e8-b0fd-0e97e856486a no longer exists
[AfterEach] [sig-storage] Projected
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  8 17:03:43.395: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-dwhrl" for this suite.
Nov  8 17:03:49.402: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  8 17:03:49.439: INFO: namespace: e2e-tests-projected-dwhrl, resource: bindings, ignored listing per whitelist
Nov  8 17:03:49.455: INFO: namespace e2e-tests-projected-dwhrl deletion completed in 6.057976757s

• [SLOW TEST:8.126 seconds]
[sig-storage] Projected
/go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: http [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Networking
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  8 17:03:49.455: INFO: >>> kubeConfig: /tmp/kubeconfig-235977939
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: http [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-hbdtp
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Nov  8 17:03:49.490: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Nov  8 17:04:09.527: INFO: ExecWithOptions {Command:[/bin/sh -c timeout -t 15 curl -g -q -s --connect-timeout 1 http://192.168.1.181:8080/hostName | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-hbdtp PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Nov  8 17:04:09.527: INFO: >>> kubeConfig: /tmp/kubeconfig-235977939
Nov  8 17:04:09.590: INFO: Found all expected endpoints: [netserver-0]
Nov  8 17:04:09.591: INFO: ExecWithOptions {Command:[/bin/sh -c timeout -t 15 curl -g -q -s --connect-timeout 1 http://192.168.2.67:8080/hostName | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-hbdtp PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Nov  8 17:04:09.591: INFO: >>> kubeConfig: /tmp/kubeconfig-235977939
Nov  8 17:04:09.662: INFO: Found all expected endpoints: [netserver-1]
[AfterEach] [sig-network] Networking
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  8 17:04:09.662: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-hbdtp" for this suite.
Nov  8 17:04:31.671: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  8 17:04:31.682: INFO: namespace: e2e-tests-pod-network-test-hbdtp, resource: bindings, ignored listing per whitelist
Nov  8 17:04:31.728: INFO: namespace e2e-tests-pod-network-test-hbdtp deletion completed in 22.063810124s

• [SLOW TEST:42.274 seconds]
[sig-network] Networking
/go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: http [NodeConformance] [Conformance]
    /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with downward pod [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  8 17:04:31.728: INFO: >>> kubeConfig: /tmp/kubeconfig-235977939
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with downward pod [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-downwardapi-x8n7
STEP: Creating a pod to test atomic-volume-subpath
Nov  8 17:04:31.773: INFO: Waiting up to 5m0s for pod "pod-subpath-test-downwardapi-x8n7" in namespace "e2e-tests-subpath-xthqh" to be "success or failure"
Nov  8 17:04:31.775: INFO: Pod "pod-subpath-test-downwardapi-x8n7": Phase="Pending", Reason="", readiness=false. Elapsed: 1.868514ms
Nov  8 17:04:33.777: INFO: Pod "pod-subpath-test-downwardapi-x8n7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.003995311s
Nov  8 17:04:35.779: INFO: Pod "pod-subpath-test-downwardapi-x8n7": Phase="Running", Reason="", readiness=false. Elapsed: 4.00612369s
Nov  8 17:04:37.781: INFO: Pod "pod-subpath-test-downwardapi-x8n7": Phase="Running", Reason="", readiness=false. Elapsed: 6.008348845s
Nov  8 17:04:39.784: INFO: Pod "pod-subpath-test-downwardapi-x8n7": Phase="Running", Reason="", readiness=false. Elapsed: 8.010644245s
Nov  8 17:04:41.785: INFO: Pod "pod-subpath-test-downwardapi-x8n7": Phase="Running", Reason="", readiness=false. Elapsed: 10.012432717s
Nov  8 17:04:43.787: INFO: Pod "pod-subpath-test-downwardapi-x8n7": Phase="Running", Reason="", readiness=false. Elapsed: 12.014398794s
Nov  8 17:04:45.789: INFO: Pod "pod-subpath-test-downwardapi-x8n7": Phase="Running", Reason="", readiness=false. Elapsed: 14.016257778s
Nov  8 17:04:47.791: INFO: Pod "pod-subpath-test-downwardapi-x8n7": Phase="Running", Reason="", readiness=false. Elapsed: 16.018377668s
Nov  8 17:04:49.794: INFO: Pod "pod-subpath-test-downwardapi-x8n7": Phase="Running", Reason="", readiness=false. Elapsed: 18.020586371s
Nov  8 17:04:51.795: INFO: Pod "pod-subpath-test-downwardapi-x8n7": Phase="Running", Reason="", readiness=false. Elapsed: 20.022370079s
Nov  8 17:04:53.798: INFO: Pod "pod-subpath-test-downwardapi-x8n7": Phase="Running", Reason="", readiness=false. Elapsed: 22.024545725s
Nov  8 17:04:55.800: INFO: Pod "pod-subpath-test-downwardapi-x8n7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.0267173s
STEP: Saw pod success
Nov  8 17:04:55.800: INFO: Pod "pod-subpath-test-downwardapi-x8n7" satisfied condition "success or failure"
Nov  8 17:04:55.801: INFO: Trying to get logs from node ip-10-0-100-224.ec2.internal pod pod-subpath-test-downwardapi-x8n7 container test-container-subpath-downwardapi-x8n7: <nil>
STEP: delete the pod
Nov  8 17:04:55.813: INFO: Waiting for pod pod-subpath-test-downwardapi-x8n7 to disappear
Nov  8 17:04:55.814: INFO: Pod pod-subpath-test-downwardapi-x8n7 no longer exists
STEP: Deleting pod pod-subpath-test-downwardapi-x8n7
Nov  8 17:04:55.814: INFO: Deleting pod "pod-subpath-test-downwardapi-x8n7" in namespace "e2e-tests-subpath-xthqh"
[AfterEach] [sig-storage] Subpath
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  8 17:04:55.816: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-xthqh" for this suite.
Nov  8 17:05:01.823: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  8 17:05:01.835: INFO: namespace: e2e-tests-subpath-xthqh, resource: bindings, ignored listing per whitelist
Nov  8 17:05:01.877: INFO: namespace e2e-tests-subpath-xthqh deletion completed in 6.059463024s

• [SLOW TEST:30.148 seconds]
[sig-storage] Subpath
/go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with downward pod [Conformance]
    /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete RS created by deployment when not orphaning [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  8 17:05:01.877: INFO: >>> kubeConfig: /tmp/kubeconfig-235977939
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete RS created by deployment when not orphaning [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for all rs to be garbage collected
STEP: expected 0 rs, got 1 rs
STEP: expected 0 pods, got 2 pods
STEP: Gathering metrics
Nov  8 17:05:02.935: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  8 17:05:02.935: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-7gtk7" for this suite.
Nov  8 17:05:08.943: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  8 17:05:08.957: INFO: namespace: e2e-tests-gc-7gtk7, resource: bindings, ignored listing per whitelist
Nov  8 17:05:08.996: INFO: namespace e2e-tests-gc-7gtk7 deletion completed in 6.058715188s

• [SLOW TEST:7.119 seconds]
[sig-api-machinery] Garbage collector
/go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should delete RS created by deployment when not orphaning [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-network] Services 
  should provide secure master service  [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Services
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  8 17:05:08.996: INFO: >>> kubeConfig: /tmp/kubeconfig-235977939
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:83
[It] should provide secure master service  [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [sig-network] Services
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  8 17:05:09.034: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-services-s4qbq" for this suite.
Nov  8 17:05:15.041: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  8 17:05:15.086: INFO: namespace: e2e-tests-services-s4qbq, resource: bindings, ignored listing per whitelist
Nov  8 17:05:15.094: INFO: namespace e2e-tests-services-s4qbq deletion completed in 6.058318991s
[AfterEach] [sig-network] Services
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:88

• [SLOW TEST:6.098 seconds]
[sig-network] Services
/go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide secure master service  [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[k8s.io] [sig-node] PreStop 
  should call prestop when killing a pod  [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] [sig-node] PreStop
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  8 17:05:15.094: INFO: >>> kubeConfig: /tmp/kubeconfig-235977939
STEP: Building a namespace api object, basename prestop
STEP: Waiting for a default service account to be provisioned in namespace
[It] should call prestop when killing a pod  [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating server pod server in namespace e2e-tests-prestop-b2jfw
STEP: Waiting for pods to come up.
STEP: Creating tester pod tester in namespace e2e-tests-prestop-b2jfw
STEP: Deleting pre-stop pod
Nov  8 17:05:26.157: INFO: Saw: {
	"Hostname": "server",
	"Sent": null,
	"Received": {
		"prestop": 1
	},
	"Errors": null,
	"Log": [
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up."
	],
	"StillContactingPeers": true
}
STEP: Deleting the server pod
[AfterEach] [k8s.io] [sig-node] PreStop
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  8 17:05:26.160: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-prestop-b2jfw" for this suite.
Nov  8 17:06:04.169: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  8 17:06:04.212: INFO: namespace: e2e-tests-prestop-b2jfw, resource: bindings, ignored listing per whitelist
Nov  8 17:06:04.225: INFO: namespace e2e-tests-prestop-b2jfw deletion completed in 38.062147129s

• [SLOW TEST:49.131 seconds]
[k8s.io] [sig-node] PreStop
/go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should call prestop when killing a pod  [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-api-machinery] Secrets 
  should be consumable via the environment [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Secrets
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  8 17:06:04.225: INFO: >>> kubeConfig: /tmp/kubeconfig-235977939
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating secret e2e-tests-secrets-kjhdc/secret-test-935b75fe-e378-11e8-b0fd-0e97e856486a
STEP: Creating a pod to test consume secrets
Nov  8 17:06:04.267: INFO: Waiting up to 5m0s for pod "pod-configmaps-935bb8c1-e378-11e8-b0fd-0e97e856486a" in namespace "e2e-tests-secrets-kjhdc" to be "success or failure"
Nov  8 17:06:04.269: INFO: Pod "pod-configmaps-935bb8c1-e378-11e8-b0fd-0e97e856486a": Phase="Pending", Reason="", readiness=false. Elapsed: 1.854376ms
Nov  8 17:06:06.271: INFO: Pod "pod-configmaps-935bb8c1-e378-11e8-b0fd-0e97e856486a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.003939737s
STEP: Saw pod success
Nov  8 17:06:06.271: INFO: Pod "pod-configmaps-935bb8c1-e378-11e8-b0fd-0e97e856486a" satisfied condition "success or failure"
Nov  8 17:06:06.272: INFO: Trying to get logs from node ip-10-0-100-224.ec2.internal pod pod-configmaps-935bb8c1-e378-11e8-b0fd-0e97e856486a container env-test: <nil>
STEP: delete the pod
Nov  8 17:06:06.282: INFO: Waiting for pod pod-configmaps-935bb8c1-e378-11e8-b0fd-0e97e856486a to disappear
Nov  8 17:06:06.284: INFO: Pod pod-configmaps-935bb8c1-e378-11e8-b0fd-0e97e856486a no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  8 17:06:06.284: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-kjhdc" for this suite.
Nov  8 17:06:12.294: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  8 17:06:12.327: INFO: namespace: e2e-tests-secrets-kjhdc, resource: bindings, ignored listing per whitelist
Nov  8 17:06:12.349: INFO: namespace e2e-tests-secrets-kjhdc deletion completed in 6.060752294s

• [SLOW TEST:8.124 seconds]
[sig-api-machinery] Secrets
/go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:31
  should be consumable via the environment [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates resource limits of pods that are allowed to run  [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  8 17:06:12.349: INFO: >>> kubeConfig: /tmp/kubeconfig-235977939
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:78
Nov  8 17:06:12.388: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Nov  8 17:06:12.391: INFO: Waiting for terminating namespaces to be deleted...
Nov  8 17:06:12.393: INFO: 
Logging pods the kubelet thinks is on node ip-10-0-100-224.ec2.internal before test
Nov  8 17:06:12.396: INFO: coredns-58b9b74789-5dxgw from kube-system started at 2018-11-08 15:08:16 +0000 UTC (1 container statuses recorded)
Nov  8 17:06:12.396: INFO: 	Container coredns ready: true, restart count 0
Nov  8 17:06:12.396: INFO: sonobuoy-systemd-logs-daemon-set-0aa241421f524e19-hj57d from heptio-sonobuoy started at 2018-11-08 16:14:30 +0000 UTC (2 container statuses recorded)
Nov  8 17:06:12.396: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 0
Nov  8 17:06:12.396: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Nov  8 17:06:12.396: INFO: kube-proxy-5cl7l from kube-system started at 2018-11-08 15:08:16 +0000 UTC (1 container statuses recorded)
Nov  8 17:06:12.396: INFO: 	Container kube-proxy ready: true, restart count 0
Nov  8 17:06:12.396: INFO: coredns-58b9b74789-j5cfk from kube-system started at 2018-11-08 15:08:16 +0000 UTC (1 container statuses recorded)
Nov  8 17:06:12.396: INFO: 	Container coredns ready: true, restart count 0
Nov  8 17:06:12.396: INFO: calico-node-v8sh8 from kube-system started at 2018-11-08 15:08:16 +0000 UTC (2 container statuses recorded)
Nov  8 17:06:12.396: INFO: 	Container calico-node ready: true, restart count 0
Nov  8 17:06:12.396: INFO: 	Container install-cni ready: true, restart count 0
Nov  8 17:06:12.396: INFO: 
Logging pods the kubelet thinks is on node ip-10-0-100-254.ec2.internal before test
Nov  8 17:06:12.400: INFO: calico-node-664xs from kube-system started at 2018-11-08 15:08:18 +0000 UTC (2 container statuses recorded)
Nov  8 17:06:12.400: INFO: 	Container calico-node ready: true, restart count 0
Nov  8 17:06:12.400: INFO: 	Container install-cni ready: true, restart count 0
Nov  8 17:06:12.400: INFO: sonobuoy from heptio-sonobuoy started at 2018-11-08 16:14:27 +0000 UTC (1 container statuses recorded)
Nov  8 17:06:12.400: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Nov  8 17:06:12.400: INFO: kube-proxy-b44s9 from kube-system started at 2018-11-08 15:08:18 +0000 UTC (1 container statuses recorded)
Nov  8 17:06:12.400: INFO: 	Container kube-proxy ready: true, restart count 0
Nov  8 17:06:12.400: INFO: sonobuoy-e2e-job-25912574a04a48fb from heptio-sonobuoy started at 2018-11-08 16:14:30 +0000 UTC (2 container statuses recorded)
Nov  8 17:06:12.400: INFO: 	Container e2e ready: true, restart count 0
Nov  8 17:06:12.400: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Nov  8 17:06:12.400: INFO: sonobuoy-systemd-logs-daemon-set-0aa241421f524e19-7g4zn from heptio-sonobuoy started at 2018-11-08 16:14:30 +0000 UTC (2 container statuses recorded)
Nov  8 17:06:12.400: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 0
Nov  8 17:06:12.400: INFO: 	Container sonobuoy-worker ready: true, restart count 0
[It] validates resource limits of pods that are allowed to run  [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: verifying the node has the label node ip-10-0-100-224.ec2.internal
STEP: verifying the node has the label node ip-10-0-100-254.ec2.internal
Nov  8 17:06:12.416: INFO: Pod sonobuoy requesting resource cpu=0m on Node ip-10-0-100-254.ec2.internal
Nov  8 17:06:12.416: INFO: Pod sonobuoy-e2e-job-25912574a04a48fb requesting resource cpu=0m on Node ip-10-0-100-254.ec2.internal
Nov  8 17:06:12.416: INFO: Pod sonobuoy-systemd-logs-daemon-set-0aa241421f524e19-7g4zn requesting resource cpu=0m on Node ip-10-0-100-254.ec2.internal
Nov  8 17:06:12.416: INFO: Pod sonobuoy-systemd-logs-daemon-set-0aa241421f524e19-hj57d requesting resource cpu=0m on Node ip-10-0-100-224.ec2.internal
Nov  8 17:06:12.416: INFO: Pod calico-node-664xs requesting resource cpu=250m on Node ip-10-0-100-254.ec2.internal
Nov  8 17:06:12.416: INFO: Pod calico-node-v8sh8 requesting resource cpu=250m on Node ip-10-0-100-224.ec2.internal
Nov  8 17:06:12.416: INFO: Pod coredns-58b9b74789-5dxgw requesting resource cpu=100m on Node ip-10-0-100-224.ec2.internal
Nov  8 17:06:12.416: INFO: Pod coredns-58b9b74789-j5cfk requesting resource cpu=100m on Node ip-10-0-100-224.ec2.internal
Nov  8 17:06:12.416: INFO: Pod kube-proxy-5cl7l requesting resource cpu=0m on Node ip-10-0-100-224.ec2.internal
Nov  8 17:06:12.416: INFO: Pod kube-proxy-b44s9 requesting resource cpu=0m on Node ip-10-0-100-254.ec2.internal
STEP: Starting Pods to consume most of the cluster CPU.
STEP: Creating another pod that requires unavailable amount of CPU.
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-9837b7ea-e378-11e8-b0fd-0e97e856486a.1565350bd7b94176], Reason = [Scheduled], Message = [Successfully assigned e2e-tests-sched-pred-87cp2/filler-pod-9837b7ea-e378-11e8-b0fd-0e97e856486a to ip-10-0-100-224.ec2.internal]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-9837b7ea-e378-11e8-b0fd-0e97e856486a.1565350bfd3f371b], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-9837b7ea-e378-11e8-b0fd-0e97e856486a.1565350c003bf52a], Reason = [Created], Message = [Created container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-9837b7ea-e378-11e8-b0fd-0e97e856486a.1565350c0b01caf3], Reason = [Started], Message = [Started container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-98382308-e378-11e8-b0fd-0e97e856486a.1565350bd7e9e2a6], Reason = [Scheduled], Message = [Successfully assigned e2e-tests-sched-pred-87cp2/filler-pod-98382308-e378-11e8-b0fd-0e97e856486a to ip-10-0-100-254.ec2.internal]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-98382308-e378-11e8-b0fd-0e97e856486a.1565350bfe813344], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-98382308-e378-11e8-b0fd-0e97e856486a.1565350c022713a6], Reason = [Created], Message = [Created container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-98382308-e378-11e8-b0fd-0e97e856486a.1565350c080ab918], Reason = [Started], Message = [Started container]
STEP: Considering event: 
Type = [Warning], Name = [additional-pod.1565350c4fa43d54], Reason = [FailedScheduling], Message = [0/3 nodes are available: 1 node(s) had taints that the pod didn't tolerate, 2 Insufficient cpu.]
STEP: removing the label node off the node ip-10-0-100-224.ec2.internal
STEP: verifying the node doesn't have the label node
STEP: removing the label node off the node ip-10-0-100-254.ec2.internal
STEP: verifying the node doesn't have the label node
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  8 17:06:15.457: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-sched-pred-87cp2" for this suite.
Nov  8 17:06:21.464: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  8 17:06:21.507: INFO: namespace: e2e-tests-sched-pred-87cp2, resource: bindings, ignored listing per whitelist
Nov  8 17:06:21.517: INFO: namespace e2e-tests-sched-pred-87cp2 deletion completed in 6.058511236s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:69

• [SLOW TEST:9.168 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates resource limits of pods that are allowed to run  [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources Simple CustomResourceDefinition 
  creating/deleting custom resource definition objects works  [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  8 17:06:21.517: INFO: >>> kubeConfig: /tmp/kubeconfig-235977939
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Waiting for a default service account to be provisioned in namespace
[It] creating/deleting custom resource definition objects works  [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Nov  8 17:06:21.556: INFO: >>> kubeConfig: /tmp/kubeconfig-235977939
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  8 17:06:22.605: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-custom-resource-definition-4wcbw" for this suite.
Nov  8 17:06:28.613: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  8 17:06:28.660: INFO: namespace: e2e-tests-custom-resource-definition-4wcbw, resource: bindings, ignored listing per whitelist
Nov  8 17:06:28.666: INFO: namespace e2e-tests-custom-resource-definition-4wcbw deletion completed in 6.058171445s

• [SLOW TEST:7.148 seconds]
[sig-api-machinery] CustomResourceDefinition resources
/go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  Simple CustomResourceDefinition
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/custom_resource_definition.go:35
    creating/deleting custom resource definition objects works  [Conformance]
    /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Projected 
  should provide container's cpu request [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  8 17:06:28.666: INFO: >>> kubeConfig: /tmp/kubeconfig-235977939
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Nov  8 17:06:28.704: INFO: Waiting up to 5m0s for pod "downwardapi-volume-a1ec8cc1-e378-11e8-b0fd-0e97e856486a" in namespace "e2e-tests-projected-gqkdw" to be "success or failure"
Nov  8 17:06:28.705: INFO: Pod "downwardapi-volume-a1ec8cc1-e378-11e8-b0fd-0e97e856486a": Phase="Pending", Reason="", readiness=false. Elapsed: 1.370436ms
Nov  8 17:06:30.707: INFO: Pod "downwardapi-volume-a1ec8cc1-e378-11e8-b0fd-0e97e856486a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.003448235s
STEP: Saw pod success
Nov  8 17:06:30.707: INFO: Pod "downwardapi-volume-a1ec8cc1-e378-11e8-b0fd-0e97e856486a" satisfied condition "success or failure"
Nov  8 17:06:30.709: INFO: Trying to get logs from node ip-10-0-100-224.ec2.internal pod downwardapi-volume-a1ec8cc1-e378-11e8-b0fd-0e97e856486a container client-container: <nil>
STEP: delete the pod
Nov  8 17:06:30.718: INFO: Waiting for pod downwardapi-volume-a1ec8cc1-e378-11e8-b0fd-0e97e856486a to disappear
Nov  8 17:06:30.719: INFO: Pod downwardapi-volume-a1ec8cc1-e378-11e8-b0fd-0e97e856486a no longer exists
[AfterEach] [sig-storage] Projected
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  8 17:06:30.720: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-gqkdw" for this suite.
Nov  8 17:06:36.727: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  8 17:06:36.765: INFO: namespace: e2e-tests-projected-gqkdw, resource: bindings, ignored listing per whitelist
Nov  8 17:06:36.780: INFO: namespace e2e-tests-projected-gqkdw deletion completed in 6.058605196s

• [SLOW TEST:8.114 seconds]
[sig-storage] Projected
/go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should provide container's cpu request [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  8 17:06:36.780: INFO: >>> kubeConfig: /tmp/kubeconfig-235977939
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-a6c39baf-e378-11e8-b0fd-0e97e856486a
STEP: Creating a pod to test consume secrets
Nov  8 17:06:36.825: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-a6c3d6fd-e378-11e8-b0fd-0e97e856486a" in namespace "e2e-tests-projected-prbhn" to be "success or failure"
Nov  8 17:06:36.827: INFO: Pod "pod-projected-secrets-a6c3d6fd-e378-11e8-b0fd-0e97e856486a": Phase="Pending", Reason="", readiness=false. Elapsed: 1.452583ms
Nov  8 17:06:38.829: INFO: Pod "pod-projected-secrets-a6c3d6fd-e378-11e8-b0fd-0e97e856486a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.003490964s
STEP: Saw pod success
Nov  8 17:06:38.829: INFO: Pod "pod-projected-secrets-a6c3d6fd-e378-11e8-b0fd-0e97e856486a" satisfied condition "success or failure"
Nov  8 17:06:38.830: INFO: Trying to get logs from node ip-10-0-100-224.ec2.internal pod pod-projected-secrets-a6c3d6fd-e378-11e8-b0fd-0e97e856486a container projected-secret-volume-test: <nil>
STEP: delete the pod
Nov  8 17:06:38.839: INFO: Waiting for pod pod-projected-secrets-a6c3d6fd-e378-11e8-b0fd-0e97e856486a to disappear
Nov  8 17:06:38.841: INFO: Pod pod-projected-secrets-a6c3d6fd-e378-11e8-b0fd-0e97e856486a no longer exists
[AfterEach] [sig-storage] Projected
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  8 17:06:38.841: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-prbhn" for this suite.
Nov  8 17:06:44.848: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  8 17:06:44.860: INFO: namespace: e2e-tests-projected-prbhn, resource: bindings, ignored listing per whitelist
Nov  8 17:06:44.900: INFO: namespace e2e-tests-projected-prbhn deletion completed in 6.057287451s

• [SLOW TEST:8.120 seconds]
[sig-storage] Projected
/go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Docker Containers
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  8 17:06:44.900: INFO: >>> kubeConfig: /tmp/kubeconfig-235977939
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test override command
Nov  8 17:06:44.939: INFO: Waiting up to 5m0s for pod "client-containers-ab99d3f6-e378-11e8-b0fd-0e97e856486a" in namespace "e2e-tests-containers-6vx5p" to be "success or failure"
Nov  8 17:06:44.943: INFO: Pod "client-containers-ab99d3f6-e378-11e8-b0fd-0e97e856486a": Phase="Pending", Reason="", readiness=false. Elapsed: 3.678663ms
Nov  8 17:06:46.945: INFO: Pod "client-containers-ab99d3f6-e378-11e8-b0fd-0e97e856486a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005722546s
STEP: Saw pod success
Nov  8 17:06:46.945: INFO: Pod "client-containers-ab99d3f6-e378-11e8-b0fd-0e97e856486a" satisfied condition "success or failure"
Nov  8 17:06:46.946: INFO: Trying to get logs from node ip-10-0-100-224.ec2.internal pod client-containers-ab99d3f6-e378-11e8-b0fd-0e97e856486a container test-container: <nil>
STEP: delete the pod
Nov  8 17:06:46.955: INFO: Waiting for pod client-containers-ab99d3f6-e378-11e8-b0fd-0e97e856486a to disappear
Nov  8 17:06:46.957: INFO: Pod client-containers-ab99d3f6-e378-11e8-b0fd-0e97e856486a no longer exists
[AfterEach] [k8s.io] Docker Containers
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  8 17:06:46.957: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-6vx5p" for this suite.
Nov  8 17:06:52.964: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  8 17:06:52.972: INFO: namespace: e2e-tests-containers-6vx5p, resource: bindings, ignored listing per whitelist
Nov  8 17:06:53.019: INFO: namespace e2e-tests-containers-6vx5p deletion completed in 6.059691482s

• [SLOW TEST:8.118 seconds]
[k8s.io] Docker Containers
/go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,default) [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  8 17:06:53.019: INFO: >>> kubeConfig: /tmp/kubeconfig-235977939
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,default) [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0666 on node default medium
Nov  8 17:06:53.063: INFO: Waiting up to 5m0s for pod "pod-b0716055-e378-11e8-b0fd-0e97e856486a" in namespace "e2e-tests-emptydir-r7csm" to be "success or failure"
Nov  8 17:06:53.065: INFO: Pod "pod-b0716055-e378-11e8-b0fd-0e97e856486a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.402603ms
Nov  8 17:06:55.067: INFO: Pod "pod-b0716055-e378-11e8-b0fd-0e97e856486a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004572402s
STEP: Saw pod success
Nov  8 17:06:55.067: INFO: Pod "pod-b0716055-e378-11e8-b0fd-0e97e856486a" satisfied condition "success or failure"
Nov  8 17:06:55.069: INFO: Trying to get logs from node ip-10-0-100-224.ec2.internal pod pod-b0716055-e378-11e8-b0fd-0e97e856486a container test-container: <nil>
STEP: delete the pod
Nov  8 17:06:55.077: INFO: Waiting for pod pod-b0716055-e378-11e8-b0fd-0e97e856486a to disappear
Nov  8 17:06:55.078: INFO: Pod pod-b0716055-e378-11e8-b0fd-0e97e856486a no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  8 17:06:55.079: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-r7csm" for this suite.
Nov  8 17:07:01.086: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  8 17:07:01.099: INFO: namespace: e2e-tests-emptydir-r7csm, resource: bindings, ignored listing per whitelist
Nov  8 17:07:01.146: INFO: namespace e2e-tests-emptydir-r7csm deletion completed in 6.065318259s

• [SLOW TEST:8.127 seconds]
[sig-storage] EmptyDir volumes
/go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0666,default) [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if matching  [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  8 17:07:01.146: INFO: >>> kubeConfig: /tmp/kubeconfig-235977939
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:78
Nov  8 17:07:01.184: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Nov  8 17:07:01.187: INFO: Waiting for terminating namespaces to be deleted...
Nov  8 17:07:01.189: INFO: 
Logging pods the kubelet thinks is on node ip-10-0-100-224.ec2.internal before test
Nov  8 17:07:01.192: INFO: coredns-58b9b74789-5dxgw from kube-system started at 2018-11-08 15:08:16 +0000 UTC (1 container statuses recorded)
Nov  8 17:07:01.192: INFO: 	Container coredns ready: true, restart count 0
Nov  8 17:07:01.192: INFO: sonobuoy-systemd-logs-daemon-set-0aa241421f524e19-hj57d from heptio-sonobuoy started at 2018-11-08 16:14:30 +0000 UTC (2 container statuses recorded)
Nov  8 17:07:01.192: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 0
Nov  8 17:07:01.192: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Nov  8 17:07:01.192: INFO: kube-proxy-5cl7l from kube-system started at 2018-11-08 15:08:16 +0000 UTC (1 container statuses recorded)
Nov  8 17:07:01.192: INFO: 	Container kube-proxy ready: true, restart count 0
Nov  8 17:07:01.192: INFO: coredns-58b9b74789-j5cfk from kube-system started at 2018-11-08 15:08:16 +0000 UTC (1 container statuses recorded)
Nov  8 17:07:01.192: INFO: 	Container coredns ready: true, restart count 0
Nov  8 17:07:01.192: INFO: calico-node-v8sh8 from kube-system started at 2018-11-08 15:08:16 +0000 UTC (2 container statuses recorded)
Nov  8 17:07:01.192: INFO: 	Container calico-node ready: true, restart count 0
Nov  8 17:07:01.192: INFO: 	Container install-cni ready: true, restart count 0
Nov  8 17:07:01.192: INFO: 
Logging pods the kubelet thinks is on node ip-10-0-100-254.ec2.internal before test
Nov  8 17:07:01.195: INFO: sonobuoy from heptio-sonobuoy started at 2018-11-08 16:14:27 +0000 UTC (1 container statuses recorded)
Nov  8 17:07:01.195: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Nov  8 17:07:01.195: INFO: kube-proxy-b44s9 from kube-system started at 2018-11-08 15:08:18 +0000 UTC (1 container statuses recorded)
Nov  8 17:07:01.195: INFO: 	Container kube-proxy ready: true, restart count 0
Nov  8 17:07:01.195: INFO: sonobuoy-e2e-job-25912574a04a48fb from heptio-sonobuoy started at 2018-11-08 16:14:30 +0000 UTC (2 container statuses recorded)
Nov  8 17:07:01.195: INFO: 	Container e2e ready: true, restart count 0
Nov  8 17:07:01.195: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Nov  8 17:07:01.195: INFO: sonobuoy-systemd-logs-daemon-set-0aa241421f524e19-7g4zn from heptio-sonobuoy started at 2018-11-08 16:14:30 +0000 UTC (2 container statuses recorded)
Nov  8 17:07:01.195: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 0
Nov  8 17:07:01.195: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Nov  8 17:07:01.195: INFO: calico-node-664xs from kube-system started at 2018-11-08 15:08:18 +0000 UTC (2 container statuses recorded)
Nov  8 17:07:01.195: INFO: 	Container calico-node ready: true, restart count 0
Nov  8 17:07:01.195: INFO: 	Container install-cni ready: true, restart count 0
[It] validates that NodeSelector is respected if matching  [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Trying to launch a pod without a label to get a node which can launch it.
STEP: Explicitly delete pod here to free the resource it takes.
STEP: Trying to apply a random label on the found node.
STEP: verifying the node has the label kubernetes.io/e2e-b67ddf90-e378-11e8-b0fd-0e97e856486a 42
STEP: Trying to relaunch the pod, now with labels.
STEP: removing the label kubernetes.io/e2e-b67ddf90-e378-11e8-b0fd-0e97e856486a off the node ip-10-0-100-224.ec2.internal
STEP: verifying the node doesn't have the label kubernetes.io/e2e-b67ddf90-e378-11e8-b0fd-0e97e856486a
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  8 17:07:05.227: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-sched-pred-lffwx" for this suite.
Nov  8 17:07:17.234: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  8 17:07:17.277: INFO: namespace: e2e-tests-sched-pred-lffwx, resource: bindings, ignored listing per whitelist
Nov  8 17:07:17.287: INFO: namespace e2e-tests-sched-pred-lffwx deletion completed in 12.058189626s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:69

• [SLOW TEST:16.141 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates that NodeSelector is respected if matching  [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected 
  should provide container's memory limit [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  8 17:07:17.287: INFO: >>> kubeConfig: /tmp/kubeconfig-235977939
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Nov  8 17:07:17.328: INFO: Waiting up to 5m0s for pod "downwardapi-volume-bee80d62-e378-11e8-b0fd-0e97e856486a" in namespace "e2e-tests-projected-75rdx" to be "success or failure"
Nov  8 17:07:17.329: INFO: Pod "downwardapi-volume-bee80d62-e378-11e8-b0fd-0e97e856486a": Phase="Pending", Reason="", readiness=false. Elapsed: 1.324195ms
Nov  8 17:07:19.331: INFO: Pod "downwardapi-volume-bee80d62-e378-11e8-b0fd-0e97e856486a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00299148s
STEP: Saw pod success
Nov  8 17:07:19.331: INFO: Pod "downwardapi-volume-bee80d62-e378-11e8-b0fd-0e97e856486a" satisfied condition "success or failure"
Nov  8 17:07:19.333: INFO: Trying to get logs from node ip-10-0-100-224.ec2.internal pod downwardapi-volume-bee80d62-e378-11e8-b0fd-0e97e856486a container client-container: <nil>
STEP: delete the pod
Nov  8 17:07:19.344: INFO: Waiting for pod downwardapi-volume-bee80d62-e378-11e8-b0fd-0e97e856486a to disappear
Nov  8 17:07:19.345: INFO: Pod downwardapi-volume-bee80d62-e378-11e8-b0fd-0e97e856486a no longer exists
[AfterEach] [sig-storage] Projected
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  8 17:07:19.345: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-75rdx" for this suite.
Nov  8 17:07:25.352: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  8 17:07:25.367: INFO: namespace: e2e-tests-projected-75rdx, resource: bindings, ignored listing per whitelist
Nov  8 17:07:25.405: INFO: namespace e2e-tests-projected-75rdx deletion completed in 6.057998369s

• [SLOW TEST:8.118 seconds]
[sig-storage] Projected
/go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should provide container's memory limit [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-auth] ServiceAccounts 
  should mount an API token into pods  [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-auth] ServiceAccounts
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  8 17:07:25.405: INFO: >>> kubeConfig: /tmp/kubeconfig-235977939
STEP: Building a namespace api object, basename svcaccounts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should mount an API token into pods  [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: getting the auto-created API token
STEP: Creating a pod to test consume service account token
Nov  8 17:07:25.954: INFO: Waiting up to 5m0s for pod "pod-service-account-c40c2197-e378-11e8-b0fd-0e97e856486a-wmxww" in namespace "e2e-tests-svcaccounts-qj84r" to be "success or failure"
Nov  8 17:07:25.956: INFO: Pod "pod-service-account-c40c2197-e378-11e8-b0fd-0e97e856486a-wmxww": Phase="Pending", Reason="", readiness=false. Elapsed: 1.641597ms
Nov  8 17:07:27.958: INFO: Pod "pod-service-account-c40c2197-e378-11e8-b0fd-0e97e856486a-wmxww": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.003729734s
STEP: Saw pod success
Nov  8 17:07:27.958: INFO: Pod "pod-service-account-c40c2197-e378-11e8-b0fd-0e97e856486a-wmxww" satisfied condition "success or failure"
Nov  8 17:07:27.959: INFO: Trying to get logs from node ip-10-0-100-254.ec2.internal pod pod-service-account-c40c2197-e378-11e8-b0fd-0e97e856486a-wmxww container token-test: <nil>
STEP: delete the pod
Nov  8 17:07:27.971: INFO: Waiting for pod pod-service-account-c40c2197-e378-11e8-b0fd-0e97e856486a-wmxww to disappear
Nov  8 17:07:27.973: INFO: Pod pod-service-account-c40c2197-e378-11e8-b0fd-0e97e856486a-wmxww no longer exists
STEP: Creating a pod to test consume service account root CA
Nov  8 17:07:27.977: INFO: Waiting up to 5m0s for pod "pod-service-account-c40c2197-e378-11e8-b0fd-0e97e856486a-pbwhh" in namespace "e2e-tests-svcaccounts-qj84r" to be "success or failure"
Nov  8 17:07:27.979: INFO: Pod "pod-service-account-c40c2197-e378-11e8-b0fd-0e97e856486a-pbwhh": Phase="Pending", Reason="", readiness=false. Elapsed: 2.130134ms
Nov  8 17:07:29.981: INFO: Pod "pod-service-account-c40c2197-e378-11e8-b0fd-0e97e856486a-pbwhh": Phase="Running", Reason="", readiness=false. Elapsed: 2.004253881s
Nov  8 17:07:31.983: INFO: Pod "pod-service-account-c40c2197-e378-11e8-b0fd-0e97e856486a-pbwhh": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.006319512s
STEP: Saw pod success
Nov  8 17:07:31.983: INFO: Pod "pod-service-account-c40c2197-e378-11e8-b0fd-0e97e856486a-pbwhh" satisfied condition "success or failure"
Nov  8 17:07:31.985: INFO: Trying to get logs from node ip-10-0-100-224.ec2.internal pod pod-service-account-c40c2197-e378-11e8-b0fd-0e97e856486a-pbwhh container root-ca-test: <nil>
STEP: delete the pod
Nov  8 17:07:31.996: INFO: Waiting for pod pod-service-account-c40c2197-e378-11e8-b0fd-0e97e856486a-pbwhh to disappear
Nov  8 17:07:31.997: INFO: Pod pod-service-account-c40c2197-e378-11e8-b0fd-0e97e856486a-pbwhh no longer exists
STEP: Creating a pod to test consume service account namespace
Nov  8 17:07:31.999: INFO: Waiting up to 5m0s for pod "pod-service-account-c40c2197-e378-11e8-b0fd-0e97e856486a-v8wbj" in namespace "e2e-tests-svcaccounts-qj84r" to be "success or failure"
Nov  8 17:07:32.000: INFO: Pod "pod-service-account-c40c2197-e378-11e8-b0fd-0e97e856486a-v8wbj": Phase="Pending", Reason="", readiness=false. Elapsed: 1.499372ms
Nov  8 17:07:34.002: INFO: Pod "pod-service-account-c40c2197-e378-11e8-b0fd-0e97e856486a-v8wbj": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.003496988s
STEP: Saw pod success
Nov  8 17:07:34.002: INFO: Pod "pod-service-account-c40c2197-e378-11e8-b0fd-0e97e856486a-v8wbj" satisfied condition "success or failure"
Nov  8 17:07:34.004: INFO: Trying to get logs from node ip-10-0-100-254.ec2.internal pod pod-service-account-c40c2197-e378-11e8-b0fd-0e97e856486a-v8wbj container namespace-test: <nil>
STEP: delete the pod
Nov  8 17:07:34.014: INFO: Waiting for pod pod-service-account-c40c2197-e378-11e8-b0fd-0e97e856486a-v8wbj to disappear
Nov  8 17:07:34.017: INFO: Pod pod-service-account-c40c2197-e378-11e8-b0fd-0e97e856486a-v8wbj no longer exists
[AfterEach] [sig-auth] ServiceAccounts
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  8 17:07:34.017: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-svcaccounts-qj84r" for this suite.
Nov  8 17:07:40.024: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  8 17:07:40.077: INFO: namespace: e2e-tests-svcaccounts-qj84r, resource: bindings, ignored listing per whitelist
Nov  8 17:07:40.080: INFO: namespace e2e-tests-svcaccounts-qj84r deletion completed in 6.060841097s

• [SLOW TEST:14.675 seconds]
[sig-auth] ServiceAccounts
/go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:22
  should mount an API token into pods  [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  8 17:07:40.080: INFO: >>> kubeConfig: /tmp/kubeconfig-235977939
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-cc7e6ea4-e378-11e8-b0fd-0e97e856486a
STEP: Creating a pod to test consume configMaps
Nov  8 17:07:40.126: INFO: Waiting up to 5m0s for pod "pod-configmaps-cc7eb183-e378-11e8-b0fd-0e97e856486a" in namespace "e2e-tests-configmap-zs5xs" to be "success or failure"
Nov  8 17:07:40.128: INFO: Pod "pod-configmaps-cc7eb183-e378-11e8-b0fd-0e97e856486a": Phase="Pending", Reason="", readiness=false. Elapsed: 1.859223ms
Nov  8 17:07:42.129: INFO: Pod "pod-configmaps-cc7eb183-e378-11e8-b0fd-0e97e856486a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.003633791s
STEP: Saw pod success
Nov  8 17:07:42.129: INFO: Pod "pod-configmaps-cc7eb183-e378-11e8-b0fd-0e97e856486a" satisfied condition "success or failure"
Nov  8 17:07:42.131: INFO: Trying to get logs from node ip-10-0-100-224.ec2.internal pod pod-configmaps-cc7eb183-e378-11e8-b0fd-0e97e856486a container configmap-volume-test: <nil>
STEP: delete the pod
Nov  8 17:07:42.142: INFO: Waiting for pod pod-configmaps-cc7eb183-e378-11e8-b0fd-0e97e856486a to disappear
Nov  8 17:07:42.143: INFO: Pod pod-configmaps-cc7eb183-e378-11e8-b0fd-0e97e856486a no longer exists
[AfterEach] [sig-storage] ConfigMap
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  8 17:07:42.143: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-zs5xs" for this suite.
Nov  8 17:07:48.151: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  8 17:07:48.201: INFO: namespace: e2e-tests-configmap-zs5xs, resource: bindings, ignored listing per whitelist
Nov  8 17:07:48.204: INFO: namespace e2e-tests-configmap-zs5xs deletion completed in 6.05889521s

• [SLOW TEST:8.124 seconds]
[sig-storage] ConfigMap
/go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  8 17:07:48.204: INFO: >>> kubeConfig: /tmp/kubeconfig-235977939
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-d15539b4-e378-11e8-b0fd-0e97e856486a
STEP: Creating a pod to test consume configMaps
Nov  8 17:07:48.244: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-d155806d-e378-11e8-b0fd-0e97e856486a" in namespace "e2e-tests-projected-rzxhz" to be "success or failure"
Nov  8 17:07:48.246: INFO: Pod "pod-projected-configmaps-d155806d-e378-11e8-b0fd-0e97e856486a": Phase="Pending", Reason="", readiness=false. Elapsed: 1.323266ms
Nov  8 17:07:50.248: INFO: Pod "pod-projected-configmaps-d155806d-e378-11e8-b0fd-0e97e856486a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.003352407s
STEP: Saw pod success
Nov  8 17:07:50.248: INFO: Pod "pod-projected-configmaps-d155806d-e378-11e8-b0fd-0e97e856486a" satisfied condition "success or failure"
Nov  8 17:07:50.249: INFO: Trying to get logs from node ip-10-0-100-224.ec2.internal pod pod-projected-configmaps-d155806d-e378-11e8-b0fd-0e97e856486a container projected-configmap-volume-test: <nil>
STEP: delete the pod
Nov  8 17:07:50.259: INFO: Waiting for pod pod-projected-configmaps-d155806d-e378-11e8-b0fd-0e97e856486a to disappear
Nov  8 17:07:50.261: INFO: Pod pod-projected-configmaps-d155806d-e378-11e8-b0fd-0e97e856486a no longer exists
[AfterEach] [sig-storage] Projected
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  8 17:07:50.261: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-rzxhz" for this suite.
Nov  8 17:07:56.269: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  8 17:07:56.301: INFO: namespace: e2e-tests-projected-rzxhz, resource: bindings, ignored listing per whitelist
Nov  8 17:07:56.322: INFO: namespace e2e-tests-projected-rzxhz deletion completed in 6.05891794s

• [SLOW TEST:8.118 seconds]
[sig-storage] Projected
/go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run --rm job 
  should create a job from an image, then delete the job  [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  8 17:07:56.322: INFO: >>> kubeConfig: /tmp/kubeconfig-235977939
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should create a job from an image, then delete the job  [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: executing a command with run --rm and attach with stdin
Nov  8 17:07:56.362: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-235977939 --namespace=e2e-tests-kubectl-kxctl run e2e-test-rm-busybox-job --image=docker.io/library/busybox:1.29 --rm=true --generator=job/v1 --restart=OnFailure --attach=true --stdin -- sh -c cat && echo 'stdin closed''
Nov  8 17:07:58.319: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl create instead.\nIf you don't see a command prompt, try pressing enter.\n"
Nov  8 17:07:58.319: INFO: stdout: "abcd1234stdin closed\njob.batch \"e2e-test-rm-busybox-job\" deleted\n"
STEP: verifying the job e2e-test-rm-busybox-job was deleted
[AfterEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  8 17:08:00.323: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-kxctl" for this suite.
Nov  8 17:08:06.330: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  8 17:08:06.385: INFO: namespace: e2e-tests-kubectl-kxctl, resource: bindings, ignored listing per whitelist
Nov  8 17:08:06.386: INFO: namespace e2e-tests-kubectl-kxctl deletion completed in 6.061424675s

• [SLOW TEST:10.064 seconds]
[sig-cli] Kubectl client
/go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run --rm job
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create a job from an image, then delete the job  [Conformance]
    /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] Projected 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  8 17:08:06.386: INFO: >>> kubeConfig: /tmp/kubeconfig-235977939
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name s-test-opt-del-dc2c2f6f-e378-11e8-b0fd-0e97e856486a
STEP: Creating secret with name s-test-opt-upd-dc2c2f97-e378-11e8-b0fd-0e97e856486a
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-dc2c2f6f-e378-11e8-b0fd-0e97e856486a
STEP: Updating secret s-test-opt-upd-dc2c2f97-e378-11e8-b0fd-0e97e856486a
STEP: Creating secret with name s-test-opt-create-dc2c2faa-e378-11e8-b0fd-0e97e856486a
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  8 17:08:10.469: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-g45j9" for this suite.
Nov  8 17:08:32.482: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  8 17:08:32.490: INFO: namespace: e2e-tests-projected-g45j9, resource: bindings, ignored listing per whitelist
Nov  8 17:08:32.537: INFO: namespace e2e-tests-projected-g45j9 deletion completed in 22.065787464s

• [SLOW TEST:26.151 seconds]
[sig-storage] Projected
/go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-api-machinery] Downward API 
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Downward API
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  8 17:08:32.537: INFO: >>> kubeConfig: /tmp/kubeconfig-235977939
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Nov  8 17:08:32.579: INFO: Waiting up to 5m0s for pod "downward-api-ebc24a94-e378-11e8-b0fd-0e97e856486a" in namespace "e2e-tests-downward-api-5pl6z" to be "success or failure"
Nov  8 17:08:32.584: INFO: Pod "downward-api-ebc24a94-e378-11e8-b0fd-0e97e856486a": Phase="Pending", Reason="", readiness=false. Elapsed: 4.737368ms
Nov  8 17:08:34.586: INFO: Pod "downward-api-ebc24a94-e378-11e8-b0fd-0e97e856486a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007110941s
STEP: Saw pod success
Nov  8 17:08:34.586: INFO: Pod "downward-api-ebc24a94-e378-11e8-b0fd-0e97e856486a" satisfied condition "success or failure"
Nov  8 17:08:34.588: INFO: Trying to get logs from node ip-10-0-100-224.ec2.internal pod downward-api-ebc24a94-e378-11e8-b0fd-0e97e856486a container dapi-container: <nil>
STEP: delete the pod
Nov  8 17:08:34.601: INFO: Waiting for pod downward-api-ebc24a94-e378-11e8-b0fd-0e97e856486a to disappear
Nov  8 17:08:34.603: INFO: Pod downward-api-ebc24a94-e378-11e8-b0fd-0e97e856486a no longer exists
[AfterEach] [sig-api-machinery] Downward API
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  8 17:08:34.603: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-5pl6z" for this suite.
Nov  8 17:08:40.611: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  8 17:08:40.629: INFO: namespace: e2e-tests-downward-api-5pl6z, resource: bindings, ignored listing per whitelist
Nov  8 17:08:40.665: INFO: namespace e2e-tests-downward-api-5pl6z deletion completed in 6.059611845s

• [SLOW TEST:8.128 seconds]
[sig-api-machinery] Downward API
/go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl label 
  should update the label on a resource  [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  8 17:08:40.665: INFO: >>> kubeConfig: /tmp/kubeconfig-235977939
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Kubectl label
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1042
STEP: creating the pod
Nov  8 17:08:40.700: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-235977939 create -f - --namespace=e2e-tests-kubectl-hwpf4'
Nov  8 17:08:40.938: INFO: stderr: ""
Nov  8 17:08:40.938: INFO: stdout: "pod/pause created\n"
Nov  8 17:08:40.938: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [pause]
Nov  8 17:08:40.938: INFO: Waiting up to 5m0s for pod "pause" in namespace "e2e-tests-kubectl-hwpf4" to be "running and ready"
Nov  8 17:08:40.940: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 1.481552ms
Nov  8 17:08:42.942: INFO: Pod "pause": Phase="Running", Reason="", readiness=true. Elapsed: 2.003317409s
Nov  8 17:08:42.942: INFO: Pod "pause" satisfied condition "running and ready"
Nov  8 17:08:42.942: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [pause]
[It] should update the label on a resource  [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: adding the label testing-label with value testing-label-value to a pod
Nov  8 17:08:42.942: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-235977939 label pods pause testing-label=testing-label-value --namespace=e2e-tests-kubectl-hwpf4'
Nov  8 17:08:43.005: INFO: stderr: ""
Nov  8 17:08:43.005: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod has the label testing-label with the value testing-label-value
Nov  8 17:08:43.005: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-235977939 get pod pause -L testing-label --namespace=e2e-tests-kubectl-hwpf4'
Nov  8 17:08:43.064: INFO: stderr: ""
Nov  8 17:08:43.065: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          3s    testing-label-value\n"
STEP: removing the label testing-label of a pod
Nov  8 17:08:43.065: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-235977939 label pods pause testing-label- --namespace=e2e-tests-kubectl-hwpf4'
Nov  8 17:08:43.128: INFO: stderr: ""
Nov  8 17:08:43.128: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod doesn't have the label testing-label
Nov  8 17:08:43.128: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-235977939 get pod pause -L testing-label --namespace=e2e-tests-kubectl-hwpf4'
Nov  8 17:08:43.188: INFO: stderr: ""
Nov  8 17:08:43.188: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          3s    \n"
[AfterEach] [k8s.io] Kubectl label
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1048
STEP: using delete to clean up resources
Nov  8 17:08:43.188: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-235977939 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-hwpf4'
Nov  8 17:08:43.251: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Nov  8 17:08:43.251: INFO: stdout: "pod \"pause\" force deleted\n"
Nov  8 17:08:43.251: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-235977939 get rc,svc -l name=pause --no-headers --namespace=e2e-tests-kubectl-hwpf4'
Nov  8 17:08:43.317: INFO: stderr: "No resources found.\n"
Nov  8 17:08:43.317: INFO: stdout: ""
Nov  8 17:08:43.318: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-235977939 get pods -l name=pause --namespace=e2e-tests-kubectl-hwpf4 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Nov  8 17:08:43.377: INFO: stderr: ""
Nov  8 17:08:43.377: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  8 17:08:43.377: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-hwpf4" for this suite.
Nov  8 17:08:49.384: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  8 17:08:49.393: INFO: namespace: e2e-tests-kubectl-hwpf4, resource: bindings, ignored listing per whitelist
Nov  8 17:08:49.486: INFO: namespace e2e-tests-kubectl-hwpf4 deletion completed in 6.106710948s

• [SLOW TEST:8.821 seconds]
[sig-cli] Kubectl client
/go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl label
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should update the label on a resource  [Conformance]
    /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  8 17:08:49.486: INFO: >>> kubeConfig: /tmp/kubeconfig-235977939
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-exec in namespace e2e-tests-container-probe-2kkcb
Nov  8 17:08:51.534: INFO: Started pod liveness-exec in namespace e2e-tests-container-probe-2kkcb
STEP: checking the pod's current state and verifying that restartCount is present
Nov  8 17:08:51.536: INFO: Initial restart count of pod liveness-exec is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  8 17:12:51.783: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-2kkcb" for this suite.
Nov  8 17:12:57.791: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  8 17:12:57.842: INFO: namespace: e2e-tests-container-probe-2kkcb, resource: bindings, ignored listing per whitelist
Nov  8 17:12:57.844: INFO: namespace e2e-tests-container-probe-2kkcb deletion completed in 6.058098236s

• [SLOW TEST:248.357 seconds]
[k8s.io] Probing container
/go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Variable Expansion
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  8 17:12:57.844: INFO: >>> kubeConfig: /tmp/kubeconfig-235977939
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's command [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test substitution in container's command
Nov  8 17:12:57.884: INFO: Waiting up to 5m0s for pod "var-expansion-89e4c6f6-e379-11e8-b0fd-0e97e856486a" in namespace "e2e-tests-var-expansion-wk6d8" to be "success or failure"
Nov  8 17:12:57.887: INFO: Pod "var-expansion-89e4c6f6-e379-11e8-b0fd-0e97e856486a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.858695ms
Nov  8 17:12:59.889: INFO: Pod "var-expansion-89e4c6f6-e379-11e8-b0fd-0e97e856486a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004976049s
STEP: Saw pod success
Nov  8 17:12:59.889: INFO: Pod "var-expansion-89e4c6f6-e379-11e8-b0fd-0e97e856486a" satisfied condition "success or failure"
Nov  8 17:12:59.891: INFO: Trying to get logs from node ip-10-0-100-224.ec2.internal pod var-expansion-89e4c6f6-e379-11e8-b0fd-0e97e856486a container dapi-container: <nil>
STEP: delete the pod
Nov  8 17:12:59.901: INFO: Waiting for pod var-expansion-89e4c6f6-e379-11e8-b0fd-0e97e856486a to disappear
Nov  8 17:12:59.902: INFO: Pod var-expansion-89e4c6f6-e379-11e8-b0fd-0e97e856486a no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  8 17:12:59.902: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-var-expansion-wk6d8" for this suite.
Nov  8 17:13:05.909: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  8 17:13:05.923: INFO: namespace: e2e-tests-var-expansion-wk6d8, resource: bindings, ignored listing per whitelist
Nov  8 17:13:05.962: INFO: namespace e2e-tests-var-expansion-wk6d8 deletion completed in 6.058532655s

• [SLOW TEST:8.119 seconds]
[k8s.io] Variable Expansion
/go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should retry creating failed daemon pods [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  8 17:13:05.963: INFO: >>> kubeConfig: /tmp/kubeconfig-235977939
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should retry creating failed daemon pods [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Nov  8 17:13:06.010: INFO: DaemonSet pods can't tolerate node ip-10-0-0-20.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov  8 17:13:06.012: INFO: Number of nodes with available pods: 0
Nov  8 17:13:06.012: INFO: Node ip-10-0-100-224.ec2.internal is running more than one daemon pod
Nov  8 17:13:07.014: INFO: DaemonSet pods can't tolerate node ip-10-0-0-20.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov  8 17:13:07.016: INFO: Number of nodes with available pods: 0
Nov  8 17:13:07.016: INFO: Node ip-10-0-100-224.ec2.internal is running more than one daemon pod
Nov  8 17:13:08.014: INFO: DaemonSet pods can't tolerate node ip-10-0-0-20.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov  8 17:13:08.016: INFO: Number of nodes with available pods: 2
Nov  8 17:13:08.016: INFO: Number of running nodes: 2, number of available pods: 2
STEP: Set a daemon pod's phase to 'Failed', check that the daemon pod is revived.
Nov  8 17:13:08.023: INFO: DaemonSet pods can't tolerate node ip-10-0-0-20.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov  8 17:13:08.026: INFO: Number of nodes with available pods: 1
Nov  8 17:13:08.026: INFO: Node ip-10-0-100-224.ec2.internal is running more than one daemon pod
Nov  8 17:13:09.029: INFO: DaemonSet pods can't tolerate node ip-10-0-0-20.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov  8 17:13:09.031: INFO: Number of nodes with available pods: 1
Nov  8 17:13:09.031: INFO: Node ip-10-0-100-224.ec2.internal is running more than one daemon pod
Nov  8 17:13:10.029: INFO: DaemonSet pods can't tolerate node ip-10-0-0-20.ec2.internal with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov  8 17:13:10.031: INFO: Number of nodes with available pods: 2
Nov  8 17:13:10.031: INFO: Number of running nodes: 2, number of available pods: 2
STEP: Wait for the failed daemon pod to be completely deleted.
[AfterEach] [sig-apps] Daemon set [Serial]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting {extensions DaemonSet} daemon-set in namespace e2e-tests-daemonsets-rb8w5, will wait for the garbage collector to delete the pods
Nov  8 17:13:10.088: INFO: Deleting {extensions DaemonSet} daemon-set took: 3.145015ms
Nov  8 17:13:10.188: INFO: Terminating {extensions DaemonSet} daemon-set pods took: 100.145106ms
Nov  8 17:13:46.090: INFO: Number of nodes with available pods: 0
Nov  8 17:13:46.090: INFO: Number of running nodes: 0, number of available pods: 0
Nov  8 17:13:46.091: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-rb8w5/daemonsets","resourceVersion":"19238"},"items":null}

Nov  8 17:13:46.092: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-rb8w5/pods","resourceVersion":"19238"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  8 17:13:46.097: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-rb8w5" for this suite.
Nov  8 17:13:52.106: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  8 17:13:52.126: INFO: namespace: e2e-tests-daemonsets-rb8w5, resource: bindings, ignored listing per whitelist
Nov  8 17:13:52.160: INFO: namespace e2e-tests-daemonsets-rb8w5 deletion completed in 6.060838522s

• [SLOW TEST:46.197 seconds]
[sig-apps] Daemon set [Serial]
/go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should retry creating failed daemon pods [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[k8s.io] Probing container 
  should have monotonically increasing restart count [Slow][NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  8 17:13:52.160: INFO: >>> kubeConfig: /tmp/kubeconfig-235977939
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should have monotonically increasing restart count [Slow][NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-http in namespace e2e-tests-container-probe-2zq9j
Nov  8 17:13:54.205: INFO: Started pod liveness-http in namespace e2e-tests-container-probe-2zq9j
STEP: checking the pod's current state and verifying that restartCount is present
Nov  8 17:13:54.207: INFO: Initial restart count of pod liveness-http is 0
Nov  8 17:14:12.226: INFO: Restart count of pod e2e-tests-container-probe-2zq9j/liveness-http is now 1 (18.019415192s elapsed)
Nov  8 17:14:32.246: INFO: Restart count of pod e2e-tests-container-probe-2zq9j/liveness-http is now 2 (38.039494946s elapsed)
Nov  8 17:14:52.270: INFO: Restart count of pod e2e-tests-container-probe-2zq9j/liveness-http is now 3 (58.063269872s elapsed)
Nov  8 17:15:12.296: INFO: Restart count of pod e2e-tests-container-probe-2zq9j/liveness-http is now 4 (1m18.089011024s elapsed)
Nov  8 17:16:12.356: INFO: Restart count of pod e2e-tests-container-probe-2zq9j/liveness-http is now 5 (2m18.148836443s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  8 17:16:12.361: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-2zq9j" for this suite.
Nov  8 17:16:18.368: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  8 17:16:18.378: INFO: namespace: e2e-tests-container-probe-2zq9j, resource: bindings, ignored listing per whitelist
Nov  8 17:16:18.421: INFO: namespace e2e-tests-container-probe-2zq9j deletion completed in 6.057515048s

• [SLOW TEST:146.261 seconds]
[k8s.io] Probing container
/go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should have monotonically increasing restart count [Slow][NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,tmpfs) [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  8 17:16:18.421: INFO: >>> kubeConfig: /tmp/kubeconfig-235977939
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,tmpfs) [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0644 on tmpfs
Nov  8 17:16:18.464: INFO: Waiting up to 5m0s for pod "pod-0172c939-e37a-11e8-b0fd-0e97e856486a" in namespace "e2e-tests-emptydir-747s2" to be "success or failure"
Nov  8 17:16:18.466: INFO: Pod "pod-0172c939-e37a-11e8-b0fd-0e97e856486a": Phase="Pending", Reason="", readiness=false. Elapsed: 1.456545ms
Nov  8 17:16:20.468: INFO: Pod "pod-0172c939-e37a-11e8-b0fd-0e97e856486a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.003457022s
STEP: Saw pod success
Nov  8 17:16:20.468: INFO: Pod "pod-0172c939-e37a-11e8-b0fd-0e97e856486a" satisfied condition "success or failure"
Nov  8 17:16:20.469: INFO: Trying to get logs from node ip-10-0-100-224.ec2.internal pod pod-0172c939-e37a-11e8-b0fd-0e97e856486a container test-container: <nil>
STEP: delete the pod
Nov  8 17:16:20.478: INFO: Waiting for pod pod-0172c939-e37a-11e8-b0fd-0e97e856486a to disappear
Nov  8 17:16:20.480: INFO: Pod pod-0172c939-e37a-11e8-b0fd-0e97e856486a no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  8 17:16:20.480: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-747s2" for this suite.
Nov  8 17:16:26.487: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  8 17:16:26.504: INFO: namespace: e2e-tests-emptydir-747s2, resource: bindings, ignored listing per whitelist
Nov  8 17:16:26.540: INFO: namespace e2e-tests-emptydir-747s2 deletion completed in 6.058285538s

• [SLOW TEST:8.120 seconds]
[sig-storage] EmptyDir volumes
/go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0644,tmpfs) [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: http [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Networking
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  8 17:16:26.540: INFO: >>> kubeConfig: /tmp/kubeconfig-235977939
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: http [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-ljbvd
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Nov  8 17:16:26.576: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Nov  8 17:16:48.606: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://192.168.1.208:8080/dial?request=hostName&protocol=http&host=192.168.2.73&port=8080&tries=1'] Namespace:e2e-tests-pod-network-test-ljbvd PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Nov  8 17:16:48.606: INFO: >>> kubeConfig: /tmp/kubeconfig-235977939
Nov  8 17:16:48.678: INFO: Waiting for endpoints: map[]
Nov  8 17:16:48.679: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://192.168.1.208:8080/dial?request=hostName&protocol=http&host=192.168.1.207&port=8080&tries=1'] Namespace:e2e-tests-pod-network-test-ljbvd PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Nov  8 17:16:48.679: INFO: >>> kubeConfig: /tmp/kubeconfig-235977939
Nov  8 17:16:48.748: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  8 17:16:48.749: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-ljbvd" for this suite.
Nov  8 17:17:10.756: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  8 17:17:10.769: INFO: namespace: e2e-tests-pod-network-test-ljbvd, resource: bindings, ignored listing per whitelist
Nov  8 17:17:10.810: INFO: namespace e2e-tests-pod-network-test-ljbvd deletion completed in 22.059195549s

• [SLOW TEST:44.270 seconds]
[sig-network] Networking
/go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: http [NodeConformance] [Conformance]
    /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[k8s.io] Pods 
  should be submitted and removed [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  8 17:17:10.810: INFO: >>> kubeConfig: /tmp/kubeconfig-235977939
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should be submitted and removed [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: setting up watch
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: verifying pod creation was observed
Nov  8 17:17:12.859: INFO: running pod: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-submit-remove-20ac5631-e37a-11e8-b0fd-0e97e856486a", GenerateName:"", Namespace:"e2e-tests-pods-cm57r", SelfLink:"/api/v1/namespaces/e2e-tests-pods-cm57r/pods/pod-submit-remove-20ac5631-e37a-11e8-b0fd-0e97e856486a", UID:"20ad2d95-e37a-11e8-a466-0a0beb0244cc", ResourceVersion:"19757", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63677294230, loc:(*time.Location)(0x6c10bc0)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"848059878"}, Annotations:map[string]string{"cni.projectcalico.org/podIP":"192.168.1.209/32"}, OwnerReferences:[]v1.OwnerReference(nil), Initializers:(*v1.Initializers)(nil), Finalizers:[]string(nil), ClusterName:""}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"default-token-z9qsk", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(0xc421b4b840), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil)}}}, InitContainers:[]v1.Container(nil), Containers:[]v1.Container{v1.Container{Name:"nginx", Image:"docker.io/library/nginx:1.14-alpine", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-z9qsk", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc421a905a8), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"ip-10-0-100-224.ec2.internal", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc421b0e2a0), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc421a905e0)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc421a90600)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc421a90608), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil)}, Status:v1.PodStatus{Phase:"Running", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63677294230, loc:(*time.Location)(0x6c10bc0)}}, Reason:"", Message:""}, v1.PodCondition{Type:"Ready", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63677294232, loc:(*time.Location)(0x6c10bc0)}}, Reason:"", Message:""}, v1.PodCondition{Type:"ContainersReady", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63677294232, loc:(*time.Location)(0x6c10bc0)}}, Reason:"", Message:""}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63677294230, loc:(*time.Location)(0x6c10bc0)}}, Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"10.0.100.224", PodIP:"192.168.1.209", StartTime:(*v1.Time)(0xc42219f3e0), InitContainerStatuses:[]v1.ContainerStatus(nil), ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"nginx", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(0xc42219f400), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:true, RestartCount:0, Image:"nginx:1.14-alpine", ImageID:"docker-pullable://nginx@sha256:75cf17cdf89cbd8da65c83050ebdab1026b98cf217442d6a1f2a8892f47967d7", ContainerID:"docker://d04b550b4eafc25c60046934519f9b0c87aa2818a887a4338f1e81d24f20a749"}}, QOSClass:"BestEffort"}}
STEP: deleting the pod gracefully
STEP: verifying the kubelet observed the termination notice
Nov  8 17:17:17.866: INFO: no pod exists with the name we were looking for, assuming the termination request was observed and completed
STEP: verifying pod deletion was observed
[AfterEach] [k8s.io] Pods
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  8 17:17:17.868: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-cm57r" for this suite.
Nov  8 17:17:23.875: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  8 17:17:23.926: INFO: namespace: e2e-tests-pods-cm57r, resource: bindings, ignored listing per whitelist
Nov  8 17:17:23.929: INFO: namespace e2e-tests-pods-cm57r deletion completed in 6.059000449s

• [SLOW TEST:13.119 seconds]
[k8s.io] Pods
/go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be submitted and removed [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for services  [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] DNS
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  8 17:17:23.929: INFO: >>> kubeConfig: /tmp/kubeconfig-235977939
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for services  [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(dig +notcp +noall +answer +search dns-test-service A)" && echo OK > /results/wheezy_udp@dns-test-service;test -n "$$(dig +tcp +noall +answer +search dns-test-service A)" && echo OK > /results/wheezy_tcp@dns-test-service;test -n "$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-kj9f8 A)" && echo OK > /results/wheezy_udp@dns-test-service.e2e-tests-dns-kj9f8;test -n "$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-kj9f8 A)" && echo OK > /results/wheezy_tcp@dns-test-service.e2e-tests-dns-kj9f8;test -n "$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-kj9f8.svc A)" && echo OK > /results/wheezy_udp@dns-test-service.e2e-tests-dns-kj9f8.svc;test -n "$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-kj9f8.svc A)" && echo OK > /results/wheezy_tcp@dns-test-service.e2e-tests-dns-kj9f8.svc;test -n "$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-kj9f8.svc SRV)" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.e2e-tests-dns-kj9f8.svc;test -n "$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-kj9f8.svc SRV)" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.e2e-tests-dns-kj9f8.svc;test -n "$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-kj9f8.svc SRV)" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.e2e-tests-dns-kj9f8.svc;test -n "$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-kj9f8.svc SRV)" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.e2e-tests-dns-kj9f8.svc;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-kj9f8.pod.cluster.local"}');test -n "$$(dig +notcp +noall +answer +search $${podARec} A)" && echo OK > /results/wheezy_udp@PodARecord;test -n "$$(dig +tcp +noall +answer +search $${podARec} A)" && echo OK > /results/wheezy_tcp@PodARecord;test -n "$$(dig +notcp +noall +answer +search 222.36.110.10.in-addr.arpa. PTR)" && echo OK > /results/10.110.36.222_udp@PTR;test -n "$$(dig +tcp +noall +answer +search 222.36.110.10.in-addr.arpa. PTR)" && echo OK > /results/10.110.36.222_tcp@PTR;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(dig +notcp +noall +answer +search dns-test-service A)" && echo OK > /results/jessie_udp@dns-test-service;test -n "$$(dig +tcp +noall +answer +search dns-test-service A)" && echo OK > /results/jessie_tcp@dns-test-service;test -n "$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-kj9f8 A)" && echo OK > /results/jessie_udp@dns-test-service.e2e-tests-dns-kj9f8;test -n "$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-kj9f8 A)" && echo OK > /results/jessie_tcp@dns-test-service.e2e-tests-dns-kj9f8;test -n "$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-kj9f8.svc A)" && echo OK > /results/jessie_udp@dns-test-service.e2e-tests-dns-kj9f8.svc;test -n "$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-kj9f8.svc A)" && echo OK > /results/jessie_tcp@dns-test-service.e2e-tests-dns-kj9f8.svc;test -n "$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-kj9f8.svc SRV)" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-kj9f8.svc;test -n "$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-kj9f8.svc SRV)" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-kj9f8.svc;test -n "$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-kj9f8.svc SRV)" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.e2e-tests-dns-kj9f8.svc;test -n "$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-kj9f8.svc SRV)" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.e2e-tests-dns-kj9f8.svc;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-kj9f8.pod.cluster.local"}');test -n "$$(dig +notcp +noall +answer +search $${podARec} A)" && echo OK > /results/jessie_udp@PodARecord;test -n "$$(dig +tcp +noall +answer +search $${podARec} A)" && echo OK > /results/jessie_tcp@PodARecord;test -n "$$(dig +notcp +noall +answer +search 222.36.110.10.in-addr.arpa. PTR)" && echo OK > /results/10.110.36.222_udp@PTR;test -n "$$(dig +tcp +noall +answer +search 222.36.110.10.in-addr.arpa. PTR)" && echo OK > /results/10.110.36.222_tcp@PTR;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Nov  8 17:17:35.990: INFO: Unable to read wheezy_tcp@dns-test-service from pod e2e-tests-dns-kj9f8/dns-test-287f98e1-e37a-11e8-b0fd-0e97e856486a: the server could not find the requested resource (get pods dns-test-287f98e1-e37a-11e8-b0fd-0e97e856486a)
Nov  8 17:17:36.010: INFO: Unable to read jessie_udp@dns-test-service from pod e2e-tests-dns-kj9f8/dns-test-287f98e1-e37a-11e8-b0fd-0e97e856486a: the server could not find the requested resource (get pods dns-test-287f98e1-e37a-11e8-b0fd-0e97e856486a)
Nov  8 17:17:36.011: INFO: Unable to read jessie_tcp@dns-test-service from pod e2e-tests-dns-kj9f8/dns-test-287f98e1-e37a-11e8-b0fd-0e97e856486a: the server could not find the requested resource (get pods dns-test-287f98e1-e37a-11e8-b0fd-0e97e856486a)
Nov  8 17:17:36.013: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-kj9f8 from pod e2e-tests-dns-kj9f8/dns-test-287f98e1-e37a-11e8-b0fd-0e97e856486a: the server could not find the requested resource (get pods dns-test-287f98e1-e37a-11e8-b0fd-0e97e856486a)
Nov  8 17:17:36.015: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-kj9f8 from pod e2e-tests-dns-kj9f8/dns-test-287f98e1-e37a-11e8-b0fd-0e97e856486a: the server could not find the requested resource (get pods dns-test-287f98e1-e37a-11e8-b0fd-0e97e856486a)
Nov  8 17:17:36.016: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-kj9f8.svc from pod e2e-tests-dns-kj9f8/dns-test-287f98e1-e37a-11e8-b0fd-0e97e856486a: the server could not find the requested resource (get pods dns-test-287f98e1-e37a-11e8-b0fd-0e97e856486a)
Nov  8 17:17:36.018: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-kj9f8.svc from pod e2e-tests-dns-kj9f8/dns-test-287f98e1-e37a-11e8-b0fd-0e97e856486a: the server could not find the requested resource (get pods dns-test-287f98e1-e37a-11e8-b0fd-0e97e856486a)
Nov  8 17:17:36.020: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-kj9f8.svc from pod e2e-tests-dns-kj9f8/dns-test-287f98e1-e37a-11e8-b0fd-0e97e856486a: the server could not find the requested resource (get pods dns-test-287f98e1-e37a-11e8-b0fd-0e97e856486a)
Nov  8 17:17:36.021: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-kj9f8.svc from pod e2e-tests-dns-kj9f8/dns-test-287f98e1-e37a-11e8-b0fd-0e97e856486a: the server could not find the requested resource (get pods dns-test-287f98e1-e37a-11e8-b0fd-0e97e856486a)
Nov  8 17:17:36.031: INFO: Lookups using e2e-tests-dns-kj9f8/dns-test-287f98e1-e37a-11e8-b0fd-0e97e856486a failed for: [wheezy_tcp@dns-test-service jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.e2e-tests-dns-kj9f8 jessie_tcp@dns-test-service.e2e-tests-dns-kj9f8 jessie_udp@dns-test-service.e2e-tests-dns-kj9f8.svc jessie_tcp@dns-test-service.e2e-tests-dns-kj9f8.svc jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-kj9f8.svc jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-kj9f8.svc]

Nov  8 17:17:45.990: INFO: Unable to read wheezy_tcp@dns-test-service from pod e2e-tests-dns-kj9f8/dns-test-287f98e1-e37a-11e8-b0fd-0e97e856486a: the server could not find the requested resource (get pods dns-test-287f98e1-e37a-11e8-b0fd-0e97e856486a)
Nov  8 17:17:46.012: INFO: Unable to read jessie_udp@dns-test-service from pod e2e-tests-dns-kj9f8/dns-test-287f98e1-e37a-11e8-b0fd-0e97e856486a: the server could not find the requested resource (get pods dns-test-287f98e1-e37a-11e8-b0fd-0e97e856486a)
Nov  8 17:17:46.014: INFO: Unable to read jessie_tcp@dns-test-service from pod e2e-tests-dns-kj9f8/dns-test-287f98e1-e37a-11e8-b0fd-0e97e856486a: the server could not find the requested resource (get pods dns-test-287f98e1-e37a-11e8-b0fd-0e97e856486a)
Nov  8 17:17:46.015: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-kj9f8 from pod e2e-tests-dns-kj9f8/dns-test-287f98e1-e37a-11e8-b0fd-0e97e856486a: the server could not find the requested resource (get pods dns-test-287f98e1-e37a-11e8-b0fd-0e97e856486a)
Nov  8 17:17:46.017: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-kj9f8 from pod e2e-tests-dns-kj9f8/dns-test-287f98e1-e37a-11e8-b0fd-0e97e856486a: the server could not find the requested resource (get pods dns-test-287f98e1-e37a-11e8-b0fd-0e97e856486a)
Nov  8 17:17:46.018: INFO: Unable to read jessie_udp@dns-test-service.e2e-tests-dns-kj9f8.svc from pod e2e-tests-dns-kj9f8/dns-test-287f98e1-e37a-11e8-b0fd-0e97e856486a: the server could not find the requested resource (get pods dns-test-287f98e1-e37a-11e8-b0fd-0e97e856486a)
Nov  8 17:17:46.020: INFO: Unable to read jessie_tcp@dns-test-service.e2e-tests-dns-kj9f8.svc from pod e2e-tests-dns-kj9f8/dns-test-287f98e1-e37a-11e8-b0fd-0e97e856486a: the server could not find the requested resource (get pods dns-test-287f98e1-e37a-11e8-b0fd-0e97e856486a)
Nov  8 17:17:46.022: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-kj9f8.svc from pod e2e-tests-dns-kj9f8/dns-test-287f98e1-e37a-11e8-b0fd-0e97e856486a: the server could not find the requested resource (get pods dns-test-287f98e1-e37a-11e8-b0fd-0e97e856486a)
Nov  8 17:17:46.024: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-kj9f8.svc from pod e2e-tests-dns-kj9f8/dns-test-287f98e1-e37a-11e8-b0fd-0e97e856486a: the server could not find the requested resource (get pods dns-test-287f98e1-e37a-11e8-b0fd-0e97e856486a)
Nov  8 17:17:46.035: INFO: Lookups using e2e-tests-dns-kj9f8/dns-test-287f98e1-e37a-11e8-b0fd-0e97e856486a failed for: [wheezy_tcp@dns-test-service jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.e2e-tests-dns-kj9f8 jessie_tcp@dns-test-service.e2e-tests-dns-kj9f8 jessie_udp@dns-test-service.e2e-tests-dns-kj9f8.svc jessie_tcp@dns-test-service.e2e-tests-dns-kj9f8.svc jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-kj9f8.svc jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-kj9f8.svc]

Nov  8 17:17:56.032: INFO: DNS probes using e2e-tests-dns-kj9f8/dns-test-287f98e1-e37a-11e8-b0fd-0e97e856486a succeeded

STEP: deleting the pod
STEP: deleting the test service
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  8 17:17:56.059: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-dns-kj9f8" for this suite.
Nov  8 17:18:02.069: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  8 17:18:02.102: INFO: namespace: e2e-tests-dns-kj9f8, resource: bindings, ignored listing per whitelist
Nov  8 17:18:02.123: INFO: namespace e2e-tests-dns-kj9f8 deletion completed in 6.061510905s

• [SLOW TEST:38.194 seconds]
[sig-network] DNS
/go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide DNS for services  [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-network] Services 
  should serve multiport endpoints from pods  [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Services
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  8 17:18:02.123: INFO: >>> kubeConfig: /tmp/kubeconfig-235977939
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:83
[It] should serve multiport endpoints from pods  [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating service multi-endpoint-test in namespace e2e-tests-services-ktsvk
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-ktsvk to expose endpoints map[]
Nov  8 17:18:02.169: INFO: Get endpoints failed (1.339511ms elapsed, ignoring for 5s): endpoints "multi-endpoint-test" not found
Nov  8 17:18:03.171: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-ktsvk exposes endpoints map[] (1.003360638s elapsed)
STEP: Creating pod pod1 in namespace e2e-tests-services-ktsvk
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-ktsvk to expose endpoints map[pod1:[100]]
Nov  8 17:18:05.184: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-ktsvk exposes endpoints map[pod1:[100]] (2.010325207s elapsed)
STEP: Creating pod pod2 in namespace e2e-tests-services-ktsvk
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-ktsvk to expose endpoints map[pod1:[100] pod2:[101]]
Nov  8 17:18:07.204: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-ktsvk exposes endpoints map[pod1:[100] pod2:[101]] (2.017258935s elapsed)
STEP: Deleting pod pod1 in namespace e2e-tests-services-ktsvk
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-ktsvk to expose endpoints map[pod2:[101]]
Nov  8 17:18:08.213: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-ktsvk exposes endpoints map[pod2:[101]] (1.006661475s elapsed)
STEP: Deleting pod pod2 in namespace e2e-tests-services-ktsvk
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-ktsvk to expose endpoints map[]
Nov  8 17:18:09.219: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-ktsvk exposes endpoints map[] (1.003031782s elapsed)
[AfterEach] [sig-network] Services
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  8 17:18:09.229: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-services-ktsvk" for this suite.
Nov  8 17:18:31.237: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  8 17:18:31.283: INFO: namespace: e2e-tests-services-ktsvk, resource: bindings, ignored listing per whitelist
Nov  8 17:18:31.293: INFO: namespace e2e-tests-services-ktsvk deletion completed in 22.061470623s
[AfterEach] [sig-network] Services
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:88

• [SLOW TEST:29.170 seconds]
[sig-network] Services
/go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should serve multiport endpoints from pods  [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartNever pod [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  8 17:18:31.293: INFO: >>> kubeConfig: /tmp/kubeconfig-235977939
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should invoke init containers on a RestartNever pod [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
Nov  8 17:18:31.332: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  8 17:18:34.363: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-init-container-tt5bp" for this suite.
Nov  8 17:18:40.371: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  8 17:18:40.376: INFO: namespace: e2e-tests-init-container-tt5bp, resource: bindings, ignored listing per whitelist
Nov  8 17:18:40.426: INFO: namespace e2e-tests-init-container-tt5bp deletion completed in 6.0603003s

• [SLOW TEST:9.133 seconds]
[k8s.io] InitContainer [NodeConformance]
/go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should invoke init containers on a RestartNever pod [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,tmpfs) [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  8 17:18:40.426: INFO: >>> kubeConfig: /tmp/kubeconfig-235977939
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,tmpfs) [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0777 on tmpfs
Nov  8 17:18:40.465: INFO: Waiting up to 5m0s for pod "pod-56167c3f-e37a-11e8-b0fd-0e97e856486a" in namespace "e2e-tests-emptydir-pq4vd" to be "success or failure"
Nov  8 17:18:40.467: INFO: Pod "pod-56167c3f-e37a-11e8-b0fd-0e97e856486a": Phase="Pending", Reason="", readiness=false. Elapsed: 1.451762ms
Nov  8 17:18:42.469: INFO: Pod "pod-56167c3f-e37a-11e8-b0fd-0e97e856486a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.003448523s
STEP: Saw pod success
Nov  8 17:18:42.469: INFO: Pod "pod-56167c3f-e37a-11e8-b0fd-0e97e856486a" satisfied condition "success or failure"
Nov  8 17:18:42.470: INFO: Trying to get logs from node ip-10-0-100-224.ec2.internal pod pod-56167c3f-e37a-11e8-b0fd-0e97e856486a container test-container: <nil>
STEP: delete the pod
Nov  8 17:18:42.482: INFO: Waiting for pod pod-56167c3f-e37a-11e8-b0fd-0e97e856486a to disappear
Nov  8 17:18:42.483: INFO: Pod pod-56167c3f-e37a-11e8-b0fd-0e97e856486a no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  8 17:18:42.483: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-pq4vd" for this suite.
Nov  8 17:18:48.490: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  8 17:18:48.511: INFO: namespace: e2e-tests-emptydir-pq4vd, resource: bindings, ignored listing per whitelist
Nov  8 17:18:48.547: INFO: namespace e2e-tests-emptydir-pq4vd deletion completed in 6.062599547s

• [SLOW TEST:8.122 seconds]
[sig-storage] EmptyDir volumes
/go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0777,tmpfs) [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should set DefaultMode on files [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  8 17:18:48.548: INFO: >>> kubeConfig: /tmp/kubeconfig-235977939
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should set DefaultMode on files [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Nov  8 17:18:48.592: INFO: Waiting up to 5m0s for pod "downwardapi-volume-5aee80bc-e37a-11e8-b0fd-0e97e856486a" in namespace "e2e-tests-downward-api-r9457" to be "success or failure"
Nov  8 17:18:48.593: INFO: Pod "downwardapi-volume-5aee80bc-e37a-11e8-b0fd-0e97e856486a": Phase="Pending", Reason="", readiness=false. Elapsed: 1.230563ms
Nov  8 17:18:50.595: INFO: Pod "downwardapi-volume-5aee80bc-e37a-11e8-b0fd-0e97e856486a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.003310817s
STEP: Saw pod success
Nov  8 17:18:50.595: INFO: Pod "downwardapi-volume-5aee80bc-e37a-11e8-b0fd-0e97e856486a" satisfied condition "success or failure"
Nov  8 17:18:50.597: INFO: Trying to get logs from node ip-10-0-100-224.ec2.internal pod downwardapi-volume-5aee80bc-e37a-11e8-b0fd-0e97e856486a container client-container: <nil>
STEP: delete the pod
Nov  8 17:18:50.606: INFO: Waiting for pod downwardapi-volume-5aee80bc-e37a-11e8-b0fd-0e97e856486a to disappear
Nov  8 17:18:50.607: INFO: Pod downwardapi-volume-5aee80bc-e37a-11e8-b0fd-0e97e856486a no longer exists
[AfterEach] [sig-storage] Downward API volume
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  8 17:18:50.607: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-r9457" for this suite.
Nov  8 17:18:56.615: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  8 17:18:56.619: INFO: namespace: e2e-tests-downward-api-r9457, resource: bindings, ignored listing per whitelist
Nov  8 17:18:56.669: INFO: namespace e2e-tests-downward-api-r9457 deletion completed in 6.059246169s

• [SLOW TEST:8.121 seconds]
[sig-storage] Downward API volume
/go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should set DefaultMode on files [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Secrets 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  8 17:18:56.669: INFO: >>> kubeConfig: /tmp/kubeconfig-235977939
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-5fc50cc9-e37a-11e8-b0fd-0e97e856486a
STEP: Creating a pod to test consume secrets
Nov  8 17:18:56.710: INFO: Waiting up to 5m0s for pod "pod-secrets-5fc5488e-e37a-11e8-b0fd-0e97e856486a" in namespace "e2e-tests-secrets-lkbg5" to be "success or failure"
Nov  8 17:18:56.712: INFO: Pod "pod-secrets-5fc5488e-e37a-11e8-b0fd-0e97e856486a": Phase="Pending", Reason="", readiness=false. Elapsed: 1.797929ms
Nov  8 17:18:58.714: INFO: Pod "pod-secrets-5fc5488e-e37a-11e8-b0fd-0e97e856486a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.003914816s
STEP: Saw pod success
Nov  8 17:18:58.714: INFO: Pod "pod-secrets-5fc5488e-e37a-11e8-b0fd-0e97e856486a" satisfied condition "success or failure"
Nov  8 17:18:58.716: INFO: Trying to get logs from node ip-10-0-100-224.ec2.internal pod pod-secrets-5fc5488e-e37a-11e8-b0fd-0e97e856486a container secret-volume-test: <nil>
STEP: delete the pod
Nov  8 17:18:58.725: INFO: Waiting for pod pod-secrets-5fc5488e-e37a-11e8-b0fd-0e97e856486a to disappear
Nov  8 17:18:58.726: INFO: Pod pod-secrets-5fc5488e-e37a-11e8-b0fd-0e97e856486a no longer exists
[AfterEach] [sig-storage] Secrets
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  8 17:18:58.726: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-lkbg5" for this suite.
Nov  8 17:19:04.734: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  8 17:19:04.782: INFO: namespace: e2e-tests-secrets-lkbg5, resource: bindings, ignored listing per whitelist
Nov  8 17:19:04.787: INFO: namespace e2e-tests-secrets-lkbg5 deletion completed in 6.058285279s

• [SLOW TEST:8.118 seconds]
[sig-storage] Secrets
/go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,tmpfs) [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  8 17:19:04.787: INFO: >>> kubeConfig: /tmp/kubeconfig-235977939
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,tmpfs) [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0666 on tmpfs
Nov  8 17:19:04.828: INFO: Waiting up to 5m0s for pod "pod-649bf33f-e37a-11e8-b0fd-0e97e856486a" in namespace "e2e-tests-emptydir-z87jb" to be "success or failure"
Nov  8 17:19:04.830: INFO: Pod "pod-649bf33f-e37a-11e8-b0fd-0e97e856486a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.132644ms
Nov  8 17:19:06.832: INFO: Pod "pod-649bf33f-e37a-11e8-b0fd-0e97e856486a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00420588s
STEP: Saw pod success
Nov  8 17:19:06.832: INFO: Pod "pod-649bf33f-e37a-11e8-b0fd-0e97e856486a" satisfied condition "success or failure"
Nov  8 17:19:06.834: INFO: Trying to get logs from node ip-10-0-100-224.ec2.internal pod pod-649bf33f-e37a-11e8-b0fd-0e97e856486a container test-container: <nil>
STEP: delete the pod
Nov  8 17:19:06.842: INFO: Waiting for pod pod-649bf33f-e37a-11e8-b0fd-0e97e856486a to disappear
Nov  8 17:19:06.844: INFO: Pod pod-649bf33f-e37a-11e8-b0fd-0e97e856486a no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  8 17:19:06.844: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-z87jb" for this suite.
Nov  8 17:19:12.851: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  8 17:19:12.879: INFO: namespace: e2e-tests-emptydir-z87jb, resource: bindings, ignored listing per whitelist
Nov  8 17:19:12.904: INFO: namespace e2e-tests-emptydir-z87jb deletion completed in 6.059004619s

• [SLOW TEST:8.118 seconds]
[sig-storage] EmptyDir volumes
/go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0666,tmpfs) [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with projected pod [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  8 17:19:12.905: INFO: >>> kubeConfig: /tmp/kubeconfig-235977939
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with projected pod [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-projected-h85b
STEP: Creating a pod to test atomic-volume-subpath
Nov  8 17:19:12.946: INFO: Waiting up to 5m0s for pod "pod-subpath-test-projected-h85b" in namespace "e2e-tests-subpath-clxjm" to be "success or failure"
Nov  8 17:19:12.948: INFO: Pod "pod-subpath-test-projected-h85b": Phase="Pending", Reason="", readiness=false. Elapsed: 1.36681ms
Nov  8 17:19:14.950: INFO: Pod "pod-subpath-test-projected-h85b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.003203462s
Nov  8 17:19:16.952: INFO: Pod "pod-subpath-test-projected-h85b": Phase="Running", Reason="", readiness=false. Elapsed: 4.005335216s
Nov  8 17:19:18.954: INFO: Pod "pod-subpath-test-projected-h85b": Phase="Running", Reason="", readiness=false. Elapsed: 6.007506179s
Nov  8 17:19:20.956: INFO: Pod "pod-subpath-test-projected-h85b": Phase="Running", Reason="", readiness=false. Elapsed: 8.009641664s
Nov  8 17:19:22.958: INFO: Pod "pod-subpath-test-projected-h85b": Phase="Running", Reason="", readiness=false. Elapsed: 10.011716491s
Nov  8 17:19:24.960: INFO: Pod "pod-subpath-test-projected-h85b": Phase="Running", Reason="", readiness=false. Elapsed: 12.01388483s
Nov  8 17:19:26.962: INFO: Pod "pod-subpath-test-projected-h85b": Phase="Running", Reason="", readiness=false. Elapsed: 14.016016754s
Nov  8 17:19:28.965: INFO: Pod "pod-subpath-test-projected-h85b": Phase="Running", Reason="", readiness=false. Elapsed: 16.018146448s
Nov  8 17:19:30.966: INFO: Pod "pod-subpath-test-projected-h85b": Phase="Running", Reason="", readiness=false. Elapsed: 18.02005404s
Nov  8 17:19:32.969: INFO: Pod "pod-subpath-test-projected-h85b": Phase="Running", Reason="", readiness=false. Elapsed: 20.022172465s
Nov  8 17:19:34.971: INFO: Pod "pod-subpath-test-projected-h85b": Phase="Running", Reason="", readiness=false. Elapsed: 22.024257437s
Nov  8 17:19:36.972: INFO: Pod "pod-subpath-test-projected-h85b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.026068056s
STEP: Saw pod success
Nov  8 17:19:36.972: INFO: Pod "pod-subpath-test-projected-h85b" satisfied condition "success or failure"
Nov  8 17:19:36.974: INFO: Trying to get logs from node ip-10-0-100-224.ec2.internal pod pod-subpath-test-projected-h85b container test-container-subpath-projected-h85b: <nil>
STEP: delete the pod
Nov  8 17:19:36.983: INFO: Waiting for pod pod-subpath-test-projected-h85b to disappear
Nov  8 17:19:36.985: INFO: Pod pod-subpath-test-projected-h85b no longer exists
STEP: Deleting pod pod-subpath-test-projected-h85b
Nov  8 17:19:36.985: INFO: Deleting pod "pod-subpath-test-projected-h85b" in namespace "e2e-tests-subpath-clxjm"
[AfterEach] [sig-storage] Subpath
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  8 17:19:36.986: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-clxjm" for this suite.
Nov  8 17:19:42.993: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  8 17:19:43.008: INFO: namespace: e2e-tests-subpath-clxjm, resource: bindings, ignored listing per whitelist
Nov  8 17:19:43.047: INFO: namespace e2e-tests-subpath-clxjm deletion completed in 6.05830637s

• [SLOW TEST:30.142 seconds]
[sig-storage] Subpath
/go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with projected pod [Conformance]
    /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop http hook properly [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  8 17:19:43.047: INFO: >>> kubeConfig: /tmp/kubeconfig-235977939
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop http hook properly [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Nov  8 17:19:47.104: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Nov  8 17:19:47.106: INFO: Pod pod-with-prestop-http-hook still exists
Nov  8 17:19:49.106: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Nov  8 17:19:49.108: INFO: Pod pod-with-prestop-http-hook still exists
Nov  8 17:19:51.106: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Nov  8 17:19:51.108: INFO: Pod pod-with-prestop-http-hook still exists
Nov  8 17:19:53.106: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Nov  8 17:19:53.108: INFO: Pod pod-with-prestop-http-hook still exists
Nov  8 17:19:55.106: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Nov  8 17:19:55.108: INFO: Pod pod-with-prestop-http-hook still exists
Nov  8 17:19:57.106: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Nov  8 17:19:57.108: INFO: Pod pod-with-prestop-http-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  8 17:19:57.113: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-lifecycle-hook-2sfgm" for this suite.
Nov  8 17:20:19.120: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  8 17:20:19.162: INFO: namespace: e2e-tests-container-lifecycle-hook-2sfgm, resource: bindings, ignored listing per whitelist
Nov  8 17:20:19.174: INFO: namespace e2e-tests-container-lifecycle-hook-2sfgm deletion completed in 22.059070062s

• [SLOW TEST:36.127 seconds]
[k8s.io] Container Lifecycle Hook
/go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when create a pod with lifecycle hook
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute prestop http hook properly [NodeConformance] [Conformance]
    /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory request [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  8 17:20:19.174: INFO: >>> kubeConfig: /tmp/kubeconfig-235977939
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's memory request [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Nov  8 17:20:19.215: INFO: Waiting up to 5m0s for pod "downwardapi-volume-90f27e04-e37a-11e8-b0fd-0e97e856486a" in namespace "e2e-tests-downward-api-r6j7k" to be "success or failure"
Nov  8 17:20:19.216: INFO: Pod "downwardapi-volume-90f27e04-e37a-11e8-b0fd-0e97e856486a": Phase="Pending", Reason="", readiness=false. Elapsed: 1.423962ms
Nov  8 17:20:21.218: INFO: Pod "downwardapi-volume-90f27e04-e37a-11e8-b0fd-0e97e856486a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.003459917s
STEP: Saw pod success
Nov  8 17:20:21.218: INFO: Pod "downwardapi-volume-90f27e04-e37a-11e8-b0fd-0e97e856486a" satisfied condition "success or failure"
Nov  8 17:20:21.220: INFO: Trying to get logs from node ip-10-0-100-224.ec2.internal pod downwardapi-volume-90f27e04-e37a-11e8-b0fd-0e97e856486a container client-container: <nil>
STEP: delete the pod
Nov  8 17:20:21.229: INFO: Waiting for pod downwardapi-volume-90f27e04-e37a-11e8-b0fd-0e97e856486a to disappear
Nov  8 17:20:21.231: INFO: Pod downwardapi-volume-90f27e04-e37a-11e8-b0fd-0e97e856486a no longer exists
[AfterEach] [sig-storage] Downward API volume
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  8 17:20:21.232: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-r6j7k" for this suite.
Nov  8 17:20:27.239: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  8 17:20:27.261: INFO: namespace: e2e-tests-downward-api-r6j7k, resource: bindings, ignored listing per whitelist
Nov  8 17:20:27.292: INFO: namespace e2e-tests-downward-api-r6j7k deletion completed in 6.058017471s

• [SLOW TEST:8.117 seconds]
[sig-storage] Downward API volume
/go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's memory request [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  8 17:20:27.292: INFO: >>> kubeConfig: /tmp/kubeconfig-235977939
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name projected-secret-test-95c99cd9-e37a-11e8-b0fd-0e97e856486a
STEP: Creating a pod to test consume secrets
Nov  8 17:20:27.337: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-95c9d7dc-e37a-11e8-b0fd-0e97e856486a" in namespace "e2e-tests-projected-4bwjv" to be "success or failure"
Nov  8 17:20:27.338: INFO: Pod "pod-projected-secrets-95c9d7dc-e37a-11e8-b0fd-0e97e856486a": Phase="Pending", Reason="", readiness=false. Elapsed: 1.339898ms
Nov  8 17:20:29.341: INFO: Pod "pod-projected-secrets-95c9d7dc-e37a-11e8-b0fd-0e97e856486a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.003420812s
STEP: Saw pod success
Nov  8 17:20:29.341: INFO: Pod "pod-projected-secrets-95c9d7dc-e37a-11e8-b0fd-0e97e856486a" satisfied condition "success or failure"
Nov  8 17:20:29.342: INFO: Trying to get logs from node ip-10-0-100-224.ec2.internal pod pod-projected-secrets-95c9d7dc-e37a-11e8-b0fd-0e97e856486a container secret-volume-test: <nil>
STEP: delete the pod
Nov  8 17:20:29.352: INFO: Waiting for pod pod-projected-secrets-95c9d7dc-e37a-11e8-b0fd-0e97e856486a to disappear
Nov  8 17:20:29.357: INFO: Pod pod-projected-secrets-95c9d7dc-e37a-11e8-b0fd-0e97e856486a no longer exists
[AfterEach] [sig-storage] Projected
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  8 17:20:29.357: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-4bwjv" for this suite.
Nov  8 17:20:35.365: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  8 17:20:35.371: INFO: namespace: e2e-tests-projected-4bwjv, resource: bindings, ignored listing per whitelist
Nov  8 17:20:35.418: INFO: namespace e2e-tests-projected-4bwjv deletion completed in 6.05843241s

• [SLOW TEST:8.126 seconds]
[sig-storage] Projected
/go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Proxy server 
  should support --unix-socket=/path  [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  8 17:20:35.418: INFO: >>> kubeConfig: /tmp/kubeconfig-235977939
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should support --unix-socket=/path  [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Starting the proxy
Nov  8 17:20:35.456: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-235977939 proxy --unix-socket=/tmp/kubectl-proxy-unix922731030/test'
STEP: retrieving proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  8 17:20:35.506: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-75dt8" for this suite.
Nov  8 17:20:41.513: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  8 17:20:41.540: INFO: namespace: e2e-tests-kubectl-75dt8, resource: bindings, ignored listing per whitelist
Nov  8 17:20:41.567: INFO: namespace e2e-tests-kubectl-75dt8 deletion completed in 6.058749589s

• [SLOW TEST:6.149 seconds]
[sig-cli] Kubectl client
/go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Proxy server
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should support --unix-socket=/path  [Conformance]
    /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,tmpfs) [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  8 17:20:41.567: INFO: >>> kubeConfig: /tmp/kubeconfig-235977939
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,tmpfs) [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0777 on tmpfs
Nov  8 17:20:41.605: INFO: Waiting up to 5m0s for pod "pod-9e4b08e5-e37a-11e8-b0fd-0e97e856486a" in namespace "e2e-tests-emptydir-92vth" to be "success or failure"
Nov  8 17:20:41.607: INFO: Pod "pod-9e4b08e5-e37a-11e8-b0fd-0e97e856486a": Phase="Pending", Reason="", readiness=false. Elapsed: 1.614121ms
Nov  8 17:20:43.609: INFO: Pod "pod-9e4b08e5-e37a-11e8-b0fd-0e97e856486a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.003783741s
STEP: Saw pod success
Nov  8 17:20:43.609: INFO: Pod "pod-9e4b08e5-e37a-11e8-b0fd-0e97e856486a" satisfied condition "success or failure"
Nov  8 17:20:43.611: INFO: Trying to get logs from node ip-10-0-100-224.ec2.internal pod pod-9e4b08e5-e37a-11e8-b0fd-0e97e856486a container test-container: <nil>
STEP: delete the pod
Nov  8 17:20:43.620: INFO: Waiting for pod pod-9e4b08e5-e37a-11e8-b0fd-0e97e856486a to disappear
Nov  8 17:20:43.622: INFO: Pod pod-9e4b08e5-e37a-11e8-b0fd-0e97e856486a no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  8 17:20:43.622: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-92vth" for this suite.
Nov  8 17:20:49.629: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  8 17:20:49.647: INFO: namespace: e2e-tests-emptydir-92vth, resource: bindings, ignored listing per whitelist
Nov  8 17:20:49.682: INFO: namespace e2e-tests-emptydir-92vth deletion completed in 6.058314321s

• [SLOW TEST:8.115 seconds]
[sig-storage] EmptyDir volumes
/go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0777,tmpfs) [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node using proxy subresource  [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] version v1
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  8 17:20:49.682: INFO: >>> kubeConfig: /tmp/kubeconfig-235977939
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node using proxy subresource  [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Nov  8 17:20:49.724: INFO: (0) /api/v1/nodes/ip-10-0-100-224.ec2.internal/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 3.090567ms)
Nov  8 17:20:49.726: INFO: (1) /api/v1/nodes/ip-10-0-100-224.ec2.internal/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 1.979275ms)
Nov  8 17:20:49.728: INFO: (2) /api/v1/nodes/ip-10-0-100-224.ec2.internal/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 1.948655ms)
Nov  8 17:20:49.730: INFO: (3) /api/v1/nodes/ip-10-0-100-224.ec2.internal/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 1.94725ms)
Nov  8 17:20:49.732: INFO: (4) /api/v1/nodes/ip-10-0-100-224.ec2.internal/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 1.843207ms)
Nov  8 17:20:49.734: INFO: (5) /api/v1/nodes/ip-10-0-100-224.ec2.internal/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 1.751326ms)
Nov  8 17:20:49.736: INFO: (6) /api/v1/nodes/ip-10-0-100-224.ec2.internal/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 1.793274ms)
Nov  8 17:20:49.738: INFO: (7) /api/v1/nodes/ip-10-0-100-224.ec2.internal/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 1.918688ms)
Nov  8 17:20:49.740: INFO: (8) /api/v1/nodes/ip-10-0-100-224.ec2.internal/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 1.85761ms)
Nov  8 17:20:49.742: INFO: (9) /api/v1/nodes/ip-10-0-100-224.ec2.internal/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 1.960161ms)
Nov  8 17:20:49.744: INFO: (10) /api/v1/nodes/ip-10-0-100-224.ec2.internal/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 2.022269ms)
Nov  8 17:20:49.746: INFO: (11) /api/v1/nodes/ip-10-0-100-224.ec2.internal/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 1.980197ms)
Nov  8 17:20:49.747: INFO: (12) /api/v1/nodes/ip-10-0-100-224.ec2.internal/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 1.86121ms)
Nov  8 17:20:49.749: INFO: (13) /api/v1/nodes/ip-10-0-100-224.ec2.internal/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 1.821951ms)
Nov  8 17:20:49.751: INFO: (14) /api/v1/nodes/ip-10-0-100-224.ec2.internal/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 1.809455ms)
Nov  8 17:20:49.753: INFO: (15) /api/v1/nodes/ip-10-0-100-224.ec2.internal/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 1.790853ms)
Nov  8 17:20:49.755: INFO: (16) /api/v1/nodes/ip-10-0-100-224.ec2.internal/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 1.7815ms)
Nov  8 17:20:49.757: INFO: (17) /api/v1/nodes/ip-10-0-100-224.ec2.internal/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 1.888844ms)
Nov  8 17:20:49.759: INFO: (18) /api/v1/nodes/ip-10-0-100-224.ec2.internal/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 1.923541ms)
Nov  8 17:20:49.760: INFO: (19) /api/v1/nodes/ip-10-0-100-224.ec2.internal/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="amazon/">amazon/</a>
<a href="apt/... (200; 1.882422ms)
[AfterEach] version v1
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  8 17:20:49.761: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-proxy-jnk2z" for this suite.
Nov  8 17:20:55.767: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  8 17:20:55.780: INFO: namespace: e2e-tests-proxy-jnk2z, resource: bindings, ignored listing per whitelist
Nov  8 17:20:55.820: INFO: namespace e2e-tests-proxy-jnk2z deletion completed in 6.057614764s

• [SLOW TEST:6.138 seconds]
[sig-network] Proxy
/go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy logs on node using proxy subresource  [Conformance]
    /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  8 17:20:55.820: INFO: >>> kubeConfig: /tmp/kubeconfig-235977939
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-a6ca6ce0-e37a-11e8-b0fd-0e97e856486a
STEP: Creating a pod to test consume configMaps
Nov  8 17:20:55.866: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-a6cb0346-e37a-11e8-b0fd-0e97e856486a" in namespace "e2e-tests-projected-gzd6q" to be "success or failure"
Nov  8 17:20:55.867: INFO: Pod "pod-projected-configmaps-a6cb0346-e37a-11e8-b0fd-0e97e856486a": Phase="Pending", Reason="", readiness=false. Elapsed: 1.430698ms
Nov  8 17:20:57.870: INFO: Pod "pod-projected-configmaps-a6cb0346-e37a-11e8-b0fd-0e97e856486a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.003553652s
STEP: Saw pod success
Nov  8 17:20:57.870: INFO: Pod "pod-projected-configmaps-a6cb0346-e37a-11e8-b0fd-0e97e856486a" satisfied condition "success or failure"
Nov  8 17:20:57.871: INFO: Trying to get logs from node ip-10-0-100-224.ec2.internal pod pod-projected-configmaps-a6cb0346-e37a-11e8-b0fd-0e97e856486a container projected-configmap-volume-test: <nil>
STEP: delete the pod
Nov  8 17:20:57.880: INFO: Waiting for pod pod-projected-configmaps-a6cb0346-e37a-11e8-b0fd-0e97e856486a to disappear
Nov  8 17:20:57.881: INFO: Pod pod-projected-configmaps-a6cb0346-e37a-11e8-b0fd-0e97e856486a no longer exists
[AfterEach] [sig-storage] Projected
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  8 17:20:57.881: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-gzd6q" for this suite.
Nov  8 17:21:03.889: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  8 17:21:03.929: INFO: namespace: e2e-tests-projected-gzd6q, resource: bindings, ignored listing per whitelist
Nov  8 17:21:03.943: INFO: namespace e2e-tests-projected-gzd6q deletion completed in 6.058444891s

• [SLOW TEST:8.123 seconds]
[sig-storage] Projected
/go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should rollback without unnecessary restarts [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  8 17:21:03.943: INFO: >>> kubeConfig: /tmp/kubeconfig-235977939
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should rollback without unnecessary restarts [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Nov  8 17:21:03.992: INFO: Requires at least 2 nodes (not -1)
[AfterEach] [sig-apps] Daemon set [Serial]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
Nov  8 17:21:03.995: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-hrzbw/daemonsets","resourceVersion":"20568"},"items":null}

Nov  8 17:21:03.997: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-hrzbw/pods","resourceVersion":"20568"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  8 17:21:04.001: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-hrzbw" for this suite.
Nov  8 17:21:10.009: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  8 17:21:10.049: INFO: namespace: e2e-tests-daemonsets-hrzbw, resource: bindings, ignored listing per whitelist
Nov  8 17:21:10.063: INFO: namespace e2e-tests-daemonsets-hrzbw deletion completed in 6.058998621s

S [SKIPPING] [6.120 seconds]
[sig-apps] Daemon set [Serial]
/go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should rollback without unnecessary restarts [Conformance] [It]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699

  Nov  8 17:21:03.992: Requires at least 2 nodes (not -1)

  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/util.go:292
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,tmpfs) [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  8 17:21:10.063: INFO: >>> kubeConfig: /tmp/kubeconfig-235977939
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,tmpfs) [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0666 on tmpfs
Nov  8 17:21:10.102: INFO: Waiting up to 5m0s for pod "pod-af473513-e37a-11e8-b0fd-0e97e856486a" in namespace "e2e-tests-emptydir-w65bs" to be "success or failure"
Nov  8 17:21:10.103: INFO: Pod "pod-af473513-e37a-11e8-b0fd-0e97e856486a": Phase="Pending", Reason="", readiness=false. Elapsed: 1.561342ms
Nov  8 17:21:12.106: INFO: Pod "pod-af473513-e37a-11e8-b0fd-0e97e856486a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00465505s
STEP: Saw pod success
Nov  8 17:21:12.106: INFO: Pod "pod-af473513-e37a-11e8-b0fd-0e97e856486a" satisfied condition "success or failure"
Nov  8 17:21:12.109: INFO: Trying to get logs from node ip-10-0-100-224.ec2.internal pod pod-af473513-e37a-11e8-b0fd-0e97e856486a container test-container: <nil>
STEP: delete the pod
Nov  8 17:21:12.120: INFO: Waiting for pod pod-af473513-e37a-11e8-b0fd-0e97e856486a to disappear
Nov  8 17:21:12.122: INFO: Pod pod-af473513-e37a-11e8-b0fd-0e97e856486a no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  8 17:21:12.122: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-w65bs" for this suite.
Nov  8 17:21:18.129: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  8 17:21:18.189: INFO: namespace: e2e-tests-emptydir-w65bs, resource: bindings, ignored listing per whitelist
Nov  8 17:21:18.189: INFO: namespace e2e-tests-emptydir-w65bs deletion completed in 6.065306768s

• [SLOW TEST:8.126 seconds]
[sig-storage] EmptyDir volumes
/go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0666,tmpfs) [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Docker Containers
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  8 17:21:18.189: INFO: >>> kubeConfig: /tmp/kubeconfig-235977939
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test override all
Nov  8 17:21:18.230: INFO: Waiting up to 5m0s for pod "client-containers-b41f8832-e37a-11e8-b0fd-0e97e856486a" in namespace "e2e-tests-containers-bg9rg" to be "success or failure"
Nov  8 17:21:18.231: INFO: Pod "client-containers-b41f8832-e37a-11e8-b0fd-0e97e856486a": Phase="Pending", Reason="", readiness=false. Elapsed: 1.289941ms
Nov  8 17:21:20.234: INFO: Pod "client-containers-b41f8832-e37a-11e8-b0fd-0e97e856486a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.003464791s
STEP: Saw pod success
Nov  8 17:21:20.234: INFO: Pod "client-containers-b41f8832-e37a-11e8-b0fd-0e97e856486a" satisfied condition "success or failure"
Nov  8 17:21:20.235: INFO: Trying to get logs from node ip-10-0-100-224.ec2.internal pod client-containers-b41f8832-e37a-11e8-b0fd-0e97e856486a container test-container: <nil>
STEP: delete the pod
Nov  8 17:21:20.245: INFO: Waiting for pod client-containers-b41f8832-e37a-11e8-b0fd-0e97e856486a to disappear
Nov  8 17:21:20.246: INFO: Pod client-containers-b41f8832-e37a-11e8-b0fd-0e97e856486a no longer exists
[AfterEach] [k8s.io] Docker Containers
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  8 17:21:20.246: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-bg9rg" for this suite.
Nov  8 17:21:26.253: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  8 17:21:26.289: INFO: namespace: e2e-tests-containers-bg9rg, resource: bindings, ignored listing per whitelist
Nov  8 17:21:26.307: INFO: namespace e2e-tests-containers-bg9rg deletion completed in 6.059086099s

• [SLOW TEST:8.118 seconds]
[k8s.io] Docker Containers
/go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  8 17:21:26.307: INFO: >>> kubeConfig: /tmp/kubeconfig-235977939
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-b8f60d27-e37a-11e8-b0fd-0e97e856486a
STEP: Creating a pod to test consume configMaps
Nov  8 17:21:26.349: INFO: Waiting up to 5m0s for pod "pod-configmaps-b8f65171-e37a-11e8-b0fd-0e97e856486a" in namespace "e2e-tests-configmap-tbwlr" to be "success or failure"
Nov  8 17:21:26.351: INFO: Pod "pod-configmaps-b8f65171-e37a-11e8-b0fd-0e97e856486a": Phase="Pending", Reason="", readiness=false. Elapsed: 1.526963ms
Nov  8 17:21:28.353: INFO: Pod "pod-configmaps-b8f65171-e37a-11e8-b0fd-0e97e856486a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.003709059s
STEP: Saw pod success
Nov  8 17:21:28.353: INFO: Pod "pod-configmaps-b8f65171-e37a-11e8-b0fd-0e97e856486a" satisfied condition "success or failure"
Nov  8 17:21:28.355: INFO: Trying to get logs from node ip-10-0-100-224.ec2.internal pod pod-configmaps-b8f65171-e37a-11e8-b0fd-0e97e856486a container configmap-volume-test: <nil>
STEP: delete the pod
Nov  8 17:21:28.364: INFO: Waiting for pod pod-configmaps-b8f65171-e37a-11e8-b0fd-0e97e856486a to disappear
Nov  8 17:21:28.366: INFO: Pod pod-configmaps-b8f65171-e37a-11e8-b0fd-0e97e856486a no longer exists
[AfterEach] [sig-storage] ConfigMap
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  8 17:21:28.366: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-tbwlr" for this suite.
Nov  8 17:21:34.373: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  8 17:21:34.423: INFO: namespace: e2e-tests-configmap-tbwlr, resource: bindings, ignored listing per whitelist
Nov  8 17:21:34.430: INFO: namespace e2e-tests-configmap-tbwlr deletion completed in 6.062407906s

• [SLOW TEST:8.123 seconds]
[sig-storage] ConfigMap
/go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-api-machinery] Garbage collector 
  should not be blocked by dependency circle [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  8 17:21:34.430: INFO: >>> kubeConfig: /tmp/kubeconfig-235977939
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be blocked by dependency circle [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Nov  8 17:21:34.480: INFO: pod1.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod3", UID:"bdcf08dd-e37a-11e8-a466-0a0beb0244cc", Controller:(*bool)(0xc42154b65e), BlockOwnerDeletion:(*bool)(0xc42154b65f)}}
Nov  8 17:21:34.484: INFO: pod2.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod1", UID:"bdce699f-e37a-11e8-a466-0a0beb0244cc", Controller:(*bool)(0xc421ddf1ce), BlockOwnerDeletion:(*bool)(0xc421ddf1cf)}}
Nov  8 17:21:34.487: INFO: pod3.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod2", UID:"bdcea69a-e37a-11e8-a466-0a0beb0244cc", Controller:(*bool)(0xc421ddf4ae), BlockOwnerDeletion:(*bool)(0xc421ddf4af)}}
[AfterEach] [sig-api-machinery] Garbage collector
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  8 17:21:39.495: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-qx2l2" for this suite.
Nov  8 17:21:45.504: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  8 17:21:45.529: INFO: namespace: e2e-tests-gc-qx2l2, resource: bindings, ignored listing per whitelist
Nov  8 17:21:45.559: INFO: namespace e2e-tests-gc-qx2l2 deletion completed in 6.061226651s

• [SLOW TEST:11.128 seconds]
[sig-api-machinery] Garbage collector
/go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should not be blocked by dependency circle [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  8 17:21:45.559: INFO: >>> kubeConfig: /tmp/kubeconfig-235977939
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
Nov  8 17:21:45.598: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  8 17:21:47.474: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-init-container-xxwfs" for this suite.
Nov  8 17:21:53.481: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  8 17:21:53.508: INFO: namespace: e2e-tests-init-container-xxwfs, resource: bindings, ignored listing per whitelist
Nov  8 17:21:53.538: INFO: namespace e2e-tests-init-container-xxwfs deletion completed in 6.061559703s

• [SLOW TEST:7.979 seconds]
[k8s.io] InitContainer [NodeConformance]
/go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] Projected 
  should set mode on item file [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  8 17:21:53.538: INFO: >>> kubeConfig: /tmp/kubeconfig-235977939
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should set mode on item file [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Nov  8 17:21:53.577: INFO: Waiting up to 5m0s for pod "downwardapi-volume-c9310b40-e37a-11e8-b0fd-0e97e856486a" in namespace "e2e-tests-projected-tjht6" to be "success or failure"
Nov  8 17:21:53.579: INFO: Pod "downwardapi-volume-c9310b40-e37a-11e8-b0fd-0e97e856486a": Phase="Pending", Reason="", readiness=false. Elapsed: 1.694842ms
Nov  8 17:21:55.581: INFO: Pod "downwardapi-volume-c9310b40-e37a-11e8-b0fd-0e97e856486a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.003703931s
STEP: Saw pod success
Nov  8 17:21:55.581: INFO: Pod "downwardapi-volume-c9310b40-e37a-11e8-b0fd-0e97e856486a" satisfied condition "success or failure"
Nov  8 17:21:55.583: INFO: Trying to get logs from node ip-10-0-100-224.ec2.internal pod downwardapi-volume-c9310b40-e37a-11e8-b0fd-0e97e856486a container client-container: <nil>
STEP: delete the pod
Nov  8 17:21:55.592: INFO: Waiting for pod downwardapi-volume-c9310b40-e37a-11e8-b0fd-0e97e856486a to disappear
Nov  8 17:21:55.594: INFO: Pod downwardapi-volume-c9310b40-e37a-11e8-b0fd-0e97e856486a no longer exists
[AfterEach] [sig-storage] Projected
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  8 17:21:55.594: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-tjht6" for this suite.
Nov  8 17:22:01.602: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  8 17:22:01.638: INFO: namespace: e2e-tests-projected-tjht6, resource: bindings, ignored listing per whitelist
Nov  8 17:22:01.654: INFO: namespace e2e-tests-projected-tjht6 deletion completed in 6.058791358s

• [SLOW TEST:8.117 seconds]
[sig-storage] Projected
/go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should set mode on item file [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-network] Service endpoints latency 
  should not be very high  [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Service endpoints latency
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  8 17:22:01.655: INFO: >>> kubeConfig: /tmp/kubeconfig-235977939
STEP: Building a namespace api object, basename svc-latency
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be very high  [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating replication controller svc-latency-rc in namespace e2e-tests-svc-latency-nv69p
Nov  8 17:22:02.854: INFO: Created: latency-svc-c79jh
Nov  8 17:22:02.860: INFO: Got endpoints: latency-svc-c79jh [11.876666ms]
Nov  8 17:22:02.868: INFO: Created: latency-svc-r85h4
Nov  8 17:22:02.873: INFO: Got endpoints: latency-svc-r85h4 [12.837072ms]
Nov  8 17:22:02.874: INFO: Created: latency-svc-4tn5f
Nov  8 17:22:02.882: INFO: Created: latency-svc-kndxz
Nov  8 17:22:02.883: INFO: Got endpoints: latency-svc-4tn5f [22.859486ms]
Nov  8 17:22:02.886: INFO: Got endpoints: latency-svc-kndxz [25.587402ms]
Nov  8 17:22:02.889: INFO: Created: latency-svc-tkfbr
Nov  8 17:22:02.890: INFO: Got endpoints: latency-svc-tkfbr [29.814649ms]
Nov  8 17:22:02.899: INFO: Created: latency-svc-dgcvj
Nov  8 17:22:02.900: INFO: Got endpoints: latency-svc-dgcvj [38.801123ms]
Nov  8 17:22:02.905: INFO: Created: latency-svc-ps6qf
Nov  8 17:22:02.912: INFO: Got endpoints: latency-svc-ps6qf [50.688732ms]
Nov  8 17:22:02.915: INFO: Created: latency-svc-crf97
Nov  8 17:22:02.920: INFO: Got endpoints: latency-svc-crf97 [58.880201ms]
Nov  8 17:22:02.924: INFO: Created: latency-svc-r6sj5
Nov  8 17:22:02.931: INFO: Got endpoints: latency-svc-r6sj5 [69.482646ms]
Nov  8 17:22:02.935: INFO: Created: latency-svc-vnbhc
Nov  8 17:22:02.938: INFO: Created: latency-svc-98gdl
Nov  8 17:22:02.938: INFO: Got endpoints: latency-svc-vnbhc [76.921142ms]
Nov  8 17:22:02.943: INFO: Got endpoints: latency-svc-98gdl [82.437052ms]
Nov  8 17:22:02.944: INFO: Created: latency-svc-bwrrn
Nov  8 17:22:02.947: INFO: Got endpoints: latency-svc-bwrrn [86.046854ms]
Nov  8 17:22:02.950: INFO: Created: latency-svc-b4c4x
Nov  8 17:22:02.956: INFO: Got endpoints: latency-svc-b4c4x [94.788199ms]
Nov  8 17:22:02.956: INFO: Created: latency-svc-4s94d
Nov  8 17:22:02.960: INFO: Got endpoints: latency-svc-4s94d [99.492626ms]
Nov  8 17:22:02.966: INFO: Created: latency-svc-pfjrz
Nov  8 17:22:02.969: INFO: Got endpoints: latency-svc-pfjrz [108.196466ms]
Nov  8 17:22:02.973: INFO: Created: latency-svc-cm2w8
Nov  8 17:22:02.973: INFO: Got endpoints: latency-svc-cm2w8 [112.200845ms]
Nov  8 17:22:02.977: INFO: Created: latency-svc-gzhcn
Nov  8 17:22:02.981: INFO: Got endpoints: latency-svc-gzhcn [108.195845ms]
Nov  8 17:22:02.985: INFO: Created: latency-svc-k2wll
Nov  8 17:22:02.988: INFO: Got endpoints: latency-svc-k2wll [104.969431ms]
Nov  8 17:22:02.992: INFO: Created: latency-svc-vwrv7
Nov  8 17:22:02.997: INFO: Got endpoints: latency-svc-vwrv7 [110.835154ms]
Nov  8 17:22:03.001: INFO: Created: latency-svc-lc45n
Nov  8 17:22:03.003: INFO: Got endpoints: latency-svc-lc45n [112.991342ms]
Nov  8 17:22:03.008: INFO: Created: latency-svc-4c5ff
Nov  8 17:22:03.009: INFO: Got endpoints: latency-svc-4c5ff [11.64182ms]
Nov  8 17:22:03.014: INFO: Created: latency-svc-76kfb
Nov  8 17:22:03.016: INFO: Got endpoints: latency-svc-76kfb [116.670905ms]
Nov  8 17:22:03.022: INFO: Created: latency-svc-tgngh
Nov  8 17:22:03.041: INFO: Got endpoints: latency-svc-tgngh [129.373783ms]
Nov  8 17:22:03.043: INFO: Created: latency-svc-jp2dx
Nov  8 17:22:03.055: INFO: Got endpoints: latency-svc-jp2dx [134.836078ms]
Nov  8 17:22:03.074: INFO: Created: latency-svc-d6lvb
Nov  8 17:22:03.111: INFO: Got endpoints: latency-svc-d6lvb [180.029195ms]
Nov  8 17:22:03.137: INFO: Created: latency-svc-4t5ht
Nov  8 17:22:03.141: INFO: Got endpoints: latency-svc-4t5ht [202.587487ms]
Nov  8 17:22:03.149: INFO: Created: latency-svc-7r86c
Nov  8 17:22:03.152: INFO: Got endpoints: latency-svc-7r86c [208.796855ms]
Nov  8 17:22:03.155: INFO: Created: latency-svc-mt7n7
Nov  8 17:22:03.157: INFO: Got endpoints: latency-svc-mt7n7 [210.14328ms]
Nov  8 17:22:03.162: INFO: Created: latency-svc-vbjjd
Nov  8 17:22:03.164: INFO: Got endpoints: latency-svc-vbjjd [207.960032ms]
Nov  8 17:22:03.179: INFO: Created: latency-svc-sv762
Nov  8 17:22:03.181: INFO: Got endpoints: latency-svc-sv762 [221.09141ms]
Nov  8 17:22:03.185: INFO: Created: latency-svc-fpv96
Nov  8 17:22:03.189: INFO: Got endpoints: latency-svc-fpv96 [219.364613ms]
Nov  8 17:22:03.197: INFO: Created: latency-svc-8scmm
Nov  8 17:22:03.197: INFO: Got endpoints: latency-svc-8scmm [224.857621ms]
Nov  8 17:22:03.201: INFO: Created: latency-svc-9fwcf
Nov  8 17:22:03.207: INFO: Created: latency-svc-xr7tv
Nov  8 17:22:03.209: INFO: Got endpoints: latency-svc-9fwcf [227.982454ms]
Nov  8 17:22:03.214: INFO: Got endpoints: latency-svc-xr7tv [225.321236ms]
Nov  8 17:22:03.215: INFO: Created: latency-svc-958hd
Nov  8 17:22:03.218: INFO: Got endpoints: latency-svc-958hd [214.577517ms]
Nov  8 17:22:03.222: INFO: Created: latency-svc-8lk2q
Nov  8 17:22:03.229: INFO: Created: latency-svc-66fzt
Nov  8 17:22:03.230: INFO: Got endpoints: latency-svc-8lk2q [220.966845ms]
Nov  8 17:22:03.234: INFO: Created: latency-svc-6n8xl
Nov  8 17:22:03.235: INFO: Got endpoints: latency-svc-66fzt [218.358502ms]
Nov  8 17:22:03.239: INFO: Created: latency-svc-gnnrw
Nov  8 17:22:03.248: INFO: Created: latency-svc-lcshf
Nov  8 17:22:03.261: INFO: Got endpoints: latency-svc-6n8xl [219.608692ms]
Nov  8 17:22:03.262: INFO: Created: latency-svc-jt2h6
Nov  8 17:22:03.268: INFO: Created: latency-svc-8zt2f
Nov  8 17:22:03.273: INFO: Created: latency-svc-n786m
Nov  8 17:22:03.280: INFO: Created: latency-svc-77xpj
Nov  8 17:22:03.284: INFO: Created: latency-svc-59z2m
Nov  8 17:22:03.290: INFO: Created: latency-svc-z5b89
Nov  8 17:22:03.295: INFO: Created: latency-svc-tqcpg
Nov  8 17:22:03.302: INFO: Created: latency-svc-w25wx
Nov  8 17:22:03.306: INFO: Created: latency-svc-t7b5k
Nov  8 17:22:03.308: INFO: Got endpoints: latency-svc-gnnrw [253.515277ms]
Nov  8 17:22:03.317: INFO: Created: latency-svc-hmrc4
Nov  8 17:22:03.321: INFO: Created: latency-svc-g5qrd
Nov  8 17:22:03.327: INFO: Created: latency-svc-7xbhc
Nov  8 17:22:03.333: INFO: Created: latency-svc-55b78
Nov  8 17:22:03.339: INFO: Created: latency-svc-lr44z
Nov  8 17:22:03.357: INFO: Got endpoints: latency-svc-lcshf [246.427765ms]
Nov  8 17:22:03.373: INFO: Created: latency-svc-k6jc8
Nov  8 17:22:03.407: INFO: Got endpoints: latency-svc-jt2h6 [266.395047ms]
Nov  8 17:22:03.414: INFO: Created: latency-svc-d7twb
Nov  8 17:22:03.457: INFO: Got endpoints: latency-svc-8zt2f [304.936962ms]
Nov  8 17:22:03.466: INFO: Created: latency-svc-cvzhz
Nov  8 17:22:03.507: INFO: Got endpoints: latency-svc-n786m [349.673875ms]
Nov  8 17:22:03.525: INFO: Created: latency-svc-v7cbp
Nov  8 17:22:03.557: INFO: Got endpoints: latency-svc-77xpj [393.328382ms]
Nov  8 17:22:03.565: INFO: Created: latency-svc-rzwnp
Nov  8 17:22:03.607: INFO: Got endpoints: latency-svc-59z2m [418.252705ms]
Nov  8 17:22:03.615: INFO: Created: latency-svc-dfwjx
Nov  8 17:22:03.657: INFO: Got endpoints: latency-svc-z5b89 [475.69621ms]
Nov  8 17:22:03.667: INFO: Created: latency-svc-bwnxj
Nov  8 17:22:03.707: INFO: Got endpoints: latency-svc-tqcpg [509.357881ms]
Nov  8 17:22:03.718: INFO: Created: latency-svc-sj2fq
Nov  8 17:22:03.757: INFO: Got endpoints: latency-svc-w25wx [547.857899ms]
Nov  8 17:22:03.765: INFO: Created: latency-svc-2fnb6
Nov  8 17:22:03.807: INFO: Got endpoints: latency-svc-t7b5k [593.514813ms]
Nov  8 17:22:03.816: INFO: Created: latency-svc-x8q96
Nov  8 17:22:03.857: INFO: Got endpoints: latency-svc-hmrc4 [639.010833ms]
Nov  8 17:22:03.865: INFO: Created: latency-svc-95v4g
Nov  8 17:22:03.907: INFO: Got endpoints: latency-svc-g5qrd [676.994179ms]
Nov  8 17:22:03.916: INFO: Created: latency-svc-7p2kr
Nov  8 17:22:03.957: INFO: Got endpoints: latency-svc-7xbhc [722.40382ms]
Nov  8 17:22:03.965: INFO: Created: latency-svc-jb9vr
Nov  8 17:22:04.007: INFO: Got endpoints: latency-svc-55b78 [746.231175ms]
Nov  8 17:22:04.015: INFO: Created: latency-svc-tlnpq
Nov  8 17:22:04.057: INFO: Got endpoints: latency-svc-lr44z [748.826624ms]
Nov  8 17:22:04.065: INFO: Created: latency-svc-vmmgm
Nov  8 17:22:04.107: INFO: Got endpoints: latency-svc-k6jc8 [749.887158ms]
Nov  8 17:22:04.115: INFO: Created: latency-svc-gzs4p
Nov  8 17:22:04.157: INFO: Got endpoints: latency-svc-d7twb [750.094766ms]
Nov  8 17:22:04.164: INFO: Created: latency-svc-6ltx7
Nov  8 17:22:04.209: INFO: Got endpoints: latency-svc-cvzhz [751.71717ms]
Nov  8 17:22:04.218: INFO: Created: latency-svc-rz8pq
Nov  8 17:22:04.257: INFO: Got endpoints: latency-svc-v7cbp [750.169779ms]
Nov  8 17:22:04.265: INFO: Created: latency-svc-k9tmk
Nov  8 17:22:04.307: INFO: Got endpoints: latency-svc-rzwnp [749.667012ms]
Nov  8 17:22:04.318: INFO: Created: latency-svc-8hcs8
Nov  8 17:22:04.357: INFO: Got endpoints: latency-svc-dfwjx [750.298071ms]
Nov  8 17:22:04.372: INFO: Created: latency-svc-27qrz
Nov  8 17:22:04.407: INFO: Got endpoints: latency-svc-bwnxj [749.824267ms]
Nov  8 17:22:04.420: INFO: Created: latency-svc-qld9c
Nov  8 17:22:04.457: INFO: Got endpoints: latency-svc-sj2fq [750.078103ms]
Nov  8 17:22:04.467: INFO: Created: latency-svc-zj94d
Nov  8 17:22:04.507: INFO: Got endpoints: latency-svc-2fnb6 [749.605877ms]
Nov  8 17:22:04.515: INFO: Created: latency-svc-9jtb6
Nov  8 17:22:04.559: INFO: Got endpoints: latency-svc-x8q96 [751.88803ms]
Nov  8 17:22:04.569: INFO: Created: latency-svc-k6hj8
Nov  8 17:22:04.607: INFO: Got endpoints: latency-svc-95v4g [750.284873ms]
Nov  8 17:22:04.616: INFO: Created: latency-svc-rphpt
Nov  8 17:22:04.658: INFO: Got endpoints: latency-svc-7p2kr [750.892621ms]
Nov  8 17:22:04.666: INFO: Created: latency-svc-bq6dt
Nov  8 17:22:04.707: INFO: Got endpoints: latency-svc-jb9vr [750.018974ms]
Nov  8 17:22:04.716: INFO: Created: latency-svc-pqr9k
Nov  8 17:22:04.757: INFO: Got endpoints: latency-svc-tlnpq [750.294436ms]
Nov  8 17:22:04.766: INFO: Created: latency-svc-5c7sf
Nov  8 17:22:04.807: INFO: Got endpoints: latency-svc-vmmgm [749.860578ms]
Nov  8 17:22:04.815: INFO: Created: latency-svc-dldqc
Nov  8 17:22:04.857: INFO: Got endpoints: latency-svc-gzs4p [749.958152ms]
Nov  8 17:22:04.865: INFO: Created: latency-svc-q4t9p
Nov  8 17:22:04.907: INFO: Got endpoints: latency-svc-6ltx7 [749.715996ms]
Nov  8 17:22:04.917: INFO: Created: latency-svc-4j7t2
Nov  8 17:22:04.957: INFO: Got endpoints: latency-svc-rz8pq [748.204182ms]
Nov  8 17:22:04.966: INFO: Created: latency-svc-sdnjh
Nov  8 17:22:05.007: INFO: Got endpoints: latency-svc-k9tmk [749.779701ms]
Nov  8 17:22:05.015: INFO: Created: latency-svc-f45jq
Nov  8 17:22:05.057: INFO: Got endpoints: latency-svc-8hcs8 [750.315795ms]
Nov  8 17:22:05.065: INFO: Created: latency-svc-hp5ln
Nov  8 17:22:05.108: INFO: Got endpoints: latency-svc-27qrz [750.80165ms]
Nov  8 17:22:05.118: INFO: Created: latency-svc-rjhfd
Nov  8 17:22:05.157: INFO: Got endpoints: latency-svc-qld9c [749.759207ms]
Nov  8 17:22:05.165: INFO: Created: latency-svc-575tg
Nov  8 17:22:05.207: INFO: Got endpoints: latency-svc-zj94d [749.877591ms]
Nov  8 17:22:05.216: INFO: Created: latency-svc-btglj
Nov  8 17:22:05.257: INFO: Got endpoints: latency-svc-9jtb6 [750.329805ms]
Nov  8 17:22:05.271: INFO: Created: latency-svc-qq6wp
Nov  8 17:22:05.307: INFO: Got endpoints: latency-svc-k6hj8 [747.958382ms]
Nov  8 17:22:05.315: INFO: Created: latency-svc-jmbgd
Nov  8 17:22:05.361: INFO: Got endpoints: latency-svc-rphpt [753.386012ms]
Nov  8 17:22:05.369: INFO: Created: latency-svc-rt5hp
Nov  8 17:22:05.407: INFO: Got endpoints: latency-svc-bq6dt [749.366252ms]
Nov  8 17:22:05.414: INFO: Created: latency-svc-jnrdj
Nov  8 17:22:05.457: INFO: Got endpoints: latency-svc-pqr9k [749.891799ms]
Nov  8 17:22:05.466: INFO: Created: latency-svc-qngbj
Nov  8 17:22:05.507: INFO: Got endpoints: latency-svc-5c7sf [749.572453ms]
Nov  8 17:22:05.515: INFO: Created: latency-svc-4rlsb
Nov  8 17:22:05.557: INFO: Got endpoints: latency-svc-dldqc [749.777561ms]
Nov  8 17:22:05.570: INFO: Created: latency-svc-h8bfd
Nov  8 17:22:05.607: INFO: Got endpoints: latency-svc-q4t9p [749.696756ms]
Nov  8 17:22:05.615: INFO: Created: latency-svc-mng4q
Nov  8 17:22:05.657: INFO: Got endpoints: latency-svc-4j7t2 [750.049869ms]
Nov  8 17:22:05.665: INFO: Created: latency-svc-4sk2m
Nov  8 17:22:05.707: INFO: Got endpoints: latency-svc-sdnjh [749.744828ms]
Nov  8 17:22:05.716: INFO: Created: latency-svc-5swkr
Nov  8 17:22:05.757: INFO: Got endpoints: latency-svc-f45jq [749.755888ms]
Nov  8 17:22:05.764: INFO: Created: latency-svc-jmv92
Nov  8 17:22:05.807: INFO: Got endpoints: latency-svc-hp5ln [749.922846ms]
Nov  8 17:22:05.815: INFO: Created: latency-svc-dh5x6
Nov  8 17:22:05.857: INFO: Got endpoints: latency-svc-rjhfd [749.055458ms]
Nov  8 17:22:05.865: INFO: Created: latency-svc-qfkd6
Nov  8 17:22:05.907: INFO: Got endpoints: latency-svc-575tg [749.967476ms]
Nov  8 17:22:05.919: INFO: Created: latency-svc-4znhb
Nov  8 17:22:05.957: INFO: Got endpoints: latency-svc-btglj [750.09906ms]
Nov  8 17:22:05.964: INFO: Created: latency-svc-2vf7f
Nov  8 17:22:06.007: INFO: Got endpoints: latency-svc-qq6wp [749.852804ms]
Nov  8 17:22:06.015: INFO: Created: latency-svc-fzwhs
Nov  8 17:22:06.058: INFO: Got endpoints: latency-svc-jmbgd [750.582919ms]
Nov  8 17:22:06.066: INFO: Created: latency-svc-b8qb4
Nov  8 17:22:06.107: INFO: Got endpoints: latency-svc-rt5hp [746.437758ms]
Nov  8 17:22:06.115: INFO: Created: latency-svc-cmd6h
Nov  8 17:22:06.157: INFO: Got endpoints: latency-svc-jnrdj [750.244814ms]
Nov  8 17:22:06.165: INFO: Created: latency-svc-5ht6t
Nov  8 17:22:06.207: INFO: Got endpoints: latency-svc-qngbj [750.276694ms]
Nov  8 17:22:06.215: INFO: Created: latency-svc-qhw6f
Nov  8 17:22:06.257: INFO: Got endpoints: latency-svc-4rlsb [750.193668ms]
Nov  8 17:22:06.269: INFO: Created: latency-svc-zxvtx
Nov  8 17:22:06.307: INFO: Got endpoints: latency-svc-h8bfd [750.421962ms]
Nov  8 17:22:06.316: INFO: Created: latency-svc-nzjwq
Nov  8 17:22:06.357: INFO: Got endpoints: latency-svc-mng4q [750.51731ms]
Nov  8 17:22:06.366: INFO: Created: latency-svc-c27t9
Nov  8 17:22:06.407: INFO: Got endpoints: latency-svc-4sk2m [749.866251ms]
Nov  8 17:22:06.414: INFO: Created: latency-svc-6tm6w
Nov  8 17:22:06.457: INFO: Got endpoints: latency-svc-5swkr [750.057374ms]
Nov  8 17:22:06.527: INFO: Got endpoints: latency-svc-jmv92 [770.665353ms]
Nov  8 17:22:06.528: INFO: Created: latency-svc-ch5n9
Nov  8 17:22:06.536: INFO: Created: latency-svc-s88kq
Nov  8 17:22:06.557: INFO: Got endpoints: latency-svc-dh5x6 [749.888543ms]
Nov  8 17:22:06.564: INFO: Created: latency-svc-4ch7c
Nov  8 17:22:06.607: INFO: Got endpoints: latency-svc-qfkd6 [750.076974ms]
Nov  8 17:22:06.615: INFO: Created: latency-svc-q76fb
Nov  8 17:22:06.658: INFO: Got endpoints: latency-svc-4znhb [751.213569ms]
Nov  8 17:22:06.666: INFO: Created: latency-svc-r2blw
Nov  8 17:22:06.707: INFO: Got endpoints: latency-svc-2vf7f [749.916908ms]
Nov  8 17:22:06.715: INFO: Created: latency-svc-7qlm7
Nov  8 17:22:06.757: INFO: Got endpoints: latency-svc-fzwhs [749.798137ms]
Nov  8 17:22:06.764: INFO: Created: latency-svc-b6l4r
Nov  8 17:22:06.807: INFO: Got endpoints: latency-svc-b8qb4 [749.402207ms]
Nov  8 17:22:06.815: INFO: Created: latency-svc-pnzzh
Nov  8 17:22:06.858: INFO: Got endpoints: latency-svc-cmd6h [750.335091ms]
Nov  8 17:22:06.865: INFO: Created: latency-svc-s7z9n
Nov  8 17:22:06.907: INFO: Got endpoints: latency-svc-5ht6t [749.389057ms]
Nov  8 17:22:06.914: INFO: Created: latency-svc-xsf72
Nov  8 17:22:06.957: INFO: Got endpoints: latency-svc-qhw6f [749.432512ms]
Nov  8 17:22:06.964: INFO: Created: latency-svc-vt6dn
Nov  8 17:22:07.007: INFO: Got endpoints: latency-svc-zxvtx [749.757138ms]
Nov  8 17:22:07.014: INFO: Created: latency-svc-p4ktb
Nov  8 17:22:07.057: INFO: Got endpoints: latency-svc-nzjwq [749.949206ms]
Nov  8 17:22:07.064: INFO: Created: latency-svc-frlvv
Nov  8 17:22:07.107: INFO: Got endpoints: latency-svc-c27t9 [749.940341ms]
Nov  8 17:22:07.116: INFO: Created: latency-svc-5886l
Nov  8 17:22:07.157: INFO: Got endpoints: latency-svc-6tm6w [750.117589ms]
Nov  8 17:22:07.164: INFO: Created: latency-svc-zrxrl
Nov  8 17:22:07.208: INFO: Got endpoints: latency-svc-ch5n9 [750.760137ms]
Nov  8 17:22:07.216: INFO: Created: latency-svc-kbmt4
Nov  8 17:22:07.257: INFO: Got endpoints: latency-svc-s88kq [729.822392ms]
Nov  8 17:22:07.265: INFO: Created: latency-svc-nzksc
Nov  8 17:22:07.307: INFO: Got endpoints: latency-svc-4ch7c [750.147011ms]
Nov  8 17:22:07.320: INFO: Created: latency-svc-6vnjg
Nov  8 17:22:07.357: INFO: Got endpoints: latency-svc-q76fb [750.25426ms]
Nov  8 17:22:07.367: INFO: Created: latency-svc-jkdgc
Nov  8 17:22:07.407: INFO: Got endpoints: latency-svc-r2blw [749.227037ms]
Nov  8 17:22:07.414: INFO: Created: latency-svc-n65jk
Nov  8 17:22:07.460: INFO: Got endpoints: latency-svc-7qlm7 [752.532522ms]
Nov  8 17:22:07.468: INFO: Created: latency-svc-p8xjt
Nov  8 17:22:07.507: INFO: Got endpoints: latency-svc-b6l4r [750.549478ms]
Nov  8 17:22:07.521: INFO: Created: latency-svc-q4l9v
Nov  8 17:22:07.558: INFO: Got endpoints: latency-svc-pnzzh [750.62406ms]
Nov  8 17:22:07.567: INFO: Created: latency-svc-t5lsw
Nov  8 17:22:07.607: INFO: Got endpoints: latency-svc-s7z9n [749.653681ms]
Nov  8 17:22:07.614: INFO: Created: latency-svc-ch2mf
Nov  8 17:22:07.657: INFO: Got endpoints: latency-svc-xsf72 [749.963066ms]
Nov  8 17:22:07.665: INFO: Created: latency-svc-sq9mx
Nov  8 17:22:07.707: INFO: Got endpoints: latency-svc-vt6dn [750.093993ms]
Nov  8 17:22:07.715: INFO: Created: latency-svc-45kr5
Nov  8 17:22:07.757: INFO: Got endpoints: latency-svc-p4ktb [750.136989ms]
Nov  8 17:22:07.764: INFO: Created: latency-svc-k4nhg
Nov  8 17:22:07.807: INFO: Got endpoints: latency-svc-frlvv [749.656113ms]
Nov  8 17:22:07.815: INFO: Created: latency-svc-9sh5p
Nov  8 17:22:07.857: INFO: Got endpoints: latency-svc-5886l [749.766469ms]
Nov  8 17:22:07.865: INFO: Created: latency-svc-f658h
Nov  8 17:22:07.907: INFO: Got endpoints: latency-svc-zrxrl [749.913632ms]
Nov  8 17:22:07.915: INFO: Created: latency-svc-l599n
Nov  8 17:22:07.957: INFO: Got endpoints: latency-svc-kbmt4 [748.906341ms]
Nov  8 17:22:07.964: INFO: Created: latency-svc-qzjhv
Nov  8 17:22:08.007: INFO: Got endpoints: latency-svc-nzksc [749.745004ms]
Nov  8 17:22:08.014: INFO: Created: latency-svc-wvdjj
Nov  8 17:22:08.057: INFO: Got endpoints: latency-svc-6vnjg [749.771228ms]
Nov  8 17:22:08.066: INFO: Created: latency-svc-dt9dg
Nov  8 17:22:08.107: INFO: Got endpoints: latency-svc-jkdgc [749.849809ms]
Nov  8 17:22:08.116: INFO: Created: latency-svc-5b84v
Nov  8 17:22:08.157: INFO: Got endpoints: latency-svc-n65jk [749.589649ms]
Nov  8 17:22:08.164: INFO: Created: latency-svc-gskjp
Nov  8 17:22:08.207: INFO: Got endpoints: latency-svc-p8xjt [747.246638ms]
Nov  8 17:22:08.214: INFO: Created: latency-svc-h2vjb
Nov  8 17:22:08.257: INFO: Got endpoints: latency-svc-q4l9v [749.569631ms]
Nov  8 17:22:08.265: INFO: Created: latency-svc-cdmrg
Nov  8 17:22:08.307: INFO: Got endpoints: latency-svc-t5lsw [748.957164ms]
Nov  8 17:22:08.314: INFO: Created: latency-svc-lfn7l
Nov  8 17:22:08.357: INFO: Got endpoints: latency-svc-ch2mf [749.573138ms]
Nov  8 17:22:08.366: INFO: Created: latency-svc-w8vg9
Nov  8 17:22:08.410: INFO: Got endpoints: latency-svc-sq9mx [752.986931ms]
Nov  8 17:22:08.423: INFO: Created: latency-svc-7b49b
Nov  8 17:22:08.457: INFO: Got endpoints: latency-svc-45kr5 [750.193135ms]
Nov  8 17:22:08.465: INFO: Created: latency-svc-gpst8
Nov  8 17:22:08.507: INFO: Got endpoints: latency-svc-k4nhg [750.106931ms]
Nov  8 17:22:08.517: INFO: Created: latency-svc-r5hzh
Nov  8 17:22:08.557: INFO: Got endpoints: latency-svc-9sh5p [750.26216ms]
Nov  8 17:22:08.564: INFO: Created: latency-svc-nbdrv
Nov  8 17:22:08.607: INFO: Got endpoints: latency-svc-f658h [749.855341ms]
Nov  8 17:22:08.615: INFO: Created: latency-svc-jkvgp
Nov  8 17:22:08.657: INFO: Got endpoints: latency-svc-l599n [750.105592ms]
Nov  8 17:22:08.664: INFO: Created: latency-svc-z4mpr
Nov  8 17:22:08.707: INFO: Got endpoints: latency-svc-qzjhv [749.649848ms]
Nov  8 17:22:08.716: INFO: Created: latency-svc-4qkcl
Nov  8 17:22:08.757: INFO: Got endpoints: latency-svc-wvdjj [749.886079ms]
Nov  8 17:22:08.764: INFO: Created: latency-svc-9jkdm
Nov  8 17:22:08.807: INFO: Got endpoints: latency-svc-dt9dg [750.034167ms]
Nov  8 17:22:08.818: INFO: Created: latency-svc-tslp8
Nov  8 17:22:08.857: INFO: Got endpoints: latency-svc-5b84v [749.837881ms]
Nov  8 17:22:08.865: INFO: Created: latency-svc-smcpf
Nov  8 17:22:08.907: INFO: Got endpoints: latency-svc-gskjp [749.929029ms]
Nov  8 17:22:08.915: INFO: Created: latency-svc-x7jff
Nov  8 17:22:08.957: INFO: Got endpoints: latency-svc-h2vjb [750.593915ms]
Nov  8 17:22:08.965: INFO: Created: latency-svc-bp6zt
Nov  8 17:22:09.007: INFO: Got endpoints: latency-svc-cdmrg [749.915089ms]
Nov  8 17:22:09.016: INFO: Created: latency-svc-s566n
Nov  8 17:22:09.057: INFO: Got endpoints: latency-svc-lfn7l [750.325977ms]
Nov  8 17:22:09.065: INFO: Created: latency-svc-kjl9q
Nov  8 17:22:09.107: INFO: Got endpoints: latency-svc-w8vg9 [749.958269ms]
Nov  8 17:22:09.114: INFO: Created: latency-svc-bmj5g
Nov  8 17:22:09.158: INFO: Got endpoints: latency-svc-7b49b [748.690813ms]
Nov  8 17:22:09.166: INFO: Created: latency-svc-vzrpd
Nov  8 17:22:09.207: INFO: Got endpoints: latency-svc-gpst8 [749.910068ms]
Nov  8 17:22:09.218: INFO: Created: latency-svc-qzpcs
Nov  8 17:22:09.258: INFO: Got endpoints: latency-svc-r5hzh [750.337119ms]
Nov  8 17:22:09.266: INFO: Created: latency-svc-g5xhr
Nov  8 17:22:09.307: INFO: Got endpoints: latency-svc-nbdrv [749.645931ms]
Nov  8 17:22:09.314: INFO: Created: latency-svc-lbcvn
Nov  8 17:22:09.357: INFO: Got endpoints: latency-svc-jkvgp [750.108783ms]
Nov  8 17:22:09.365: INFO: Created: latency-svc-zjwp2
Nov  8 17:22:09.407: INFO: Got endpoints: latency-svc-z4mpr [749.573217ms]
Nov  8 17:22:09.414: INFO: Created: latency-svc-fnhdq
Nov  8 17:22:09.459: INFO: Got endpoints: latency-svc-4qkcl [752.658087ms]
Nov  8 17:22:09.467: INFO: Created: latency-svc-zfcjv
Nov  8 17:22:09.507: INFO: Got endpoints: latency-svc-9jkdm [749.972724ms]
Nov  8 17:22:09.516: INFO: Created: latency-svc-h2867
Nov  8 17:22:09.557: INFO: Got endpoints: latency-svc-tslp8 [749.967144ms]
Nov  8 17:22:09.568: INFO: Created: latency-svc-wdpwl
Nov  8 17:22:09.609: INFO: Got endpoints: latency-svc-smcpf [751.425838ms]
Nov  8 17:22:09.621: INFO: Created: latency-svc-hztjf
Nov  8 17:22:09.657: INFO: Got endpoints: latency-svc-x7jff [750.34579ms]
Nov  8 17:22:09.665: INFO: Created: latency-svc-9z254
Nov  8 17:22:09.707: INFO: Got endpoints: latency-svc-bp6zt [749.710432ms]
Nov  8 17:22:09.715: INFO: Created: latency-svc-n47bs
Nov  8 17:22:09.757: INFO: Got endpoints: latency-svc-s566n [749.922591ms]
Nov  8 17:22:09.765: INFO: Created: latency-svc-k85r2
Nov  8 17:22:09.807: INFO: Got endpoints: latency-svc-kjl9q [749.94705ms]
Nov  8 17:22:09.814: INFO: Created: latency-svc-tl45g
Nov  8 17:22:09.857: INFO: Got endpoints: latency-svc-bmj5g [750.208175ms]
Nov  8 17:22:09.865: INFO: Created: latency-svc-m62x5
Nov  8 17:22:09.907: INFO: Got endpoints: latency-svc-vzrpd [748.670483ms]
Nov  8 17:22:09.915: INFO: Created: latency-svc-kn9cb
Nov  8 17:22:09.957: INFO: Got endpoints: latency-svc-qzpcs [750.123202ms]
Nov  8 17:22:09.964: INFO: Created: latency-svc-p6842
Nov  8 17:22:10.007: INFO: Got endpoints: latency-svc-g5xhr [749.299166ms]
Nov  8 17:22:10.016: INFO: Created: latency-svc-w4njn
Nov  8 17:22:10.057: INFO: Got endpoints: latency-svc-lbcvn [750.386116ms]
Nov  8 17:22:10.065: INFO: Created: latency-svc-p9mpv
Nov  8 17:22:10.107: INFO: Got endpoints: latency-svc-zjwp2 [750.497603ms]
Nov  8 17:22:10.115: INFO: Created: latency-svc-sdhtr
Nov  8 17:22:10.157: INFO: Got endpoints: latency-svc-fnhdq [750.361192ms]
Nov  8 17:22:10.165: INFO: Created: latency-svc-n9fmt
Nov  8 17:22:10.207: INFO: Got endpoints: latency-svc-zfcjv [747.808498ms]
Nov  8 17:22:10.215: INFO: Created: latency-svc-t8q6q
Nov  8 17:22:10.257: INFO: Got endpoints: latency-svc-h2867 [749.855904ms]
Nov  8 17:22:10.264: INFO: Created: latency-svc-j75zp
Nov  8 17:22:10.307: INFO: Got endpoints: latency-svc-wdpwl [749.962007ms]
Nov  8 17:22:10.314: INFO: Created: latency-svc-8m4fm
Nov  8 17:22:10.357: INFO: Got endpoints: latency-svc-hztjf [748.162002ms]
Nov  8 17:22:10.366: INFO: Created: latency-svc-lmm4f
Nov  8 17:22:10.407: INFO: Got endpoints: latency-svc-9z254 [749.78656ms]
Nov  8 17:22:10.415: INFO: Created: latency-svc-258h9
Nov  8 17:22:10.457: INFO: Got endpoints: latency-svc-n47bs [750.236337ms]
Nov  8 17:22:10.467: INFO: Created: latency-svc-hvmnb
Nov  8 17:22:10.507: INFO: Got endpoints: latency-svc-k85r2 [749.780955ms]
Nov  8 17:22:10.518: INFO: Created: latency-svc-jsj9z
Nov  8 17:22:10.557: INFO: Got endpoints: latency-svc-tl45g [749.667841ms]
Nov  8 17:22:10.565: INFO: Created: latency-svc-hztg7
Nov  8 17:22:10.607: INFO: Got endpoints: latency-svc-m62x5 [749.975898ms]
Nov  8 17:22:10.618: INFO: Created: latency-svc-vptjj
Nov  8 17:22:10.657: INFO: Got endpoints: latency-svc-kn9cb [750.349994ms]
Nov  8 17:22:10.665: INFO: Created: latency-svc-54xsq
Nov  8 17:22:10.707: INFO: Got endpoints: latency-svc-p6842 [749.712463ms]
Nov  8 17:22:10.757: INFO: Got endpoints: latency-svc-w4njn [750.514929ms]
Nov  8 17:22:10.807: INFO: Got endpoints: latency-svc-p9mpv [749.620378ms]
Nov  8 17:22:10.857: INFO: Got endpoints: latency-svc-sdhtr [749.699892ms]
Nov  8 17:22:10.907: INFO: Got endpoints: latency-svc-n9fmt [749.538081ms]
Nov  8 17:22:10.957: INFO: Got endpoints: latency-svc-t8q6q [749.718626ms]
Nov  8 17:22:11.007: INFO: Got endpoints: latency-svc-j75zp [749.962922ms]
Nov  8 17:22:11.057: INFO: Got endpoints: latency-svc-8m4fm [749.872476ms]
Nov  8 17:22:11.107: INFO: Got endpoints: latency-svc-lmm4f [749.851448ms]
Nov  8 17:22:11.157: INFO: Got endpoints: latency-svc-258h9 [749.742396ms]
Nov  8 17:22:11.207: INFO: Got endpoints: latency-svc-hvmnb [749.403718ms]
Nov  8 17:22:11.257: INFO: Got endpoints: latency-svc-jsj9z [750.173634ms]
Nov  8 17:22:11.307: INFO: Got endpoints: latency-svc-hztg7 [749.950149ms]
Nov  8 17:22:11.357: INFO: Got endpoints: latency-svc-vptjj [749.745838ms]
Nov  8 17:22:11.407: INFO: Got endpoints: latency-svc-54xsq [749.294695ms]
Nov  8 17:22:11.407: INFO: Latencies: [11.64182ms 12.837072ms 22.859486ms 25.587402ms 29.814649ms 38.801123ms 50.688732ms 58.880201ms 69.482646ms 76.921142ms 82.437052ms 86.046854ms 94.788199ms 99.492626ms 104.969431ms 108.195845ms 108.196466ms 110.835154ms 112.200845ms 112.991342ms 116.670905ms 129.373783ms 134.836078ms 180.029195ms 202.587487ms 207.960032ms 208.796855ms 210.14328ms 214.577517ms 218.358502ms 219.364613ms 219.608692ms 220.966845ms 221.09141ms 224.857621ms 225.321236ms 227.982454ms 246.427765ms 253.515277ms 266.395047ms 304.936962ms 349.673875ms 393.328382ms 418.252705ms 475.69621ms 509.357881ms 547.857899ms 593.514813ms 639.010833ms 676.994179ms 722.40382ms 729.822392ms 746.231175ms 746.437758ms 747.246638ms 747.808498ms 747.958382ms 748.162002ms 748.204182ms 748.670483ms 748.690813ms 748.826624ms 748.906341ms 748.957164ms 749.055458ms 749.227037ms 749.294695ms 749.299166ms 749.366252ms 749.389057ms 749.402207ms 749.403718ms 749.432512ms 749.538081ms 749.569631ms 749.572453ms 749.573138ms 749.573217ms 749.589649ms 749.605877ms 749.620378ms 749.645931ms 749.649848ms 749.653681ms 749.656113ms 749.667012ms 749.667841ms 749.696756ms 749.699892ms 749.710432ms 749.712463ms 749.715996ms 749.718626ms 749.742396ms 749.744828ms 749.745004ms 749.745838ms 749.755888ms 749.757138ms 749.759207ms 749.766469ms 749.771228ms 749.777561ms 749.779701ms 749.780955ms 749.78656ms 749.798137ms 749.824267ms 749.837881ms 749.849809ms 749.851448ms 749.852804ms 749.855341ms 749.855904ms 749.860578ms 749.866251ms 749.872476ms 749.877591ms 749.886079ms 749.887158ms 749.888543ms 749.891799ms 749.910068ms 749.913632ms 749.915089ms 749.916908ms 749.922591ms 749.922846ms 749.929029ms 749.940341ms 749.94705ms 749.949206ms 749.950149ms 749.958152ms 749.958269ms 749.962007ms 749.962922ms 749.963066ms 749.967144ms 749.967476ms 749.972724ms 749.975898ms 750.018974ms 750.034167ms 750.049869ms 750.057374ms 750.076974ms 750.078103ms 750.093993ms 750.094766ms 750.09906ms 750.105592ms 750.106931ms 750.108783ms 750.117589ms 750.123202ms 750.136989ms 750.147011ms 750.169779ms 750.173634ms 750.193135ms 750.193668ms 750.208175ms 750.236337ms 750.244814ms 750.25426ms 750.26216ms 750.276694ms 750.284873ms 750.294436ms 750.298071ms 750.315795ms 750.325977ms 750.329805ms 750.335091ms 750.337119ms 750.34579ms 750.349994ms 750.361192ms 750.386116ms 750.421962ms 750.497603ms 750.514929ms 750.51731ms 750.549478ms 750.582919ms 750.593915ms 750.62406ms 750.760137ms 750.80165ms 750.892621ms 751.213569ms 751.425838ms 751.71717ms 751.88803ms 752.532522ms 752.658087ms 752.986931ms 753.386012ms 770.665353ms]
Nov  8 17:22:11.407: INFO: 50 %ile: 749.766469ms
Nov  8 17:22:11.407: INFO: 90 %ile: 750.421962ms
Nov  8 17:22:11.407: INFO: 99 %ile: 753.386012ms
Nov  8 17:22:11.407: INFO: Total sample count: 200
[AfterEach] [sig-network] Service endpoints latency
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  8 17:22:11.407: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-svc-latency-nv69p" for this suite.
Nov  8 17:22:21.416: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  8 17:22:21.430: INFO: namespace: e2e-tests-svc-latency-nv69p, resource: bindings, ignored listing per whitelist
Nov  8 17:22:21.471: INFO: namespace e2e-tests-svc-latency-nv69p deletion completed in 10.06126336s

• [SLOW TEST:19.816 seconds]
[sig-network] Service endpoints latency
/go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should not be very high  [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[k8s.io] Docker Containers 
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Docker Containers
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  8 17:22:21.471: INFO: >>> kubeConfig: /tmp/kubeconfig-235977939
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test use defaults
Nov  8 17:22:21.515: INFO: Waiting up to 5m0s for pod "client-containers-d9d801cc-e37a-11e8-b0fd-0e97e856486a" in namespace "e2e-tests-containers-vg9v9" to be "success or failure"
Nov  8 17:22:21.517: INFO: Pod "client-containers-d9d801cc-e37a-11e8-b0fd-0e97e856486a": Phase="Pending", Reason="", readiness=false. Elapsed: 1.793632ms
Nov  8 17:22:23.519: INFO: Pod "client-containers-d9d801cc-e37a-11e8-b0fd-0e97e856486a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.003793341s
STEP: Saw pod success
Nov  8 17:22:23.519: INFO: Pod "client-containers-d9d801cc-e37a-11e8-b0fd-0e97e856486a" satisfied condition "success or failure"
Nov  8 17:22:23.520: INFO: Trying to get logs from node ip-10-0-100-224.ec2.internal pod client-containers-d9d801cc-e37a-11e8-b0fd-0e97e856486a container test-container: <nil>
STEP: delete the pod
Nov  8 17:22:23.529: INFO: Waiting for pod client-containers-d9d801cc-e37a-11e8-b0fd-0e97e856486a to disappear
Nov  8 17:22:23.530: INFO: Pod client-containers-d9d801cc-e37a-11e8-b0fd-0e97e856486a no longer exists
[AfterEach] [k8s.io] Docker Containers
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  8 17:22:23.530: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-vg9v9" for this suite.
Nov  8 17:22:29.541: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  8 17:22:29.588: INFO: namespace: e2e-tests-containers-vg9v9, resource: bindings, ignored listing per whitelist
Nov  8 17:22:29.595: INFO: namespace e2e-tests-containers-vg9v9 deletion completed in 6.062234152s

• [SLOW TEST:8.124 seconds]
[k8s.io] Docker Containers
/go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,default) [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  8 17:22:29.595: INFO: >>> kubeConfig: /tmp/kubeconfig-235977939
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,default) [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0644 on node default medium
Nov  8 17:22:29.635: INFO: Waiting up to 5m0s for pod "pod-deaf12a5-e37a-11e8-b0fd-0e97e856486a" in namespace "e2e-tests-emptydir-xkh4x" to be "success or failure"
Nov  8 17:22:29.637: INFO: Pod "pod-deaf12a5-e37a-11e8-b0fd-0e97e856486a": Phase="Pending", Reason="", readiness=false. Elapsed: 1.571266ms
Nov  8 17:22:31.639: INFO: Pod "pod-deaf12a5-e37a-11e8-b0fd-0e97e856486a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.003732101s
STEP: Saw pod success
Nov  8 17:22:31.639: INFO: Pod "pod-deaf12a5-e37a-11e8-b0fd-0e97e856486a" satisfied condition "success or failure"
Nov  8 17:22:31.641: INFO: Trying to get logs from node ip-10-0-100-224.ec2.internal pod pod-deaf12a5-e37a-11e8-b0fd-0e97e856486a container test-container: <nil>
STEP: delete the pod
Nov  8 17:22:31.651: INFO: Waiting for pod pod-deaf12a5-e37a-11e8-b0fd-0e97e856486a to disappear
Nov  8 17:22:31.652: INFO: Pod pod-deaf12a5-e37a-11e8-b0fd-0e97e856486a no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  8 17:22:31.652: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-xkh4x" for this suite.
Nov  8 17:22:37.660: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  8 17:22:37.680: INFO: namespace: e2e-tests-emptydir-xkh4x, resource: bindings, ignored listing per whitelist
Nov  8 17:22:37.714: INFO: namespace e2e-tests-emptydir-xkh4x deletion completed in 6.059562338s

• [SLOW TEST:8.119 seconds]
[sig-storage] EmptyDir volumes
/go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0644,default) [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  8 17:22:37.714: INFO: >>> kubeConfig: /tmp/kubeconfig-235977939
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-e3862511-e37a-11e8-b0fd-0e97e856486a
STEP: Creating a pod to test consume secrets
Nov  8 17:22:37.757: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-e38664c7-e37a-11e8-b0fd-0e97e856486a" in namespace "e2e-tests-projected-5vj78" to be "success or failure"
Nov  8 17:22:37.759: INFO: Pod "pod-projected-secrets-e38664c7-e37a-11e8-b0fd-0e97e856486a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.069941ms
Nov  8 17:22:39.761: INFO: Pod "pod-projected-secrets-e38664c7-e37a-11e8-b0fd-0e97e856486a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004060502s
STEP: Saw pod success
Nov  8 17:22:39.761: INFO: Pod "pod-projected-secrets-e38664c7-e37a-11e8-b0fd-0e97e856486a" satisfied condition "success or failure"
Nov  8 17:22:39.763: INFO: Trying to get logs from node ip-10-0-100-224.ec2.internal pod pod-projected-secrets-e38664c7-e37a-11e8-b0fd-0e97e856486a container projected-secret-volume-test: <nil>
STEP: delete the pod
Nov  8 17:22:39.772: INFO: Waiting for pod pod-projected-secrets-e38664c7-e37a-11e8-b0fd-0e97e856486a to disappear
Nov  8 17:22:39.773: INFO: Pod pod-projected-secrets-e38664c7-e37a-11e8-b0fd-0e97e856486a no longer exists
[AfterEach] [sig-storage] Projected
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  8 17:22:39.773: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-5vj78" for this suite.
Nov  8 17:22:45.780: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  8 17:22:45.831: INFO: namespace: e2e-tests-projected-5vj78, resource: bindings, ignored listing per whitelist
Nov  8 17:22:45.835: INFO: namespace e2e-tests-projected-5vj78 deletion completed in 6.059460755s

• [SLOW TEST:8.121 seconds]
[sig-storage] Projected
/go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Docker Containers
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  8 17:22:45.835: INFO: >>> kubeConfig: /tmp/kubeconfig-235977939
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test override arguments
Nov  8 17:22:45.874: INFO: Waiting up to 5m0s for pod "client-containers-e85ced4b-e37a-11e8-b0fd-0e97e856486a" in namespace "e2e-tests-containers-rpn9j" to be "success or failure"
Nov  8 17:22:45.876: INFO: Pod "client-containers-e85ced4b-e37a-11e8-b0fd-0e97e856486a": Phase="Pending", Reason="", readiness=false. Elapsed: 1.818116ms
Nov  8 17:22:47.878: INFO: Pod "client-containers-e85ced4b-e37a-11e8-b0fd-0e97e856486a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.003957503s
STEP: Saw pod success
Nov  8 17:22:47.878: INFO: Pod "client-containers-e85ced4b-e37a-11e8-b0fd-0e97e856486a" satisfied condition "success or failure"
Nov  8 17:22:47.880: INFO: Trying to get logs from node ip-10-0-100-224.ec2.internal pod client-containers-e85ced4b-e37a-11e8-b0fd-0e97e856486a container test-container: <nil>
STEP: delete the pod
Nov  8 17:22:47.889: INFO: Waiting for pod client-containers-e85ced4b-e37a-11e8-b0fd-0e97e856486a to disappear
Nov  8 17:22:47.893: INFO: Pod client-containers-e85ced4b-e37a-11e8-b0fd-0e97e856486a no longer exists
[AfterEach] [k8s.io] Docker Containers
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  8 17:22:47.893: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-rpn9j" for this suite.
Nov  8 17:22:53.901: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  8 17:22:53.926: INFO: namespace: e2e-tests-containers-rpn9j, resource: bindings, ignored listing per whitelist
Nov  8 17:22:53.954: INFO: namespace e2e-tests-containers-rpn9j deletion completed in 6.059534388s

• [SLOW TEST:8.120 seconds]
[k8s.io] Docker Containers
/go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  8 17:22:53.955: INFO: >>> kubeConfig: /tmp/kubeconfig-235977939
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-map-ed342182-e37a-11e8-b0fd-0e97e856486a
STEP: Creating a pod to test consume secrets
Nov  8 17:22:53.997: INFO: Waiting up to 5m0s for pod "pod-secrets-ed345eef-e37a-11e8-b0fd-0e97e856486a" in namespace "e2e-tests-secrets-gbbwx" to be "success or failure"
Nov  8 17:22:53.999: INFO: Pod "pod-secrets-ed345eef-e37a-11e8-b0fd-0e97e856486a": Phase="Pending", Reason="", readiness=false. Elapsed: 1.609644ms
Nov  8 17:22:56.001: INFO: Pod "pod-secrets-ed345eef-e37a-11e8-b0fd-0e97e856486a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.003810898s
STEP: Saw pod success
Nov  8 17:22:56.001: INFO: Pod "pod-secrets-ed345eef-e37a-11e8-b0fd-0e97e856486a" satisfied condition "success or failure"
Nov  8 17:22:56.002: INFO: Trying to get logs from node ip-10-0-100-224.ec2.internal pod pod-secrets-ed345eef-e37a-11e8-b0fd-0e97e856486a container secret-volume-test: <nil>
STEP: delete the pod
Nov  8 17:22:56.013: INFO: Waiting for pod pod-secrets-ed345eef-e37a-11e8-b0fd-0e97e856486a to disappear
Nov  8 17:22:56.014: INFO: Pod pod-secrets-ed345eef-e37a-11e8-b0fd-0e97e856486a no longer exists
[AfterEach] [sig-storage] Secrets
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  8 17:22:56.014: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-gbbwx" for this suite.
Nov  8 17:23:02.022: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  8 17:23:02.061: INFO: namespace: e2e-tests-secrets-gbbwx, resource: bindings, ignored listing per whitelist
Nov  8 17:23:02.076: INFO: namespace e2e-tests-secrets-gbbwx deletion completed in 6.059815934s

• [SLOW TEST:8.121 seconds]
[sig-storage] Secrets
/go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  8 17:23:02.076: INFO: >>> kubeConfig: /tmp/kubeconfig-235977939
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-map-f20b21a8-e37a-11e8-b0fd-0e97e856486a
STEP: Creating a pod to test consume configMaps
Nov  8 17:23:02.118: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-f20b5dce-e37a-11e8-b0fd-0e97e856486a" in namespace "e2e-tests-projected-rm498" to be "success or failure"
Nov  8 17:23:02.119: INFO: Pod "pod-projected-configmaps-f20b5dce-e37a-11e8-b0fd-0e97e856486a": Phase="Pending", Reason="", readiness=false. Elapsed: 1.469353ms
Nov  8 17:23:04.121: INFO: Pod "pod-projected-configmaps-f20b5dce-e37a-11e8-b0fd-0e97e856486a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.003551204s
STEP: Saw pod success
Nov  8 17:23:04.121: INFO: Pod "pod-projected-configmaps-f20b5dce-e37a-11e8-b0fd-0e97e856486a" satisfied condition "success or failure"
Nov  8 17:23:04.123: INFO: Trying to get logs from node ip-10-0-100-224.ec2.internal pod pod-projected-configmaps-f20b5dce-e37a-11e8-b0fd-0e97e856486a container projected-configmap-volume-test: <nil>
STEP: delete the pod
Nov  8 17:23:04.133: INFO: Waiting for pod pod-projected-configmaps-f20b5dce-e37a-11e8-b0fd-0e97e856486a to disappear
Nov  8 17:23:04.134: INFO: Pod pod-projected-configmaps-f20b5dce-e37a-11e8-b0fd-0e97e856486a no longer exists
[AfterEach] [sig-storage] Projected
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  8 17:23:04.134: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-rm498" for this suite.
Nov  8 17:23:10.141: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  8 17:23:10.178: INFO: namespace: e2e-tests-projected-rm498, resource: bindings, ignored listing per whitelist
Nov  8 17:23:10.198: INFO: namespace e2e-tests-projected-rm498 deletion completed in 6.06138023s

• [SLOW TEST:8.122 seconds]
[sig-storage] Projected
/go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] Projected 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  8 17:23:10.198: INFO: >>> kubeConfig: /tmp/kubeconfig-235977939
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name cm-test-opt-del-f6e2e566-e37a-11e8-b0fd-0e97e856486a
STEP: Creating configMap with name cm-test-opt-upd-f6e2e58d-e37a-11e8-b0fd-0e97e856486a
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-f6e2e566-e37a-11e8-b0fd-0e97e856486a
STEP: Updating configmap cm-test-opt-upd-f6e2e58d-e37a-11e8-b0fd-0e97e856486a
STEP: Creating configMap with name cm-test-opt-create-f6e2e59a-e37a-11e8-b0fd-0e97e856486a
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  8 17:23:14.284: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-zfgpm" for this suite.
Nov  8 17:23:36.292: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  8 17:23:36.343: INFO: namespace: e2e-tests-projected-zfgpm, resource: bindings, ignored listing per whitelist
Nov  8 17:23:36.346: INFO: namespace e2e-tests-projected-zfgpm deletion completed in 22.059474734s

• [SLOW TEST:26.148 seconds]
[sig-storage] Projected
/go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should update labels on modification [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  8 17:23:36.346: INFO: >>> kubeConfig: /tmp/kubeconfig-235977939
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should update labels on modification [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating the pod
Nov  8 17:23:38.903: INFO: Successfully updated pod "labelsupdate0678cdc7-e37b-11e8-b0fd-0e97e856486a"
[AfterEach] [sig-storage] Downward API volume
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  8 17:23:42.922: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-hn6fw" for this suite.
Nov  8 17:24:04.930: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  8 17:24:04.978: INFO: namespace: e2e-tests-downward-api-hn6fw, resource: bindings, ignored listing per whitelist
Nov  8 17:24:04.985: INFO: namespace e2e-tests-downward-api-hn6fw deletion completed in 22.060221518s

• [SLOW TEST:28.638 seconds]
[sig-storage] Downward API volume
/go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should update labels on modification [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  8 17:24:04.985: INFO: >>> kubeConfig: /tmp/kubeconfig-235977939
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-http in namespace e2e-tests-container-probe-jcfp5
Nov  8 17:24:07.030: INFO: Started pod liveness-http in namespace e2e-tests-container-probe-jcfp5
STEP: checking the pod's current state and verifying that restartCount is present
Nov  8 17:24:07.031: INFO: Initial restart count of pod liveness-http is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  8 17:28:07.293: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-jcfp5" for this suite.
Nov  8 17:28:13.301: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  8 17:28:13.306: INFO: namespace: e2e-tests-container-probe-jcfp5, resource: bindings, ignored listing per whitelist
Nov  8 17:28:13.359: INFO: namespace e2e-tests-container-probe-jcfp5 deletion completed in 6.063419888s

• [SLOW TEST:248.374 seconds]
[k8s.io] Probing container
/go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  8 17:28:13.359: INFO: >>> kubeConfig: /tmp/kubeconfig-235977939
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-map-ab9590d0-e37b-11e8-b0fd-0e97e856486a
STEP: Creating a pod to test consume configMaps
Nov  8 17:28:13.403: INFO: Waiting up to 5m0s for pod "pod-configmaps-ab95cc20-e37b-11e8-b0fd-0e97e856486a" in namespace "e2e-tests-configmap-j4wnv" to be "success or failure"
Nov  8 17:28:13.406: INFO: Pod "pod-configmaps-ab95cc20-e37b-11e8-b0fd-0e97e856486a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.511199ms
Nov  8 17:28:15.408: INFO: Pod "pod-configmaps-ab95cc20-e37b-11e8-b0fd-0e97e856486a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004631165s
STEP: Saw pod success
Nov  8 17:28:15.408: INFO: Pod "pod-configmaps-ab95cc20-e37b-11e8-b0fd-0e97e856486a" satisfied condition "success or failure"
Nov  8 17:28:15.410: INFO: Trying to get logs from node ip-10-0-100-224.ec2.internal pod pod-configmaps-ab95cc20-e37b-11e8-b0fd-0e97e856486a container configmap-volume-test: <nil>
STEP: delete the pod
Nov  8 17:28:15.420: INFO: Waiting for pod pod-configmaps-ab95cc20-e37b-11e8-b0fd-0e97e856486a to disappear
Nov  8 17:28:15.421: INFO: Pod pod-configmaps-ab95cc20-e37b-11e8-b0fd-0e97e856486a no longer exists
[AfterEach] [sig-storage] ConfigMap
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  8 17:28:15.421: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-j4wnv" for this suite.
Nov  8 17:28:21.431: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  8 17:28:21.436: INFO: namespace: e2e-tests-configmap-j4wnv, resource: bindings, ignored listing per whitelist
Nov  8 17:28:21.485: INFO: namespace e2e-tests-configmap-j4wnv deletion completed in 6.061439985s

• [SLOW TEST:8.126 seconds]
[sig-storage] ConfigMap
/go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Projected 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  8 17:28:21.485: INFO: >>> kubeConfig: /tmp/kubeconfig-235977939
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-b06d1ef0-e37b-11e8-b0fd-0e97e856486a
STEP: Creating a pod to test consume configMaps
Nov  8 17:28:21.526: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-b06d6013-e37b-11e8-b0fd-0e97e856486a" in namespace "e2e-tests-projected-qnmts" to be "success or failure"
Nov  8 17:28:21.528: INFO: Pod "pod-projected-configmaps-b06d6013-e37b-11e8-b0fd-0e97e856486a": Phase="Pending", Reason="", readiness=false. Elapsed: 1.615573ms
Nov  8 17:28:23.530: INFO: Pod "pod-projected-configmaps-b06d6013-e37b-11e8-b0fd-0e97e856486a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.003700983s
STEP: Saw pod success
Nov  8 17:28:23.530: INFO: Pod "pod-projected-configmaps-b06d6013-e37b-11e8-b0fd-0e97e856486a" satisfied condition "success or failure"
Nov  8 17:28:23.532: INFO: Trying to get logs from node ip-10-0-100-224.ec2.internal pod pod-projected-configmaps-b06d6013-e37b-11e8-b0fd-0e97e856486a container projected-configmap-volume-test: <nil>
STEP: delete the pod
Nov  8 17:28:23.542: INFO: Waiting for pod pod-projected-configmaps-b06d6013-e37b-11e8-b0fd-0e97e856486a to disappear
Nov  8 17:28:23.543: INFO: Pod pod-projected-configmaps-b06d6013-e37b-11e8-b0fd-0e97e856486a no longer exists
[AfterEach] [sig-storage] Projected
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  8 17:28:23.543: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-qnmts" for this suite.
Nov  8 17:28:29.550: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  8 17:28:29.574: INFO: namespace: e2e-tests-projected-qnmts, resource: bindings, ignored listing per whitelist
Nov  8 17:28:29.604: INFO: namespace e2e-tests-projected-qnmts deletion completed in 6.058784911s

• [SLOW TEST:8.119 seconds]
[sig-storage] Projected
/go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] Downward API volume 
  should set mode on item file [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  8 17:28:29.604: INFO: >>> kubeConfig: /tmp/kubeconfig-235977939
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should set mode on item file [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Nov  8 17:28:29.645: INFO: Waiting up to 5m0s for pod "downwardapi-volume-b5443298-e37b-11e8-b0fd-0e97e856486a" in namespace "e2e-tests-downward-api-57b7q" to be "success or failure"
Nov  8 17:28:29.647: INFO: Pod "downwardapi-volume-b5443298-e37b-11e8-b0fd-0e97e856486a": Phase="Pending", Reason="", readiness=false. Elapsed: 1.631742ms
Nov  8 17:28:31.649: INFO: Pod "downwardapi-volume-b5443298-e37b-11e8-b0fd-0e97e856486a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.003786185s
STEP: Saw pod success
Nov  8 17:28:31.649: INFO: Pod "downwardapi-volume-b5443298-e37b-11e8-b0fd-0e97e856486a" satisfied condition "success or failure"
Nov  8 17:28:31.650: INFO: Trying to get logs from node ip-10-0-100-224.ec2.internal pod downwardapi-volume-b5443298-e37b-11e8-b0fd-0e97e856486a container client-container: <nil>
STEP: delete the pod
Nov  8 17:28:31.660: INFO: Waiting for pod downwardapi-volume-b5443298-e37b-11e8-b0fd-0e97e856486a to disappear
Nov  8 17:28:31.661: INFO: Pod downwardapi-volume-b5443298-e37b-11e8-b0fd-0e97e856486a no longer exists
[AfterEach] [sig-storage] Downward API volume
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  8 17:28:31.661: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-57b7q" for this suite.
Nov  8 17:28:37.669: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  8 17:28:37.692: INFO: namespace: e2e-tests-downward-api-57b7q, resource: bindings, ignored listing per whitelist
Nov  8 17:28:37.723: INFO: namespace e2e-tests-downward-api-57b7q deletion completed in 6.059737596s

• [SLOW TEST:8.120 seconds]
[sig-storage] Downward API volume
/go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should set mode on item file [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  8 17:28:37.724: INFO: >>> kubeConfig: /tmp/kubeconfig-235977939
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-upd-ba1b2c25-e37b-11e8-b0fd-0e97e856486a
STEP: Creating the pod
STEP: Updating configmap configmap-test-upd-ba1b2c25-e37b-11e8-b0fd-0e97e856486a
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  8 17:28:41.787: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-s8mws" for this suite.
Nov  8 17:29:03.795: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  8 17:29:03.831: INFO: namespace: e2e-tests-configmap-s8mws, resource: bindings, ignored listing per whitelist
Nov  8 17:29:03.850: INFO: namespace e2e-tests-configmap-s8mws deletion completed in 22.060325921s

• [SLOW TEST:26.126 seconds]
[sig-storage] ConfigMap
/go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  updates should be reflected in volume [NodeConformance] [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl version 
  should check is all data is printed  [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Nov  8 17:29:03.850: INFO: >>> kubeConfig: /tmp/kubeconfig-235977939
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should check is all data is printed  [Conformance]
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Nov  8 17:29:03.889: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-235977939 version'
Nov  8 17:29:03.949: INFO: stderr: ""
Nov  8 17:29:03.949: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"12+\", GitVersion:\"v1.12.2-heptio.1\", GitCommit:\"066ecbf74983f77692028c559a35725ce74122a4\", GitTreeState:\"clean\", BuildDate:\"2018-10-30T16:02:00Z\", GoVersion:\"go1.10.4\", Compiler:\"gc\", Platform:\"linux/amd64\"}\nServer Version: version.Info{Major:\"1\", Minor:\"12+\", GitVersion:\"v1.12.2-heptio.1\", GitCommit:\"066ecbf74983f77692028c559a35725ce74122a4\", GitTreeState:\"clean\", BuildDate:\"2018-10-30T15:57:21Z\", GoVersion:\"go1.10.4\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
[AfterEach] [sig-cli] Kubectl client
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Nov  8 17:29:03.949: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-2jzs8" for this suite.
Nov  8 17:29:09.957: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  8 17:29:09.994: INFO: namespace: e2e-tests-kubectl-2jzs8, resource: bindings, ignored listing per whitelist
Nov  8 17:29:10.011: INFO: namespace e2e-tests-kubectl-2jzs8 deletion completed in 6.059502888s

• [SLOW TEST:6.161 seconds]
[sig-cli] Kubectl client
/go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl version
  /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should check is all data is printed  [Conformance]
    /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSNov  8 17:29:10.011: INFO: Running AfterSuite actions on all node
Nov  8 17:29:10.011: INFO: Running AfterSuite actions on node 1
Nov  8 17:29:10.011: INFO: Dumping logs locally to: /tmp/results
Nov  8 17:29:10.011: INFO: Error running cluster/log-dump/log-dump.sh: fork/exec ../../cluster/log-dump/log-dump.sh: no such file or directory

Ran 187 of 1814 Specs in 4477.940 seconds
SUCCESS! -- 187 Passed | 0 Failed | 0 Pending | 1627 Skipped PASS
