Jan 21 21:19:42.941: INFO: Overriding default scale value of zero to 1
Jan 21 21:19:42.941: INFO: Overriding default milliseconds value of zero to 5000
I0121 21:19:43.934103      15 test_context.go:385] Using a temporary kubeconfig file from in-cluster config : /tmp/kubeconfig-933165938
I0121 21:19:43.939002      15 e2e.go:304] Starting e2e run "44dcb9d7-1dc2-11e9-8130-be6597f3ae53" on Ginkgo node 1
Running Suite: Kubernetes e2e suite
===================================
Random Seed: 1548105582 - Will randomize all specs
Will run 188 of 1814 specs

Jan 21 21:19:44.190: INFO: >>> kubeConfig: /tmp/kubeconfig-933165938
Jan 21 21:19:44.195: INFO: Waiting up to 30m0s for all (but 0) nodes to be schedulable
Jan 21 21:19:44.247: INFO: Waiting up to 10m0s for all pods (need at least 0) in namespace 'kube-system' to be running and ready
Jan 21 21:19:44.329: INFO: 23 / 23 pods in namespace 'kube-system' are running and ready (0 seconds elapsed)
Jan 21 21:19:44.329: INFO: expected 11 pod replicas in namespace 'kube-system', 11 are Running and Ready.
Jan 21 21:19:44.329: INFO: Waiting up to 5m0s for all daemonsets in namespace 'kube-system' to start
Jan 21 21:19:44.354: INFO: 3 / 3 pods ready in namespace 'kube-system' in daemonset 'calico-node' (0 seconds elapsed)
Jan 21 21:19:44.354: INFO: 3 / 3 pods ready in namespace 'kube-system' in daemonset 'ibm-keepalived-watcher' (0 seconds elapsed)
Jan 21 21:19:44.355: INFO: 3 / 3 pods ready in namespace 'kube-system' in daemonset 'ibm-kube-fluentd' (0 seconds elapsed)
Jan 21 21:19:44.355: INFO: 0 / 0 pods ready in namespace 'kube-system' in daemonset 'ibm-master-proxy' (0 seconds elapsed)
Jan 21 21:19:44.355: INFO: 0 / 0 pods ready in namespace 'kube-system' in daemonset 'nvidia-driver-installer' (0 seconds elapsed)
Jan 21 21:19:44.355: INFO: 0 / 0 pods ready in namespace 'kube-system' in daemonset 'nvidia-gpu-device-plugin' (0 seconds elapsed)
Jan 21 21:19:44.355: INFO: e2e test version: v1.12.1
Jan 21 21:19:44.358: INFO: kube-apiserver version: v1.12.4+IKS
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on default medium should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 21:19:44.362: INFO: >>> kubeConfig: /tmp/kubeconfig-933165938
STEP: Building a namespace api object, basename emptydir
Jan 21 21:19:44.755: INFO: Found PodSecurityPolicies; assuming PodSecurityPolicy is enabled.
Jan 21 21:19:44.781: INFO: Found ClusterRoles; assuming RBAC is enabled.
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-kdhkg
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on default medium should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir volume type on node default medium
Jan 21 21:19:44.925: INFO: Waiting up to 5m0s for pod "pod-4623070f-1dc2-11e9-8130-be6597f3ae53" in namespace "e2e-tests-emptydir-kdhkg" to be "success or failure"
Jan 21 21:19:44.934: INFO: Pod "pod-4623070f-1dc2-11e9-8130-be6597f3ae53": Phase="Pending", Reason="", readiness=false. Elapsed: 9.269464ms
Jan 21 21:19:46.945: INFO: Pod "pod-4623070f-1dc2-11e9-8130-be6597f3ae53": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.019401008s
STEP: Saw pod success
Jan 21 21:19:46.945: INFO: Pod "pod-4623070f-1dc2-11e9-8130-be6597f3ae53" satisfied condition "success or failure"
Jan 21 21:19:46.954: INFO: Trying to get logs from node 10.191.28.39 pod pod-4623070f-1dc2-11e9-8130-be6597f3ae53 container test-container: <nil>
STEP: delete the pod
Jan 21 21:19:47.065: INFO: Waiting for pod pod-4623070f-1dc2-11e9-8130-be6597f3ae53 to disappear
Jan 21 21:19:47.074: INFO: Pod pod-4623070f-1dc2-11e9-8130-be6597f3ae53 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 21:19:47.075: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-kdhkg" for this suite.
Jan 21 21:19:53.123: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 21:19:53.403: INFO: namespace: e2e-tests-emptydir-kdhkg, resource: bindings, ignored listing per whitelist
Jan 21 21:19:53.479: INFO: namespace e2e-tests-emptydir-kdhkg deletion completed in 6.38974737s

• [SLOW TEST:9.117 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  volume on default medium should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 21:19:53.480: INFO: >>> kubeConfig: /tmp/kubeconfig-933165938
STEP: Building a namespace api object, basename init-container
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-init-container-hm5wk
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
Jan 21 21:19:53.806: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 21:19:57.534: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-init-container-hm5wk" for this suite.
Jan 21 21:20:03.597: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 21:20:03.765: INFO: namespace: e2e-tests-init-container-hm5wk, resource: bindings, ignored listing per whitelist
Jan 21 21:20:04.149: INFO: namespace e2e-tests-init-container-hm5wk deletion completed in 6.600772825s

• [SLOW TEST:10.670 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] ConfigMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 21:20:04.151: INFO: >>> kubeConfig: /tmp/kubeconfig-933165938
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-rvgg9
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-upd-51ddf95c-1dc2-11e9-8130-be6597f3ae53
STEP: Creating the pod
STEP: Updating configmap configmap-test-upd-51ddf95c-1dc2-11e9-8130-be6597f3ae53
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 21:20:08.840: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-rvgg9" for this suite.
Jan 21 21:20:32.892: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 21:20:32.998: INFO: namespace: e2e-tests-configmap-rvgg9, resource: bindings, ignored listing per whitelist
Jan 21 21:20:33.294: INFO: namespace e2e-tests-configmap-rvgg9 deletion completed in 24.437868453s

• [SLOW TEST:29.144 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] version v1
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 21:20:33.295: INFO: >>> kubeConfig: /tmp/kubeconfig-933165938
STEP: Building a namespace api object, basename proxy
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-proxy-4nvc6
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Jan 21 21:20:33.783: INFO: (0) /api/v1/nodes/10.191.28.39:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 103.245807ms)
Jan 21 21:20:33.800: INFO: (1) /api/v1/nodes/10.191.28.39:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 16.932392ms)
Jan 21 21:20:33.817: INFO: (2) /api/v1/nodes/10.191.28.39:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 16.277061ms)
Jan 21 21:20:33.832: INFO: (3) /api/v1/nodes/10.191.28.39:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 14.620574ms)
Jan 21 21:20:33.848: INFO: (4) /api/v1/nodes/10.191.28.39:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 16.039091ms)
Jan 21 21:20:33.869: INFO: (5) /api/v1/nodes/10.191.28.39:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 20.539328ms)
Jan 21 21:20:33.886: INFO: (6) /api/v1/nodes/10.191.28.39:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 17.195635ms)
Jan 21 21:20:33.901: INFO: (7) /api/v1/nodes/10.191.28.39:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 14.59374ms)
Jan 21 21:20:33.916: INFO: (8) /api/v1/nodes/10.191.28.39:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 14.478178ms)
Jan 21 21:20:33.931: INFO: (9) /api/v1/nodes/10.191.28.39:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 14.789512ms)
Jan 21 21:20:33.945: INFO: (10) /api/v1/nodes/10.191.28.39:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 14.231919ms)
Jan 21 21:20:33.960: INFO: (11) /api/v1/nodes/10.191.28.39:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 14.765696ms)
Jan 21 21:20:33.976: INFO: (12) /api/v1/nodes/10.191.28.39:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 15.218899ms)
Jan 21 21:20:33.990: INFO: (13) /api/v1/nodes/10.191.28.39:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 14.07482ms)
Jan 21 21:20:34.005: INFO: (14) /api/v1/nodes/10.191.28.39:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 14.819242ms)
Jan 21 21:20:34.021: INFO: (15) /api/v1/nodes/10.191.28.39:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 16.405331ms)
Jan 21 21:20:34.037: INFO: (16) /api/v1/nodes/10.191.28.39:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 15.824115ms)
Jan 21 21:20:34.052: INFO: (17) /api/v1/nodes/10.191.28.39:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 14.527811ms)
Jan 21 21:20:34.067: INFO: (18) /api/v1/nodes/10.191.28.39:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 14.88317ms)
Jan 21 21:20:34.081: INFO: (19) /api/v1/nodes/10.191.28.39:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 13.948474ms)
[AfterEach] version v1
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 21:20:34.082: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-proxy-4nvc6" for this suite.
Jan 21 21:20:40.130: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 21:20:40.232: INFO: namespace: e2e-tests-proxy-4nvc6, resource: bindings, ignored listing per whitelist
Jan 21 21:20:40.688: INFO: namespace e2e-tests-proxy-4nvc6 deletion completed in 6.592325746s

• [SLOW TEST:7.393 seconds]
[sig-network] Proxy
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 21:20:40.690: INFO: >>> kubeConfig: /tmp/kubeconfig-933165938
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-deployment-9rknf
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Jan 21 21:20:40.995: INFO: Creating deployment "nginx-deployment"
Jan 21 21:20:41.005: INFO: Waiting for observed generation 1
Jan 21 21:20:43.020: INFO: Waiting for all required pods to come up
Jan 21 21:20:43.033: INFO: Pod name nginx: Found 10 pods out of 10
STEP: ensuring each pod is running
Jan 21 21:20:45.061: INFO: Waiting for deployment "nginx-deployment" to complete
Jan 21 21:20:45.081: INFO: Updating deployment "nginx-deployment" with a non-existent image
Jan 21 21:20:45.107: INFO: Updating deployment nginx-deployment
Jan 21 21:20:45.107: INFO: Waiting for observed generation 2
Jan 21 21:20:47.125: INFO: Waiting for the first rollout's replicaset to have .status.availableReplicas = 8
Jan 21 21:20:47.136: INFO: Waiting for the first rollout's replicaset to have .spec.replicas = 8
Jan 21 21:20:47.145: INFO: Waiting for the first rollout's replicaset of deployment "nginx-deployment" to have desired number of replicas
Jan 21 21:20:47.175: INFO: Verifying that the second rollout's replicaset has .status.availableReplicas = 0
Jan 21 21:20:47.175: INFO: Waiting for the second rollout's replicaset to have .spec.replicas = 5
Jan 21 21:20:47.189: INFO: Waiting for the second rollout's replicaset of deployment "nginx-deployment" to have desired number of replicas
Jan 21 21:20:47.213: INFO: Verifying that deployment "nginx-deployment" has minimum required number of available replicas
Jan 21 21:20:47.213: INFO: Scaling up the deployment "nginx-deployment" from 10 to 30
Jan 21 21:20:47.231: INFO: Updating deployment nginx-deployment
Jan 21 21:20:47.231: INFO: Waiting for the replicasets of deployment "nginx-deployment" to have desired number of replicas
Jan 21 21:20:47.251: INFO: Verifying that first rollout's replicaset has .spec.replicas = 20
Jan 21 21:20:47.275: INFO: Verifying that second rollout's replicaset has .spec.replicas = 13
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Jan 21 21:20:49.368: INFO: Deployment "nginx-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment,GenerateName:,Namespace:e2e-tests-deployment-9rknf,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-9rknf/deployments/nginx-deployment,UID:67916566-1dc2-11e9-903f-ee5d7ad9296f,ResourceVersion:30602,Generation:3,CreationTimestamp:2019-01-21 21:20:40 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*30,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:2,MaxSurge:3,},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:3,Replicas:33,UpdatedReplicas:13,AvailableReplicas:10,UnavailableReplicas:23,Conditions:[{Available False 2019-01-21 21:20:47 +0000 UTC 2019-01-21 21:20:47 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.} {Progressing True 2019-01-21 21:20:49 +0000 UTC 2019-01-21 21:20:41 +0000 UTC ReplicaSetUpdated ReplicaSet "nginx-deployment-7dc8f79789" is progressing.}],ReadyReplicas:10,CollisionCount:nil,},}

Jan 21 21:20:49.380: INFO: New ReplicaSet "nginx-deployment-7dc8f79789" of Deployment "nginx-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789,GenerateName:,Namespace:e2e-tests-deployment-9rknf,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-9rknf/replicasets/nginx-deployment-7dc8f79789,UID:6a0466a9-1dc2-11e9-903f-ee5d7ad9296f,ResourceVersion:30476,Generation:3,CreationTimestamp:2019-01-21 21:20:45 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 30,deployment.kubernetes.io/max-replicas: 33,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment nginx-deployment 67916566-1dc2-11e9-903f-ee5d7ad9296f 0xc421edb7e7 0xc421edb7e8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*13,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:13,FullyLabeledReplicas:13,ObservedGeneration:3,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Jan 21 21:20:49.382: INFO: All old ReplicaSets of Deployment "nginx-deployment":
Jan 21 21:20:49.384: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b,GenerateName:,Namespace:e2e-tests-deployment-9rknf,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-9rknf/replicasets/nginx-deployment-7f9675fb8b,UID:67944207-1dc2-11e9-903f-ee5d7ad9296f,ResourceVersion:30601,Generation:3,CreationTimestamp:2019-01-21 21:20:41 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 30,deployment.kubernetes.io/max-replicas: 33,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment nginx-deployment 67916566-1dc2-11e9-903f-ee5d7ad9296f 0xc421edb8a7 0xc421edb8a8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*20,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:20,FullyLabeledReplicas:20,ObservedGeneration:3,ReadyReplicas:10,AvailableReplicas:10,Conditions:[],},}
Jan 21 21:20:49.407: INFO: Pod "nginx-deployment-7dc8f79789-42qcg" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-42qcg,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-9rknf,SelfLink:/api/v1/namespaces/e2e-tests-deployment-9rknf/pods/nginx-deployment-7dc8f79789-42qcg,UID:6b4eb1ce-1dc2-11e9-903f-ee5d7ad9296f,ResourceVersion:30472,Generation:0,CreationTimestamp:2019-01-21 21:20:47 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 6a0466a9-1dc2-11e9-903f-ee5d7ad9296f 0xc421dc4187 0xc421dc4188}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-tmfjx {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-tmfjx,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-tmfjx true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.191.28.45,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc421dc4200} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421dc4220}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-21 21:20:47 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-21 21:20:47 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-01-21 21:20:47 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-21 21:20:47 +0000 UTC  }],Message:,Reason:,HostIP:10.191.28.45,PodIP:,StartTime:2019-01-21 21:20:47 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan 21 21:20:49.407: INFO: Pod "nginx-deployment-7dc8f79789-8jr9q" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-8jr9q,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-9rknf,SelfLink:/api/v1/namespaces/e2e-tests-deployment-9rknf/pods/nginx-deployment-7dc8f79789-8jr9q,UID:6a080d7d-1dc2-11e9-903f-ee5d7ad9296f,ResourceVersion:30376,Generation:0,CreationTimestamp:2019-01-21 21:20:45 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 6a0466a9-1dc2-11e9-903f-ee5d7ad9296f 0xc421dc42e0 0xc421dc42e1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-tmfjx {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-tmfjx,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-tmfjx true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.191.28.45,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc421dc4360} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421dc4380}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-21 21:20:45 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-21 21:20:45 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-01-21 21:20:45 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-21 21:20:45 +0000 UTC  }],Message:,Reason:,HostIP:10.191.28.45,PodIP:172.30.41.7,StartTime:2019-01-21 21:20:45 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = failed to resolve image "docker.io/library/nginx:404": docker.io/library/nginx:404 not found,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan 21 21:20:49.408: INFO: Pod "nginx-deployment-7dc8f79789-98kll" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-98kll,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-9rknf,SelfLink:/api/v1/namespaces/e2e-tests-deployment-9rknf/pods/nginx-deployment-7dc8f79789-98kll,UID:6b4cefbe-1dc2-11e9-903f-ee5d7ad9296f,ResourceVersion:30590,Generation:0,CreationTimestamp:2019-01-21 21:20:47 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 6a0466a9-1dc2-11e9-903f-ee5d7ad9296f 0xc421dc4460 0xc421dc4461}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-tmfjx {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-tmfjx,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-tmfjx true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.191.28.39,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc421dc44e0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421dc4500}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-21 21:20:47 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-21 21:20:47 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-01-21 21:20:47 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-21 21:20:47 +0000 UTC  }],Message:,Reason:,HostIP:10.191.28.39,PodIP:172.30.216.56,StartTime:2019-01-21 21:20:47 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = failed to resolve image "docker.io/library/nginx:404": docker.io/library/nginx:404 not found,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan 21 21:20:49.408: INFO: Pod "nginx-deployment-7dc8f79789-9sv8n" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-9sv8n,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-9rknf,SelfLink:/api/v1/namespaces/e2e-tests-deployment-9rknf/pods/nginx-deployment-7dc8f79789-9sv8n,UID:6b4eaf8c-1dc2-11e9-903f-ee5d7ad9296f,ResourceVersion:30457,Generation:0,CreationTimestamp:2019-01-21 21:20:47 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 6a0466a9-1dc2-11e9-903f-ee5d7ad9296f 0xc421dc45e0 0xc421dc45e1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-tmfjx {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-tmfjx,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-tmfjx true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.191.28.59,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc421dc4660} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421dc4680}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-21 21:20:47 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-21 21:20:47 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-01-21 21:20:47 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-21 21:20:47 +0000 UTC  }],Message:,Reason:,HostIP:10.191.28.59,PodIP:,StartTime:2019-01-21 21:20:47 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan 21 21:20:49.408: INFO: Pod "nginx-deployment-7dc8f79789-h8fwr" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-h8fwr,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-9rknf,SelfLink:/api/v1/namespaces/e2e-tests-deployment-9rknf/pods/nginx-deployment-7dc8f79789-h8fwr,UID:6b4e9303-1dc2-11e9-903f-ee5d7ad9296f,ResourceVersion:30468,Generation:0,CreationTimestamp:2019-01-21 21:20:47 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 6a0466a9-1dc2-11e9-903f-ee5d7ad9296f 0xc421dc4740 0xc421dc4741}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-tmfjx {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-tmfjx,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-tmfjx true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.191.28.39,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc421dc47c0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421dc47e0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-21 21:20:47 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-21 21:20:47 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-01-21 21:20:47 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-21 21:20:47 +0000 UTC  }],Message:,Reason:,HostIP:10.191.28.39,PodIP:,StartTime:2019-01-21 21:20:47 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan 21 21:20:49.409: INFO: Pod "nginx-deployment-7dc8f79789-nxbdf" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-nxbdf,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-9rknf,SelfLink:/api/v1/namespaces/e2e-tests-deployment-9rknf/pods/nginx-deployment-7dc8f79789-nxbdf,UID:6a109b68-1dc2-11e9-903f-ee5d7ad9296f,ResourceVersion:30597,Generation:0,CreationTimestamp:2019-01-21 21:20:45 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 6a0466a9-1dc2-11e9-903f-ee5d7ad9296f 0xc421dc48a0 0xc421dc48a1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-tmfjx {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-tmfjx,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-tmfjx true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.191.28.45,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc421dc4920} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421dc4940}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-21 21:20:45 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-21 21:20:45 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-01-21 21:20:45 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-21 21:20:45 +0000 UTC  }],Message:,Reason:,HostIP:10.191.28.45,PodIP:172.30.41.8,StartTime:2019-01-21 21:20:45 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = failed to resolve image "docker.io/library/nginx:404": docker.io/library/nginx:404 not found,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan 21 21:20:49.409: INFO: Pod "nginx-deployment-7dc8f79789-p4kdp" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-p4kdp,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-9rknf,SelfLink:/api/v1/namespaces/e2e-tests-deployment-9rknf/pods/nginx-deployment-7dc8f79789-p4kdp,UID:6b4d4aee-1dc2-11e9-903f-ee5d7ad9296f,ResourceVersion:30449,Generation:0,CreationTimestamp:2019-01-21 21:20:47 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 6a0466a9-1dc2-11e9-903f-ee5d7ad9296f 0xc421dc4a20 0xc421dc4a21}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-tmfjx {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-tmfjx,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-tmfjx true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.191.28.45,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc421dc4aa0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421dc4ac0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-21 21:20:47 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-21 21:20:47 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-01-21 21:20:47 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-21 21:20:47 +0000 UTC  }],Message:,Reason:,HostIP:10.191.28.45,PodIP:,StartTime:2019-01-21 21:20:47 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan 21 21:20:49.409: INFO: Pod "nginx-deployment-7dc8f79789-ppqv8" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-ppqv8,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-9rknf,SelfLink:/api/v1/namespaces/e2e-tests-deployment-9rknf/pods/nginx-deployment-7dc8f79789-ppqv8,UID:6a165909-1dc2-11e9-903f-ee5d7ad9296f,ResourceVersion:30365,Generation:0,CreationTimestamp:2019-01-21 21:20:45 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 6a0466a9-1dc2-11e9-903f-ee5d7ad9296f 0xc421dc4b80 0xc421dc4b81}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-tmfjx {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-tmfjx,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-tmfjx true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.191.28.39,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc421dc4c00} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421dc4c20}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-21 21:20:45 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-21 21:20:45 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-01-21 21:20:45 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-21 21:20:45 +0000 UTC  }],Message:,Reason:,HostIP:10.191.28.39,PodIP:172.30.216.53,StartTime:2019-01-21 21:20:45 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = failed to resolve image "docker.io/library/nginx:404": docker.io/library/nginx:404 not found,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan 21 21:20:49.410: INFO: Pod "nginx-deployment-7dc8f79789-tdlqb" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-tdlqb,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-9rknf,SelfLink:/api/v1/namespaces/e2e-tests-deployment-9rknf/pods/nginx-deployment-7dc8f79789-tdlqb,UID:6a07bf2e-1dc2-11e9-903f-ee5d7ad9296f,ResourceVersion:30360,Generation:0,CreationTimestamp:2019-01-21 21:20:45 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 6a0466a9-1dc2-11e9-903f-ee5d7ad9296f 0xc421dc4d00 0xc421dc4d01}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-tmfjx {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-tmfjx,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-tmfjx true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.191.28.59,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc421dc4d80} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421dc4da0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-21 21:20:45 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-21 21:20:45 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-01-21 21:20:45 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-21 21:20:45 +0000 UTC  }],Message:,Reason:,HostIP:10.191.28.59,PodIP:172.30.156.134,StartTime:2019-01-21 21:20:45 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = failed to resolve image "docker.io/library/nginx:404": docker.io/library/nginx:404 not found,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan 21 21:20:49.410: INFO: Pod "nginx-deployment-7dc8f79789-twx7t" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-twx7t,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-9rknf,SelfLink:/api/v1/namespaces/e2e-tests-deployment-9rknf/pods/nginx-deployment-7dc8f79789-twx7t,UID:6b50bc6e-1dc2-11e9-903f-ee5d7ad9296f,ResourceVersion:30537,Generation:0,CreationTimestamp:2019-01-21 21:20:47 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 6a0466a9-1dc2-11e9-903f-ee5d7ad9296f 0xc421dc4e80 0xc421dc4e81}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-tmfjx {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-tmfjx,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-tmfjx true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.191.28.45,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc421dc4f00} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421dc4f20}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-21 21:20:47 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-21 21:20:47 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-01-21 21:20:47 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-21 21:20:47 +0000 UTC  }],Message:,Reason:,HostIP:10.191.28.45,PodIP:,StartTime:2019-01-21 21:20:47 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan 21 21:20:49.410: INFO: Pod "nginx-deployment-7dc8f79789-tzchq" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-tzchq,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-9rknf,SelfLink:/api/v1/namespaces/e2e-tests-deployment-9rknf/pods/nginx-deployment-7dc8f79789-tzchq,UID:6a060c6a-1dc2-11e9-903f-ee5d7ad9296f,ResourceVersion:30370,Generation:0,CreationTimestamp:2019-01-21 21:20:45 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 6a0466a9-1dc2-11e9-903f-ee5d7ad9296f 0xc421dc4fe0 0xc421dc4fe1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-tmfjx {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-tmfjx,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-tmfjx true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.191.28.39,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc421dc5060} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421dc5080}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-21 21:20:45 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-21 21:20:45 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-01-21 21:20:45 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-21 21:20:45 +0000 UTC  }],Message:,Reason:,HostIP:10.191.28.39,PodIP:172.30.216.54,StartTime:2019-01-21 21:20:45 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = failed to resolve image "docker.io/library/nginx:404": docker.io/library/nginx:404 not found,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan 21 21:20:49.410: INFO: Pod "nginx-deployment-7dc8f79789-whc59" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-whc59,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-9rknf,SelfLink:/api/v1/namespaces/e2e-tests-deployment-9rknf/pods/nginx-deployment-7dc8f79789-whc59,UID:6b4ea425-1dc2-11e9-903f-ee5d7ad9296f,ResourceVersion:30452,Generation:0,CreationTimestamp:2019-01-21 21:20:47 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 6a0466a9-1dc2-11e9-903f-ee5d7ad9296f 0xc421dc5160 0xc421dc5161}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-tmfjx {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-tmfjx,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-tmfjx true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.191.28.59,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc421dc51e0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421dc5200}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-21 21:20:47 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-21 21:20:47 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-01-21 21:20:47 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-21 21:20:47 +0000 UTC  }],Message:,Reason:,HostIP:10.191.28.59,PodIP:,StartTime:2019-01-21 21:20:47 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan 21 21:20:49.411: INFO: Pod "nginx-deployment-7dc8f79789-xrsjf" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-xrsjf,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-9rknf,SelfLink:/api/v1/namespaces/e2e-tests-deployment-9rknf/pods/nginx-deployment-7dc8f79789-xrsjf,UID:6b4b644b-1dc2-11e9-903f-ee5d7ad9296f,ResourceVersion:30428,Generation:0,CreationTimestamp:2019-01-21 21:20:47 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 6a0466a9-1dc2-11e9-903f-ee5d7ad9296f 0xc421dc52c0 0xc421dc52c1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-tmfjx {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-tmfjx,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-tmfjx true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.191.28.59,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc421dc5340} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421dc5360}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-21 21:20:47 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-21 21:20:47 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-01-21 21:20:47 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-21 21:20:47 +0000 UTC  }],Message:,Reason:,HostIP:10.191.28.59,PodIP:,StartTime:2019-01-21 21:20:47 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan 21 21:20:49.411: INFO: Pod "nginx-deployment-7f9675fb8b-26lkv" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-26lkv,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-9rknf,SelfLink:/api/v1/namespaces/e2e-tests-deployment-9rknf/pods/nginx-deployment-7f9675fb8b-26lkv,UID:6b4bb10a-1dc2-11e9-903f-ee5d7ad9296f,ResourceVersion:30446,Generation:0,CreationTimestamp:2019-01-21 21:20:47 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 67944207-1dc2-11e9-903f-ee5d7ad9296f 0xc421dc5420 0xc421dc5421}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-tmfjx {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-tmfjx,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-tmfjx true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.191.28.59,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc421dc5490} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421dc54b0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-21 21:20:47 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-21 21:20:47 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-01-21 21:20:47 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-21 21:20:47 +0000 UTC  }],Message:,Reason:,HostIP:10.191.28.59,PodIP:,StartTime:2019-01-21 21:20:47 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan 21 21:20:49.413: INFO: Pod "nginx-deployment-7f9675fb8b-7gnzl" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-7gnzl,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-9rknf,SelfLink:/api/v1/namespaces/e2e-tests-deployment-9rknf/pods/nginx-deployment-7f9675fb8b-7gnzl,UID:679c8581-1dc2-11e9-903f-ee5d7ad9296f,ResourceVersion:30247,Generation:0,CreationTimestamp:2019-01-21 21:20:41 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 67944207-1dc2-11e9-903f-ee5d7ad9296f 0xc421dc5567 0xc421dc5568}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-tmfjx {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-tmfjx,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-tmfjx true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.191.28.39,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc421dc55e0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421dc5600}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-21 21:20:41 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-01-21 21:20:42 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-01-21 21:20:42 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-21 21:20:41 +0000 UTC  }],Message:,Reason:,HostIP:10.191.28.39,PodIP:172.30.216.52,StartTime:2019-01-21 21:20:41 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-01-21 21:20:42 +0000 UTC,} nil} {nil nil nil} true 0 docker.io/library/nginx:1.14-alpine docker.io/library/nginx@sha256:e3f77f7f4a6bb5e7820e013fa60b96602b34f5704e796cfd94b561ae73adcf96 containerd://643569f93e11dce635e696ba654a5cf302d741abb919f48cfe9309bcc6140040}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan 21 21:20:49.413: INFO: Pod "nginx-deployment-7f9675fb8b-88z6t" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-88z6t,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-9rknf,SelfLink:/api/v1/namespaces/e2e-tests-deployment-9rknf/pods/nginx-deployment-7f9675fb8b-88z6t,UID:6b50d3b0-1dc2-11e9-903f-ee5d7ad9296f,ResourceVersion:30485,Generation:0,CreationTimestamp:2019-01-21 21:20:47 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 67944207-1dc2-11e9-903f-ee5d7ad9296f 0xc421dc56c7 0xc421dc56c8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-tmfjx {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-tmfjx,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-tmfjx true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.191.28.39,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc421dc5740} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421dc5760}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-21 21:20:47 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-21 21:20:47 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-01-21 21:20:47 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-21 21:20:47 +0000 UTC  }],Message:,Reason:,HostIP:10.191.28.39,PodIP:,StartTime:2019-01-21 21:20:47 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan 21 21:20:49.414: INFO: Pod "nginx-deployment-7f9675fb8b-9phjk" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-9phjk,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-9rknf,SelfLink:/api/v1/namespaces/e2e-tests-deployment-9rknf/pods/nginx-deployment-7f9675fb8b-9phjk,UID:6b50e021-1dc2-11e9-903f-ee5d7ad9296f,ResourceVersion:30565,Generation:0,CreationTimestamp:2019-01-21 21:20:47 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 67944207-1dc2-11e9-903f-ee5d7ad9296f 0xc421dc5817 0xc421dc5818}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-tmfjx {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-tmfjx,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-tmfjx true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.191.28.45,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc421dc5890} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421dc58b0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-21 21:20:47 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-21 21:20:47 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-01-21 21:20:47 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-21 21:20:47 +0000 UTC  }],Message:,Reason:,HostIP:10.191.28.45,PodIP:,StartTime:2019-01-21 21:20:47 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan 21 21:20:49.414: INFO: Pod "nginx-deployment-7f9675fb8b-bqj2g" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-bqj2g,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-9rknf,SelfLink:/api/v1/namespaces/e2e-tests-deployment-9rknf/pods/nginx-deployment-7f9675fb8b-bqj2g,UID:679c46f9-1dc2-11e9-903f-ee5d7ad9296f,ResourceVersion:30236,Generation:0,CreationTimestamp:2019-01-21 21:20:41 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 67944207-1dc2-11e9-903f-ee5d7ad9296f 0xc421dc5967 0xc421dc5968}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-tmfjx {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-tmfjx,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-tmfjx true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.191.28.59,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc421dc59e0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421dc5a00}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-21 21:20:41 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-01-21 21:20:42 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-01-21 21:20:42 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-21 21:20:41 +0000 UTC  }],Message:,Reason:,HostIP:10.191.28.59,PodIP:172.30.156.191,StartTime:2019-01-21 21:20:41 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-01-21 21:20:42 +0000 UTC,} nil} {nil nil nil} true 0 docker.io/library/nginx:1.14-alpine docker.io/library/nginx@sha256:e3f77f7f4a6bb5e7820e013fa60b96602b34f5704e796cfd94b561ae73adcf96 containerd://98411bcac6ab04b906e05bb60bd3e8e2a32a918a568cfd143d5d6d0cc94f5c91}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan 21 21:20:49.415: INFO: Pod "nginx-deployment-7f9675fb8b-fmbjk" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-fmbjk,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-9rknf,SelfLink:/api/v1/namespaces/e2e-tests-deployment-9rknf/pods/nginx-deployment-7f9675fb8b-fmbjk,UID:6b4e32dc-1dc2-11e9-903f-ee5d7ad9296f,ResourceVersion:30464,Generation:0,CreationTimestamp:2019-01-21 21:20:47 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 67944207-1dc2-11e9-903f-ee5d7ad9296f 0xc421dc5ac7 0xc421dc5ac8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-tmfjx {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-tmfjx,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-tmfjx true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.191.28.45,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc421dc5b40} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421dc5b60}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-21 21:20:47 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-21 21:20:47 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-01-21 21:20:47 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-21 21:20:47 +0000 UTC  }],Message:,Reason:,HostIP:10.191.28.45,PodIP:,StartTime:2019-01-21 21:20:47 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan 21 21:20:49.415: INFO: Pod "nginx-deployment-7f9675fb8b-g4f2r" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-g4f2r,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-9rknf,SelfLink:/api/v1/namespaces/e2e-tests-deployment-9rknf/pods/nginx-deployment-7f9675fb8b-g4f2r,UID:679a49aa-1dc2-11e9-903f-ee5d7ad9296f,ResourceVersion:30251,Generation:0,CreationTimestamp:2019-01-21 21:20:41 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 67944207-1dc2-11e9-903f-ee5d7ad9296f 0xc421dc5c17 0xc421dc5c18}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-tmfjx {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-tmfjx,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-tmfjx true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.191.28.39,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc421dc5c90} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421dc5cb0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-21 21:20:41 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-01-21 21:20:42 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-01-21 21:20:42 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-21 21:20:41 +0000 UTC  }],Message:,Reason:,HostIP:10.191.28.39,PodIP:172.30.216.49,StartTime:2019-01-21 21:20:41 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-01-21 21:20:42 +0000 UTC,} nil} {nil nil nil} true 0 docker.io/library/nginx:1.14-alpine docker.io/library/nginx@sha256:e3f77f7f4a6bb5e7820e013fa60b96602b34f5704e796cfd94b561ae73adcf96 containerd://98522139b39eaf5a2e282d2e8ca68f515097edadb97e94aef5fd4d4b8dbbd974}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan 21 21:20:49.415: INFO: Pod "nginx-deployment-7f9675fb8b-hf5gz" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-hf5gz,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-9rknf,SelfLink:/api/v1/namespaces/e2e-tests-deployment-9rknf/pods/nginx-deployment-7f9675fb8b-hf5gz,UID:67988e37-1dc2-11e9-903f-ee5d7ad9296f,ResourceVersion:30244,Generation:0,CreationTimestamp:2019-01-21 21:20:41 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 67944207-1dc2-11e9-903f-ee5d7ad9296f 0xc421dc5d77 0xc421dc5d78}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-tmfjx {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-tmfjx,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-tmfjx true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.191.28.59,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc421dc5df0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421dc5e10}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-21 21:20:41 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-01-21 21:20:42 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-01-21 21:20:42 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-21 21:20:41 +0000 UTC  }],Message:,Reason:,HostIP:10.191.28.59,PodIP:172.30.156.189,StartTime:2019-01-21 21:20:41 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-01-21 21:20:42 +0000 UTC,} nil} {nil nil nil} true 0 docker.io/library/nginx:1.14-alpine docker.io/library/nginx@sha256:e3f77f7f4a6bb5e7820e013fa60b96602b34f5704e796cfd94b561ae73adcf96 containerd://88bf8f9cd53c2a61eac52d660e985cb6d27f8cd9766188768c38d685ea9805ba}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan 21 21:20:49.415: INFO: Pod "nginx-deployment-7f9675fb8b-jcmgn" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-jcmgn,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-9rknf,SelfLink:/api/v1/namespaces/e2e-tests-deployment-9rknf/pods/nginx-deployment-7f9675fb8b-jcmgn,UID:6b50bee6-1dc2-11e9-903f-ee5d7ad9296f,ResourceVersion:30462,Generation:0,CreationTimestamp:2019-01-21 21:20:47 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 67944207-1dc2-11e9-903f-ee5d7ad9296f 0xc421dc5ed7 0xc421dc5ed8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-tmfjx {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-tmfjx,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-tmfjx true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.191.28.59,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc421dc5f50} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421dc5f70}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-21 21:20:47 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-21 21:20:47 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-01-21 21:20:47 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-21 21:20:47 +0000 UTC  }],Message:,Reason:,HostIP:10.191.28.59,PodIP:,StartTime:2019-01-21 21:20:47 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan 21 21:20:49.416: INFO: Pod "nginx-deployment-7f9675fb8b-m6sbw" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-m6sbw,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-9rknf,SelfLink:/api/v1/namespaces/e2e-tests-deployment-9rknf/pods/nginx-deployment-7f9675fb8b-m6sbw,UID:6b50e33e-1dc2-11e9-903f-ee5d7ad9296f,ResourceVersion:30481,Generation:0,CreationTimestamp:2019-01-21 21:20:47 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 67944207-1dc2-11e9-903f-ee5d7ad9296f 0xc4218ca027 0xc4218ca028}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-tmfjx {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-tmfjx,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-tmfjx true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.191.28.59,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc4218ca0a0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc4218ca0c0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-21 21:20:47 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-21 21:20:47 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-01-21 21:20:47 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-21 21:20:47 +0000 UTC  }],Message:,Reason:,HostIP:10.191.28.59,PodIP:,StartTime:2019-01-21 21:20:47 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan 21 21:20:49.416: INFO: Pod "nginx-deployment-7f9675fb8b-mgsvh" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-mgsvh,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-9rknf,SelfLink:/api/v1/namespaces/e2e-tests-deployment-9rknf/pods/nginx-deployment-7f9675fb8b-mgsvh,UID:6b4e1ef8-1dc2-11e9-903f-ee5d7ad9296f,ResourceVersion:30483,Generation:0,CreationTimestamp:2019-01-21 21:20:47 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 67944207-1dc2-11e9-903f-ee5d7ad9296f 0xc4218ca177 0xc4218ca178}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-tmfjx {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-tmfjx,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-tmfjx true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.191.28.45,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc4218ca1f0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc4218ca210}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-21 21:20:47 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-21 21:20:47 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-01-21 21:20:47 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-21 21:20:47 +0000 UTC  }],Message:,Reason:,HostIP:10.191.28.45,PodIP:,StartTime:2019-01-21 21:20:47 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan 21 21:20:49.416: INFO: Pod "nginx-deployment-7f9675fb8b-n42dv" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-n42dv,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-9rknf,SelfLink:/api/v1/namespaces/e2e-tests-deployment-9rknf/pods/nginx-deployment-7f9675fb8b-n42dv,UID:6b4e26b2-1dc2-11e9-903f-ee5d7ad9296f,ResourceVersion:30470,Generation:0,CreationTimestamp:2019-01-21 21:20:47 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 67944207-1dc2-11e9-903f-ee5d7ad9296f 0xc4218ca2c7 0xc4218ca2c8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-tmfjx {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-tmfjx,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-tmfjx true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.191.28.45,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc4218ca340} {node.kubernetes.io/unreachable Exists  NoExecute 0xc4218ca360}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-21 21:20:47 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-21 21:20:47 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-01-21 21:20:47 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-21 21:20:47 +0000 UTC  }],Message:,Reason:,HostIP:10.191.28.45,PodIP:,StartTime:2019-01-21 21:20:47 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan 21 21:20:49.417: INFO: Pod "nginx-deployment-7f9675fb8b-nc744" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-nc744,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-9rknf,SelfLink:/api/v1/namespaces/e2e-tests-deployment-9rknf/pods/nginx-deployment-7f9675fb8b-nc744,UID:6b4bed9e-1dc2-11e9-903f-ee5d7ad9296f,ResourceVersion:30600,Generation:0,CreationTimestamp:2019-01-21 21:20:47 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 67944207-1dc2-11e9-903f-ee5d7ad9296f 0xc4218ca417 0xc4218ca418}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-tmfjx {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-tmfjx,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-tmfjx true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.191.28.39,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc4218ca490} {node.kubernetes.io/unreachable Exists  NoExecute 0xc4218ca4b0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-21 21:20:47 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-01-21 21:20:48 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-01-21 21:20:48 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-21 21:20:47 +0000 UTC  }],Message:,Reason:,HostIP:10.191.28.39,PodIP:172.30.216.11,StartTime:2019-01-21 21:20:47 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-01-21 21:20:48 +0000 UTC,} nil} {nil nil nil} true 0 docker.io/library/nginx:1.14-alpine docker.io/library/nginx@sha256:e3f77f7f4a6bb5e7820e013fa60b96602b34f5704e796cfd94b561ae73adcf96 containerd://9d8888c1c4712a2380ff8a2530b81606dca304e46f74f1d265d974e848ee5c1b}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan 21 21:20:49.417: INFO: Pod "nginx-deployment-7f9675fb8b-nnqrb" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-nnqrb,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-9rknf,SelfLink:/api/v1/namespaces/e2e-tests-deployment-9rknf/pods/nginx-deployment-7f9675fb8b-nnqrb,UID:6b508e5b-1dc2-11e9-903f-ee5d7ad9296f,ResourceVersion:30593,Generation:0,CreationTimestamp:2019-01-21 21:20:47 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 67944207-1dc2-11e9-903f-ee5d7ad9296f 0xc4218ca577 0xc4218ca578}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-tmfjx {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-tmfjx,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-tmfjx true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.191.28.39,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc4218ca5f0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc4218ca610}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-21 21:20:47 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-01-21 21:20:48 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-01-21 21:20:48 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-21 21:20:47 +0000 UTC  }],Message:,Reason:,HostIP:10.191.28.39,PodIP:172.30.216.60,StartTime:2019-01-21 21:20:47 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-01-21 21:20:48 +0000 UTC,} nil} {nil nil nil} true 0 docker.io/library/nginx:1.14-alpine docker.io/library/nginx@sha256:e3f77f7f4a6bb5e7820e013fa60b96602b34f5704e796cfd94b561ae73adcf96 containerd://28cbce2ac388829936f7d8e6e010286a87e28e925b7e3356c9057a50b3e7a7e0}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan 21 21:20:49.418: INFO: Pod "nginx-deployment-7f9675fb8b-q6tng" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-q6tng,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-9rknf,SelfLink:/api/v1/namespaces/e2e-tests-deployment-9rknf/pods/nginx-deployment-7f9675fb8b-q6tng,UID:679c4cf7-1dc2-11e9-903f-ee5d7ad9296f,ResourceVersion:30240,Generation:0,CreationTimestamp:2019-01-21 21:20:41 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 67944207-1dc2-11e9-903f-ee5d7ad9296f 0xc4218ca6d7 0xc4218ca6d8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-tmfjx {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-tmfjx,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-tmfjx true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.191.28.59,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc4218ca750} {node.kubernetes.io/unreachable Exists  NoExecute 0xc4218ca770}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-21 21:20:41 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-01-21 21:20:42 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-01-21 21:20:42 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-21 21:20:41 +0000 UTC  }],Message:,Reason:,HostIP:10.191.28.59,PodIP:172.30.156.133,StartTime:2019-01-21 21:20:41 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-01-21 21:20:42 +0000 UTC,} nil} {nil nil nil} true 0 docker.io/library/nginx:1.14-alpine docker.io/library/nginx@sha256:e3f77f7f4a6bb5e7820e013fa60b96602b34f5704e796cfd94b561ae73adcf96 containerd://744e287a324a2726e74e554336b4b730fbd3c71da9c0e7a7bcf17c28965d5ba2}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan 21 21:20:49.418: INFO: Pod "nginx-deployment-7f9675fb8b-qqv6m" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-qqv6m,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-9rknf,SelfLink:/api/v1/namespaces/e2e-tests-deployment-9rknf/pods/nginx-deployment-7f9675fb8b-qqv6m,UID:679ebc09-1dc2-11e9-903f-ee5d7ad9296f,ResourceVersion:30272,Generation:0,CreationTimestamp:2019-01-21 21:20:41 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 67944207-1dc2-11e9-903f-ee5d7ad9296f 0xc4218ca837 0xc4218ca838}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-tmfjx {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-tmfjx,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-tmfjx true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.191.28.45,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc4218ca8b0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc4218ca8d0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-21 21:20:41 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-01-21 21:20:43 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-01-21 21:20:43 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-21 21:20:41 +0000 UTC  }],Message:,Reason:,HostIP:10.191.28.45,PodIP:172.30.41.6,StartTime:2019-01-21 21:20:41 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-01-21 21:20:43 +0000 UTC,} nil} {nil nil nil} true 0 docker.io/library/nginx:1.14-alpine docker.io/library/nginx@sha256:e3f77f7f4a6bb5e7820e013fa60b96602b34f5704e796cfd94b561ae73adcf96 containerd://5a030f98af7e26f0fc9f43326e618e0c1fed824921db2e6b2f531bf1ab74240b}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan 21 21:20:49.420: INFO: Pod "nginx-deployment-7f9675fb8b-rkp4h" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-rkp4h,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-9rknf,SelfLink:/api/v1/namespaces/e2e-tests-deployment-9rknf/pods/nginx-deployment-7f9675fb8b-rkp4h,UID:679c64f4-1dc2-11e9-903f-ee5d7ad9296f,ResourceVersion:30254,Generation:0,CreationTimestamp:2019-01-21 21:20:41 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 67944207-1dc2-11e9-903f-ee5d7ad9296f 0xc4218ca990 0xc4218ca991}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-tmfjx {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-tmfjx,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-tmfjx true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.191.28.39,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc4218caa00} {node.kubernetes.io/unreachable Exists  NoExecute 0xc4218caa20}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-21 21:20:41 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-01-21 21:20:42 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-01-21 21:20:42 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-21 21:20:41 +0000 UTC  }],Message:,Reason:,HostIP:10.191.28.39,PodIP:172.30.216.51,StartTime:2019-01-21 21:20:41 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-01-21 21:20:42 +0000 UTC,} nil} {nil nil nil} true 0 docker.io/library/nginx:1.14-alpine docker.io/library/nginx@sha256:e3f77f7f4a6bb5e7820e013fa60b96602b34f5704e796cfd94b561ae73adcf96 containerd://2f1117f3ccecef746ac46e84ad49c0264a0a0e4bc152ab75a1b1fbcc4e829ff7}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan 21 21:20:49.420: INFO: Pod "nginx-deployment-7f9675fb8b-tjp6z" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-tjp6z,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-9rknf,SelfLink:/api/v1/namespaces/e2e-tests-deployment-9rknf/pods/nginx-deployment-7f9675fb8b-tjp6z,UID:6b4e20e1-1dc2-11e9-903f-ee5d7ad9296f,ResourceVersion:30460,Generation:0,CreationTimestamp:2019-01-21 21:20:47 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 67944207-1dc2-11e9-903f-ee5d7ad9296f 0xc4218caae7 0xc4218caae8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-tmfjx {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-tmfjx,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-tmfjx true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.191.28.39,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc4218cab60} {node.kubernetes.io/unreachable Exists  NoExecute 0xc4218cab80}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-21 21:20:47 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-21 21:20:47 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-01-21 21:20:47 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-21 21:20:47 +0000 UTC  }],Message:,Reason:,HostIP:10.191.28.39,PodIP:,StartTime:2019-01-21 21:20:47 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan 21 21:20:49.421: INFO: Pod "nginx-deployment-7f9675fb8b-wrd58" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-wrd58,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-9rknf,SelfLink:/api/v1/namespaces/e2e-tests-deployment-9rknf/pods/nginx-deployment-7f9675fb8b-wrd58,UID:6b4a353d-1dc2-11e9-903f-ee5d7ad9296f,ResourceVersion:30427,Generation:0,CreationTimestamp:2019-01-21 21:20:47 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 67944207-1dc2-11e9-903f-ee5d7ad9296f 0xc4218cac37 0xc4218cac38}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-tmfjx {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-tmfjx,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-tmfjx true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.191.28.45,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc4218cacb0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc4218cacd0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-21 21:20:47 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-21 21:20:47 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-01-21 21:20:47 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-21 21:20:47 +0000 UTC  }],Message:,Reason:,HostIP:10.191.28.45,PodIP:,StartTime:2019-01-21 21:20:47 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Jan 21 21:20:49.425: INFO: Pod "nginx-deployment-7f9675fb8b-zzjvz" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-zzjvz,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-9rknf,SelfLink:/api/v1/namespaces/e2e-tests-deployment-9rknf/pods/nginx-deployment-7f9675fb8b-zzjvz,UID:679edbbb-1dc2-11e9-903f-ee5d7ad9296f,ResourceVersion:30262,Generation:0,CreationTimestamp:2019-01-21 21:20:41 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b 67944207-1dc2-11e9-903f-ee5d7ad9296f 0xc4218cad87 0xc4218cad88}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-tmfjx {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-tmfjx,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-tmfjx true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.191.28.59,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc4218cae00} {node.kubernetes.io/unreachable Exists  NoExecute 0xc4218cae20}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-21 21:20:41 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-01-21 21:20:43 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-01-21 21:20:43 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-21 21:20:41 +0000 UTC  }],Message:,Reason:,HostIP:10.191.28.59,PodIP:172.30.156.190,StartTime:2019-01-21 21:20:41 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-01-21 21:20:42 +0000 UTC,} nil} {nil nil nil} true 0 docker.io/library/nginx:1.14-alpine docker.io/library/nginx@sha256:e3f77f7f4a6bb5e7820e013fa60b96602b34f5704e796cfd94b561ae73adcf96 containerd://fb57d5593fdb61ec8d99da78c238c957cca3cd5c6959112a5a4bf7ac998a1cbf}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 21:20:49.425: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-9rknf" for this suite.
Jan 21 21:20:59.503: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 21:20:59.832: INFO: namespace: e2e-tests-deployment-9rknf, resource: bindings, ignored listing per whitelist
Jan 21 21:20:59.958: INFO: namespace e2e-tests-deployment-9rknf deletion completed in 10.519267053s

• [SLOW TEST:19.269 seconds]
[sig-apps] Deployment
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-apps] Deployment 
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 21:20:59.960: INFO: >>> kubeConfig: /tmp/kubeconfig-933165938
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-deployment-k72pl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Jan 21 21:21:00.365: INFO: Creating replica set "test-rolling-update-controller" (going to be adopted)
Jan 21 21:21:00.390: INFO: Pod name sample-pod: Found 0 pods out of 1
Jan 21 21:21:05.401: INFO: Pod name sample-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Jan 21 21:21:05.401: INFO: Creating deployment "test-rolling-update-deployment"
Jan 21 21:21:05.412: INFO: Ensuring deployment "test-rolling-update-deployment" gets the next revision from the one the adopted replica set "test-rolling-update-controller" has
Jan 21 21:21:05.437: INFO: new replicaset for deployment "test-rolling-update-deployment" is yet to be created
Jan 21 21:21:07.488: INFO: Ensuring status for deployment "test-rolling-update-deployment" is the expected
Jan 21 21:21:07.495: INFO: Ensuring deployment "test-rolling-update-deployment" has one old replica set (the one it adopted)
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Jan 21 21:21:07.521: INFO: Deployment "test-rolling-update-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment,GenerateName:,Namespace:e2e-tests-deployment-k72pl,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-k72pl/deployments/test-rolling-update-deployment,UID:761d73fe-1dc2-11e9-903f-ee5d7ad9296f,ResourceVersion:31074,Generation:1,CreationTimestamp:2019-01-21 21:21:05 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,},Annotations:map[string]string{deployment.kubernetes.io/revision: 3546343826724305833,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[{Available True 2019-01-21 21:21:05 +0000 UTC 2019-01-21 21:21:05 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2019-01-21 21:21:07 +0000 UTC 2019-01-21 21:21:05 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-rolling-update-deployment-65b7695dcf" has successfully progressed.}],ReadyReplicas:1,CollisionCount:nil,},}

Jan 21 21:21:07.533: INFO: New ReplicaSet "test-rolling-update-deployment-65b7695dcf" of Deployment "test-rolling-update-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment-65b7695dcf,GenerateName:,Namespace:e2e-tests-deployment-k72pl,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-k72pl/replicasets/test-rolling-update-deployment-65b7695dcf,UID:7623cb3b-1dc2-11e9-903f-ee5d7ad9296f,ResourceVersion:31065,Generation:1,CreationTimestamp:2019-01-21 21:21:05 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 65b7695dcf,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 3546343826724305833,},OwnerReferences:[{apps/v1 Deployment test-rolling-update-deployment 761d73fe-1dc2-11e9-903f-ee5d7ad9296f 0xc420b782e7 0xc420b782e8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod-template-hash: 65b7695dcf,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 65b7695dcf,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Jan 21 21:21:07.534: INFO: All old ReplicaSets of Deployment "test-rolling-update-deployment":
Jan 21 21:21:07.534: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-controller,GenerateName:,Namespace:e2e-tests-deployment-k72pl,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-k72pl/replicasets/test-rolling-update-controller,UID:731d03c6-1dc2-11e9-903f-ee5d7ad9296f,ResourceVersion:31073,Generation:2,CreationTimestamp:2019-01-21 21:21:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod: nginx,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 3546343826724305832,},OwnerReferences:[{apps/v1 Deployment test-rolling-update-deployment 761d73fe-1dc2-11e9-903f-ee5d7ad9296f 0xc420b7821e 0xc420b7821f}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Jan 21 21:21:07.574: INFO: Pod "test-rolling-update-deployment-65b7695dcf-7spql" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment-65b7695dcf-7spql,GenerateName:test-rolling-update-deployment-65b7695dcf-,Namespace:e2e-tests-deployment-k72pl,SelfLink:/api/v1/namespaces/e2e-tests-deployment-k72pl/pods/test-rolling-update-deployment-65b7695dcf-7spql,UID:7627d287-1dc2-11e9-903f-ee5d7ad9296f,ResourceVersion:31064,Generation:0,CreationTimestamp:2019-01-21 21:21:05 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 65b7695dcf,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet test-rolling-update-deployment-65b7695dcf 7623cb3b-1dc2-11e9-903f-ee5d7ad9296f 0xc420b78b47 0xc420b78b48}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-lcs2z {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-lcs2z,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-lcs2z true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.191.28.39,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc420b78bc0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc420b78be0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-21 21:21:05 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-01-21 21:21:06 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-01-21 21:21:06 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-21 21:21:05 +0000 UTC  }],Message:,Reason:,HostIP:10.191.28.39,PodIP:172.30.216.61,StartTime:2019-01-21 21:21:05 +0000 UTC,ContainerStatuses:[{redis {nil ContainerStateRunning{StartedAt:2019-01-21 21:21:06 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/redis:1.0 gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830 containerd://03769085c7419440b7b8e591e01e1a007db33413ef3efb34f2fc1fc36c20d90d}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 21:21:07.574: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-k72pl" for this suite.
Jan 21 21:21:13.621: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 21:21:13.671: INFO: namespace: e2e-tests-deployment-k72pl, resource: bindings, ignored listing per whitelist
Jan 21 21:21:13.961: INFO: namespace e2e-tests-deployment-k72pl deletion completed in 6.374143987s

• [SLOW TEST:14.002 seconds]
[sig-apps] Deployment
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 21:21:13.963: INFO: >>> kubeConfig: /tmp/kubeconfig-933165938
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-container-probe-cpnmn
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-exec in namespace e2e-tests-container-probe-cpnmn
Jan 21 21:21:16.375: INFO: Started pod liveness-exec in namespace e2e-tests-container-probe-cpnmn
STEP: checking the pod's current state and verifying that restartCount is present
Jan 21 21:21:16.384: INFO: Initial restart count of pod liveness-exec is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 21:25:18.072: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-cpnmn" for this suite.
Jan 21 21:25:24.120: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 21:25:24.434: INFO: namespace: e2e-tests-container-probe-cpnmn, resource: bindings, ignored listing per whitelist
Jan 21 21:25:24.478: INFO: namespace e2e-tests-container-probe-cpnmn deletion completed in 6.391478156s

• [SLOW TEST:250.515 seconds]
[k8s.io] Probing container
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl api-versions 
  should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 21:25:24.480: INFO: >>> kubeConfig: /tmp/kubeconfig-933165938
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-2dwd8
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: validating api versions
Jan 21 21:25:24.801: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-933165938 api-versions'
Jan 21 21:25:24.994: INFO: stderr: ""
Jan 21 21:25:24.994: INFO: stdout: "admissionregistration.k8s.io/v1alpha1\nadmissionregistration.k8s.io/v1beta1\napiextensions.k8s.io/v1beta1\napiregistration.k8s.io/v1\napiregistration.k8s.io/v1beta1\napps/v1\napps/v1beta1\napps/v1beta2\nauthentication.k8s.io/v1\nauthentication.k8s.io/v1beta1\nauthorization.k8s.io/v1\nauthorization.k8s.io/v1beta1\nautoscaling/v1\nautoscaling/v2beta1\nautoscaling/v2beta2\nbatch/v1\nbatch/v1beta1\nbatch/v2alpha1\ncertificates.k8s.io/v1beta1\ncoordination.k8s.io/v1beta1\nevents.k8s.io/v1beta1\nextensions/v1beta1\nmetrics.k8s.io/v1beta1\nnetworking.k8s.io/v1\npolicy/v1beta1\nrbac.authorization.k8s.io/v1\nrbac.authorization.k8s.io/v1beta1\nscheduling.k8s.io/v1beta1\nstorage.k8s.io/v1\nstorage.k8s.io/v1beta1\nv1\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 21:25:24.994: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-2dwd8" for this suite.
Jan 21 21:25:31.045: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 21:25:31.199: INFO: namespace: e2e-tests-kubectl-2dwd8, resource: bindings, ignored listing per whitelist
Jan 21 21:25:31.453: INFO: namespace e2e-tests-kubectl-2dwd8 deletion completed in 6.445570893s

• [SLOW TEST:6.974 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl api-versions
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should check if v1 is in available api versions  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 21:25:31.454: INFO: >>> kubeConfig: /tmp/kubeconfig-933165938
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-n8mvt
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-map-14e2fd7d-1dc3-11e9-8130-be6597f3ae53
STEP: Creating a pod to test consume configMaps
Jan 21 21:25:31.864: INFO: Waiting up to 5m0s for pod "pod-configmaps-14e469ac-1dc3-11e9-8130-be6597f3ae53" in namespace "e2e-tests-configmap-n8mvt" to be "success or failure"
Jan 21 21:25:31.874: INFO: Pod "pod-configmaps-14e469ac-1dc3-11e9-8130-be6597f3ae53": Phase="Pending", Reason="", readiness=false. Elapsed: 10.123576ms
Jan 21 21:25:33.886: INFO: Pod "pod-configmaps-14e469ac-1dc3-11e9-8130-be6597f3ae53": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.022194714s
STEP: Saw pod success
Jan 21 21:25:33.886: INFO: Pod "pod-configmaps-14e469ac-1dc3-11e9-8130-be6597f3ae53" satisfied condition "success or failure"
Jan 21 21:25:33.896: INFO: Trying to get logs from node 10.191.28.39 pod pod-configmaps-14e469ac-1dc3-11e9-8130-be6597f3ae53 container configmap-volume-test: <nil>
STEP: delete the pod
Jan 21 21:25:33.999: INFO: Waiting for pod pod-configmaps-14e469ac-1dc3-11e9-8130-be6597f3ae53 to disappear
Jan 21 21:25:34.010: INFO: Pod pod-configmaps-14e469ac-1dc3-11e9-8130-be6597f3ae53 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 21:25:34.011: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-n8mvt" for this suite.
Jan 21 21:25:40.061: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 21:25:40.270: INFO: namespace: e2e-tests-configmap-n8mvt, resource: bindings, ignored listing per whitelist
Jan 21 21:25:40.466: INFO: namespace e2e-tests-configmap-n8mvt deletion completed in 6.441327735s

• [SLOW TEST:9.013 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 21:25:40.469: INFO: >>> kubeConfig: /tmp/kubeconfig-933165938
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-kncsx
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-map-1a4bf300-1dc3-11e9-8130-be6597f3ae53
STEP: Creating a pod to test consume configMaps
Jan 21 21:25:40.881: INFO: Waiting up to 5m0s for pod "pod-configmaps-1a4d4d9a-1dc3-11e9-8130-be6597f3ae53" in namespace "e2e-tests-configmap-kncsx" to be "success or failure"
Jan 21 21:25:40.891: INFO: Pod "pod-configmaps-1a4d4d9a-1dc3-11e9-8130-be6597f3ae53": Phase="Pending", Reason="", readiness=false. Elapsed: 9.560197ms
Jan 21 21:25:43.290: INFO: Pod "pod-configmaps-1a4d4d9a-1dc3-11e9-8130-be6597f3ae53": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.4087662s
STEP: Saw pod success
Jan 21 21:25:43.290: INFO: Pod "pod-configmaps-1a4d4d9a-1dc3-11e9-8130-be6597f3ae53" satisfied condition "success or failure"
Jan 21 21:25:43.308: INFO: Trying to get logs from node 10.191.28.59 pod pod-configmaps-1a4d4d9a-1dc3-11e9-8130-be6597f3ae53 container configmap-volume-test: <nil>
STEP: delete the pod
Jan 21 21:25:43.381: INFO: Waiting for pod pod-configmaps-1a4d4d9a-1dc3-11e9-8130-be6597f3ae53 to disappear
Jan 21 21:25:43.398: INFO: Pod pod-configmaps-1a4d4d9a-1dc3-11e9-8130-be6597f3ae53 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 21:25:43.399: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-kncsx" for this suite.
Jan 21 21:25:49.444: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 21:25:49.612: INFO: namespace: e2e-tests-configmap-kncsx, resource: bindings, ignored listing per whitelist
Jan 21 21:25:49.869: INFO: namespace e2e-tests-configmap-kncsx deletion completed in 6.457299278s

• [SLOW TEST:9.401 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 21:25:49.871: INFO: >>> kubeConfig: /tmp/kubeconfig-933165938
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-container-probe-887pd
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-exec in namespace e2e-tests-container-probe-887pd
Jan 21 21:25:52.284: INFO: Started pod liveness-exec in namespace e2e-tests-container-probe-887pd
STEP: checking the pod's current state and verifying that restartCount is present
Jan 21 21:25:52.294: INFO: Initial restart count of pod liveness-exec is 0
Jan 21 21:26:44.599: INFO: Restart count of pod e2e-tests-container-probe-887pd/liveness-exec is now 1 (52.30483244s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 21:26:44.646: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-887pd" for this suite.
Jan 21 21:26:50.715: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 21:26:51.148: INFO: namespace: e2e-tests-container-probe-887pd, resource: bindings, ignored listing per whitelist
Jan 21 21:26:51.317: INFO: namespace e2e-tests-container-probe-887pd deletion completed in 6.639267118s

• [SLOW TEST:61.445 seconds]
[k8s.io] Probing container
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 21:26:51.318: INFO: >>> kubeConfig: /tmp/kubeconfig-933165938
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-daemonsets-8skz4
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:98
[It] should run and stop complex daemon [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Jan 21 21:26:51.692: INFO: Creating daemon "daemon-set" with a node selector
STEP: Initially, daemon pods should not be running on any nodes.
Jan 21 21:26:51.711: INFO: Number of nodes with available pods: 0
Jan 21 21:26:51.711: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Change node label to blue, check that daemon pod is launched.
Jan 21 21:26:51.756: INFO: Number of nodes with available pods: 0
Jan 21 21:26:51.756: INFO: Node 10.191.28.39 is running more than one daemon pod
Jan 21 21:26:52.770: INFO: Number of nodes with available pods: 0
Jan 21 21:26:52.770: INFO: Node 10.191.28.39 is running more than one daemon pod
Jan 21 21:26:53.767: INFO: Number of nodes with available pods: 1
Jan 21 21:26:53.767: INFO: Number of running nodes: 1, number of available pods: 1
STEP: Update the node label to green, and wait for daemons to be unscheduled
Jan 21 21:26:53.888: INFO: Number of nodes with available pods: 1
Jan 21 21:26:53.888: INFO: Number of running nodes: 0, number of available pods: 1
Jan 21 21:26:54.898: INFO: Number of nodes with available pods: 0
Jan 21 21:26:54.899: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Update DaemonSet node selector to green, and change its update strategy to RollingUpdate
Jan 21 21:26:54.918: INFO: Number of nodes with available pods: 0
Jan 21 21:26:54.918: INFO: Node 10.191.28.39 is running more than one daemon pod
Jan 21 21:26:55.929: INFO: Number of nodes with available pods: 0
Jan 21 21:26:55.929: INFO: Node 10.191.28.39 is running more than one daemon pod
Jan 21 21:26:56.929: INFO: Number of nodes with available pods: 0
Jan 21 21:26:56.929: INFO: Node 10.191.28.39 is running more than one daemon pod
Jan 21 21:26:58.219: INFO: Number of nodes with available pods: 0
Jan 21 21:26:58.219: INFO: Node 10.191.28.39 is running more than one daemon pod
Jan 21 21:26:58.929: INFO: Number of nodes with available pods: 0
Jan 21 21:26:58.929: INFO: Node 10.191.28.39 is running more than one daemon pod
Jan 21 21:26:59.929: INFO: Number of nodes with available pods: 0
Jan 21 21:26:59.929: INFO: Node 10.191.28.39 is running more than one daemon pod
Jan 21 21:27:00.930: INFO: Number of nodes with available pods: 0
Jan 21 21:27:00.930: INFO: Node 10.191.28.39 is running more than one daemon pod
Jan 21 21:27:01.929: INFO: Number of nodes with available pods: 0
Jan 21 21:27:01.929: INFO: Node 10.191.28.39 is running more than one daemon pod
Jan 21 21:27:02.929: INFO: Number of nodes with available pods: 0
Jan 21 21:27:02.929: INFO: Node 10.191.28.39 is running more than one daemon pod
Jan 21 21:27:03.935: INFO: Number of nodes with available pods: 0
Jan 21 21:27:03.935: INFO: Node 10.191.28.39 is running more than one daemon pod
Jan 21 21:27:04.932: INFO: Number of nodes with available pods: 0
Jan 21 21:27:04.932: INFO: Node 10.191.28.39 is running more than one daemon pod
Jan 21 21:27:05.929: INFO: Number of nodes with available pods: 0
Jan 21 21:27:05.929: INFO: Node 10.191.28.39 is running more than one daemon pod
Jan 21 21:27:06.929: INFO: Number of nodes with available pods: 0
Jan 21 21:27:06.929: INFO: Node 10.191.28.39 is running more than one daemon pod
Jan 21 21:27:07.929: INFO: Number of nodes with available pods: 0
Jan 21 21:27:07.929: INFO: Node 10.191.28.39 is running more than one daemon pod
Jan 21 21:27:08.929: INFO: Number of nodes with available pods: 0
Jan 21 21:27:08.929: INFO: Node 10.191.28.39 is running more than one daemon pod
Jan 21 21:27:09.929: INFO: Number of nodes with available pods: 0
Jan 21 21:27:09.929: INFO: Node 10.191.28.39 is running more than one daemon pod
Jan 21 21:27:10.930: INFO: Number of nodes with available pods: 0
Jan 21 21:27:10.930: INFO: Node 10.191.28.39 is running more than one daemon pod
Jan 21 21:27:11.931: INFO: Number of nodes with available pods: 0
Jan 21 21:27:11.931: INFO: Node 10.191.28.39 is running more than one daemon pod
Jan 21 21:27:12.928: INFO: Number of nodes with available pods: 0
Jan 21 21:27:12.928: INFO: Node 10.191.28.39 is running more than one daemon pod
Jan 21 21:27:13.928: INFO: Number of nodes with available pods: 0
Jan 21 21:27:13.928: INFO: Node 10.191.28.39 is running more than one daemon pod
Jan 21 21:27:14.928: INFO: Number of nodes with available pods: 0
Jan 21 21:27:14.928: INFO: Node 10.191.28.39 is running more than one daemon pod
Jan 21 21:27:15.929: INFO: Number of nodes with available pods: 0
Jan 21 21:27:15.929: INFO: Node 10.191.28.39 is running more than one daemon pod
Jan 21 21:27:16.929: INFO: Number of nodes with available pods: 0
Jan 21 21:27:16.929: INFO: Node 10.191.28.39 is running more than one daemon pod
Jan 21 21:27:18.354: INFO: Number of nodes with available pods: 0
Jan 21 21:27:18.355: INFO: Node 10.191.28.39 is running more than one daemon pod
Jan 21 21:27:18.930: INFO: Number of nodes with available pods: 0
Jan 21 21:27:18.930: INFO: Node 10.191.28.39 is running more than one daemon pod
Jan 21 21:27:19.928: INFO: Number of nodes with available pods: 0
Jan 21 21:27:19.928: INFO: Node 10.191.28.39 is running more than one daemon pod
Jan 21 21:27:20.929: INFO: Number of nodes with available pods: 0
Jan 21 21:27:20.929: INFO: Node 10.191.28.39 is running more than one daemon pod
Jan 21 21:27:21.929: INFO: Number of nodes with available pods: 0
Jan 21 21:27:21.929: INFO: Node 10.191.28.39 is running more than one daemon pod
Jan 21 21:27:22.929: INFO: Number of nodes with available pods: 0
Jan 21 21:27:22.929: INFO: Node 10.191.28.39 is running more than one daemon pod
Jan 21 21:27:23.929: INFO: Number of nodes with available pods: 0
Jan 21 21:27:23.929: INFO: Node 10.191.28.39 is running more than one daemon pod
Jan 21 21:27:24.928: INFO: Number of nodes with available pods: 0
Jan 21 21:27:24.928: INFO: Node 10.191.28.39 is running more than one daemon pod
Jan 21 21:27:25.929: INFO: Number of nodes with available pods: 0
Jan 21 21:27:25.929: INFO: Node 10.191.28.39 is running more than one daemon pod
Jan 21 21:27:26.931: INFO: Number of nodes with available pods: 0
Jan 21 21:27:26.931: INFO: Node 10.191.28.39 is running more than one daemon pod
Jan 21 21:27:27.935: INFO: Number of nodes with available pods: 0
Jan 21 21:27:27.936: INFO: Node 10.191.28.39 is running more than one daemon pod
Jan 21 21:27:28.928: INFO: Number of nodes with available pods: 0
Jan 21 21:27:28.928: INFO: Node 10.191.28.39 is running more than one daemon pod
Jan 21 21:27:29.929: INFO: Number of nodes with available pods: 0
Jan 21 21:27:29.929: INFO: Node 10.191.28.39 is running more than one daemon pod
Jan 21 21:27:30.928: INFO: Number of nodes with available pods: 0
Jan 21 21:27:30.929: INFO: Node 10.191.28.39 is running more than one daemon pod
Jan 21 21:27:31.929: INFO: Number of nodes with available pods: 0
Jan 21 21:27:31.929: INFO: Node 10.191.28.39 is running more than one daemon pod
Jan 21 21:27:32.930: INFO: Number of nodes with available pods: 0
Jan 21 21:27:32.930: INFO: Node 10.191.28.39 is running more than one daemon pod
Jan 21 21:27:33.930: INFO: Number of nodes with available pods: 0
Jan 21 21:27:33.930: INFO: Node 10.191.28.39 is running more than one daemon pod
Jan 21 21:27:34.929: INFO: Number of nodes with available pods: 0
Jan 21 21:27:34.929: INFO: Node 10.191.28.39 is running more than one daemon pod
Jan 21 21:27:35.929: INFO: Number of nodes with available pods: 0
Jan 21 21:27:35.929: INFO: Node 10.191.28.39 is running more than one daemon pod
Jan 21 21:27:36.932: INFO: Number of nodes with available pods: 1
Jan 21 21:27:36.932: INFO: Number of running nodes: 1, number of available pods: 1
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:64
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting {extensions DaemonSet} daemon-set in namespace e2e-tests-daemonsets-8skz4, will wait for the garbage collector to delete the pods
Jan 21 21:27:37.037: INFO: Deleting {extensions DaemonSet} daemon-set took: 25.127033ms
Jan 21 21:27:37.137: INFO: Terminating {extensions DaemonSet} daemon-set pods took: 100.286259ms
Jan 21 21:28:15.772: INFO: Number of nodes with available pods: 0
Jan 21 21:28:15.772: INFO: Number of running nodes: 0, number of available pods: 0
Jan 21 21:28:15.785: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-8skz4/daemonsets","resourceVersion":"32062"},"items":null}

Jan 21 21:28:15.795: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-8skz4/pods","resourceVersion":"32062"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 21:28:15.867: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-8skz4" for this suite.
Jan 21 21:28:21.922: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 21:28:22.329: INFO: namespace: e2e-tests-daemonsets-8skz4, resource: bindings, ignored listing per whitelist
Jan 21 21:28:22.349: INFO: namespace e2e-tests-daemonsets-8skz4 deletion completed in 6.460747626s

• [SLOW TEST:91.032 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[k8s.io] Pods 
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 21:28:22.352: INFO: >>> kubeConfig: /tmp/kubeconfig-933165938
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-pods-fv4tj
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating pod
Jan 21 21:28:24.760: INFO: Pod pod-hostip-7ac32fba-1dc3-11e9-8130-be6597f3ae53 has hostIP: 10.191.28.59
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 21:28:24.760: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-fv4tj" for this suite.
Jan 21 21:28:48.817: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 21:28:48.878: INFO: namespace: e2e-tests-pods-fv4tj, resource: bindings, ignored listing per whitelist
Jan 21 21:28:49.209: INFO: namespace e2e-tests-pods-fv4tj deletion completed in 24.433456627s

• [SLOW TEST:26.858 seconds]
[k8s.io] Pods
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-api-machinery] CustomResourceDefinition resources Simple CustomResourceDefinition 
  creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 21:28:49.210: INFO: >>> kubeConfig: /tmp/kubeconfig-933165938
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-custom-resource-definition-44r8x
STEP: Waiting for a default service account to be provisioned in namespace
[It] creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Jan 21 21:28:49.544: INFO: >>> kubeConfig: /tmp/kubeconfig-933165938
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 21:28:50.719: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-custom-resource-definition-44r8x" for this suite.
Jan 21 21:28:56.765: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 21:28:57.031: INFO: namespace: e2e-tests-custom-resource-definition-44r8x, resource: bindings, ignored listing per whitelist
Jan 21 21:28:57.197: INFO: namespace e2e-tests-custom-resource-definition-44r8x deletion completed in 6.465235746s

• [SLOW TEST:7.988 seconds]
[sig-api-machinery] CustomResourceDefinition resources
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  Simple CustomResourceDefinition
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/custom_resource_definition.go:35
    creating/deleting custom resource definition objects works  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 21:28:57.199: INFO: >>> kubeConfig: /tmp/kubeconfig-933165938
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-bx9l2
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:293
[It] should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a replication controller
Jan 21 21:28:57.527: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-933165938 create -f - --namespace=e2e-tests-kubectl-bx9l2'
Jan 21 21:28:58.273: INFO: stderr: ""
Jan 21 21:28:58.273: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Jan 21 21:28:58.273: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-933165938 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-bx9l2'
Jan 21 21:28:58.495: INFO: stderr: ""
Jan 21 21:28:58.495: INFO: stdout: "update-demo-nautilus-2kkq5 update-demo-nautilus-js48h "
Jan 21 21:28:58.495: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-933165938 get pods update-demo-nautilus-2kkq5 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-bx9l2'
Jan 21 21:28:58.692: INFO: stderr: ""
Jan 21 21:28:58.693: INFO: stdout: ""
Jan 21 21:28:58.693: INFO: update-demo-nautilus-2kkq5 is created but not running
Jan 21 21:29:03.693: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-933165938 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-bx9l2'
Jan 21 21:29:03.883: INFO: stderr: ""
Jan 21 21:29:03.884: INFO: stdout: "update-demo-nautilus-2kkq5 update-demo-nautilus-js48h "
Jan 21 21:29:03.884: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-933165938 get pods update-demo-nautilus-2kkq5 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-bx9l2'
Jan 21 21:29:04.054: INFO: stderr: ""
Jan 21 21:29:04.054: INFO: stdout: "true"
Jan 21 21:29:04.055: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-933165938 get pods update-demo-nautilus-2kkq5 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-bx9l2'
Jan 21 21:29:04.278: INFO: stderr: ""
Jan 21 21:29:04.278: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Jan 21 21:29:04.278: INFO: validating pod update-demo-nautilus-2kkq5
Jan 21 21:29:04.302: INFO: got data: {
  "image": "nautilus.jpg"
}

Jan 21 21:29:04.302: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Jan 21 21:29:04.302: INFO: update-demo-nautilus-2kkq5 is verified up and running
Jan 21 21:29:04.302: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-933165938 get pods update-demo-nautilus-js48h -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-bx9l2'
Jan 21 21:29:04.496: INFO: stderr: ""
Jan 21 21:29:04.496: INFO: stdout: "true"
Jan 21 21:29:04.496: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-933165938 get pods update-demo-nautilus-js48h -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-bx9l2'
Jan 21 21:29:04.669: INFO: stderr: ""
Jan 21 21:29:04.669: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Jan 21 21:29:04.669: INFO: validating pod update-demo-nautilus-js48h
Jan 21 21:29:04.693: INFO: got data: {
  "image": "nautilus.jpg"
}

Jan 21 21:29:04.693: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Jan 21 21:29:04.693: INFO: update-demo-nautilus-js48h is verified up and running
STEP: using delete to clean up resources
Jan 21 21:29:04.693: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-933165938 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-bx9l2'
Jan 21 21:29:04.894: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Jan 21 21:29:04.894: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Jan 21 21:29:04.894: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-933165938 get rc,svc -l name=update-demo --no-headers --namespace=e2e-tests-kubectl-bx9l2'
Jan 21 21:29:05.128: INFO: stderr: "No resources found.\n"
Jan 21 21:29:05.128: INFO: stdout: ""
Jan 21 21:29:05.128: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-933165938 get pods -l name=update-demo --namespace=e2e-tests-kubectl-bx9l2 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Jan 21 21:29:05.336: INFO: stderr: ""
Jan 21 21:29:05.336: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 21:29:05.336: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-bx9l2" for this suite.
Jan 21 21:29:21.389: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 21:29:21.709: INFO: namespace: e2e-tests-kubectl-bx9l2, resource: bindings, ignored listing per whitelist
Jan 21 21:29:21.783: INFO: namespace e2e-tests-kubectl-bx9l2 deletion completed in 16.430242172s

• [SLOW TEST:24.584 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Update Demo
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create and stop a replication controller  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] Projected 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 21:29:21.785: INFO: >>> kubeConfig: /tmp/kubeconfig-933165938
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-fvflt
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Jan 21 21:29:22.183: INFO: Waiting up to 5m0s for pod "downwardapi-volume-9e35afa7-1dc3-11e9-8130-be6597f3ae53" in namespace "e2e-tests-projected-fvflt" to be "success or failure"
Jan 21 21:29:22.196: INFO: Pod "downwardapi-volume-9e35afa7-1dc3-11e9-8130-be6597f3ae53": Phase="Pending", Reason="", readiness=false. Elapsed: 12.172533ms
Jan 21 21:29:24.206: INFO: Pod "downwardapi-volume-9e35afa7-1dc3-11e9-8130-be6597f3ae53": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.022380281s
STEP: Saw pod success
Jan 21 21:29:24.206: INFO: Pod "downwardapi-volume-9e35afa7-1dc3-11e9-8130-be6597f3ae53" satisfied condition "success or failure"
Jan 21 21:29:24.217: INFO: Trying to get logs from node 10.191.28.59 pod downwardapi-volume-9e35afa7-1dc3-11e9-8130-be6597f3ae53 container client-container: <nil>
STEP: delete the pod
Jan 21 21:29:24.293: INFO: Waiting for pod downwardapi-volume-9e35afa7-1dc3-11e9-8130-be6597f3ae53 to disappear
Jan 21 21:29:24.304: INFO: Pod downwardapi-volume-9e35afa7-1dc3-11e9-8130-be6597f3ae53 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 21:29:24.304: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-fvflt" for this suite.
Jan 21 21:29:30.350: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 21:29:30.436: INFO: namespace: e2e-tests-projected-fvflt, resource: bindings, ignored listing per whitelist
Jan 21 21:29:30.766: INFO: namespace e2e-tests-projected-fvflt deletion completed in 6.447941588s

• [SLOW TEST:8.980 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with secret pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 21:29:30.766: INFO: >>> kubeConfig: /tmp/kubeconfig-933165938
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-subpath-r52ft
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with secret pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-secret-rqhb
STEP: Creating a pod to test atomic-volume-subpath
Jan 21 21:29:31.208: INFO: Waiting up to 5m0s for pod "pod-subpath-test-secret-rqhb" in namespace "e2e-tests-subpath-r52ft" to be "success or failure"
Jan 21 21:29:31.230: INFO: Pod "pod-subpath-test-secret-rqhb": Phase="Pending", Reason="", readiness=false. Elapsed: 21.818307ms
Jan 21 21:29:33.242: INFO: Pod "pod-subpath-test-secret-rqhb": Phase="Pending", Reason="", readiness=false. Elapsed: 2.034241588s
Jan 21 21:29:35.254: INFO: Pod "pod-subpath-test-secret-rqhb": Phase="Running", Reason="", readiness=false. Elapsed: 4.045912526s
Jan 21 21:29:37.264: INFO: Pod "pod-subpath-test-secret-rqhb": Phase="Running", Reason="", readiness=false. Elapsed: 6.056465728s
Jan 21 21:29:39.275: INFO: Pod "pod-subpath-test-secret-rqhb": Phase="Running", Reason="", readiness=false. Elapsed: 8.066829988s
Jan 21 21:29:41.286: INFO: Pod "pod-subpath-test-secret-rqhb": Phase="Running", Reason="", readiness=false. Elapsed: 10.078049323s
Jan 21 21:29:43.296: INFO: Pod "pod-subpath-test-secret-rqhb": Phase="Running", Reason="", readiness=false. Elapsed: 12.088238776s
Jan 21 21:29:45.307: INFO: Pod "pod-subpath-test-secret-rqhb": Phase="Running", Reason="", readiness=false. Elapsed: 14.098790608s
Jan 21 21:29:47.318: INFO: Pod "pod-subpath-test-secret-rqhb": Phase="Running", Reason="", readiness=false. Elapsed: 16.109630147s
Jan 21 21:29:49.329: INFO: Pod "pod-subpath-test-secret-rqhb": Phase="Running", Reason="", readiness=false. Elapsed: 18.121043275s
Jan 21 21:29:51.340: INFO: Pod "pod-subpath-test-secret-rqhb": Phase="Running", Reason="", readiness=false. Elapsed: 20.132350644s
Jan 21 21:29:53.350: INFO: Pod "pod-subpath-test-secret-rqhb": Phase="Running", Reason="", readiness=false. Elapsed: 22.142531697s
Jan 21 21:29:55.364: INFO: Pod "pod-subpath-test-secret-rqhb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.156247845s
STEP: Saw pod success
Jan 21 21:29:55.364: INFO: Pod "pod-subpath-test-secret-rqhb" satisfied condition "success or failure"
Jan 21 21:29:55.375: INFO: Trying to get logs from node 10.191.28.59 pod pod-subpath-test-secret-rqhb container test-container-subpath-secret-rqhb: <nil>
STEP: delete the pod
Jan 21 21:29:55.431: INFO: Waiting for pod pod-subpath-test-secret-rqhb to disappear
Jan 21 21:29:55.464: INFO: Pod pod-subpath-test-secret-rqhb no longer exists
STEP: Deleting pod pod-subpath-test-secret-rqhb
Jan 21 21:29:55.465: INFO: Deleting pod "pod-subpath-test-secret-rqhb" in namespace "e2e-tests-subpath-r52ft"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 21:29:55.477: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-r52ft" for this suite.
Jan 21 21:30:01.525: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 21:30:01.690: INFO: namespace: e2e-tests-subpath-r52ft, resource: bindings, ignored listing per whitelist
Jan 21 21:30:02.096: INFO: namespace e2e-tests-subpath-r52ft deletion completed in 6.604647444s

• [SLOW TEST:31.330 seconds]
[sig-storage] Subpath
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with secret pod [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 21:30:02.098: INFO: >>> kubeConfig: /tmp/kubeconfig-933165938
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-9g8s5
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-map-b63fb2b2-1dc3-11e9-8130-be6597f3ae53
STEP: Creating a pod to test consume secrets
Jan 21 21:30:02.524: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-b6412b0d-1dc3-11e9-8130-be6597f3ae53" in namespace "e2e-tests-projected-9g8s5" to be "success or failure"
Jan 21 21:30:02.535: INFO: Pod "pod-projected-secrets-b6412b0d-1dc3-11e9-8130-be6597f3ae53": Phase="Pending", Reason="", readiness=false. Elapsed: 10.160629ms
Jan 21 21:30:04.546: INFO: Pod "pod-projected-secrets-b6412b0d-1dc3-11e9-8130-be6597f3ae53": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.021722681s
STEP: Saw pod success
Jan 21 21:30:04.546: INFO: Pod "pod-projected-secrets-b6412b0d-1dc3-11e9-8130-be6597f3ae53" satisfied condition "success or failure"
Jan 21 21:30:04.556: INFO: Trying to get logs from node 10.191.28.39 pod pod-projected-secrets-b6412b0d-1dc3-11e9-8130-be6597f3ae53 container projected-secret-volume-test: <nil>
STEP: delete the pod
Jan 21 21:30:04.614: INFO: Waiting for pod pod-projected-secrets-b6412b0d-1dc3-11e9-8130-be6597f3ae53 to disappear
Jan 21 21:30:04.624: INFO: Pod pod-projected-secrets-b6412b0d-1dc3-11e9-8130-be6597f3ae53 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 21:30:04.624: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-9g8s5" for this suite.
Jan 21 21:30:10.674: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 21:30:10.843: INFO: namespace: e2e-tests-projected-9g8s5, resource: bindings, ignored listing per whitelist
Jan 21 21:30:11.091: INFO: namespace e2e-tests-projected-9g8s5 deletion completed in 6.448342386s

• [SLOW TEST:8.993 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[k8s.io] Probing container 
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 21:30:11.091: INFO: >>> kubeConfig: /tmp/kubeconfig-933165938
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-container-probe-9d25l
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Jan 21 21:30:37.512: INFO: Container started at 2019-01-21 21:30:13 +0000 UTC, pod became ready at 2019-01-21 21:30:37 +0000 UTC
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 21:30:37.512: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-9d25l" for this suite.
Jan 21 21:31:01.561: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 21:31:01.952: INFO: namespace: e2e-tests-container-probe-9d25l, resource: bindings, ignored listing per whitelist
Jan 21 21:31:01.989: INFO: namespace e2e-tests-container-probe-9d25l deletion completed in 24.462393325s

• [SLOW TEST:50.899 seconds]
[k8s.io] Probing container
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 21:31:01.990: INFO: >>> kubeConfig: /tmp/kubeconfig-933165938
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-gc-sq527
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Jan 21 21:31:02.398: INFO: pod1.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod3", UID:"d9efc01e-1dc3-11e9-903f-ee5d7ad9296f", Controller:(*bool)(0xc420fcfb5e), BlockOwnerDeletion:(*bool)(0xc420fcfb5f)}}
Jan 21 21:31:02.409: INFO: pod2.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod1", UID:"d9ebfca4-1dc3-11e9-903f-ee5d7ad9296f", Controller:(*bool)(0xc420f72176), BlockOwnerDeletion:(*bool)(0xc420f72177)}}
Jan 21 21:31:02.421: INFO: pod3.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod2", UID:"d9ede9bb-1dc3-11e9-903f-ee5d7ad9296f", Controller:(*bool)(0xc420fcfd5e), BlockOwnerDeletion:(*bool)(0xc420fcfd5f)}}
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 21:31:07.453: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-sq527" for this suite.
Jan 21 21:31:13.500: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 21:31:13.883: INFO: namespace: e2e-tests-gc-sq527, resource: bindings, ignored listing per whitelist
Jan 21 21:31:14.038: INFO: namespace e2e-tests-gc-sq527 deletion completed in 6.571120185s

• [SLOW TEST:12.048 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 21:31:14.041: INFO: >>> kubeConfig: /tmp/kubeconfig-933165938
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-pods-tsk46
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: setting up watch
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: verifying pod creation was observed
Jan 21 21:31:16.540: INFO: running pod: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-submit-remove-e119d90f-1dc3-11e9-8130-be6597f3ae53", GenerateName:"", Namespace:"e2e-tests-pods-tsk46", SelfLink:"/api/v1/namespaces/e2e-tests-pods-tsk46/pods/pod-submit-remove-e119d90f-1dc3-11e9-8130-be6597f3ae53", UID:"e1280649-1dc3-11e9-903f-ee5d7ad9296f", ResourceVersion:"32776", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63683703074, loc:(*time.Location)(0x6c43b60)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"390667216"}, Annotations:map[string]string{"kubernetes.io/psp":"e2e-test-privileged-psp"}, OwnerReferences:[]v1.OwnerReference(nil), Initializers:(*v1.Initializers)(nil), Finalizers:[]string(nil), ClusterName:""}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"default-token-9fjn9", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(0xc421d61fc0), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil)}}}, InitContainers:[]v1.Container(nil), Containers:[]v1.Container{v1.Container{Name:"nginx", Image:"docker.io/library/nginx:1.14-alpine", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-9fjn9", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc42154ee08), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"10.191.28.59", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc420e3dd40), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc42154ee50)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc42154ee70)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc42154ee78), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil)}, Status:v1.PodStatus{Phase:"Running", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63683703074, loc:(*time.Location)(0x6c43b60)}}, Reason:"", Message:""}, v1.PodCondition{Type:"Ready", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63683703075, loc:(*time.Location)(0x6c43b60)}}, Reason:"", Message:""}, v1.PodCondition{Type:"ContainersReady", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63683703075, loc:(*time.Location)(0x6c43b60)}}, Reason:"", Message:""}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63683703074, loc:(*time.Location)(0x6c43b60)}}, Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"10.191.28.59", PodIP:"172.30.156.149", StartTime:(*v1.Time)(0xc421bf4b00), InitContainerStatuses:[]v1.ContainerStatus(nil), ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"nginx", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(0xc421bf4b20), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:true, RestartCount:0, Image:"docker.io/library/nginx:1.14-alpine", ImageID:"docker.io/library/nginx@sha256:e3f77f7f4a6bb5e7820e013fa60b96602b34f5704e796cfd94b561ae73adcf96", ContainerID:"containerd://463b1ab08e6bfce00289dbac28841d20ea7be013349bf73866f2b1159b41fe91"}}, QOSClass:"BestEffort"}}
STEP: deleting the pod gracefully
STEP: verifying the kubelet observed the termination notice
Jan 21 21:31:21.666: INFO: no pod exists with the name we were looking for, assuming the termination request was observed and completed
STEP: verifying pod deletion was observed
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 21:31:21.681: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-tsk46" for this suite.
Jan 21 21:31:27.726: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 21:31:28.030: INFO: namespace: e2e-tests-pods-tsk46, resource: bindings, ignored listing per whitelist
Jan 21 21:31:28.066: INFO: namespace e2e-tests-pods-tsk46 deletion completed in 6.372873083s

• [SLOW TEST:14.025 seconds]
[k8s.io] Pods
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[k8s.io] Pods 
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 21:31:28.066: INFO: >>> kubeConfig: /tmp/kubeconfig-933165938
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-pods-mvlsl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Jan 21 21:31:30.516: INFO: Waiting up to 5m0s for pod "client-envvars-eab45a8a-1dc3-11e9-8130-be6597f3ae53" in namespace "e2e-tests-pods-mvlsl" to be "success or failure"
Jan 21 21:31:30.536: INFO: Pod "client-envvars-eab45a8a-1dc3-11e9-8130-be6597f3ae53": Phase="Pending", Reason="", readiness=false. Elapsed: 19.2792ms
Jan 21 21:31:32.547: INFO: Pod "client-envvars-eab45a8a-1dc3-11e9-8130-be6597f3ae53": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.030640139s
STEP: Saw pod success
Jan 21 21:31:32.547: INFO: Pod "client-envvars-eab45a8a-1dc3-11e9-8130-be6597f3ae53" satisfied condition "success or failure"
Jan 21 21:31:32.559: INFO: Trying to get logs from node 10.191.28.59 pod client-envvars-eab45a8a-1dc3-11e9-8130-be6597f3ae53 container env3cont: <nil>
STEP: delete the pod
Jan 21 21:31:32.616: INFO: Waiting for pod client-envvars-eab45a8a-1dc3-11e9-8130-be6597f3ae53 to disappear
Jan 21 21:31:32.626: INFO: Pod client-envvars-eab45a8a-1dc3-11e9-8130-be6597f3ae53 no longer exists
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 21:31:32.627: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-mvlsl" for this suite.
Jan 21 21:32:17.102: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 21:32:17.231: INFO: namespace: e2e-tests-pods-mvlsl, resource: bindings, ignored listing per whitelist
Jan 21 21:32:17.488: INFO: namespace e2e-tests-pods-mvlsl deletion completed in 44.847854414s

• [SLOW TEST:49.422 seconds]
[k8s.io] Pods
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 21:32:17.490: INFO: >>> kubeConfig: /tmp/kubeconfig-933165938
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-x5dxd
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0644 on tmpfs
Jan 21 21:32:17.850: INFO: Waiting up to 5m0s for pod "pod-06e9aa78-1dc4-11e9-8130-be6597f3ae53" in namespace "e2e-tests-emptydir-x5dxd" to be "success or failure"
Jan 21 21:32:17.860: INFO: Pod "pod-06e9aa78-1dc4-11e9-8130-be6597f3ae53": Phase="Pending", Reason="", readiness=false. Elapsed: 10.37763ms
Jan 21 21:32:19.871: INFO: Pod "pod-06e9aa78-1dc4-11e9-8130-be6597f3ae53": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.020822058s
STEP: Saw pod success
Jan 21 21:32:19.871: INFO: Pod "pod-06e9aa78-1dc4-11e9-8130-be6597f3ae53" satisfied condition "success or failure"
Jan 21 21:32:19.881: INFO: Trying to get logs from node 10.191.28.39 pod pod-06e9aa78-1dc4-11e9-8130-be6597f3ae53 container test-container: <nil>
STEP: delete the pod
Jan 21 21:32:19.965: INFO: Waiting for pod pod-06e9aa78-1dc4-11e9-8130-be6597f3ae53 to disappear
Jan 21 21:32:19.980: INFO: Pod pod-06e9aa78-1dc4-11e9-8130-be6597f3ae53 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 21:32:19.981: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-x5dxd" for this suite.
Jan 21 21:32:26.029: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 21:32:26.274: INFO: namespace: e2e-tests-emptydir-x5dxd, resource: bindings, ignored listing per whitelist
Jan 21 21:32:26.401: INFO: namespace e2e-tests-emptydir-x5dxd deletion completed in 6.406698254s

• [SLOW TEST:8.911 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 21:32:26.401: INFO: >>> kubeConfig: /tmp/kubeconfig-933165938
STEP: Building a namespace api object, basename pod-network-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-pod-network-test-xcdsz
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-xcdsz
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Jan 21 21:32:26.730: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Jan 21 21:32:48.966: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://172.30.156.152:8080/dial?request=hostName&protocol=udp&host=172.30.41.18&port=8081&tries=1'] Namespace:e2e-tests-pod-network-test-xcdsz PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jan 21 21:32:48.966: INFO: >>> kubeConfig: /tmp/kubeconfig-933165938
Jan 21 21:32:49.200: INFO: Waiting for endpoints: map[]
Jan 21 21:32:49.211: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://172.30.156.152:8080/dial?request=hostName&protocol=udp&host=172.30.156.151&port=8081&tries=1'] Namespace:e2e-tests-pod-network-test-xcdsz PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jan 21 21:32:49.211: INFO: >>> kubeConfig: /tmp/kubeconfig-933165938
Jan 21 21:32:49.435: INFO: Waiting for endpoints: map[]
Jan 21 21:32:49.447: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://172.30.156.152:8080/dial?request=hostName&protocol=udp&host=172.30.216.14&port=8081&tries=1'] Namespace:e2e-tests-pod-network-test-xcdsz PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jan 21 21:32:49.447: INFO: >>> kubeConfig: /tmp/kubeconfig-933165938
Jan 21 21:32:49.646: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 21:32:49.646: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-xcdsz" for this suite.
Jan 21 21:33:13.695: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 21:33:14.054: INFO: namespace: e2e-tests-pod-network-test-xcdsz, resource: bindings, ignored listing per whitelist
Jan 21 21:33:14.069: INFO: namespace e2e-tests-pod-network-test-xcdsz deletion completed in 24.409674883s

• [SLOW TEST:47.669 seconds]
[sig-network] Networking
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: udp [NodeConformance] [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl replace 
  should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 21:33:14.073: INFO: >>> kubeConfig: /tmp/kubeconfig-933165938
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-rxs8v
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Kubectl replace
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1511
[It] should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Jan 21 21:33:14.431: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-933165938 run e2e-test-nginx-pod --generator=run-pod/v1 --image=docker.io/library/nginx:1.14-alpine --labels=run=e2e-test-nginx-pod --namespace=e2e-tests-kubectl-rxs8v'
Jan 21 21:33:14.646: INFO: stderr: ""
Jan 21 21:33:14.646: INFO: stdout: "pod/e2e-test-nginx-pod created\n"
STEP: verifying the pod e2e-test-nginx-pod is running
STEP: verifying the pod e2e-test-nginx-pod was created
Jan 21 21:33:19.697: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-933165938 get pod e2e-test-nginx-pod --namespace=e2e-tests-kubectl-rxs8v -o json'
Jan 21 21:33:19.878: INFO: stderr: ""
Jan 21 21:33:19.878: INFO: stdout: "{\n    \"apiVersion\": \"v1\",\n    \"kind\": \"Pod\",\n    \"metadata\": {\n        \"annotations\": {\n            \"kubernetes.io/psp\": \"e2e-test-privileged-psp\"\n        },\n        \"creationTimestamp\": \"2019-01-21T21:33:14Z\",\n        \"labels\": {\n            \"run\": \"e2e-test-nginx-pod\"\n        },\n        \"name\": \"e2e-test-nginx-pod\",\n        \"namespace\": \"e2e-tests-kubectl-rxs8v\",\n        \"resourceVersion\": \"33221\",\n        \"selfLink\": \"/api/v1/namespaces/e2e-tests-kubectl-rxs8v/pods/e2e-test-nginx-pod\",\n        \"uid\": \"28c2d036-1dc4-11e9-b8a7-eaddb2a75ec8\"\n    },\n    \"spec\": {\n        \"containers\": [\n            {\n                \"image\": \"docker.io/library/nginx:1.14-alpine\",\n                \"imagePullPolicy\": \"IfNotPresent\",\n                \"name\": \"e2e-test-nginx-pod\",\n                \"resources\": {},\n                \"terminationMessagePath\": \"/dev/termination-log\",\n                \"terminationMessagePolicy\": \"File\",\n                \"volumeMounts\": [\n                    {\n                        \"mountPath\": \"/var/run/secrets/kubernetes.io/serviceaccount\",\n                        \"name\": \"default-token-mbfvh\",\n                        \"readOnly\": true\n                    }\n                ]\n            }\n        ],\n        \"dnsPolicy\": \"ClusterFirst\",\n        \"nodeName\": \"10.191.28.59\",\n        \"priority\": 0,\n        \"restartPolicy\": \"Always\",\n        \"schedulerName\": \"default-scheduler\",\n        \"securityContext\": {},\n        \"serviceAccount\": \"default\",\n        \"serviceAccountName\": \"default\",\n        \"terminationGracePeriodSeconds\": 30,\n        \"tolerations\": [\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/not-ready\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            },\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/unreachable\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            }\n        ],\n        \"volumes\": [\n            {\n                \"name\": \"default-token-mbfvh\",\n                \"secret\": {\n                    \"defaultMode\": 420,\n                    \"secretName\": \"default-token-mbfvh\"\n                }\n            }\n        ]\n    },\n    \"status\": {\n        \"conditions\": [\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-01-21T21:33:14Z\",\n                \"status\": \"True\",\n                \"type\": \"Initialized\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-01-21T21:33:16Z\",\n                \"status\": \"True\",\n                \"type\": \"Ready\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-01-21T21:33:16Z\",\n                \"status\": \"True\",\n                \"type\": \"ContainersReady\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-01-21T21:33:14Z\",\n                \"status\": \"True\",\n                \"type\": \"PodScheduled\"\n            }\n        ],\n        \"containerStatuses\": [\n            {\n                \"containerID\": \"containerd://620ad37ac370aa6c49ea8349d20c371b2b53acad296849fa4e3a2ade21b9c4c6\",\n                \"image\": \"docker.io/library/nginx:1.14-alpine\",\n                \"imageID\": \"docker.io/library/nginx@sha256:e3f77f7f4a6bb5e7820e013fa60b96602b34f5704e796cfd94b561ae73adcf96\",\n                \"lastState\": {},\n                \"name\": \"e2e-test-nginx-pod\",\n                \"ready\": true,\n                \"restartCount\": 0,\n                \"state\": {\n                    \"running\": {\n                        \"startedAt\": \"2019-01-21T21:33:15Z\"\n                    }\n                }\n            }\n        ],\n        \"hostIP\": \"10.191.28.59\",\n        \"phase\": \"Running\",\n        \"podIP\": \"172.30.156.153\",\n        \"qosClass\": \"BestEffort\",\n        \"startTime\": \"2019-01-21T21:33:14Z\"\n    }\n}\n"
STEP: replace the image in the pod
Jan 21 21:33:19.879: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-933165938 replace -f - --namespace=e2e-tests-kubectl-rxs8v'
Jan 21 21:33:20.275: INFO: stderr: ""
Jan 21 21:33:20.275: INFO: stdout: "pod/e2e-test-nginx-pod replaced\n"
STEP: verifying the pod e2e-test-nginx-pod has the right image docker.io/library/busybox:1.29
[AfterEach] [k8s.io] Kubectl replace
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1516
Jan 21 21:33:20.285: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-933165938 delete pods e2e-test-nginx-pod --namespace=e2e-tests-kubectl-rxs8v'
Jan 21 21:33:22.140: INFO: stderr: ""
Jan 21 21:33:22.140: INFO: stdout: "pod \"e2e-test-nginx-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 21:33:22.140: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-rxs8v" for this suite.
Jan 21 21:33:28.215: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 21:33:28.552: INFO: namespace: e2e-tests-kubectl-rxs8v, resource: bindings, ignored listing per whitelist
Jan 21 21:33:28.572: INFO: namespace e2e-tests-kubectl-rxs8v deletion completed in 6.388253861s

• [SLOW TEST:14.499 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl replace
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should update a single-container pod's image  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl logs 
  should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 21:33:28.574: INFO: >>> kubeConfig: /tmp/kubeconfig-933165938
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-fpm5p
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Kubectl logs
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1083
STEP: creating an rc
Jan 21 21:33:28.895: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-933165938 create -f - --namespace=e2e-tests-kubectl-fpm5p'
Jan 21 21:33:29.328: INFO: stderr: ""
Jan 21 21:33:29.328: INFO: stdout: "replicationcontroller/redis-master created\n"
[It] should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Waiting for Redis master to start.
Jan 21 21:33:30.339: INFO: Selector matched 1 pods for map[app:redis]
Jan 21 21:33:30.339: INFO: Found 0 / 1
Jan 21 21:33:31.342: INFO: Selector matched 1 pods for map[app:redis]
Jan 21 21:33:31.342: INFO: Found 1 / 1
Jan 21 21:33:31.342: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Jan 21 21:33:31.353: INFO: Selector matched 1 pods for map[app:redis]
Jan 21 21:33:31.353: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
STEP: checking for a matching strings
Jan 21 21:33:31.353: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-933165938 logs redis-master-wqzc7 redis-master --namespace=e2e-tests-kubectl-fpm5p'
Jan 21 21:33:32.145: INFO: stderr: ""
Jan 21 21:33:32.145: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 21 Jan 21:33:30.304 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 21 Jan 21:33:30.304 # Server started, Redis version 3.2.12\n1:M 21 Jan 21:33:30.304 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 21 Jan 21:33:30.304 * The server is now ready to accept connections on port 6379\n"
STEP: limiting log lines
Jan 21 21:33:32.146: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-933165938 log redis-master-wqzc7 redis-master --namespace=e2e-tests-kubectl-fpm5p --tail=1'
Jan 21 21:33:32.403: INFO: stderr: ""
Jan 21 21:33:32.403: INFO: stdout: "1:M 21 Jan 21:33:30.304 * The server is now ready to accept connections on port 6379\n"
STEP: limiting log bytes
Jan 21 21:33:32.403: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-933165938 log redis-master-wqzc7 redis-master --namespace=e2e-tests-kubectl-fpm5p --limit-bytes=1'
Jan 21 21:33:32.700: INFO: stderr: ""
Jan 21 21:33:32.700: INFO: stdout: " "
STEP: exposing timestamps
Jan 21 21:33:32.700: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-933165938 log redis-master-wqzc7 redis-master --namespace=e2e-tests-kubectl-fpm5p --tail=1 --timestamps'
Jan 21 21:33:32.904: INFO: stderr: ""
Jan 21 21:33:32.904: INFO: stdout: "2019-01-21T21:33:30.304949653Z 1:M 21 Jan 21:33:30.304 * The server is now ready to accept connections on port 6379\n"
STEP: restricting to a time range
Jan 21 21:33:35.404: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-933165938 log redis-master-wqzc7 redis-master --namespace=e2e-tests-kubectl-fpm5p --since=1s'
Jan 21 21:33:35.605: INFO: stderr: ""
Jan 21 21:33:35.605: INFO: stdout: ""
Jan 21 21:33:35.605: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-933165938 log redis-master-wqzc7 redis-master --namespace=e2e-tests-kubectl-fpm5p --since=24h'
Jan 21 21:33:35.901: INFO: stderr: ""
Jan 21 21:33:35.901: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 21 Jan 21:33:30.304 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 21 Jan 21:33:30.304 # Server started, Redis version 3.2.12\n1:M 21 Jan 21:33:30.304 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 21 Jan 21:33:30.304 * The server is now ready to accept connections on port 6379\n"
[AfterEach] [k8s.io] Kubectl logs
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1088
STEP: using delete to clean up resources
Jan 21 21:33:35.901: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-933165938 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-fpm5p'
Jan 21 21:33:36.106: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Jan 21 21:33:36.106: INFO: stdout: "replicationcontroller \"redis-master\" force deleted\n"
Jan 21 21:33:36.106: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-933165938 get rc,svc -l name=nginx --no-headers --namespace=e2e-tests-kubectl-fpm5p'
Jan 21 21:33:36.295: INFO: stderr: "No resources found.\n"
Jan 21 21:33:36.295: INFO: stdout: ""
Jan 21 21:33:36.295: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-933165938 get pods -l name=nginx --namespace=e2e-tests-kubectl-fpm5p -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Jan 21 21:33:36.493: INFO: stderr: ""
Jan 21 21:33:36.493: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 21:33:36.493: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-fpm5p" for this suite.
Jan 21 21:34:00.539: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 21:34:00.652: INFO: namespace: e2e-tests-kubectl-fpm5p, resource: bindings, ignored listing per whitelist
Jan 21 21:34:01.012: INFO: namespace e2e-tests-kubectl-fpm5p deletion completed in 24.506145221s

• [SLOW TEST:32.439 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl logs
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should be able to retrieve and filter logs  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 21:34:01.013: INFO: >>> kubeConfig: /tmp/kubeconfig-933165938
STEP: Building a namespace api object, basename sched-pred
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-sched-pred-tmvsv
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:78
Jan 21 21:34:01.370: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Jan 21 21:34:01.476: INFO: Waiting for terminating namespaces to be deleted...
Jan 21 21:34:01.485: INFO: 
Logging pods the kubelet thinks is on node 10.191.28.39 before test
Jan 21 21:34:01.515: INFO: ibm-storage-watcher-6fb675df47-x2x4h from kube-system started at 2019-01-21 19:04:47 +0000 UTC (1 container statuses recorded)
Jan 21 21:34:01.516: INFO: 	Container ibm-storage-watcher-container ready: true, restart count 0
Jan 21 21:34:01.516: INFO: ibm-file-plugin-56f866c9c7-bz4g8 from kube-system started at 2019-01-21 19:04:47 +0000 UTC (1 container statuses recorded)
Jan 21 21:34:01.516: INFO: 	Container ibm-file-plugin-container ready: true, restart count 0
Jan 21 21:34:01.516: INFO: ibm-kube-fluentd-swfr2 from kube-system started at 2019-01-21 19:08:16 +0000 UTC (1 container statuses recorded)
Jan 21 21:34:01.516: INFO: 	Container fluentd ready: true, restart count 0
Jan 21 21:34:01.516: INFO: sonobuoy-systemd-logs-daemon-set-e7ca68af2267426a-f655g from heptio-sonobuoy started at 2019-01-21 21:19:23 +0000 UTC (2 container statuses recorded)
Jan 21 21:34:01.516: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 0
Jan 21 21:34:01.516: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Jan 21 21:34:01.516: INFO: ibm-master-proxy-static-10.191.28.39 from kube-system started at <nil> (0 container statuses recorded)
Jan 21 21:34:01.516: INFO: kube-dns-autoscaler-587cd5cd44-sg6d7 from kube-system started at 2019-01-21 19:04:47 +0000 UTC (1 container statuses recorded)
Jan 21 21:34:01.516: INFO: 	Container autoscaler ready: true, restart count 0
Jan 21 21:34:01.517: INFO: ibm-keepalived-watcher-nw8wp from kube-system started at 2019-01-21 19:04:47 +0000 UTC (1 container statuses recorded)
Jan 21 21:34:01.517: INFO: 	Container keepalived-watcher ready: true, restart count 0
Jan 21 21:34:01.517: INFO: calico-node-6zjw9 from kube-system started at 2019-01-21 19:04:47 +0000 UTC (2 container statuses recorded)
Jan 21 21:34:01.517: INFO: 	Container calico-node ready: true, restart count 0
Jan 21 21:34:01.517: INFO: 	Container install-cni ready: true, restart count 0
Jan 21 21:34:01.517: INFO: test-k8s-e2e-pvg-master-verification from default started at 2019-01-21 21:18:59 +0000 UTC (1 container statuses recorded)
Jan 21 21:34:01.517: INFO: 	Container test-k8s-e2e-pvg-master-verification ready: true, restart count 0
Jan 21 21:34:01.517: INFO: kube-dns-amd64-fddfcc69-l7fs4 from kube-system started at 2019-01-21 19:04:47 +0000 UTC (3 container statuses recorded)
Jan 21 21:34:01.517: INFO: 	Container dnsmasq ready: true, restart count 0
Jan 21 21:34:01.517: INFO: 	Container kubedns ready: true, restart count 0
Jan 21 21:34:01.517: INFO: 	Container sidecar ready: true, restart count 0
Jan 21 21:34:01.517: INFO: calico-kube-controllers-5c699798bc-7cfbr from kube-system started at 2019-01-21 19:04:47 +0000 UTC (1 container statuses recorded)
Jan 21 21:34:01.517: INFO: 	Container calico-kube-controllers ready: true, restart count 0
Jan 21 21:34:01.518: INFO: kubernetes-dashboard-b4bc7db5d-4stht from kube-system started at 2019-01-21 19:04:47 +0000 UTC (1 container statuses recorded)
Jan 21 21:34:01.518: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
Jan 21 21:34:01.518: INFO: vpn-65599665d9-n57t7 from kube-system started at 2019-01-21 19:04:47 +0000 UTC (1 container statuses recorded)
Jan 21 21:34:01.518: INFO: 	Container vpn ready: true, restart count 0
Jan 21 21:34:01.518: INFO: 
Logging pods the kubelet thinks is on node 10.191.28.45 before test
Jan 21 21:34:01.550: INFO: ibm-keepalived-watcher-lpbc8 from kube-system started at 2019-01-21 19:04:54 +0000 UTC (1 container statuses recorded)
Jan 21 21:34:01.550: INFO: 	Container keepalived-watcher ready: true, restart count 0
Jan 21 21:34:01.550: INFO: ibm-cloud-provider-ip-169-62-39-214-854b8b4b9f-jhb5h from ibm-system started at 2019-01-21 19:07:08 +0000 UTC (1 container statuses recorded)
Jan 21 21:34:01.550: INFO: 	Container ibm-cloud-provider-ip-169-62-39-214 ready: true, restart count 0
Jan 21 21:34:01.550: INFO: ibm-kube-fluentd-dgst5 from kube-system started at 2019-01-21 19:08:16 +0000 UTC (1 container statuses recorded)
Jan 21 21:34:01.550: INFO: 	Container fluentd ready: true, restart count 0
Jan 21 21:34:01.551: INFO: calico-node-wf86f from kube-system started at 2019-01-21 19:04:54 +0000 UTC (2 container statuses recorded)
Jan 21 21:34:01.551: INFO: 	Container calico-node ready: true, restart count 0
Jan 21 21:34:01.551: INFO: 	Container install-cni ready: true, restart count 0
Jan 21 21:34:01.551: INFO: sonobuoy-e2e-job-f09952848bde41e6 from heptio-sonobuoy started at 2019-01-21 21:19:23 +0000 UTC (2 container statuses recorded)
Jan 21 21:34:01.551: INFO: 	Container e2e ready: true, restart count 0
Jan 21 21:34:01.551: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Jan 21 21:34:01.551: INFO: sonobuoy-systemd-logs-daemon-set-e7ca68af2267426a-x52k6 from heptio-sonobuoy started at 2019-01-21 21:19:23 +0000 UTC (2 container statuses recorded)
Jan 21 21:34:01.551: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 0
Jan 21 21:34:01.551: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Jan 21 21:34:01.551: INFO: ibm-master-proxy-static-10.191.28.45 from kube-system started at <nil> (0 container statuses recorded)
Jan 21 21:34:01.551: INFO: kube-dns-amd64-fddfcc69-pfbsg from kube-system started at 2019-01-21 19:05:17 +0000 UTC (3 container statuses recorded)
Jan 21 21:34:01.551: INFO: 	Container dnsmasq ready: true, restart count 0
Jan 21 21:34:01.551: INFO: 	Container kubedns ready: true, restart count 0
Jan 21 21:34:01.551: INFO: 	Container sidecar ready: true, restart count 0
Jan 21 21:34:01.551: INFO: public-cra84c924d32e442ceb4b6d3925b452e95-alb1-5487bcf49f-2lh5k from kube-system started at 2019-01-21 19:07:51 +0000 UTC (4 container statuses recorded)
Jan 21 21:34:01.551: INFO: 	Container ingress-auth-1 ready: true, restart count 0
Jan 21 21:34:01.551: INFO: 	Container ingress-auth-2 ready: true, restart count 0
Jan 21 21:34:01.551: INFO: 	Container ingress-auth-3 ready: true, restart count 0
Jan 21 21:34:01.551: INFO: 	Container nginx-ingress ready: true, restart count 0
Jan 21 21:34:01.551: INFO: 
Logging pods the kubelet thinks is on node 10.191.28.59 before test
Jan 21 21:34:01.581: INFO: ibm-kube-fluentd-4qcmt from kube-system started at 2019-01-21 19:08:16 +0000 UTC (1 container statuses recorded)
Jan 21 21:34:01.581: INFO: 	Container fluentd ready: true, restart count 0
Jan 21 21:34:01.581: INFO: metrics-server-79744c9677-q495s from kube-system started at 2019-01-21 19:05:26 +0000 UTC (2 container statuses recorded)
Jan 21 21:34:01.581: INFO: 	Container metrics-server ready: true, restart count 0
Jan 21 21:34:01.581: INFO: 	Container metrics-server-nanny ready: true, restart count 0
Jan 21 21:34:01.581: INFO: ibm-cloud-provider-ip-169-62-39-214-854b8b4b9f-hhkzk from ibm-system started at 2019-01-21 19:07:08 +0000 UTC (1 container statuses recorded)
Jan 21 21:34:01.581: INFO: 	Container ibm-cloud-provider-ip-169-62-39-214 ready: true, restart count 0
Jan 21 21:34:01.581: INFO: public-cra84c924d32e442ceb4b6d3925b452e95-alb1-5487bcf49f-d2tg2 from kube-system started at 2019-01-21 19:07:51 +0000 UTC (4 container statuses recorded)
Jan 21 21:34:01.581: INFO: 	Container ingress-auth-1 ready: true, restart count 0
Jan 21 21:34:01.581: INFO: 	Container ingress-auth-2 ready: true, restart count 0
Jan 21 21:34:01.581: INFO: 	Container ingress-auth-3 ready: true, restart count 0
Jan 21 21:34:01.581: INFO: 	Container nginx-ingress ready: true, restart count 0
Jan 21 21:34:01.581: INFO: sonobuoy from heptio-sonobuoy started at 2019-01-21 21:19:21 +0000 UTC (1 container statuses recorded)
Jan 21 21:34:01.581: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Jan 21 21:34:01.581: INFO: ibm-master-proxy-static-10.191.28.59 from kube-system started at <nil> (0 container statuses recorded)
Jan 21 21:34:01.581: INFO: ibm-keepalived-watcher-tlqx2 from kube-system started at 2019-01-21 19:04:59 +0000 UTC (1 container statuses recorded)
Jan 21 21:34:01.581: INFO: 	Container keepalived-watcher ready: true, restart count 0
Jan 21 21:34:01.581: INFO: calico-node-z9frg from kube-system started at 2019-01-21 19:04:59 +0000 UTC (2 container statuses recorded)
Jan 21 21:34:01.581: INFO: 	Container calico-node ready: true, restart count 0
Jan 21 21:34:01.581: INFO: 	Container install-cni ready: true, restart count 0
Jan 21 21:34:01.581: INFO: sonobuoy-systemd-logs-daemon-set-e7ca68af2267426a-x9rm8 from heptio-sonobuoy started at 2019-01-21 21:19:23 +0000 UTC (2 container statuses recorded)
Jan 21 21:34:01.581: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 0
Jan 21 21:34:01.581: INFO: 	Container sonobuoy-worker ready: true, restart count 0
[It] validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Trying to launch a pod without a label to get a node which can launch it.
STEP: Explicitly delete pod here to free the resource it takes.
STEP: Trying to apply a random label on the found node.
STEP: verifying the node has the label kubernetes.io/e2e-46040d80-1dc4-11e9-8130-be6597f3ae53 42
STEP: Trying to relaunch the pod, now with labels.
STEP: removing the label kubernetes.io/e2e-46040d80-1dc4-11e9-8130-be6597f3ae53 off the node 10.191.28.59
STEP: verifying the node doesn't have the label kubernetes.io/e2e-46040d80-1dc4-11e9-8130-be6597f3ae53
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 21:34:05.799: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-sched-pred-tmvsv" for this suite.
Jan 21 21:34:19.846: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 21:34:19.905: INFO: namespace: e2e-tests-sched-pred-tmvsv, resource: bindings, ignored listing per whitelist
Jan 21 21:34:20.175: INFO: namespace e2e-tests-sched-pred-tmvsv deletion completed in 14.362175682s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:69

• [SLOW TEST:19.162 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] Secrets 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 21:34:20.175: INFO: >>> kubeConfig: /tmp/kubeconfig-933165938
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-secrets-jj6tr
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-501fceec-1dc4-11e9-8130-be6597f3ae53
STEP: Creating a pod to test consume secrets
Jan 21 21:34:20.690: INFO: Waiting up to 5m0s for pod "pod-secrets-5021b263-1dc4-11e9-8130-be6597f3ae53" in namespace "e2e-tests-secrets-jj6tr" to be "success or failure"
Jan 21 21:34:20.706: INFO: Pod "pod-secrets-5021b263-1dc4-11e9-8130-be6597f3ae53": Phase="Pending", Reason="", readiness=false. Elapsed: 14.85978ms
Jan 21 21:34:22.717: INFO: Pod "pod-secrets-5021b263-1dc4-11e9-8130-be6597f3ae53": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.025708777s
STEP: Saw pod success
Jan 21 21:34:22.717: INFO: Pod "pod-secrets-5021b263-1dc4-11e9-8130-be6597f3ae53" satisfied condition "success or failure"
Jan 21 21:34:22.727: INFO: Trying to get logs from node 10.191.28.39 pod pod-secrets-5021b263-1dc4-11e9-8130-be6597f3ae53 container secret-volume-test: <nil>
STEP: delete the pod
Jan 21 21:34:22.797: INFO: Waiting for pod pod-secrets-5021b263-1dc4-11e9-8130-be6597f3ae53 to disappear
Jan 21 21:34:22.809: INFO: Pod pod-secrets-5021b263-1dc4-11e9-8130-be6597f3ae53 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 21:34:22.810: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-jj6tr" for this suite.
Jan 21 21:34:28.870: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 21:34:29.643: INFO: namespace: e2e-tests-secrets-jj6tr, resource: bindings, ignored listing per whitelist
Jan 21 21:34:29.727: INFO: namespace e2e-tests-secrets-jj6tr deletion completed in 6.902944763s

• [SLOW TEST:9.552 seconds]
[sig-storage] Secrets
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-api-machinery] Secrets 
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 21:34:29.728: INFO: >>> kubeConfig: /tmp/kubeconfig-933165938
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-secrets-bb72r
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-55b82739-1dc4-11e9-8130-be6597f3ae53
STEP: Creating a pod to test consume secrets
Jan 21 21:34:30.074: INFO: Waiting up to 5m0s for pod "pod-secrets-55b9b209-1dc4-11e9-8130-be6597f3ae53" in namespace "e2e-tests-secrets-bb72r" to be "success or failure"
Jan 21 21:34:30.084: INFO: Pod "pod-secrets-55b9b209-1dc4-11e9-8130-be6597f3ae53": Phase="Pending", Reason="", readiness=false. Elapsed: 10.085977ms
Jan 21 21:34:32.098: INFO: Pod "pod-secrets-55b9b209-1dc4-11e9-8130-be6597f3ae53": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.024405951s
STEP: Saw pod success
Jan 21 21:34:32.098: INFO: Pod "pod-secrets-55b9b209-1dc4-11e9-8130-be6597f3ae53" satisfied condition "success or failure"
Jan 21 21:34:32.108: INFO: Trying to get logs from node 10.191.28.59 pod pod-secrets-55b9b209-1dc4-11e9-8130-be6597f3ae53 container secret-env-test: <nil>
STEP: delete the pod
Jan 21 21:34:32.196: INFO: Waiting for pod pod-secrets-55b9b209-1dc4-11e9-8130-be6597f3ae53 to disappear
Jan 21 21:34:32.205: INFO: Pod pod-secrets-55b9b209-1dc4-11e9-8130-be6597f3ae53 no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 21:34:32.205: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-bb72r" for this suite.
Jan 21 21:34:38.253: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 21:34:38.559: INFO: namespace: e2e-tests-secrets-bb72r, resource: bindings, ignored listing per whitelist
Jan 21 21:34:38.669: INFO: namespace e2e-tests-secrets-bb72r deletion completed in 6.449921066s

• [SLOW TEST:8.942 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:31
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Secrets 
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 21:34:38.671: INFO: >>> kubeConfig: /tmp/kubeconfig-933165938
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-secrets-tz499
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-secret-namespace-xtl5w
STEP: Creating secret with name secret-test-5b10642d-1dc4-11e9-8130-be6597f3ae53
STEP: Creating a pod to test consume secrets
Jan 21 21:34:39.252: INFO: Waiting up to 5m0s for pod "pod-secrets-5b32a0bc-1dc4-11e9-8130-be6597f3ae53" in namespace "e2e-tests-secrets-tz499" to be "success or failure"
Jan 21 21:34:39.269: INFO: Pod "pod-secrets-5b32a0bc-1dc4-11e9-8130-be6597f3ae53": Phase="Pending", Reason="", readiness=false. Elapsed: 16.996277ms
Jan 21 21:34:41.284: INFO: Pod "pod-secrets-5b32a0bc-1dc4-11e9-8130-be6597f3ae53": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.031813934s
STEP: Saw pod success
Jan 21 21:34:41.284: INFO: Pod "pod-secrets-5b32a0bc-1dc4-11e9-8130-be6597f3ae53" satisfied condition "success or failure"
Jan 21 21:34:41.296: INFO: Trying to get logs from node 10.191.28.39 pod pod-secrets-5b32a0bc-1dc4-11e9-8130-be6597f3ae53 container secret-volume-test: <nil>
STEP: delete the pod
Jan 21 21:34:41.355: INFO: Waiting for pod pod-secrets-5b32a0bc-1dc4-11e9-8130-be6597f3ae53 to disappear
Jan 21 21:34:41.367: INFO: Pod pod-secrets-5b32a0bc-1dc4-11e9-8130-be6597f3ae53 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 21:34:41.367: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-tz499" for this suite.
Jan 21 21:34:47.415: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 21:34:47.573: INFO: namespace: e2e-tests-secrets-tz499, resource: bindings, ignored listing per whitelist
Jan 21 21:34:47.966: INFO: namespace e2e-tests-secrets-tz499 deletion completed in 6.585070129s
STEP: Destroying namespace "e2e-tests-secret-namespace-xtl5w" for this suite.
Jan 21 21:34:54.001: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 21:34:54.323: INFO: namespace: e2e-tests-secret-namespace-xtl5w, resource: bindings, ignored listing per whitelist
Jan 21 21:34:54.367: INFO: namespace e2e-tests-secret-namespace-xtl5w deletion completed in 6.400751915s

• [SLOW TEST:15.697 seconds]
[sig-storage] Secrets
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run pod 
  should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 21:34:54.368: INFO: >>> kubeConfig: /tmp/kubeconfig-933165938
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-5x8n6
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Kubectl run pod
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1475
[It] should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Jan 21 21:34:54.729: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-933165938 run e2e-test-nginx-pod --restart=Never --generator=run-pod/v1 --image=docker.io/library/nginx:1.14-alpine --namespace=e2e-tests-kubectl-5x8n6'
Jan 21 21:34:54.976: INFO: stderr: ""
Jan 21 21:34:54.976: INFO: stdout: "pod/e2e-test-nginx-pod created\n"
STEP: verifying the pod e2e-test-nginx-pod was created
[AfterEach] [k8s.io] Kubectl run pod
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1480
Jan 21 21:34:54.989: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-933165938 delete pods e2e-test-nginx-pod --namespace=e2e-tests-kubectl-5x8n6'
Jan 21 21:34:56.357: INFO: stderr: ""
Jan 21 21:34:56.357: INFO: stdout: "pod \"e2e-test-nginx-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 21:34:56.357: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-5x8n6" for this suite.
Jan 21 21:35:02.410: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 21:35:02.604: INFO: namespace: e2e-tests-kubectl-5x8n6, resource: bindings, ignored listing per whitelist
Jan 21 21:35:02.779: INFO: namespace e2e-tests-kubectl-5x8n6 deletion completed in 6.403193355s

• [SLOW TEST:8.412 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run pod
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create a pod from an image when restart is Never  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on tmpfs should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 21:35:02.779: INFO: >>> kubeConfig: /tmp/kubeconfig-933165938
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-4cm6v
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on tmpfs should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir volume type on tmpfs
Jan 21 21:35:03.134: INFO: Waiting up to 5m0s for pod "pod-696e7ba4-1dc4-11e9-8130-be6597f3ae53" in namespace "e2e-tests-emptydir-4cm6v" to be "success or failure"
Jan 21 21:35:03.147: INFO: Pod "pod-696e7ba4-1dc4-11e9-8130-be6597f3ae53": Phase="Pending", Reason="", readiness=false. Elapsed: 11.897369ms
Jan 21 21:35:05.158: INFO: Pod "pod-696e7ba4-1dc4-11e9-8130-be6597f3ae53": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.023243574s
STEP: Saw pod success
Jan 21 21:35:05.158: INFO: Pod "pod-696e7ba4-1dc4-11e9-8130-be6597f3ae53" satisfied condition "success or failure"
Jan 21 21:35:05.168: INFO: Trying to get logs from node 10.191.28.39 pod pod-696e7ba4-1dc4-11e9-8130-be6597f3ae53 container test-container: <nil>
STEP: delete the pod
Jan 21 21:35:05.222: INFO: Waiting for pod pod-696e7ba4-1dc4-11e9-8130-be6597f3ae53 to disappear
Jan 21 21:35:05.232: INFO: Pod pod-696e7ba4-1dc4-11e9-8130-be6597f3ae53 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 21:35:05.232: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-4cm6v" for this suite.
Jan 21 21:35:11.280: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 21:35:11.518: INFO: namespace: e2e-tests-emptydir-4cm6v, resource: bindings, ignored listing per whitelist
Jan 21 21:35:11.769: INFO: namespace e2e-tests-emptydir-4cm6v deletion completed in 6.523154319s

• [SLOW TEST:8.989 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  volume on tmpfs should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 21:35:11.769: INFO: >>> kubeConfig: /tmp/kubeconfig-933165938
STEP: Building a namespace api object, basename containers
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-containers-6r7m6
STEP: Waiting for a default service account to be provisioned in namespace
[It] should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test use defaults
Jan 21 21:35:12.107: INFO: Waiting up to 5m0s for pod "client-containers-6ec7a813-1dc4-11e9-8130-be6597f3ae53" in namespace "e2e-tests-containers-6r7m6" to be "success or failure"
Jan 21 21:35:12.118: INFO: Pod "client-containers-6ec7a813-1dc4-11e9-8130-be6597f3ae53": Phase="Pending", Reason="", readiness=false. Elapsed: 10.293212ms
Jan 21 21:35:14.129: INFO: Pod "client-containers-6ec7a813-1dc4-11e9-8130-be6597f3ae53": Phase="Pending", Reason="", readiness=false. Elapsed: 2.021458926s
Jan 21 21:35:16.140: INFO: Pod "client-containers-6ec7a813-1dc4-11e9-8130-be6597f3ae53": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.031990202s
STEP: Saw pod success
Jan 21 21:35:16.140: INFO: Pod "client-containers-6ec7a813-1dc4-11e9-8130-be6597f3ae53" satisfied condition "success or failure"
Jan 21 21:35:16.151: INFO: Trying to get logs from node 10.191.28.59 pod client-containers-6ec7a813-1dc4-11e9-8130-be6597f3ae53 container test-container: <nil>
STEP: delete the pod
Jan 21 21:35:16.264: INFO: Waiting for pod client-containers-6ec7a813-1dc4-11e9-8130-be6597f3ae53 to disappear
Jan 21 21:35:16.323: INFO: Pod client-containers-6ec7a813-1dc4-11e9-8130-be6597f3ae53 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 21:35:16.323: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-6r7m6" for this suite.
Jan 21 21:35:22.370: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 21:35:22.504: INFO: namespace: e2e-tests-containers-6r7m6, resource: bindings, ignored listing per whitelist
Jan 21 21:35:22.855: INFO: namespace e2e-tests-containers-6r7m6 deletion completed in 6.519442413s

• [SLOW TEST:11.087 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 21:35:22.856: INFO: >>> kubeConfig: /tmp/kubeconfig-933165938
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-container-probe-vm79f
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-http in namespace e2e-tests-container-probe-vm79f
Jan 21 21:35:25.243: INFO: Started pod liveness-http in namespace e2e-tests-container-probe-vm79f
STEP: checking the pod's current state and verifying that restartCount is present
Jan 21 21:35:25.257: INFO: Initial restart count of pod liveness-http is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 21:39:25.667: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-vm79f" for this suite.
Jan 21 21:39:31.721: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 21:39:32.101: INFO: namespace: e2e-tests-container-probe-vm79f, resource: bindings, ignored listing per whitelist
Jan 21 21:39:32.158: INFO: namespace e2e-tests-container-probe-vm79f deletion completed in 6.472523635s

• [SLOW TEST:249.303 seconds]
[k8s.io] Probing container
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Downward API volume 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 21:39:32.158: INFO: >>> kubeConfig: /tmp/kubeconfig-933165938
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-d8k59
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating the pod
Jan 21 21:39:35.145: INFO: Successfully updated pod "labelsupdate09fd893e-1dc5-11e9-8130-be6597f3ae53"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 21:39:39.216: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-d8k59" for this suite.
Jan 21 21:40:03.262: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 21:40:03.441: INFO: namespace: e2e-tests-downward-api-d8k59, resource: bindings, ignored listing per whitelist
Jan 21 21:40:03.668: INFO: namespace e2e-tests-downward-api-d8k59 deletion completed in 24.436453136s

• [SLOW TEST:31.510 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 21:40:03.670: INFO: >>> kubeConfig: /tmp/kubeconfig-933165938
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-kpww8
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0644 on node default medium
Jan 21 21:40:04.023: INFO: Waiting up to 5m0s for pod "pod-1cc606c7-1dc5-11e9-8130-be6597f3ae53" in namespace "e2e-tests-emptydir-kpww8" to be "success or failure"
Jan 21 21:40:04.032: INFO: Pod "pod-1cc606c7-1dc5-11e9-8130-be6597f3ae53": Phase="Pending", Reason="", readiness=false. Elapsed: 9.515729ms
Jan 21 21:40:06.046: INFO: Pod "pod-1cc606c7-1dc5-11e9-8130-be6597f3ae53": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.022951185s
STEP: Saw pod success
Jan 21 21:40:06.046: INFO: Pod "pod-1cc606c7-1dc5-11e9-8130-be6597f3ae53" satisfied condition "success or failure"
Jan 21 21:40:06.056: INFO: Trying to get logs from node 10.191.28.39 pod pod-1cc606c7-1dc5-11e9-8130-be6597f3ae53 container test-container: <nil>
STEP: delete the pod
Jan 21 21:40:06.164: INFO: Waiting for pod pod-1cc606c7-1dc5-11e9-8130-be6597f3ae53 to disappear
Jan 21 21:40:06.174: INFO: Pod pod-1cc606c7-1dc5-11e9-8130-be6597f3ae53 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 21:40:06.175: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-kpww8" for this suite.
Jan 21 21:40:12.237: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 21:40:12.554: INFO: namespace: e2e-tests-emptydir-kpww8, resource: bindings, ignored listing per whitelist
Jan 21 21:40:12.626: INFO: namespace e2e-tests-emptydir-kpww8 deletion completed in 6.436825009s

• [SLOW TEST:8.956 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 21:40:12.626: INFO: >>> kubeConfig: /tmp/kubeconfig-933165938
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-xt7rm
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Jan 21 21:40:12.970: INFO: Waiting up to 5m0s for pod "downwardapi-volume-221b9801-1dc5-11e9-8130-be6597f3ae53" in namespace "e2e-tests-downward-api-xt7rm" to be "success or failure"
Jan 21 21:40:12.985: INFO: Pod "downwardapi-volume-221b9801-1dc5-11e9-8130-be6597f3ae53": Phase="Pending", Reason="", readiness=false. Elapsed: 14.883096ms
Jan 21 21:40:14.998: INFO: Pod "downwardapi-volume-221b9801-1dc5-11e9-8130-be6597f3ae53": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.027821315s
STEP: Saw pod success
Jan 21 21:40:14.998: INFO: Pod "downwardapi-volume-221b9801-1dc5-11e9-8130-be6597f3ae53" satisfied condition "success or failure"
Jan 21 21:40:15.013: INFO: Trying to get logs from node 10.191.28.59 pod downwardapi-volume-221b9801-1dc5-11e9-8130-be6597f3ae53 container client-container: <nil>
STEP: delete the pod
Jan 21 21:40:15.071: INFO: Waiting for pod downwardapi-volume-221b9801-1dc5-11e9-8130-be6597f3ae53 to disappear
Jan 21 21:40:15.079: INFO: Pod downwardapi-volume-221b9801-1dc5-11e9-8130-be6597f3ae53 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 21:40:15.079: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-xt7rm" for this suite.
Jan 21 21:40:21.138: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 21:40:21.269: INFO: namespace: e2e-tests-downward-api-xt7rm, resource: bindings, ignored listing per whitelist
Jan 21 21:40:21.574: INFO: namespace e2e-tests-downward-api-xt7rm deletion completed in 6.479759044s

• [SLOW TEST:8.948 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-api-machinery] ConfigMap 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 21:40:21.575: INFO: >>> kubeConfig: /tmp/kubeconfig-933165938
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-clplv
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap e2e-tests-configmap-clplv/configmap-test-27713c6f-1dc5-11e9-8130-be6597f3ae53
STEP: Creating a pod to test consume configMaps
Jan 21 21:40:21.928: INFO: Waiting up to 5m0s for pod "pod-configmaps-2772977d-1dc5-11e9-8130-be6597f3ae53" in namespace "e2e-tests-configmap-clplv" to be "success or failure"
Jan 21 21:40:21.940: INFO: Pod "pod-configmaps-2772977d-1dc5-11e9-8130-be6597f3ae53": Phase="Pending", Reason="", readiness=false. Elapsed: 11.09393ms
Jan 21 21:40:23.951: INFO: Pod "pod-configmaps-2772977d-1dc5-11e9-8130-be6597f3ae53": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.022705276s
STEP: Saw pod success
Jan 21 21:40:23.951: INFO: Pod "pod-configmaps-2772977d-1dc5-11e9-8130-be6597f3ae53" satisfied condition "success or failure"
Jan 21 21:40:23.962: INFO: Trying to get logs from node 10.191.28.39 pod pod-configmaps-2772977d-1dc5-11e9-8130-be6597f3ae53 container env-test: <nil>
STEP: delete the pod
Jan 21 21:40:24.022: INFO: Waiting for pod pod-configmaps-2772977d-1dc5-11e9-8130-be6597f3ae53 to disappear
Jan 21 21:40:24.035: INFO: Pod pod-configmaps-2772977d-1dc5-11e9-8130-be6597f3ae53 no longer exists
[AfterEach] [sig-api-machinery] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 21:40:24.035: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-clplv" for this suite.
Jan 21 21:40:32.088: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 21:40:32.342: INFO: namespace: e2e-tests-configmap-clplv, resource: bindings, ignored listing per whitelist
Jan 21 21:40:32.481: INFO: namespace e2e-tests-configmap-clplv deletion completed in 8.431698388s

• [SLOW TEST:10.907 seconds]
[sig-api-machinery] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:30
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 21:40:32.483: INFO: >>> kubeConfig: /tmp/kubeconfig-933165938
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-watch-ggmpn
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a watch on configmaps with a certain label
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: changing the label value of the configmap
STEP: Expecting to observe a delete notification for the watched object
Jan 21 21:40:32.860: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-ggmpn,SelfLink:/api/v1/namespaces/e2e-tests-watch-ggmpn/configmaps/e2e-watch-test-label-changed,UID:2df27e4d-1dc5-11e9-903f-ee5d7ad9296f,ResourceVersion:34554,Generation:0,CreationTimestamp:2019-01-21 21:40:32 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Jan 21 21:40:32.860: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-ggmpn,SelfLink:/api/v1/namespaces/e2e-tests-watch-ggmpn/configmaps/e2e-watch-test-label-changed,UID:2df27e4d-1dc5-11e9-903f-ee5d7ad9296f,ResourceVersion:34555,Generation:0,CreationTimestamp:2019-01-21 21:40:32 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Jan 21 21:40:32.861: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-ggmpn,SelfLink:/api/v1/namespaces/e2e-tests-watch-ggmpn/configmaps/e2e-watch-test-label-changed,UID:2df27e4d-1dc5-11e9-903f-ee5d7ad9296f,ResourceVersion:34556,Generation:0,CreationTimestamp:2019-01-21 21:40:32 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time
STEP: Expecting not to observe a notification because the object no longer meets the selector's requirements
STEP: changing the label value of the configmap back
STEP: modifying the configmap a third time
STEP: deleting the configmap
STEP: Expecting to observe an add notification for the watched object when the label value was restored
Jan 21 21:40:42.989: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-ggmpn,SelfLink:/api/v1/namespaces/e2e-tests-watch-ggmpn/configmaps/e2e-watch-test-label-changed,UID:2df27e4d-1dc5-11e9-903f-ee5d7ad9296f,ResourceVersion:34574,Generation:0,CreationTimestamp:2019-01-21 21:40:32 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Jan 21 21:40:42.990: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-ggmpn,SelfLink:/api/v1/namespaces/e2e-tests-watch-ggmpn/configmaps/e2e-watch-test-label-changed,UID:2df27e4d-1dc5-11e9-903f-ee5d7ad9296f,ResourceVersion:34575,Generation:0,CreationTimestamp:2019-01-21 21:40:32 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
Jan 21 21:40:42.990: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-ggmpn,SelfLink:/api/v1/namespaces/e2e-tests-watch-ggmpn/configmaps/e2e-watch-test-label-changed,UID:2df27e4d-1dc5-11e9-903f-ee5d7ad9296f,ResourceVersion:34576,Generation:0,CreationTimestamp:2019-01-21 21:40:32 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 21:40:42.990: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-ggmpn" for this suite.
Jan 21 21:40:49.053: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 21:40:49.485: INFO: namespace: e2e-tests-watch-ggmpn, resource: bindings, ignored listing per whitelist
Jan 21 21:40:49.558: INFO: namespace e2e-tests-watch-ggmpn deletion completed in 6.552902693s

• [SLOW TEST:17.075 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Downward API volume 
  should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 21:40:49.558: INFO: >>> kubeConfig: /tmp/kubeconfig-933165938
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-7bnnm
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Jan 21 21:40:50.105: INFO: Waiting up to 5m0s for pod "downwardapi-volume-383dea0e-1dc5-11e9-8130-be6597f3ae53" in namespace "e2e-tests-downward-api-7bnnm" to be "success or failure"
Jan 21 21:40:50.117: INFO: Pod "downwardapi-volume-383dea0e-1dc5-11e9-8130-be6597f3ae53": Phase="Pending", Reason="", readiness=false. Elapsed: 10.68477ms
Jan 21 21:40:52.127: INFO: Pod "downwardapi-volume-383dea0e-1dc5-11e9-8130-be6597f3ae53": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.021513277s
STEP: Saw pod success
Jan 21 21:40:52.128: INFO: Pod "downwardapi-volume-383dea0e-1dc5-11e9-8130-be6597f3ae53" satisfied condition "success or failure"
Jan 21 21:40:52.164: INFO: Trying to get logs from node 10.191.28.59 pod downwardapi-volume-383dea0e-1dc5-11e9-8130-be6597f3ae53 container client-container: <nil>
STEP: delete the pod
Jan 21 21:40:52.218: INFO: Waiting for pod downwardapi-volume-383dea0e-1dc5-11e9-8130-be6597f3ae53 to disappear
Jan 21 21:40:52.228: INFO: Pod downwardapi-volume-383dea0e-1dc5-11e9-8130-be6597f3ae53 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 21:40:52.228: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-7bnnm" for this suite.
Jan 21 21:40:58.302: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 21:40:58.537: INFO: namespace: e2e-tests-downward-api-7bnnm, resource: bindings, ignored listing per whitelist
Jan 21 21:40:58.891: INFO: namespace e2e-tests-downward-api-7bnnm deletion completed in 6.647370722s

• [SLOW TEST:9.334 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 21:40:58.892: INFO: >>> kubeConfig: /tmp/kubeconfig-933165938
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-5t9ch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0644 on node default medium
Jan 21 21:40:59.269: INFO: Waiting up to 5m0s for pod "pod-3db46688-1dc5-11e9-8130-be6597f3ae53" in namespace "e2e-tests-emptydir-5t9ch" to be "success or failure"
Jan 21 21:40:59.281: INFO: Pod "pod-3db46688-1dc5-11e9-8130-be6597f3ae53": Phase="Pending", Reason="", readiness=false. Elapsed: 11.932159ms
Jan 21 21:41:01.292: INFO: Pod "pod-3db46688-1dc5-11e9-8130-be6597f3ae53": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.022685038s
STEP: Saw pod success
Jan 21 21:41:01.292: INFO: Pod "pod-3db46688-1dc5-11e9-8130-be6597f3ae53" satisfied condition "success or failure"
Jan 21 21:41:01.303: INFO: Trying to get logs from node 10.191.28.39 pod pod-3db46688-1dc5-11e9-8130-be6597f3ae53 container test-container: <nil>
STEP: delete the pod
Jan 21 21:41:01.378: INFO: Waiting for pod pod-3db46688-1dc5-11e9-8130-be6597f3ae53 to disappear
Jan 21 21:41:01.387: INFO: Pod pod-3db46688-1dc5-11e9-8130-be6597f3ae53 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 21:41:01.388: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-5t9ch" for this suite.
Jan 21 21:41:07.440: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 21:41:07.632: INFO: namespace: e2e-tests-emptydir-5t9ch, resource: bindings, ignored listing per whitelist
Jan 21 21:41:07.958: INFO: namespace e2e-tests-emptydir-5t9ch deletion completed in 6.555321419s

• [SLOW TEST:9.066 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 21:41:07.959: INFO: >>> kubeConfig: /tmp/kubeconfig-933165938
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-vl8vm
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-map-43251f69-1dc5-11e9-8130-be6597f3ae53
STEP: Creating a pod to test consume configMaps
Jan 21 21:41:08.412: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-4326a15f-1dc5-11e9-8130-be6597f3ae53" in namespace "e2e-tests-projected-vl8vm" to be "success or failure"
Jan 21 21:41:08.422: INFO: Pod "pod-projected-configmaps-4326a15f-1dc5-11e9-8130-be6597f3ae53": Phase="Pending", Reason="", readiness=false. Elapsed: 10.012044ms
Jan 21 21:41:10.437: INFO: Pod "pod-projected-configmaps-4326a15f-1dc5-11e9-8130-be6597f3ae53": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.025424845s
STEP: Saw pod success
Jan 21 21:41:10.437: INFO: Pod "pod-projected-configmaps-4326a15f-1dc5-11e9-8130-be6597f3ae53" satisfied condition "success or failure"
Jan 21 21:41:10.447: INFO: Trying to get logs from node 10.191.28.59 pod pod-projected-configmaps-4326a15f-1dc5-11e9-8130-be6597f3ae53 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Jan 21 21:41:10.564: INFO: Waiting for pod pod-projected-configmaps-4326a15f-1dc5-11e9-8130-be6597f3ae53 to disappear
Jan 21 21:41:10.574: INFO: Pod pod-projected-configmaps-4326a15f-1dc5-11e9-8130-be6597f3ae53 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 21:41:10.574: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-vl8vm" for this suite.
Jan 21 21:41:16.622: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 21:41:16.670: INFO: namespace: e2e-tests-projected-vl8vm, resource: bindings, ignored listing per whitelist
Jan 21 21:41:16.995: INFO: namespace e2e-tests-projected-vl8vm deletion completed in 6.407832952s

• [SLOW TEST:9.037 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 21:41:16.998: INFO: >>> kubeConfig: /tmp/kubeconfig-933165938
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-secrets-4dgq4
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-4879e2c8-1dc5-11e9-8130-be6597f3ae53
STEP: Creating a pod to test consume secrets
Jan 21 21:41:17.348: INFO: Waiting up to 5m0s for pod "pod-secrets-487b5506-1dc5-11e9-8130-be6597f3ae53" in namespace "e2e-tests-secrets-4dgq4" to be "success or failure"
Jan 21 21:41:17.360: INFO: Pod "pod-secrets-487b5506-1dc5-11e9-8130-be6597f3ae53": Phase="Pending", Reason="", readiness=false. Elapsed: 11.584621ms
Jan 21 21:41:19.375: INFO: Pod "pod-secrets-487b5506-1dc5-11e9-8130-be6597f3ae53": Phase="Running", Reason="", readiness=true. Elapsed: 2.026848083s
Jan 21 21:41:21.386: INFO: Pod "pod-secrets-487b5506-1dc5-11e9-8130-be6597f3ae53": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.037443991s
STEP: Saw pod success
Jan 21 21:41:21.386: INFO: Pod "pod-secrets-487b5506-1dc5-11e9-8130-be6597f3ae53" satisfied condition "success or failure"
Jan 21 21:41:21.396: INFO: Trying to get logs from node 10.191.28.39 pod pod-secrets-487b5506-1dc5-11e9-8130-be6597f3ae53 container secret-volume-test: <nil>
STEP: delete the pod
Jan 21 21:41:21.450: INFO: Waiting for pod pod-secrets-487b5506-1dc5-11e9-8130-be6597f3ae53 to disappear
Jan 21 21:41:21.503: INFO: Pod pod-secrets-487b5506-1dc5-11e9-8130-be6597f3ae53 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 21:41:21.503: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-4dgq4" for this suite.
Jan 21 21:41:27.550: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 21:41:27.858: INFO: namespace: e2e-tests-secrets-4dgq4, resource: bindings, ignored listing per whitelist
Jan 21 21:41:27.918: INFO: namespace e2e-tests-secrets-4dgq4 deletion completed in 6.401001419s

• [SLOW TEST:10.921 seconds]
[sig-storage] Secrets
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-storage] Projected 
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 21:41:27.921: INFO: >>> kubeConfig: /tmp/kubeconfig-933165938
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-l27hj
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-projected-all-test-volume-4f01ea8a-1dc5-11e9-8130-be6597f3ae53
STEP: Creating secret with name secret-projected-all-test-volume-4f01ea69-1dc5-11e9-8130-be6597f3ae53
STEP: Creating a pod to test Check all projections for projected volume plugin
Jan 21 21:41:28.416: INFO: Waiting up to 5m0s for pod "projected-volume-4f01e382-1dc5-11e9-8130-be6597f3ae53" in namespace "e2e-tests-projected-l27hj" to be "success or failure"
Jan 21 21:41:28.427: INFO: Pod "projected-volume-4f01e382-1dc5-11e9-8130-be6597f3ae53": Phase="Pending", Reason="", readiness=false. Elapsed: 10.535395ms
Jan 21 21:41:30.438: INFO: Pod "projected-volume-4f01e382-1dc5-11e9-8130-be6597f3ae53": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.022394908s
STEP: Saw pod success
Jan 21 21:41:30.439: INFO: Pod "projected-volume-4f01e382-1dc5-11e9-8130-be6597f3ae53" satisfied condition "success or failure"
Jan 21 21:41:30.450: INFO: Trying to get logs from node 10.191.28.59 pod projected-volume-4f01e382-1dc5-11e9-8130-be6597f3ae53 container projected-all-volume-test: <nil>
STEP: delete the pod
Jan 21 21:41:30.509: INFO: Waiting for pod projected-volume-4f01e382-1dc5-11e9-8130-be6597f3ae53 to disappear
Jan 21 21:41:30.518: INFO: Pod projected-volume-4f01e382-1dc5-11e9-8130-be6597f3ae53 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 21:41:30.518: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-l27hj" for this suite.
Jan 21 21:41:36.565: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 21:41:36.876: INFO: namespace: e2e-tests-projected-l27hj, resource: bindings, ignored listing per whitelist
Jan 21 21:41:37.115: INFO: namespace e2e-tests-projected-l27hj deletion completed in 6.583774989s

• [SLOW TEST:9.194 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run rc 
  should create an rc from an image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 21:41:37.116: INFO: >>> kubeConfig: /tmp/kubeconfig-933165938
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-pjfhk
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Kubectl run rc
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1246
[It] should create an rc from an image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Jan 21 21:41:37.940: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-933165938 run e2e-test-nginx-rc --image=docker.io/library/nginx:1.14-alpine --generator=run/v1 --namespace=e2e-tests-kubectl-pjfhk'
Jan 21 21:41:38.393: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl create instead.\n"
Jan 21 21:41:38.393: INFO: stdout: "replicationcontroller/e2e-test-nginx-rc created\n"
STEP: verifying the rc e2e-test-nginx-rc was created
STEP: verifying the pod controlled by rc e2e-test-nginx-rc was created
STEP: confirm that you can get logs from an rc
Jan 21 21:41:38.434: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [e2e-test-nginx-rc-278g2]
Jan 21 21:41:38.434: INFO: Waiting up to 5m0s for pod "e2e-test-nginx-rc-278g2" in namespace "e2e-tests-kubectl-pjfhk" to be "running and ready"
Jan 21 21:41:38.444: INFO: Pod "e2e-test-nginx-rc-278g2": Phase="Pending", Reason="", readiness=false. Elapsed: 9.798453ms
Jan 21 21:41:40.455: INFO: Pod "e2e-test-nginx-rc-278g2": Phase="Running", Reason="", readiness=true. Elapsed: 2.021137876s
Jan 21 21:41:40.455: INFO: Pod "e2e-test-nginx-rc-278g2" satisfied condition "running and ready"
Jan 21 21:41:40.455: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [e2e-test-nginx-rc-278g2]
Jan 21 21:41:40.455: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-933165938 logs rc/e2e-test-nginx-rc --namespace=e2e-tests-kubectl-pjfhk'
Jan 21 21:41:40.677: INFO: stderr: ""
Jan 21 21:41:40.677: INFO: stdout: ""
[AfterEach] [k8s.io] Kubectl run rc
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1251
Jan 21 21:41:40.677: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-933165938 delete rc e2e-test-nginx-rc --namespace=e2e-tests-kubectl-pjfhk'
Jan 21 21:41:40.893: INFO: stderr: ""
Jan 21 21:41:40.893: INFO: stdout: "replicationcontroller \"e2e-test-nginx-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 21:41:40.894: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-pjfhk" for this suite.
Jan 21 21:41:46.945: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 21:41:47.137: INFO: namespace: e2e-tests-kubectl-pjfhk, resource: bindings, ignored listing per whitelist
Jan 21 21:41:47.299: INFO: namespace e2e-tests-kubectl-pjfhk deletion completed in 6.389209812s

• [SLOW TEST:10.184 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run rc
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create an rc from an image  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 21:41:47.300: INFO: >>> kubeConfig: /tmp/kubeconfig-933165938
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-secrets-txxdw
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-5a8ab40c-1dc5-11e9-8130-be6597f3ae53
STEP: Creating a pod to test consume secrets
Jan 21 21:41:47.659: INFO: Waiting up to 5m0s for pod "pod-secrets-5a8c475e-1dc5-11e9-8130-be6597f3ae53" in namespace "e2e-tests-secrets-txxdw" to be "success or failure"
Jan 21 21:41:47.670: INFO: Pod "pod-secrets-5a8c475e-1dc5-11e9-8130-be6597f3ae53": Phase="Pending", Reason="", readiness=false. Elapsed: 10.767118ms
Jan 21 21:41:49.681: INFO: Pod "pod-secrets-5a8c475e-1dc5-11e9-8130-be6597f3ae53": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.021736392s
STEP: Saw pod success
Jan 21 21:41:49.681: INFO: Pod "pod-secrets-5a8c475e-1dc5-11e9-8130-be6597f3ae53" satisfied condition "success or failure"
Jan 21 21:41:49.692: INFO: Trying to get logs from node 10.191.28.59 pod pod-secrets-5a8c475e-1dc5-11e9-8130-be6597f3ae53 container secret-volume-test: <nil>
STEP: delete the pod
Jan 21 21:41:49.792: INFO: Waiting for pod pod-secrets-5a8c475e-1dc5-11e9-8130-be6597f3ae53 to disappear
Jan 21 21:41:49.801: INFO: Pod pod-secrets-5a8c475e-1dc5-11e9-8130-be6597f3ae53 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 21:41:49.801: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-txxdw" for this suite.
Jan 21 21:41:55.847: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 21:41:56.024: INFO: namespace: e2e-tests-secrets-txxdw, resource: bindings, ignored listing per whitelist
Jan 21 21:41:56.191: INFO: namespace e2e-tests-secrets-txxdw deletion completed in 6.375237632s

• [SLOW TEST:8.891 seconds]
[sig-storage] Secrets
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] Projected 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 21:41:56.192: INFO: >>> kubeConfig: /tmp/kubeconfig-933165938
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-svgwn
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Jan 21 21:41:56.546: INFO: Waiting up to 5m0s for pod "downwardapi-volume-5fd86520-1dc5-11e9-8130-be6597f3ae53" in namespace "e2e-tests-projected-svgwn" to be "success or failure"
Jan 21 21:41:56.559: INFO: Pod "downwardapi-volume-5fd86520-1dc5-11e9-8130-be6597f3ae53": Phase="Pending", Reason="", readiness=false. Elapsed: 11.810843ms
Jan 21 21:41:58.570: INFO: Pod "downwardapi-volume-5fd86520-1dc5-11e9-8130-be6597f3ae53": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.023052553s
STEP: Saw pod success
Jan 21 21:41:58.570: INFO: Pod "downwardapi-volume-5fd86520-1dc5-11e9-8130-be6597f3ae53" satisfied condition "success or failure"
Jan 21 21:41:58.580: INFO: Trying to get logs from node 10.191.28.59 pod downwardapi-volume-5fd86520-1dc5-11e9-8130-be6597f3ae53 container client-container: <nil>
STEP: delete the pod
Jan 21 21:41:58.635: INFO: Waiting for pod downwardapi-volume-5fd86520-1dc5-11e9-8130-be6597f3ae53 to disappear
Jan 21 21:41:58.645: INFO: Pod downwardapi-volume-5fd86520-1dc5-11e9-8130-be6597f3ae53 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 21:41:58.645: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-svgwn" for this suite.
Jan 21 21:42:04.698: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 21:42:04.963: INFO: namespace: e2e-tests-projected-svgwn, resource: bindings, ignored listing per whitelist
Jan 21 21:42:05.122: INFO: namespace e2e-tests-projected-svgwn deletion completed in 6.464039951s

• [SLOW TEST:8.931 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-cli] Kubectl client [k8s.io] Proxy server 
  should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 21:42:05.123: INFO: >>> kubeConfig: /tmp/kubeconfig-933165938
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-gjvdm
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Starting the proxy
Jan 21 21:42:05.564: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-933165938 proxy --unix-socket=/tmp/kubectl-proxy-unix663788585/test'
STEP: retrieving proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 21:42:05.677: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-gjvdm" for this suite.
Jan 21 21:42:11.780: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 21:42:12.196: INFO: namespace: e2e-tests-kubectl-gjvdm, resource: bindings, ignored listing per whitelist
Jan 21 21:42:12.227: INFO: namespace e2e-tests-kubectl-gjvdm deletion completed in 6.536560911s

• [SLOW TEST:7.105 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Proxy server
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should support --unix-socket=/path  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 21:42:12.228: INFO: >>> kubeConfig: /tmp/kubeconfig-933165938
STEP: Building a namespace api object, basename pod-network-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-pod-network-test-mh79n
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-mh79n
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Jan 21 21:42:12.577: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Jan 21 21:42:34.937: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://172.30.156.169:8080/dial?request=hostName&protocol=http&host=172.30.156.167&port=8080&tries=1'] Namespace:e2e-tests-pod-network-test-mh79n PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jan 21 21:42:34.937: INFO: >>> kubeConfig: /tmp/kubeconfig-933165938
Jan 21 21:42:35.141: INFO: Waiting for endpoints: map[]
Jan 21 21:42:35.154: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://172.30.156.169:8080/dial?request=hostName&protocol=http&host=172.30.41.19&port=8080&tries=1'] Namespace:e2e-tests-pod-network-test-mh79n PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jan 21 21:42:35.154: INFO: >>> kubeConfig: /tmp/kubeconfig-933165938
Jan 21 21:42:35.361: INFO: Waiting for endpoints: map[]
Jan 21 21:42:35.373: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://172.30.156.169:8080/dial?request=hostName&protocol=http&host=172.30.216.24&port=8080&tries=1'] Namespace:e2e-tests-pod-network-test-mh79n PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jan 21 21:42:35.373: INFO: >>> kubeConfig: /tmp/kubeconfig-933165938
Jan 21 21:42:35.597: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 21:42:35.597: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-mh79n" for this suite.
Jan 21 21:42:59.647: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 21:42:59.711: INFO: namespace: e2e-tests-pod-network-test-mh79n, resource: bindings, ignored listing per whitelist
Jan 21 21:43:00.148: INFO: namespace e2e-tests-pod-network-test-mh79n deletion completed in 24.536805245s

• [SLOW TEST:47.920 seconds]
[sig-network] Networking
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: http [NodeConformance] [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 21:43:00.149: INFO: >>> kubeConfig: /tmp/kubeconfig-933165938
STEP: Building a namespace api object, basename containers
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-containers-jxjtq
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test override command
Jan 21 21:43:00.482: INFO: Waiting up to 5m0s for pod "client-containers-85f3e4cd-1dc5-11e9-8130-be6597f3ae53" in namespace "e2e-tests-containers-jxjtq" to be "success or failure"
Jan 21 21:43:00.495: INFO: Pod "client-containers-85f3e4cd-1dc5-11e9-8130-be6597f3ae53": Phase="Pending", Reason="", readiness=false. Elapsed: 12.446259ms
Jan 21 21:43:02.507: INFO: Pod "client-containers-85f3e4cd-1dc5-11e9-8130-be6597f3ae53": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.02414978s
STEP: Saw pod success
Jan 21 21:43:02.507: INFO: Pod "client-containers-85f3e4cd-1dc5-11e9-8130-be6597f3ae53" satisfied condition "success or failure"
Jan 21 21:43:02.518: INFO: Trying to get logs from node 10.191.28.59 pod client-containers-85f3e4cd-1dc5-11e9-8130-be6597f3ae53 container test-container: <nil>
STEP: delete the pod
Jan 21 21:43:02.575: INFO: Waiting for pod client-containers-85f3e4cd-1dc5-11e9-8130-be6597f3ae53 to disappear
Jan 21 21:43:02.584: INFO: Pod client-containers-85f3e4cd-1dc5-11e9-8130-be6597f3ae53 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 21:43:02.585: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-jxjtq" for this suite.
Jan 21 21:43:08.634: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 21:43:08.724: INFO: namespace: e2e-tests-containers-jxjtq, resource: bindings, ignored listing per whitelist
Jan 21 21:43:08.984: INFO: namespace e2e-tests-containers-jxjtq deletion completed in 6.38542166s

• [SLOW TEST:8.835 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 21:43:08.984: INFO: >>> kubeConfig: /tmp/kubeconfig-933165938
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-z6xq4
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Jan 21 21:43:09.472: INFO: Waiting up to 5m0s for pod "downwardapi-volume-8b4fa8c5-1dc5-11e9-8130-be6597f3ae53" in namespace "e2e-tests-downward-api-z6xq4" to be "success or failure"
Jan 21 21:43:09.484: INFO: Pod "downwardapi-volume-8b4fa8c5-1dc5-11e9-8130-be6597f3ae53": Phase="Pending", Reason="", readiness=false. Elapsed: 11.477114ms
Jan 21 21:43:11.705: INFO: Pod "downwardapi-volume-8b4fa8c5-1dc5-11e9-8130-be6597f3ae53": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.233006726s
STEP: Saw pod success
Jan 21 21:43:11.706: INFO: Pod "downwardapi-volume-8b4fa8c5-1dc5-11e9-8130-be6597f3ae53" satisfied condition "success or failure"
Jan 21 21:43:11.740: INFO: Trying to get logs from node 10.191.28.59 pod downwardapi-volume-8b4fa8c5-1dc5-11e9-8130-be6597f3ae53 container client-container: <nil>
STEP: delete the pod
Jan 21 21:43:11.799: INFO: Waiting for pod downwardapi-volume-8b4fa8c5-1dc5-11e9-8130-be6597f3ae53 to disappear
Jan 21 21:43:11.809: INFO: Pod downwardapi-volume-8b4fa8c5-1dc5-11e9-8130-be6597f3ae53 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 21:43:11.809: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-z6xq4" for this suite.
Jan 21 21:43:17.866: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 21:43:18.157: INFO: namespace: e2e-tests-downward-api-z6xq4, resource: bindings, ignored listing per whitelist
Jan 21 21:43:18.347: INFO: namespace e2e-tests-downward-api-z6xq4 deletion completed in 6.518208777s

• [SLOW TEST:9.363 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Projected 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 21:43:18.348: INFO: >>> kubeConfig: /tmp/kubeconfig-933165938
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-mvw25
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Jan 21 21:43:18.699: INFO: Waiting up to 5m0s for pod "downwardapi-volume-90cfe8f6-1dc5-11e9-8130-be6597f3ae53" in namespace "e2e-tests-projected-mvw25" to be "success or failure"
Jan 21 21:43:18.714: INFO: Pod "downwardapi-volume-90cfe8f6-1dc5-11e9-8130-be6597f3ae53": Phase="Pending", Reason="", readiness=false. Elapsed: 14.255752ms
Jan 21 21:43:20.725: INFO: Pod "downwardapi-volume-90cfe8f6-1dc5-11e9-8130-be6597f3ae53": Phase="Pending", Reason="", readiness=false. Elapsed: 2.025153355s
Jan 21 21:43:22.736: INFO: Pod "downwardapi-volume-90cfe8f6-1dc5-11e9-8130-be6597f3ae53": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.036285611s
STEP: Saw pod success
Jan 21 21:43:22.736: INFO: Pod "downwardapi-volume-90cfe8f6-1dc5-11e9-8130-be6597f3ae53" satisfied condition "success or failure"
Jan 21 21:43:22.746: INFO: Trying to get logs from node 10.191.28.59 pod downwardapi-volume-90cfe8f6-1dc5-11e9-8130-be6597f3ae53 container client-container: <nil>
STEP: delete the pod
Jan 21 21:43:22.804: INFO: Waiting for pod downwardapi-volume-90cfe8f6-1dc5-11e9-8130-be6597f3ae53 to disappear
Jan 21 21:43:22.814: INFO: Pod downwardapi-volume-90cfe8f6-1dc5-11e9-8130-be6597f3ae53 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 21:43:22.815: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-mvw25" for this suite.
Jan 21 21:43:28.868: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 21:43:29.143: INFO: namespace: e2e-tests-projected-mvw25, resource: bindings, ignored listing per whitelist
Jan 21 21:43:29.398: INFO: namespace e2e-tests-projected-mvw25 deletion completed in 6.569515425s

• [SLOW TEST:11.050 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 21:43:29.401: INFO: >>> kubeConfig: /tmp/kubeconfig-933165938
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-qq88p
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0666 on tmpfs
Jan 21 21:43:29.736: INFO: Waiting up to 5m0s for pod "pod-9764198e-1dc5-11e9-8130-be6597f3ae53" in namespace "e2e-tests-emptydir-qq88p" to be "success or failure"
Jan 21 21:43:29.747: INFO: Pod "pod-9764198e-1dc5-11e9-8130-be6597f3ae53": Phase="Pending", Reason="", readiness=false. Elapsed: 10.358374ms
Jan 21 21:43:31.759: INFO: Pod "pod-9764198e-1dc5-11e9-8130-be6597f3ae53": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.022289117s
STEP: Saw pod success
Jan 21 21:43:31.759: INFO: Pod "pod-9764198e-1dc5-11e9-8130-be6597f3ae53" satisfied condition "success or failure"
Jan 21 21:43:31.769: INFO: Trying to get logs from node 10.191.28.39 pod pod-9764198e-1dc5-11e9-8130-be6597f3ae53 container test-container: <nil>
STEP: delete the pod
Jan 21 21:43:31.864: INFO: Waiting for pod pod-9764198e-1dc5-11e9-8130-be6597f3ae53 to disappear
Jan 21 21:43:31.874: INFO: Pod pod-9764198e-1dc5-11e9-8130-be6597f3ae53 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 21:43:31.875: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-qq88p" for this suite.
Jan 21 21:43:37.926: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 21:43:38.075: INFO: namespace: e2e-tests-emptydir-qq88p, resource: bindings, ignored listing per whitelist
Jan 21 21:43:38.304: INFO: namespace e2e-tests-emptydir-qq88p deletion completed in 6.416589706s

• [SLOW TEST:8.904 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 21:43:38.305: INFO: >>> kubeConfig: /tmp/kubeconfig-933165938
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-dns-7fd8q
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(dig +notcp +noall +answer +search kubernetes.default A)" && echo OK > /results/wheezy_udp@kubernetes.default;test -n "$$(dig +tcp +noall +answer +search kubernetes.default A)" && echo OK > /results/wheezy_tcp@kubernetes.default;test -n "$$(dig +notcp +noall +answer +search kubernetes.default.svc A)" && echo OK > /results/wheezy_udp@kubernetes.default.svc;test -n "$$(dig +tcp +noall +answer +search kubernetes.default.svc A)" && echo OK > /results/wheezy_tcp@kubernetes.default.svc;test -n "$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && echo OK > /results/wheezy_udp@kubernetes.default.svc.cluster.local;test -n "$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && echo OK > /results/wheezy_tcp@kubernetes.default.svc.cluster.local;test -n "$$(getent hosts dns-querier-1.dns-test-service.e2e-tests-dns-7fd8q.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-1.dns-test-service.e2e-tests-dns-7fd8q.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/wheezy_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-7fd8q.pod.cluster.local"}');test -n "$$(dig +notcp +noall +answer +search $${podARec} A)" && echo OK > /results/wheezy_udp@PodARecord;test -n "$$(dig +tcp +noall +answer +search $${podARec} A)" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(dig +notcp +noall +answer +search kubernetes.default A)" && echo OK > /results/jessie_udp@kubernetes.default;test -n "$$(dig +tcp +noall +answer +search kubernetes.default A)" && echo OK > /results/jessie_tcp@kubernetes.default;test -n "$$(dig +notcp +noall +answer +search kubernetes.default.svc A)" && echo OK > /results/jessie_udp@kubernetes.default.svc;test -n "$$(dig +tcp +noall +answer +search kubernetes.default.svc A)" && echo OK > /results/jessie_tcp@kubernetes.default.svc;test -n "$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && echo OK > /results/jessie_udp@kubernetes.default.svc.cluster.local;test -n "$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && echo OK > /results/jessie_tcp@kubernetes.default.svc.cluster.local;test -n "$$(getent hosts dns-querier-1.dns-test-service.e2e-tests-dns-7fd8q.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-1.dns-test-service.e2e-tests-dns-7fd8q.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/jessie_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-7fd8q.pod.cluster.local"}');test -n "$$(dig +notcp +noall +answer +search $${podARec} A)" && echo OK > /results/jessie_udp@PodARecord;test -n "$$(dig +tcp +noall +answer +search $${podARec} A)" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Jan 21 21:44:05.117: INFO: DNS probes using e2e-tests-dns-7fd8q/dns-test-9cb94e9d-1dc5-11e9-8130-be6597f3ae53 succeeded

STEP: deleting the pod
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 21:44:05.156: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-dns-7fd8q" for this suite.
Jan 21 21:44:11.212: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 21:44:11.362: INFO: namespace: e2e-tests-dns-7fd8q, resource: bindings, ignored listing per whitelist
Jan 21 21:44:11.595: INFO: namespace e2e-tests-dns-7fd8q deletion completed in 6.424690029s

• [SLOW TEST:33.290 seconds]
[sig-network] DNS
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 21:44:11.597: INFO: >>> kubeConfig: /tmp/kubeconfig-933165938
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-secrets-mgjl5
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-b08c72d6-1dc5-11e9-8130-be6597f3ae53
STEP: Creating a pod to test consume secrets
Jan 21 21:44:11.957: INFO: Waiting up to 5m0s for pod "pod-secrets-b08e27c1-1dc5-11e9-8130-be6597f3ae53" in namespace "e2e-tests-secrets-mgjl5" to be "success or failure"
Jan 21 21:44:11.980: INFO: Pod "pod-secrets-b08e27c1-1dc5-11e9-8130-be6597f3ae53": Phase="Pending", Reason="", readiness=false. Elapsed: 23.058745ms
Jan 21 21:44:13.992: INFO: Pod "pod-secrets-b08e27c1-1dc5-11e9-8130-be6597f3ae53": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.034363517s
STEP: Saw pod success
Jan 21 21:44:13.992: INFO: Pod "pod-secrets-b08e27c1-1dc5-11e9-8130-be6597f3ae53" satisfied condition "success or failure"
Jan 21 21:44:14.002: INFO: Trying to get logs from node 10.191.28.39 pod pod-secrets-b08e27c1-1dc5-11e9-8130-be6597f3ae53 container secret-volume-test: <nil>
STEP: delete the pod
Jan 21 21:44:14.065: INFO: Waiting for pod pod-secrets-b08e27c1-1dc5-11e9-8130-be6597f3ae53 to disappear
Jan 21 21:44:14.075: INFO: Pod pod-secrets-b08e27c1-1dc5-11e9-8130-be6597f3ae53 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 21:44:14.075: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-mgjl5" for this suite.
Jan 21 21:44:20.127: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 21:44:20.483: INFO: namespace: e2e-tests-secrets-mgjl5, resource: bindings, ignored listing per whitelist
Jan 21 21:44:20.588: INFO: namespace e2e-tests-secrets-mgjl5 deletion completed in 6.499481971s

• [SLOW TEST:8.991 seconds]
[sig-storage] Secrets
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[k8s.io] Pods 
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 21:44:20.589: INFO: >>> kubeConfig: /tmp/kubeconfig-933165938
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-pods-7rwm4
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Jan 21 21:44:23.501: INFO: Successfully updated pod "pod-update-activedeadlineseconds-b5e7ab5e-1dc5-11e9-8130-be6597f3ae53"
Jan 21 21:44:23.501: INFO: Waiting up to 5m0s for pod "pod-update-activedeadlineseconds-b5e7ab5e-1dc5-11e9-8130-be6597f3ae53" in namespace "e2e-tests-pods-7rwm4" to be "terminated due to deadline exceeded"
Jan 21 21:44:23.511: INFO: Pod "pod-update-activedeadlineseconds-b5e7ab5e-1dc5-11e9-8130-be6597f3ae53": Phase="Running", Reason="", readiness=true. Elapsed: 9.573472ms
Jan 21 21:44:25.522: INFO: Pod "pod-update-activedeadlineseconds-b5e7ab5e-1dc5-11e9-8130-be6597f3ae53": Phase="Running", Reason="", readiness=true. Elapsed: 2.021062518s
Jan 21 21:44:27.534: INFO: Pod "pod-update-activedeadlineseconds-b5e7ab5e-1dc5-11e9-8130-be6597f3ae53": Phase="Failed", Reason="DeadlineExceeded", readiness=false. Elapsed: 4.032755456s
Jan 21 21:44:27.534: INFO: Pod "pod-update-activedeadlineseconds-b5e7ab5e-1dc5-11e9-8130-be6597f3ae53" satisfied condition "terminated due to deadline exceeded"
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 21:44:27.534: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-7rwm4" for this suite.
Jan 21 21:44:33.614: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 21:44:33.753: INFO: namespace: e2e-tests-pods-7rwm4, resource: bindings, ignored listing per whitelist
Jan 21 21:44:34.010: INFO: namespace e2e-tests-pods-7rwm4 deletion completed in 6.457966342s

• [SLOW TEST:13.421 seconds]
[k8s.io] Pods
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 21:44:34.012: INFO: >>> kubeConfig: /tmp/kubeconfig-933165938
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-fln9k
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0666 on node default medium
Jan 21 21:44:34.383: INFO: Waiting up to 5m0s for pod "pod-bdebfbdc-1dc5-11e9-8130-be6597f3ae53" in namespace "e2e-tests-emptydir-fln9k" to be "success or failure"
Jan 21 21:44:34.392: INFO: Pod "pod-bdebfbdc-1dc5-11e9-8130-be6597f3ae53": Phase="Pending", Reason="", readiness=false. Elapsed: 9.829571ms
Jan 21 21:44:36.405: INFO: Pod "pod-bdebfbdc-1dc5-11e9-8130-be6597f3ae53": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.022672222s
STEP: Saw pod success
Jan 21 21:44:36.405: INFO: Pod "pod-bdebfbdc-1dc5-11e9-8130-be6597f3ae53" satisfied condition "success or failure"
Jan 21 21:44:36.416: INFO: Trying to get logs from node 10.191.28.39 pod pod-bdebfbdc-1dc5-11e9-8130-be6597f3ae53 container test-container: <nil>
STEP: delete the pod
Jan 21 21:44:36.481: INFO: Waiting for pod pod-bdebfbdc-1dc5-11e9-8130-be6597f3ae53 to disappear
Jan 21 21:44:36.491: INFO: Pod pod-bdebfbdc-1dc5-11e9-8130-be6597f3ae53 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 21:44:36.491: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-fln9k" for this suite.
Jan 21 21:44:42.541: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 21:44:42.620: INFO: namespace: e2e-tests-emptydir-fln9k, resource: bindings, ignored listing per whitelist
Jan 21 21:44:42.948: INFO: namespace e2e-tests-emptydir-fln9k deletion completed in 6.440312465s

• [SLOW TEST:8.936 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Downward API 
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 21:44:42.951: INFO: >>> kubeConfig: /tmp/kubeconfig-933165938
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-nrjvd
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Jan 21 21:44:43.283: INFO: Waiting up to 5m0s for pod "downward-api-c339dc6e-1dc5-11e9-8130-be6597f3ae53" in namespace "e2e-tests-downward-api-nrjvd" to be "success or failure"
Jan 21 21:44:43.296: INFO: Pod "downward-api-c339dc6e-1dc5-11e9-8130-be6597f3ae53": Phase="Pending", Reason="", readiness=false. Elapsed: 12.561157ms
Jan 21 21:44:45.306: INFO: Pod "downward-api-c339dc6e-1dc5-11e9-8130-be6597f3ae53": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.023298744s
STEP: Saw pod success
Jan 21 21:44:45.307: INFO: Pod "downward-api-c339dc6e-1dc5-11e9-8130-be6597f3ae53" satisfied condition "success or failure"
Jan 21 21:44:45.317: INFO: Trying to get logs from node 10.191.28.59 pod downward-api-c339dc6e-1dc5-11e9-8130-be6597f3ae53 container dapi-container: <nil>
STEP: delete the pod
Jan 21 21:44:45.382: INFO: Waiting for pod downward-api-c339dc6e-1dc5-11e9-8130-be6597f3ae53 to disappear
Jan 21 21:44:45.395: INFO: Pod downward-api-c339dc6e-1dc5-11e9-8130-be6597f3ae53 no longer exists
[AfterEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 21:44:45.395: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-nrjvd" for this suite.
Jan 21 21:44:51.445: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 21:44:51.644: INFO: namespace: e2e-tests-downward-api-nrjvd, resource: bindings, ignored listing per whitelist
Jan 21 21:44:51.839: INFO: namespace e2e-tests-downward-api-nrjvd deletion completed in 6.429686511s

• [SLOW TEST:8.889 seconds]
[sig-api-machinery] Downward API
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 21:44:51.841: INFO: >>> kubeConfig: /tmp/kubeconfig-933165938
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-jnj64
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-c89a8e68-1dc5-11e9-8130-be6597f3ae53
STEP: Creating a pod to test consume secrets
Jan 21 21:44:52.312: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-c89c21f3-1dc5-11e9-8130-be6597f3ae53" in namespace "e2e-tests-projected-jnj64" to be "success or failure"
Jan 21 21:44:52.326: INFO: Pod "pod-projected-secrets-c89c21f3-1dc5-11e9-8130-be6597f3ae53": Phase="Pending", Reason="", readiness=false. Elapsed: 13.538055ms
Jan 21 21:44:54.337: INFO: Pod "pod-projected-secrets-c89c21f3-1dc5-11e9-8130-be6597f3ae53": Phase="Pending", Reason="", readiness=false. Elapsed: 2.024490029s
Jan 21 21:44:56.349: INFO: Pod "pod-projected-secrets-c89c21f3-1dc5-11e9-8130-be6597f3ae53": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.036423234s
STEP: Saw pod success
Jan 21 21:44:56.349: INFO: Pod "pod-projected-secrets-c89c21f3-1dc5-11e9-8130-be6597f3ae53" satisfied condition "success or failure"
Jan 21 21:44:56.359: INFO: Trying to get logs from node 10.191.28.39 pod pod-projected-secrets-c89c21f3-1dc5-11e9-8130-be6597f3ae53 container projected-secret-volume-test: <nil>
STEP: delete the pod
Jan 21 21:44:56.464: INFO: Waiting for pod pod-projected-secrets-c89c21f3-1dc5-11e9-8130-be6597f3ae53 to disappear
Jan 21 21:44:56.475: INFO: Pod pod-projected-secrets-c89c21f3-1dc5-11e9-8130-be6597f3ae53 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 21:44:56.475: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-jnj64" for this suite.
Jan 21 21:45:02.530: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 21:45:02.953: INFO: namespace: e2e-tests-projected-jnj64, resource: bindings, ignored listing per whitelist
Jan 21 21:45:03.030: INFO: namespace e2e-tests-projected-jnj64 deletion completed in 6.540715137s

• [SLOW TEST:11.189 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl version 
  should check is all data is printed  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 21:45:03.033: INFO: >>> kubeConfig: /tmp/kubeconfig-933165938
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-9rvkz
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should check is all data is printed  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Jan 21 21:45:03.355: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-933165938 version'
Jan 21 21:45:03.571: INFO: stderr: ""
Jan 21 21:45:03.571: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"12\", GitVersion:\"v1.12.1\", GitCommit:\"4ed3216f3ec431b140b1d899130a69fc671678f4\", GitTreeState:\"clean\", BuildDate:\"2018-10-05T16:46:06Z\", GoVersion:\"go1.10.4\", Compiler:\"gc\", Platform:\"linux/amd64\"}\nServer Version: version.Info{Major:\"1\", Minor:\"12\", GitVersion:\"v1.12.4+IKS\", GitCommit:\"27c949c1ae36d3c99246bde7ef68ff8bd3bb4ad3\", GitTreeState:\"clean\", BuildDate:\"2019-01-09T10:08:47Z\", GoVersion:\"go1.10.4\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 21:45:03.571: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-9rvkz" for this suite.
Jan 21 21:45:09.619: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 21:45:09.730: INFO: namespace: e2e-tests-kubectl-9rvkz, resource: bindings, ignored listing per whitelist
Jan 21 21:45:10.008: INFO: namespace e2e-tests-kubectl-9rvkz deletion completed in 6.423054029s

• [SLOW TEST:6.975 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl version
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should check is all data is printed  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 21:45:10.010: INFO: >>> kubeConfig: /tmp/kubeconfig-933165938
STEP: Building a namespace api object, basename init-container
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-init-container-qnrt9
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
Jan 21 21:45:10.378: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 21:45:14.292: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-init-container-qnrt9" for this suite.
Jan 21 21:45:38.400: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 21:45:38.629: INFO: namespace: e2e-tests-init-container-qnrt9, resource: bindings, ignored listing per whitelist
Jan 21 21:45:38.791: INFO: namespace e2e-tests-init-container-qnrt9 deletion completed in 24.426029318s

• [SLOW TEST:28.781 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 21:45:38.792: INFO: >>> kubeConfig: /tmp/kubeconfig-933165938
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-statefulset-zsbr6
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-zsbr6
[It] Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Looking for a node to schedule stateful set and pod
STEP: Creating pod with conflicting port in namespace e2e-tests-statefulset-zsbr6
STEP: Creating statefulset with conflicting port in namespace e2e-tests-statefulset-zsbr6
STEP: Waiting until pod test-pod will start running in namespace e2e-tests-statefulset-zsbr6
STEP: Waiting until stateful pod ss-0 will be recreated and deleted at least once in namespace e2e-tests-statefulset-zsbr6
Jan 21 21:45:41.287: INFO: Observed stateful pod in namespace: e2e-tests-statefulset-zsbr6, name: ss-0, uid: e4a7c27d-1dc5-11e9-903f-ee5d7ad9296f, status phase: Pending. Waiting for statefulset controller to delete.
Jan 21 21:45:45.642: INFO: Observed stateful pod in namespace: e2e-tests-statefulset-zsbr6, name: ss-0, uid: e4a7c27d-1dc5-11e9-903f-ee5d7ad9296f, status phase: Failed. Waiting for statefulset controller to delete.
Jan 21 21:45:45.658: INFO: Observed stateful pod in namespace: e2e-tests-statefulset-zsbr6, name: ss-0, uid: e4a7c27d-1dc5-11e9-903f-ee5d7ad9296f, status phase: Failed. Waiting for statefulset controller to delete.
Jan 21 21:45:45.671: INFO: Observed delete event for stateful pod ss-0 in namespace e2e-tests-statefulset-zsbr6
STEP: Removing pod with conflicting port in namespace e2e-tests-statefulset-zsbr6
STEP: Waiting when stateful pod ss-0 will be recreated in namespace e2e-tests-statefulset-zsbr6 and will be in running state
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Jan 21 21:45:55.774: INFO: Deleting all statefulset in ns e2e-tests-statefulset-zsbr6
Jan 21 21:45:55.784: INFO: Scaling statefulset ss to 0
Jan 21 21:46:05.912: INFO: Waiting for statefulset status.replicas updated to 0
Jan 21 21:46:05.924: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 21:46:05.968: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-zsbr6" for this suite.
Jan 21 21:46:12.022: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 21:46:12.237: INFO: namespace: e2e-tests-statefulset-zsbr6, resource: bindings, ignored listing per whitelist
Jan 21 21:46:12.486: INFO: namespace e2e-tests-statefulset-zsbr6 deletion completed in 6.504085648s

• [SLOW TEST:33.694 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    Should recreate evicted statefulset [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 21:46:12.488: INFO: >>> kubeConfig: /tmp/kubeconfig-933165938
STEP: Building a namespace api object, basename namespaces
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-namespaces-pltlx
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a test namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-nsdeletetest-7j8s8
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a service in the namespace
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-nsdeletetest-qfvz4
STEP: Verifying there is no service in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 21:46:19.365: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-namespaces-pltlx" for this suite.
Jan 21 21:46:25.480: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 21:46:25.680: INFO: namespace: e2e-tests-namespaces-pltlx, resource: bindings, ignored listing per whitelist
Jan 21 21:46:25.862: INFO: namespace e2e-tests-namespaces-pltlx deletion completed in 6.482104926s
STEP: Destroying namespace "e2e-tests-nsdeletetest-7j8s8" for this suite.
Jan 21 21:46:25.871: INFO: Namespace e2e-tests-nsdeletetest-7j8s8 was already deleted
STEP: Destroying namespace "e2e-tests-nsdeletetest-qfvz4" for this suite.
Jan 21 21:46:31.908: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 21:46:32.093: INFO: namespace: e2e-tests-nsdeletetest-qfvz4, resource: bindings, ignored listing per whitelist
Jan 21 21:46:32.391: INFO: namespace e2e-tests-nsdeletetest-qfvz4 deletion completed in 6.519769463s

• [SLOW TEST:19.903 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-network] Services 
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 21:46:32.391: INFO: >>> kubeConfig: /tmp/kubeconfig-933165938
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-services-8fj8x
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:83
[It] should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating service multi-endpoint-test in namespace e2e-tests-services-8fj8x
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-8fj8x to expose endpoints map[]
Jan 21 21:46:32.765: INFO: Get endpoints failed (9.427864ms elapsed, ignoring for 5s): endpoints "multi-endpoint-test" not found
Jan 21 21:46:33.774: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-8fj8x exposes endpoints map[] (1.018276635s elapsed)
STEP: Creating pod pod1 in namespace e2e-tests-services-8fj8x
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-8fj8x to expose endpoints map[pod1:[100]]
Jan 21 21:46:35.919: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-8fj8x exposes endpoints map[pod1:[100]] (2.123919575s elapsed)
STEP: Creating pod pod2 in namespace e2e-tests-services-8fj8x
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-8fj8x to expose endpoints map[pod1:[100] pod2:[101]]
Jan 21 21:46:38.023: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-8fj8x exposes endpoints map[pod1:[100] pod2:[101]] (2.08995314s elapsed)
STEP: Deleting pod pod1 in namespace e2e-tests-services-8fj8x
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-8fj8x to expose endpoints map[pod2:[101]]
Jan 21 21:46:38.076: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-8fj8x exposes endpoints map[pod2:[101]] (31.411321ms elapsed)
STEP: Deleting pod pod2 in namespace e2e-tests-services-8fj8x
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-8fj8x to expose endpoints map[]
Jan 21 21:46:38.104: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-8fj8x exposes endpoints map[] (7.279751ms elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 21:46:38.149: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-services-8fj8x" for this suite.
Jan 21 21:47:02.199: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 21:47:02.313: INFO: namespace: e2e-tests-services-8fj8x, resource: bindings, ignored listing per whitelist
Jan 21 21:47:02.602: INFO: namespace e2e-tests-services-8fj8x deletion completed in 24.437155612s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:88

• [SLOW TEST:30.211 seconds]
[sig-network] Services
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 21:47:02.603: INFO: >>> kubeConfig: /tmp/kubeconfig-933165938
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-6xd8f
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0777 on node default medium
Jan 21 21:47:02.981: INFO: Waiting up to 5m0s for pod "pod-167e4ef5-1dc6-11e9-8130-be6597f3ae53" in namespace "e2e-tests-emptydir-6xd8f" to be "success or failure"
Jan 21 21:47:02.992: INFO: Pod "pod-167e4ef5-1dc6-11e9-8130-be6597f3ae53": Phase="Pending", Reason="", readiness=false. Elapsed: 11.555313ms
Jan 21 21:47:05.003: INFO: Pod "pod-167e4ef5-1dc6-11e9-8130-be6597f3ae53": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.022428521s
STEP: Saw pod success
Jan 21 21:47:05.003: INFO: Pod "pod-167e4ef5-1dc6-11e9-8130-be6597f3ae53" satisfied condition "success or failure"
Jan 21 21:47:05.015: INFO: Trying to get logs from node 10.191.28.39 pod pod-167e4ef5-1dc6-11e9-8130-be6597f3ae53 container test-container: <nil>
STEP: delete the pod
Jan 21 21:47:05.079: INFO: Waiting for pod pod-167e4ef5-1dc6-11e9-8130-be6597f3ae53 to disappear
Jan 21 21:47:05.090: INFO: Pod pod-167e4ef5-1dc6-11e9-8130-be6597f3ae53 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 21:47:05.090: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-6xd8f" for this suite.
Jan 21 21:47:11.145: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 21:47:11.347: INFO: namespace: e2e-tests-emptydir-6xd8f, resource: bindings, ignored listing per whitelist
Jan 21 21:47:11.514: INFO: namespace e2e-tests-emptydir-6xd8f deletion completed in 6.410082761s

• [SLOW TEST:8.912 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-network] DNS 
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 21:47:11.515: INFO: >>> kubeConfig: /tmp/kubeconfig-933165938
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-dns-xfgfs
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for services  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(dig +notcp +noall +answer +search dns-test-service A)" && echo OK > /results/wheezy_udp@dns-test-service;test -n "$$(dig +tcp +noall +answer +search dns-test-service A)" && echo OK > /results/wheezy_tcp@dns-test-service;test -n "$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-xfgfs A)" && echo OK > /results/wheezy_udp@dns-test-service.e2e-tests-dns-xfgfs;test -n "$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-xfgfs A)" && echo OK > /results/wheezy_tcp@dns-test-service.e2e-tests-dns-xfgfs;test -n "$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-xfgfs.svc A)" && echo OK > /results/wheezy_udp@dns-test-service.e2e-tests-dns-xfgfs.svc;test -n "$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-xfgfs.svc A)" && echo OK > /results/wheezy_tcp@dns-test-service.e2e-tests-dns-xfgfs.svc;test -n "$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-xfgfs.svc SRV)" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.e2e-tests-dns-xfgfs.svc;test -n "$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-xfgfs.svc SRV)" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.e2e-tests-dns-xfgfs.svc;test -n "$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-xfgfs.svc SRV)" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.e2e-tests-dns-xfgfs.svc;test -n "$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-xfgfs.svc SRV)" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.e2e-tests-dns-xfgfs.svc;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-xfgfs.pod.cluster.local"}');test -n "$$(dig +notcp +noall +answer +search $${podARec} A)" && echo OK > /results/wheezy_udp@PodARecord;test -n "$$(dig +tcp +noall +answer +search $${podARec} A)" && echo OK > /results/wheezy_tcp@PodARecord;test -n "$$(dig +notcp +noall +answer +search 50.136.21.172.in-addr.arpa. PTR)" && echo OK > /results/172.21.136.50_udp@PTR;test -n "$$(dig +tcp +noall +answer +search 50.136.21.172.in-addr.arpa. PTR)" && echo OK > /results/172.21.136.50_tcp@PTR;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(dig +notcp +noall +answer +search dns-test-service A)" && echo OK > /results/jessie_udp@dns-test-service;test -n "$$(dig +tcp +noall +answer +search dns-test-service A)" && echo OK > /results/jessie_tcp@dns-test-service;test -n "$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-xfgfs A)" && echo OK > /results/jessie_udp@dns-test-service.e2e-tests-dns-xfgfs;test -n "$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-xfgfs A)" && echo OK > /results/jessie_tcp@dns-test-service.e2e-tests-dns-xfgfs;test -n "$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-xfgfs.svc A)" && echo OK > /results/jessie_udp@dns-test-service.e2e-tests-dns-xfgfs.svc;test -n "$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-xfgfs.svc A)" && echo OK > /results/jessie_tcp@dns-test-service.e2e-tests-dns-xfgfs.svc;test -n "$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-xfgfs.svc SRV)" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-xfgfs.svc;test -n "$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-xfgfs.svc SRV)" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-xfgfs.svc;test -n "$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-xfgfs.svc SRV)" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.e2e-tests-dns-xfgfs.svc;test -n "$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-xfgfs.svc SRV)" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.e2e-tests-dns-xfgfs.svc;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-xfgfs.pod.cluster.local"}');test -n "$$(dig +notcp +noall +answer +search $${podARec} A)" && echo OK > /results/jessie_udp@PodARecord;test -n "$$(dig +tcp +noall +answer +search $${podARec} A)" && echo OK > /results/jessie_tcp@PodARecord;test -n "$$(dig +notcp +noall +answer +search 50.136.21.172.in-addr.arpa. PTR)" && echo OK > /results/172.21.136.50_udp@PTR;test -n "$$(dig +tcp +noall +answer +search 50.136.21.172.in-addr.arpa. PTR)" && echo OK > /results/172.21.136.50_tcp@PTR;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Jan 21 21:47:24.353: INFO: DNS probes using e2e-tests-dns-xfgfs/dns-test-1bcea301-1dc6-11e9-8130-be6597f3ae53 succeeded

STEP: deleting the pod
STEP: deleting the test service
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 21:47:24.472: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-dns-xfgfs" for this suite.
Jan 21 21:47:30.519: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 21:47:30.713: INFO: namespace: e2e-tests-dns-xfgfs, resource: bindings, ignored listing per whitelist
Jan 21 21:47:30.884: INFO: namespace e2e-tests-dns-xfgfs deletion completed in 6.399033148s

• [SLOW TEST:19.369 seconds]
[sig-network] DNS
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts 
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 21:47:30.884: INFO: >>> kubeConfig: /tmp/kubeconfig-933165938
STEP: Building a namespace api object, basename svcaccounts
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-svcaccounts-9bwn5
STEP: Waiting for a default service account to be provisioned in namespace
[It] should mount an API token into pods  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: getting the auto-created API token
STEP: Creating a pod to test consume service account token
Jan 21 21:47:31.797: INFO: Waiting up to 5m0s for pod "pod-service-account-27ab89a4-1dc6-11e9-8130-be6597f3ae53-gtmqm" in namespace "e2e-tests-svcaccounts-9bwn5" to be "success or failure"
Jan 21 21:47:31.814: INFO: Pod "pod-service-account-27ab89a4-1dc6-11e9-8130-be6597f3ae53-gtmqm": Phase="Pending", Reason="", readiness=false. Elapsed: 9.522334ms
Jan 21 21:47:33.824: INFO: Pod "pod-service-account-27ab89a4-1dc6-11e9-8130-be6597f3ae53-gtmqm": Phase="Pending", Reason="", readiness=false. Elapsed: 2.020111858s
Jan 21 21:47:35.835: INFO: Pod "pod-service-account-27ab89a4-1dc6-11e9-8130-be6597f3ae53-gtmqm": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.031002026s
STEP: Saw pod success
Jan 21 21:47:35.836: INFO: Pod "pod-service-account-27ab89a4-1dc6-11e9-8130-be6597f3ae53-gtmqm" satisfied condition "success or failure"
Jan 21 21:47:35.850: INFO: Trying to get logs from node 10.191.28.39 pod pod-service-account-27ab89a4-1dc6-11e9-8130-be6597f3ae53-gtmqm container token-test: <nil>
STEP: delete the pod
Jan 21 21:47:35.907: INFO: Waiting for pod pod-service-account-27ab89a4-1dc6-11e9-8130-be6597f3ae53-gtmqm to disappear
Jan 21 21:47:35.974: INFO: Pod pod-service-account-27ab89a4-1dc6-11e9-8130-be6597f3ae53-gtmqm no longer exists
STEP: Creating a pod to test consume service account root CA
Jan 21 21:47:35.986: INFO: Waiting up to 5m0s for pod "pod-service-account-27ab89a4-1dc6-11e9-8130-be6597f3ae53-dzr2n" in namespace "e2e-tests-svcaccounts-9bwn5" to be "success or failure"
Jan 21 21:47:35.999: INFO: Pod "pod-service-account-27ab89a4-1dc6-11e9-8130-be6597f3ae53-dzr2n": Phase="Pending", Reason="", readiness=false. Elapsed: 12.579789ms
Jan 21 21:47:38.012: INFO: Pod "pod-service-account-27ab89a4-1dc6-11e9-8130-be6597f3ae53-dzr2n": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.025337218s
STEP: Saw pod success
Jan 21 21:47:38.012: INFO: Pod "pod-service-account-27ab89a4-1dc6-11e9-8130-be6597f3ae53-dzr2n" satisfied condition "success or failure"
Jan 21 21:47:38.022: INFO: Trying to get logs from node 10.191.28.59 pod pod-service-account-27ab89a4-1dc6-11e9-8130-be6597f3ae53-dzr2n container root-ca-test: <nil>
STEP: delete the pod
Jan 21 21:47:38.075: INFO: Waiting for pod pod-service-account-27ab89a4-1dc6-11e9-8130-be6597f3ae53-dzr2n to disappear
Jan 21 21:47:38.084: INFO: Pod pod-service-account-27ab89a4-1dc6-11e9-8130-be6597f3ae53-dzr2n no longer exists
STEP: Creating a pod to test consume service account namespace
Jan 21 21:47:38.098: INFO: Waiting up to 5m0s for pod "pod-service-account-27ab89a4-1dc6-11e9-8130-be6597f3ae53-l8x48" in namespace "e2e-tests-svcaccounts-9bwn5" to be "success or failure"
Jan 21 21:47:38.110: INFO: Pod "pod-service-account-27ab89a4-1dc6-11e9-8130-be6597f3ae53-l8x48": Phase="Pending", Reason="", readiness=false. Elapsed: 10.809402ms
Jan 21 21:47:40.121: INFO: Pod "pod-service-account-27ab89a4-1dc6-11e9-8130-be6597f3ae53-l8x48": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.022609676s
STEP: Saw pod success
Jan 21 21:47:40.121: INFO: Pod "pod-service-account-27ab89a4-1dc6-11e9-8130-be6597f3ae53-l8x48" satisfied condition "success or failure"
Jan 21 21:47:40.132: INFO: Trying to get logs from node 10.191.28.39 pod pod-service-account-27ab89a4-1dc6-11e9-8130-be6597f3ae53-l8x48 container namespace-test: <nil>
STEP: delete the pod
Jan 21 21:47:40.201: INFO: Waiting for pod pod-service-account-27ab89a4-1dc6-11e9-8130-be6597f3ae53-l8x48 to disappear
Jan 21 21:47:40.214: INFO: Pod pod-service-account-27ab89a4-1dc6-11e9-8130-be6597f3ae53-l8x48 no longer exists
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 21:47:40.214: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-svcaccounts-9bwn5" for this suite.
Jan 21 21:47:48.265: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 21:47:48.386: INFO: namespace: e2e-tests-svcaccounts-9bwn5, resource: bindings, ignored listing per whitelist
Jan 21 21:47:48.694: INFO: namespace e2e-tests-svcaccounts-9bwn5 deletion completed in 8.465245188s

• [SLOW TEST:17.810 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:22
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 21:47:48.696: INFO: >>> kubeConfig: /tmp/kubeconfig-933165938
STEP: Building a namespace api object, basename containers
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-containers-rctx4
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test override all
Jan 21 21:47:49.123: INFO: Waiting up to 5m0s for pod "client-containers-31fe8370-1dc6-11e9-8130-be6597f3ae53" in namespace "e2e-tests-containers-rctx4" to be "success or failure"
Jan 21 21:47:49.133: INFO: Pod "client-containers-31fe8370-1dc6-11e9-8130-be6597f3ae53": Phase="Pending", Reason="", readiness=false. Elapsed: 10.377919ms
Jan 21 21:47:51.145: INFO: Pod "client-containers-31fe8370-1dc6-11e9-8130-be6597f3ae53": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.021470417s
STEP: Saw pod success
Jan 21 21:47:51.145: INFO: Pod "client-containers-31fe8370-1dc6-11e9-8130-be6597f3ae53" satisfied condition "success or failure"
Jan 21 21:47:51.155: INFO: Trying to get logs from node 10.191.28.59 pod client-containers-31fe8370-1dc6-11e9-8130-be6597f3ae53 container test-container: <nil>
STEP: delete the pod
Jan 21 21:47:51.264: INFO: Waiting for pod client-containers-31fe8370-1dc6-11e9-8130-be6597f3ae53 to disappear
Jan 21 21:47:51.274: INFO: Pod client-containers-31fe8370-1dc6-11e9-8130-be6597f3ae53 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 21:47:51.274: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-rctx4" for this suite.
Jan 21 21:47:57.325: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 21:47:57.730: INFO: namespace: e2e-tests-containers-rctx4, resource: bindings, ignored listing per whitelist
Jan 21 21:47:57.762: INFO: namespace e2e-tests-containers-rctx4 deletion completed in 6.470809786s

• [SLOW TEST:9.066 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 21:47:57.762: INFO: >>> kubeConfig: /tmp/kubeconfig-933165938
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-container-lifecycle-hook-5g44n
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Jan 21 21:48:02.223: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Jan 21 21:48:02.273: INFO: Pod pod-with-poststart-http-hook still exists
Jan 21 21:48:04.274: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Jan 21 21:48:04.285: INFO: Pod pod-with-poststart-http-hook still exists
Jan 21 21:48:06.274: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Jan 21 21:48:06.285: INFO: Pod pod-with-poststart-http-hook still exists
Jan 21 21:48:08.275: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Jan 21 21:48:08.285: INFO: Pod pod-with-poststart-http-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 21:48:08.286: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-lifecycle-hook-5g44n" for this suite.
Jan 21 21:48:32.398: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 21:48:32.491: INFO: namespace: e2e-tests-container-lifecycle-hook-5g44n, resource: bindings, ignored listing per whitelist
Jan 21 21:48:32.923: INFO: namespace e2e-tests-container-lifecycle-hook-5g44n deletion completed in 24.623746202s

• [SLOW TEST:35.161 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when create a pod with lifecycle hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute poststart http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 21:48:32.924: INFO: >>> kubeConfig: /tmp/kubeconfig-933165938
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-q4xp5
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0777 on node default medium
Jan 21 21:48:33.383: INFO: Waiting up to 5m0s for pod "pod-4c5206fc-1dc6-11e9-8130-be6597f3ae53" in namespace "e2e-tests-emptydir-q4xp5" to be "success or failure"
Jan 21 21:48:33.393: INFO: Pod "pod-4c5206fc-1dc6-11e9-8130-be6597f3ae53": Phase="Pending", Reason="", readiness=false. Elapsed: 9.579529ms
Jan 21 21:48:35.404: INFO: Pod "pod-4c5206fc-1dc6-11e9-8130-be6597f3ae53": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.020303185s
STEP: Saw pod success
Jan 21 21:48:35.404: INFO: Pod "pod-4c5206fc-1dc6-11e9-8130-be6597f3ae53" satisfied condition "success or failure"
Jan 21 21:48:35.415: INFO: Trying to get logs from node 10.191.28.39 pod pod-4c5206fc-1dc6-11e9-8130-be6597f3ae53 container test-container: <nil>
STEP: delete the pod
Jan 21 21:48:35.495: INFO: Waiting for pod pod-4c5206fc-1dc6-11e9-8130-be6597f3ae53 to disappear
Jan 21 21:48:35.507: INFO: Pod pod-4c5206fc-1dc6-11e9-8130-be6597f3ae53 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 21:48:35.507: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-q4xp5" for this suite.
Jan 21 21:48:41.554: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 21:48:41.738: INFO: namespace: e2e-tests-emptydir-q4xp5, resource: bindings, ignored listing per whitelist
Jan 21 21:48:41.946: INFO: namespace e2e-tests-emptydir-q4xp5 deletion completed in 6.425333019s

• [SLOW TEST:9.022 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 21:48:41.947: INFO: >>> kubeConfig: /tmp/kubeconfig-933165938
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-7xb7l
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:293
[It] should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the initial replication controller
Jan 21 21:48:42.364: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-933165938 create -f - --namespace=e2e-tests-kubectl-7xb7l'
Jan 21 21:48:42.731: INFO: stderr: ""
Jan 21 21:48:42.731: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Jan 21 21:48:42.732: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-933165938 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-7xb7l'
Jan 21 21:48:42.945: INFO: stderr: ""
Jan 21 21:48:42.945: INFO: stdout: "update-demo-nautilus-fj924 update-demo-nautilus-s4c47 "
Jan 21 21:48:42.946: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-933165938 get pods update-demo-nautilus-fj924 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-7xb7l'
Jan 21 21:48:43.178: INFO: stderr: ""
Jan 21 21:48:43.178: INFO: stdout: ""
Jan 21 21:48:43.178: INFO: update-demo-nautilus-fj924 is created but not running
Jan 21 21:48:48.178: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-933165938 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-7xb7l'
Jan 21 21:48:48.391: INFO: stderr: ""
Jan 21 21:48:48.391: INFO: stdout: "update-demo-nautilus-fj924 update-demo-nautilus-s4c47 "
Jan 21 21:48:48.391: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-933165938 get pods update-demo-nautilus-fj924 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-7xb7l'
Jan 21 21:48:48.598: INFO: stderr: ""
Jan 21 21:48:48.598: INFO: stdout: "true"
Jan 21 21:48:48.598: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-933165938 get pods update-demo-nautilus-fj924 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-7xb7l'
Jan 21 21:48:48.792: INFO: stderr: ""
Jan 21 21:48:48.792: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Jan 21 21:48:48.792: INFO: validating pod update-demo-nautilus-fj924
Jan 21 21:48:48.882: INFO: got data: {
  "image": "nautilus.jpg"
}

Jan 21 21:48:48.882: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Jan 21 21:48:48.882: INFO: update-demo-nautilus-fj924 is verified up and running
Jan 21 21:48:48.882: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-933165938 get pods update-demo-nautilus-s4c47 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-7xb7l'
Jan 21 21:48:49.132: INFO: stderr: ""
Jan 21 21:48:49.132: INFO: stdout: "true"
Jan 21 21:48:49.132: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-933165938 get pods update-demo-nautilus-s4c47 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-7xb7l'
Jan 21 21:48:49.326: INFO: stderr: ""
Jan 21 21:48:49.327: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Jan 21 21:48:49.327: INFO: validating pod update-demo-nautilus-s4c47
Jan 21 21:48:49.382: INFO: got data: {
  "image": "nautilus.jpg"
}

Jan 21 21:48:49.382: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Jan 21 21:48:49.382: INFO: update-demo-nautilus-s4c47 is verified up and running
STEP: rolling-update to new replication controller
Jan 21 21:48:49.385: INFO: scanned /root for discovery docs: <nil>
Jan 21 21:48:49.385: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-933165938 rolling-update update-demo-nautilus --update-period=1s -f - --namespace=e2e-tests-kubectl-7xb7l'
Jan 21 21:49:12.268: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Jan 21 21:49:12.268: INFO: stdout: "Created update-demo-kitten\nScaling up update-demo-kitten from 0 to 2, scaling down update-demo-nautilus from 2 to 0 (keep 2 pods available, don't exceed 3 pods)\nScaling update-demo-kitten up to 1\nScaling update-demo-nautilus down to 1\nScaling update-demo-kitten up to 2\nScaling update-demo-nautilus down to 0\nUpdate succeeded. Deleting old controller: update-demo-nautilus\nRenaming update-demo-kitten to update-demo-nautilus\nreplicationcontroller/update-demo-nautilus rolling updated\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Jan 21 21:49:12.268: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-933165938 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-7xb7l'
Jan 21 21:49:12.481: INFO: stderr: ""
Jan 21 21:49:12.481: INFO: stdout: "update-demo-kitten-b2mh4 update-demo-kitten-mk6qz "
Jan 21 21:49:12.481: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-933165938 get pods update-demo-kitten-b2mh4 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-7xb7l'
Jan 21 21:49:12.667: INFO: stderr: ""
Jan 21 21:49:12.667: INFO: stdout: "true"
Jan 21 21:49:12.667: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-933165938 get pods update-demo-kitten-b2mh4 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-7xb7l'
Jan 21 21:49:12.877: INFO: stderr: ""
Jan 21 21:49:12.877: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
Jan 21 21:49:12.877: INFO: validating pod update-demo-kitten-b2mh4
Jan 21 21:49:12.900: INFO: got data: {
  "image": "kitten.jpg"
}

Jan 21 21:49:12.900: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Jan 21 21:49:12.900: INFO: update-demo-kitten-b2mh4 is verified up and running
Jan 21 21:49:12.900: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-933165938 get pods update-demo-kitten-mk6qz -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-7xb7l'
Jan 21 21:49:13.072: INFO: stderr: ""
Jan 21 21:49:13.072: INFO: stdout: "true"
Jan 21 21:49:13.072: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-933165938 get pods update-demo-kitten-mk6qz -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-7xb7l'
Jan 21 21:49:13.268: INFO: stderr: ""
Jan 21 21:49:13.268: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
Jan 21 21:49:13.268: INFO: validating pod update-demo-kitten-mk6qz
Jan 21 21:49:13.289: INFO: got data: {
  "image": "kitten.jpg"
}

Jan 21 21:49:13.289: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Jan 21 21:49:13.289: INFO: update-demo-kitten-mk6qz is verified up and running
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 21:49:13.289: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-7xb7l" for this suite.
Jan 21 21:49:37.336: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 21:49:37.672: INFO: namespace: e2e-tests-kubectl-7xb7l, resource: bindings, ignored listing per whitelist
Jan 21 21:49:37.704: INFO: namespace e2e-tests-kubectl-7xb7l deletion completed in 24.401258681s

• [SLOW TEST:55.758 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Update Demo
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should do a rolling update of a replication controller  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 21:49:37.709: INFO: >>> kubeConfig: /tmp/kubeconfig-933165938
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-b789m
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name s-test-opt-del-72f13c6c-1dc6-11e9-8130-be6597f3ae53
STEP: Creating secret with name s-test-opt-upd-72f13d0e-1dc6-11e9-8130-be6597f3ae53
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-72f13c6c-1dc6-11e9-8130-be6597f3ae53
STEP: Updating secret s-test-opt-upd-72f13d0e-1dc6-11e9-8130-be6597f3ae53
STEP: Creating secret with name s-test-opt-create-72f13d3c-1dc6-11e9-8130-be6597f3ae53
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 21:49:44.378: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-b789m" for this suite.
Jan 21 21:50:08.429: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 21:50:08.571: INFO: namespace: e2e-tests-projected-b789m, resource: bindings, ignored listing per whitelist
Jan 21 21:50:08.837: INFO: namespace e2e-tests-projected-b789m deletion completed in 24.440703879s

• [SLOW TEST:31.129 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 21:50:08.838: INFO: >>> kubeConfig: /tmp/kubeconfig-933165938
STEP: Building a namespace api object, basename pod-network-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-pod-network-test-rgv2p
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-rgv2p
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Jan 21 21:50:09.276: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Jan 21 21:50:29.553: INFO: ExecWithOptions {Command:[/bin/sh -c timeout -t 15 curl -g -q -s --connect-timeout 1 http://172.30.216.40:8080/hostName | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-rgv2p PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jan 21 21:50:29.553: INFO: >>> kubeConfig: /tmp/kubeconfig-933165938
Jan 21 21:50:29.753: INFO: Found all expected endpoints: [netserver-0]
Jan 21 21:50:29.764: INFO: ExecWithOptions {Command:[/bin/sh -c timeout -t 15 curl -g -q -s --connect-timeout 1 http://172.30.156.186:8080/hostName | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-rgv2p PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jan 21 21:50:29.764: INFO: >>> kubeConfig: /tmp/kubeconfig-933165938
Jan 21 21:50:29.992: INFO: Found all expected endpoints: [netserver-1]
Jan 21 21:50:30.003: INFO: ExecWithOptions {Command:[/bin/sh -c timeout -t 15 curl -g -q -s --connect-timeout 1 http://172.30.41.17:8080/hostName | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-rgv2p PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jan 21 21:50:30.003: INFO: >>> kubeConfig: /tmp/kubeconfig-933165938
Jan 21 21:50:30.197: INFO: Found all expected endpoints: [netserver-2]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 21:50:30.198: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-rgv2p" for this suite.
Jan 21 21:50:54.370: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 21:50:54.644: INFO: namespace: e2e-tests-pod-network-test-rgv2p, resource: bindings, ignored listing per whitelist
Jan 21 21:50:54.791: INFO: namespace e2e-tests-pod-network-test-rgv2p deletion completed in 24.579939104s

• [SLOW TEST:45.953 seconds]
[sig-network] Networking
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: http [NodeConformance] [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl describe 
  should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 21:50:54.793: INFO: >>> kubeConfig: /tmp/kubeconfig-933165938
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-7ttjn
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Jan 21 21:50:55.144: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-933165938 version --client'
Jan 21 21:50:55.252: INFO: stderr: ""
Jan 21 21:50:55.252: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"12\", GitVersion:\"v1.12.1\", GitCommit:\"4ed3216f3ec431b140b1d899130a69fc671678f4\", GitTreeState:\"clean\", BuildDate:\"2018-10-05T16:46:06Z\", GoVersion:\"go1.10.4\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
Jan 21 21:50:55.256: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-933165938 create -f - --namespace=e2e-tests-kubectl-7ttjn'
Jan 21 21:50:55.617: INFO: stderr: ""
Jan 21 21:50:55.617: INFO: stdout: "replicationcontroller/redis-master created\n"
Jan 21 21:50:55.617: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-933165938 create -f - --namespace=e2e-tests-kubectl-7ttjn'
Jan 21 21:50:56.050: INFO: stderr: ""
Jan 21 21:50:56.050: INFO: stdout: "service/redis-master created\n"
STEP: Waiting for Redis master to start.
Jan 21 21:50:57.060: INFO: Selector matched 1 pods for map[app:redis]
Jan 21 21:50:57.060: INFO: Found 1 / 1
Jan 21 21:50:57.060: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Jan 21 21:50:57.074: INFO: Selector matched 1 pods for map[app:redis]
Jan 21 21:50:57.074: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Jan 21 21:50:57.074: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-933165938 describe pod redis-master-rn6f5 --namespace=e2e-tests-kubectl-7ttjn'
Jan 21 21:50:57.309: INFO: stderr: ""
Jan 21 21:50:57.309: INFO: stdout: "Name:               redis-master-rn6f5\nNamespace:          e2e-tests-kubectl-7ttjn\nPriority:           0\nPriorityClassName:  <none>\nNode:               10.191.28.39/10.191.28.39\nStart Time:         Mon, 21 Jan 2019 21:50:55 +0000\nLabels:             app=redis\n                    role=master\nAnnotations:        kubernetes.io/psp: e2e-test-privileged-psp\nStatus:             Running\nIP:                 172.30.216.43\nControlled By:      ReplicationController/redis-master\nContainers:\n  redis-master:\n    Container ID:   containerd://d62618de335c11e4c88d8ee2b53b3d1429e93d595ad36e52329a5d66fd622602\n    Image:          gcr.io/kubernetes-e2e-test-images/redis:1.0\n    Image ID:       gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830\n    Port:           6379/TCP\n    Host Port:      0/TCP\n    State:          Running\n      Started:      Mon, 21 Jan 2019 21:50:56 +0000\n    Ready:          True\n    Restart Count:  0\n    Environment:    <none>\n    Mounts:\n      /var/run/secrets/kubernetes.io/serviceaccount from default-token-26qp9 (ro)\nConditions:\n  Type              Status\n  Initialized       True \n  Ready             True \n  ContainersReady   True \n  PodScheduled      True \nVolumes:\n  default-token-26qp9:\n    Type:        Secret (a volume populated by a Secret)\n    SecretName:  default-token-26qp9\n    Optional:    false\nQoS Class:       BestEffort\nNode-Selectors:  <none>\nTolerations:     node.kubernetes.io/not-ready:NoExecute for 300s\n                 node.kubernetes.io/unreachable:NoExecute for 300s\nEvents:\n  Type    Reason     Age   From                   Message\n  ----    ------     ----  ----                   -------\n  Normal  Scheduled  2s    default-scheduler      Successfully assigned e2e-tests-kubectl-7ttjn/redis-master-rn6f5 to 10.191.28.39\n  Normal  Pulled     1s    kubelet, 10.191.28.39  Container image \"gcr.io/kubernetes-e2e-test-images/redis:1.0\" already present on machine\n  Normal  Created    1s    kubelet, 10.191.28.39  Created container\n  Normal  Started    1s    kubelet, 10.191.28.39  Started container\n"
Jan 21 21:50:57.309: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-933165938 describe rc redis-master --namespace=e2e-tests-kubectl-7ttjn'
Jan 21 21:50:57.572: INFO: stderr: ""
Jan 21 21:50:57.572: INFO: stdout: "Name:         redis-master\nNamespace:    e2e-tests-kubectl-7ttjn\nSelector:     app=redis,role=master\nLabels:       app=redis\n              role=master\nAnnotations:  <none>\nReplicas:     1 current / 1 desired\nPods Status:  1 Running / 0 Waiting / 0 Succeeded / 0 Failed\nPod Template:\n  Labels:  app=redis\n           role=master\n  Containers:\n   redis-master:\n    Image:        gcr.io/kubernetes-e2e-test-images/redis:1.0\n    Port:         6379/TCP\n    Host Port:    0/TCP\n    Environment:  <none>\n    Mounts:       <none>\n  Volumes:        <none>\nEvents:\n  Type    Reason            Age   From                    Message\n  ----    ------            ----  ----                    -------\n  Normal  SuccessfulCreate  2s    replication-controller  Created pod: redis-master-rn6f5\n"
Jan 21 21:50:57.573: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-933165938 describe service redis-master --namespace=e2e-tests-kubectl-7ttjn'
Jan 21 21:50:57.876: INFO: stderr: ""
Jan 21 21:50:57.876: INFO: stdout: "Name:              redis-master\nNamespace:         e2e-tests-kubectl-7ttjn\nLabels:            app=redis\n                   role=master\nAnnotations:       <none>\nSelector:          app=redis,role=master\nType:              ClusterIP\nIP:                172.21.228.118\nPort:              <unset>  6379/TCP\nTargetPort:        redis-server/TCP\nEndpoints:         172.30.216.43:6379\nSession Affinity:  None\nEvents:            <none>\n"
Jan 21 21:50:57.889: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-933165938 describe node 10.191.28.39'
Jan 21 21:50:58.120: INFO: stderr: ""
Jan 21 21:50:58.120: INFO: stdout: "Name:               10.191.28.39\nRoles:              <none>\nLabels:             arch=amd64\n                    beta.kubernetes.io/arch=amd64\n                    beta.kubernetes.io/instance-type=u2c.2x4.encrypted\n                    beta.kubernetes.io/os=linux\n                    failure-domain.beta.kubernetes.io/region=us-east\n                    failure-domain.beta.kubernetes.io/zone=wdc07\n                    ibm-cloud.kubernetes.io/encrypted-docker-data=true\n                    ibm-cloud.kubernetes.io/ha-worker=true\n                    ibm-cloud.kubernetes.io/iaas-provider=softlayer\n                    ibm-cloud.kubernetes.io/machine-type=u2c.2x4.encrypted\n                    ibm-cloud.kubernetes.io/sgx-enabled=false\n                    ibm-cloud.kubernetes.io/worker-pool-id=a84c924d32e442ceb4b6d3925b452e95-9688161\n                    ibm-cloud.kubernetes.io/worker-version=1.12.4_1534\n                    kubernetes.io/hostname=10.191.28.39\n                    privateVLAN=2530551\n                    publicVLAN=2530549\nAnnotations:        node.alpha.kubernetes.io/ttl: 0\n                    volumes.kubernetes.io/controller-managed-attach-detach: true\nCreationTimestamp:  Mon, 21 Jan 2019 19:04:47 +0000\nTaints:             <none>\nUnschedulable:      false\nConditions:\n  Type             Status  LastHeartbeatTime                 LastTransitionTime                Reason                       Message\n  ----             ------  -----------------                 ------------------                ------                       -------\n  OutOfDisk        False   Mon, 21 Jan 2019 21:50:51 +0000   Mon, 21 Jan 2019 19:04:47 +0000   KubeletHasSufficientDisk     kubelet has sufficient disk space available\n  MemoryPressure   False   Mon, 21 Jan 2019 21:50:51 +0000   Mon, 21 Jan 2019 19:04:47 +0000   KubeletHasSufficientMemory   kubelet has sufficient memory available\n  DiskPressure     False   Mon, 21 Jan 2019 21:50:51 +0000   Mon, 21 Jan 2019 19:04:47 +0000   KubeletHasNoDiskPressure     kubelet has no disk pressure\n  PIDPressure      False   Mon, 21 Jan 2019 21:50:51 +0000   Mon, 21 Jan 2019 19:04:47 +0000   KubeletHasSufficientPID      kubelet has sufficient PID available\n  Ready            True    Mon, 21 Jan 2019 21:50:51 +0000   Mon, 21 Jan 2019 19:05:07 +0000   KubeletReady                 kubelet is posting ready status. AppArmor enabled\nAddresses:\n  InternalIP:  10.191.28.39\n  ExternalIP:  169.61.92.172\n  Hostname:    10.191.28.39\nCapacity:\n cpu:                2\n ephemeral-storage:  103079200Ki\n hugepages-1Gi:      0\n hugepages-2Mi:      0\n memory:             4041600Ki\n pods:               110\nAllocatable:\n cpu:                1920m\n ephemeral-storage:  100275445682\n hugepages-1Gi:      0\n hugepages-2Mi:      0\n memory:             3535744Ki\n pods:               110\nSystem Info:\n Machine ID:                 266c2075dace453da02500b328c9e325\n System UUID:                83847567-FF5D-B1DE-A6DC-022A0FAEE1EB\n Boot ID:                    b033203a-4431-42ac-97a4-f3fe98846c33\n Kernel Version:             4.4.0-141-generic\n OS Image:                   Ubuntu 16.04.5 LTS\n Operating System:           linux\n Architecture:               amd64\n Container Runtime Version:  containerd://1.1.5\n Kubelet Version:            v1.12.4+IKS\n Kube-Proxy Version:         v1.12.4+IKS\nProviderID:                  ibm://d18c889395112a40d2f4e3065f237a7d///a84c924d32e442ceb4b6d3925b452e95/kube-wdc07-cra84c924d32e442ceb4b6d3925b452e95-w2\nNon-terminated Pods:         (14 in total)\n  Namespace                  Name                                                       CPU Requests  CPU Limits  Memory Requests  Memory Limits\n  ---------                  ----                                                       ------------  ----------  ---------------  -------------\n  default                    test-k8s-e2e-pvg-master-verification                       0 (0%)        0 (0%)      0 (0%)           0 (0%)\n  e2e-tests-kubectl-7ttjn    redis-master-rn6f5                                         0 (0%)        0 (0%)      0 (0%)           0 (0%)\n  heptio-sonobuoy            sonobuoy-systemd-logs-daemon-set-e7ca68af2267426a-f655g    0 (0%)        0 (0%)      0 (0%)           0 (0%)\n  kube-system                calico-kube-controllers-5c699798bc-7cfbr                   10m (0%)      0 (0%)      25Mi (0%)        0 (0%)\n  kube-system                calico-node-6zjw9                                          255m (13%)    0 (0%)      85Mi (2%)        0 (0%)\n  kube-system                ibm-file-plugin-56f866c9c7-bz4g8                           50m (2%)      200m (10%)  100Mi (2%)       0 (0%)\n  kube-system                ibm-keepalived-watcher-nw8wp                               5m (0%)       0 (0%)      10Mi (0%)        0 (0%)\n  kube-system                ibm-kube-fluentd-swfr2                                     25m (1%)      300m (15%)  50Mi (1%)        800M (22%)\n  kube-system                ibm-master-proxy-static-10.191.28.39                       25m (1%)      300m (15%)  32M (0%)         512M (14%)\n  kube-system                ibm-storage-watcher-6fb675df47-x2x4h                       50m (2%)      200m (10%)  100Mi (2%)       0 (0%)\n  kube-system                kube-dns-amd64-fddfcc69-l7fs4                              260m (13%)    0 (0%)      110Mi (3%)       170Mi (4%)\n  kube-system                kube-dns-autoscaler-587cd5cd44-sg6d7                       20m (1%)      0 (0%)      10Mi (0%)        0 (0%)\n  kube-system                kubernetes-dashboard-b4bc7db5d-4stht                       50m (2%)      0 (0%)      100Mi (2%)       0 (0%)\n  kube-system                vpn-65599665d9-n57t7                                       5m (0%)       0 (0%)      5Mi (0%)         0 (0%)\nAllocated resources:\n  (Total limits may be over 100 percent, i.e., overcommitted.)\n  Resource  Requests        Limits\n  --------  --------        ------\n  cpu       755m (39%)      1 (52%)\n  memory    640530Ki (18%)  1490257920 (41%)\nEvents:     <none>\n"
Jan 21 21:50:58.120: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-933165938 describe namespace e2e-tests-kubectl-7ttjn'
Jan 21 21:50:58.314: INFO: stderr: ""
Jan 21 21:50:58.314: INFO: stdout: "Name:         e2e-tests-kubectl-7ttjn\nLabels:       e2e-framework=kubectl\n              e2e-run=44dcb9d7-1dc2-11e9-8130-be6597f3ae53\nAnnotations:  <none>\nStatus:       Active\n\nNo resource quota.\n\nNo resource limits.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 21:50:58.314: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-7ttjn" for this suite.
Jan 21 21:51:22.362: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 21:51:22.723: INFO: namespace: e2e-tests-kubectl-7ttjn, resource: bindings, ignored listing per whitelist
Jan 21 21:51:22.845: INFO: namespace e2e-tests-kubectl-7ttjn deletion completed in 24.516240188s

• [SLOW TEST:28.052 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl describe
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should check if kubectl describe prints relevant information for rc and pods  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod with mountPath of existing file [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 21:51:22.847: INFO: >>> kubeConfig: /tmp/kubeconfig-933165938
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-subpath-v8r8l
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with configmap pod with mountPath of existing file [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-configmap-jzn8
STEP: Creating a pod to test atomic-volume-subpath
Jan 21 21:51:23.333: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-jzn8" in namespace "e2e-tests-subpath-v8r8l" to be "success or failure"
Jan 21 21:51:23.343: INFO: Pod "pod-subpath-test-configmap-jzn8": Phase="Pending", Reason="", readiness=false. Elapsed: 9.962913ms
Jan 21 21:51:25.354: INFO: Pod "pod-subpath-test-configmap-jzn8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.02090901s
Jan 21 21:51:27.368: INFO: Pod "pod-subpath-test-configmap-jzn8": Phase="Running", Reason="", readiness=false. Elapsed: 4.035152237s
Jan 21 21:51:29.378: INFO: Pod "pod-subpath-test-configmap-jzn8": Phase="Running", Reason="", readiness=false. Elapsed: 6.045683913s
Jan 21 21:51:31.389: INFO: Pod "pod-subpath-test-configmap-jzn8": Phase="Running", Reason="", readiness=false. Elapsed: 8.056578599s
Jan 21 21:51:33.400: INFO: Pod "pod-subpath-test-configmap-jzn8": Phase="Running", Reason="", readiness=false. Elapsed: 10.067426387s
Jan 21 21:51:35.411: INFO: Pod "pod-subpath-test-configmap-jzn8": Phase="Running", Reason="", readiness=false. Elapsed: 12.078073014s
Jan 21 21:51:37.422: INFO: Pod "pod-subpath-test-configmap-jzn8": Phase="Running", Reason="", readiness=false. Elapsed: 14.089207625s
Jan 21 21:51:39.433: INFO: Pod "pod-subpath-test-configmap-jzn8": Phase="Running", Reason="", readiness=false. Elapsed: 16.099906601s
Jan 21 21:51:41.444: INFO: Pod "pod-subpath-test-configmap-jzn8": Phase="Running", Reason="", readiness=false. Elapsed: 18.110912424s
Jan 21 21:51:43.455: INFO: Pod "pod-subpath-test-configmap-jzn8": Phase="Running", Reason="", readiness=false. Elapsed: 20.122388733s
Jan 21 21:51:45.467: INFO: Pod "pod-subpath-test-configmap-jzn8": Phase="Running", Reason="", readiness=false. Elapsed: 22.134682965s
Jan 21 21:51:47.479: INFO: Pod "pod-subpath-test-configmap-jzn8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.145969811s
STEP: Saw pod success
Jan 21 21:51:47.479: INFO: Pod "pod-subpath-test-configmap-jzn8" satisfied condition "success or failure"
Jan 21 21:51:47.489: INFO: Trying to get logs from node 10.191.28.59 pod pod-subpath-test-configmap-jzn8 container test-container-subpath-configmap-jzn8: <nil>
STEP: delete the pod
Jan 21 21:51:47.564: INFO: Waiting for pod pod-subpath-test-configmap-jzn8 to disappear
Jan 21 21:51:47.574: INFO: Pod pod-subpath-test-configmap-jzn8 no longer exists
STEP: Deleting pod pod-subpath-test-configmap-jzn8
Jan 21 21:51:47.574: INFO: Deleting pod "pod-subpath-test-configmap-jzn8" in namespace "e2e-tests-subpath-v8r8l"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 21:51:47.584: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-v8r8l" for this suite.
Jan 21 21:51:53.637: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 21:51:53.824: INFO: namespace: e2e-tests-subpath-v8r8l, resource: bindings, ignored listing per whitelist
Jan 21 21:51:54.048: INFO: namespace e2e-tests-subpath-v8r8l deletion completed in 6.450707583s

• [SLOW TEST:31.201 seconds]
[sig-storage] Subpath
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with configmap pod with mountPath of existing file [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should scale a replication controller  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 21:51:54.049: INFO: >>> kubeConfig: /tmp/kubeconfig-933165938
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-k26dr
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:293
[It] should scale a replication controller  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a replication controller
Jan 21 21:51:54.481: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-933165938 create -f - --namespace=e2e-tests-kubectl-k26dr'
Jan 21 21:51:55.133: INFO: stderr: ""
Jan 21 21:51:55.133: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Jan 21 21:51:55.133: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-933165938 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-k26dr'
Jan 21 21:51:55.344: INFO: stderr: ""
Jan 21 21:51:55.344: INFO: stdout: "update-demo-nautilus-4rbvb update-demo-nautilus-dqw4p "
Jan 21 21:51:55.344: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-933165938 get pods update-demo-nautilus-4rbvb -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-k26dr'
Jan 21 21:51:55.525: INFO: stderr: ""
Jan 21 21:51:55.525: INFO: stdout: ""
Jan 21 21:51:55.525: INFO: update-demo-nautilus-4rbvb is created but not running
Jan 21 21:52:00.526: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-933165938 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-k26dr'
Jan 21 21:52:00.721: INFO: stderr: ""
Jan 21 21:52:00.721: INFO: stdout: "update-demo-nautilus-4rbvb update-demo-nautilus-dqw4p "
Jan 21 21:52:00.721: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-933165938 get pods update-demo-nautilus-4rbvb -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-k26dr'
Jan 21 21:52:00.968: INFO: stderr: ""
Jan 21 21:52:00.968: INFO: stdout: "true"
Jan 21 21:52:00.968: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-933165938 get pods update-demo-nautilus-4rbvb -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-k26dr'
Jan 21 21:52:01.165: INFO: stderr: ""
Jan 21 21:52:01.165: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Jan 21 21:52:01.165: INFO: validating pod update-demo-nautilus-4rbvb
Jan 21 21:52:01.185: INFO: got data: {
  "image": "nautilus.jpg"
}

Jan 21 21:52:01.185: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Jan 21 21:52:01.185: INFO: update-demo-nautilus-4rbvb is verified up and running
Jan 21 21:52:01.185: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-933165938 get pods update-demo-nautilus-dqw4p -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-k26dr'
Jan 21 21:52:01.372: INFO: stderr: ""
Jan 21 21:52:01.372: INFO: stdout: "true"
Jan 21 21:52:01.372: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-933165938 get pods update-demo-nautilus-dqw4p -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-k26dr'
Jan 21 21:52:01.580: INFO: stderr: ""
Jan 21 21:52:01.580: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Jan 21 21:52:01.580: INFO: validating pod update-demo-nautilus-dqw4p
Jan 21 21:52:01.601: INFO: got data: {
  "image": "nautilus.jpg"
}

Jan 21 21:52:01.601: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Jan 21 21:52:01.601: INFO: update-demo-nautilus-dqw4p is verified up and running
STEP: scaling down the replication controller
Jan 21 21:52:01.603: INFO: scanned /root for discovery docs: <nil>
Jan 21 21:52:01.604: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-933165938 scale rc update-demo-nautilus --replicas=1 --timeout=5m --namespace=e2e-tests-kubectl-k26dr'
Jan 21 21:52:02.889: INFO: stderr: ""
Jan 21 21:52:02.889: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Jan 21 21:52:02.889: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-933165938 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-k26dr'
Jan 21 21:52:03.173: INFO: stderr: ""
Jan 21 21:52:03.173: INFO: stdout: "update-demo-nautilus-4rbvb update-demo-nautilus-dqw4p "
STEP: Replicas for name=update-demo: expected=1 actual=2
Jan 21 21:52:08.173: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-933165938 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-k26dr'
Jan 21 21:52:08.362: INFO: stderr: ""
Jan 21 21:52:08.362: INFO: stdout: "update-demo-nautilus-dqw4p "
Jan 21 21:52:08.363: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-933165938 get pods update-demo-nautilus-dqw4p -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-k26dr'
Jan 21 21:52:08.568: INFO: stderr: ""
Jan 21 21:52:08.568: INFO: stdout: "true"
Jan 21 21:52:08.568: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-933165938 get pods update-demo-nautilus-dqw4p -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-k26dr'
Jan 21 21:52:08.877: INFO: stderr: ""
Jan 21 21:52:08.877: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Jan 21 21:52:08.877: INFO: validating pod update-demo-nautilus-dqw4p
Jan 21 21:52:08.894: INFO: got data: {
  "image": "nautilus.jpg"
}

Jan 21 21:52:08.894: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Jan 21 21:52:08.894: INFO: update-demo-nautilus-dqw4p is verified up and running
STEP: scaling up the replication controller
Jan 21 21:52:08.896: INFO: scanned /root for discovery docs: <nil>
Jan 21 21:52:08.896: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-933165938 scale rc update-demo-nautilus --replicas=2 --timeout=5m --namespace=e2e-tests-kubectl-k26dr'
Jan 21 21:52:10.234: INFO: stderr: ""
Jan 21 21:52:10.234: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Jan 21 21:52:10.234: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-933165938 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-k26dr'
Jan 21 21:52:10.484: INFO: stderr: ""
Jan 21 21:52:10.484: INFO: stdout: "update-demo-nautilus-dqw4p update-demo-nautilus-m9qgs "
Jan 21 21:52:10.485: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-933165938 get pods update-demo-nautilus-dqw4p -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-k26dr'
Jan 21 21:52:10.656: INFO: stderr: ""
Jan 21 21:52:10.656: INFO: stdout: "true"
Jan 21 21:52:10.656: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-933165938 get pods update-demo-nautilus-dqw4p -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-k26dr'
Jan 21 21:52:10.931: INFO: stderr: ""
Jan 21 21:52:10.931: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Jan 21 21:52:10.931: INFO: validating pod update-demo-nautilus-dqw4p
Jan 21 21:52:10.945: INFO: got data: {
  "image": "nautilus.jpg"
}

Jan 21 21:52:10.945: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Jan 21 21:52:10.945: INFO: update-demo-nautilus-dqw4p is verified up and running
Jan 21 21:52:10.946: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-933165938 get pods update-demo-nautilus-m9qgs -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-k26dr'
Jan 21 21:52:11.167: INFO: stderr: ""
Jan 21 21:52:11.167: INFO: stdout: "true"
Jan 21 21:52:11.168: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-933165938 get pods update-demo-nautilus-m9qgs -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-k26dr'
Jan 21 21:52:11.346: INFO: stderr: ""
Jan 21 21:52:11.346: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Jan 21 21:52:11.346: INFO: validating pod update-demo-nautilus-m9qgs
Jan 21 21:52:11.366: INFO: got data: {
  "image": "nautilus.jpg"
}

Jan 21 21:52:11.366: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Jan 21 21:52:11.366: INFO: update-demo-nautilus-m9qgs is verified up and running
STEP: using delete to clean up resources
Jan 21 21:52:11.366: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-933165938 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-k26dr'
Jan 21 21:52:11.574: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Jan 21 21:52:11.574: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Jan 21 21:52:11.575: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-933165938 get rc,svc -l name=update-demo --no-headers --namespace=e2e-tests-kubectl-k26dr'
Jan 21 21:52:11.802: INFO: stderr: "No resources found.\n"
Jan 21 21:52:11.802: INFO: stdout: ""
Jan 21 21:52:11.802: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-933165938 get pods -l name=update-demo --namespace=e2e-tests-kubectl-k26dr -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Jan 21 21:52:11.994: INFO: stderr: ""
Jan 21 21:52:11.994: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 21:52:11.994: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-k26dr" for this suite.
Jan 21 21:52:36.053: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 21:52:36.086: INFO: namespace: e2e-tests-kubectl-k26dr, resource: bindings, ignored listing per whitelist
Jan 21 21:52:36.509: INFO: namespace e2e-tests-kubectl-k26dr deletion completed in 24.500133298s

• [SLOW TEST:42.460 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Update Demo
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should scale a replication controller  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] ConfigMap 
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 21:52:36.510: INFO: >>> kubeConfig: /tmp/kubeconfig-933165938
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-xp8v8
STEP: Waiting for a default service account to be provisioned in namespace
[It] binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-upd-dd85c263-1dc6-11e9-8130-be6597f3ae53
STEP: Creating the pod
STEP: Waiting for pod with text data
STEP: Waiting for pod with binary data
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 21:52:39.014: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-xp8v8" for this suite.
Jan 21 21:53:03.077: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 21:53:03.305: INFO: namespace: e2e-tests-configmap-xp8v8, resource: bindings, ignored listing per whitelist
Jan 21 21:53:03.521: INFO: namespace e2e-tests-configmap-xp8v8 deletion completed in 24.488345417s

• [SLOW TEST:27.012 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[k8s.io] [sig-node] Pods Extended [k8s.io] Pods Set QOS Class 
  should be submitted and removed  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 21:53:03.523: INFO: >>> kubeConfig: /tmp/kubeconfig-933165938
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-pods-98nj4
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pods.go:204
[It] should be submitted and removed  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying QOS class is set on the pod
[AfterEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 21:53:03.891: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-98nj4" for this suite.
Jan 21 21:53:27.941: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 21:53:28.031: INFO: namespace: e2e-tests-pods-98nj4, resource: bindings, ignored listing per whitelist
Jan 21 21:53:28.295: INFO: namespace e2e-tests-pods-98nj4 deletion completed in 24.390108063s

• [SLOW TEST:24.772 seconds]
[k8s.io] [sig-node] Pods Extended
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should be submitted and removed  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-auth] ServiceAccounts 
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 21:53:28.296: INFO: >>> kubeConfig: /tmp/kubeconfig-933165938
STEP: Building a namespace api object, basename svcaccounts
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-svcaccounts-8fxs6
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: getting the auto-created API token
Jan 21 21:53:29.186: INFO: created pod pod-service-account-defaultsa
Jan 21 21:53:29.186: INFO: pod pod-service-account-defaultsa service account token volume mount: true
Jan 21 21:53:29.275: INFO: created pod pod-service-account-mountsa
Jan 21 21:53:29.275: INFO: pod pod-service-account-mountsa service account token volume mount: true
Jan 21 21:53:29.290: INFO: created pod pod-service-account-nomountsa
Jan 21 21:53:29.290: INFO: pod pod-service-account-nomountsa service account token volume mount: false
Jan 21 21:53:29.302: INFO: created pod pod-service-account-defaultsa-mountspec
Jan 21 21:53:29.302: INFO: pod pod-service-account-defaultsa-mountspec service account token volume mount: true
Jan 21 21:53:29.316: INFO: created pod pod-service-account-mountsa-mountspec
Jan 21 21:53:29.317: INFO: pod pod-service-account-mountsa-mountspec service account token volume mount: true
Jan 21 21:53:29.331: INFO: created pod pod-service-account-nomountsa-mountspec
Jan 21 21:53:29.331: INFO: pod pod-service-account-nomountsa-mountspec service account token volume mount: true
Jan 21 21:53:29.343: INFO: created pod pod-service-account-defaultsa-nomountspec
Jan 21 21:53:29.343: INFO: pod pod-service-account-defaultsa-nomountspec service account token volume mount: false
Jan 21 21:53:29.362: INFO: created pod pod-service-account-mountsa-nomountspec
Jan 21 21:53:29.362: INFO: pod pod-service-account-mountsa-nomountspec service account token volume mount: false
Jan 21 21:53:29.379: INFO: created pod pod-service-account-nomountsa-nomountspec
Jan 21 21:53:29.379: INFO: pod pod-service-account-nomountsa-nomountspec service account token volume mount: false
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 21:53:29.380: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-svcaccounts-8fxs6" for this suite.
Jan 21 21:53:37.455: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 21:53:37.606: INFO: namespace: e2e-tests-svcaccounts-8fxs6, resource: bindings, ignored listing per whitelist
Jan 21 21:53:37.989: INFO: namespace e2e-tests-svcaccounts-8fxs6 deletion completed in 8.576505312s

• [SLOW TEST:9.693 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:22
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 21:53:37.989: INFO: >>> kubeConfig: /tmp/kubeconfig-933165938
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-gc-29w54
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for all rs to be garbage collected
STEP: expected 0 rs, got 1 rs
STEP: expected 0 pods, got 2 pods
STEP: Gathering metrics
W0121 21:53:39.478027      15 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Jan 21 21:53:39.478: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 21:53:39.478: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-29w54" for this suite.
Jan 21 21:53:45.524: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 21:53:45.800: INFO: namespace: e2e-tests-gc-29w54, resource: bindings, ignored listing per whitelist
Jan 21 21:53:45.896: INFO: namespace e2e-tests-gc-29w54 deletion completed in 6.405557223s

• [SLOW TEST:7.907 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl expose 
  should create services for rc  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 21:53:45.897: INFO: >>> kubeConfig: /tmp/kubeconfig-933165938
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-77vn5
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should create services for rc  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating Redis RC
Jan 21 21:53:46.268: INFO: namespace e2e-tests-kubectl-77vn5
Jan 21 21:53:46.269: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-933165938 create -f - --namespace=e2e-tests-kubectl-77vn5'
Jan 21 21:53:46.658: INFO: stderr: ""
Jan 21 21:53:46.658: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
Jan 21 21:53:47.669: INFO: Selector matched 1 pods for map[app:redis]
Jan 21 21:53:47.669: INFO: Found 0 / 1
Jan 21 21:53:48.672: INFO: Selector matched 1 pods for map[app:redis]
Jan 21 21:53:48.673: INFO: Found 1 / 1
Jan 21 21:53:48.673: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Jan 21 21:53:48.682: INFO: Selector matched 1 pods for map[app:redis]
Jan 21 21:53:48.682: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Jan 21 21:53:48.682: INFO: wait on redis-master startup in e2e-tests-kubectl-77vn5 
Jan 21 21:53:48.683: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-933165938 logs redis-master-qzdht redis-master --namespace=e2e-tests-kubectl-77vn5'
Jan 21 21:53:48.911: INFO: stderr: ""
Jan 21 21:53:48.911: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 21 Jan 21:53:47.719 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 21 Jan 21:53:47.719 # Server started, Redis version 3.2.12\n1:M 21 Jan 21:53:47.719 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 21 Jan 21:53:47.719 * The server is now ready to accept connections on port 6379\n"
STEP: exposing RC
Jan 21 21:53:48.912: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-933165938 expose rc redis-master --name=rm2 --port=1234 --target-port=6379 --namespace=e2e-tests-kubectl-77vn5'
Jan 21 21:53:49.319: INFO: stderr: ""
Jan 21 21:53:49.319: INFO: stdout: "service/rm2 exposed\n"
Jan 21 21:53:49.333: INFO: Service rm2 in namespace e2e-tests-kubectl-77vn5 found.
STEP: exposing service
Jan 21 21:53:51.351: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-933165938 expose service rm2 --name=rm3 --port=2345 --target-port=6379 --namespace=e2e-tests-kubectl-77vn5'
Jan 21 21:53:51.599: INFO: stderr: ""
Jan 21 21:53:51.599: INFO: stdout: "service/rm3 exposed\n"
Jan 21 21:53:51.609: INFO: Service rm3 in namespace e2e-tests-kubectl-77vn5 found.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 21:53:53.632: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-77vn5" for this suite.
Jan 21 21:54:17.696: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 21:54:17.813: INFO: namespace: e2e-tests-kubectl-77vn5, resource: bindings, ignored listing per whitelist
Jan 21 21:54:18.183: INFO: namespace e2e-tests-kubectl-77vn5 deletion completed in 24.537032832s

• [SLOW TEST:32.286 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl expose
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create services for rc  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should provide secure master service  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 21:54:18.183: INFO: >>> kubeConfig: /tmp/kubeconfig-933165938
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-services-hd4cf
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:83
[It] should provide secure master service  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 21:54:18.541: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-services-hd4cf" for this suite.
Jan 21 21:54:24.589: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 21:54:24.656: INFO: namespace: e2e-tests-services-hd4cf, resource: bindings, ignored listing per whitelist
Jan 21 21:54:25.094: INFO: namespace e2e-tests-services-hd4cf deletion completed in 6.539145534s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:88

• [SLOW TEST:6.911 seconds]
[sig-network] Services
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide secure master service  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Proxy server 
  should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 21:54:25.096: INFO: >>> kubeConfig: /tmp/kubeconfig-933165938
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-crrcp
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: starting the proxy server
Jan 21 21:54:25.450: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-933165938 proxy -p 0 --disable-filter'
STEP: curling proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 21:54:25.634: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-crrcp" for this suite.
Jan 21 21:54:31.706: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 21:54:32.396: INFO: namespace: e2e-tests-kubectl-crrcp, resource: bindings, ignored listing per whitelist
Jan 21 21:54:32.414: INFO: namespace e2e-tests-kubectl-crrcp deletion completed in 6.73784819s

• [SLOW TEST:7.319 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Proxy server
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should support proxy with --port 0  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 21:54:32.416: INFO: >>> kubeConfig: /tmp/kubeconfig-933165938
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-watch-jhd8p
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a watch on configmaps
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: closing the watch once it receives two notifications
Jan 21 21:54:32.897: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-jhd8p,SelfLink:/api/v1/namespaces/e2e-tests-watch-jhd8p/configmaps/e2e-watch-test-watch-closed,UID:22a78965-1dc7-11e9-903f-ee5d7ad9296f,ResourceVersion:38411,Generation:0,CreationTimestamp:2019-01-21 21:54:32 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Jan 21 21:54:32.898: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-jhd8p,SelfLink:/api/v1/namespaces/e2e-tests-watch-jhd8p/configmaps/e2e-watch-test-watch-closed,UID:22a78965-1dc7-11e9-903f-ee5d7ad9296f,ResourceVersion:38412,Generation:0,CreationTimestamp:2019-01-21 21:54:32 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time, while the watch is closed
STEP: creating a new watch on configmaps from the last resource version observed by the first watch
STEP: deleting the configmap
STEP: Expecting to observe notifications for all changes to the configmap since the first watch closed
Jan 21 21:54:32.937: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-jhd8p,SelfLink:/api/v1/namespaces/e2e-tests-watch-jhd8p/configmaps/e2e-watch-test-watch-closed,UID:22a78965-1dc7-11e9-903f-ee5d7ad9296f,ResourceVersion:38413,Generation:0,CreationTimestamp:2019-01-21 21:54:32 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Jan 21 21:54:32.938: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-jhd8p,SelfLink:/api/v1/namespaces/e2e-tests-watch-jhd8p/configmaps/e2e-watch-test-watch-closed,UID:22a78965-1dc7-11e9-903f-ee5d7ad9296f,ResourceVersion:38414,Generation:0,CreationTimestamp:2019-01-21 21:54:32 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 21:54:32.938: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-jhd8p" for this suite.
Jan 21 21:54:38.985: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 21:54:39.091: INFO: namespace: e2e-tests-watch-jhd8p, resource: bindings, ignored listing per whitelist
Jan 21 21:54:39.406: INFO: namespace e2e-tests-watch-jhd8p deletion completed in 6.452913991s

• [SLOW TEST:6.991 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-apps] Deployment 
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 21:54:39.406: INFO: >>> kubeConfig: /tmp/kubeconfig-933165938
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-deployment-lvnpk
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Jan 21 21:54:39.768: INFO: Pod name cleanup-pod: Found 0 pods out of 1
Jan 21 21:54:44.779: INFO: Pod name cleanup-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Jan 21 21:54:44.779: INFO: Creating deployment test-cleanup-deployment
STEP: Waiting for deployment test-cleanup-deployment history to be cleaned up
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Jan 21 21:54:44.902: INFO: Deployment "test-cleanup-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-deployment,GenerateName:,Namespace:e2e-tests-deployment-lvnpk,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-lvnpk/deployments/test-cleanup-deployment,UID:29ced4c7-1dc7-11e9-903f-ee5d7ad9296f,ResourceVersion:38465,Generation:1,CreationTimestamp:2019-01-21 21:54:44 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*0,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:0,Replicas:0,UpdatedReplicas:0,AvailableReplicas:0,UnavailableReplicas:0,Conditions:[],ReadyReplicas:0,CollisionCount:nil,},}

Jan 21 21:54:44.916: INFO: New ReplicaSet of Deployment "test-cleanup-deployment" is nil.
Jan 21 21:54:44.916: INFO: All old ReplicaSets of Deployment "test-cleanup-deployment":
Jan 21 21:54:44.916: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-controller,GenerateName:,Namespace:e2e-tests-deployment-lvnpk,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-lvnpk/replicasets/test-cleanup-controller,UID:26bf9a94-1dc7-11e9-903f-ee5d7ad9296f,ResourceVersion:38466,Generation:1,CreationTimestamp:2019-01-21 21:54:39 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 Deployment test-cleanup-deployment 29ced4c7-1dc7-11e9-903f-ee5d7ad9296f 0xc422115c77 0xc422115c78}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Jan 21 21:54:44.932: INFO: Pod "test-cleanup-controller-d2w78" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-controller-d2w78,GenerateName:test-cleanup-controller-,Namespace:e2e-tests-deployment-lvnpk,SelfLink:/api/v1/namespaces/e2e-tests-deployment-lvnpk/pods/test-cleanup-controller-d2w78,UID:26c6277f-1dc7-11e9-903f-ee5d7ad9296f,ResourceVersion:38456,Generation:0,CreationTimestamp:2019-01-21 21:54:39 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod: nginx,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet test-cleanup-controller 26bf9a94-1dc7-11e9-903f-ee5d7ad9296f 0xc421eb6b97 0xc421eb6b98}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-cw95w {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-cw95w,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-cw95w true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.191.28.59,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc421eb6cb0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421eb6cd0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-21 21:54:39 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-01-21 21:54:40 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-01-21 21:54:40 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-21 21:54:39 +0000 UTC  }],Message:,Reason:,HostIP:10.191.28.59,PodIP:172.30.156.136,StartTime:2019-01-21 21:54:39 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-01-21 21:54:40 +0000 UTC,} nil} {nil nil nil} true 0 docker.io/library/nginx:1.14-alpine docker.io/library/nginx@sha256:e3f77f7f4a6bb5e7820e013fa60b96602b34f5704e796cfd94b561ae73adcf96 containerd://1955963f30988563beeb975f804a30fa7745bde2796f69b9f5eebae674e595ad}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 21:54:44.932: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-lvnpk" for this suite.
Jan 21 21:54:50.987: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 21:54:51.279: INFO: namespace: e2e-tests-deployment-lvnpk, resource: bindings, ignored listing per whitelist
Jan 21 21:54:51.447: INFO: namespace e2e-tests-deployment-lvnpk deletion completed in 6.498885433s

• [SLOW TEST:12.041 seconds]
[sig-apps] Deployment
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Downward API 
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 21:54:51.452: INFO: >>> kubeConfig: /tmp/kubeconfig-933165938
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-hxc8x
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Jan 21 21:54:51.999: INFO: Waiting up to 5m0s for pod "downward-api-2e0cb30e-1dc7-11e9-8130-be6597f3ae53" in namespace "e2e-tests-downward-api-hxc8x" to be "success or failure"
Jan 21 21:54:52.073: INFO: Pod "downward-api-2e0cb30e-1dc7-11e9-8130-be6597f3ae53": Phase="Pending", Reason="", readiness=false. Elapsed: 73.954397ms
Jan 21 21:54:54.085: INFO: Pod "downward-api-2e0cb30e-1dc7-11e9-8130-be6597f3ae53": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.085502259s
STEP: Saw pod success
Jan 21 21:54:54.085: INFO: Pod "downward-api-2e0cb30e-1dc7-11e9-8130-be6597f3ae53" satisfied condition "success or failure"
Jan 21 21:54:54.095: INFO: Trying to get logs from node 10.191.28.59 pod downward-api-2e0cb30e-1dc7-11e9-8130-be6597f3ae53 container dapi-container: <nil>
STEP: delete the pod
Jan 21 21:54:54.164: INFO: Waiting for pod downward-api-2e0cb30e-1dc7-11e9-8130-be6597f3ae53 to disappear
Jan 21 21:54:54.173: INFO: Pod downward-api-2e0cb30e-1dc7-11e9-8130-be6597f3ae53 no longer exists
[AfterEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 21:54:54.173: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-hxc8x" for this suite.
Jan 21 21:55:00.222: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 21:55:00.296: INFO: namespace: e2e-tests-downward-api-hxc8x, resource: bindings, ignored listing per whitelist
Jan 21 21:55:00.578: INFO: namespace e2e-tests-downward-api-hxc8x deletion completed in 6.388542373s

• [SLOW TEST:9.126 seconds]
[sig-api-machinery] Downward API
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run default 
  should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 21:55:00.580: INFO: >>> kubeConfig: /tmp/kubeconfig-933165938
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-xr59x
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Kubectl run default
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1210
[It] should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Jan 21 21:55:00.945: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-933165938 run e2e-test-nginx-deployment --image=docker.io/library/nginx:1.14-alpine --namespace=e2e-tests-kubectl-xr59x'
Jan 21 21:55:01.211: INFO: stderr: "kubectl run --generator=deployment/apps.v1beta1 is DEPRECATED and will be removed in a future version. Use kubectl create instead.\n"
Jan 21 21:55:01.211: INFO: stdout: "deployment.apps/e2e-test-nginx-deployment created\n"
STEP: verifying the pod controlled by e2e-test-nginx-deployment gets created
[AfterEach] [k8s.io] Kubectl run default
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1216
Jan 21 21:55:03.232: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-933165938 delete deployment e2e-test-nginx-deployment --namespace=e2e-tests-kubectl-xr59x'
Jan 21 21:55:03.426: INFO: stderr: ""
Jan 21 21:55:03.426: INFO: stdout: "deployment.extensions \"e2e-test-nginx-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 21:55:03.426: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-xr59x" for this suite.
Jan 21 21:55:09.473: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 21:55:09.708: INFO: namespace: e2e-tests-kubectl-xr59x, resource: bindings, ignored listing per whitelist
Jan 21 21:55:09.947: INFO: namespace e2e-tests-kubectl-xr59x deletion completed in 6.506150082s

• [SLOW TEST:9.368 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run default
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create an rc or deployment from an image  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-api-machinery] Garbage collector 
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 21:55:09.948: INFO: >>> kubeConfig: /tmp/kubeconfig-933165938
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-gc-8tjlc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: Gathering metrics
W0121 21:55:16.521454      15 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Jan 21 21:55:16.521: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 21:55:16.521: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-8tjlc" for this suite.
Jan 21 21:55:24.624: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 21:55:24.902: INFO: namespace: e2e-tests-gc-8tjlc, resource: bindings, ignored listing per whitelist
Jan 21 21:55:25.147: INFO: namespace e2e-tests-gc-8tjlc deletion completed in 8.598269137s

• [SLOW TEST:15.200 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Secrets 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 21:55:25.149: INFO: >>> kubeConfig: /tmp/kubeconfig-933165938
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-secrets-kptk6
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating secret e2e-tests-secrets-kptk6/secret-test-42068bbd-1dc7-11e9-8130-be6597f3ae53
STEP: Creating a pod to test consume secrets
Jan 21 21:55:25.521: INFO: Waiting up to 5m0s for pod "pod-configmaps-420814c0-1dc7-11e9-8130-be6597f3ae53" in namespace "e2e-tests-secrets-kptk6" to be "success or failure"
Jan 21 21:55:25.532: INFO: Pod "pod-configmaps-420814c0-1dc7-11e9-8130-be6597f3ae53": Phase="Pending", Reason="", readiness=false. Elapsed: 10.739842ms
Jan 21 21:55:27.544: INFO: Pod "pod-configmaps-420814c0-1dc7-11e9-8130-be6597f3ae53": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.022639466s
STEP: Saw pod success
Jan 21 21:55:27.544: INFO: Pod "pod-configmaps-420814c0-1dc7-11e9-8130-be6597f3ae53" satisfied condition "success or failure"
Jan 21 21:55:27.557: INFO: Trying to get logs from node 10.191.28.59 pod pod-configmaps-420814c0-1dc7-11e9-8130-be6597f3ae53 container env-test: <nil>
STEP: delete the pod
Jan 21 21:55:27.612: INFO: Waiting for pod pod-configmaps-420814c0-1dc7-11e9-8130-be6597f3ae53 to disappear
Jan 21 21:55:27.622: INFO: Pod pod-configmaps-420814c0-1dc7-11e9-8130-be6597f3ae53 no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 21:55:27.622: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-kptk6" for this suite.
Jan 21 21:55:33.675: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 21:55:33.821: INFO: namespace: e2e-tests-secrets-kptk6, resource: bindings, ignored listing per whitelist
Jan 21 21:55:34.241: INFO: namespace e2e-tests-secrets-kptk6 deletion completed in 6.605731056s

• [SLOW TEST:9.092 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:31
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-apps] Daemon set [Serial] 
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 21:55:34.242: INFO: >>> kubeConfig: /tmp/kubeconfig-933165938
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-daemonsets-2lrbn
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:98
[It] should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Jan 21 21:55:34.693: INFO: Creating simple daemon set daemon-set
STEP: Check that daemon pods launch on every node of the cluster.
Jan 21 21:55:34.725: INFO: Number of nodes with available pods: 0
Jan 21 21:55:34.725: INFO: Node 10.191.28.39 is running more than one daemon pod
Jan 21 21:55:35.750: INFO: Number of nodes with available pods: 0
Jan 21 21:55:35.750: INFO: Node 10.191.28.39 is running more than one daemon pod
Jan 21 21:55:36.750: INFO: Number of nodes with available pods: 3
Jan 21 21:55:36.750: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Update daemon pods image.
STEP: Check that daemon pods images are updated.
Jan 21 21:55:36.821: INFO: Wrong image for pod: daemon-set-mv2mj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 21:55:36.821: INFO: Wrong image for pod: daemon-set-pmm8g. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 21:55:36.821: INFO: Wrong image for pod: daemon-set-pnrn9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 21:55:37.849: INFO: Wrong image for pod: daemon-set-mv2mj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 21:55:37.849: INFO: Wrong image for pod: daemon-set-pmm8g. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 21:55:37.849: INFO: Wrong image for pod: daemon-set-pnrn9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 21:55:38.848: INFO: Wrong image for pod: daemon-set-mv2mj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 21:55:38.849: INFO: Wrong image for pod: daemon-set-pmm8g. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 21:55:38.849: INFO: Wrong image for pod: daemon-set-pnrn9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 21:55:39.850: INFO: Wrong image for pod: daemon-set-mv2mj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 21:55:39.850: INFO: Wrong image for pod: daemon-set-pmm8g. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 21:55:39.850: INFO: Wrong image for pod: daemon-set-pnrn9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 21:55:40.849: INFO: Wrong image for pod: daemon-set-mv2mj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 21:55:40.849: INFO: Wrong image for pod: daemon-set-pmm8g. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 21:55:40.849: INFO: Wrong image for pod: daemon-set-pnrn9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 21:55:41.849: INFO: Wrong image for pod: daemon-set-mv2mj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 21:55:41.849: INFO: Wrong image for pod: daemon-set-pmm8g. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 21:55:41.849: INFO: Wrong image for pod: daemon-set-pnrn9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 21:55:42.873: INFO: Wrong image for pod: daemon-set-mv2mj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 21:55:42.873: INFO: Wrong image for pod: daemon-set-pmm8g. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 21:55:42.873: INFO: Wrong image for pod: daemon-set-pnrn9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 21:55:43.861: INFO: Wrong image for pod: daemon-set-mv2mj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 21:55:43.861: INFO: Wrong image for pod: daemon-set-pmm8g. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 21:55:43.861: INFO: Wrong image for pod: daemon-set-pnrn9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 21:55:44.848: INFO: Wrong image for pod: daemon-set-mv2mj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 21:55:44.848: INFO: Wrong image for pod: daemon-set-pmm8g. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 21:55:44.848: INFO: Wrong image for pod: daemon-set-pnrn9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 21:55:45.848: INFO: Wrong image for pod: daemon-set-mv2mj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 21:55:45.848: INFO: Wrong image for pod: daemon-set-pmm8g. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 21:55:45.849: INFO: Wrong image for pod: daemon-set-pnrn9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 21:55:46.848: INFO: Wrong image for pod: daemon-set-mv2mj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 21:55:46.849: INFO: Wrong image for pod: daemon-set-pmm8g. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 21:55:46.849: INFO: Wrong image for pod: daemon-set-pnrn9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 21:55:47.848: INFO: Wrong image for pod: daemon-set-mv2mj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 21:55:47.848: INFO: Wrong image for pod: daemon-set-pmm8g. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 21:55:47.848: INFO: Wrong image for pod: daemon-set-pnrn9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 21:55:48.850: INFO: Wrong image for pod: daemon-set-mv2mj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 21:55:48.850: INFO: Wrong image for pod: daemon-set-pmm8g. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 21:55:48.850: INFO: Wrong image for pod: daemon-set-pnrn9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 21:55:49.848: INFO: Wrong image for pod: daemon-set-mv2mj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 21:55:49.848: INFO: Wrong image for pod: daemon-set-pmm8g. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 21:55:49.848: INFO: Wrong image for pod: daemon-set-pnrn9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 21:55:50.851: INFO: Wrong image for pod: daemon-set-mv2mj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 21:55:50.851: INFO: Wrong image for pod: daemon-set-pmm8g. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 21:55:50.851: INFO: Wrong image for pod: daemon-set-pnrn9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 21:55:51.847: INFO: Wrong image for pod: daemon-set-mv2mj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 21:55:51.847: INFO: Wrong image for pod: daemon-set-pmm8g. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 21:55:51.847: INFO: Wrong image for pod: daemon-set-pnrn9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 21:55:52.873: INFO: Wrong image for pod: daemon-set-mv2mj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 21:55:52.874: INFO: Wrong image for pod: daemon-set-pmm8g. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 21:55:52.874: INFO: Wrong image for pod: daemon-set-pnrn9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 21:55:53.848: INFO: Wrong image for pod: daemon-set-mv2mj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 21:55:53.849: INFO: Wrong image for pod: daemon-set-pmm8g. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 21:55:53.849: INFO: Wrong image for pod: daemon-set-pnrn9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 21:55:54.847: INFO: Wrong image for pod: daemon-set-mv2mj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 21:55:54.848: INFO: Wrong image for pod: daemon-set-pmm8g. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 21:55:54.848: INFO: Wrong image for pod: daemon-set-pnrn9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 21:55:55.848: INFO: Wrong image for pod: daemon-set-mv2mj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 21:55:55.848: INFO: Wrong image for pod: daemon-set-pmm8g. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 21:55:55.848: INFO: Wrong image for pod: daemon-set-pnrn9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 21:55:56.850: INFO: Wrong image for pod: daemon-set-mv2mj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 21:55:56.850: INFO: Wrong image for pod: daemon-set-pmm8g. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 21:55:56.850: INFO: Wrong image for pod: daemon-set-pnrn9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 21:55:57.848: INFO: Wrong image for pod: daemon-set-mv2mj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 21:55:57.848: INFO: Wrong image for pod: daemon-set-pmm8g. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 21:55:57.848: INFO: Wrong image for pod: daemon-set-pnrn9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 21:55:58.848: INFO: Wrong image for pod: daemon-set-mv2mj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 21:55:58.848: INFO: Wrong image for pod: daemon-set-pmm8g. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 21:55:58.848: INFO: Wrong image for pod: daemon-set-pnrn9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 21:55:59.848: INFO: Wrong image for pod: daemon-set-mv2mj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 21:55:59.848: INFO: Wrong image for pod: daemon-set-pmm8g. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 21:55:59.848: INFO: Wrong image for pod: daemon-set-pnrn9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 21:56:00.848: INFO: Wrong image for pod: daemon-set-mv2mj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 21:56:00.848: INFO: Wrong image for pod: daemon-set-pmm8g. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 21:56:00.848: INFO: Wrong image for pod: daemon-set-pnrn9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 21:56:01.848: INFO: Wrong image for pod: daemon-set-mv2mj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 21:56:01.848: INFO: Wrong image for pod: daemon-set-pmm8g. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 21:56:01.849: INFO: Wrong image for pod: daemon-set-pnrn9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 21:56:03.407: INFO: Wrong image for pod: daemon-set-mv2mj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 21:56:03.407: INFO: Wrong image for pod: daemon-set-pmm8g. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 21:56:03.407: INFO: Wrong image for pod: daemon-set-pnrn9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 21:56:03.849: INFO: Wrong image for pod: daemon-set-mv2mj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 21:56:03.849: INFO: Wrong image for pod: daemon-set-pmm8g. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 21:56:03.849: INFO: Wrong image for pod: daemon-set-pnrn9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 21:56:04.851: INFO: Wrong image for pod: daemon-set-mv2mj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 21:56:04.851: INFO: Wrong image for pod: daemon-set-pmm8g. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 21:56:04.851: INFO: Wrong image for pod: daemon-set-pnrn9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 21:56:05.848: INFO: Wrong image for pod: daemon-set-mv2mj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 21:56:05.848: INFO: Wrong image for pod: daemon-set-pmm8g. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 21:56:05.848: INFO: Wrong image for pod: daemon-set-pnrn9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 21:56:06.849: INFO: Wrong image for pod: daemon-set-mv2mj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 21:56:06.849: INFO: Wrong image for pod: daemon-set-pmm8g. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 21:56:06.849: INFO: Wrong image for pod: daemon-set-pnrn9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 21:56:07.849: INFO: Wrong image for pod: daemon-set-mv2mj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 21:56:07.849: INFO: Wrong image for pod: daemon-set-pmm8g. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 21:56:07.849: INFO: Wrong image for pod: daemon-set-pnrn9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 21:56:08.853: INFO: Wrong image for pod: daemon-set-mv2mj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 21:56:08.853: INFO: Wrong image for pod: daemon-set-pmm8g. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 21:56:08.853: INFO: Wrong image for pod: daemon-set-pnrn9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 21:56:09.847: INFO: Wrong image for pod: daemon-set-mv2mj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 21:56:09.847: INFO: Wrong image for pod: daemon-set-pmm8g. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 21:56:09.847: INFO: Wrong image for pod: daemon-set-pnrn9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 21:56:09.847: INFO: Pod daemon-set-pnrn9 is not available
Jan 21 21:56:10.848: INFO: Wrong image for pod: daemon-set-mv2mj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 21:56:10.848: INFO: Wrong image for pod: daemon-set-pmm8g. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 21:56:10.848: INFO: Wrong image for pod: daemon-set-pnrn9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 21:56:10.848: INFO: Pod daemon-set-pnrn9 is not available
Jan 21 21:56:11.862: INFO: Wrong image for pod: daemon-set-mv2mj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 21:56:11.862: INFO: Wrong image for pod: daemon-set-pmm8g. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 21:56:11.862: INFO: Wrong image for pod: daemon-set-pnrn9. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 21:56:11.862: INFO: Pod daemon-set-pnrn9 is not available
Jan 21 21:56:12.848: INFO: Wrong image for pod: daemon-set-mv2mj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 21:56:12.848: INFO: Wrong image for pod: daemon-set-pmm8g. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 21:56:12.848: INFO: Pod daemon-set-pvvkm is not available
Jan 21 21:56:14.401: INFO: Wrong image for pod: daemon-set-mv2mj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 21:56:14.401: INFO: Wrong image for pod: daemon-set-pmm8g. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 21:56:14.401: INFO: Pod daemon-set-pvvkm is not available
Jan 21 21:56:14.848: INFO: Wrong image for pod: daemon-set-mv2mj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 21:56:14.848: INFO: Wrong image for pod: daemon-set-pmm8g. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 21:56:15.848: INFO: Wrong image for pod: daemon-set-mv2mj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 21:56:15.848: INFO: Wrong image for pod: daemon-set-pmm8g. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 21:56:16.848: INFO: Wrong image for pod: daemon-set-mv2mj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 21:56:16.848: INFO: Wrong image for pod: daemon-set-pmm8g. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 21:56:17.849: INFO: Wrong image for pod: daemon-set-mv2mj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 21:56:17.849: INFO: Wrong image for pod: daemon-set-pmm8g. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 21:56:18.848: INFO: Wrong image for pod: daemon-set-mv2mj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 21:56:18.848: INFO: Wrong image for pod: daemon-set-pmm8g. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 21:56:19.848: INFO: Wrong image for pod: daemon-set-mv2mj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 21:56:19.848: INFO: Wrong image for pod: daemon-set-pmm8g. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 21:56:20.849: INFO: Wrong image for pod: daemon-set-mv2mj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 21:56:20.849: INFO: Wrong image for pod: daemon-set-pmm8g. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 21:56:21.849: INFO: Wrong image for pod: daemon-set-mv2mj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 21:56:21.849: INFO: Wrong image for pod: daemon-set-pmm8g. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 21:56:22.848: INFO: Wrong image for pod: daemon-set-mv2mj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 21:56:22.848: INFO: Wrong image for pod: daemon-set-pmm8g. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 21:56:23.848: INFO: Wrong image for pod: daemon-set-mv2mj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 21:56:23.848: INFO: Wrong image for pod: daemon-set-pmm8g. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 21:56:24.848: INFO: Wrong image for pod: daemon-set-mv2mj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 21:56:24.848: INFO: Wrong image for pod: daemon-set-pmm8g. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 21:56:25.849: INFO: Wrong image for pod: daemon-set-mv2mj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 21:56:25.849: INFO: Wrong image for pod: daemon-set-pmm8g. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 21:56:26.848: INFO: Wrong image for pod: daemon-set-mv2mj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 21:56:26.848: INFO: Wrong image for pod: daemon-set-pmm8g. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 21:56:27.849: INFO: Wrong image for pod: daemon-set-mv2mj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 21:56:27.849: INFO: Wrong image for pod: daemon-set-pmm8g. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 21:56:28.850: INFO: Wrong image for pod: daemon-set-mv2mj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 21:56:28.850: INFO: Wrong image for pod: daemon-set-pmm8g. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 21:56:29.847: INFO: Wrong image for pod: daemon-set-mv2mj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 21:56:29.847: INFO: Wrong image for pod: daemon-set-pmm8g. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 21:56:30.848: INFO: Wrong image for pod: daemon-set-mv2mj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 21:56:30.848: INFO: Wrong image for pod: daemon-set-pmm8g. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 21:56:31.849: INFO: Wrong image for pod: daemon-set-mv2mj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 21:56:31.849: INFO: Wrong image for pod: daemon-set-pmm8g. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 21:56:32.849: INFO: Wrong image for pod: daemon-set-mv2mj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 21:56:32.849: INFO: Wrong image for pod: daemon-set-pmm8g. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 21:56:33.847: INFO: Wrong image for pod: daemon-set-mv2mj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 21:56:33.847: INFO: Wrong image for pod: daemon-set-pmm8g. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 21:56:34.848: INFO: Wrong image for pod: daemon-set-mv2mj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 21:56:34.848: INFO: Wrong image for pod: daemon-set-pmm8g. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 21:56:35.849: INFO: Wrong image for pod: daemon-set-mv2mj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 21:56:35.849: INFO: Wrong image for pod: daemon-set-pmm8g. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 21:56:36.848: INFO: Wrong image for pod: daemon-set-mv2mj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 21:56:36.848: INFO: Wrong image for pod: daemon-set-pmm8g. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 21:56:37.848: INFO: Wrong image for pod: daemon-set-mv2mj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 21:56:37.848: INFO: Wrong image for pod: daemon-set-pmm8g. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 21:56:38.847: INFO: Wrong image for pod: daemon-set-mv2mj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 21:56:38.847: INFO: Wrong image for pod: daemon-set-pmm8g. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 21:56:39.849: INFO: Wrong image for pod: daemon-set-mv2mj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 21:56:39.849: INFO: Wrong image for pod: daemon-set-pmm8g. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 21:56:40.850: INFO: Wrong image for pod: daemon-set-mv2mj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 21:56:40.850: INFO: Wrong image for pod: daemon-set-pmm8g. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 21:56:41.848: INFO: Wrong image for pod: daemon-set-mv2mj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 21:56:41.848: INFO: Wrong image for pod: daemon-set-pmm8g. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 21:56:42.848: INFO: Wrong image for pod: daemon-set-mv2mj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 21:56:42.848: INFO: Wrong image for pod: daemon-set-pmm8g. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 21:56:43.849: INFO: Wrong image for pod: daemon-set-mv2mj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 21:56:43.849: INFO: Wrong image for pod: daemon-set-pmm8g. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 21:56:44.849: INFO: Wrong image for pod: daemon-set-mv2mj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 21:56:44.849: INFO: Wrong image for pod: daemon-set-pmm8g. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 21:56:45.848: INFO: Wrong image for pod: daemon-set-mv2mj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 21:56:45.848: INFO: Pod daemon-set-mv2mj is not available
Jan 21 21:56:45.848: INFO: Wrong image for pod: daemon-set-pmm8g. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 21:56:46.848: INFO: Pod daemon-set-7vhgv is not available
Jan 21 21:56:46.848: INFO: Wrong image for pod: daemon-set-pmm8g. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 21:56:47.851: INFO: Pod daemon-set-7vhgv is not available
Jan 21 21:56:47.851: INFO: Wrong image for pod: daemon-set-pmm8g. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 21:56:48.848: INFO: Wrong image for pod: daemon-set-pmm8g. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 21:56:49.995: INFO: Wrong image for pod: daemon-set-pmm8g. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 21:56:50.848: INFO: Wrong image for pod: daemon-set-pmm8g. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 21:56:51.848: INFO: Wrong image for pod: daemon-set-pmm8g. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 21:56:52.849: INFO: Wrong image for pod: daemon-set-pmm8g. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 21:56:53.847: INFO: Wrong image for pod: daemon-set-pmm8g. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 21:56:54.850: INFO: Wrong image for pod: daemon-set-pmm8g. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 21:56:55.848: INFO: Wrong image for pod: daemon-set-pmm8g. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 21:56:56.850: INFO: Wrong image for pod: daemon-set-pmm8g. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 21:56:57.848: INFO: Wrong image for pod: daemon-set-pmm8g. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 21:56:58.848: INFO: Wrong image for pod: daemon-set-pmm8g. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 21:56:59.848: INFO: Wrong image for pod: daemon-set-pmm8g. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 21:57:00.848: INFO: Wrong image for pod: daemon-set-pmm8g. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 21:57:01.848: INFO: Wrong image for pod: daemon-set-pmm8g. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 21:57:02.849: INFO: Wrong image for pod: daemon-set-pmm8g. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 21:57:03.848: INFO: Wrong image for pod: daemon-set-pmm8g. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 21:57:04.848: INFO: Wrong image for pod: daemon-set-pmm8g. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 21:57:05.848: INFO: Wrong image for pod: daemon-set-pmm8g. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 21:57:06.847: INFO: Wrong image for pod: daemon-set-pmm8g. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 21:57:07.850: INFO: Wrong image for pod: daemon-set-pmm8g. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 21:57:08.848: INFO: Wrong image for pod: daemon-set-pmm8g. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 21:57:09.848: INFO: Wrong image for pod: daemon-set-pmm8g. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 21:57:10.849: INFO: Wrong image for pod: daemon-set-pmm8g. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 21:57:11.847: INFO: Wrong image for pod: daemon-set-pmm8g. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 21:57:12.848: INFO: Wrong image for pod: daemon-set-pmm8g. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 21:57:13.850: INFO: Wrong image for pod: daemon-set-pmm8g. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 21:57:14.848: INFO: Wrong image for pod: daemon-set-pmm8g. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 21:57:15.848: INFO: Wrong image for pod: daemon-set-pmm8g. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 21:57:16.848: INFO: Wrong image for pod: daemon-set-pmm8g. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 21:57:17.849: INFO: Wrong image for pod: daemon-set-pmm8g. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 21:57:18.849: INFO: Wrong image for pod: daemon-set-pmm8g. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 21:57:19.848: INFO: Wrong image for pod: daemon-set-pmm8g. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 21:57:19.848: INFO: Pod daemon-set-pmm8g is not available
Jan 21 21:57:20.848: INFO: Wrong image for pod: daemon-set-pmm8g. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 21:57:20.849: INFO: Pod daemon-set-pmm8g is not available
Jan 21 21:57:21.852: INFO: Wrong image for pod: daemon-set-pmm8g. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 21:57:21.853: INFO: Pod daemon-set-pmm8g is not available
Jan 21 21:57:22.848: INFO: Wrong image for pod: daemon-set-pmm8g. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 21:57:22.848: INFO: Pod daemon-set-pmm8g is not available
Jan 21 21:57:23.852: INFO: Wrong image for pod: daemon-set-pmm8g. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 21:57:23.852: INFO: Pod daemon-set-pmm8g is not available
Jan 21 21:57:25.117: INFO: Wrong image for pod: daemon-set-pmm8g. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Jan 21 21:57:25.117: INFO: Pod daemon-set-pmm8g is not available
Jan 21 21:57:25.856: INFO: Pod daemon-set-wgpwt is not available
STEP: Check that daemon pods are still running on every node of the cluster.
Jan 21 21:57:25.898: INFO: Number of nodes with available pods: 2
Jan 21 21:57:25.898: INFO: Node 10.191.28.39 is running more than one daemon pod
Jan 21 21:57:26.964: INFO: Number of nodes with available pods: 2
Jan 21 21:57:26.964: INFO: Node 10.191.28.39 is running more than one daemon pod
Jan 21 21:57:27.926: INFO: Number of nodes with available pods: 3
Jan 21 21:57:27.926: INFO: Number of running nodes: 3, number of available pods: 3
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:64
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting {extensions DaemonSet} daemon-set in namespace e2e-tests-daemonsets-2lrbn, will wait for the garbage collector to delete the pods
Jan 21 21:57:28.089: INFO: Deleting {extensions DaemonSet} daemon-set took: 26.790809ms
Jan 21 21:57:28.190: INFO: Terminating {extensions DaemonSet} daemon-set pods took: 100.369828ms
Jan 21 21:57:35.764: INFO: Number of nodes with available pods: 0
Jan 21 21:57:35.764: INFO: Number of running nodes: 0, number of available pods: 0
Jan 21 21:57:35.772: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-2lrbn/daemonsets","resourceVersion":"39396"},"items":null}

Jan 21 21:57:35.781: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-2lrbn/pods","resourceVersion":"39396"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 21:57:35.843: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-2lrbn" for this suite.
Jan 21 21:57:43.888: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 21:57:44.176: INFO: namespace: e2e-tests-daemonsets-2lrbn, resource: bindings, ignored listing per whitelist
Jan 21 21:57:44.338: INFO: namespace e2e-tests-daemonsets-2lrbn deletion completed in 8.482673763s

• [SLOW TEST:130.097 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] Projected 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 21:57:44.340: INFO: >>> kubeConfig: /tmp/kubeconfig-933165938
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-g57kj
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Jan 21 21:57:45.256: INFO: Waiting up to 5m0s for pod "downwardapi-volume-9551eab1-1dc7-11e9-8130-be6597f3ae53" in namespace "e2e-tests-projected-g57kj" to be "success or failure"
Jan 21 21:57:45.271: INFO: Pod "downwardapi-volume-9551eab1-1dc7-11e9-8130-be6597f3ae53": Phase="Pending", Reason="", readiness=false. Elapsed: 14.339467ms
Jan 21 21:57:47.553: INFO: Pod "downwardapi-volume-9551eab1-1dc7-11e9-8130-be6597f3ae53": Phase="Pending", Reason="", readiness=false. Elapsed: 2.296128541s
Jan 21 21:57:49.565: INFO: Pod "downwardapi-volume-9551eab1-1dc7-11e9-8130-be6597f3ae53": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.308103478s
STEP: Saw pod success
Jan 21 21:57:49.565: INFO: Pod "downwardapi-volume-9551eab1-1dc7-11e9-8130-be6597f3ae53" satisfied condition "success or failure"
Jan 21 21:57:49.577: INFO: Trying to get logs from node 10.191.28.39 pod downwardapi-volume-9551eab1-1dc7-11e9-8130-be6597f3ae53 container client-container: <nil>
STEP: delete the pod
Jan 21 21:57:49.665: INFO: Waiting for pod downwardapi-volume-9551eab1-1dc7-11e9-8130-be6597f3ae53 to disappear
Jan 21 21:57:49.678: INFO: Pod downwardapi-volume-9551eab1-1dc7-11e9-8130-be6597f3ae53 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 21:57:49.678: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-g57kj" for this suite.
Jan 21 21:57:55.727: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 21:57:55.849: INFO: namespace: e2e-tests-projected-g57kj, resource: bindings, ignored listing per whitelist
Jan 21 21:57:56.074: INFO: namespace e2e-tests-projected-g57kj deletion completed in 6.381082312s

• [SLOW TEST:11.734 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 21:57:56.074: INFO: >>> kubeConfig: /tmp/kubeconfig-933165938
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-zd69g
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Jan 21 21:57:56.438: INFO: Waiting up to 5m0s for pod "downwardapi-volume-9bfc2a0f-1dc7-11e9-8130-be6597f3ae53" in namespace "e2e-tests-projected-zd69g" to be "success or failure"
Jan 21 21:57:56.448: INFO: Pod "downwardapi-volume-9bfc2a0f-1dc7-11e9-8130-be6597f3ae53": Phase="Pending", Reason="", readiness=false. Elapsed: 10.496934ms
Jan 21 21:57:58.477: INFO: Pod "downwardapi-volume-9bfc2a0f-1dc7-11e9-8130-be6597f3ae53": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.03947775s
STEP: Saw pod success
Jan 21 21:57:58.478: INFO: Pod "downwardapi-volume-9bfc2a0f-1dc7-11e9-8130-be6597f3ae53" satisfied condition "success or failure"
Jan 21 21:57:58.488: INFO: Trying to get logs from node 10.191.28.59 pod downwardapi-volume-9bfc2a0f-1dc7-11e9-8130-be6597f3ae53 container client-container: <nil>
STEP: delete the pod
Jan 21 21:57:58.553: INFO: Waiting for pod downwardapi-volume-9bfc2a0f-1dc7-11e9-8130-be6597f3ae53 to disappear
Jan 21 21:57:58.565: INFO: Pod downwardapi-volume-9bfc2a0f-1dc7-11e9-8130-be6597f3ae53 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 21:57:58.565: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-zd69g" for this suite.
Jan 21 21:58:04.616: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 21:58:04.961: INFO: namespace: e2e-tests-projected-zd69g, resource: bindings, ignored listing per whitelist
Jan 21 21:58:05.293: INFO: namespace e2e-tests-projected-zd69g deletion completed in 6.712216624s

• [SLOW TEST:9.219 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 21:58:05.295: INFO: >>> kubeConfig: /tmp/kubeconfig-933165938
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-cjth4
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name cm-test-opt-del-a17a042f-1dc7-11e9-8130-be6597f3ae53
STEP: Creating configMap with name cm-test-opt-upd-a17a04b3-1dc7-11e9-8130-be6597f3ae53
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-a17a042f-1dc7-11e9-8130-be6597f3ae53
STEP: Updating configmap cm-test-opt-upd-a17a04b3-1dc7-11e9-8130-be6597f3ae53
STEP: Creating configMap with name cm-test-opt-create-a17a04f2-1dc7-11e9-8130-be6597f3ae53
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 21:58:09.939: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-cjth4" for this suite.
Jan 21 21:58:33.997: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 21:58:34.221: INFO: namespace: e2e-tests-projected-cjth4, resource: bindings, ignored listing per whitelist
Jan 21 21:58:34.452: INFO: namespace e2e-tests-projected-cjth4 deletion completed in 24.49576983s

• [SLOW TEST:29.158 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl label 
  should update the label on a resource  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 21:58:34.453: INFO: >>> kubeConfig: /tmp/kubeconfig-933165938
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-vksgq
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Kubectl label
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1042
STEP: creating the pod
Jan 21 21:58:34.915: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-933165938 create -f - --namespace=e2e-tests-kubectl-vksgq'
Jan 21 21:58:35.347: INFO: stderr: ""
Jan 21 21:58:35.347: INFO: stdout: "pod/pause created\n"
Jan 21 21:58:35.347: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [pause]
Jan 21 21:58:35.347: INFO: Waiting up to 5m0s for pod "pause" in namespace "e2e-tests-kubectl-vksgq" to be "running and ready"
Jan 21 21:58:35.359: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 11.666395ms
Jan 21 21:58:37.369: INFO: Pod "pause": Phase="Running", Reason="", readiness=true. Elapsed: 2.022216941s
Jan 21 21:58:37.369: INFO: Pod "pause" satisfied condition "running and ready"
Jan 21 21:58:37.369: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [pause]
[It] should update the label on a resource  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: adding the label testing-label with value testing-label-value to a pod
Jan 21 21:58:37.370: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-933165938 label pods pause testing-label=testing-label-value --namespace=e2e-tests-kubectl-vksgq'
Jan 21 21:58:37.595: INFO: stderr: ""
Jan 21 21:58:37.595: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod has the label testing-label with the value testing-label-value
Jan 21 21:58:37.595: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-933165938 get pod pause -L testing-label --namespace=e2e-tests-kubectl-vksgq'
Jan 21 21:58:37.800: INFO: stderr: ""
Jan 21 21:58:37.800: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          2s    testing-label-value\n"
STEP: removing the label testing-label of a pod
Jan 21 21:58:37.800: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-933165938 label pods pause testing-label- --namespace=e2e-tests-kubectl-vksgq'
Jan 21 21:58:38.000: INFO: stderr: ""
Jan 21 21:58:38.000: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod doesn't have the label testing-label
Jan 21 21:58:38.000: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-933165938 get pod pause -L testing-label --namespace=e2e-tests-kubectl-vksgq'
Jan 21 21:58:38.204: INFO: stderr: ""
Jan 21 21:58:38.204: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          3s    \n"
[AfterEach] [k8s.io] Kubectl label
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1048
STEP: using delete to clean up resources
Jan 21 21:58:38.204: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-933165938 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-vksgq'
Jan 21 21:58:38.416: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Jan 21 21:58:38.416: INFO: stdout: "pod \"pause\" force deleted\n"
Jan 21 21:58:38.417: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-933165938 get rc,svc -l name=pause --no-headers --namespace=e2e-tests-kubectl-vksgq'
Jan 21 21:58:38.678: INFO: stderr: "No resources found.\n"
Jan 21 21:58:38.678: INFO: stdout: ""
Jan 21 21:58:38.678: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-933165938 get pods -l name=pause --namespace=e2e-tests-kubectl-vksgq -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Jan 21 21:58:38.850: INFO: stderr: ""
Jan 21 21:58:38.850: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 21:58:38.850: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-vksgq" for this suite.
Jan 21 21:58:44.898: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 21:58:45.213: INFO: namespace: e2e-tests-kubectl-vksgq, resource: bindings, ignored listing per whitelist
Jan 21 21:58:45.286: INFO: namespace e2e-tests-kubectl-vksgq deletion completed in 6.419520254s

• [SLOW TEST:10.833 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl label
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should update the label on a resource  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 21:58:45.289: INFO: >>> kubeConfig: /tmp/kubeconfig-933165938
STEP: Building a namespace api object, basename var-expansion
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-var-expansion-kdgrc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test substitution in container's args
Jan 21 21:58:45.680: INFO: Waiting up to 5m0s for pod "var-expansion-b9559daa-1dc7-11e9-8130-be6597f3ae53" in namespace "e2e-tests-var-expansion-kdgrc" to be "success or failure"
Jan 21 21:58:45.690: INFO: Pod "var-expansion-b9559daa-1dc7-11e9-8130-be6597f3ae53": Phase="Pending", Reason="", readiness=false. Elapsed: 9.785207ms
Jan 21 21:58:47.702: INFO: Pod "var-expansion-b9559daa-1dc7-11e9-8130-be6597f3ae53": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.022109992s
STEP: Saw pod success
Jan 21 21:58:47.702: INFO: Pod "var-expansion-b9559daa-1dc7-11e9-8130-be6597f3ae53" satisfied condition "success or failure"
Jan 21 21:58:47.714: INFO: Trying to get logs from node 10.191.28.59 pod var-expansion-b9559daa-1dc7-11e9-8130-be6597f3ae53 container dapi-container: <nil>
STEP: delete the pod
Jan 21 21:58:47.835: INFO: Waiting for pod var-expansion-b9559daa-1dc7-11e9-8130-be6597f3ae53 to disappear
Jan 21 21:58:47.846: INFO: Pod var-expansion-b9559daa-1dc7-11e9-8130-be6597f3ae53 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 21:58:47.846: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-var-expansion-kdgrc" for this suite.
Jan 21 21:58:53.899: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 21:58:54.020: INFO: namespace: e2e-tests-var-expansion-kdgrc, resource: bindings, ignored listing per whitelist
Jan 21 21:58:54.288: INFO: namespace e2e-tests-var-expansion-kdgrc deletion completed in 6.425084998s

• [SLOW TEST:8.999 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] Projected 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 21:58:54.288: INFO: >>> kubeConfig: /tmp/kubeconfig-933165938
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-8vl24
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating the pod
Jan 21 21:58:57.290: INFO: Successfully updated pod "annotationupdatebeb06292-1dc7-11e9-8130-be6597f3ae53"
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 21:59:01.365: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-8vl24" for this suite.
Jan 21 21:59:21.483: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 21:59:21.720: INFO: namespace: e2e-tests-projected-8vl24, resource: bindings, ignored listing per whitelist
Jan 21 21:59:21.868: INFO: namespace e2e-tests-projected-8vl24 deletion completed in 20.488047815s

• [SLOW TEST:27.580 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Guestbook application 
  should create and stop a working application  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 21:59:21.870: INFO: >>> kubeConfig: /tmp/kubeconfig-933165938
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-25rp9
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should create and stop a working application  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating all guestbook components
Jan 21 21:59:22.257: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-slave
  labels:
    app: redis
    role: slave
    tier: backend
spec:
  ports:
  - port: 6379
  selector:
    app: redis
    role: slave
    tier: backend

Jan 21 21:59:22.257: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-933165938 create -f - --namespace=e2e-tests-kubectl-25rp9'
Jan 21 21:59:22.645: INFO: stderr: ""
Jan 21 21:59:22.645: INFO: stdout: "service/redis-slave created\n"
Jan 21 21:59:22.645: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-master
  labels:
    app: redis
    role: master
    tier: backend
spec:
  ports:
  - port: 6379
    targetPort: 6379
  selector:
    app: redis
    role: master
    tier: backend

Jan 21 21:59:22.645: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-933165938 create -f - --namespace=e2e-tests-kubectl-25rp9'
Jan 21 21:59:23.076: INFO: stderr: ""
Jan 21 21:59:23.076: INFO: stdout: "service/redis-master created\n"
Jan 21 21:59:23.077: INFO: apiVersion: v1
kind: Service
metadata:
  name: frontend
  labels:
    app: guestbook
    tier: frontend
spec:
  # if your cluster supports it, uncomment the following to automatically create
  # an external load-balanced IP for the frontend service.
  # type: LoadBalancer
  ports:
  - port: 80
  selector:
    app: guestbook
    tier: frontend

Jan 21 21:59:23.077: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-933165938 create -f - --namespace=e2e-tests-kubectl-25rp9'
Jan 21 21:59:23.492: INFO: stderr: ""
Jan 21 21:59:23.492: INFO: stdout: "service/frontend created\n"
Jan 21 21:59:23.492: INFO: apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: frontend
spec:
  replicas: 3
  template:
    metadata:
      labels:
        app: guestbook
        tier: frontend
    spec:
      containers:
      - name: php-redis
        image: gcr.io/google-samples/gb-frontend:v6
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access environment variables to find service host
          # info, comment out the 'value: dns' line above, and uncomment the
          # line below:
          # value: env
        ports:
        - containerPort: 80

Jan 21 21:59:23.492: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-933165938 create -f - --namespace=e2e-tests-kubectl-25rp9'
Jan 21 21:59:23.873: INFO: stderr: ""
Jan 21 21:59:23.873: INFO: stdout: "deployment.extensions/frontend created\n"
Jan 21 21:59:23.873: INFO: apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: redis-master
spec:
  replicas: 1
  template:
    metadata:
      labels:
        app: redis
        role: master
        tier: backend
    spec:
      containers:
      - name: master
        image: gcr.io/kubernetes-e2e-test-images/redis:1.0
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        ports:
        - containerPort: 6379

Jan 21 21:59:23.873: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-933165938 create -f - --namespace=e2e-tests-kubectl-25rp9'
Jan 21 21:59:24.201: INFO: stderr: ""
Jan 21 21:59:24.202: INFO: stdout: "deployment.extensions/redis-master created\n"
Jan 21 21:59:24.202: INFO: apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: redis-slave
spec:
  replicas: 2
  template:
    metadata:
      labels:
        app: redis
        role: slave
        tier: backend
    spec:
      containers:
      - name: slave
        image: gcr.io/google-samples/gb-redisslave:v3
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access an environment variable to find the master
          # service's host, comment out the 'value: dns' line above, and
          # uncomment the line below:
          # value: env
        ports:
        - containerPort: 6379

Jan 21 21:59:24.202: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-933165938 create -f - --namespace=e2e-tests-kubectl-25rp9'
Jan 21 21:59:24.564: INFO: stderr: ""
Jan 21 21:59:24.564: INFO: stdout: "deployment.extensions/redis-slave created\n"
STEP: validating guestbook app
Jan 21 21:59:24.564: INFO: Waiting for all frontend pods to be Running.
Jan 21 21:59:29.615: INFO: Waiting for frontend to serve content.
Jan 21 21:59:29.648: INFO: Trying to add a new entry to the guestbook.
Jan 21 21:59:29.671: INFO: Verifying that added entry can be retrieved.
Jan 21 21:59:29.708: INFO: Failed to get response from guestbook. err: <nil>, response: {"data": ""}
STEP: using delete to clean up resources
Jan 21 21:59:34.795: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-933165938 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-25rp9'
Jan 21 21:59:35.016: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Jan 21 21:59:35.017: INFO: stdout: "service \"redis-slave\" force deleted\n"
STEP: using delete to clean up resources
Jan 21 21:59:35.017: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-933165938 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-25rp9'
Jan 21 21:59:35.277: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Jan 21 21:59:35.277: INFO: stdout: "service \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
Jan 21 21:59:35.277: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-933165938 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-25rp9'
Jan 21 21:59:35.508: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Jan 21 21:59:35.508: INFO: stdout: "service \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Jan 21 21:59:35.508: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-933165938 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-25rp9'
Jan 21 21:59:35.699: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Jan 21 21:59:35.699: INFO: stdout: "deployment.extensions \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Jan 21 21:59:35.700: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-933165938 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-25rp9'
Jan 21 21:59:36.434: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Jan 21 21:59:36.434: INFO: stdout: "deployment.extensions \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
Jan 21 21:59:36.434: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-933165938 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-25rp9'
Jan 21 21:59:36.722: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Jan 21 21:59:36.722: INFO: stdout: "deployment.extensions \"redis-slave\" force deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 21:59:36.722: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-25rp9" for this suite.
Jan 21 22:00:18.777: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 22:00:18.934: INFO: namespace: e2e-tests-kubectl-25rp9, resource: bindings, ignored listing per whitelist
Jan 21 22:00:19.233: INFO: namespace e2e-tests-kubectl-25rp9 deletion completed in 42.496299019s

• [SLOW TEST:57.364 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Guestbook application
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create and stop a working application  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 22:00:19.236: INFO: >>> kubeConfig: /tmp/kubeconfig-933165938
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-watch-s7sbf
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: modifying the configmap a second time
STEP: deleting the configmap
STEP: creating a watch on configmaps from the resource version returned by the first update
STEP: Expecting to observe notifications for all changes to the configmap after the first update
Jan 21 22:00:19.726: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-resource-version,GenerateName:,Namespace:e2e-tests-watch-s7sbf,SelfLink:/api/v1/namespaces/e2e-tests-watch-s7sbf/configmaps/e2e-watch-test-resource-version,UID:f15ce012-1dc7-11e9-903f-ee5d7ad9296f,ResourceVersion:40242,Generation:0,CreationTimestamp:2019-01-21 22:00:19 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: from-resource-version,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Jan 21 22:00:19.726: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-resource-version,GenerateName:,Namespace:e2e-tests-watch-s7sbf,SelfLink:/api/v1/namespaces/e2e-tests-watch-s7sbf/configmaps/e2e-watch-test-resource-version,UID:f15ce012-1dc7-11e9-903f-ee5d7ad9296f,ResourceVersion:40243,Generation:0,CreationTimestamp:2019-01-21 22:00:19 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: from-resource-version,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 22:00:19.727: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-s7sbf" for this suite.
Jan 21 22:00:25.775: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 22:00:26.070: INFO: namespace: e2e-tests-watch-s7sbf, resource: bindings, ignored listing per whitelist
Jan 21 22:00:26.380: INFO: namespace e2e-tests-watch-s7sbf deletion completed in 6.640541658s

• [SLOW TEST:7.144 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with projected pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 22:00:26.381: INFO: >>> kubeConfig: /tmp/kubeconfig-933165938
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-subpath-kx26n
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with projected pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-projected-7k7v
STEP: Creating a pod to test atomic-volume-subpath
Jan 21 22:00:26.960: INFO: Waiting up to 5m0s for pod "pod-subpath-test-projected-7k7v" in namespace "e2e-tests-subpath-kx26n" to be "success or failure"
Jan 21 22:00:27.064: INFO: Pod "pod-subpath-test-projected-7k7v": Phase="Pending", Reason="", readiness=false. Elapsed: 103.299468ms
Jan 21 22:00:29.087: INFO: Pod "pod-subpath-test-projected-7k7v": Phase="Pending", Reason="", readiness=false. Elapsed: 2.126891977s
Jan 21 22:00:31.102: INFO: Pod "pod-subpath-test-projected-7k7v": Phase="Running", Reason="", readiness=false. Elapsed: 4.141209119s
Jan 21 22:00:33.112: INFO: Pod "pod-subpath-test-projected-7k7v": Phase="Running", Reason="", readiness=false. Elapsed: 6.151765349s
Jan 21 22:00:35.124: INFO: Pod "pod-subpath-test-projected-7k7v": Phase="Running", Reason="", readiness=false. Elapsed: 8.163886649s
Jan 21 22:00:37.135: INFO: Pod "pod-subpath-test-projected-7k7v": Phase="Running", Reason="", readiness=false. Elapsed: 10.174818466s
Jan 21 22:00:39.153: INFO: Pod "pod-subpath-test-projected-7k7v": Phase="Running", Reason="", readiness=false. Elapsed: 12.192795636s
Jan 21 22:00:41.175: INFO: Pod "pod-subpath-test-projected-7k7v": Phase="Running", Reason="", readiness=false. Elapsed: 14.214766169s
Jan 21 22:00:43.187: INFO: Pod "pod-subpath-test-projected-7k7v": Phase="Running", Reason="", readiness=false. Elapsed: 16.225989017s
Jan 21 22:00:45.198: INFO: Pod "pod-subpath-test-projected-7k7v": Phase="Running", Reason="", readiness=false. Elapsed: 18.237589731s
Jan 21 22:00:47.209: INFO: Pod "pod-subpath-test-projected-7k7v": Phase="Running", Reason="", readiness=false. Elapsed: 20.248074215s
Jan 21 22:00:49.221: INFO: Pod "pod-subpath-test-projected-7k7v": Phase="Running", Reason="", readiness=false. Elapsed: 22.260030947s
Jan 21 22:00:51.232: INFO: Pod "pod-subpath-test-projected-7k7v": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.271393693s
STEP: Saw pod success
Jan 21 22:00:51.232: INFO: Pod "pod-subpath-test-projected-7k7v" satisfied condition "success or failure"
Jan 21 22:00:51.247: INFO: Trying to get logs from node 10.191.28.39 pod pod-subpath-test-projected-7k7v container test-container-subpath-projected-7k7v: <nil>
STEP: delete the pod
Jan 21 22:00:51.307: INFO: Waiting for pod pod-subpath-test-projected-7k7v to disappear
Jan 21 22:00:51.317: INFO: Pod pod-subpath-test-projected-7k7v no longer exists
STEP: Deleting pod pod-subpath-test-projected-7k7v
Jan 21 22:00:51.317: INFO: Deleting pod "pod-subpath-test-projected-7k7v" in namespace "e2e-tests-subpath-kx26n"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 22:00:51.328: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-kx26n" for this suite.
Jan 21 22:00:57.375: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 22:00:57.572: INFO: namespace: e2e-tests-subpath-kx26n, resource: bindings, ignored listing per whitelist
Jan 21 22:00:57.862: INFO: namespace e2e-tests-subpath-kx26n deletion completed in 6.520859602s

• [SLOW TEST:31.481 seconds]
[sig-storage] Subpath
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with projected pod [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 22:00:57.863: INFO: >>> kubeConfig: /tmp/kubeconfig-933165938
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-deployment-27qwg
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Jan 21 22:00:58.290: INFO: Creating deployment "test-recreate-deployment"
Jan 21 22:00:58.373: INFO: Waiting deployment "test-recreate-deployment" to be updated to revision 1
Jan 21 22:00:58.390: INFO: new replicaset for deployment "test-recreate-deployment" is yet to be created
Jan 21 22:01:00.409: INFO: Waiting deployment "test-recreate-deployment" to complete
Jan 21 22:01:00.417: INFO: Triggering a new rollout for deployment "test-recreate-deployment"
Jan 21 22:01:00.481: INFO: Updating deployment test-recreate-deployment
Jan 21 22:01:00.481: INFO: Watching deployment "test-recreate-deployment" to verify that new pods will not run with olds pods
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Jan 21 22:01:00.614: INFO: Deployment "test-recreate-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment,GenerateName:,Namespace:e2e-tests-deployment-27qwg,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-27qwg/deployments/test-recreate-deployment,UID:086e607f-1dc8-11e9-903f-ee5d7ad9296f,ResourceVersion:40422,Generation:2,CreationTimestamp:2019-01-21 22:00:58 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},Strategy:DeploymentStrategy{Type:Recreate,RollingUpdate:nil,},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:0,UnavailableReplicas:1,Conditions:[{Available False 2019-01-21 22:01:00 +0000 UTC 2019-01-21 22:01:00 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.} {Progressing True 2019-01-21 22:01:00 +0000 UTC 2019-01-21 22:00:58 +0000 UTC ReplicaSetUpdated ReplicaSet "test-recreate-deployment-7cf749666b" is progressing.}],ReadyReplicas:0,CollisionCount:nil,},}

Jan 21 22:01:00.625: INFO: New ReplicaSet "test-recreate-deployment-7cf749666b" of Deployment "test-recreate-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-7cf749666b,GenerateName:,Namespace:e2e-tests-deployment-27qwg,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-27qwg/replicasets/test-recreate-deployment-7cf749666b,UID:09baf00e-1dc8-11e9-903f-ee5d7ad9296f,ResourceVersion:40420,Generation:1,CreationTimestamp:2019-01-21 22:01:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 7cf749666b,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 1,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment test-recreate-deployment 086e607f-1dc8-11e9-903f-ee5d7ad9296f 0xc421843017 0xc421843018}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 7cf749666b,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 7cf749666b,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Jan 21 22:01:00.625: INFO: All old ReplicaSets of Deployment "test-recreate-deployment":
Jan 21 22:01:00.626: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-79f694ff59,GenerateName:,Namespace:e2e-tests-deployment-27qwg,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-27qwg/replicasets/test-recreate-deployment-79f694ff59,UID:087262dc-1dc8-11e9-903f-ee5d7ad9296f,ResourceVersion:40410,Generation:2,CreationTimestamp:2019-01-21 22:00:58 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 79f694ff59,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 1,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-recreate-deployment 086e607f-1dc8-11e9-903f-ee5d7ad9296f 0xc421842e97 0xc421842e98}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 79f694ff59,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 79f694ff59,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Jan 21 22:01:00.637: INFO: Pod "test-recreate-deployment-7cf749666b-pz5t6" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-7cf749666b-pz5t6,GenerateName:test-recreate-deployment-7cf749666b-,Namespace:e2e-tests-deployment-27qwg,SelfLink:/api/v1/namespaces/e2e-tests-deployment-27qwg/pods/test-recreate-deployment-7cf749666b-pz5t6,UID:09bd2c8b-1dc8-11e9-903f-ee5d7ad9296f,ResourceVersion:40417,Generation:0,CreationTimestamp:2019-01-21 22:01:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 7cf749666b,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet test-recreate-deployment-7cf749666b 09baf00e-1dc8-11e9-903f-ee5d7ad9296f 0xc4211d8547 0xc4211d8548}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-dznqm {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-dznqm,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-dznqm true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.191.28.39,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc4211d8680} {node.kubernetes.io/unreachable Exists  NoExecute 0xc4211d86b0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-21 22:01:00 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 22:01:00.637: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-27qwg" for this suite.
Jan 21 22:01:06.689: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 22:01:06.807: INFO: namespace: e2e-tests-deployment-27qwg, resource: bindings, ignored listing per whitelist
Jan 21 22:01:07.090: INFO: namespace e2e-tests-deployment-27qwg deletion completed in 6.438243745s

• [SLOW TEST:9.227 seconds]
[sig-apps] Deployment
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 22:01:07.095: INFO: >>> kubeConfig: /tmp/kubeconfig-933165938
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-container-probe-vbht9
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 22:02:07.440: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-vbht9" for this suite.
Jan 21 22:02:31.490: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 22:02:31.588: INFO: namespace: e2e-tests-container-probe-vbht9, resource: bindings, ignored listing per whitelist
Jan 21 22:02:31.872: INFO: namespace e2e-tests-container-probe-vbht9 deletion completed in 24.417960287s

• [SLOW TEST:84.777 seconds]
[k8s.io] Probing container
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-storage] Projected 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 22:02:31.873: INFO: >>> kubeConfig: /tmp/kubeconfig-933165938
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-5wcjx
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Jan 21 22:02:32.222: INFO: Waiting up to 5m0s for pod "downwardapi-volume-405d24fd-1dc8-11e9-8130-be6597f3ae53" in namespace "e2e-tests-projected-5wcjx" to be "success or failure"
Jan 21 22:02:32.234: INFO: Pod "downwardapi-volume-405d24fd-1dc8-11e9-8130-be6597f3ae53": Phase="Pending", Reason="", readiness=false. Elapsed: 11.359169ms
Jan 21 22:02:34.245: INFO: Pod "downwardapi-volume-405d24fd-1dc8-11e9-8130-be6597f3ae53": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.022757168s
STEP: Saw pod success
Jan 21 22:02:34.245: INFO: Pod "downwardapi-volume-405d24fd-1dc8-11e9-8130-be6597f3ae53" satisfied condition "success or failure"
Jan 21 22:02:34.256: INFO: Trying to get logs from node 10.191.28.59 pod downwardapi-volume-405d24fd-1dc8-11e9-8130-be6597f3ae53 container client-container: <nil>
STEP: delete the pod
Jan 21 22:02:34.326: INFO: Waiting for pod downwardapi-volume-405d24fd-1dc8-11e9-8130-be6597f3ae53 to disappear
Jan 21 22:02:34.336: INFO: Pod downwardapi-volume-405d24fd-1dc8-11e9-8130-be6597f3ae53 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 22:02:34.336: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-5wcjx" for this suite.
Jan 21 22:02:40.393: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 22:02:40.647: INFO: namespace: e2e-tests-projected-5wcjx, resource: bindings, ignored listing per whitelist
Jan 21 22:02:40.786: INFO: namespace e2e-tests-projected-5wcjx deletion completed in 6.435550842s

• [SLOW TEST:8.913 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-network] Services 
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 22:02:40.786: INFO: >>> kubeConfig: /tmp/kubeconfig-933165938
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-services-tm892
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:83
[It] should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating service endpoint-test2 in namespace e2e-tests-services-tm892
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-tm892 to expose endpoints map[]
Jan 21 22:02:41.142: INFO: Get endpoints failed (8.781309ms elapsed, ignoring for 5s): endpoints "endpoint-test2" not found
Jan 21 22:02:42.150: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-tm892 exposes endpoints map[] (1.017090624s elapsed)
STEP: Creating pod pod1 in namespace e2e-tests-services-tm892
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-tm892 to expose endpoints map[pod1:[80]]
Jan 21 22:02:43.283: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-tm892 exposes endpoints map[pod1:[80]] (1.114575853s elapsed)
STEP: Creating pod pod2 in namespace e2e-tests-services-tm892
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-tm892 to expose endpoints map[pod1:[80] pod2:[80]]
Jan 21 22:02:45.393: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-tm892 exposes endpoints map[pod1:[80] pod2:[80]] (2.090460884s elapsed)
STEP: Deleting pod pod1 in namespace e2e-tests-services-tm892
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-tm892 to expose endpoints map[pod2:[80]]
Jan 21 22:02:46.530: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-tm892 exposes endpoints map[pod2:[80]] (1.040346947s elapsed)
STEP: Deleting pod pod2 in namespace e2e-tests-services-tm892
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-tm892 to expose endpoints map[]
Jan 21 22:02:46.558: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-tm892 exposes endpoints map[] (7.506392ms elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 22:02:46.611: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-services-tm892" for this suite.
Jan 21 22:03:10.662: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 22:03:10.938: INFO: namespace: e2e-tests-services-tm892, resource: bindings, ignored listing per whitelist
Jan 21 22:03:11.073: INFO: namespace e2e-tests-services-tm892 deletion completed in 24.448533923s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:88

• [SLOW TEST:30.287 seconds]
[sig-network] Services
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 22:03:11.075: INFO: >>> kubeConfig: /tmp/kubeconfig-933165938
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-rcdr6
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0777 on tmpfs
Jan 21 22:03:11.479: INFO: Waiting up to 5m0s for pod "pod-57c3439d-1dc8-11e9-8130-be6597f3ae53" in namespace "e2e-tests-emptydir-rcdr6" to be "success or failure"
Jan 21 22:03:11.514: INFO: Pod "pod-57c3439d-1dc8-11e9-8130-be6597f3ae53": Phase="Pending", Reason="", readiness=false. Elapsed: 35.392267ms
Jan 21 22:03:13.530: INFO: Pod "pod-57c3439d-1dc8-11e9-8130-be6597f3ae53": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.051124968s
STEP: Saw pod success
Jan 21 22:03:13.530: INFO: Pod "pod-57c3439d-1dc8-11e9-8130-be6597f3ae53" satisfied condition "success or failure"
Jan 21 22:03:13.540: INFO: Trying to get logs from node 10.191.28.59 pod pod-57c3439d-1dc8-11e9-8130-be6597f3ae53 container test-container: <nil>
STEP: delete the pod
Jan 21 22:03:13.603: INFO: Waiting for pod pod-57c3439d-1dc8-11e9-8130-be6597f3ae53 to disappear
Jan 21 22:03:13.613: INFO: Pod pod-57c3439d-1dc8-11e9-8130-be6597f3ae53 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 22:03:13.613: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-rcdr6" for this suite.
Jan 21 22:03:19.661: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 22:03:19.850: INFO: namespace: e2e-tests-emptydir-rcdr6, resource: bindings, ignored listing per whitelist
Jan 21 22:03:20.051: INFO: namespace e2e-tests-emptydir-rcdr6 deletion completed in 6.425416301s

• [SLOW TEST:8.976 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-api-machinery] Downward API 
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 22:03:20.051: INFO: >>> kubeConfig: /tmp/kubeconfig-933165938
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-9l2bw
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Jan 21 22:03:20.660: INFO: Waiting up to 5m0s for pod "downward-api-5d3a0aa2-1dc8-11e9-8130-be6597f3ae53" in namespace "e2e-tests-downward-api-9l2bw" to be "success or failure"
Jan 21 22:03:20.683: INFO: Pod "downward-api-5d3a0aa2-1dc8-11e9-8130-be6597f3ae53": Phase="Pending", Reason="", readiness=false. Elapsed: 22.637068ms
Jan 21 22:03:22.694: INFO: Pod "downward-api-5d3a0aa2-1dc8-11e9-8130-be6597f3ae53": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.034050246s
STEP: Saw pod success
Jan 21 22:03:22.694: INFO: Pod "downward-api-5d3a0aa2-1dc8-11e9-8130-be6597f3ae53" satisfied condition "success or failure"
Jan 21 22:03:22.705: INFO: Trying to get logs from node 10.191.28.59 pod downward-api-5d3a0aa2-1dc8-11e9-8130-be6597f3ae53 container dapi-container: <nil>
STEP: delete the pod
Jan 21 22:03:22.762: INFO: Waiting for pod downward-api-5d3a0aa2-1dc8-11e9-8130-be6597f3ae53 to disappear
Jan 21 22:03:22.774: INFO: Pod downward-api-5d3a0aa2-1dc8-11e9-8130-be6597f3ae53 no longer exists
[AfterEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 22:03:22.775: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-9l2bw" for this suite.
Jan 21 22:03:28.826: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 22:03:28.972: INFO: namespace: e2e-tests-downward-api-9l2bw, resource: bindings, ignored listing per whitelist
Jan 21 22:03:29.212: INFO: namespace e2e-tests-downward-api-9l2bw deletion completed in 6.422086785s

• [SLOW TEST:9.161 seconds]
[sig-api-machinery] Downward API
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 22:03:29.213: INFO: >>> kubeConfig: /tmp/kubeconfig-933165938
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-k5rt5
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-628ce13f-1dc8-11e9-8130-be6597f3ae53
STEP: Creating a pod to test consume configMaps
Jan 21 22:03:29.584: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-628e488d-1dc8-11e9-8130-be6597f3ae53" in namespace "e2e-tests-projected-k5rt5" to be "success or failure"
Jan 21 22:03:29.593: INFO: Pod "pod-projected-configmaps-628e488d-1dc8-11e9-8130-be6597f3ae53": Phase="Pending", Reason="", readiness=false. Elapsed: 8.795257ms
Jan 21 22:03:32.085: INFO: Pod "pod-projected-configmaps-628e488d-1dc8-11e9-8130-be6597f3ae53": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.501440213s
STEP: Saw pod success
Jan 21 22:03:32.085: INFO: Pod "pod-projected-configmaps-628e488d-1dc8-11e9-8130-be6597f3ae53" satisfied condition "success or failure"
Jan 21 22:03:32.166: INFO: Trying to get logs from node 10.191.28.59 pod pod-projected-configmaps-628e488d-1dc8-11e9-8130-be6597f3ae53 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Jan 21 22:03:32.222: INFO: Waiting for pod pod-projected-configmaps-628e488d-1dc8-11e9-8130-be6597f3ae53 to disappear
Jan 21 22:03:32.245: INFO: Pod pod-projected-configmaps-628e488d-1dc8-11e9-8130-be6597f3ae53 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 22:03:32.245: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-k5rt5" for this suite.
Jan 21 22:03:38.303: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 22:03:38.521: INFO: namespace: e2e-tests-projected-k5rt5, resource: bindings, ignored listing per whitelist
Jan 21 22:03:38.708: INFO: namespace e2e-tests-projected-k5rt5 deletion completed in 6.448049066s

• [SLOW TEST:9.495 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 22:03:38.711: INFO: >>> kubeConfig: /tmp/kubeconfig-933165938
STEP: Building a namespace api object, basename init-container
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-init-container-7f247
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
Jan 21 22:03:39.430: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 22:03:42.556: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-init-container-7f247" for this suite.
Jan 21 22:03:48.685: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 22:03:48.833: INFO: namespace: e2e-tests-init-container-7f247, resource: bindings, ignored listing per whitelist
Jan 21 22:03:49.108: INFO: namespace e2e-tests-init-container-7f247 deletion completed in 6.539197578s

• [SLOW TEST:10.397 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 22:03:49.108: INFO: >>> kubeConfig: /tmp/kubeconfig-933165938
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-statefulset-mkbwz
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-mkbwz
[It] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Initializing watcher for selector baz=blah,foo=bar
STEP: Creating stateful set ss in namespace e2e-tests-statefulset-mkbwz
STEP: Waiting until all stateful set ss replicas will be running in namespace e2e-tests-statefulset-mkbwz
Jan 21 22:03:49.516: INFO: Found 0 stateful pods, waiting for 1
Jan 21 22:03:59.529: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will halt with unhealthy stateful pod
Jan 21 22:03:59.539: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-933165938 exec --namespace=e2e-tests-statefulset-mkbwz ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Jan 21 22:03:59.944: INFO: stderr: ""
Jan 21 22:03:59.944: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Jan 21 22:03:59.944: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Jan 21 22:03:59.973: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Jan 21 22:04:10.000: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Jan 21 22:04:10.000: INFO: Waiting for statefulset status.replicas updated to 0
Jan 21 22:04:10.086: INFO: Verifying statefulset ss doesn't scale past 1 for another 9.999998575s
Jan 21 22:04:11.101: INFO: Verifying statefulset ss doesn't scale past 1 for another 8.988893407s
Jan 21 22:04:12.112: INFO: Verifying statefulset ss doesn't scale past 1 for another 7.973575495s
Jan 21 22:04:13.125: INFO: Verifying statefulset ss doesn't scale past 1 for another 6.962884279s
Jan 21 22:04:14.137: INFO: Verifying statefulset ss doesn't scale past 1 for another 5.950094628s
Jan 21 22:04:15.148: INFO: Verifying statefulset ss doesn't scale past 1 for another 4.937902308s
Jan 21 22:04:16.160: INFO: Verifying statefulset ss doesn't scale past 1 for another 3.926792613s
Jan 21 22:04:17.171: INFO: Verifying statefulset ss doesn't scale past 1 for another 2.914905208s
Jan 21 22:04:18.182: INFO: Verifying statefulset ss doesn't scale past 1 for another 1.90363284s
Jan 21 22:04:19.193: INFO: Verifying statefulset ss doesn't scale past 1 for another 892.959913ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace e2e-tests-statefulset-mkbwz
Jan 21 22:04:20.205: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-933165938 exec --namespace=e2e-tests-statefulset-mkbwz ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jan 21 22:04:20.589: INFO: stderr: ""
Jan 21 22:04:20.589: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Jan 21 22:04:20.589: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Jan 21 22:04:20.600: INFO: Found 1 stateful pods, waiting for 3
Jan 21 22:04:30.613: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Jan 21 22:04:30.614: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Jan 21 22:04:30.614: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Verifying that stateful set ss was scaled up in order
STEP: Scale down will halt with unhealthy stateful pod
Jan 21 22:04:30.674: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-933165938 exec --namespace=e2e-tests-statefulset-mkbwz ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Jan 21 22:04:31.062: INFO: stderr: ""
Jan 21 22:04:31.062: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Jan 21 22:04:31.062: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Jan 21 22:04:31.062: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-933165938 exec --namespace=e2e-tests-statefulset-mkbwz ss-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Jan 21 22:04:31.562: INFO: stderr: ""
Jan 21 22:04:31.562: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Jan 21 22:04:31.562: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Jan 21 22:04:31.562: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-933165938 exec --namespace=e2e-tests-statefulset-mkbwz ss-2 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Jan 21 22:04:32.060: INFO: stderr: ""
Jan 21 22:04:32.060: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Jan 21 22:04:32.060: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-2: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Jan 21 22:04:32.060: INFO: Waiting for statefulset status.replicas updated to 0
Jan 21 22:04:32.070: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 2
Jan 21 22:04:42.093: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Jan 21 22:04:42.093: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Jan 21 22:04:42.093: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Jan 21 22:04:42.199: INFO: Verifying statefulset ss doesn't scale past 3 for another 9.999998474s
Jan 21 22:04:43.212: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.983820281s
Jan 21 22:04:44.225: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.970882979s
Jan 21 22:04:45.237: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.957915157s
Jan 21 22:04:46.253: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.942237806s
Jan 21 22:04:47.266: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.929657907s
Jan 21 22:04:48.279: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.916408993s
Jan 21 22:04:49.292: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.903672363s
Jan 21 22:04:50.303: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.890484837s
Jan 21 22:04:51.315: INFO: Verifying statefulset ss doesn't scale past 3 for another 879.0974ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacee2e-tests-statefulset-mkbwz
Jan 21 22:04:52.327: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-933165938 exec --namespace=e2e-tests-statefulset-mkbwz ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jan 21 22:04:52.765: INFO: stderr: ""
Jan 21 22:04:52.765: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Jan 21 22:04:52.765: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Jan 21 22:04:52.765: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-933165938 exec --namespace=e2e-tests-statefulset-mkbwz ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jan 21 22:04:53.221: INFO: stderr: ""
Jan 21 22:04:53.221: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Jan 21 22:04:53.221: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Jan 21 22:04:53.221: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-933165938 exec --namespace=e2e-tests-statefulset-mkbwz ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jan 21 22:04:53.665: INFO: stderr: ""
Jan 21 22:04:53.665: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Jan 21 22:04:53.665: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-2: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Jan 21 22:04:53.665: INFO: Scaling statefulset ss to 0
STEP: Verifying that stateful set ss was scaled down in reverse order
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Jan 21 22:05:13.716: INFO: Deleting all statefulset in ns e2e-tests-statefulset-mkbwz
Jan 21 22:05:13.778: INFO: Scaling statefulset ss to 0
Jan 21 22:05:14.015: INFO: Waiting for statefulset status.replicas updated to 0
Jan 21 22:05:14.025: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 22:05:14.073: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-mkbwz" for this suite.
Jan 21 22:05:22.141: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 22:05:22.524: INFO: namespace: e2e-tests-statefulset-mkbwz, resource: bindings, ignored listing per whitelist
Jan 21 22:05:22.562: INFO: namespace e2e-tests-statefulset-mkbwz deletion completed in 8.453633009s

• [SLOW TEST:93.454 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected 
  should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 22:05:22.564: INFO: >>> kubeConfig: /tmp/kubeconfig-933165938
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-tqgct
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Jan 21 22:05:22.929: INFO: Waiting up to 5m0s for pod "downwardapi-volume-a61ce3bc-1dc8-11e9-8130-be6597f3ae53" in namespace "e2e-tests-projected-tqgct" to be "success or failure"
Jan 21 22:05:22.940: INFO: Pod "downwardapi-volume-a61ce3bc-1dc8-11e9-8130-be6597f3ae53": Phase="Pending", Reason="", readiness=false. Elapsed: 11.593543ms
Jan 21 22:05:24.952: INFO: Pod "downwardapi-volume-a61ce3bc-1dc8-11e9-8130-be6597f3ae53": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.023526777s
STEP: Saw pod success
Jan 21 22:05:24.953: INFO: Pod "downwardapi-volume-a61ce3bc-1dc8-11e9-8130-be6597f3ae53" satisfied condition "success or failure"
Jan 21 22:05:24.963: INFO: Trying to get logs from node 10.191.28.39 pod downwardapi-volume-a61ce3bc-1dc8-11e9-8130-be6597f3ae53 container client-container: <nil>
STEP: delete the pod
Jan 21 22:05:25.018: INFO: Waiting for pod downwardapi-volume-a61ce3bc-1dc8-11e9-8130-be6597f3ae53 to disappear
Jan 21 22:05:25.032: INFO: Pod downwardapi-volume-a61ce3bc-1dc8-11e9-8130-be6597f3ae53 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 22:05:25.032: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-tqgct" for this suite.
Jan 21 22:05:31.083: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 22:05:31.294: INFO: namespace: e2e-tests-projected-tqgct, resource: bindings, ignored listing per whitelist
Jan 21 22:05:31.476: INFO: namespace e2e-tests-projected-tqgct deletion completed in 6.427220145s

• [SLOW TEST:8.912 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 22:05:31.476: INFO: >>> kubeConfig: /tmp/kubeconfig-933165938
STEP: Building a namespace api object, basename replication-controller
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-replication-controller-lpwmg
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating replication controller my-hostname-basic-ab69ac03-1dc8-11e9-8130-be6597f3ae53
Jan 21 22:05:31.821: INFO: Pod name my-hostname-basic-ab69ac03-1dc8-11e9-8130-be6597f3ae53: Found 0 pods out of 1
Jan 21 22:05:36.833: INFO: Pod name my-hostname-basic-ab69ac03-1dc8-11e9-8130-be6597f3ae53: Found 1 pods out of 1
Jan 21 22:05:36.833: INFO: Ensuring all pods for ReplicationController "my-hostname-basic-ab69ac03-1dc8-11e9-8130-be6597f3ae53" are running
Jan 21 22:05:36.872: INFO: Pod "my-hostname-basic-ab69ac03-1dc8-11e9-8130-be6597f3ae53-dvzxw" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-01-21 22:05:31 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-01-21 22:05:33 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-01-21 22:05:33 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-01-21 22:05:31 +0000 UTC Reason: Message:}])
Jan 21 22:05:36.873: INFO: Trying to dial the pod
Jan 21 22:05:41.914: INFO: Controller my-hostname-basic-ab69ac03-1dc8-11e9-8130-be6597f3ae53: Got expected result from replica 1 [my-hostname-basic-ab69ac03-1dc8-11e9-8130-be6597f3ae53-dvzxw]: "my-hostname-basic-ab69ac03-1dc8-11e9-8130-be6597f3ae53-dvzxw", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 22:05:41.914: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-replication-controller-lpwmg" for this suite.
Jan 21 22:05:48.003: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 22:05:48.259: INFO: namespace: e2e-tests-replication-controller-lpwmg, resource: bindings, ignored listing per whitelist
Jan 21 22:05:48.468: INFO: namespace e2e-tests-replication-controller-lpwmg deletion completed in 6.502257027s

• [SLOW TEST:16.992 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 22:05:48.470: INFO: >>> kubeConfig: /tmp/kubeconfig-933165938
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-statefulset-zlhw2
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-zlhw2
[It] should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a new StatefulSet
Jan 21 22:05:48.834: INFO: Found 0 stateful pods, waiting for 3
Jan 21 22:05:58.849: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Jan 21 22:05:58.850: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Jan 21 22:05:58.850: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
Jan 21 22:05:58.881: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-933165938 exec --namespace=e2e-tests-statefulset-zlhw2 ss2-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Jan 21 22:05:59.348: INFO: stderr: ""
Jan 21 22:05:59.348: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Jan 21 22:05:59.348: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss2-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

STEP: Updating StatefulSet template: update image from docker.io/library/nginx:1.14-alpine to docker.io/library/nginx:1.15-alpine
Jan 21 22:06:09.428: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Updating Pods in reverse ordinal order
Jan 21 22:06:09.495: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-933165938 exec --namespace=e2e-tests-statefulset-zlhw2 ss2-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jan 21 22:06:09.908: INFO: stderr: ""
Jan 21 22:06:09.908: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Jan 21 22:06:09.908: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss2-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Jan 21 22:06:19.975: INFO: Waiting for StatefulSet e2e-tests-statefulset-zlhw2/ss2 to complete update
Jan 21 22:06:19.975: INFO: Waiting for Pod e2e-tests-statefulset-zlhw2/ss2-0 to have revision ss2-c79899b9 update revision ss2-787997d666
Jan 21 22:06:19.975: INFO: Waiting for Pod e2e-tests-statefulset-zlhw2/ss2-1 to have revision ss2-c79899b9 update revision ss2-787997d666
Jan 21 22:06:19.976: INFO: Waiting for Pod e2e-tests-statefulset-zlhw2/ss2-2 to have revision ss2-c79899b9 update revision ss2-787997d666
Jan 21 22:06:29.998: INFO: Waiting for StatefulSet e2e-tests-statefulset-zlhw2/ss2 to complete update
Jan 21 22:06:29.999: INFO: Waiting for Pod e2e-tests-statefulset-zlhw2/ss2-0 to have revision ss2-c79899b9 update revision ss2-787997d666
Jan 21 22:06:29.999: INFO: Waiting for Pod e2e-tests-statefulset-zlhw2/ss2-1 to have revision ss2-c79899b9 update revision ss2-787997d666
Jan 21 22:06:39.998: INFO: Waiting for StatefulSet e2e-tests-statefulset-zlhw2/ss2 to complete update
Jan 21 22:06:39.998: INFO: Waiting for Pod e2e-tests-statefulset-zlhw2/ss2-0 to have revision ss2-c79899b9 update revision ss2-787997d666
STEP: Rolling back to a previous revision
Jan 21 22:06:50.005: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-933165938 exec --namespace=e2e-tests-statefulset-zlhw2 ss2-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Jan 21 22:06:50.415: INFO: stderr: ""
Jan 21 22:06:50.415: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Jan 21 22:06:50.415: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss2-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Jan 21 22:07:00.501: INFO: Updating stateful set ss2
STEP: Rolling back update in reverse ordinal order
Jan 21 22:07:10.573: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-933165938 exec --namespace=e2e-tests-statefulset-zlhw2 ss2-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jan 21 22:07:10.937: INFO: stderr: ""
Jan 21 22:07:10.937: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Jan 21 22:07:10.937: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss2-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Jan 21 22:07:21.008: INFO: Waiting for StatefulSet e2e-tests-statefulset-zlhw2/ss2 to complete update
Jan 21 22:07:21.008: INFO: Waiting for Pod e2e-tests-statefulset-zlhw2/ss2-0 to have revision ss2-787997d666 update revision ss2-c79899b9
Jan 21 22:07:21.008: INFO: Waiting for Pod e2e-tests-statefulset-zlhw2/ss2-1 to have revision ss2-787997d666 update revision ss2-c79899b9
Jan 21 22:07:21.008: INFO: Waiting for Pod e2e-tests-statefulset-zlhw2/ss2-2 to have revision ss2-787997d666 update revision ss2-c79899b9
Jan 21 22:07:31.032: INFO: Waiting for StatefulSet e2e-tests-statefulset-zlhw2/ss2 to complete update
Jan 21 22:07:31.032: INFO: Waiting for Pod e2e-tests-statefulset-zlhw2/ss2-0 to have revision ss2-787997d666 update revision ss2-c79899b9
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Jan 21 22:07:41.045: INFO: Deleting all statefulset in ns e2e-tests-statefulset-zlhw2
Jan 21 22:07:41.057: INFO: Scaling statefulset ss2 to 0
Jan 21 22:08:11.102: INFO: Waiting for statefulset status.replicas updated to 0
Jan 21 22:08:11.112: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 22:08:11.164: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-zlhw2" for this suite.
Jan 21 22:08:19.214: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 22:08:19.577: INFO: namespace: e2e-tests-statefulset-zlhw2, resource: bindings, ignored listing per whitelist
Jan 21 22:08:19.756: INFO: namespace e2e-tests-statefulset-zlhw2 deletion completed in 8.57851288s

• [SLOW TEST:151.286 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should perform rolling updates and roll backs of template modifications [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 22:08:19.757: INFO: >>> kubeConfig: /tmp/kubeconfig-933165938
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-vdvkn
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-0fb923e6-1dc9-11e9-8130-be6597f3ae53
STEP: Creating a pod to test consume configMaps
Jan 21 22:08:20.120: INFO: Waiting up to 5m0s for pod "pod-configmaps-0fba711e-1dc9-11e9-8130-be6597f3ae53" in namespace "e2e-tests-configmap-vdvkn" to be "success or failure"
Jan 21 22:08:20.134: INFO: Pod "pod-configmaps-0fba711e-1dc9-11e9-8130-be6597f3ae53": Phase="Pending", Reason="", readiness=false. Elapsed: 14.448101ms
Jan 21 22:08:22.148: INFO: Pod "pod-configmaps-0fba711e-1dc9-11e9-8130-be6597f3ae53": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.028276719s
STEP: Saw pod success
Jan 21 22:08:22.148: INFO: Pod "pod-configmaps-0fba711e-1dc9-11e9-8130-be6597f3ae53" satisfied condition "success or failure"
Jan 21 22:08:22.160: INFO: Trying to get logs from node 10.191.28.59 pod pod-configmaps-0fba711e-1dc9-11e9-8130-be6597f3ae53 container configmap-volume-test: <nil>
STEP: delete the pod
Jan 21 22:08:22.228: INFO: Waiting for pod pod-configmaps-0fba711e-1dc9-11e9-8130-be6597f3ae53 to disappear
Jan 21 22:08:22.237: INFO: Pod pod-configmaps-0fba711e-1dc9-11e9-8130-be6597f3ae53 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 22:08:22.237: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-vdvkn" for this suite.
Jan 21 22:08:28.296: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 22:08:28.772: INFO: namespace: e2e-tests-configmap-vdvkn, resource: bindings, ignored listing per whitelist
Jan 21 22:08:28.830: INFO: namespace e2e-tests-configmap-vdvkn deletion completed in 6.578307447s

• [SLOW TEST:9.073 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 22:08:28.831: INFO: >>> kubeConfig: /tmp/kubeconfig-933165938
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-dh5jm
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-1520746d-1dc9-11e9-8130-be6597f3ae53
STEP: Creating a pod to test consume secrets
Jan 21 22:08:29.190: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-15221525-1dc9-11e9-8130-be6597f3ae53" in namespace "e2e-tests-projected-dh5jm" to be "success or failure"
Jan 21 22:08:29.202: INFO: Pod "pod-projected-secrets-15221525-1dc9-11e9-8130-be6597f3ae53": Phase="Pending", Reason="", readiness=false. Elapsed: 11.983468ms
Jan 21 22:08:31.216: INFO: Pod "pod-projected-secrets-15221525-1dc9-11e9-8130-be6597f3ae53": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.026200696s
STEP: Saw pod success
Jan 21 22:08:31.216: INFO: Pod "pod-projected-secrets-15221525-1dc9-11e9-8130-be6597f3ae53" satisfied condition "success or failure"
Jan 21 22:08:31.227: INFO: Trying to get logs from node 10.191.28.39 pod pod-projected-secrets-15221525-1dc9-11e9-8130-be6597f3ae53 container projected-secret-volume-test: <nil>
STEP: delete the pod
Jan 21 22:08:31.286: INFO: Waiting for pod pod-projected-secrets-15221525-1dc9-11e9-8130-be6597f3ae53 to disappear
Jan 21 22:08:31.301: INFO: Pod pod-projected-secrets-15221525-1dc9-11e9-8130-be6597f3ae53 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 22:08:31.301: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-dh5jm" for this suite.
Jan 21 22:08:37.352: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 22:08:37.428: INFO: namespace: e2e-tests-projected-dh5jm, resource: bindings, ignored listing per whitelist
Jan 21 22:08:37.686: INFO: namespace e2e-tests-projected-dh5jm deletion completed in 6.370441484s

• [SLOW TEST:8.854 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] version v1
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 22:08:37.687: INFO: >>> kubeConfig: /tmp/kubeconfig-933165938
STEP: Building a namespace api object, basename proxy
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-proxy-9zpgk
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: starting an echo server on multiple ports
STEP: creating replication controller proxy-service-cbvv5 in namespace e2e-tests-proxy-9zpgk
I0121 22:08:38.167071      15 runners.go:180] Created replication controller with name: proxy-service-cbvv5, namespace: e2e-tests-proxy-9zpgk, replica count: 1
I0121 22:08:39.218198      15 runners.go:180] proxy-service-cbvv5 Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0121 22:08:40.218524      15 runners.go:180] proxy-service-cbvv5 Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0121 22:08:41.218877      15 runners.go:180] proxy-service-cbvv5 Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0121 22:08:42.219260      15 runners.go:180] proxy-service-cbvv5 Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0121 22:08:43.219602      15 runners.go:180] proxy-service-cbvv5 Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0121 22:08:44.220019      15 runners.go:180] proxy-service-cbvv5 Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0121 22:08:45.220470      15 runners.go:180] proxy-service-cbvv5 Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0121 22:08:46.220754      15 runners.go:180] proxy-service-cbvv5 Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0121 22:08:47.221033      15 runners.go:180] proxy-service-cbvv5 Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0121 22:08:48.221444      15 runners.go:180] proxy-service-cbvv5 Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0121 22:08:49.221762      15 runners.go:180] proxy-service-cbvv5 Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Jan 21 22:08:49.230: INFO: setup took 11.173787616s, starting test cases
STEP: running 16 cases, 20 attempts per case, 320 total attempts
Jan 21 22:08:49.255: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-9zpgk/pods/http:proxy-service-cbvv5-mg6jw:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9zpgk/pods/http:proxy-service-cbvv5-mg6jw:1080/proxy/... (200; 22.809012ms)
Jan 21 22:08:49.256: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-9zpgk/pods/proxy-service-cbvv5-mg6jw/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9zpgk/pods/proxy-service-cbvv5-mg6jw/proxy/rewriteme"... (200; 24.551626ms)
Jan 21 22:08:49.264: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-9zpgk/pods/proxy-service-cbvv5-mg6jw:162/proxy/: bar (200; 33.057493ms)
Jan 21 22:08:49.264: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-9zpgk/services/proxy-service-cbvv5:portname1/proxy/: foo (200; 32.223647ms)
Jan 21 22:08:49.264: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-9zpgk/pods/http:proxy-service-cbvv5-mg6jw:160/proxy/: foo (200; 32.4035ms)
Jan 21 22:08:49.264: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-9zpgk/pods/proxy-service-cbvv5-mg6jw:160/proxy/: foo (200; 32.556735ms)
Jan 21 22:08:49.264: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-9zpgk/services/http:proxy-service-cbvv5:portname2/proxy/: bar (200; 33.143698ms)
Jan 21 22:08:49.264: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-9zpgk/pods/proxy-service-cbvv5-mg6jw:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9zpgk/pods/proxy-service-cbvv5-mg6jw:1080/proxy/rewri... (200; 32.406295ms)
Jan 21 22:08:49.264: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-9zpgk/services/proxy-service-cbvv5:portname2/proxy/: bar (200; 31.877037ms)
Jan 21 22:08:49.265: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-9zpgk/services/http:proxy-service-cbvv5:portname1/proxy/: foo (200; 33.940083ms)
Jan 21 22:08:49.265: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-9zpgk/pods/http:proxy-service-cbvv5-mg6jw:162/proxy/: bar (200; 34.301068ms)
Jan 21 22:08:49.270: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-9zpgk/pods/https:proxy-service-cbvv5-mg6jw:460/proxy/: tls baz (200; 38.938883ms)
Jan 21 22:08:49.270: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-9zpgk/pods/https:proxy-service-cbvv5-mg6jw:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9zpgk/pods/https:proxy-service-cbvv5-mg6jw:443/proxy/... (200; 39.215253ms)
Jan 21 22:08:49.278: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-9zpgk/services/https:proxy-service-cbvv5:tlsportname1/proxy/: tls baz (200; 46.863771ms)
Jan 21 22:08:49.279: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-9zpgk/pods/https:proxy-service-cbvv5-mg6jw:462/proxy/: tls qux (200; 48.926365ms)
Jan 21 22:08:49.280: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-9zpgk/services/https:proxy-service-cbvv5:tlsportname2/proxy/: tls qux (200; 47.854453ms)
Jan 21 22:08:49.295: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-9zpgk/pods/proxy-service-cbvv5-mg6jw:162/proxy/: bar (200; 15.05268ms)
Jan 21 22:08:49.299: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-9zpgk/pods/https:proxy-service-cbvv5-mg6jw:462/proxy/: tls qux (200; 18.914177ms)
Jan 21 22:08:49.299: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-9zpgk/pods/https:proxy-service-cbvv5-mg6jw:460/proxy/: tls baz (200; 18.572488ms)
Jan 21 22:08:49.300: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-9zpgk/pods/http:proxy-service-cbvv5-mg6jw:160/proxy/: foo (200; 18.644379ms)
Jan 21 22:08:49.300: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-9zpgk/pods/proxy-service-cbvv5-mg6jw:160/proxy/: foo (200; 18.638361ms)
Jan 21 22:08:49.300: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-9zpgk/pods/http:proxy-service-cbvv5-mg6jw:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9zpgk/pods/http:proxy-service-cbvv5-mg6jw:1080/proxy/... (200; 19.268858ms)
Jan 21 22:08:49.300: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-9zpgk/pods/proxy-service-cbvv5-mg6jw/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9zpgk/pods/proxy-service-cbvv5-mg6jw/proxy/rewriteme"... (200; 19.399684ms)
Jan 21 22:08:49.300: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-9zpgk/pods/proxy-service-cbvv5-mg6jw:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9zpgk/pods/proxy-service-cbvv5-mg6jw:1080/proxy/rewri... (200; 19.507867ms)
Jan 21 22:08:49.303: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-9zpgk/services/http:proxy-service-cbvv5:portname2/proxy/: bar (200; 22.811845ms)
Jan 21 22:08:49.303: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-9zpgk/services/http:proxy-service-cbvv5:portname1/proxy/: foo (200; 22.23055ms)
Jan 21 22:08:49.303: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-9zpgk/pods/https:proxy-service-cbvv5-mg6jw:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9zpgk/pods/https:proxy-service-cbvv5-mg6jw:443/proxy/... (200; 22.803227ms)
Jan 21 22:08:49.303: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-9zpgk/services/https:proxy-service-cbvv5:tlsportname2/proxy/: tls qux (200; 23.11618ms)
Jan 21 22:08:49.304: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-9zpgk/services/proxy-service-cbvv5:portname2/proxy/: bar (200; 23.390714ms)
Jan 21 22:08:49.304: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-9zpgk/services/proxy-service-cbvv5:portname1/proxy/: foo (200; 23.628855ms)
Jan 21 22:08:49.307: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-9zpgk/services/https:proxy-service-cbvv5:tlsportname1/proxy/: tls baz (200; 26.200374ms)
Jan 21 22:08:49.307: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-9zpgk/pods/http:proxy-service-cbvv5-mg6jw:162/proxy/: bar (200; 26.701758ms)
Jan 21 22:08:49.323: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-9zpgk/pods/http:proxy-service-cbvv5-mg6jw:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9zpgk/pods/http:proxy-service-cbvv5-mg6jw:1080/proxy/... (200; 15.874278ms)
Jan 21 22:08:49.327: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-9zpgk/pods/https:proxy-service-cbvv5-mg6jw:462/proxy/: tls qux (200; 19.361756ms)
Jan 21 22:08:49.328: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-9zpgk/pods/https:proxy-service-cbvv5-mg6jw:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9zpgk/pods/https:proxy-service-cbvv5-mg6jw:443/proxy/... (200; 19.857891ms)
Jan 21 22:08:49.328: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-9zpgk/pods/https:proxy-service-cbvv5-mg6jw:460/proxy/: tls baz (200; 20.854605ms)
Jan 21 22:08:49.328: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-9zpgk/pods/proxy-service-cbvv5-mg6jw:162/proxy/: bar (200; 20.295236ms)
Jan 21 22:08:49.328: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-9zpgk/pods/proxy-service-cbvv5-mg6jw:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9zpgk/pods/proxy-service-cbvv5-mg6jw:1080/proxy/rewri... (200; 20.706199ms)
Jan 21 22:08:49.328: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-9zpgk/pods/http:proxy-service-cbvv5-mg6jw:160/proxy/: foo (200; 20.0535ms)
Jan 21 22:08:49.328: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-9zpgk/pods/http:proxy-service-cbvv5-mg6jw:162/proxy/: bar (200; 20.86333ms)
Jan 21 22:08:49.328: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-9zpgk/pods/proxy-service-cbvv5-mg6jw:160/proxy/: foo (200; 20.1418ms)
Jan 21 22:08:49.328: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-9zpgk/pods/proxy-service-cbvv5-mg6jw/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9zpgk/pods/proxy-service-cbvv5-mg6jw/proxy/rewriteme"... (200; 20.403792ms)
Jan 21 22:08:49.330: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-9zpgk/services/https:proxy-service-cbvv5:tlsportname1/proxy/: tls baz (200; 22.54927ms)
Jan 21 22:08:49.331: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-9zpgk/services/http:proxy-service-cbvv5:portname2/proxy/: bar (200; 23.493406ms)
Jan 21 22:08:49.331: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-9zpgk/services/proxy-service-cbvv5:portname1/proxy/: foo (200; 23.515582ms)
Jan 21 22:08:49.331: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-9zpgk/services/proxy-service-cbvv5:portname2/proxy/: bar (200; 23.277167ms)
Jan 21 22:08:49.331: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-9zpgk/services/https:proxy-service-cbvv5:tlsportname2/proxy/: tls qux (200; 23.751935ms)
Jan 21 22:08:49.343: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-9zpgk/services/http:proxy-service-cbvv5:portname1/proxy/: foo (200; 34.725394ms)
Jan 21 22:08:49.358: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-9zpgk/pods/proxy-service-cbvv5-mg6jw:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9zpgk/pods/proxy-service-cbvv5-mg6jw:1080/proxy/rewri... (200; 14.082783ms)
Jan 21 22:08:49.364: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-9zpgk/pods/http:proxy-service-cbvv5-mg6jw:160/proxy/: foo (200; 19.496882ms)
Jan 21 22:08:49.364: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-9zpgk/pods/https:proxy-service-cbvv5-mg6jw:460/proxy/: tls baz (200; 19.798203ms)
Jan 21 22:08:49.364: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-9zpgk/pods/http:proxy-service-cbvv5-mg6jw:162/proxy/: bar (200; 19.976303ms)
Jan 21 22:08:49.364: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-9zpgk/pods/https:proxy-service-cbvv5-mg6jw:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9zpgk/pods/https:proxy-service-cbvv5-mg6jw:443/proxy/... (200; 20.113198ms)
Jan 21 22:08:49.364: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-9zpgk/pods/proxy-service-cbvv5-mg6jw:160/proxy/: foo (200; 20.18364ms)
Jan 21 22:08:49.364: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-9zpgk/pods/proxy-service-cbvv5-mg6jw:162/proxy/: bar (200; 20.591022ms)
Jan 21 22:08:49.364: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-9zpgk/pods/proxy-service-cbvv5-mg6jw/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9zpgk/pods/proxy-service-cbvv5-mg6jw/proxy/rewriteme"... (200; 20.783267ms)
Jan 21 22:08:49.364: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-9zpgk/pods/https:proxy-service-cbvv5-mg6jw:462/proxy/: tls qux (200; 20.475712ms)
Jan 21 22:08:49.364: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-9zpgk/pods/http:proxy-service-cbvv5-mg6jw:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9zpgk/pods/http:proxy-service-cbvv5-mg6jw:1080/proxy/... (200; 20.856401ms)
Jan 21 22:08:49.365: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-9zpgk/services/https:proxy-service-cbvv5:tlsportname1/proxy/: tls baz (200; 22.101768ms)
Jan 21 22:08:49.366: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-9zpgk/services/proxy-service-cbvv5:portname2/proxy/: bar (200; 22.460896ms)
Jan 21 22:08:49.366: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-9zpgk/services/http:proxy-service-cbvv5:portname1/proxy/: foo (200; 22.548467ms)
Jan 21 22:08:49.366: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-9zpgk/services/http:proxy-service-cbvv5:portname2/proxy/: bar (200; 22.081589ms)
Jan 21 22:08:49.372: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-9zpgk/services/https:proxy-service-cbvv5:tlsportname2/proxy/: tls qux (200; 28.604516ms)
Jan 21 22:08:49.372: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-9zpgk/services/proxy-service-cbvv5:portname1/proxy/: foo (200; 28.601189ms)
Jan 21 22:08:49.386: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-9zpgk/pods/https:proxy-service-cbvv5-mg6jw:460/proxy/: tls baz (200; 14.303377ms)
Jan 21 22:08:49.391: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-9zpgk/pods/http:proxy-service-cbvv5-mg6jw:160/proxy/: foo (200; 17.821942ms)
Jan 21 22:08:49.392: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-9zpgk/pods/https:proxy-service-cbvv5-mg6jw:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9zpgk/pods/https:proxy-service-cbvv5-mg6jw:443/proxy/... (200; 18.511688ms)
Jan 21 22:08:49.392: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-9zpgk/pods/http:proxy-service-cbvv5-mg6jw:162/proxy/: bar (200; 18.650806ms)
Jan 21 22:08:49.392: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-9zpgk/pods/proxy-service-cbvv5-mg6jw:162/proxy/: bar (200; 18.669654ms)
Jan 21 22:08:49.392: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-9zpgk/pods/https:proxy-service-cbvv5-mg6jw:462/proxy/: tls qux (200; 18.830933ms)
Jan 21 22:08:49.392: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-9zpgk/pods/proxy-service-cbvv5-mg6jw:160/proxy/: foo (200; 19.184123ms)
Jan 21 22:08:49.392: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-9zpgk/pods/proxy-service-cbvv5-mg6jw:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9zpgk/pods/proxy-service-cbvv5-mg6jw:1080/proxy/rewri... (200; 19.814711ms)
Jan 21 22:08:49.393: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-9zpgk/pods/http:proxy-service-cbvv5-mg6jw:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9zpgk/pods/http:proxy-service-cbvv5-mg6jw:1080/proxy/... (200; 19.691066ms)
Jan 21 22:08:49.393: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-9zpgk/pods/proxy-service-cbvv5-mg6jw/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9zpgk/pods/proxy-service-cbvv5-mg6jw/proxy/rewriteme"... (200; 19.861877ms)
Jan 21 22:08:49.395: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-9zpgk/services/http:proxy-service-cbvv5:portname2/proxy/: bar (200; 21.660385ms)
Jan 21 22:08:49.395: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-9zpgk/services/http:proxy-service-cbvv5:portname1/proxy/: foo (200; 22.548609ms)
Jan 21 22:08:49.395: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-9zpgk/services/https:proxy-service-cbvv5:tlsportname2/proxy/: tls qux (200; 21.438681ms)
Jan 21 22:08:49.395: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-9zpgk/services/https:proxy-service-cbvv5:tlsportname1/proxy/: tls baz (200; 21.553447ms)
Jan 21 22:08:49.395: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-9zpgk/services/proxy-service-cbvv5:portname2/proxy/: bar (200; 22.375322ms)
Jan 21 22:08:49.396: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-9zpgk/services/proxy-service-cbvv5:portname1/proxy/: foo (200; 22.360987ms)
Jan 21 22:08:49.410: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-9zpgk/pods/proxy-service-cbvv5-mg6jw:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9zpgk/pods/proxy-service-cbvv5-mg6jw:1080/proxy/rewri... (200; 14.070218ms)
Jan 21 22:08:49.416: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-9zpgk/pods/http:proxy-service-cbvv5-mg6jw:162/proxy/: bar (200; 17.509309ms)
Jan 21 22:08:49.416: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-9zpgk/pods/proxy-service-cbvv5-mg6jw:162/proxy/: bar (200; 18.151953ms)
Jan 21 22:08:49.416: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-9zpgk/pods/https:proxy-service-cbvv5-mg6jw:460/proxy/: tls baz (200; 20.233826ms)
Jan 21 22:08:49.416: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-9zpgk/pods/proxy-service-cbvv5-mg6jw:160/proxy/: foo (200; 19.375278ms)
Jan 21 22:08:49.416: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-9zpgk/pods/https:proxy-service-cbvv5-mg6jw:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9zpgk/pods/https:proxy-service-cbvv5-mg6jw:443/proxy/... (200; 17.981845ms)
Jan 21 22:08:49.416: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-9zpgk/pods/https:proxy-service-cbvv5-mg6jw:462/proxy/: tls qux (200; 19.500857ms)
Jan 21 22:08:49.416: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-9zpgk/pods/proxy-service-cbvv5-mg6jw/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9zpgk/pods/proxy-service-cbvv5-mg6jw/proxy/rewriteme"... (200; 19.667123ms)
Jan 21 22:08:49.417: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-9zpgk/pods/http:proxy-service-cbvv5-mg6jw:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9zpgk/pods/http:proxy-service-cbvv5-mg6jw:1080/proxy/... (200; 18.854194ms)
Jan 21 22:08:49.417: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-9zpgk/services/http:proxy-service-cbvv5:portname1/proxy/: foo (200; 20.354272ms)
Jan 21 22:08:49.418: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-9zpgk/pods/http:proxy-service-cbvv5-mg6jw:160/proxy/: foo (200; 20.857095ms)
Jan 21 22:08:49.418: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-9zpgk/services/proxy-service-cbvv5:portname1/proxy/: foo (200; 22.150953ms)
Jan 21 22:08:49.418: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-9zpgk/services/https:proxy-service-cbvv5:tlsportname1/proxy/: tls baz (200; 22.042616ms)
Jan 21 22:08:49.418: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-9zpgk/services/https:proxy-service-cbvv5:tlsportname2/proxy/: tls qux (200; 22.007585ms)
Jan 21 22:08:49.418: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-9zpgk/services/proxy-service-cbvv5:portname2/proxy/: bar (200; 21.535989ms)
Jan 21 22:08:49.423: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-9zpgk/services/http:proxy-service-cbvv5:portname2/proxy/: bar (200; 25.51144ms)
Jan 21 22:08:49.438: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-9zpgk/pods/https:proxy-service-cbvv5-mg6jw:460/proxy/: tls baz (200; 14.554604ms)
Jan 21 22:08:49.442: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-9zpgk/pods/proxy-service-cbvv5-mg6jw/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9zpgk/pods/proxy-service-cbvv5-mg6jw/proxy/rewriteme"... (200; 18.411552ms)
Jan 21 22:08:49.442: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-9zpgk/pods/http:proxy-service-cbvv5-mg6jw:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9zpgk/pods/http:proxy-service-cbvv5-mg6jw:1080/proxy/... (200; 18.395024ms)
Jan 21 22:08:49.442: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-9zpgk/pods/proxy-service-cbvv5-mg6jw:160/proxy/: foo (200; 18.771354ms)
Jan 21 22:08:49.443: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-9zpgk/pods/http:proxy-service-cbvv5-mg6jw:160/proxy/: foo (200; 18.60242ms)
Jan 21 22:08:49.443: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-9zpgk/pods/https:proxy-service-cbvv5-mg6jw:462/proxy/: tls qux (200; 18.095542ms)
Jan 21 22:08:49.443: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-9zpgk/pods/proxy-service-cbvv5-mg6jw:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9zpgk/pods/proxy-service-cbvv5-mg6jw:1080/proxy/rewri... (200; 19.110102ms)
Jan 21 22:08:49.443: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-9zpgk/pods/proxy-service-cbvv5-mg6jw:162/proxy/: bar (200; 18.419827ms)
Jan 21 22:08:49.443: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-9zpgk/pods/https:proxy-service-cbvv5-mg6jw:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9zpgk/pods/https:proxy-service-cbvv5-mg6jw:443/proxy/... (200; 18.274858ms)
Jan 21 22:08:49.443: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-9zpgk/pods/http:proxy-service-cbvv5-mg6jw:162/proxy/: bar (200; 18.352811ms)
Jan 21 22:08:49.445: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-9zpgk/services/https:proxy-service-cbvv5:tlsportname1/proxy/: tls baz (200; 19.979277ms)
Jan 21 22:08:49.445: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-9zpgk/services/http:proxy-service-cbvv5:portname2/proxy/: bar (200; 21.144837ms)
Jan 21 22:08:49.449: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-9zpgk/services/proxy-service-cbvv5:portname2/proxy/: bar (200; 25.031968ms)
Jan 21 22:08:49.449: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-9zpgk/services/http:proxy-service-cbvv5:portname1/proxy/: foo (200; 25.200511ms)
Jan 21 22:08:49.449: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-9zpgk/services/proxy-service-cbvv5:portname1/proxy/: foo (200; 24.536723ms)
Jan 21 22:08:49.449: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-9zpgk/services/https:proxy-service-cbvv5:tlsportname2/proxy/: tls qux (200; 24.47155ms)
Jan 21 22:08:49.464: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-9zpgk/pods/http:proxy-service-cbvv5-mg6jw:160/proxy/: foo (200; 13.575665ms)
Jan 21 22:08:49.470: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-9zpgk/pods/https:proxy-service-cbvv5-mg6jw:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9zpgk/pods/https:proxy-service-cbvv5-mg6jw:443/proxy/... (200; 19.955578ms)
Jan 21 22:08:49.470: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-9zpgk/pods/http:proxy-service-cbvv5-mg6jw:162/proxy/: bar (200; 20.156524ms)
Jan 21 22:08:49.470: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-9zpgk/pods/proxy-service-cbvv5-mg6jw:162/proxy/: bar (200; 19.376492ms)
Jan 21 22:08:49.470: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-9zpgk/pods/proxy-service-cbvv5-mg6jw:160/proxy/: foo (200; 19.989085ms)
Jan 21 22:08:49.470: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-9zpgk/pods/https:proxy-service-cbvv5-mg6jw:460/proxy/: tls baz (200; 20.504242ms)
Jan 21 22:08:49.470: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-9zpgk/pods/http:proxy-service-cbvv5-mg6jw:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9zpgk/pods/http:proxy-service-cbvv5-mg6jw:1080/proxy/... (200; 19.548817ms)
Jan 21 22:08:49.470: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-9zpgk/pods/proxy-service-cbvv5-mg6jw:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9zpgk/pods/proxy-service-cbvv5-mg6jw:1080/proxy/rewri... (200; 19.881042ms)
Jan 21 22:08:49.470: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-9zpgk/pods/proxy-service-cbvv5-mg6jw/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9zpgk/pods/proxy-service-cbvv5-mg6jw/proxy/rewriteme"... (200; 20.098265ms)
Jan 21 22:08:49.471: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-9zpgk/pods/https:proxy-service-cbvv5-mg6jw:462/proxy/: tls qux (200; 20.363525ms)
Jan 21 22:08:49.471: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-9zpgk/services/http:proxy-service-cbvv5:portname1/proxy/: foo (200; 20.645434ms)
Jan 21 22:08:49.474: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-9zpgk/services/https:proxy-service-cbvv5:tlsportname1/proxy/: tls baz (200; 23.656115ms)
Jan 21 22:08:49.474: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-9zpgk/services/http:proxy-service-cbvv5:portname2/proxy/: bar (200; 23.643246ms)
Jan 21 22:08:49.474: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-9zpgk/services/proxy-service-cbvv5:portname1/proxy/: foo (200; 23.265218ms)
Jan 21 22:08:49.474: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-9zpgk/services/proxy-service-cbvv5:portname2/proxy/: bar (200; 24.054147ms)
Jan 21 22:08:49.474: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-9zpgk/services/https:proxy-service-cbvv5:tlsportname2/proxy/: tls qux (200; 23.509243ms)
Jan 21 22:08:49.488: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-9zpgk/pods/http:proxy-service-cbvv5-mg6jw:160/proxy/: foo (200; 14.148489ms)
Jan 21 22:08:49.493: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-9zpgk/pods/https:proxy-service-cbvv5-mg6jw:462/proxy/: tls qux (200; 18.411967ms)
Jan 21 22:08:49.493: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-9zpgk/pods/https:proxy-service-cbvv5-mg6jw:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9zpgk/pods/https:proxy-service-cbvv5-mg6jw:443/proxy/... (200; 19.141812ms)
Jan 21 22:08:49.494: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-9zpgk/pods/proxy-service-cbvv5-mg6jw:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9zpgk/pods/proxy-service-cbvv5-mg6jw:1080/proxy/rewri... (200; 18.854723ms)
Jan 21 22:08:49.494: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-9zpgk/pods/proxy-service-cbvv5-mg6jw/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9zpgk/pods/proxy-service-cbvv5-mg6jw/proxy/rewriteme"... (200; 18.923444ms)
Jan 21 22:08:49.494: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-9zpgk/pods/https:proxy-service-cbvv5-mg6jw:460/proxy/: tls baz (200; 19.274671ms)
Jan 21 22:08:49.494: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-9zpgk/pods/http:proxy-service-cbvv5-mg6jw:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9zpgk/pods/http:proxy-service-cbvv5-mg6jw:1080/proxy/... (200; 18.887932ms)
Jan 21 22:08:49.494: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-9zpgk/pods/proxy-service-cbvv5-mg6jw:160/proxy/: foo (200; 19.260278ms)
Jan 21 22:08:49.494: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-9zpgk/pods/http:proxy-service-cbvv5-mg6jw:162/proxy/: bar (200; 19.472216ms)
Jan 21 22:08:49.495: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-9zpgk/pods/proxy-service-cbvv5-mg6jw:162/proxy/: bar (200; 20.487226ms)
Jan 21 22:08:49.498: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-9zpgk/services/proxy-service-cbvv5:portname2/proxy/: bar (200; 23.645051ms)
Jan 21 22:08:49.498: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-9zpgk/services/http:proxy-service-cbvv5:portname1/proxy/: foo (200; 24.020245ms)
Jan 21 22:08:49.498: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-9zpgk/services/https:proxy-service-cbvv5:tlsportname2/proxy/: tls qux (200; 23.971712ms)
Jan 21 22:08:49.499: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-9zpgk/services/https:proxy-service-cbvv5:tlsportname1/proxy/: tls baz (200; 23.877687ms)
Jan 21 22:08:49.499: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-9zpgk/services/http:proxy-service-cbvv5:portname2/proxy/: bar (200; 24.29276ms)
Jan 21 22:08:49.499: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-9zpgk/services/proxy-service-cbvv5:portname1/proxy/: foo (200; 23.982715ms)
Jan 21 22:08:49.513: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-9zpgk/pods/proxy-service-cbvv5-mg6jw:160/proxy/: foo (200; 13.228777ms)
Jan 21 22:08:49.519: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-9zpgk/pods/http:proxy-service-cbvv5-mg6jw:160/proxy/: foo (200; 18.701091ms)
Jan 21 22:08:49.519: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-9zpgk/pods/proxy-service-cbvv5-mg6jw:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9zpgk/pods/proxy-service-cbvv5-mg6jw:1080/proxy/rewri... (200; 19.441487ms)
Jan 21 22:08:49.519: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-9zpgk/pods/http:proxy-service-cbvv5-mg6jw:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9zpgk/pods/http:proxy-service-cbvv5-mg6jw:1080/proxy/... (200; 19.518736ms)
Jan 21 22:08:49.520: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-9zpgk/pods/https:proxy-service-cbvv5-mg6jw:460/proxy/: tls baz (200; 19.646027ms)
Jan 21 22:08:49.520: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-9zpgk/pods/https:proxy-service-cbvv5-mg6jw:462/proxy/: tls qux (200; 20.205767ms)
Jan 21 22:08:49.520: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-9zpgk/pods/proxy-service-cbvv5-mg6jw/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9zpgk/pods/proxy-service-cbvv5-mg6jw/proxy/rewriteme"... (200; 19.7427ms)
Jan 21 22:08:49.520: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-9zpgk/pods/proxy-service-cbvv5-mg6jw:162/proxy/: bar (200; 20.272952ms)
Jan 21 22:08:49.520: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-9zpgk/pods/https:proxy-service-cbvv5-mg6jw:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9zpgk/pods/https:proxy-service-cbvv5-mg6jw:443/proxy/... (200; 19.835644ms)
Jan 21 22:08:49.520: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-9zpgk/pods/http:proxy-service-cbvv5-mg6jw:162/proxy/: bar (200; 19.89805ms)
Jan 21 22:08:49.522: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-9zpgk/services/https:proxy-service-cbvv5:tlsportname1/proxy/: tls baz (200; 22.263668ms)
Jan 21 22:08:49.522: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-9zpgk/services/proxy-service-cbvv5:portname2/proxy/: bar (200; 22.511769ms)
Jan 21 22:08:49.522: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-9zpgk/services/http:proxy-service-cbvv5:portname2/proxy/: bar (200; 22.427648ms)
Jan 21 22:08:49.523: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-9zpgk/services/http:proxy-service-cbvv5:portname1/proxy/: foo (200; 22.41477ms)
Jan 21 22:08:49.523: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-9zpgk/services/https:proxy-service-cbvv5:tlsportname2/proxy/: tls qux (200; 22.842312ms)
Jan 21 22:08:49.523: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-9zpgk/services/proxy-service-cbvv5:portname1/proxy/: foo (200; 22.961124ms)
Jan 21 22:08:49.539: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-9zpgk/pods/https:proxy-service-cbvv5-mg6jw:460/proxy/: tls baz (200; 15.903131ms)
Jan 21 22:08:49.546: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-9zpgk/pods/https:proxy-service-cbvv5-mg6jw:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9zpgk/pods/https:proxy-service-cbvv5-mg6jw:443/proxy/... (200; 21.793655ms)
Jan 21 22:08:49.546: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-9zpgk/pods/proxy-service-cbvv5-mg6jw:162/proxy/: bar (200; 22.174998ms)
Jan 21 22:08:49.546: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-9zpgk/pods/http:proxy-service-cbvv5-mg6jw:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9zpgk/pods/http:proxy-service-cbvv5-mg6jw:1080/proxy/... (200; 22.393207ms)
Jan 21 22:08:49.546: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-9zpgk/pods/proxy-service-cbvv5-mg6jw/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9zpgk/pods/proxy-service-cbvv5-mg6jw/proxy/rewriteme"... (200; 22.523261ms)
Jan 21 22:08:49.547: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-9zpgk/pods/proxy-service-cbvv5-mg6jw:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9zpgk/pods/proxy-service-cbvv5-mg6jw:1080/proxy/rewri... (200; 23.888817ms)
Jan 21 22:08:49.547: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-9zpgk/pods/http:proxy-service-cbvv5-mg6jw:162/proxy/: bar (200; 23.16851ms)
Jan 21 22:08:49.547: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-9zpgk/pods/https:proxy-service-cbvv5-mg6jw:462/proxy/: tls qux (200; 23.050998ms)
Jan 21 22:08:49.547: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-9zpgk/pods/http:proxy-service-cbvv5-mg6jw:160/proxy/: foo (200; 23.700246ms)
Jan 21 22:08:49.548: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-9zpgk/pods/proxy-service-cbvv5-mg6jw:160/proxy/: foo (200; 24.449817ms)
Jan 21 22:08:49.551: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-9zpgk/services/https:proxy-service-cbvv5:tlsportname2/proxy/: tls qux (200; 26.925339ms)
Jan 21 22:08:49.551: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-9zpgk/services/https:proxy-service-cbvv5:tlsportname1/proxy/: tls baz (200; 27.13795ms)
Jan 21 22:08:49.552: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-9zpgk/services/http:proxy-service-cbvv5:portname2/proxy/: bar (200; 27.708944ms)
Jan 21 22:08:49.552: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-9zpgk/services/proxy-service-cbvv5:portname1/proxy/: foo (200; 27.497242ms)
Jan 21 22:08:49.552: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-9zpgk/services/proxy-service-cbvv5:portname2/proxy/: bar (200; 28.288515ms)
Jan 21 22:08:49.552: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-9zpgk/services/http:proxy-service-cbvv5:portname1/proxy/: foo (200; 28.540545ms)
Jan 21 22:08:49.568: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-9zpgk/pods/proxy-service-cbvv5-mg6jw:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9zpgk/pods/proxy-service-cbvv5-mg6jw:1080/proxy/rewri... (200; 14.909407ms)
Jan 21 22:08:49.573: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-9zpgk/pods/https:proxy-service-cbvv5-mg6jw:460/proxy/: tls baz (200; 18.480789ms)
Jan 21 22:08:49.573: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-9zpgk/pods/http:proxy-service-cbvv5-mg6jw:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9zpgk/pods/http:proxy-service-cbvv5-mg6jw:1080/proxy/... (200; 19.414022ms)
Jan 21 22:08:49.574: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-9zpgk/pods/proxy-service-cbvv5-mg6jw:160/proxy/: foo (200; 18.67355ms)
Jan 21 22:08:49.574: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-9zpgk/pods/proxy-service-cbvv5-mg6jw:162/proxy/: bar (200; 19.131388ms)
Jan 21 22:08:49.574: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-9zpgk/pods/http:proxy-service-cbvv5-mg6jw:160/proxy/: foo (200; 18.967388ms)
Jan 21 22:08:49.574: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-9zpgk/pods/https:proxy-service-cbvv5-mg6jw:462/proxy/: tls qux (200; 19.033636ms)
Jan 21 22:08:49.574: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-9zpgk/pods/proxy-service-cbvv5-mg6jw/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9zpgk/pods/proxy-service-cbvv5-mg6jw/proxy/rewriteme"... (200; 20.749241ms)
Jan 21 22:08:49.574: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-9zpgk/pods/https:proxy-service-cbvv5-mg6jw:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9zpgk/pods/https:proxy-service-cbvv5-mg6jw:443/proxy/... (200; 20.030482ms)
Jan 21 22:08:49.575: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-9zpgk/pods/http:proxy-service-cbvv5-mg6jw:162/proxy/: bar (200; 20.285149ms)
Jan 21 22:08:49.577: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-9zpgk/services/proxy-service-cbvv5:portname2/proxy/: bar (200; 24.340016ms)
Jan 21 22:08:49.577: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-9zpgk/services/http:proxy-service-cbvv5:portname2/proxy/: bar (200; 23.053494ms)
Jan 21 22:08:49.577: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-9zpgk/services/https:proxy-service-cbvv5:tlsportname1/proxy/: tls baz (200; 24.45251ms)
Jan 21 22:08:49.577: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-9zpgk/services/https:proxy-service-cbvv5:tlsportname2/proxy/: tls qux (200; 24.313582ms)
Jan 21 22:08:49.578: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-9zpgk/services/http:proxy-service-cbvv5:portname1/proxy/: foo (200; 25.024006ms)
Jan 21 22:08:49.578: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-9zpgk/services/proxy-service-cbvv5:portname1/proxy/: foo (200; 24.173696ms)
Jan 21 22:08:49.592: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-9zpgk/pods/proxy-service-cbvv5-mg6jw:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9zpgk/pods/proxy-service-cbvv5-mg6jw:1080/proxy/rewri... (200; 13.843682ms)
Jan 21 22:08:49.592: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-9zpgk/pods/https:proxy-service-cbvv5-mg6jw:460/proxy/: tls baz (200; 13.92919ms)
Jan 21 22:08:49.596: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-9zpgk/pods/proxy-service-cbvv5-mg6jw:162/proxy/: bar (200; 17.293803ms)
Jan 21 22:08:49.596: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-9zpgk/pods/http:proxy-service-cbvv5-mg6jw:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9zpgk/pods/http:proxy-service-cbvv5-mg6jw:1080/proxy/... (200; 17.42546ms)
Jan 21 22:08:49.596: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-9zpgk/pods/http:proxy-service-cbvv5-mg6jw:160/proxy/: foo (200; 17.479877ms)
Jan 21 22:08:49.596: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-9zpgk/pods/https:proxy-service-cbvv5-mg6jw:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9zpgk/pods/https:proxy-service-cbvv5-mg6jw:443/proxy/... (200; 17.652142ms)
Jan 21 22:08:49.597: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-9zpgk/pods/https:proxy-service-cbvv5-mg6jw:462/proxy/: tls qux (200; 17.615119ms)
Jan 21 22:08:49.596: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-9zpgk/pods/http:proxy-service-cbvv5-mg6jw:162/proxy/: bar (200; 17.649941ms)
Jan 21 22:08:49.597: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-9zpgk/pods/proxy-service-cbvv5-mg6jw/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9zpgk/pods/proxy-service-cbvv5-mg6jw/proxy/rewriteme"... (200; 18.223187ms)
Jan 21 22:08:49.597: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-9zpgk/pods/proxy-service-cbvv5-mg6jw:160/proxy/: foo (200; 18.617572ms)
Jan 21 22:08:49.601: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-9zpgk/services/proxy-service-cbvv5:portname1/proxy/: foo (200; 21.936923ms)
Jan 21 22:08:49.601: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-9zpgk/services/proxy-service-cbvv5:portname2/proxy/: bar (200; 22.438926ms)
Jan 21 22:08:49.601: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-9zpgk/services/http:proxy-service-cbvv5:portname1/proxy/: foo (200; 22.737036ms)
Jan 21 22:08:49.601: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-9zpgk/services/https:proxy-service-cbvv5:tlsportname2/proxy/: tls qux (200; 22.425813ms)
Jan 21 22:08:49.604: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-9zpgk/services/https:proxy-service-cbvv5:tlsportname1/proxy/: tls baz (200; 25.272763ms)
Jan 21 22:08:49.604: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-9zpgk/services/http:proxy-service-cbvv5:portname2/proxy/: bar (200; 25.679001ms)
Jan 21 22:08:49.618: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-9zpgk/pods/proxy-service-cbvv5-mg6jw:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9zpgk/pods/proxy-service-cbvv5-mg6jw:1080/proxy/rewri... (200; 12.762934ms)
Jan 21 22:08:49.622: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-9zpgk/pods/https:proxy-service-cbvv5-mg6jw:462/proxy/: tls qux (200; 16.602413ms)
Jan 21 22:08:49.622: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-9zpgk/pods/proxy-service-cbvv5-mg6jw:162/proxy/: bar (200; 16.978675ms)
Jan 21 22:08:49.623: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-9zpgk/pods/http:proxy-service-cbvv5-mg6jw:162/proxy/: bar (200; 17.04924ms)
Jan 21 22:08:49.623: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-9zpgk/pods/https:proxy-service-cbvv5-mg6jw:460/proxy/: tls baz (200; 18.183649ms)
Jan 21 22:08:49.623: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-9zpgk/pods/http:proxy-service-cbvv5-mg6jw:160/proxy/: foo (200; 17.607246ms)
Jan 21 22:08:49.623: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-9zpgk/pods/proxy-service-cbvv5-mg6jw:160/proxy/: foo (200; 17.717127ms)
Jan 21 22:08:49.623: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-9zpgk/pods/http:proxy-service-cbvv5-mg6jw:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9zpgk/pods/http:proxy-service-cbvv5-mg6jw:1080/proxy/... (200; 17.397445ms)
Jan 21 22:08:49.623: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-9zpgk/pods/https:proxy-service-cbvv5-mg6jw:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9zpgk/pods/https:proxy-service-cbvv5-mg6jw:443/proxy/... (200; 17.487353ms)
Jan 21 22:08:49.623: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-9zpgk/pods/proxy-service-cbvv5-mg6jw/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9zpgk/pods/proxy-service-cbvv5-mg6jw/proxy/rewriteme"... (200; 17.684328ms)
Jan 21 22:08:49.627: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-9zpgk/services/proxy-service-cbvv5:portname2/proxy/: bar (200; 20.98968ms)
Jan 21 22:08:49.627: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-9zpgk/services/proxy-service-cbvv5:portname1/proxy/: foo (200; 21.288711ms)
Jan 21 22:08:49.627: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-9zpgk/services/https:proxy-service-cbvv5:tlsportname1/proxy/: tls baz (200; 21.36637ms)
Jan 21 22:08:49.627: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-9zpgk/services/http:proxy-service-cbvv5:portname1/proxy/: foo (200; 21.83816ms)
Jan 21 22:08:49.627: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-9zpgk/services/http:proxy-service-cbvv5:portname2/proxy/: bar (200; 21.27631ms)
Jan 21 22:08:49.627: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-9zpgk/services/https:proxy-service-cbvv5:tlsportname2/proxy/: tls qux (200; 21.622101ms)
Jan 21 22:08:49.644: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-9zpgk/pods/proxy-service-cbvv5-mg6jw:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9zpgk/pods/proxy-service-cbvv5-mg6jw:1080/proxy/rewri... (200; 16.563562ms)
Jan 21 22:08:49.648: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-9zpgk/pods/http:proxy-service-cbvv5-mg6jw:162/proxy/: bar (200; 19.566715ms)
Jan 21 22:08:49.648: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-9zpgk/pods/http:proxy-service-cbvv5-mg6jw:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9zpgk/pods/http:proxy-service-cbvv5-mg6jw:1080/proxy/... (200; 19.998406ms)
Jan 21 22:08:49.649: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-9zpgk/pods/https:proxy-service-cbvv5-mg6jw:462/proxy/: tls qux (200; 20.848571ms)
Jan 21 22:08:49.649: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-9zpgk/pods/https:proxy-service-cbvv5-mg6jw:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9zpgk/pods/https:proxy-service-cbvv5-mg6jw:443/proxy/... (200; 19.983598ms)
Jan 21 22:08:49.649: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-9zpgk/pods/proxy-service-cbvv5-mg6jw:160/proxy/: foo (200; 21.298103ms)
Jan 21 22:08:49.649: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-9zpgk/services/https:proxy-service-cbvv5:tlsportname1/proxy/: tls baz (200; 21.026529ms)
Jan 21 22:08:49.649: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-9zpgk/pods/proxy-service-cbvv5-mg6jw/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9zpgk/pods/proxy-service-cbvv5-mg6jw/proxy/rewriteme"... (200; 20.724368ms)
Jan 21 22:08:49.649: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-9zpgk/pods/http:proxy-service-cbvv5-mg6jw:160/proxy/: foo (200; 21.622849ms)
Jan 21 22:08:49.649: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-9zpgk/pods/proxy-service-cbvv5-mg6jw:162/proxy/: bar (200; 21.259359ms)
Jan 21 22:08:49.649: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-9zpgk/pods/https:proxy-service-cbvv5-mg6jw:460/proxy/: tls baz (200; 22.297464ms)
Jan 21 22:08:49.651: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-9zpgk/services/https:proxy-service-cbvv5:tlsportname2/proxy/: tls qux (200; 22.703349ms)
Jan 21 22:08:49.651: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-9zpgk/services/http:proxy-service-cbvv5:portname2/proxy/: bar (200; 22.370389ms)
Jan 21 22:08:49.651: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-9zpgk/services/proxy-service-cbvv5:portname2/proxy/: bar (200; 23.197822ms)
Jan 21 22:08:49.651: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-9zpgk/services/http:proxy-service-cbvv5:portname1/proxy/: foo (200; 23.953239ms)
Jan 21 22:08:49.652: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-9zpgk/services/proxy-service-cbvv5:portname1/proxy/: foo (200; 23.650555ms)
Jan 21 22:08:49.672: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-9zpgk/pods/https:proxy-service-cbvv5-mg6jw:462/proxy/: tls qux (200; 19.755676ms)
Jan 21 22:08:49.675: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-9zpgk/pods/proxy-service-cbvv5-mg6jw:160/proxy/: foo (200; 21.896605ms)
Jan 21 22:08:49.675: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-9zpgk/pods/https:proxy-service-cbvv5-mg6jw:460/proxy/: tls baz (200; 22.200026ms)
Jan 21 22:08:49.675: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-9zpgk/pods/http:proxy-service-cbvv5-mg6jw:160/proxy/: foo (200; 22.13742ms)
Jan 21 22:08:49.676: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-9zpgk/pods/proxy-service-cbvv5-mg6jw/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9zpgk/pods/proxy-service-cbvv5-mg6jw/proxy/rewriteme"... (200; 22.816512ms)
Jan 21 22:08:49.676: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-9zpgk/pods/https:proxy-service-cbvv5-mg6jw:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9zpgk/pods/https:proxy-service-cbvv5-mg6jw:443/proxy/... (200; 23.582485ms)
Jan 21 22:08:49.676: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-9zpgk/pods/http:proxy-service-cbvv5-mg6jw:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9zpgk/pods/http:proxy-service-cbvv5-mg6jw:1080/proxy/... (200; 23.235464ms)
Jan 21 22:08:49.676: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-9zpgk/pods/http:proxy-service-cbvv5-mg6jw:162/proxy/: bar (200; 24.136565ms)
Jan 21 22:08:49.676: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-9zpgk/pods/proxy-service-cbvv5-mg6jw:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9zpgk/pods/proxy-service-cbvv5-mg6jw:1080/proxy/rewri... (200; 23.764821ms)
Jan 21 22:08:49.676: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-9zpgk/pods/proxy-service-cbvv5-mg6jw:162/proxy/: bar (200; 24.471037ms)
Jan 21 22:08:49.680: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-9zpgk/services/https:proxy-service-cbvv5:tlsportname1/proxy/: tls baz (200; 27.341895ms)
Jan 21 22:08:49.680: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-9zpgk/services/http:proxy-service-cbvv5:portname2/proxy/: bar (200; 28.180525ms)
Jan 21 22:08:49.680: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-9zpgk/services/proxy-service-cbvv5:portname1/proxy/: foo (200; 28.04431ms)
Jan 21 22:08:49.680: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-9zpgk/services/proxy-service-cbvv5:portname2/proxy/: bar (200; 27.763293ms)
Jan 21 22:08:49.681: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-9zpgk/services/http:proxy-service-cbvv5:portname1/proxy/: foo (200; 27.563916ms)
Jan 21 22:08:49.681: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-9zpgk/services/https:proxy-service-cbvv5:tlsportname2/proxy/: tls qux (200; 28.124012ms)
Jan 21 22:08:49.695: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-9zpgk/pods/proxy-service-cbvv5-mg6jw:160/proxy/: foo (200; 13.477249ms)
Jan 21 22:08:49.701: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-9zpgk/pods/proxy-service-cbvv5-mg6jw:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9zpgk/pods/proxy-service-cbvv5-mg6jw:1080/proxy/rewri... (200; 19.449126ms)
Jan 21 22:08:49.701: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-9zpgk/pods/proxy-service-cbvv5-mg6jw/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9zpgk/pods/proxy-service-cbvv5-mg6jw/proxy/rewriteme"... (200; 20.092694ms)
Jan 21 22:08:49.702: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-9zpgk/pods/https:proxy-service-cbvv5-mg6jw:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9zpgk/pods/https:proxy-service-cbvv5-mg6jw:443/proxy/... (200; 19.552917ms)
Jan 21 22:08:49.702: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-9zpgk/pods/http:proxy-service-cbvv5-mg6jw:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9zpgk/pods/http:proxy-service-cbvv5-mg6jw:1080/proxy/... (200; 20.085198ms)
Jan 21 22:08:49.702: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-9zpgk/pods/proxy-service-cbvv5-mg6jw:162/proxy/: bar (200; 20.072665ms)
Jan 21 22:08:49.702: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-9zpgk/pods/http:proxy-service-cbvv5-mg6jw:160/proxy/: foo (200; 20.652094ms)
Jan 21 22:08:49.702: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-9zpgk/pods/https:proxy-service-cbvv5-mg6jw:460/proxy/: tls baz (200; 19.790336ms)
Jan 21 22:08:49.702: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-9zpgk/pods/http:proxy-service-cbvv5-mg6jw:162/proxy/: bar (200; 20.226624ms)
Jan 21 22:08:49.703: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-9zpgk/pods/https:proxy-service-cbvv5-mg6jw:462/proxy/: tls qux (200; 21.193301ms)
Jan 21 22:08:49.706: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-9zpgk/services/http:proxy-service-cbvv5:portname1/proxy/: foo (200; 24.174892ms)
Jan 21 22:08:49.706: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-9zpgk/services/https:proxy-service-cbvv5:tlsportname2/proxy/: tls qux (200; 23.847321ms)
Jan 21 22:08:49.706: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-9zpgk/services/proxy-service-cbvv5:portname2/proxy/: bar (200; 23.746502ms)
Jan 21 22:08:49.706: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-9zpgk/services/http:proxy-service-cbvv5:portname2/proxy/: bar (200; 24.859205ms)
Jan 21 22:08:49.706: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-9zpgk/services/https:proxy-service-cbvv5:tlsportname1/proxy/: tls baz (200; 24.175231ms)
Jan 21 22:08:49.706: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-9zpgk/services/proxy-service-cbvv5:portname1/proxy/: foo (200; 25.177393ms)
Jan 21 22:08:49.721: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-9zpgk/pods/http:proxy-service-cbvv5-mg6jw:160/proxy/: foo (200; 14.139095ms)
Jan 21 22:08:49.726: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-9zpgk/pods/http:proxy-service-cbvv5-mg6jw:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9zpgk/pods/http:proxy-service-cbvv5-mg6jw:1080/proxy/... (200; 17.853072ms)
Jan 21 22:08:49.726: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-9zpgk/pods/https:proxy-service-cbvv5-mg6jw:462/proxy/: tls qux (200; 19.046019ms)
Jan 21 22:08:49.726: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-9zpgk/pods/proxy-service-cbvv5-mg6jw/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9zpgk/pods/proxy-service-cbvv5-mg6jw/proxy/rewriteme"... (200; 18.694453ms)
Jan 21 22:08:49.726: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-9zpgk/pods/proxy-service-cbvv5-mg6jw:162/proxy/: bar (200; 18.028393ms)
Jan 21 22:08:49.726: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-9zpgk/pods/proxy-service-cbvv5-mg6jw:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9zpgk/pods/proxy-service-cbvv5-mg6jw:1080/proxy/rewri... (200; 18.292009ms)
Jan 21 22:08:49.726: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-9zpgk/pods/https:proxy-service-cbvv5-mg6jw:460/proxy/: tls baz (200; 19.489661ms)
Jan 21 22:08:49.726: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-9zpgk/pods/https:proxy-service-cbvv5-mg6jw:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9zpgk/pods/https:proxy-service-cbvv5-mg6jw:443/proxy/... (200; 18.129779ms)
Jan 21 22:08:49.727: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-9zpgk/pods/proxy-service-cbvv5-mg6jw:160/proxy/: foo (200; 19.563997ms)
Jan 21 22:08:49.727: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-9zpgk/services/http:proxy-service-cbvv5:portname1/proxy/: foo (200; 19.728408ms)
Jan 21 22:08:49.727: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-9zpgk/pods/http:proxy-service-cbvv5-mg6jw:162/proxy/: bar (200; 19.01691ms)
Jan 21 22:08:49.729: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-9zpgk/services/https:proxy-service-cbvv5:tlsportname1/proxy/: tls baz (200; 21.970525ms)
Jan 21 22:08:49.730: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-9zpgk/services/http:proxy-service-cbvv5:portname2/proxy/: bar (200; 22.518881ms)
Jan 21 22:08:49.731: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-9zpgk/services/proxy-service-cbvv5:portname2/proxy/: bar (200; 22.845427ms)
Jan 21 22:08:49.731: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-9zpgk/services/https:proxy-service-cbvv5:tlsportname2/proxy/: tls qux (200; 23.390004ms)
Jan 21 22:08:49.731: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-9zpgk/services/proxy-service-cbvv5:portname1/proxy/: foo (200; 23.525404ms)
Jan 21 22:08:49.746: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-9zpgk/pods/https:proxy-service-cbvv5-mg6jw:462/proxy/: tls qux (200; 13.785619ms)
Jan 21 22:08:49.752: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-9zpgk/pods/proxy-service-cbvv5-mg6jw:160/proxy/: foo (200; 18.515473ms)
Jan 21 22:08:49.753: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-9zpgk/pods/proxy-service-cbvv5-mg6jw:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9zpgk/pods/proxy-service-cbvv5-mg6jw:1080/proxy/rewri... (200; 20.124311ms)
Jan 21 22:08:49.753: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-9zpgk/pods/http:proxy-service-cbvv5-mg6jw:162/proxy/: bar (200; 20.804768ms)
Jan 21 22:08:49.753: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-9zpgk/pods/proxy-service-cbvv5-mg6jw/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9zpgk/pods/proxy-service-cbvv5-mg6jw/proxy/rewriteme"... (200; 20.309784ms)
Jan 21 22:08:49.753: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-9zpgk/pods/http:proxy-service-cbvv5-mg6jw:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9zpgk/pods/http:proxy-service-cbvv5-mg6jw:1080/proxy/... (200; 20.466276ms)
Jan 21 22:08:49.753: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-9zpgk/pods/https:proxy-service-cbvv5-mg6jw:460/proxy/: tls baz (200; 20.726881ms)
Jan 21 22:08:49.754: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-9zpgk/pods/proxy-service-cbvv5-mg6jw:162/proxy/: bar (200; 21.834635ms)
Jan 21 22:08:49.754: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-9zpgk/pods/http:proxy-service-cbvv5-mg6jw:160/proxy/: foo (200; 20.71924ms)
Jan 21 22:08:49.754: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-9zpgk/pods/https:proxy-service-cbvv5-mg6jw:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9zpgk/pods/https:proxy-service-cbvv5-mg6jw:443/proxy/... (200; 21.936251ms)
Jan 21 22:08:49.756: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-9zpgk/services/http:proxy-service-cbvv5:portname2/proxy/: bar (200; 23.624366ms)
Jan 21 22:08:49.758: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-9zpgk/services/proxy-service-cbvv5:portname2/proxy/: bar (200; 24.884338ms)
Jan 21 22:08:49.758: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-9zpgk/services/proxy-service-cbvv5:portname1/proxy/: foo (200; 25.279654ms)
Jan 21 22:08:49.758: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-9zpgk/services/https:proxy-service-cbvv5:tlsportname1/proxy/: tls baz (200; 25.250546ms)
Jan 21 22:08:49.758: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-9zpgk/services/http:proxy-service-cbvv5:portname1/proxy/: foo (200; 24.593311ms)
Jan 21 22:08:49.758: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-9zpgk/services/https:proxy-service-cbvv5:tlsportname2/proxy/: tls qux (200; 25.180537ms)
Jan 21 22:08:49.775: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-9zpgk/pods/https:proxy-service-cbvv5-mg6jw:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9zpgk/pods/https:proxy-service-cbvv5-mg6jw:443/proxy/... (200; 17.022953ms)
Jan 21 22:08:49.779: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-9zpgk/pods/https:proxy-service-cbvv5-mg6jw:462/proxy/: tls qux (200; 20.630829ms)
Jan 21 22:08:49.779: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-9zpgk/pods/proxy-service-cbvv5-mg6jw:160/proxy/: foo (200; 20.529652ms)
Jan 21 22:08:49.781: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-9zpgk/pods/http:proxy-service-cbvv5-mg6jw:162/proxy/: bar (200; 22.391469ms)
Jan 21 22:08:49.782: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-9zpgk/pods/proxy-service-cbvv5-mg6jw:162/proxy/: bar (200; 23.52992ms)
Jan 21 22:08:49.782: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-9zpgk/pods/proxy-service-cbvv5-mg6jw:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9zpgk/pods/proxy-service-cbvv5-mg6jw:1080/proxy/rewri... (200; 23.010313ms)
Jan 21 22:08:49.782: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-9zpgk/pods/http:proxy-service-cbvv5-mg6jw:160/proxy/: foo (200; 23.239409ms)
Jan 21 22:08:49.782: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-9zpgk/pods/https:proxy-service-cbvv5-mg6jw:460/proxy/: tls baz (200; 23.439273ms)
Jan 21 22:08:49.782: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-9zpgk/pods/http:proxy-service-cbvv5-mg6jw:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9zpgk/pods/http:proxy-service-cbvv5-mg6jw:1080/proxy/... (200; 23.66404ms)
Jan 21 22:08:49.782: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-9zpgk/pods/proxy-service-cbvv5-mg6jw/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-9zpgk/pods/proxy-service-cbvv5-mg6jw/proxy/rewriteme"... (200; 23.811791ms)
Jan 21 22:08:49.783: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-9zpgk/services/http:proxy-service-cbvv5:portname1/proxy/: foo (200; 23.950541ms)
Jan 21 22:08:49.783: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-9zpgk/services/https:proxy-service-cbvv5:tlsportname2/proxy/: tls qux (200; 24.797363ms)
Jan 21 22:08:49.788: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-9zpgk/services/proxy-service-cbvv5:portname2/proxy/: bar (200; 29.4763ms)
Jan 21 22:08:49.788: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-9zpgk/services/proxy-service-cbvv5:portname1/proxy/: foo (200; 28.738812ms)
Jan 21 22:08:49.788: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-9zpgk/services/https:proxy-service-cbvv5:tlsportname1/proxy/: tls baz (200; 28.742554ms)
Jan 21 22:08:49.788: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-9zpgk/services/http:proxy-service-cbvv5:portname2/proxy/: bar (200; 29.662913ms)
STEP: deleting { ReplicationController} proxy-service-cbvv5 in namespace e2e-tests-proxy-9zpgk, will wait for the garbage collector to delete the pods
Jan 21 22:08:49.874: INFO: Deleting { ReplicationController} proxy-service-cbvv5 took: 25.607948ms
Jan 21 22:08:49.974: INFO: Terminating { ReplicationController} proxy-service-cbvv5 pods took: 100.615105ms
[AfterEach] version v1
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 22:08:52.275: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-proxy-9zpgk" for this suite.
Jan 21 22:08:58.341: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 22:08:58.626: INFO: namespace: e2e-tests-proxy-9zpgk, resource: bindings, ignored listing per whitelist
Jan 21 22:08:58.751: INFO: namespace e2e-tests-proxy-9zpgk deletion completed in 6.46023294s

• [SLOW TEST:21.064 seconds]
[sig-network] Proxy
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy through a service and a pod  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 22:08:58.753: INFO: >>> kubeConfig: /tmp/kubeconfig-933165938
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-container-lifecycle-hook-pp2kc
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Jan 21 22:09:03.223: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Jan 21 22:09:03.274: INFO: Pod pod-with-prestop-http-hook still exists
Jan 21 22:09:05.274: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Jan 21 22:09:05.286: INFO: Pod pod-with-prestop-http-hook still exists
Jan 21 22:09:07.274: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Jan 21 22:09:07.285: INFO: Pod pod-with-prestop-http-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 22:09:07.307: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-lifecycle-hook-pp2kc" for this suite.
Jan 21 22:09:37.401: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 22:09:37.635: INFO: namespace: e2e-tests-container-lifecycle-hook-pp2kc, resource: bindings, ignored listing per whitelist
Jan 21 22:09:37.775: INFO: namespace e2e-tests-container-lifecycle-hook-pp2kc deletion completed in 30.410378272s

• [SLOW TEST:39.022 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when create a pod with lifecycle hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute prestop http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run deployment 
  should create a deployment from an image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 22:09:37.776: INFO: >>> kubeConfig: /tmp/kubeconfig-933165938
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-jbnpf
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Kubectl run deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1347
[It] should create a deployment from an image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Jan 21 22:09:38.157: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-933165938 run e2e-test-nginx-deployment --image=docker.io/library/nginx:1.14-alpine --generator=deployment/v1beta1 --namespace=e2e-tests-kubectl-jbnpf'
Jan 21 22:09:38.693: INFO: stderr: "kubectl run --generator=deployment/v1beta1 is DEPRECATED and will be removed in a future version. Use kubectl create instead.\n"
Jan 21 22:09:38.693: INFO: stdout: "deployment.extensions/e2e-test-nginx-deployment created\n"
STEP: verifying the deployment e2e-test-nginx-deployment was created
STEP: verifying the pod controlled by deployment e2e-test-nginx-deployment was created
[AfterEach] [k8s.io] Kubectl run deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1352
Jan 21 22:09:42.724: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-933165938 delete deployment e2e-test-nginx-deployment --namespace=e2e-tests-kubectl-jbnpf'
Jan 21 22:09:43.029: INFO: stderr: ""
Jan 21 22:09:43.029: INFO: stdout: "deployment.extensions \"e2e-test-nginx-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 22:09:43.029: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-jbnpf" for this suite.
Jan 21 22:10:07.080: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 22:10:07.354: INFO: namespace: e2e-tests-kubectl-jbnpf, resource: bindings, ignored listing per whitelist
Jan 21 22:10:07.547: INFO: namespace e2e-tests-kubectl-jbnpf deletion completed in 24.501359506s

• [SLOW TEST:29.771 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create a deployment from an image  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] HostPath 
  should give a volume the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 22:10:07.549: INFO: >>> kubeConfig: /tmp/kubeconfig-933165938
STEP: Building a namespace api object, basename hostpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-hostpath-q2pht
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:37
[It] should give a volume the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test hostPath mode
Jan 21 22:10:08.001: INFO: Waiting up to 5m0s for pod "pod-host-path-test" in namespace "e2e-tests-hostpath-q2pht" to be "success or failure"
Jan 21 22:10:08.013: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 11.2387ms
Jan 21 22:10:10.024: INFO: Pod "pod-host-path-test": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.022087337s
STEP: Saw pod success
Jan 21 22:10:10.024: INFO: Pod "pod-host-path-test" satisfied condition "success or failure"
Jan 21 22:10:10.033: INFO: Trying to get logs from node 10.191.28.59 pod pod-host-path-test container test-container-1: <nil>
STEP: delete the pod
Jan 21 22:10:10.090: INFO: Waiting for pod pod-host-path-test to disappear
Jan 21 22:10:10.099: INFO: Pod pod-host-path-test no longer exists
[AfterEach] [sig-storage] HostPath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 22:10:10.099: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-hostpath-q2pht" for this suite.
Jan 21 22:10:16.172: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 22:10:16.498: INFO: namespace: e2e-tests-hostpath-q2pht, resource: bindings, ignored listing per whitelist
Jan 21 22:10:16.558: INFO: namespace e2e-tests-hostpath-q2pht deletion completed in 6.44504823s

• [SLOW TEST:9.009 seconds]
[sig-storage] HostPath
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:34
  should give a volume the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Downward API volume 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 22:10:16.558: INFO: >>> kubeConfig: /tmp/kubeconfig-933165938
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-5sbws
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating the pod
Jan 21 22:10:19.667: INFO: Successfully updated pod "annotationupdate556f3f2f-1dc9-11e9-8130-be6597f3ae53"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 22:10:21.786: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-5sbws" for this suite.
Jan 21 22:10:45.839: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 22:10:46.081: INFO: namespace: e2e-tests-downward-api-5sbws, resource: bindings, ignored listing per whitelist
Jan 21 22:10:46.347: INFO: namespace e2e-tests-downward-api-5sbws deletion completed in 24.546650553s

• [SLOW TEST:29.789 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 22:10:46.348: INFO: >>> kubeConfig: /tmp/kubeconfig-933165938
STEP: Building a namespace api object, basename var-expansion
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-var-expansion-rc6xk
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test env composition
Jan 21 22:10:46.883: INFO: Waiting up to 5m0s for pod "var-expansion-67347488-1dc9-11e9-8130-be6597f3ae53" in namespace "e2e-tests-var-expansion-rc6xk" to be "success or failure"
Jan 21 22:10:46.893: INFO: Pod "var-expansion-67347488-1dc9-11e9-8130-be6597f3ae53": Phase="Pending", Reason="", readiness=false. Elapsed: 10.624606ms
Jan 21 22:10:48.905: INFO: Pod "var-expansion-67347488-1dc9-11e9-8130-be6597f3ae53": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.021809548s
STEP: Saw pod success
Jan 21 22:10:48.905: INFO: Pod "var-expansion-67347488-1dc9-11e9-8130-be6597f3ae53" satisfied condition "success or failure"
Jan 21 22:10:48.915: INFO: Trying to get logs from node 10.191.28.59 pod var-expansion-67347488-1dc9-11e9-8130-be6597f3ae53 container dapi-container: <nil>
STEP: delete the pod
Jan 21 22:10:48.971: INFO: Waiting for pod var-expansion-67347488-1dc9-11e9-8130-be6597f3ae53 to disappear
Jan 21 22:10:48.983: INFO: Pod var-expansion-67347488-1dc9-11e9-8130-be6597f3ae53 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 22:10:48.983: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-var-expansion-rc6xk" for this suite.
Jan 21 22:10:55.030: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 22:10:55.083: INFO: namespace: e2e-tests-var-expansion-rc6xk, resource: bindings, ignored listing per whitelist
Jan 21 22:10:55.975: INFO: namespace e2e-tests-var-expansion-rc6xk deletion completed in 6.978104058s

• [SLOW TEST:9.628 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 22:10:55.976: INFO: >>> kubeConfig: /tmp/kubeconfig-933165938
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-mdx4b
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-map-6cdcc6f4-1dc9-11e9-8130-be6597f3ae53
STEP: Creating a pod to test consume secrets
Jan 21 22:10:56.385: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-6cde2c7b-1dc9-11e9-8130-be6597f3ae53" in namespace "e2e-tests-projected-mdx4b" to be "success or failure"
Jan 21 22:10:56.395: INFO: Pod "pod-projected-secrets-6cde2c7b-1dc9-11e9-8130-be6597f3ae53": Phase="Pending", Reason="", readiness=false. Elapsed: 9.864639ms
Jan 21 22:10:58.407: INFO: Pod "pod-projected-secrets-6cde2c7b-1dc9-11e9-8130-be6597f3ae53": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.02158543s
STEP: Saw pod success
Jan 21 22:10:58.407: INFO: Pod "pod-projected-secrets-6cde2c7b-1dc9-11e9-8130-be6597f3ae53" satisfied condition "success or failure"
Jan 21 22:10:58.417: INFO: Trying to get logs from node 10.191.28.39 pod pod-projected-secrets-6cde2c7b-1dc9-11e9-8130-be6597f3ae53 container projected-secret-volume-test: <nil>
STEP: delete the pod
Jan 21 22:10:58.471: INFO: Waiting for pod pod-projected-secrets-6cde2c7b-1dc9-11e9-8130-be6597f3ae53 to disappear
Jan 21 22:10:58.480: INFO: Pod pod-projected-secrets-6cde2c7b-1dc9-11e9-8130-be6597f3ae53 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 22:10:58.480: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-mdx4b" for this suite.
Jan 21 22:11:04.528: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 22:11:04.836: INFO: namespace: e2e-tests-projected-mdx4b, resource: bindings, ignored listing per whitelist
Jan 21 22:11:04.910: INFO: namespace e2e-tests-projected-mdx4b deletion completed in 6.414013086s

• [SLOW TEST:8.934 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 22:11:04.911: INFO: >>> kubeConfig: /tmp/kubeconfig-933165938
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-gc-4kks2
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the pods
STEP: Gathering metrics
W0121 22:11:45.359867      15 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Jan 21 22:11:45.359: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 22:11:45.359: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-4kks2" for this suite.
Jan 21 22:11:53.412: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 22:11:53.754: INFO: namespace: e2e-tests-gc-4kks2, resource: bindings, ignored listing per whitelist
Jan 21 22:11:53.804: INFO: namespace e2e-tests-gc-4kks2 deletion completed in 8.427623256s

• [SLOW TEST:48.893 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 22:11:53.805: INFO: >>> kubeConfig: /tmp/kubeconfig-933165938
STEP: Building a namespace api object, basename init-container
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-init-container-mn9kh
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
Jan 21 22:11:54.136: INFO: PodSpec: initContainers in spec.initContainers
Jan 21 22:12:36.182: INFO: init container has failed twice: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-init-8f4d7858-1dc9-11e9-8130-be6597f3ae53", GenerateName:"", Namespace:"e2e-tests-init-container-mn9kh", SelfLink:"/api/v1/namespaces/e2e-tests-init-container-mn9kh/pods/pod-init-8f4d7858-1dc9-11e9-8130-be6597f3ae53", UID:"8f4e3e46-1dc9-11e9-903f-ee5d7ad9296f", ResourceVersion:"43362", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63683705514, loc:(*time.Location)(0x6c43b60)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"136185448"}, Annotations:map[string]string{"kubernetes.io/psp":"e2e-test-privileged-psp"}, OwnerReferences:[]v1.OwnerReference(nil), Initializers:(*v1.Initializers)(nil), Finalizers:[]string(nil), ClusterName:""}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"default-token-jm9gj", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(0xc4218a37c0), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil)}}}, InitContainers:[]v1.Container{v1.Container{Name:"init1", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/false"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-jm9gj", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}, v1.Container{Name:"init2", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/true"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-jm9gj", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, Containers:[]v1.Container{v1.Container{Name:"run1", Image:"k8s.gcr.io/pause:3.1", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}, Requests:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-jm9gj", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc42247bab8), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"10.191.28.59", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc421e59bc0), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc42247bba0)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc42247bbc0)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc42247bbc8), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil)}, Status:v1.PodStatus{Phase:"Pending", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63683705514, loc:(*time.Location)(0x6c43b60)}}, Reason:"ContainersNotInitialized", Message:"containers with incomplete status: [init1 init2]"}, v1.PodCondition{Type:"Ready", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63683705514, loc:(*time.Location)(0x6c43b60)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"ContainersReady", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63683705514, loc:(*time.Location)(0x6c43b60)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63683705514, loc:(*time.Location)(0x6c43b60)}}, Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"10.191.28.59", PodIP:"172.30.156.180", StartTime:(*v1.Time)(0xc421fbe280), InitContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"init1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc421dfe2a0)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc421dfe310)}, Ready:false, RestartCount:3, Image:"docker.io/library/busybox:1.29", ImageID:"docker.io/library/busybox@sha256:8ccbac733d19c0dd4d70b4f0c1e12245b5fa3ad24758a11035ee505c629c0796", ContainerID:"containerd://cd347bcb84dec4de41b3d4b990714586dbc127d573a0b98d72aeaae185feaf0a"}, v1.ContainerStatus{Name:"init2", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc421fbe2c0), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"docker.io/library/busybox:1.29", ImageID:"", ContainerID:""}}, ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"run1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc421fbe2a0), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"k8s.gcr.io/pause:3.1", ImageID:"", ContainerID:""}}, QOSClass:"Guaranteed"}}
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 22:12:36.183: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-init-container-mn9kh" for this suite.
Jan 21 22:13:00.282: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 22:13:00.491: INFO: namespace: e2e-tests-init-container-mn9kh, resource: bindings, ignored listing per whitelist
Jan 21 22:13:00.693: INFO: namespace e2e-tests-init-container-mn9kh deletion completed in 24.49516184s

• [SLOW TEST:66.889 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 22:13:00.694: INFO: >>> kubeConfig: /tmp/kubeconfig-933165938
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-g5h7t
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Jan 21 22:13:01.051: INFO: Waiting up to 5m0s for pod "downwardapi-volume-b72c7298-1dc9-11e9-8130-be6597f3ae53" in namespace "e2e-tests-downward-api-g5h7t" to be "success or failure"
Jan 21 22:13:01.062: INFO: Pod "downwardapi-volume-b72c7298-1dc9-11e9-8130-be6597f3ae53": Phase="Pending", Reason="", readiness=false. Elapsed: 10.141724ms
Jan 21 22:13:03.073: INFO: Pod "downwardapi-volume-b72c7298-1dc9-11e9-8130-be6597f3ae53": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.021209874s
STEP: Saw pod success
Jan 21 22:13:03.073: INFO: Pod "downwardapi-volume-b72c7298-1dc9-11e9-8130-be6597f3ae53" satisfied condition "success or failure"
Jan 21 22:13:03.085: INFO: Trying to get logs from node 10.191.28.39 pod downwardapi-volume-b72c7298-1dc9-11e9-8130-be6597f3ae53 container client-container: <nil>
STEP: delete the pod
Jan 21 22:13:03.160: INFO: Waiting for pod downwardapi-volume-b72c7298-1dc9-11e9-8130-be6597f3ae53 to disappear
Jan 21 22:13:03.175: INFO: Pod downwardapi-volume-b72c7298-1dc9-11e9-8130-be6597f3ae53 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 22:13:03.175: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-g5h7t" for this suite.
Jan 21 22:13:09.221: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 22:13:09.531: INFO: namespace: e2e-tests-downward-api-g5h7t, resource: bindings, ignored listing per whitelist
Jan 21 22:13:09.567: INFO: namespace e2e-tests-downward-api-g5h7t deletion completed in 6.378398196s

• [SLOW TEST:8.873 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 22:13:09.568: INFO: >>> kubeConfig: /tmp/kubeconfig-933165938
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-kmhb7
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Jan 21 22:13:10.088: INFO: Waiting up to 5m0s for pod "downwardapi-volume-bc8f8024-1dc9-11e9-8130-be6597f3ae53" in namespace "e2e-tests-downward-api-kmhb7" to be "success or failure"
Jan 21 22:13:10.165: INFO: Pod "downwardapi-volume-bc8f8024-1dc9-11e9-8130-be6597f3ae53": Phase="Pending", Reason="", readiness=false. Elapsed: 76.33298ms
Jan 21 22:13:12.176: INFO: Pod "downwardapi-volume-bc8f8024-1dc9-11e9-8130-be6597f3ae53": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.087544259s
STEP: Saw pod success
Jan 21 22:13:12.176: INFO: Pod "downwardapi-volume-bc8f8024-1dc9-11e9-8130-be6597f3ae53" satisfied condition "success or failure"
Jan 21 22:13:12.188: INFO: Trying to get logs from node 10.191.28.59 pod downwardapi-volume-bc8f8024-1dc9-11e9-8130-be6597f3ae53 container client-container: <nil>
STEP: delete the pod
Jan 21 22:13:12.264: INFO: Waiting for pod downwardapi-volume-bc8f8024-1dc9-11e9-8130-be6597f3ae53 to disappear
Jan 21 22:13:12.274: INFO: Pod downwardapi-volume-bc8f8024-1dc9-11e9-8130-be6597f3ae53 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 22:13:12.274: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-kmhb7" for this suite.
Jan 21 22:13:18.332: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 22:13:18.387: INFO: namespace: e2e-tests-downward-api-kmhb7, resource: bindings, ignored listing per whitelist
Jan 21 22:13:18.688: INFO: namespace e2e-tests-downward-api-kmhb7 deletion completed in 6.396003815s

• [SLOW TEST:9.121 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-storage] ConfigMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 22:13:18.688: INFO: >>> kubeConfig: /tmp/kubeconfig-933165938
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-54762
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name cm-test-opt-del-c1eeece7-1dc9-11e9-8130-be6597f3ae53
STEP: Creating configMap with name cm-test-opt-upd-c1eeed5e-1dc9-11e9-8130-be6597f3ae53
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-c1eeece7-1dc9-11e9-8130-be6597f3ae53
STEP: Updating configmap cm-test-opt-upd-c1eeed5e-1dc9-11e9-8130-be6597f3ae53
STEP: Creating configMap with name cm-test-opt-create-c1eeed9f-1dc9-11e9-8130-be6597f3ae53
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 22:14:46.581: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-54762" for this suite.
Jan 21 22:15:10.630: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 22:15:10.923: INFO: namespace: e2e-tests-configmap-54762, resource: bindings, ignored listing per whitelist
Jan 21 22:15:11.084: INFO: namespace e2e-tests-configmap-54762 deletion completed in 24.489137702s

• [SLOW TEST:112.396 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should support rollover [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 22:15:11.088: INFO: >>> kubeConfig: /tmp/kubeconfig-933165938
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-deployment-bs4tm
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should support rollover [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Jan 21 22:15:11.592: INFO: Pod name rollover-pod: Found 0 pods out of 1
Jan 21 22:15:16.603: INFO: Pod name rollover-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Jan 21 22:15:16.603: INFO: Waiting for pods owned by replica set "test-rollover-controller" to become ready
Jan 21 22:15:18.614: INFO: Creating deployment "test-rollover-deployment"
Jan 21 22:15:18.633: INFO: Make sure deployment "test-rollover-deployment" performs scaling operations
Jan 21 22:15:20.664: INFO: Check revision of new replica set for deployment "test-rollover-deployment"
Jan 21 22:15:20.685: INFO: Ensure that both replica sets have 1 created replica
Jan 21 22:15:20.707: INFO: Rollover old replica sets for deployment "test-rollover-deployment" with new image update
Jan 21 22:15:20.728: INFO: Updating deployment test-rollover-deployment
Jan 21 22:15:20.728: INFO: Wait deployment "test-rollover-deployment" to be observed by the deployment controller
Jan 21 22:15:22.745: INFO: Wait for revision update of deployment "test-rollover-deployment" to 2
Jan 21 22:15:22.764: INFO: Make sure deployment "test-rollover-deployment" is complete
Jan 21 22:15:22.783: INFO: all replica sets need to contain the pod-template-hash label
Jan 21 22:15:22.784: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63683705718, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63683705718, loc:(*time.Location)(0x6c43b60)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63683705722, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63683705718, loc:(*time.Location)(0x6c43b60)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-5b76ff8c4\" is progressing."}}, CollisionCount:(*int32)(nil)}
Jan 21 22:15:24.803: INFO: all replica sets need to contain the pod-template-hash label
Jan 21 22:15:24.803: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63683705718, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63683705718, loc:(*time.Location)(0x6c43b60)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63683705722, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63683705718, loc:(*time.Location)(0x6c43b60)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-5b76ff8c4\" is progressing."}}, CollisionCount:(*int32)(nil)}
Jan 21 22:15:26.805: INFO: all replica sets need to contain the pod-template-hash label
Jan 21 22:15:26.805: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63683705718, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63683705718, loc:(*time.Location)(0x6c43b60)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63683705722, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63683705718, loc:(*time.Location)(0x6c43b60)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-5b76ff8c4\" is progressing."}}, CollisionCount:(*int32)(nil)}
Jan 21 22:15:28.802: INFO: all replica sets need to contain the pod-template-hash label
Jan 21 22:15:28.803: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63683705718, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63683705718, loc:(*time.Location)(0x6c43b60)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63683705722, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63683705718, loc:(*time.Location)(0x6c43b60)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-5b76ff8c4\" is progressing."}}, CollisionCount:(*int32)(nil)}
Jan 21 22:15:30.803: INFO: all replica sets need to contain the pod-template-hash label
Jan 21 22:15:30.803: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63683705718, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63683705718, loc:(*time.Location)(0x6c43b60)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63683705722, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63683705718, loc:(*time.Location)(0x6c43b60)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-5b76ff8c4\" is progressing."}}, CollisionCount:(*int32)(nil)}
Jan 21 22:15:32.803: INFO: 
Jan 21 22:15:32.803: INFO: Ensure that both old replica sets have no replicas
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Jan 21 22:15:32.832: INFO: Deployment "test-rollover-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment,GenerateName:,Namespace:e2e-tests-deployment-bs4tm,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-bs4tm/deployments/test-rollover-deployment,UID:092e4bf1-1dca-11e9-903f-ee5d7ad9296f,ResourceVersion:43921,Generation:2,CreationTimestamp:2019-01-21 22:15:18 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:0,MaxSurge:1,},},MinReadySeconds:10,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[{Available True 2019-01-21 22:15:18 +0000 UTC 2019-01-21 22:15:18 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2019-01-21 22:15:32 +0000 UTC 2019-01-21 22:15:18 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-rollover-deployment-5b76ff8c4" has successfully progressed.}],ReadyReplicas:1,CollisionCount:nil,},}

Jan 21 22:15:32.846: INFO: New ReplicaSet "test-rollover-deployment-5b76ff8c4" of Deployment "test-rollover-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-5b76ff8c4,GenerateName:,Namespace:e2e-tests-deployment-bs4tm,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-bs4tm/replicasets/test-rollover-deployment-5b76ff8c4,UID:0a7073ad-1dca-11e9-903f-ee5d7ad9296f,ResourceVersion:43912,Generation:2,CreationTimestamp:2019-01-21 22:15:20 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 5b76ff8c4,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment 092e4bf1-1dca-11e9-903f-ee5d7ad9296f 0xc420fcfc97 0xc420fcfc98}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 5b76ff8c4,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 5b76ff8c4,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:2,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Jan 21 22:15:32.846: INFO: All old ReplicaSets of Deployment "test-rollover-deployment":
Jan 21 22:15:32.846: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-controller,GenerateName:,Namespace:e2e-tests-deployment-bs4tm,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-bs4tm/replicasets/test-rollover-controller,UID:04fb5d25-1dca-11e9-903f-ee5d7ad9296f,ResourceVersion:43920,Generation:2,CreationTimestamp:2019-01-21 22:15:11 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod: nginx,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment 092e4bf1-1dca-11e9-903f-ee5d7ad9296f 0xc420fcfbbe 0xc420fcfbbf}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Jan 21 22:15:32.847: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-6975f4fb87,GenerateName:,Namespace:e2e-tests-deployment-bs4tm,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-bs4tm/replicasets/test-rollover-deployment-6975f4fb87,UID:0933f798-1dca-11e9-903f-ee5d7ad9296f,ResourceVersion:43876,Generation:2,CreationTimestamp:2019-01-21 22:15:18 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6975f4fb87,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment 092e4bf1-1dca-11e9-903f-ee5d7ad9296f 0xc420fcfd57 0xc420fcfd58}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 6975f4fb87,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6975f4fb87,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis-slave gcr.io/google_samples/gb-redisslave:nonexistent [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Jan 21 22:15:32.859: INFO: Pod "test-rollover-deployment-5b76ff8c4-lxncx" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-5b76ff8c4-lxncx,GenerateName:test-rollover-deployment-5b76ff8c4-,Namespace:e2e-tests-deployment-bs4tm,SelfLink:/api/v1/namespaces/e2e-tests-deployment-bs4tm/pods/test-rollover-deployment-5b76ff8c4-lxncx,UID:0a77fe85-1dca-11e9-903f-ee5d7ad9296f,ResourceVersion:43893,Generation:0,CreationTimestamp:2019-01-21 22:15:20 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 5b76ff8c4,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet test-rollover-deployment-5b76ff8c4 0a7073ad-1dca-11e9-903f-ee5d7ad9296f 0xc420f72440 0xc420f72441}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-mkrkp {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-mkrkp,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-mkrkp true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.191.28.59,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc420f724b0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc420f724d0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-21 22:15:20 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-01-21 22:15:22 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-01-21 22:15:22 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-21 22:15:20 +0000 UTC  }],Message:,Reason:,HostIP:10.191.28.59,PodIP:172.30.156.176,StartTime:2019-01-21 22:15:20 +0000 UTC,ContainerStatuses:[{redis {nil ContainerStateRunning{StartedAt:2019-01-21 22:15:21 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/redis:1.0 gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830 containerd://f9d97d8d9d282a52eeba0f414fb68d812443d3d8ef60dd3775934b34206023d3}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 22:15:32.860: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-bs4tm" for this suite.
Jan 21 22:15:38.908: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 22:15:39.466: INFO: namespace: e2e-tests-deployment-bs4tm, resource: bindings, ignored listing per whitelist
Jan 21 22:15:39.627: INFO: namespace e2e-tests-deployment-bs4tm deletion completed in 6.75258918s

• [SLOW TEST:28.539 seconds]
[sig-apps] Deployment
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  deployment should support rollover [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 22:15:39.628: INFO: >>> kubeConfig: /tmp/kubeconfig-933165938
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-fhczr
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-15e9415b-1dca-11e9-8130-be6597f3ae53
STEP: Creating a pod to test consume configMaps
Jan 21 22:15:40.094: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-15f8fbe4-1dca-11e9-8130-be6597f3ae53" in namespace "e2e-tests-projected-fhczr" to be "success or failure"
Jan 21 22:15:40.104: INFO: Pod "pod-projected-configmaps-15f8fbe4-1dca-11e9-8130-be6597f3ae53": Phase="Pending", Reason="", readiness=false. Elapsed: 9.690528ms
Jan 21 22:15:42.118: INFO: Pod "pod-projected-configmaps-15f8fbe4-1dca-11e9-8130-be6597f3ae53": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.023195539s
STEP: Saw pod success
Jan 21 22:15:42.118: INFO: Pod "pod-projected-configmaps-15f8fbe4-1dca-11e9-8130-be6597f3ae53" satisfied condition "success or failure"
Jan 21 22:15:42.128: INFO: Trying to get logs from node 10.191.28.39 pod pod-projected-configmaps-15f8fbe4-1dca-11e9-8130-be6597f3ae53 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Jan 21 22:15:42.193: INFO: Waiting for pod pod-projected-configmaps-15f8fbe4-1dca-11e9-8130-be6597f3ae53 to disappear
Jan 21 22:15:42.205: INFO: Pod pod-projected-configmaps-15f8fbe4-1dca-11e9-8130-be6597f3ae53 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 22:15:42.205: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-fhczr" for this suite.
Jan 21 22:15:48.253: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 22:15:48.289: INFO: namespace: e2e-tests-projected-fhczr, resource: bindings, ignored listing per whitelist
Jan 21 22:15:48.598: INFO: namespace e2e-tests-projected-fhczr deletion completed in 6.377741014s

• [SLOW TEST:8.970 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-apps] ReplicaSet 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 22:15:48.599: INFO: >>> kubeConfig: /tmp/kubeconfig-933165938
STEP: Building a namespace api object, basename replicaset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-replicaset-5p76v
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Jan 21 22:15:49.002: INFO: Creating ReplicaSet my-hostname-basic-1b4b2e90-1dca-11e9-8130-be6597f3ae53
Jan 21 22:15:49.028: INFO: Pod name my-hostname-basic-1b4b2e90-1dca-11e9-8130-be6597f3ae53: Found 0 pods out of 1
Jan 21 22:15:54.042: INFO: Pod name my-hostname-basic-1b4b2e90-1dca-11e9-8130-be6597f3ae53: Found 1 pods out of 1
Jan 21 22:15:54.043: INFO: Ensuring a pod for ReplicaSet "my-hostname-basic-1b4b2e90-1dca-11e9-8130-be6597f3ae53" is running
Jan 21 22:15:54.053: INFO: Pod "my-hostname-basic-1b4b2e90-1dca-11e9-8130-be6597f3ae53-9h2zb" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-01-21 22:15:49 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-01-21 22:15:50 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-01-21 22:15:50 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-01-21 22:15:49 +0000 UTC Reason: Message:}])
Jan 21 22:15:54.053: INFO: Trying to dial the pod
Jan 21 22:15:59.100: INFO: Controller my-hostname-basic-1b4b2e90-1dca-11e9-8130-be6597f3ae53: Got expected result from replica 1 [my-hostname-basic-1b4b2e90-1dca-11e9-8130-be6597f3ae53-9h2zb]: "my-hostname-basic-1b4b2e90-1dca-11e9-8130-be6597f3ae53-9h2zb", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 22:15:59.100: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-replicaset-5p76v" for this suite.
Jan 21 22:16:05.194: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 22:16:05.368: INFO: namespace: e2e-tests-replicaset-5p76v, resource: bindings, ignored listing per whitelist
Jan 21 22:16:05.560: INFO: namespace e2e-tests-replicaset-5p76v deletion completed in 6.438439262s

• [SLOW TEST:16.961 seconds]
[sig-apps] ReplicaSet
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 22:16:05.560: INFO: >>> kubeConfig: /tmp/kubeconfig-933165938
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-secrets-d7b2j
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-map-255ac194-1dca-11e9-8130-be6597f3ae53
STEP: Creating a pod to test consume secrets
Jan 21 22:16:05.909: INFO: Waiting up to 5m0s for pod "pod-secrets-255c2e58-1dca-11e9-8130-be6597f3ae53" in namespace "e2e-tests-secrets-d7b2j" to be "success or failure"
Jan 21 22:16:05.923: INFO: Pod "pod-secrets-255c2e58-1dca-11e9-8130-be6597f3ae53": Phase="Pending", Reason="", readiness=false. Elapsed: 13.666878ms
Jan 21 22:16:07.934: INFO: Pod "pod-secrets-255c2e58-1dca-11e9-8130-be6597f3ae53": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.024837977s
STEP: Saw pod success
Jan 21 22:16:07.934: INFO: Pod "pod-secrets-255c2e58-1dca-11e9-8130-be6597f3ae53" satisfied condition "success or failure"
Jan 21 22:16:07.945: INFO: Trying to get logs from node 10.191.28.39 pod pod-secrets-255c2e58-1dca-11e9-8130-be6597f3ae53 container secret-volume-test: <nil>
STEP: delete the pod
Jan 21 22:16:07.998: INFO: Waiting for pod pod-secrets-255c2e58-1dca-11e9-8130-be6597f3ae53 to disappear
Jan 21 22:16:08.073: INFO: Pod pod-secrets-255c2e58-1dca-11e9-8130-be6597f3ae53 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 22:16:08.073: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-d7b2j" for this suite.
Jan 21 22:16:14.124: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 22:16:14.345: INFO: namespace: e2e-tests-secrets-d7b2j, resource: bindings, ignored listing per whitelist
Jan 21 22:16:14.486: INFO: namespace e2e-tests-secrets-d7b2j deletion completed in 6.398560459s

• [SLOW TEST:8.925 seconds]
[sig-storage] Secrets
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 22:16:14.487: INFO: >>> kubeConfig: /tmp/kubeconfig-933165938
STEP: Building a namespace api object, basename namespaces
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-namespaces-qdfgv
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a test namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-nsdeletetest-5f4vn
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a pod in the namespace
STEP: Waiting for the pod to have running status
STEP: Creating an uninitialized pod in the namespace
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
Jan 21 22:16:24.776: INFO: error from create uninitialized namespace: Internal error occurred: object deleted while waiting for creation
STEP: Recreating the namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-nsdeletetest-mwtgl
STEP: Verifying there are no pods in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 22:16:42.470: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-namespaces-qdfgv" for this suite.
Jan 21 22:16:48.518: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 22:16:48.703: INFO: namespace: e2e-tests-namespaces-qdfgv, resource: bindings, ignored listing per whitelist
Jan 21 22:16:48.995: INFO: namespace e2e-tests-namespaces-qdfgv deletion completed in 6.510475367s
STEP: Destroying namespace "e2e-tests-nsdeletetest-5f4vn" for this suite.
Jan 21 22:16:49.004: INFO: Namespace e2e-tests-nsdeletetest-5f4vn was already deleted
STEP: Destroying namespace "e2e-tests-nsdeletetest-mwtgl" for this suite.
Jan 21 22:16:55.068: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 22:16:55.448: INFO: namespace: e2e-tests-nsdeletetest-mwtgl, resource: bindings, ignored listing per whitelist
Jan 21 22:16:55.502: INFO: namespace e2e-tests-nsdeletetest-mwtgl deletion completed in 6.497679969s

• [SLOW TEST:41.016 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-api-machinery] Downward API 
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 22:16:55.502: INFO: >>> kubeConfig: /tmp/kubeconfig-933165938
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-p7psl
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Jan 21 22:16:55.856: INFO: Waiting up to 5m0s for pod "downward-api-4320b7e1-1dca-11e9-8130-be6597f3ae53" in namespace "e2e-tests-downward-api-p7psl" to be "success or failure"
Jan 21 22:16:55.869: INFO: Pod "downward-api-4320b7e1-1dca-11e9-8130-be6597f3ae53": Phase="Pending", Reason="", readiness=false. Elapsed: 13.01186ms
Jan 21 22:16:57.896: INFO: Pod "downward-api-4320b7e1-1dca-11e9-8130-be6597f3ae53": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.039889908s
STEP: Saw pod success
Jan 21 22:16:57.896: INFO: Pod "downward-api-4320b7e1-1dca-11e9-8130-be6597f3ae53" satisfied condition "success or failure"
Jan 21 22:16:57.907: INFO: Trying to get logs from node 10.191.28.59 pod downward-api-4320b7e1-1dca-11e9-8130-be6597f3ae53 container dapi-container: <nil>
STEP: delete the pod
Jan 21 22:16:57.983: INFO: Waiting for pod downward-api-4320b7e1-1dca-11e9-8130-be6597f3ae53 to disappear
Jan 21 22:16:57.993: INFO: Pod downward-api-4320b7e1-1dca-11e9-8130-be6597f3ae53 no longer exists
[AfterEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 22:16:57.994: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-p7psl" for this suite.
Jan 21 22:17:04.058: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 22:17:04.515: INFO: namespace: e2e-tests-downward-api-p7psl, resource: bindings, ignored listing per whitelist
Jan 21 22:17:04.615: INFO: namespace e2e-tests-downward-api-p7psl deletion completed in 6.59376772s

• [SLOW TEST:9.113 seconds]
[sig-api-machinery] Downward API
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Downward API volume 
  should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 22:17:04.617: INFO: >>> kubeConfig: /tmp/kubeconfig-933165938
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-l9h8q
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Jan 21 22:17:05.551: INFO: Waiting up to 5m0s for pod "downwardapi-volume-48e8c2a2-1dca-11e9-8130-be6597f3ae53" in namespace "e2e-tests-downward-api-l9h8q" to be "success or failure"
Jan 21 22:17:05.561: INFO: Pod "downwardapi-volume-48e8c2a2-1dca-11e9-8130-be6597f3ae53": Phase="Pending", Reason="", readiness=false. Elapsed: 9.999383ms
Jan 21 22:17:07.574: INFO: Pod "downwardapi-volume-48e8c2a2-1dca-11e9-8130-be6597f3ae53": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.022276433s
STEP: Saw pod success
Jan 21 22:17:07.574: INFO: Pod "downwardapi-volume-48e8c2a2-1dca-11e9-8130-be6597f3ae53" satisfied condition "success or failure"
Jan 21 22:17:07.585: INFO: Trying to get logs from node 10.191.28.59 pod downwardapi-volume-48e8c2a2-1dca-11e9-8130-be6597f3ae53 container client-container: <nil>
STEP: delete the pod
Jan 21 22:17:07.642: INFO: Waiting for pod downwardapi-volume-48e8c2a2-1dca-11e9-8130-be6597f3ae53 to disappear
Jan 21 22:17:07.652: INFO: Pod downwardapi-volume-48e8c2a2-1dca-11e9-8130-be6597f3ae53 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 22:17:07.653: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-l9h8q" for this suite.
Jan 21 22:17:13.701: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 22:17:13.856: INFO: namespace: e2e-tests-downward-api-l9h8q, resource: bindings, ignored listing per whitelist
Jan 21 22:17:14.077: INFO: namespace e2e-tests-downward-api-l9h8q deletion completed in 6.4089305s

• [SLOW TEST:9.460 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl patch 
  should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 22:17:14.078: INFO: >>> kubeConfig: /tmp/kubeconfig-933165938
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-tvlrz
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating Redis RC
Jan 21 22:17:14.441: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-933165938 create -f - --namespace=e2e-tests-kubectl-tvlrz'
Jan 21 22:17:14.864: INFO: stderr: ""
Jan 21 22:17:14.864: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
Jan 21 22:17:15.875: INFO: Selector matched 1 pods for map[app:redis]
Jan 21 22:17:15.875: INFO: Found 0 / 1
Jan 21 22:17:16.876: INFO: Selector matched 1 pods for map[app:redis]
Jan 21 22:17:16.876: INFO: Found 0 / 1
Jan 21 22:17:17.875: INFO: Selector matched 1 pods for map[app:redis]
Jan 21 22:17:17.875: INFO: Found 1 / 1
Jan 21 22:17:17.875: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
STEP: patching all pods
Jan 21 22:17:17.885: INFO: Selector matched 1 pods for map[app:redis]
Jan 21 22:17:17.885: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Jan 21 22:17:17.886: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-933165938 patch pod redis-master-kszjg --namespace=e2e-tests-kubectl-tvlrz -p {"metadata":{"annotations":{"x":"y"}}}'
Jan 21 22:17:18.669: INFO: stderr: ""
Jan 21 22:17:18.669: INFO: stdout: "pod/redis-master-kszjg patched\n"
STEP: checking annotations
Jan 21 22:17:18.682: INFO: Selector matched 1 pods for map[app:redis]
Jan 21 22:17:18.682: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 22:17:18.682: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-tvlrz" for this suite.
Jan 21 22:17:42.741: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 22:17:42.909: INFO: namespace: e2e-tests-kubectl-tvlrz, resource: bindings, ignored listing per whitelist
Jan 21 22:17:43.119: INFO: namespace e2e-tests-kubectl-tvlrz deletion completed in 24.421306378s

• [SLOW TEST:29.041 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl patch
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should add annotations for pods in rc  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 22:17:43.120: INFO: >>> kubeConfig: /tmp/kubeconfig-933165938
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-gc-vtdkf
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the rc1
STEP: create the rc2
STEP: set half of pods created by rc simpletest-rc-to-be-deleted to have rc simpletest-rc-to-stay as owner as well
STEP: delete the rc simpletest-rc-to-be-deleted
STEP: wait for the rc to be deleted
STEP: Gathering metrics
W0121 22:17:53.686607      15 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Jan 21 22:17:53.686: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 22:17:53.686: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-vtdkf" for this suite.
Jan 21 22:18:01.737: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 22:18:01.895: INFO: namespace: e2e-tests-gc-vtdkf, resource: bindings, ignored listing per whitelist
Jan 21 22:18:02.312: INFO: namespace e2e-tests-gc-vtdkf deletion completed in 8.608265262s

• [SLOW TEST:19.192 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 22:18:02.315: INFO: >>> kubeConfig: /tmp/kubeconfig-933165938
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-x4p25
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0777 on tmpfs
Jan 21 22:18:02.666: INFO: Waiting up to 5m0s for pod "pod-6af40584-1dca-11e9-8130-be6597f3ae53" in namespace "e2e-tests-emptydir-x4p25" to be "success or failure"
Jan 21 22:18:02.675: INFO: Pod "pod-6af40584-1dca-11e9-8130-be6597f3ae53": Phase="Pending", Reason="", readiness=false. Elapsed: 9.414955ms
Jan 21 22:18:04.686: INFO: Pod "pod-6af40584-1dca-11e9-8130-be6597f3ae53": Phase="Pending", Reason="", readiness=false. Elapsed: 2.020139923s
Jan 21 22:18:06.697: INFO: Pod "pod-6af40584-1dca-11e9-8130-be6597f3ae53": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.031413147s
STEP: Saw pod success
Jan 21 22:18:06.697: INFO: Pod "pod-6af40584-1dca-11e9-8130-be6597f3ae53" satisfied condition "success or failure"
Jan 21 22:18:06.711: INFO: Trying to get logs from node 10.191.28.59 pod pod-6af40584-1dca-11e9-8130-be6597f3ae53 container test-container: <nil>
STEP: delete the pod
Jan 21 22:18:06.795: INFO: Waiting for pod pod-6af40584-1dca-11e9-8130-be6597f3ae53 to disappear
Jan 21 22:18:06.805: INFO: Pod pod-6af40584-1dca-11e9-8130-be6597f3ae53 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 22:18:06.805: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-x4p25" for this suite.
Jan 21 22:18:12.885: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 22:18:13.168: INFO: namespace: e2e-tests-emptydir-x4p25, resource: bindings, ignored listing per whitelist
Jan 21 22:18:13.329: INFO: namespace e2e-tests-emptydir-x4p25 deletion completed in 6.478878148s

• [SLOW TEST:11.014 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] KubeletManagedEtcHosts 
  should test kubelet managed /etc/hosts file [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 22:18:13.332: INFO: >>> kubeConfig: /tmp/kubeconfig-933165938
STEP: Building a namespace api object, basename e2e-kubelet-etc-hosts
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-e2e-kubelet-etc-hosts-6zgbx
STEP: Waiting for a default service account to be provisioned in namespace
[It] should test kubelet managed /etc/hosts file [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Setting up the test
STEP: Creating hostNetwork=false pod
STEP: Creating hostNetwork=true pod
STEP: Running the test
STEP: Verifying /etc/hosts of container is kubelet-managed for pod with hostNetwork=false
Jan 21 22:18:17.798: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-6zgbx PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jan 21 22:18:17.798: INFO: >>> kubeConfig: /tmp/kubeconfig-933165938
Jan 21 22:18:18.007: INFO: Exec stderr: ""
Jan 21 22:18:18.007: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-6zgbx PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jan 21 22:18:18.007: INFO: >>> kubeConfig: /tmp/kubeconfig-933165938
Jan 21 22:18:18.208: INFO: Exec stderr: ""
Jan 21 22:18:18.208: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-6zgbx PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jan 21 22:18:18.208: INFO: >>> kubeConfig: /tmp/kubeconfig-933165938
Jan 21 22:18:18.423: INFO: Exec stderr: ""
Jan 21 22:18:18.423: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-6zgbx PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jan 21 22:18:18.423: INFO: >>> kubeConfig: /tmp/kubeconfig-933165938
Jan 21 22:18:18.590: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts of container is not kubelet-managed since container specifies /etc/hosts mount
Jan 21 22:18:18.591: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-6zgbx PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jan 21 22:18:18.591: INFO: >>> kubeConfig: /tmp/kubeconfig-933165938
Jan 21 22:18:18.777: INFO: Exec stderr: ""
Jan 21 22:18:18.777: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-6zgbx PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jan 21 22:18:18.778: INFO: >>> kubeConfig: /tmp/kubeconfig-933165938
Jan 21 22:18:18.951: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts content of container is not kubelet-managed for pod with hostNetwork=true
Jan 21 22:18:18.952: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-6zgbx PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jan 21 22:18:18.952: INFO: >>> kubeConfig: /tmp/kubeconfig-933165938
Jan 21 22:18:19.188: INFO: Exec stderr: ""
Jan 21 22:18:19.188: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-6zgbx PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jan 21 22:18:19.188: INFO: >>> kubeConfig: /tmp/kubeconfig-933165938
Jan 21 22:18:19.384: INFO: Exec stderr: ""
Jan 21 22:18:19.384: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-6zgbx PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jan 21 22:18:19.384: INFO: >>> kubeConfig: /tmp/kubeconfig-933165938
Jan 21 22:18:19.577: INFO: Exec stderr: ""
Jan 21 22:18:19.577: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-6zgbx PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jan 21 22:18:19.577: INFO: >>> kubeConfig: /tmp/kubeconfig-933165938
Jan 21 22:18:19.777: INFO: Exec stderr: ""
[AfterEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 22:18:19.778: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-e2e-kubelet-etc-hosts-6zgbx" for this suite.
Jan 21 22:19:09.828: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 22:19:10.094: INFO: namespace: e2e-tests-e2e-kubelet-etc-hosts-6zgbx, resource: bindings, ignored listing per whitelist
Jan 21 22:19:10.190: INFO: namespace e2e-tests-e2e-kubelet-etc-hosts-6zgbx deletion completed in 50.396935105s

• [SLOW TEST:56.858 seconds]
[k8s.io] KubeletManagedEtcHosts
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should test kubelet managed /etc/hosts file [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should have monotonically increasing restart count [Slow][NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 22:19:10.192: INFO: >>> kubeConfig: /tmp/kubeconfig-933165938
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-container-probe-9fktj
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should have monotonically increasing restart count [Slow][NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-http in namespace e2e-tests-container-probe-9fktj
Jan 21 22:19:12.553: INFO: Started pod liveness-http in namespace e2e-tests-container-probe-9fktj
STEP: checking the pod's current state and verifying that restartCount is present
Jan 21 22:19:12.572: INFO: Initial restart count of pod liveness-http is 0
Jan 21 22:19:25.022: INFO: Restart count of pod e2e-tests-container-probe-9fktj/liveness-http is now 1 (12.449382672s elapsed)
Jan 21 22:19:45.150: INFO: Restart count of pod e2e-tests-container-probe-9fktj/liveness-http is now 2 (32.577799444s elapsed)
Jan 21 22:20:05.263: INFO: Restart count of pod e2e-tests-container-probe-9fktj/liveness-http is now 3 (52.690684387s elapsed)
Jan 21 22:20:25.387: INFO: Restart count of pod e2e-tests-container-probe-9fktj/liveness-http is now 4 (1m12.81490049s elapsed)
Jan 21 22:21:34.165: INFO: Restart count of pod e2e-tests-container-probe-9fktj/liveness-http is now 5 (2m21.592232218s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 22:21:34.264: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-9fktj" for this suite.
Jan 21 22:21:40.316: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 22:21:40.637: INFO: namespace: e2e-tests-container-probe-9fktj, resource: bindings, ignored listing per whitelist
Jan 21 22:21:40.666: INFO: namespace e2e-tests-container-probe-9fktj deletion completed in 6.385652934s

• [SLOW TEST:150.474 seconds]
[k8s.io] Probing container
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should have monotonically increasing restart count [Slow][NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 22:21:40.666: INFO: >>> kubeConfig: /tmp/kubeconfig-933165938
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-ph2nh
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-ed9ef101-1dca-11e9-8130-be6597f3ae53
STEP: Creating a pod to test consume configMaps
Jan 21 22:21:41.903: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-eda0667a-1dca-11e9-8130-be6597f3ae53" in namespace "e2e-tests-projected-ph2nh" to be "success or failure"
Jan 21 22:21:41.914: INFO: Pod "pod-projected-configmaps-eda0667a-1dca-11e9-8130-be6597f3ae53": Phase="Pending", Reason="", readiness=false. Elapsed: 10.725497ms
Jan 21 22:21:43.925: INFO: Pod "pod-projected-configmaps-eda0667a-1dca-11e9-8130-be6597f3ae53": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.021833096s
STEP: Saw pod success
Jan 21 22:21:43.926: INFO: Pod "pod-projected-configmaps-eda0667a-1dca-11e9-8130-be6597f3ae53" satisfied condition "success or failure"
Jan 21 22:21:43.935: INFO: Trying to get logs from node 10.191.28.59 pod pod-projected-configmaps-eda0667a-1dca-11e9-8130-be6597f3ae53 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Jan 21 22:21:43.992: INFO: Waiting for pod pod-projected-configmaps-eda0667a-1dca-11e9-8130-be6597f3ae53 to disappear
Jan 21 22:21:44.002: INFO: Pod pod-projected-configmaps-eda0667a-1dca-11e9-8130-be6597f3ae53 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 22:21:44.003: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-ph2nh" for this suite.
Jan 21 22:21:50.053: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 22:21:50.275: INFO: namespace: e2e-tests-projected-ph2nh, resource: bindings, ignored listing per whitelist
Jan 21 22:21:50.516: INFO: namespace e2e-tests-projected-ph2nh deletion completed in 6.499683688s

• [SLOW TEST:9.850 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] version v1
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 22:21:50.517: INFO: >>> kubeConfig: /tmp/kubeconfig-933165938
STEP: Building a namespace api object, basename proxy
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-proxy-crfdc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Jan 21 22:21:50.887: INFO: (0) /api/v1/nodes/10.191.28.39/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 20.112797ms)
Jan 21 22:21:50.901: INFO: (1) /api/v1/nodes/10.191.28.39/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 13.872205ms)
Jan 21 22:21:50.916: INFO: (2) /api/v1/nodes/10.191.28.39/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 14.71923ms)
Jan 21 22:21:50.934: INFO: (3) /api/v1/nodes/10.191.28.39/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 17.292675ms)
Jan 21 22:21:50.948: INFO: (4) /api/v1/nodes/10.191.28.39/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 14.595467ms)
Jan 21 22:21:50.965: INFO: (5) /api/v1/nodes/10.191.28.39/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 15.766119ms)
Jan 21 22:21:50.980: INFO: (6) /api/v1/nodes/10.191.28.39/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 15.090231ms)
Jan 21 22:21:50.996: INFO: (7) /api/v1/nodes/10.191.28.39/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 15.986625ms)
Jan 21 22:21:51.012: INFO: (8) /api/v1/nodes/10.191.28.39/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 16.146874ms)
Jan 21 22:21:51.027: INFO: (9) /api/v1/nodes/10.191.28.39/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 14.363975ms)
Jan 21 22:21:51.041: INFO: (10) /api/v1/nodes/10.191.28.39/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 13.960365ms)
Jan 21 22:21:51.056: INFO: (11) /api/v1/nodes/10.191.28.39/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 14.831917ms)
Jan 21 22:21:51.071: INFO: (12) /api/v1/nodes/10.191.28.39/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 14.620705ms)
Jan 21 22:21:51.086: INFO: (13) /api/v1/nodes/10.191.28.39/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 15.07591ms)
Jan 21 22:21:51.101: INFO: (14) /api/v1/nodes/10.191.28.39/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 14.693749ms)
Jan 21 22:21:51.115: INFO: (15) /api/v1/nodes/10.191.28.39/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 13.937168ms)
Jan 21 22:21:51.131: INFO: (16) /api/v1/nodes/10.191.28.39/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 14.883469ms)
Jan 21 22:21:51.145: INFO: (17) /api/v1/nodes/10.191.28.39/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 14.296448ms)
Jan 21 22:21:51.165: INFO: (18) /api/v1/nodes/10.191.28.39/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 19.667809ms)
Jan 21 22:21:51.180: INFO: (19) /api/v1/nodes/10.191.28.39/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 14.915276ms)
[AfterEach] version v1
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 22:21:51.181: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-proxy-crfdc" for this suite.
Jan 21 22:21:57.325: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 22:21:57.450: INFO: namespace: e2e-tests-proxy-crfdc, resource: bindings, ignored listing per whitelist
Jan 21 22:21:57.702: INFO: namespace e2e-tests-proxy-crfdc deletion completed in 6.509030439s

• [SLOW TEST:7.185 seconds]
[sig-network] Proxy
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy logs on node using proxy subresource  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Projected 
  should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 22:21:57.703: INFO: >>> kubeConfig: /tmp/kubeconfig-933165938
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-bcrzc
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Jan 21 22:21:58.047: INFO: Waiting up to 5m0s for pod "downwardapi-volume-f7405a9e-1dca-11e9-8130-be6597f3ae53" in namespace "e2e-tests-projected-bcrzc" to be "success or failure"
Jan 21 22:21:58.057: INFO: Pod "downwardapi-volume-f7405a9e-1dca-11e9-8130-be6597f3ae53": Phase="Pending", Reason="", readiness=false. Elapsed: 10.306454ms
Jan 21 22:22:00.068: INFO: Pod "downwardapi-volume-f7405a9e-1dca-11e9-8130-be6597f3ae53": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.021082718s
STEP: Saw pod success
Jan 21 22:22:00.068: INFO: Pod "downwardapi-volume-f7405a9e-1dca-11e9-8130-be6597f3ae53" satisfied condition "success or failure"
Jan 21 22:22:00.078: INFO: Trying to get logs from node 10.191.28.39 pod downwardapi-volume-f7405a9e-1dca-11e9-8130-be6597f3ae53 container client-container: <nil>
STEP: delete the pod
Jan 21 22:22:00.144: INFO: Waiting for pod downwardapi-volume-f7405a9e-1dca-11e9-8130-be6597f3ae53 to disappear
Jan 21 22:22:00.153: INFO: Pod downwardapi-volume-f7405a9e-1dca-11e9-8130-be6597f3ae53 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 22:22:00.153: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-bcrzc" for this suite.
Jan 21 22:22:06.210: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 22:22:06.407: INFO: namespace: e2e-tests-projected-bcrzc, resource: bindings, ignored listing per whitelist
Jan 21 22:22:06.590: INFO: namespace e2e-tests-projected-bcrzc deletion completed in 6.421543669s

• [SLOW TEST:8.887 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 22:22:06.590: INFO: >>> kubeConfig: /tmp/kubeconfig-933165938
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-sdwnc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0644 on tmpfs
Jan 21 22:22:06.944: INFO: Waiting up to 5m0s for pod "pod-fc8d4923-1dca-11e9-8130-be6597f3ae53" in namespace "e2e-tests-emptydir-sdwnc" to be "success or failure"
Jan 21 22:22:06.955: INFO: Pod "pod-fc8d4923-1dca-11e9-8130-be6597f3ae53": Phase="Pending", Reason="", readiness=false. Elapsed: 10.596363ms
Jan 21 22:22:08.966: INFO: Pod "pod-fc8d4923-1dca-11e9-8130-be6597f3ae53": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.021234482s
STEP: Saw pod success
Jan 21 22:22:08.966: INFO: Pod "pod-fc8d4923-1dca-11e9-8130-be6597f3ae53" satisfied condition "success or failure"
Jan 21 22:22:08.976: INFO: Trying to get logs from node 10.191.28.39 pod pod-fc8d4923-1dca-11e9-8130-be6597f3ae53 container test-container: <nil>
STEP: delete the pod
Jan 21 22:22:09.095: INFO: Waiting for pod pod-fc8d4923-1dca-11e9-8130-be6597f3ae53 to disappear
Jan 21 22:22:09.114: INFO: Pod pod-fc8d4923-1dca-11e9-8130-be6597f3ae53 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 22:22:09.114: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-sdwnc" for this suite.
Jan 21 22:22:15.178: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 22:22:15.273: INFO: namespace: e2e-tests-emptydir-sdwnc, resource: bindings, ignored listing per whitelist
Jan 21 22:22:15.580: INFO: namespace e2e-tests-emptydir-sdwnc deletion completed in 6.450553221s

• [SLOW TEST:8.990 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 22:22:15.580: INFO: >>> kubeConfig: /tmp/kubeconfig-933165938
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-xcd8v
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-01efe440-1dcb-11e9-8130-be6597f3ae53
STEP: Creating a pod to test consume configMaps
Jan 21 22:22:15.986: INFO: Waiting up to 5m0s for pod "pod-configmaps-01f1a134-1dcb-11e9-8130-be6597f3ae53" in namespace "e2e-tests-configmap-xcd8v" to be "success or failure"
Jan 21 22:22:15.997: INFO: Pod "pod-configmaps-01f1a134-1dcb-11e9-8130-be6597f3ae53": Phase="Pending", Reason="", readiness=false. Elapsed: 10.936027ms
Jan 21 22:22:18.008: INFO: Pod "pod-configmaps-01f1a134-1dcb-11e9-8130-be6597f3ae53": Phase="Running", Reason="", readiness=true. Elapsed: 2.021730534s
Jan 21 22:22:20.023: INFO: Pod "pod-configmaps-01f1a134-1dcb-11e9-8130-be6597f3ae53": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.037000718s
STEP: Saw pod success
Jan 21 22:22:20.024: INFO: Pod "pod-configmaps-01f1a134-1dcb-11e9-8130-be6597f3ae53" satisfied condition "success or failure"
Jan 21 22:22:20.034: INFO: Trying to get logs from node 10.191.28.39 pod pod-configmaps-01f1a134-1dcb-11e9-8130-be6597f3ae53 container configmap-volume-test: <nil>
STEP: delete the pod
Jan 21 22:22:20.089: INFO: Waiting for pod pod-configmaps-01f1a134-1dcb-11e9-8130-be6597f3ae53 to disappear
Jan 21 22:22:20.098: INFO: Pod pod-configmaps-01f1a134-1dcb-11e9-8130-be6597f3ae53 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 22:22:20.099: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-xcd8v" for this suite.
Jan 21 22:22:26.144: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 22:22:26.388: INFO: namespace: e2e-tests-configmap-xcd8v, resource: bindings, ignored listing per whitelist
Jan 21 22:22:26.552: INFO: namespace e2e-tests-configmap-xcd8v deletion completed in 6.440576628s

• [SLOW TEST:10.972 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 22:22:26.555: INFO: >>> kubeConfig: /tmp/kubeconfig-933165938
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-v2t7b
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-087664d9-1dcb-11e9-8130-be6597f3ae53
STEP: Creating a pod to test consume configMaps
Jan 21 22:22:26.938: INFO: Waiting up to 5m0s for pod "pod-configmaps-0878055a-1dcb-11e9-8130-be6597f3ae53" in namespace "e2e-tests-configmap-v2t7b" to be "success or failure"
Jan 21 22:22:26.949: INFO: Pod "pod-configmaps-0878055a-1dcb-11e9-8130-be6597f3ae53": Phase="Pending", Reason="", readiness=false. Elapsed: 10.980813ms
Jan 21 22:22:28.959: INFO: Pod "pod-configmaps-0878055a-1dcb-11e9-8130-be6597f3ae53": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.021087906s
STEP: Saw pod success
Jan 21 22:22:28.959: INFO: Pod "pod-configmaps-0878055a-1dcb-11e9-8130-be6597f3ae53" satisfied condition "success or failure"
Jan 21 22:22:28.969: INFO: Trying to get logs from node 10.191.28.59 pod pod-configmaps-0878055a-1dcb-11e9-8130-be6597f3ae53 container configmap-volume-test: <nil>
STEP: delete the pod
Jan 21 22:22:29.069: INFO: Waiting for pod pod-configmaps-0878055a-1dcb-11e9-8130-be6597f3ae53 to disappear
Jan 21 22:22:29.082: INFO: Pod pod-configmaps-0878055a-1dcb-11e9-8130-be6597f3ae53 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 22:22:29.082: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-v2t7b" for this suite.
Jan 21 22:22:35.150: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 22:22:35.375: INFO: namespace: e2e-tests-configmap-v2t7b, resource: bindings, ignored listing per whitelist
Jan 21 22:22:35.552: INFO: namespace e2e-tests-configmap-v2t7b deletion completed in 6.437151154s

• [SLOW TEST:8.998 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 22:22:35.553: INFO: >>> kubeConfig: /tmp/kubeconfig-933165938
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-lxvcl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Jan 21 22:22:35.982: INFO: Waiting up to 5m0s for pod "downwardapi-volume-0dcf51af-1dcb-11e9-8130-be6597f3ae53" in namespace "e2e-tests-downward-api-lxvcl" to be "success or failure"
Jan 21 22:22:35.992: INFO: Pod "downwardapi-volume-0dcf51af-1dcb-11e9-8130-be6597f3ae53": Phase="Pending", Reason="", readiness=false. Elapsed: 10.305116ms
Jan 21 22:22:38.004: INFO: Pod "downwardapi-volume-0dcf51af-1dcb-11e9-8130-be6597f3ae53": Phase="Running", Reason="", readiness=true. Elapsed: 2.021721346s
Jan 21 22:22:40.016: INFO: Pod "downwardapi-volume-0dcf51af-1dcb-11e9-8130-be6597f3ae53": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.034091631s
STEP: Saw pod success
Jan 21 22:22:40.016: INFO: Pod "downwardapi-volume-0dcf51af-1dcb-11e9-8130-be6597f3ae53" satisfied condition "success or failure"
Jan 21 22:22:40.027: INFO: Trying to get logs from node 10.191.28.39 pod downwardapi-volume-0dcf51af-1dcb-11e9-8130-be6597f3ae53 container client-container: <nil>
STEP: delete the pod
Jan 21 22:22:40.092: INFO: Waiting for pod downwardapi-volume-0dcf51af-1dcb-11e9-8130-be6597f3ae53 to disappear
Jan 21 22:22:40.101: INFO: Pod downwardapi-volume-0dcf51af-1dcb-11e9-8130-be6597f3ae53 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 22:22:40.102: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-lxvcl" for this suite.
Jan 21 22:22:46.149: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 22:22:46.212: INFO: namespace: e2e-tests-downward-api-lxvcl, resource: bindings, ignored listing per whitelist
Jan 21 22:22:46.530: INFO: namespace e2e-tests-downward-api-lxvcl deletion completed in 6.412108641s

• [SLOW TEST:10.976 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 22:22:46.531: INFO: >>> kubeConfig: /tmp/kubeconfig-933165938
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-64ntg
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0666 on tmpfs
Jan 21 22:22:46.884: INFO: Waiting up to 5m0s for pod "pod-145bc543-1dcb-11e9-8130-be6597f3ae53" in namespace "e2e-tests-emptydir-64ntg" to be "success or failure"
Jan 21 22:22:46.894: INFO: Pod "pod-145bc543-1dcb-11e9-8130-be6597f3ae53": Phase="Pending", Reason="", readiness=false. Elapsed: 10.392295ms
Jan 21 22:22:48.908: INFO: Pod "pod-145bc543-1dcb-11e9-8130-be6597f3ae53": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.023541671s
STEP: Saw pod success
Jan 21 22:22:48.908: INFO: Pod "pod-145bc543-1dcb-11e9-8130-be6597f3ae53" satisfied condition "success or failure"
Jan 21 22:22:48.919: INFO: Trying to get logs from node 10.191.28.59 pod pod-145bc543-1dcb-11e9-8130-be6597f3ae53 container test-container: <nil>
STEP: delete the pod
Jan 21 22:22:48.986: INFO: Waiting for pod pod-145bc543-1dcb-11e9-8130-be6597f3ae53 to disappear
Jan 21 22:22:49.077: INFO: Pod pod-145bc543-1dcb-11e9-8130-be6597f3ae53 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 22:22:49.077: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-64ntg" for this suite.
Jan 21 22:22:55.131: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 22:22:55.426: INFO: namespace: e2e-tests-emptydir-64ntg, resource: bindings, ignored listing per whitelist
Jan 21 22:22:55.477: INFO: namespace e2e-tests-emptydir-64ntg deletion completed in 6.380337273s

• [SLOW TEST:8.946 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 22:22:55.478: INFO: >>> kubeConfig: /tmp/kubeconfig-933165938
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-watch-klsls
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a watch on configmaps with label A
STEP: creating a watch on configmaps with label B
STEP: creating a watch on configmaps with label A or B
STEP: creating a configmap with label A and ensuring the correct watchers observe the notification
Jan 21 22:22:55.810: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-klsls,SelfLink:/api/v1/namespaces/e2e-tests-watch-klsls/configmaps/e2e-watch-test-configmap-a,UID:19af3ace-1dcb-11e9-903f-ee5d7ad9296f,ResourceVersion:45834,Generation:0,CreationTimestamp:2019-01-21 22:22:55 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Jan 21 22:22:55.810: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-klsls,SelfLink:/api/v1/namespaces/e2e-tests-watch-klsls/configmaps/e2e-watch-test-configmap-a,UID:19af3ace-1dcb-11e9-903f-ee5d7ad9296f,ResourceVersion:45834,Generation:0,CreationTimestamp:2019-01-21 22:22:55 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: modifying configmap A and ensuring the correct watchers observe the notification
Jan 21 22:23:11.228: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-klsls,SelfLink:/api/v1/namespaces/e2e-tests-watch-klsls/configmaps/e2e-watch-test-configmap-a,UID:19af3ace-1dcb-11e9-903f-ee5d7ad9296f,ResourceVersion:45855,Generation:0,CreationTimestamp:2019-01-21 22:22:55 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Jan 21 22:23:11.229: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-klsls,SelfLink:/api/v1/namespaces/e2e-tests-watch-klsls/configmaps/e2e-watch-test-configmap-a,UID:19af3ace-1dcb-11e9-903f-ee5d7ad9296f,ResourceVersion:45855,Generation:0,CreationTimestamp:2019-01-21 22:22:55 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying configmap A again and ensuring the correct watchers observe the notification
Jan 21 22:23:21.249: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-klsls,SelfLink:/api/v1/namespaces/e2e-tests-watch-klsls/configmaps/e2e-watch-test-configmap-a,UID:19af3ace-1dcb-11e9-903f-ee5d7ad9296f,ResourceVersion:45872,Generation:0,CreationTimestamp:2019-01-21 22:22:55 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Jan 21 22:23:21.249: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-klsls,SelfLink:/api/v1/namespaces/e2e-tests-watch-klsls/configmaps/e2e-watch-test-configmap-a,UID:19af3ace-1dcb-11e9-903f-ee5d7ad9296f,ResourceVersion:45872,Generation:0,CreationTimestamp:2019-01-21 22:22:55 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: deleting configmap A and ensuring the correct watchers observe the notification
Jan 21 22:23:31.267: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-klsls,SelfLink:/api/v1/namespaces/e2e-tests-watch-klsls/configmaps/e2e-watch-test-configmap-a,UID:19af3ace-1dcb-11e9-903f-ee5d7ad9296f,ResourceVersion:45889,Generation:0,CreationTimestamp:2019-01-21 22:22:55 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Jan 21 22:23:31.268: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-klsls,SelfLink:/api/v1/namespaces/e2e-tests-watch-klsls/configmaps/e2e-watch-test-configmap-a,UID:19af3ace-1dcb-11e9-903f-ee5d7ad9296f,ResourceVersion:45889,Generation:0,CreationTimestamp:2019-01-21 22:22:55 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: creating a configmap with label B and ensuring the correct watchers observe the notification
Jan 21 22:23:41.287: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-klsls,SelfLink:/api/v1/namespaces/e2e-tests-watch-klsls/configmaps/e2e-watch-test-configmap-b,UID:34c9644b-1dcb-11e9-903f-ee5d7ad9296f,ResourceVersion:45906,Generation:0,CreationTimestamp:2019-01-21 22:23:41 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Jan 21 22:23:41.288: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-klsls,SelfLink:/api/v1/namespaces/e2e-tests-watch-klsls/configmaps/e2e-watch-test-configmap-b,UID:34c9644b-1dcb-11e9-903f-ee5d7ad9296f,ResourceVersion:45906,Generation:0,CreationTimestamp:2019-01-21 22:23:41 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: deleting configmap B and ensuring the correct watchers observe the notification
Jan 21 22:23:51.308: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-klsls,SelfLink:/api/v1/namespaces/e2e-tests-watch-klsls/configmaps/e2e-watch-test-configmap-b,UID:34c9644b-1dcb-11e9-903f-ee5d7ad9296f,ResourceVersion:45924,Generation:0,CreationTimestamp:2019-01-21 22:23:41 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Jan 21 22:23:51.308: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-klsls,SelfLink:/api/v1/namespaces/e2e-tests-watch-klsls/configmaps/e2e-watch-test-configmap-b,UID:34c9644b-1dcb-11e9-903f-ee5d7ad9296f,ResourceVersion:45924,Generation:0,CreationTimestamp:2019-01-21 22:23:41 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 22:24:01.309: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-klsls" for this suite.
Jan 21 22:24:07.405: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 22:24:07.478: INFO: namespace: e2e-tests-watch-klsls, resource: bindings, ignored listing per whitelist
Jan 21 22:24:07.741: INFO: namespace e2e-tests-watch-klsls deletion completed in 6.376749504s

• [SLOW TEST:72.263 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 22:24:07.743: INFO: >>> kubeConfig: /tmp/kubeconfig-933165938
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-statefulset-n4bxr
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-n4bxr
[It] should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a new StaefulSet
Jan 21 22:24:08.135: INFO: Found 0 stateful pods, waiting for 3
Jan 21 22:24:18.148: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Jan 21 22:24:18.148: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Jan 21 22:24:18.148: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Updating stateful set template: update image from docker.io/library/nginx:1.14-alpine to docker.io/library/nginx:1.15-alpine
Jan 21 22:24:18.276: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Not applying an update when the partition is greater than the number of replicas
STEP: Performing a canary update
Jan 21 22:24:28.377: INFO: Updating stateful set ss2
Jan 21 22:24:28.398: INFO: Waiting for Pod e2e-tests-statefulset-n4bxr/ss2-2 to have revision ss2-c79899b9 update revision ss2-787997d666
STEP: Restoring Pods to the correct revision when they are deleted
Jan 21 22:24:38.545: INFO: Found 2 stateful pods, waiting for 3
Jan 21 22:24:48.557: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Jan 21 22:24:48.557: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Jan 21 22:24:48.557: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Performing a phased rolling update
Jan 21 22:24:48.677: INFO: Updating stateful set ss2
Jan 21 22:24:48.698: INFO: Waiting for Pod e2e-tests-statefulset-n4bxr/ss2-1 to have revision ss2-c79899b9 update revision ss2-787997d666
Jan 21 22:24:58.764: INFO: Updating stateful set ss2
Jan 21 22:24:58.789: INFO: Waiting for StatefulSet e2e-tests-statefulset-n4bxr/ss2 to complete update
Jan 21 22:24:58.789: INFO: Waiting for Pod e2e-tests-statefulset-n4bxr/ss2-0 to have revision ss2-c79899b9 update revision ss2-787997d666
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Jan 21 22:25:08.811: INFO: Deleting all statefulset in ns e2e-tests-statefulset-n4bxr
Jan 21 22:25:08.821: INFO: Scaling statefulset ss2 to 0
Jan 21 22:25:38.891: INFO: Waiting for statefulset status.replicas updated to 0
Jan 21 22:25:38.900: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 22:25:38.986: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-n4bxr" for this suite.
Jan 21 22:25:47.054: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 22:25:47.196: INFO: namespace: e2e-tests-statefulset-n4bxr, resource: bindings, ignored listing per whitelist
Jan 21 22:25:47.411: INFO: namespace e2e-tests-statefulset-n4bxr deletion completed in 8.408528342s

• [SLOW TEST:99.668 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should perform canary updates and phased rolling updates of template modifications [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 22:25:47.412: INFO: >>> kubeConfig: /tmp/kubeconfig-933165938
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-daemonsets-5wd7s
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:98
[It] should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Jan 21 22:25:47.789: INFO: Requires at least 2 nodes (not -1)
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:64
Jan 21 22:25:47.806: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-5wd7s/daemonsets","resourceVersion":"46466"},"items":null}

Jan 21 22:25:47.816: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-5wd7s/pods","resourceVersion":"46466"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 22:25:47.863: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-5wd7s" for this suite.
Jan 21 22:25:53.912: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 22:25:54.031: INFO: namespace: e2e-tests-daemonsets-5wd7s, resource: bindings, ignored listing per whitelist
Jan 21 22:25:54.271: INFO: namespace e2e-tests-daemonsets-5wd7s deletion completed in 6.391680918s

S [SKIPPING] [6.859 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should rollback without unnecessary restarts [Conformance] [It]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699

  Jan 21 22:25:47.789: Requires at least 2 nodes (not -1)

  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/util.go:292
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Burst scaling should run to completion even with unhealthy pods [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 22:25:54.272: INFO: >>> kubeConfig: /tmp/kubeconfig-933165938
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-statefulset-n45ll
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-n45ll
[It] Burst scaling should run to completion even with unhealthy pods [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating stateful set ss in namespace e2e-tests-statefulset-n45ll
STEP: Waiting until all stateful set ss replicas will be running in namespace e2e-tests-statefulset-n45ll
Jan 21 22:25:54.635: INFO: Found 0 stateful pods, waiting for 1
Jan 21 22:26:04.646: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will not halt with unhealthy stateful pod
Jan 21 22:26:04.656: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-933165938 exec --namespace=e2e-tests-statefulset-n45ll ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Jan 21 22:26:05.075: INFO: stderr: ""
Jan 21 22:26:05.075: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Jan 21 22:26:05.077: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Jan 21 22:26:05.088: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Jan 21 22:26:15.099: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Jan 21 22:26:15.099: INFO: Waiting for statefulset status.replicas updated to 0
Jan 21 22:26:15.146: INFO: POD   NODE          PHASE    GRACE  CONDITIONS
Jan 21 22:26:15.147: INFO: ss-0  10.191.28.39  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-21 22:25:54 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-21 22:26:05 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-01-21 22:26:05 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-21 22:25:54 +0000 UTC  }]
Jan 21 22:26:15.147: INFO: 
Jan 21 22:26:15.147: INFO: StatefulSet ss has not reached scale 3, at 1
Jan 21 22:26:16.174: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.984171612s
Jan 21 22:26:17.185: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.956672251s
Jan 21 22:26:18.200: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.945654131s
Jan 21 22:26:19.218: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.930666096s
Jan 21 22:26:20.229: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.912924642s
Jan 21 22:26:21.240: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.901500426s
Jan 21 22:26:22.254: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.890619079s
Jan 21 22:26:23.266: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.87708196s
Jan 21 22:26:24.278: INFO: Verifying statefulset ss doesn't scale past 3 for another 864.868041ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace e2e-tests-statefulset-n45ll
Jan 21 22:26:25.295: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-933165938 exec --namespace=e2e-tests-statefulset-n45ll ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jan 21 22:26:25.698: INFO: stderr: ""
Jan 21 22:26:25.698: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Jan 21 22:26:25.698: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Jan 21 22:26:25.698: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-933165938 exec --namespace=e2e-tests-statefulset-n45ll ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jan 21 22:26:26.092: INFO: stderr: "mv: can't rename '/tmp/index.html': No such file or directory\n"
Jan 21 22:26:26.092: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Jan 21 22:26:26.092: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Jan 21 22:26:26.092: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-933165938 exec --namespace=e2e-tests-statefulset-n45ll ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Jan 21 22:26:26.566: INFO: stderr: "mv: can't rename '/tmp/index.html': No such file or directory\n"
Jan 21 22:26:26.567: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Jan 21 22:26:26.567: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-2: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Jan 21 22:26:26.578: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Jan 21 22:26:26.578: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Jan 21 22:26:26.578: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Scale down will not halt with unhealthy stateful pod
Jan 21 22:26:26.588: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-933165938 exec --namespace=e2e-tests-statefulset-n45ll ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Jan 21 22:26:27.646: INFO: stderr: ""
Jan 21 22:26:27.646: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Jan 21 22:26:27.646: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Jan 21 22:26:27.646: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-933165938 exec --namespace=e2e-tests-statefulset-n45ll ss-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Jan 21 22:26:28.026: INFO: stderr: ""
Jan 21 22:26:28.026: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Jan 21 22:26:28.026: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Jan 21 22:26:28.026: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-933165938 exec --namespace=e2e-tests-statefulset-n45ll ss-2 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Jan 21 22:26:28.536: INFO: stderr: ""
Jan 21 22:26:28.536: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Jan 21 22:26:28.536: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-2: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Jan 21 22:26:28.536: INFO: Waiting for statefulset status.replicas updated to 0
Jan 21 22:26:28.546: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 1
Jan 21 22:26:38.567: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Jan 21 22:26:38.567: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Jan 21 22:26:38.567: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Jan 21 22:26:38.604: INFO: POD   NODE          PHASE    GRACE  CONDITIONS
Jan 21 22:26:38.604: INFO: ss-0  10.191.28.39  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-21 22:25:54 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-21 22:26:28 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-01-21 22:26:28 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-21 22:25:54 +0000 UTC  }]
Jan 21 22:26:38.604: INFO: ss-1  10.191.28.59  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-21 22:26:15 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-21 22:26:28 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-01-21 22:26:28 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-21 22:26:15 +0000 UTC  }]
Jan 21 22:26:38.604: INFO: ss-2  10.191.28.45  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-21 22:26:15 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-21 22:26:28 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-01-21 22:26:28 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-21 22:26:15 +0000 UTC  }]
Jan 21 22:26:38.604: INFO: 
Jan 21 22:26:38.604: INFO: StatefulSet ss has not reached scale 0, at 3
Jan 21 22:26:39.616: INFO: POD   NODE          PHASE    GRACE  CONDITIONS
Jan 21 22:26:39.616: INFO: ss-0  10.191.28.39  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-21 22:25:54 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-21 22:26:28 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-01-21 22:26:28 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-21 22:25:54 +0000 UTC  }]
Jan 21 22:26:39.616: INFO: ss-1  10.191.28.59  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-21 22:26:15 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-21 22:26:28 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-01-21 22:26:28 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-21 22:26:15 +0000 UTC  }]
Jan 21 22:26:39.616: INFO: ss-2  10.191.28.45  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-21 22:26:15 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-21 22:26:28 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-01-21 22:26:28 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-21 22:26:15 +0000 UTC  }]
Jan 21 22:26:39.616: INFO: 
Jan 21 22:26:39.616: INFO: StatefulSet ss has not reached scale 0, at 3
Jan 21 22:26:40.628: INFO: POD   NODE          PHASE    GRACE  CONDITIONS
Jan 21 22:26:40.628: INFO: ss-0  10.191.28.39  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-21 22:25:54 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-21 22:26:28 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-01-21 22:26:28 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-21 22:25:54 +0000 UTC  }]
Jan 21 22:26:40.628: INFO: ss-1  10.191.28.59  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-21 22:26:15 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-21 22:26:28 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-01-21 22:26:28 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-21 22:26:15 +0000 UTC  }]
Jan 21 22:26:40.628: INFO: ss-2  10.191.28.45  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-21 22:26:15 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-21 22:26:28 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-01-21 22:26:28 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-21 22:26:15 +0000 UTC  }]
Jan 21 22:26:40.628: INFO: 
Jan 21 22:26:40.628: INFO: StatefulSet ss has not reached scale 0, at 3
Jan 21 22:26:41.641: INFO: POD   NODE          PHASE    GRACE  CONDITIONS
Jan 21 22:26:41.641: INFO: ss-0  10.191.28.39  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-21 22:25:54 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-21 22:26:28 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-01-21 22:26:28 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-21 22:25:54 +0000 UTC  }]
Jan 21 22:26:41.641: INFO: ss-1  10.191.28.59  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-21 22:26:15 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-21 22:26:28 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-01-21 22:26:28 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-21 22:26:15 +0000 UTC  }]
Jan 21 22:26:41.641: INFO: 
Jan 21 22:26:41.641: INFO: StatefulSet ss has not reached scale 0, at 2
Jan 21 22:26:42.653: INFO: POD   NODE          PHASE    GRACE  CONDITIONS
Jan 21 22:26:42.653: INFO: ss-0  10.191.28.39  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-21 22:25:54 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-21 22:26:28 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-01-21 22:26:28 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-21 22:25:54 +0000 UTC  }]
Jan 21 22:26:42.653: INFO: ss-1  10.191.28.59  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-21 22:26:15 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-21 22:26:28 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-01-21 22:26:28 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-21 22:26:15 +0000 UTC  }]
Jan 21 22:26:42.653: INFO: 
Jan 21 22:26:42.653: INFO: StatefulSet ss has not reached scale 0, at 2
Jan 21 22:26:43.668: INFO: POD   NODE          PHASE    GRACE  CONDITIONS
Jan 21 22:26:43.668: INFO: ss-0  10.191.28.39  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-21 22:25:54 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-21 22:26:28 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-01-21 22:26:28 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-21 22:25:54 +0000 UTC  }]
Jan 21 22:26:43.668: INFO: ss-1  10.191.28.59  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-21 22:26:15 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-21 22:26:28 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-01-21 22:26:28 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-21 22:26:15 +0000 UTC  }]
Jan 21 22:26:43.668: INFO: 
Jan 21 22:26:43.668: INFO: StatefulSet ss has not reached scale 0, at 2
Jan 21 22:26:44.680: INFO: POD   NODE          PHASE    GRACE  CONDITIONS
Jan 21 22:26:44.680: INFO: ss-0  10.191.28.39  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-21 22:25:54 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-21 22:26:28 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-01-21 22:26:28 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-21 22:25:54 +0000 UTC  }]
Jan 21 22:26:44.680: INFO: ss-1  10.191.28.59  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-21 22:26:15 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-21 22:26:28 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-01-21 22:26:28 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-21 22:26:15 +0000 UTC  }]
Jan 21 22:26:44.681: INFO: 
Jan 21 22:26:44.681: INFO: StatefulSet ss has not reached scale 0, at 2
Jan 21 22:26:45.695: INFO: POD   NODE          PHASE    GRACE  CONDITIONS
Jan 21 22:26:45.695: INFO: ss-1  10.191.28.59  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-21 22:26:15 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-21 22:26:28 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-01-21 22:26:28 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-21 22:26:15 +0000 UTC  }]
Jan 21 22:26:45.695: INFO: 
Jan 21 22:26:45.695: INFO: StatefulSet ss has not reached scale 0, at 1
Jan 21 22:26:46.707: INFO: POD   NODE          PHASE    GRACE  CONDITIONS
Jan 21 22:26:46.707: INFO: ss-1  10.191.28.59  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-21 22:26:15 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-21 22:26:28 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-01-21 22:26:28 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-21 22:26:15 +0000 UTC  }]
Jan 21 22:26:46.707: INFO: 
Jan 21 22:26:46.707: INFO: StatefulSet ss has not reached scale 0, at 1
Jan 21 22:26:47.719: INFO: POD   NODE          PHASE    GRACE  CONDITIONS
Jan 21 22:26:47.719: INFO: ss-1  10.191.28.59  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-21 22:26:15 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-01-21 22:26:28 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-01-21 22:26:28 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-21 22:26:15 +0000 UTC  }]
Jan 21 22:26:47.719: INFO: 
Jan 21 22:26:47.719: INFO: StatefulSet ss has not reached scale 0, at 1
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacee2e-tests-statefulset-n45ll
Jan 21 22:26:48.730: INFO: Scaling statefulset ss to 0
Jan 21 22:26:48.761: INFO: Waiting for statefulset status.replicas updated to 0
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Jan 21 22:26:48.772: INFO: Deleting all statefulset in ns e2e-tests-statefulset-n45ll
Jan 21 22:26:48.782: INFO: Scaling statefulset ss to 0
Jan 21 22:26:48.815: INFO: Waiting for statefulset status.replicas updated to 0
Jan 21 22:26:48.825: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 22:26:48.865: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-n45ll" for this suite.
Jan 21 22:26:54.908: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 22:26:55.201: INFO: namespace: e2e-tests-statefulset-n45ll, resource: bindings, ignored listing per whitelist
Jan 21 22:26:55.258: INFO: namespace e2e-tests-statefulset-n45ll deletion completed in 6.379860266s

• [SLOW TEST:60.986 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    Burst scaling should run to completion even with unhealthy pods [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 22:26:55.258: INFO: >>> kubeConfig: /tmp/kubeconfig-933165938
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-nzgnf
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-a89f7119-1dcb-11e9-8130-be6597f3ae53
STEP: Creating a pod to test consume secrets
Jan 21 22:26:55.635: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-a8a0e22d-1dcb-11e9-8130-be6597f3ae53" in namespace "e2e-tests-projected-nzgnf" to be "success or failure"
Jan 21 22:26:55.646: INFO: Pod "pod-projected-secrets-a8a0e22d-1dcb-11e9-8130-be6597f3ae53": Phase="Pending", Reason="", readiness=false. Elapsed: 10.921164ms
Jan 21 22:26:57.656: INFO: Pod "pod-projected-secrets-a8a0e22d-1dcb-11e9-8130-be6597f3ae53": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.021257731s
STEP: Saw pod success
Jan 21 22:26:57.656: INFO: Pod "pod-projected-secrets-a8a0e22d-1dcb-11e9-8130-be6597f3ae53" satisfied condition "success or failure"
Jan 21 22:26:57.666: INFO: Trying to get logs from node 10.191.28.59 pod pod-projected-secrets-a8a0e22d-1dcb-11e9-8130-be6597f3ae53 container projected-secret-volume-test: <nil>
STEP: delete the pod
Jan 21 22:26:57.764: INFO: Waiting for pod pod-projected-secrets-a8a0e22d-1dcb-11e9-8130-be6597f3ae53 to disappear
Jan 21 22:26:57.774: INFO: Pod pod-projected-secrets-a8a0e22d-1dcb-11e9-8130-be6597f3ae53 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 22:26:57.774: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-nzgnf" for this suite.
Jan 21 22:27:03.822: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 22:27:03.878: INFO: namespace: e2e-tests-projected-nzgnf, resource: bindings, ignored listing per whitelist
Jan 21 22:27:04.245: INFO: namespace e2e-tests-projected-nzgnf deletion completed in 6.457166197s

• [SLOW TEST:8.987 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 22:27:04.247: INFO: >>> kubeConfig: /tmp/kubeconfig-933165938
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-daemonsets-vkswg
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:98
[It] should run and stop simple daemon [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Jan 21 22:27:04.733: INFO: Number of nodes with available pods: 0
Jan 21 22:27:04.733: INFO: Node 10.191.28.39 is running more than one daemon pod
Jan 21 22:27:05.773: INFO: Number of nodes with available pods: 0
Jan 21 22:27:05.773: INFO: Node 10.191.28.39 is running more than one daemon pod
Jan 21 22:27:06.757: INFO: Number of nodes with available pods: 2
Jan 21 22:27:06.757: INFO: Node 10.191.28.45 is running more than one daemon pod
Jan 21 22:27:07.764: INFO: Number of nodes with available pods: 3
Jan 21 22:27:07.764: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Stop a daemon pod, check that the daemon pod is revived.
Jan 21 22:27:07.830: INFO: Number of nodes with available pods: 2
Jan 21 22:27:07.830: INFO: Node 10.191.28.45 is running more than one daemon pod
Jan 21 22:27:08.887: INFO: Number of nodes with available pods: 2
Jan 21 22:27:08.887: INFO: Node 10.191.28.45 is running more than one daemon pod
Jan 21 22:27:09.857: INFO: Number of nodes with available pods: 2
Jan 21 22:27:09.857: INFO: Node 10.191.28.45 is running more than one daemon pod
Jan 21 22:27:10.864: INFO: Number of nodes with available pods: 2
Jan 21 22:27:10.865: INFO: Node 10.191.28.45 is running more than one daemon pod
Jan 21 22:27:11.858: INFO: Number of nodes with available pods: 2
Jan 21 22:27:11.858: INFO: Node 10.191.28.45 is running more than one daemon pod
Jan 21 22:27:12.855: INFO: Number of nodes with available pods: 2
Jan 21 22:27:12.855: INFO: Node 10.191.28.45 is running more than one daemon pod
Jan 21 22:27:13.855: INFO: Number of nodes with available pods: 2
Jan 21 22:27:13.855: INFO: Node 10.191.28.45 is running more than one daemon pod
Jan 21 22:27:14.856: INFO: Number of nodes with available pods: 2
Jan 21 22:27:14.856: INFO: Node 10.191.28.45 is running more than one daemon pod
Jan 21 22:27:15.864: INFO: Number of nodes with available pods: 2
Jan 21 22:27:15.864: INFO: Node 10.191.28.45 is running more than one daemon pod
Jan 21 22:27:16.873: INFO: Number of nodes with available pods: 2
Jan 21 22:27:16.873: INFO: Node 10.191.28.45 is running more than one daemon pod
Jan 21 22:27:17.855: INFO: Number of nodes with available pods: 2
Jan 21 22:27:17.855: INFO: Node 10.191.28.45 is running more than one daemon pod
Jan 21 22:27:18.856: INFO: Number of nodes with available pods: 2
Jan 21 22:27:18.856: INFO: Node 10.191.28.45 is running more than one daemon pod
Jan 21 22:27:19.864: INFO: Number of nodes with available pods: 2
Jan 21 22:27:19.864: INFO: Node 10.191.28.45 is running more than one daemon pod
Jan 21 22:27:20.857: INFO: Number of nodes with available pods: 2
Jan 21 22:27:20.857: INFO: Node 10.191.28.45 is running more than one daemon pod
Jan 21 22:27:21.855: INFO: Number of nodes with available pods: 2
Jan 21 22:27:21.855: INFO: Node 10.191.28.45 is running more than one daemon pod
Jan 21 22:27:22.867: INFO: Number of nodes with available pods: 2
Jan 21 22:27:22.867: INFO: Node 10.191.28.45 is running more than one daemon pod
Jan 21 22:27:23.856: INFO: Number of nodes with available pods: 2
Jan 21 22:27:23.856: INFO: Node 10.191.28.45 is running more than one daemon pod
Jan 21 22:27:24.859: INFO: Number of nodes with available pods: 2
Jan 21 22:27:24.859: INFO: Node 10.191.28.45 is running more than one daemon pod
Jan 21 22:27:25.860: INFO: Number of nodes with available pods: 2
Jan 21 22:27:25.860: INFO: Node 10.191.28.45 is running more than one daemon pod
Jan 21 22:27:26.855: INFO: Number of nodes with available pods: 2
Jan 21 22:27:26.855: INFO: Node 10.191.28.45 is running more than one daemon pod
Jan 21 22:27:27.882: INFO: Number of nodes with available pods: 2
Jan 21 22:27:27.882: INFO: Node 10.191.28.45 is running more than one daemon pod
Jan 21 22:27:28.855: INFO: Number of nodes with available pods: 2
Jan 21 22:27:28.856: INFO: Node 10.191.28.45 is running more than one daemon pod
Jan 21 22:27:29.864: INFO: Number of nodes with available pods: 2
Jan 21 22:27:29.864: INFO: Node 10.191.28.45 is running more than one daemon pod
Jan 21 22:27:30.855: INFO: Number of nodes with available pods: 2
Jan 21 22:27:30.855: INFO: Node 10.191.28.45 is running more than one daemon pod
Jan 21 22:27:31.855: INFO: Number of nodes with available pods: 2
Jan 21 22:27:31.855: INFO: Node 10.191.28.45 is running more than one daemon pod
Jan 21 22:27:32.875: INFO: Number of nodes with available pods: 2
Jan 21 22:27:32.875: INFO: Node 10.191.28.45 is running more than one daemon pod
Jan 21 22:27:33.864: INFO: Number of nodes with available pods: 2
Jan 21 22:27:33.865: INFO: Node 10.191.28.45 is running more than one daemon pod
Jan 21 22:27:34.860: INFO: Number of nodes with available pods: 2
Jan 21 22:27:34.860: INFO: Node 10.191.28.45 is running more than one daemon pod
Jan 21 22:27:35.856: INFO: Number of nodes with available pods: 2
Jan 21 22:27:35.856: INFO: Node 10.191.28.45 is running more than one daemon pod
Jan 21 22:27:36.857: INFO: Number of nodes with available pods: 2
Jan 21 22:27:36.857: INFO: Node 10.191.28.45 is running more than one daemon pod
Jan 21 22:27:37.873: INFO: Number of nodes with available pods: 2
Jan 21 22:27:37.873: INFO: Node 10.191.28.45 is running more than one daemon pod
Jan 21 22:27:38.855: INFO: Number of nodes with available pods: 2
Jan 21 22:27:38.856: INFO: Node 10.191.28.45 is running more than one daemon pod
Jan 21 22:27:39.856: INFO: Number of nodes with available pods: 2
Jan 21 22:27:39.856: INFO: Node 10.191.28.45 is running more than one daemon pod
Jan 21 22:27:40.854: INFO: Number of nodes with available pods: 2
Jan 21 22:27:40.854: INFO: Node 10.191.28.45 is running more than one daemon pod
Jan 21 22:27:41.859: INFO: Number of nodes with available pods: 2
Jan 21 22:27:41.859: INFO: Node 10.191.28.45 is running more than one daemon pod
Jan 21 22:27:42.874: INFO: Number of nodes with available pods: 2
Jan 21 22:27:42.874: INFO: Node 10.191.28.45 is running more than one daemon pod
Jan 21 22:27:44.055: INFO: Number of nodes with available pods: 3
Jan 21 22:27:44.055: INFO: Number of running nodes: 3, number of available pods: 3
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:64
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting {extensions DaemonSet} daemon-set in namespace e2e-tests-daemonsets-vkswg, will wait for the garbage collector to delete the pods
Jan 21 22:27:44.155: INFO: Deleting {extensions DaemonSet} daemon-set took: 24.621525ms
Jan 21 22:27:44.255: INFO: Terminating {extensions DaemonSet} daemon-set pods took: 100.298184ms
Jan 21 22:28:22.566: INFO: Number of nodes with available pods: 0
Jan 21 22:28:22.566: INFO: Number of running nodes: 0, number of available pods: 0
Jan 21 22:28:22.574: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-vkswg/daemonsets","resourceVersion":"47049"},"items":null}

Jan 21 22:28:22.584: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-vkswg/pods","resourceVersion":"47049"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 22:28:22.627: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-vkswg" for this suite.
Jan 21 22:28:30.675: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 22:28:30.797: INFO: namespace: e2e-tests-daemonsets-vkswg, resource: bindings, ignored listing per whitelist
Jan 21 22:28:31.107: INFO: namespace e2e-tests-daemonsets-vkswg deletion completed in 8.468212458s

• [SLOW TEST:86.860 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 22:28:31.109: INFO: >>> kubeConfig: /tmp/kubeconfig-933165938
STEP: Building a namespace api object, basename pod-network-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-pod-network-test-rzpjp
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-rzpjp
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Jan 21 22:28:31.444: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Jan 21 22:28:55.764: INFO: ExecWithOptions {Command:[/bin/sh -c echo 'hostName' | timeout -t 2 nc -w 1 -u 172.30.41.41 8081 | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-rzpjp PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jan 21 22:28:55.764: INFO: >>> kubeConfig: /tmp/kubeconfig-933165938
Jan 21 22:28:56.961: INFO: Found all expected endpoints: [netserver-0]
Jan 21 22:28:56.972: INFO: ExecWithOptions {Command:[/bin/sh -c echo 'hostName' | timeout -t 2 nc -w 1 -u 172.30.156.191 8081 | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-rzpjp PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jan 21 22:28:56.972: INFO: >>> kubeConfig: /tmp/kubeconfig-933165938
Jan 21 22:28:58.206: INFO: Found all expected endpoints: [netserver-1]
Jan 21 22:28:58.217: INFO: ExecWithOptions {Command:[/bin/sh -c echo 'hostName' | timeout -t 2 nc -w 1 -u 172.30.216.50 8081 | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-rzpjp PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jan 21 22:28:58.217: INFO: >>> kubeConfig: /tmp/kubeconfig-933165938
Jan 21 22:28:59.420: INFO: Found all expected endpoints: [netserver-2]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 22:28:59.420: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-rzpjp" for this suite.
Jan 21 22:29:21.525: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 22:29:21.864: INFO: namespace: e2e-tests-pod-network-test-rzpjp, resource: bindings, ignored listing per whitelist
Jan 21 22:29:21.875: INFO: namespace e2e-tests-pod-network-test-rzpjp deletion completed in 22.440096957s

• [SLOW TEST:50.767 seconds]
[sig-network] Networking
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: udp [NodeConformance] [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 22:29:21.878: INFO: >>> kubeConfig: /tmp/kubeconfig-933165938
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-container-lifecycle-hook-5lk2p
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Jan 21 22:29:26.386: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Jan 21 22:29:26.398: INFO: Pod pod-with-poststart-exec-hook still exists
Jan 21 22:29:28.398: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Jan 21 22:29:28.409: INFO: Pod pod-with-poststart-exec-hook still exists
Jan 21 22:29:30.398: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Jan 21 22:29:30.420: INFO: Pod pod-with-poststart-exec-hook still exists
Jan 21 22:29:32.398: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Jan 21 22:29:32.413: INFO: Pod pod-with-poststart-exec-hook still exists
Jan 21 22:29:34.404: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Jan 21 22:29:34.416: INFO: Pod pod-with-poststart-exec-hook still exists
Jan 21 22:29:36.398: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Jan 21 22:29:36.409: INFO: Pod pod-with-poststart-exec-hook still exists
Jan 21 22:29:38.398: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Jan 21 22:29:38.409: INFO: Pod pod-with-poststart-exec-hook still exists
Jan 21 22:29:40.398: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Jan 21 22:29:40.412: INFO: Pod pod-with-poststart-exec-hook still exists
Jan 21 22:29:42.398: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Jan 21 22:29:42.414: INFO: Pod pod-with-poststart-exec-hook still exists
Jan 21 22:29:44.399: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Jan 21 22:29:44.410: INFO: Pod pod-with-poststart-exec-hook still exists
Jan 21 22:29:46.398: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Jan 21 22:29:46.409: INFO: Pod pod-with-poststart-exec-hook still exists
Jan 21 22:29:48.398: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Jan 21 22:29:48.424: INFO: Pod pod-with-poststart-exec-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 22:29:48.424: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-lifecycle-hook-5lk2p" for this suite.
Jan 21 22:30:12.472: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 22:30:12.901: INFO: namespace: e2e-tests-container-lifecycle-hook-5lk2p, resource: bindings, ignored listing per whitelist
Jan 21 22:30:12.956: INFO: namespace e2e-tests-container-lifecycle-hook-5lk2p deletion completed in 24.517136012s

• [SLOW TEST:51.078 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when create a pod with lifecycle hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute poststart exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 22:30:12.960: INFO: >>> kubeConfig: /tmp/kubeconfig-933165938
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-hqrpz
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-1e72dcd5-1dcc-11e9-8130-be6597f3ae53
STEP: Creating a pod to test consume configMaps
Jan 21 22:30:13.314: INFO: Waiting up to 5m0s for pod "pod-configmaps-1e743146-1dcc-11e9-8130-be6597f3ae53" in namespace "e2e-tests-configmap-hqrpz" to be "success or failure"
Jan 21 22:30:13.323: INFO: Pod "pod-configmaps-1e743146-1dcc-11e9-8130-be6597f3ae53": Phase="Pending", Reason="", readiness=false. Elapsed: 8.897871ms
Jan 21 22:30:15.335: INFO: Pod "pod-configmaps-1e743146-1dcc-11e9-8130-be6597f3ae53": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.020244146s
STEP: Saw pod success
Jan 21 22:30:15.335: INFO: Pod "pod-configmaps-1e743146-1dcc-11e9-8130-be6597f3ae53" satisfied condition "success or failure"
Jan 21 22:30:15.346: INFO: Trying to get logs from node 10.191.28.39 pod pod-configmaps-1e743146-1dcc-11e9-8130-be6597f3ae53 container configmap-volume-test: <nil>
STEP: delete the pod
Jan 21 22:30:15.404: INFO: Waiting for pod pod-configmaps-1e743146-1dcc-11e9-8130-be6597f3ae53 to disappear
Jan 21 22:30:15.415: INFO: Pod pod-configmaps-1e743146-1dcc-11e9-8130-be6597f3ae53 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 22:30:15.415: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-hqrpz" for this suite.
Jan 21 22:30:21.460: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 22:30:21.823: INFO: namespace: e2e-tests-configmap-hqrpz, resource: bindings, ignored listing per whitelist
Jan 21 22:30:21.860: INFO: namespace e2e-tests-configmap-hqrpz deletion completed in 6.433164403s

• [SLOW TEST:8.902 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 22:30:21.865: INFO: >>> kubeConfig: /tmp/kubeconfig-933165938
STEP: Building a namespace api object, basename sched-pred
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-sched-pred-kslvv
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:78
Jan 21 22:30:22.260: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Jan 21 22:30:22.374: INFO: Waiting for terminating namespaces to be deleted...
Jan 21 22:30:22.385: INFO: 
Logging pods the kubelet thinks is on node 10.191.28.39 before test
Jan 21 22:30:22.419: INFO: ibm-keepalived-watcher-nw8wp from kube-system started at 2019-01-21 19:04:47 +0000 UTC (1 container statuses recorded)
Jan 21 22:30:22.420: INFO: 	Container keepalived-watcher ready: true, restart count 0
Jan 21 22:30:22.420: INFO: calico-node-6zjw9 from kube-system started at 2019-01-21 19:04:47 +0000 UTC (2 container statuses recorded)
Jan 21 22:30:22.420: INFO: 	Container calico-node ready: true, restart count 0
Jan 21 22:30:22.420: INFO: 	Container install-cni ready: true, restart count 0
Jan 21 22:30:22.420: INFO: test-k8s-e2e-pvg-master-verification from default started at 2019-01-21 21:18:59 +0000 UTC (1 container statuses recorded)
Jan 21 22:30:22.421: INFO: 	Container test-k8s-e2e-pvg-master-verification ready: true, restart count 0
Jan 21 22:30:22.421: INFO: kube-dns-amd64-fddfcc69-l7fs4 from kube-system started at 2019-01-21 19:04:47 +0000 UTC (3 container statuses recorded)
Jan 21 22:30:22.421: INFO: 	Container dnsmasq ready: true, restart count 0
Jan 21 22:30:22.421: INFO: 	Container kubedns ready: true, restart count 0
Jan 21 22:30:22.421: INFO: 	Container sidecar ready: true, restart count 0
Jan 21 22:30:22.421: INFO: calico-kube-controllers-5c699798bc-7cfbr from kube-system started at 2019-01-21 19:04:47 +0000 UTC (1 container statuses recorded)
Jan 21 22:30:22.421: INFO: 	Container calico-kube-controllers ready: true, restart count 0
Jan 21 22:30:22.421: INFO: kubernetes-dashboard-b4bc7db5d-4stht from kube-system started at 2019-01-21 19:04:47 +0000 UTC (1 container statuses recorded)
Jan 21 22:30:22.422: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
Jan 21 22:30:22.422: INFO: vpn-65599665d9-n57t7 from kube-system started at 2019-01-21 19:04:47 +0000 UTC (1 container statuses recorded)
Jan 21 22:30:22.422: INFO: 	Container vpn ready: true, restart count 0
Jan 21 22:30:22.422: INFO: ibm-storage-watcher-6fb675df47-x2x4h from kube-system started at 2019-01-21 19:04:47 +0000 UTC (1 container statuses recorded)
Jan 21 22:30:22.422: INFO: 	Container ibm-storage-watcher-container ready: true, restart count 0
Jan 21 22:30:22.422: INFO: ibm-file-plugin-56f866c9c7-bz4g8 from kube-system started at 2019-01-21 19:04:47 +0000 UTC (1 container statuses recorded)
Jan 21 22:30:22.422: INFO: 	Container ibm-file-plugin-container ready: true, restart count 0
Jan 21 22:30:22.423: INFO: ibm-kube-fluentd-swfr2 from kube-system started at 2019-01-21 19:08:16 +0000 UTC (1 container statuses recorded)
Jan 21 22:30:22.423: INFO: 	Container fluentd ready: true, restart count 0
Jan 21 22:30:22.423: INFO: sonobuoy-systemd-logs-daemon-set-e7ca68af2267426a-f655g from heptio-sonobuoy started at 2019-01-21 21:19:23 +0000 UTC (2 container statuses recorded)
Jan 21 22:30:22.423: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 1
Jan 21 22:30:22.423: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Jan 21 22:30:22.423: INFO: ibm-master-proxy-static-10.191.28.39 from kube-system started at <nil> (0 container statuses recorded)
Jan 21 22:30:22.423: INFO: kube-dns-autoscaler-587cd5cd44-sg6d7 from kube-system started at 2019-01-21 19:04:47 +0000 UTC (1 container statuses recorded)
Jan 21 22:30:22.424: INFO: 	Container autoscaler ready: true, restart count 0
Jan 21 22:30:22.424: INFO: 
Logging pods the kubelet thinks is on node 10.191.28.45 before test
Jan 21 22:30:22.461: INFO: ibm-keepalived-watcher-lpbc8 from kube-system started at 2019-01-21 19:04:54 +0000 UTC (1 container statuses recorded)
Jan 21 22:30:22.461: INFO: 	Container keepalived-watcher ready: true, restart count 0
Jan 21 22:30:22.461: INFO: ibm-cloud-provider-ip-169-62-39-214-854b8b4b9f-jhb5h from ibm-system started at 2019-01-21 19:07:08 +0000 UTC (1 container statuses recorded)
Jan 21 22:30:22.461: INFO: 	Container ibm-cloud-provider-ip-169-62-39-214 ready: true, restart count 0
Jan 21 22:30:22.461: INFO: ibm-kube-fluentd-dgst5 from kube-system started at 2019-01-21 19:08:16 +0000 UTC (1 container statuses recorded)
Jan 21 22:30:22.461: INFO: 	Container fluentd ready: true, restart count 0
Jan 21 22:30:22.461: INFO: calico-node-wf86f from kube-system started at 2019-01-21 19:04:54 +0000 UTC (2 container statuses recorded)
Jan 21 22:30:22.461: INFO: 	Container calico-node ready: true, restart count 0
Jan 21 22:30:22.461: INFO: 	Container install-cni ready: true, restart count 0
Jan 21 22:30:22.461: INFO: sonobuoy-e2e-job-f09952848bde41e6 from heptio-sonobuoy started at 2019-01-21 21:19:23 +0000 UTC (2 container statuses recorded)
Jan 21 22:30:22.461: INFO: 	Container e2e ready: true, restart count 0
Jan 21 22:30:22.461: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Jan 21 22:30:22.461: INFO: sonobuoy-systemd-logs-daemon-set-e7ca68af2267426a-x52k6 from heptio-sonobuoy started at 2019-01-21 21:19:23 +0000 UTC (2 container statuses recorded)
Jan 21 22:30:22.461: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 1
Jan 21 22:30:22.461: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Jan 21 22:30:22.461: INFO: ibm-master-proxy-static-10.191.28.45 from kube-system started at <nil> (0 container statuses recorded)
Jan 21 22:30:22.461: INFO: kube-dns-amd64-fddfcc69-pfbsg from kube-system started at 2019-01-21 19:05:17 +0000 UTC (3 container statuses recorded)
Jan 21 22:30:22.461: INFO: 	Container dnsmasq ready: true, restart count 0
Jan 21 22:30:22.461: INFO: 	Container kubedns ready: true, restart count 0
Jan 21 22:30:22.461: INFO: 	Container sidecar ready: true, restart count 0
Jan 21 22:30:22.461: INFO: public-cra84c924d32e442ceb4b6d3925b452e95-alb1-5487bcf49f-2lh5k from kube-system started at 2019-01-21 19:07:51 +0000 UTC (4 container statuses recorded)
Jan 21 22:30:22.461: INFO: 	Container ingress-auth-1 ready: true, restart count 0
Jan 21 22:30:22.461: INFO: 	Container ingress-auth-2 ready: true, restart count 0
Jan 21 22:30:22.461: INFO: 	Container ingress-auth-3 ready: true, restart count 0
Jan 21 22:30:22.461: INFO: 	Container nginx-ingress ready: true, restart count 0
Jan 21 22:30:22.461: INFO: 
Logging pods the kubelet thinks is on node 10.191.28.59 before test
Jan 21 22:30:22.498: INFO: metrics-server-79744c9677-q495s from kube-system started at 2019-01-21 19:05:26 +0000 UTC (2 container statuses recorded)
Jan 21 22:30:22.498: INFO: 	Container metrics-server ready: true, restart count 0
Jan 21 22:30:22.498: INFO: 	Container metrics-server-nanny ready: true, restart count 0
Jan 21 22:30:22.498: INFO: ibm-cloud-provider-ip-169-62-39-214-854b8b4b9f-hhkzk from ibm-system started at 2019-01-21 19:07:08 +0000 UTC (1 container statuses recorded)
Jan 21 22:30:22.498: INFO: 	Container ibm-cloud-provider-ip-169-62-39-214 ready: true, restart count 0
Jan 21 22:30:22.498: INFO: public-cra84c924d32e442ceb4b6d3925b452e95-alb1-5487bcf49f-d2tg2 from kube-system started at 2019-01-21 19:07:51 +0000 UTC (4 container statuses recorded)
Jan 21 22:30:22.498: INFO: 	Container ingress-auth-1 ready: true, restart count 0
Jan 21 22:30:22.498: INFO: 	Container ingress-auth-2 ready: true, restart count 0
Jan 21 22:30:22.498: INFO: 	Container ingress-auth-3 ready: true, restart count 0
Jan 21 22:30:22.498: INFO: 	Container nginx-ingress ready: true, restart count 0
Jan 21 22:30:22.498: INFO: sonobuoy from heptio-sonobuoy started at 2019-01-21 21:19:21 +0000 UTC (1 container statuses recorded)
Jan 21 22:30:22.498: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Jan 21 22:30:22.498: INFO: ibm-master-proxy-static-10.191.28.59 from kube-system started at <nil> (0 container statuses recorded)
Jan 21 22:30:22.498: INFO: ibm-keepalived-watcher-tlqx2 from kube-system started at 2019-01-21 19:04:59 +0000 UTC (1 container statuses recorded)
Jan 21 22:30:22.498: INFO: 	Container keepalived-watcher ready: true, restart count 0
Jan 21 22:30:22.498: INFO: calico-node-z9frg from kube-system started at 2019-01-21 19:04:59 +0000 UTC (2 container statuses recorded)
Jan 21 22:30:22.498: INFO: 	Container calico-node ready: true, restart count 0
Jan 21 22:30:22.498: INFO: 	Container install-cni ready: true, restart count 0
Jan 21 22:30:22.498: INFO: sonobuoy-systemd-logs-daemon-set-e7ca68af2267426a-x9rm8 from heptio-sonobuoy started at 2019-01-21 21:19:23 +0000 UTC (2 container statuses recorded)
Jan 21 22:30:22.498: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 1
Jan 21 22:30:22.498: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Jan 21 22:30:22.498: INFO: ibm-kube-fluentd-4qcmt from kube-system started at 2019-01-21 19:08:16 +0000 UTC (1 container statuses recorded)
Jan 21 22:30:22.498: INFO: 	Container fluentd ready: true, restart count 0
[It] validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: verifying the node has the label node 10.191.28.39
STEP: verifying the node has the label node 10.191.28.45
STEP: verifying the node has the label node 10.191.28.59
Jan 21 22:30:22.632: INFO: Pod test-k8s-e2e-pvg-master-verification requesting resource cpu=0m on Node 10.191.28.39
Jan 21 22:30:22.633: INFO: Pod sonobuoy requesting resource cpu=0m on Node 10.191.28.59
Jan 21 22:30:22.633: INFO: Pod sonobuoy-e2e-job-f09952848bde41e6 requesting resource cpu=0m on Node 10.191.28.45
Jan 21 22:30:22.633: INFO: Pod sonobuoy-systemd-logs-daemon-set-e7ca68af2267426a-f655g requesting resource cpu=0m on Node 10.191.28.39
Jan 21 22:30:22.633: INFO: Pod sonobuoy-systemd-logs-daemon-set-e7ca68af2267426a-x52k6 requesting resource cpu=0m on Node 10.191.28.45
Jan 21 22:30:22.633: INFO: Pod sonobuoy-systemd-logs-daemon-set-e7ca68af2267426a-x9rm8 requesting resource cpu=0m on Node 10.191.28.59
Jan 21 22:30:22.633: INFO: Pod ibm-cloud-provider-ip-169-62-39-214-854b8b4b9f-hhkzk requesting resource cpu=5m on Node 10.191.28.59
Jan 21 22:30:22.633: INFO: Pod ibm-cloud-provider-ip-169-62-39-214-854b8b4b9f-jhb5h requesting resource cpu=5m on Node 10.191.28.45
Jan 21 22:30:22.634: INFO: Pod calico-kube-controllers-5c699798bc-7cfbr requesting resource cpu=10m on Node 10.191.28.39
Jan 21 22:30:22.634: INFO: Pod calico-node-6zjw9 requesting resource cpu=255m on Node 10.191.28.39
Jan 21 22:30:22.634: INFO: Pod calico-node-wf86f requesting resource cpu=255m on Node 10.191.28.45
Jan 21 22:30:22.634: INFO: Pod calico-node-z9frg requesting resource cpu=255m on Node 10.191.28.59
Jan 21 22:30:22.634: INFO: Pod ibm-file-plugin-56f866c9c7-bz4g8 requesting resource cpu=50m on Node 10.191.28.39
Jan 21 22:30:22.634: INFO: Pod ibm-keepalived-watcher-lpbc8 requesting resource cpu=5m on Node 10.191.28.45
Jan 21 22:30:22.634: INFO: Pod ibm-keepalived-watcher-nw8wp requesting resource cpu=5m on Node 10.191.28.39
Jan 21 22:30:22.634: INFO: Pod ibm-keepalived-watcher-tlqx2 requesting resource cpu=5m on Node 10.191.28.59
Jan 21 22:30:22.634: INFO: Pod ibm-kube-fluentd-4qcmt requesting resource cpu=25m on Node 10.191.28.59
Jan 21 22:30:22.635: INFO: Pod ibm-kube-fluentd-dgst5 requesting resource cpu=25m on Node 10.191.28.45
Jan 21 22:30:22.635: INFO: Pod ibm-kube-fluentd-swfr2 requesting resource cpu=25m on Node 10.191.28.39
Jan 21 22:30:22.635: INFO: Pod ibm-master-proxy-static-10.191.28.39 requesting resource cpu=25m on Node 10.191.28.39
Jan 21 22:30:22.635: INFO: Pod ibm-master-proxy-static-10.191.28.45 requesting resource cpu=25m on Node 10.191.28.45
Jan 21 22:30:22.635: INFO: Pod ibm-master-proxy-static-10.191.28.59 requesting resource cpu=25m on Node 10.191.28.59
Jan 21 22:30:22.635: INFO: Pod ibm-storage-watcher-6fb675df47-x2x4h requesting resource cpu=50m on Node 10.191.28.39
Jan 21 22:30:22.635: INFO: Pod kube-dns-amd64-fddfcc69-l7fs4 requesting resource cpu=260m on Node 10.191.28.39
Jan 21 22:30:22.635: INFO: Pod kube-dns-amd64-fddfcc69-pfbsg requesting resource cpu=260m on Node 10.191.28.45
Jan 21 22:30:22.635: INFO: Pod kube-dns-autoscaler-587cd5cd44-sg6d7 requesting resource cpu=20m on Node 10.191.28.39
Jan 21 22:30:22.636: INFO: Pod kubernetes-dashboard-b4bc7db5d-4stht requesting resource cpu=50m on Node 10.191.28.39
Jan 21 22:30:22.636: INFO: Pod metrics-server-79744c9677-q495s requesting resource cpu=53m on Node 10.191.28.59
Jan 21 22:30:22.636: INFO: Pod public-cra84c924d32e442ceb4b6d3925b452e95-alb1-5487bcf49f-2lh5k requesting resource cpu=0m on Node 10.191.28.45
Jan 21 22:30:22.636: INFO: Pod public-cra84c924d32e442ceb4b6d3925b452e95-alb1-5487bcf49f-d2tg2 requesting resource cpu=0m on Node 10.191.28.59
Jan 21 22:30:22.636: INFO: Pod vpn-65599665d9-n57t7 requesting resource cpu=5m on Node 10.191.28.39
STEP: Starting Pods to consume most of the cluster CPU.
STEP: Creating another pod that requires unavailable amount of CPU.
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-240534c6-1dcc-11e9-8130-be6597f3ae53.157bfdae755512c4], Reason = [Scheduled], Message = [Successfully assigned e2e-tests-sched-pred-kslvv/filler-pod-240534c6-1dcc-11e9-8130-be6597f3ae53 to 10.191.28.59]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-240534c6-1dcc-11e9-8130-be6597f3ae53.157bfdaeb4f6ca34], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-240534c6-1dcc-11e9-8130-be6597f3ae53.157bfdaeb7c31bb4], Reason = [Created], Message = [Created container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-240534c6-1dcc-11e9-8130-be6597f3ae53.157bfdaebf7ebd41], Reason = [Started], Message = [Started container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-2408865f-1dcc-11e9-8130-be6597f3ae53.157bfdae761b453a], Reason = [Scheduled], Message = [Successfully assigned e2e-tests-sched-pred-kslvv/filler-pod-2408865f-1dcc-11e9-8130-be6597f3ae53 to 10.191.28.39]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-2408865f-1dcc-11e9-8130-be6597f3ae53.157bfdaea342f956], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-2408865f-1dcc-11e9-8130-be6597f3ae53.157bfdaea6153e6a], Reason = [Created], Message = [Created container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-2408865f-1dcc-11e9-8130-be6597f3ae53.157bfdaead00af49], Reason = [Started], Message = [Started container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-240a58ed-1dcc-11e9-8130-be6597f3ae53.157bfdae76eb25bd], Reason = [Scheduled], Message = [Successfully assigned e2e-tests-sched-pred-kslvv/filler-pod-240a58ed-1dcc-11e9-8130-be6597f3ae53 to 10.191.28.45]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-240a58ed-1dcc-11e9-8130-be6597f3ae53.157bfdaebe50a409], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-240a58ed-1dcc-11e9-8130-be6597f3ae53.157bfdaec214c65e], Reason = [Created], Message = [Created container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-240a58ed-1dcc-11e9-8130-be6597f3ae53.157bfdaed062ee43], Reason = [Started], Message = [Started container]
STEP: Considering event: 
Type = [Warning], Name = [additional-pod.157bfdaef51539b4], Reason = [FailedScheduling], Message = [0/3 nodes are available: 3 Insufficient cpu.]
STEP: removing the label node off the node 10.191.28.59
STEP: verifying the node doesn't have the label node
STEP: removing the label node off the node 10.191.28.39
STEP: verifying the node doesn't have the label node
STEP: removing the label node off the node 10.191.28.45
STEP: verifying the node doesn't have the label node
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 22:30:26.066: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-sched-pred-kslvv" for this suite.
Jan 21 22:30:34.164: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 22:30:34.701: INFO: namespace: e2e-tests-sched-pred-kslvv, resource: bindings, ignored listing per whitelist
Jan 21 22:30:34.732: INFO: namespace e2e-tests-sched-pred-kslvv deletion completed in 8.653178707s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:69

• [SLOW TEST:12.868 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 22:30:34.733: INFO: >>> kubeConfig: /tmp/kubeconfig-933165938
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-24z4m
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-map-2b6fa492-1dcc-11e9-8130-be6597f3ae53
STEP: Creating a pod to test consume configMaps
Jan 21 22:30:35.113: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-2b7167a5-1dcc-11e9-8130-be6597f3ae53" in namespace "e2e-tests-projected-24z4m" to be "success or failure"
Jan 21 22:30:35.124: INFO: Pod "pod-projected-configmaps-2b7167a5-1dcc-11e9-8130-be6597f3ae53": Phase="Pending", Reason="", readiness=false. Elapsed: 11.047933ms
Jan 21 22:30:37.144: INFO: Pod "pod-projected-configmaps-2b7167a5-1dcc-11e9-8130-be6597f3ae53": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.031565707s
STEP: Saw pod success
Jan 21 22:30:37.144: INFO: Pod "pod-projected-configmaps-2b7167a5-1dcc-11e9-8130-be6597f3ae53" satisfied condition "success or failure"
Jan 21 22:30:37.155: INFO: Trying to get logs from node 10.191.28.59 pod pod-projected-configmaps-2b7167a5-1dcc-11e9-8130-be6597f3ae53 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Jan 21 22:30:37.264: INFO: Waiting for pod pod-projected-configmaps-2b7167a5-1dcc-11e9-8130-be6597f3ae53 to disappear
Jan 21 22:30:37.274: INFO: Pod pod-projected-configmaps-2b7167a5-1dcc-11e9-8130-be6597f3ae53 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 22:30:37.274: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-24z4m" for this suite.
Jan 21 22:30:43.319: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 22:30:43.426: INFO: namespace: e2e-tests-projected-24z4m, resource: bindings, ignored listing per whitelist
Jan 21 22:30:43.824: INFO: namespace e2e-tests-projected-24z4m deletion completed in 6.536888683s

• [SLOW TEST:9.091 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 22:30:43.827: INFO: >>> kubeConfig: /tmp/kubeconfig-933165938
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-secrets-gnf7l
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name s-test-opt-del-30d9c2bb-1dcc-11e9-8130-be6597f3ae53
STEP: Creating secret with name s-test-opt-upd-30d9c468-1dcc-11e9-8130-be6597f3ae53
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-30d9c2bb-1dcc-11e9-8130-be6597f3ae53
STEP: Updating secret s-test-opt-upd-30d9c468-1dcc-11e9-8130-be6597f3ae53
STEP: Creating secret with name s-test-opt-create-30d9c4a2-1dcc-11e9-8130-be6597f3ae53
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 22:31:59.406: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-gnf7l" for this suite.
Jan 21 22:32:23.511: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 22:32:23.586: INFO: namespace: e2e-tests-secrets-gnf7l, resource: bindings, ignored listing per whitelist
Jan 21 22:32:23.892: INFO: namespace e2e-tests-secrets-gnf7l deletion completed in 24.42795027s

• [SLOW TEST:100.066 seconds]
[sig-storage] Secrets
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] Projected 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 22:32:23.893: INFO: >>> kubeConfig: /tmp/kubeconfig-933165938
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-8pwrq
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Jan 21 22:32:24.280: INFO: Waiting up to 5m0s for pod "downwardapi-volume-6c835f59-1dcc-11e9-8130-be6597f3ae53" in namespace "e2e-tests-projected-8pwrq" to be "success or failure"
Jan 21 22:32:24.291: INFO: Pod "downwardapi-volume-6c835f59-1dcc-11e9-8130-be6597f3ae53": Phase="Pending", Reason="", readiness=false. Elapsed: 10.846054ms
Jan 21 22:32:26.303: INFO: Pod "downwardapi-volume-6c835f59-1dcc-11e9-8130-be6597f3ae53": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.022571517s
STEP: Saw pod success
Jan 21 22:32:26.303: INFO: Pod "downwardapi-volume-6c835f59-1dcc-11e9-8130-be6597f3ae53" satisfied condition "success or failure"
Jan 21 22:32:26.322: INFO: Trying to get logs from node 10.191.28.59 pod downwardapi-volume-6c835f59-1dcc-11e9-8130-be6597f3ae53 container client-container: <nil>
STEP: delete the pod
Jan 21 22:32:26.378: INFO: Waiting for pod downwardapi-volume-6c835f59-1dcc-11e9-8130-be6597f3ae53 to disappear
Jan 21 22:32:26.387: INFO: Pod downwardapi-volume-6c835f59-1dcc-11e9-8130-be6597f3ae53 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 22:32:26.388: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-8pwrq" for this suite.
Jan 21 22:32:32.438: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 22:32:32.704: INFO: namespace: e2e-tests-projected-8pwrq, resource: bindings, ignored listing per whitelist
Jan 21 22:32:32.955: INFO: namespace e2e-tests-projected-8pwrq deletion completed in 6.55037608s

• [SLOW TEST:9.062 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Projected 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 22:32:32.955: INFO: >>> kubeConfig: /tmp/kubeconfig-933165938
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-76df7
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with configMap that has name projected-configmap-test-upd-71e3777f-1dcc-11e9-8130-be6597f3ae53
STEP: Creating the pod
STEP: Updating configmap projected-configmap-test-upd-71e3777f-1dcc-11e9-8130-be6597f3ae53
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 22:32:37.517: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-76df7" for this suite.
Jan 21 22:33:01.600: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 22:33:01.963: INFO: namespace: e2e-tests-projected-76df7, resource: bindings, ignored listing per whitelist
Jan 21 22:33:01.985: INFO: namespace e2e-tests-projected-76df7 deletion completed in 24.453820369s

• [SLOW TEST:29.030 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 22:33:01.986: INFO: >>> kubeConfig: /tmp/kubeconfig-933165938
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-container-lifecycle-hook-zh9w8
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Jan 21 22:33:06.515: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Jan 21 22:33:06.525: INFO: Pod pod-with-prestop-exec-hook still exists
Jan 21 22:33:08.525: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Jan 21 22:33:08.536: INFO: Pod pod-with-prestop-exec-hook still exists
Jan 21 22:33:10.525: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Jan 21 22:33:10.536: INFO: Pod pod-with-prestop-exec-hook still exists
Jan 21 22:33:12.525: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Jan 21 22:33:12.535: INFO: Pod pod-with-prestop-exec-hook still exists
Jan 21 22:33:14.525: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Jan 21 22:33:14.564: INFO: Pod pod-with-prestop-exec-hook still exists
Jan 21 22:33:16.525: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Jan 21 22:33:16.536: INFO: Pod pod-with-prestop-exec-hook still exists
Jan 21 22:33:18.525: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Jan 21 22:33:18.536: INFO: Pod pod-with-prestop-exec-hook still exists
Jan 21 22:33:20.525: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Jan 21 22:33:20.535: INFO: Pod pod-with-prestop-exec-hook still exists
Jan 21 22:33:22.525: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Jan 21 22:33:22.549: INFO: Pod pod-with-prestop-exec-hook still exists
Jan 21 22:33:24.525: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Jan 21 22:33:24.537: INFO: Pod pod-with-prestop-exec-hook still exists
Jan 21 22:33:26.525: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Jan 21 22:33:26.545: INFO: Pod pod-with-prestop-exec-hook still exists
Jan 21 22:33:28.525: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Jan 21 22:33:28.954: INFO: Pod pod-with-prestop-exec-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 22:33:28.988: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-lifecycle-hook-zh9w8" for this suite.
Jan 21 22:33:53.049: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 22:33:53.547: INFO: namespace: e2e-tests-container-lifecycle-hook-zh9w8, resource: bindings, ignored listing per whitelist
Jan 21 22:33:53.696: INFO: namespace e2e-tests-container-lifecycle-hook-zh9w8 deletion completed in 24.692084726s

• [SLOW TEST:51.711 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when create a pod with lifecycle hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute prestop exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 22:33:53.698: INFO: >>> kubeConfig: /tmp/kubeconfig-933165938
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-z5zrb
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-a21a7d39-1dcc-11e9-8130-be6597f3ae53
STEP: Creating a pod to test consume configMaps
Jan 21 22:33:54.283: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-a22904c3-1dcc-11e9-8130-be6597f3ae53" in namespace "e2e-tests-projected-z5zrb" to be "success or failure"
Jan 21 22:33:54.293: INFO: Pod "pod-projected-configmaps-a22904c3-1dcc-11e9-8130-be6597f3ae53": Phase="Pending", Reason="", readiness=false. Elapsed: 9.351546ms
Jan 21 22:33:56.306: INFO: Pod "pod-projected-configmaps-a22904c3-1dcc-11e9-8130-be6597f3ae53": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.022876011s
STEP: Saw pod success
Jan 21 22:33:56.306: INFO: Pod "pod-projected-configmaps-a22904c3-1dcc-11e9-8130-be6597f3ae53" satisfied condition "success or failure"
Jan 21 22:33:56.319: INFO: Trying to get logs from node 10.191.28.59 pod pod-projected-configmaps-a22904c3-1dcc-11e9-8130-be6597f3ae53 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Jan 21 22:33:56.375: INFO: Waiting for pod pod-projected-configmaps-a22904c3-1dcc-11e9-8130-be6597f3ae53 to disappear
Jan 21 22:33:56.387: INFO: Pod pod-projected-configmaps-a22904c3-1dcc-11e9-8130-be6597f3ae53 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 22:33:56.387: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-z5zrb" for this suite.
Jan 21 22:34:02.435: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 22:34:02.493: INFO: namespace: e2e-tests-projected-z5zrb, resource: bindings, ignored listing per whitelist
Jan 21 22:34:02.790: INFO: namespace e2e-tests-projected-z5zrb deletion completed in 6.388847125s

• [SLOW TEST:9.092 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 22:34:02.792: INFO: >>> kubeConfig: /tmp/kubeconfig-933165938
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-pods-qt252
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Jan 21 22:34:05.700: INFO: Successfully updated pod "pod-update-a76ed134-1dcc-11e9-8130-be6597f3ae53"
STEP: verifying the updated pod is in kubernetes
Jan 21 22:34:05.765: INFO: Pod update OK
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 22:34:05.765: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-qt252" for this suite.
Jan 21 22:34:21.812: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 22:34:22.177: INFO: namespace: e2e-tests-pods-qt252, resource: bindings, ignored listing per whitelist
Jan 21 22:34:22.253: INFO: namespace e2e-tests-pods-qt252 deletion completed in 16.474529921s

• [SLOW TEST:19.461 seconds]
[k8s.io] Pods
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 22:34:22.255: INFO: >>> kubeConfig: /tmp/kubeconfig-933165938
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-mqtvt
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-map-b30b38f3-1dcc-11e9-8130-be6597f3ae53
STEP: Creating a pod to test consume configMaps
Jan 21 22:34:22.619: INFO: Waiting up to 5m0s for pod "pod-configmaps-b30cc14b-1dcc-11e9-8130-be6597f3ae53" in namespace "e2e-tests-configmap-mqtvt" to be "success or failure"
Jan 21 22:34:22.629: INFO: Pod "pod-configmaps-b30cc14b-1dcc-11e9-8130-be6597f3ae53": Phase="Pending", Reason="", readiness=false. Elapsed: 10.223397ms
Jan 21 22:34:24.640: INFO: Pod "pod-configmaps-b30cc14b-1dcc-11e9-8130-be6597f3ae53": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.0212348s
STEP: Saw pod success
Jan 21 22:34:24.640: INFO: Pod "pod-configmaps-b30cc14b-1dcc-11e9-8130-be6597f3ae53" satisfied condition "success or failure"
Jan 21 22:34:24.651: INFO: Trying to get logs from node 10.191.28.59 pod pod-configmaps-b30cc14b-1dcc-11e9-8130-be6597f3ae53 container configmap-volume-test: <nil>
STEP: delete the pod
Jan 21 22:34:24.715: INFO: Waiting for pod pod-configmaps-b30cc14b-1dcc-11e9-8130-be6597f3ae53 to disappear
Jan 21 22:34:24.727: INFO: Pod pod-configmaps-b30cc14b-1dcc-11e9-8130-be6597f3ae53 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 22:34:24.728: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-mqtvt" for this suite.
Jan 21 22:34:30.781: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 22:34:30.950: INFO: namespace: e2e-tests-configmap-mqtvt, resource: bindings, ignored listing per whitelist
Jan 21 22:34:31.354: INFO: namespace e2e-tests-configmap-mqtvt deletion completed in 6.60956729s

• [SLOW TEST:9.100 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] Projected 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 22:34:31.355: INFO: >>> kubeConfig: /tmp/kubeconfig-933165938
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-54ht2
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name projected-secret-test-b8749684-1dcc-11e9-8130-be6597f3ae53
STEP: Creating a pod to test consume secrets
Jan 21 22:34:31.698: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-b8763e08-1dcc-11e9-8130-be6597f3ae53" in namespace "e2e-tests-projected-54ht2" to be "success or failure"
Jan 21 22:34:31.707: INFO: Pod "pod-projected-secrets-b8763e08-1dcc-11e9-8130-be6597f3ae53": Phase="Pending", Reason="", readiness=false. Elapsed: 9.326871ms
Jan 21 22:34:33.764: INFO: Pod "pod-projected-secrets-b8763e08-1dcc-11e9-8130-be6597f3ae53": Phase="Running", Reason="", readiness=true. Elapsed: 2.065889422s
Jan 21 22:34:35.774: INFO: Pod "pod-projected-secrets-b8763e08-1dcc-11e9-8130-be6597f3ae53": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.076511311s
STEP: Saw pod success
Jan 21 22:34:35.775: INFO: Pod "pod-projected-secrets-b8763e08-1dcc-11e9-8130-be6597f3ae53" satisfied condition "success or failure"
Jan 21 22:34:35.785: INFO: Trying to get logs from node 10.191.28.39 pod pod-projected-secrets-b8763e08-1dcc-11e9-8130-be6597f3ae53 container secret-volume-test: <nil>
STEP: delete the pod
Jan 21 22:34:35.848: INFO: Waiting for pod pod-projected-secrets-b8763e08-1dcc-11e9-8130-be6597f3ae53 to disappear
Jan 21 22:34:35.858: INFO: Pod pod-projected-secrets-b8763e08-1dcc-11e9-8130-be6597f3ae53 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 22:34:35.858: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-54ht2" for this suite.
Jan 21 22:34:41.904: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 22:34:42.264: INFO: namespace: e2e-tests-projected-54ht2, resource: bindings, ignored listing per whitelist
Jan 21 22:34:42.357: INFO: namespace e2e-tests-projected-54ht2 deletion completed in 6.485365972s

• [SLOW TEST:11.002 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 22:34:42.362: INFO: >>> kubeConfig: /tmp/kubeconfig-933165938
STEP: Building a namespace api object, basename containers
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-containers-c488m
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test override arguments
Jan 21 22:34:42.773: INFO: Waiting up to 5m0s for pod "client-containers-bf0fb194-1dcc-11e9-8130-be6597f3ae53" in namespace "e2e-tests-containers-c488m" to be "success or failure"
Jan 21 22:34:42.785: INFO: Pod "client-containers-bf0fb194-1dcc-11e9-8130-be6597f3ae53": Phase="Pending", Reason="", readiness=false. Elapsed: 12.205111ms
Jan 21 22:34:44.800: INFO: Pod "client-containers-bf0fb194-1dcc-11e9-8130-be6597f3ae53": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.026494058s
STEP: Saw pod success
Jan 21 22:34:44.800: INFO: Pod "client-containers-bf0fb194-1dcc-11e9-8130-be6597f3ae53" satisfied condition "success or failure"
Jan 21 22:34:44.810: INFO: Trying to get logs from node 10.191.28.59 pod client-containers-bf0fb194-1dcc-11e9-8130-be6597f3ae53 container test-container: <nil>
STEP: delete the pod
Jan 21 22:34:44.869: INFO: Waiting for pod client-containers-bf0fb194-1dcc-11e9-8130-be6597f3ae53 to disappear
Jan 21 22:34:44.879: INFO: Pod client-containers-bf0fb194-1dcc-11e9-8130-be6597f3ae53 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 22:34:44.879: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-c488m" for this suite.
Jan 21 22:34:50.931: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 22:34:51.255: INFO: namespace: e2e-tests-containers-c488m, resource: bindings, ignored listing per whitelist
Jan 21 22:34:51.282: INFO: namespace e2e-tests-containers-c488m deletion completed in 6.387905731s

• [SLOW TEST:8.921 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 22:34:51.288: INFO: >>> kubeConfig: /tmp/kubeconfig-933165938
STEP: Building a namespace api object, basename sched-pred
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-sched-pred-b694m
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:78
Jan 21 22:34:51.646: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Jan 21 22:34:51.669: INFO: Waiting for terminating namespaces to be deleted...
Jan 21 22:34:51.678: INFO: 
Logging pods the kubelet thinks is on node 10.191.28.39 before test
Jan 21 22:34:51.709: INFO: ibm-keepalived-watcher-nw8wp from kube-system started at 2019-01-21 19:04:47 +0000 UTC (1 container statuses recorded)
Jan 21 22:34:51.709: INFO: 	Container keepalived-watcher ready: true, restart count 0
Jan 21 22:34:51.709: INFO: kube-dns-amd64-fddfcc69-l7fs4 from kube-system started at 2019-01-21 19:04:47 +0000 UTC (3 container statuses recorded)
Jan 21 22:34:51.709: INFO: 	Container dnsmasq ready: true, restart count 0
Jan 21 22:34:51.709: INFO: 	Container kubedns ready: true, restart count 0
Jan 21 22:34:51.709: INFO: 	Container sidecar ready: true, restart count 0
Jan 21 22:34:51.709: INFO: calico-kube-controllers-5c699798bc-7cfbr from kube-system started at 2019-01-21 19:04:47 +0000 UTC (1 container statuses recorded)
Jan 21 22:34:51.709: INFO: 	Container calico-kube-controllers ready: true, restart count 0
Jan 21 22:34:51.709: INFO: kubernetes-dashboard-b4bc7db5d-4stht from kube-system started at 2019-01-21 19:04:47 +0000 UTC (1 container statuses recorded)
Jan 21 22:34:51.709: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
Jan 21 22:34:51.709: INFO: vpn-65599665d9-n57t7 from kube-system started at 2019-01-21 19:04:47 +0000 UTC (1 container statuses recorded)
Jan 21 22:34:51.709: INFO: 	Container vpn ready: true, restart count 0
Jan 21 22:34:51.709: INFO: calico-node-6zjw9 from kube-system started at 2019-01-21 19:04:47 +0000 UTC (2 container statuses recorded)
Jan 21 22:34:51.709: INFO: 	Container calico-node ready: true, restart count 0
Jan 21 22:34:51.709: INFO: 	Container install-cni ready: true, restart count 0
Jan 21 22:34:51.709: INFO: test-k8s-e2e-pvg-master-verification from default started at 2019-01-21 21:18:59 +0000 UTC (1 container statuses recorded)
Jan 21 22:34:51.709: INFO: 	Container test-k8s-e2e-pvg-master-verification ready: true, restart count 0
Jan 21 22:34:51.709: INFO: ibm-storage-watcher-6fb675df47-x2x4h from kube-system started at 2019-01-21 19:04:47 +0000 UTC (1 container statuses recorded)
Jan 21 22:34:51.709: INFO: 	Container ibm-storage-watcher-container ready: true, restart count 0
Jan 21 22:34:51.709: INFO: ibm-file-plugin-56f866c9c7-bz4g8 from kube-system started at 2019-01-21 19:04:47 +0000 UTC (1 container statuses recorded)
Jan 21 22:34:51.709: INFO: 	Container ibm-file-plugin-container ready: true, restart count 0
Jan 21 22:34:51.709: INFO: ibm-kube-fluentd-swfr2 from kube-system started at 2019-01-21 19:08:16 +0000 UTC (1 container statuses recorded)
Jan 21 22:34:51.709: INFO: 	Container fluentd ready: true, restart count 0
Jan 21 22:34:51.709: INFO: sonobuoy-systemd-logs-daemon-set-e7ca68af2267426a-f655g from heptio-sonobuoy started at 2019-01-21 21:19:23 +0000 UTC (2 container statuses recorded)
Jan 21 22:34:51.709: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 1
Jan 21 22:34:51.709: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Jan 21 22:34:51.709: INFO: ibm-master-proxy-static-10.191.28.39 from kube-system started at <nil> (0 container statuses recorded)
Jan 21 22:34:51.709: INFO: kube-dns-autoscaler-587cd5cd44-sg6d7 from kube-system started at 2019-01-21 19:04:47 +0000 UTC (1 container statuses recorded)
Jan 21 22:34:51.709: INFO: 	Container autoscaler ready: true, restart count 0
Jan 21 22:34:51.709: INFO: 
Logging pods the kubelet thinks is on node 10.191.28.45 before test
Jan 21 22:34:51.740: INFO: ibm-keepalived-watcher-lpbc8 from kube-system started at 2019-01-21 19:04:54 +0000 UTC (1 container statuses recorded)
Jan 21 22:34:51.741: INFO: 	Container keepalived-watcher ready: true, restart count 0
Jan 21 22:34:51.741: INFO: ibm-cloud-provider-ip-169-62-39-214-854b8b4b9f-jhb5h from ibm-system started at 2019-01-21 19:07:08 +0000 UTC (1 container statuses recorded)
Jan 21 22:34:51.741: INFO: 	Container ibm-cloud-provider-ip-169-62-39-214 ready: true, restart count 0
Jan 21 22:34:51.741: INFO: ibm-kube-fluentd-dgst5 from kube-system started at 2019-01-21 19:08:16 +0000 UTC (1 container statuses recorded)
Jan 21 22:34:51.741: INFO: 	Container fluentd ready: true, restart count 0
Jan 21 22:34:51.741: INFO: calico-node-wf86f from kube-system started at 2019-01-21 19:04:54 +0000 UTC (2 container statuses recorded)
Jan 21 22:34:51.741: INFO: 	Container calico-node ready: true, restart count 0
Jan 21 22:34:51.741: INFO: 	Container install-cni ready: true, restart count 0
Jan 21 22:34:51.741: INFO: sonobuoy-e2e-job-f09952848bde41e6 from heptio-sonobuoy started at 2019-01-21 21:19:23 +0000 UTC (2 container statuses recorded)
Jan 21 22:34:51.742: INFO: 	Container e2e ready: true, restart count 0
Jan 21 22:34:51.742: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Jan 21 22:34:51.742: INFO: sonobuoy-systemd-logs-daemon-set-e7ca68af2267426a-x52k6 from heptio-sonobuoy started at 2019-01-21 21:19:23 +0000 UTC (2 container statuses recorded)
Jan 21 22:34:51.742: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 1
Jan 21 22:34:51.742: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Jan 21 22:34:51.742: INFO: ibm-master-proxy-static-10.191.28.45 from kube-system started at <nil> (0 container statuses recorded)
Jan 21 22:34:51.742: INFO: kube-dns-amd64-fddfcc69-pfbsg from kube-system started at 2019-01-21 19:05:17 +0000 UTC (3 container statuses recorded)
Jan 21 22:34:51.743: INFO: 	Container dnsmasq ready: true, restart count 0
Jan 21 22:34:51.743: INFO: 	Container kubedns ready: true, restart count 0
Jan 21 22:34:51.743: INFO: 	Container sidecar ready: true, restart count 0
Jan 21 22:34:51.743: INFO: public-cra84c924d32e442ceb4b6d3925b452e95-alb1-5487bcf49f-2lh5k from kube-system started at 2019-01-21 19:07:51 +0000 UTC (4 container statuses recorded)
Jan 21 22:34:51.743: INFO: 	Container ingress-auth-1 ready: true, restart count 0
Jan 21 22:34:51.743: INFO: 	Container ingress-auth-2 ready: true, restart count 0
Jan 21 22:34:51.743: INFO: 	Container ingress-auth-3 ready: true, restart count 0
Jan 21 22:34:51.743: INFO: 	Container nginx-ingress ready: true, restart count 0
Jan 21 22:34:51.743: INFO: 
Logging pods the kubelet thinks is on node 10.191.28.59 before test
Jan 21 22:34:51.778: INFO: metrics-server-79744c9677-q495s from kube-system started at 2019-01-21 19:05:26 +0000 UTC (2 container statuses recorded)
Jan 21 22:34:51.778: INFO: 	Container metrics-server ready: true, restart count 0
Jan 21 22:34:51.778: INFO: 	Container metrics-server-nanny ready: true, restart count 0
Jan 21 22:34:51.778: INFO: ibm-cloud-provider-ip-169-62-39-214-854b8b4b9f-hhkzk from ibm-system started at 2019-01-21 19:07:08 +0000 UTC (1 container statuses recorded)
Jan 21 22:34:51.778: INFO: 	Container ibm-cloud-provider-ip-169-62-39-214 ready: true, restart count 0
Jan 21 22:34:51.778: INFO: public-cra84c924d32e442ceb4b6d3925b452e95-alb1-5487bcf49f-d2tg2 from kube-system started at 2019-01-21 19:07:51 +0000 UTC (4 container statuses recorded)
Jan 21 22:34:51.779: INFO: 	Container ingress-auth-1 ready: true, restart count 0
Jan 21 22:34:51.779: INFO: 	Container ingress-auth-2 ready: true, restart count 0
Jan 21 22:34:51.779: INFO: 	Container ingress-auth-3 ready: true, restart count 0
Jan 21 22:34:51.779: INFO: 	Container nginx-ingress ready: true, restart count 0
Jan 21 22:34:51.779: INFO: sonobuoy from heptio-sonobuoy started at 2019-01-21 21:19:21 +0000 UTC (1 container statuses recorded)
Jan 21 22:34:51.779: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Jan 21 22:34:51.779: INFO: ibm-master-proxy-static-10.191.28.59 from kube-system started at <nil> (0 container statuses recorded)
Jan 21 22:34:51.779: INFO: ibm-keepalived-watcher-tlqx2 from kube-system started at 2019-01-21 19:04:59 +0000 UTC (1 container statuses recorded)
Jan 21 22:34:51.779: INFO: 	Container keepalived-watcher ready: true, restart count 0
Jan 21 22:34:51.779: INFO: calico-node-z9frg from kube-system started at 2019-01-21 19:04:59 +0000 UTC (2 container statuses recorded)
Jan 21 22:34:51.779: INFO: 	Container calico-node ready: true, restart count 0
Jan 21 22:34:51.779: INFO: 	Container install-cni ready: true, restart count 0
Jan 21 22:34:51.779: INFO: sonobuoy-systemd-logs-daemon-set-e7ca68af2267426a-x9rm8 from heptio-sonobuoy started at 2019-01-21 21:19:23 +0000 UTC (2 container statuses recorded)
Jan 21 22:34:51.779: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 1
Jan 21 22:34:51.779: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Jan 21 22:34:51.779: INFO: ibm-kube-fluentd-4qcmt from kube-system started at 2019-01-21 19:08:16 +0000 UTC (1 container statuses recorded)
Jan 21 22:34:51.779: INFO: 	Container fluentd ready: true, restart count 0
[It] validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Trying to schedule Pod with nonempty NodeSelector.
STEP: Considering event: 
Type = [Warning], Name = [restricted-pod.157bfded2084245f], Reason = [FailedScheduling], Message = [0/3 nodes are available: 3 node(s) didn't match node selector.]
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 22:34:52.845: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-sched-pred-b694m" for this suite.
Jan 21 22:34:58.903: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 22:34:59.158: INFO: namespace: e2e-tests-sched-pred-b694m, resource: bindings, ignored listing per whitelist
Jan 21 22:34:59.415: INFO: namespace e2e-tests-sched-pred-b694m deletion completed in 6.55224197s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:69

• [SLOW TEST:8.128 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 22:34:59.416: INFO: >>> kubeConfig: /tmp/kubeconfig-933165938
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-95rz8
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-map-c932feb1-1dcc-11e9-8130-be6597f3ae53
STEP: Creating a pod to test consume configMaps
Jan 21 22:34:59.789: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-c9348809-1dcc-11e9-8130-be6597f3ae53" in namespace "e2e-tests-projected-95rz8" to be "success or failure"
Jan 21 22:34:59.800: INFO: Pod "pod-projected-configmaps-c9348809-1dcc-11e9-8130-be6597f3ae53": Phase="Pending", Reason="", readiness=false. Elapsed: 11.136475ms
Jan 21 22:35:01.811: INFO: Pod "pod-projected-configmaps-c9348809-1dcc-11e9-8130-be6597f3ae53": Phase="Pending", Reason="", readiness=false. Elapsed: 2.021596198s
Jan 21 22:35:03.821: INFO: Pod "pod-projected-configmaps-c9348809-1dcc-11e9-8130-be6597f3ae53": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.032126867s
STEP: Saw pod success
Jan 21 22:35:03.821: INFO: Pod "pod-projected-configmaps-c9348809-1dcc-11e9-8130-be6597f3ae53" satisfied condition "success or failure"
Jan 21 22:35:03.831: INFO: Trying to get logs from node 10.191.28.39 pod pod-projected-configmaps-c9348809-1dcc-11e9-8130-be6597f3ae53 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Jan 21 22:35:03.898: INFO: Waiting for pod pod-projected-configmaps-c9348809-1dcc-11e9-8130-be6597f3ae53 to disappear
Jan 21 22:35:03.908: INFO: Pod pod-projected-configmaps-c9348809-1dcc-11e9-8130-be6597f3ae53 no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 22:35:03.909: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-95rz8" for this suite.
Jan 21 22:35:09.960: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 22:35:10.349: INFO: namespace: e2e-tests-projected-95rz8, resource: bindings, ignored listing per whitelist
Jan 21 22:35:10.455: INFO: namespace e2e-tests-projected-95rz8 deletion completed in 6.530657059s

• [SLOW TEST:11.040 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-api-machinery] Downward API 
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 22:35:10.458: INFO: >>> kubeConfig: /tmp/kubeconfig-933165938
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-xqphv
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Jan 21 22:35:10.881: INFO: Waiting up to 5m0s for pod "downward-api-cfd0a24a-1dcc-11e9-8130-be6597f3ae53" in namespace "e2e-tests-downward-api-xqphv" to be "success or failure"
Jan 21 22:35:10.964: INFO: Pod "downward-api-cfd0a24a-1dcc-11e9-8130-be6597f3ae53": Phase="Pending", Reason="", readiness=false. Elapsed: 82.374839ms
Jan 21 22:35:12.975: INFO: Pod "downward-api-cfd0a24a-1dcc-11e9-8130-be6597f3ae53": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.093264503s
STEP: Saw pod success
Jan 21 22:35:12.975: INFO: Pod "downward-api-cfd0a24a-1dcc-11e9-8130-be6597f3ae53" satisfied condition "success or failure"
Jan 21 22:35:12.985: INFO: Trying to get logs from node 10.191.28.59 pod downward-api-cfd0a24a-1dcc-11e9-8130-be6597f3ae53 container dapi-container: <nil>
STEP: delete the pod
Jan 21 22:35:13.064: INFO: Waiting for pod downward-api-cfd0a24a-1dcc-11e9-8130-be6597f3ae53 to disappear
Jan 21 22:35:13.073: INFO: Pod downward-api-cfd0a24a-1dcc-11e9-8130-be6597f3ae53 no longer exists
[AfterEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 22:35:13.074: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-xqphv" for this suite.
Jan 21 22:35:19.125: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 22:35:19.175: INFO: namespace: e2e-tests-downward-api-xqphv, resource: bindings, ignored listing per whitelist
Jan 21 22:35:19.498: INFO: namespace e2e-tests-downward-api-xqphv deletion completed in 6.409725247s

• [SLOW TEST:9.041 seconds]
[sig-api-machinery] Downward API
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with downward pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 22:35:19.502: INFO: >>> kubeConfig: /tmp/kubeconfig-933165938
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-subpath-l8pkp
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with downward pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-downwardapi-pq5z
STEP: Creating a pod to test atomic-volume-subpath
Jan 21 22:35:19.862: INFO: Waiting up to 5m0s for pod "pod-subpath-test-downwardapi-pq5z" in namespace "e2e-tests-subpath-l8pkp" to be "success or failure"
Jan 21 22:35:19.875: INFO: Pod "pod-subpath-test-downwardapi-pq5z": Phase="Pending", Reason="", readiness=false. Elapsed: 13.314583ms
Jan 21 22:35:21.887: INFO: Pod "pod-subpath-test-downwardapi-pq5z": Phase="Pending", Reason="", readiness=false. Elapsed: 2.024682804s
Jan 21 22:35:23.898: INFO: Pod "pod-subpath-test-downwardapi-pq5z": Phase="Running", Reason="", readiness=false. Elapsed: 4.035589802s
Jan 21 22:35:25.908: INFO: Pod "pod-subpath-test-downwardapi-pq5z": Phase="Running", Reason="", readiness=false. Elapsed: 6.04607724s
Jan 21 22:35:27.920: INFO: Pod "pod-subpath-test-downwardapi-pq5z": Phase="Running", Reason="", readiness=false. Elapsed: 8.057584627s
Jan 21 22:35:29.930: INFO: Pod "pod-subpath-test-downwardapi-pq5z": Phase="Running", Reason="", readiness=false. Elapsed: 10.068174879s
Jan 21 22:35:31.945: INFO: Pod "pod-subpath-test-downwardapi-pq5z": Phase="Running", Reason="", readiness=false. Elapsed: 12.083381621s
Jan 21 22:35:33.957: INFO: Pod "pod-subpath-test-downwardapi-pq5z": Phase="Running", Reason="", readiness=false. Elapsed: 14.094714956s
Jan 21 22:35:35.967: INFO: Pod "pod-subpath-test-downwardapi-pq5z": Phase="Running", Reason="", readiness=false. Elapsed: 16.10515366s
Jan 21 22:35:37.979: INFO: Pod "pod-subpath-test-downwardapi-pq5z": Phase="Running", Reason="", readiness=false. Elapsed: 18.117461594s
Jan 21 22:35:39.989: INFO: Pod "pod-subpath-test-downwardapi-pq5z": Phase="Running", Reason="", readiness=false. Elapsed: 20.127238472s
Jan 21 22:35:42.001: INFO: Pod "pod-subpath-test-downwardapi-pq5z": Phase="Running", Reason="", readiness=false. Elapsed: 22.138590699s
Jan 21 22:35:44.011: INFO: Pod "pod-subpath-test-downwardapi-pq5z": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.149318236s
STEP: Saw pod success
Jan 21 22:35:44.011: INFO: Pod "pod-subpath-test-downwardapi-pq5z" satisfied condition "success or failure"
Jan 21 22:35:44.022: INFO: Trying to get logs from node 10.191.28.39 pod pod-subpath-test-downwardapi-pq5z container test-container-subpath-downwardapi-pq5z: <nil>
STEP: delete the pod
Jan 21 22:35:44.112: INFO: Waiting for pod pod-subpath-test-downwardapi-pq5z to disappear
Jan 21 22:35:44.121: INFO: Pod pod-subpath-test-downwardapi-pq5z no longer exists
STEP: Deleting pod pod-subpath-test-downwardapi-pq5z
Jan 21 22:35:44.121: INFO: Deleting pod "pod-subpath-test-downwardapi-pq5z" in namespace "e2e-tests-subpath-l8pkp"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 22:35:44.130: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-l8pkp" for this suite.
Jan 21 22:35:50.175: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 22:35:50.647: INFO: namespace: e2e-tests-subpath-l8pkp, resource: bindings, ignored listing per whitelist
Jan 21 22:35:50.792: INFO: namespace e2e-tests-subpath-l8pkp deletion completed in 6.648279179s

• [SLOW TEST:31.290 seconds]
[sig-storage] Subpath
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with downward pod [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[k8s.io] Probing container 
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 22:35:50.792: INFO: >>> kubeConfig: /tmp/kubeconfig-933165938
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-container-probe-shzhm
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-http in namespace e2e-tests-container-probe-shzhm
Jan 21 22:35:55.289: INFO: Started pod liveness-http in namespace e2e-tests-container-probe-shzhm
STEP: checking the pod's current state and verifying that restartCount is present
Jan 21 22:35:55.300: INFO: Initial restart count of pod liveness-http is 0
Jan 21 22:36:13.410: INFO: Restart count of pod e2e-tests-container-probe-shzhm/liveness-http is now 1 (18.11041119s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 22:36:13.440: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-shzhm" for this suite.
Jan 21 22:36:19.502: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 22:36:19.589: INFO: namespace: e2e-tests-container-probe-shzhm, resource: bindings, ignored listing per whitelist
Jan 21 22:36:19.924: INFO: namespace e2e-tests-container-probe-shzhm deletion completed in 6.454922542s

• [SLOW TEST:29.132 seconds]
[k8s.io] Probing container
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl cluster-info 
  should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 22:36:19.924: INFO: >>> kubeConfig: /tmp/kubeconfig-933165938
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-44xtf
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: validating cluster-info
Jan 21 22:36:20.318: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-933165938 cluster-info'
Jan 21 22:36:20.700: INFO: stderr: ""
Jan 21 22:36:20.700: INFO: stdout: "\x1b[0;32mKubernetes master\x1b[0m is running at \x1b[0;33mhttps://172.21.0.1:443\x1b[0m\n\x1b[0;32mKubeDNS\x1b[0m is running at \x1b[0;33mhttps://172.21.0.1:443/api/v1/namespaces/kube-system/services/kube-dns:dns/proxy\x1b[0m\n\x1b[0;32mkubernetes-dashboard\x1b[0m is running at \x1b[0;33mhttps://172.21.0.1:443/api/v1/namespaces/kube-system/services/https:kubernetes-dashboard:/proxy\x1b[0m\n\x1b[0;32mMetrics-server\x1b[0m is running at \x1b[0;33mhttps://172.21.0.1:443/api/v1/namespaces/kube-system/services/https:metrics-server:/proxy\x1b[0m\n\nTo further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 22:36:20.700: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-44xtf" for this suite.
Jan 21 22:36:26.754: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 22:36:27.006: INFO: namespace: e2e-tests-kubectl-44xtf, resource: bindings, ignored listing per whitelist
Jan 21 22:36:27.136: INFO: namespace e2e-tests-kubectl-44xtf deletion completed in 6.420954137s

• [SLOW TEST:7.212 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl cluster-info
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should check if Kubernetes master services is included in cluster-info  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] Projected 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 22:36:27.138: INFO: >>> kubeConfig: /tmp/kubeconfig-933165938
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-kjcrf
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating the pod
Jan 21 22:36:30.070: INFO: Successfully updated pod "labelsupdatefd7953e8-1dcc-11e9-8130-be6597f3ae53"
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 22:36:32.114: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-kjcrf" for this suite.
Jan 21 22:36:56.195: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 22:36:56.423: INFO: namespace: e2e-tests-projected-kjcrf, resource: bindings, ignored listing per whitelist
Jan 21 22:36:56.586: INFO: namespace e2e-tests-projected-kjcrf deletion completed in 24.459048632s

• [SLOW TEST:29.449 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[k8s.io] [sig-node] PreStop 
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 22:36:56.589: INFO: >>> kubeConfig: /tmp/kubeconfig-933165938
STEP: Building a namespace api object, basename prestop
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-prestop-5nxst
STEP: Waiting for a default service account to be provisioned in namespace
[It] should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating server pod server in namespace e2e-tests-prestop-5nxst
STEP: Waiting for pods to come up.
STEP: Creating tester pod tester in namespace e2e-tests-prestop-5nxst
STEP: Deleting pre-stop pod
Jan 21 22:37:08.121: INFO: Saw: {
	"Hostname": "server",
	"Sent": null,
	"Received": {
		"prestop": 1
	},
	"Errors": null,
	"Log": [
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up."
	],
	"StillContactingPeers": true
}
STEP: Deleting the server pod
[AfterEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 22:37:08.142: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-prestop-5nxst" for this suite.
Jan 21 22:37:48.198: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 22:37:48.386: INFO: namespace: e2e-tests-prestop-5nxst, resource: bindings, ignored listing per whitelist
Jan 21 22:37:48.661: INFO: namespace e2e-tests-prestop-5nxst deletion completed in 40.496735964s

• [SLOW TEST:52.073 seconds]
[k8s.io] [sig-node] PreStop
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 22:37:48.663: INFO: >>> kubeConfig: /tmp/kubeconfig-933165938
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-7ccqx
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Jan 21 22:37:49.024: INFO: Waiting up to 5m0s for pod "downwardapi-volume-2e134455-1dcd-11e9-8130-be6597f3ae53" in namespace "e2e-tests-downward-api-7ccqx" to be "success or failure"
Jan 21 22:37:49.039: INFO: Pod "downwardapi-volume-2e134455-1dcd-11e9-8130-be6597f3ae53": Phase="Pending", Reason="", readiness=false. Elapsed: 14.062807ms
Jan 21 22:37:51.051: INFO: Pod "downwardapi-volume-2e134455-1dcd-11e9-8130-be6597f3ae53": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.025901689s
STEP: Saw pod success
Jan 21 22:37:51.051: INFO: Pod "downwardapi-volume-2e134455-1dcd-11e9-8130-be6597f3ae53" satisfied condition "success or failure"
Jan 21 22:37:51.063: INFO: Trying to get logs from node 10.191.28.59 pod downwardapi-volume-2e134455-1dcd-11e9-8130-be6597f3ae53 container client-container: <nil>
STEP: delete the pod
Jan 21 22:37:51.131: INFO: Waiting for pod downwardapi-volume-2e134455-1dcd-11e9-8130-be6597f3ae53 to disappear
Jan 21 22:37:51.142: INFO: Pod downwardapi-volume-2e134455-1dcd-11e9-8130-be6597f3ae53 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 22:37:51.143: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-7ccqx" for this suite.
Jan 21 22:37:57.192: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 22:37:57.325: INFO: namespace: e2e-tests-downward-api-7ccqx, resource: bindings, ignored listing per whitelist
Jan 21 22:37:57.767: INFO: namespace e2e-tests-downward-api-7ccqx deletion completed in 6.610293189s

• [SLOW TEST:9.104 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 22:37:57.768: INFO: >>> kubeConfig: /tmp/kubeconfig-933165938
STEP: Building a namespace api object, basename var-expansion
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-var-expansion-62r4p
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test substitution in container's command
Jan 21 22:37:58.281: INFO: Waiting up to 5m0s for pod "var-expansion-338a7092-1dcd-11e9-8130-be6597f3ae53" in namespace "e2e-tests-var-expansion-62r4p" to be "success or failure"
Jan 21 22:37:58.293: INFO: Pod "var-expansion-338a7092-1dcd-11e9-8130-be6597f3ae53": Phase="Pending", Reason="", readiness=false. Elapsed: 11.320121ms
Jan 21 22:38:00.364: INFO: Pod "var-expansion-338a7092-1dcd-11e9-8130-be6597f3ae53": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.082467027s
STEP: Saw pod success
Jan 21 22:38:00.364: INFO: Pod "var-expansion-338a7092-1dcd-11e9-8130-be6597f3ae53" satisfied condition "success or failure"
Jan 21 22:38:00.375: INFO: Trying to get logs from node 10.191.28.39 pod var-expansion-338a7092-1dcd-11e9-8130-be6597f3ae53 container dapi-container: <nil>
STEP: delete the pod
Jan 21 22:38:00.435: INFO: Waiting for pod var-expansion-338a7092-1dcd-11e9-8130-be6597f3ae53 to disappear
Jan 21 22:38:00.445: INFO: Pod var-expansion-338a7092-1dcd-11e9-8130-be6597f3ae53 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 22:38:00.445: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-var-expansion-62r4p" for this suite.
Jan 21 22:38:06.489: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 22:38:06.855: INFO: namespace: e2e-tests-var-expansion-62r4p, resource: bindings, ignored listing per whitelist
Jan 21 22:38:06.899: INFO: namespace e2e-tests-var-expansion-62r4p deletion completed in 6.44175797s

• [SLOW TEST:9.132 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 22:38:06.903: INFO: >>> kubeConfig: /tmp/kubeconfig-933165938
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-gc-cv8hr
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the rc
STEP: delete the rc
STEP: wait for all pods to be garbage collected
STEP: Gathering metrics
W0121 22:38:17.365086      15 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Jan 21 22:38:17.365: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 22:38:17.365: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-cv8hr" for this suite.
Jan 21 22:38:23.421: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 22:38:23.787: INFO: namespace: e2e-tests-gc-cv8hr, resource: bindings, ignored listing per whitelist
Jan 21 22:38:23.818: INFO: namespace e2e-tests-gc-cv8hr deletion completed in 6.437737177s

• [SLOW TEST:16.916 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-network] Service endpoints latency 
  should not be very high  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 22:38:23.820: INFO: >>> kubeConfig: /tmp/kubeconfig-933165938
STEP: Building a namespace api object, basename svc-latency
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-svc-latency-6n7rz
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be very high  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating replication controller svc-latency-rc in namespace e2e-tests-svc-latency-6n7rz
I0121 22:38:24.169186      15 runners.go:180] Created replication controller with name: svc-latency-rc, namespace: e2e-tests-svc-latency-6n7rz, replica count: 1
I0121 22:38:25.219906      15 runners.go:180] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0121 22:38:26.220225      15 runners.go:180] svc-latency-rc Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Jan 21 22:38:26.346: INFO: Created: latency-svc-p7qcb
Jan 21 22:38:26.367: INFO: Got endpoints: latency-svc-p7qcb [47.485588ms]
Jan 21 22:38:26.465: INFO: Created: latency-svc-nxcff
Jan 21 22:38:26.465: INFO: Created: latency-svc-8b6rr
Jan 21 22:38:26.465: INFO: Created: latency-svc-gdgpv
Jan 21 22:38:26.465: INFO: Created: latency-svc-7wrvs
Jan 21 22:38:26.465: INFO: Got endpoints: latency-svc-nxcff [97.231796ms]
Jan 21 22:38:26.466: INFO: Got endpoints: latency-svc-gdgpv [96.930606ms]
Jan 21 22:38:26.466: INFO: Got endpoints: latency-svc-8b6rr [97.966118ms]
Jan 21 22:38:26.465: INFO: Got endpoints: latency-svc-7wrvs [96.732395ms]
Jan 21 22:38:26.465: INFO: Created: latency-svc-lrppn
Jan 21 22:38:26.469: INFO: Got endpoints: latency-svc-lrppn [100.613287ms]
Jan 21 22:38:26.487: INFO: Created: latency-svc-79cdx
Jan 21 22:38:26.494: INFO: Got endpoints: latency-svc-79cdx [124.880352ms]
Jan 21 22:38:26.498: INFO: Created: latency-svc-xxpt5
Jan 21 22:38:26.506: INFO: Got endpoints: latency-svc-xxpt5 [136.980354ms]
Jan 21 22:38:26.514: INFO: Created: latency-svc-d88xl
Jan 21 22:38:26.520: INFO: Created: latency-svc-2mckm
Jan 21 22:38:26.520: INFO: Got endpoints: latency-svc-d88xl [151.463089ms]
Jan 21 22:38:26.527: INFO: Got endpoints: latency-svc-2mckm [157.947377ms]
Jan 21 22:38:26.528: INFO: Created: latency-svc-hghdc
Jan 21 22:38:26.536: INFO: Got endpoints: latency-svc-hghdc [166.831893ms]
Jan 21 22:38:26.541: INFO: Created: latency-svc-jxhbh
Jan 21 22:38:26.549: INFO: Got endpoints: latency-svc-jxhbh [180.162742ms]
Jan 21 22:38:26.555: INFO: Created: latency-svc-m9xcx
Jan 21 22:38:26.564: INFO: Got endpoints: latency-svc-m9xcx [194.895196ms]
Jan 21 22:38:26.564: INFO: Created: latency-svc-dxg8j
Jan 21 22:38:26.569: INFO: Got endpoints: latency-svc-dxg8j [200.023749ms]
Jan 21 22:38:26.570: INFO: Created: latency-svc-6cdbh
Jan 21 22:38:26.578: INFO: Got endpoints: latency-svc-6cdbh [209.02854ms]
Jan 21 22:38:26.581: INFO: Created: latency-svc-m4lvv
Jan 21 22:38:26.587: INFO: Got endpoints: latency-svc-m4lvv [217.963655ms]
Jan 21 22:38:26.592: INFO: Created: latency-svc-tpx74
Jan 21 22:38:26.599: INFO: Got endpoints: latency-svc-tpx74 [133.026485ms]
Jan 21 22:38:26.601: INFO: Created: latency-svc-nmrxv
Jan 21 22:38:26.608: INFO: Got endpoints: latency-svc-nmrxv [138.450321ms]
Jan 21 22:38:26.611: INFO: Created: latency-svc-dv7fw
Jan 21 22:38:26.618: INFO: Got endpoints: latency-svc-dv7fw [150.529335ms]
Jan 21 22:38:26.622: INFO: Created: latency-svc-zl86t
Jan 21 22:38:26.629: INFO: Got endpoints: latency-svc-zl86t [29.379802ms]
Jan 21 22:38:26.630: INFO: Created: latency-svc-zsdn4
Jan 21 22:38:26.636: INFO: Got endpoints: latency-svc-zsdn4 [168.855955ms]
Jan 21 22:38:26.639: INFO: Created: latency-svc-2hp2c
Jan 21 22:38:26.644: INFO: Got endpoints: latency-svc-2hp2c [178.882726ms]
Jan 21 22:38:26.650: INFO: Created: latency-svc-l658f
Jan 21 22:38:26.658: INFO: Created: latency-svc-cpl6k
Jan 21 22:38:26.659: INFO: Got endpoints: latency-svc-l658f [164.754776ms]
Jan 21 22:38:26.665: INFO: Got endpoints: latency-svc-cpl6k [158.759741ms]
Jan 21 22:38:26.668: INFO: Created: latency-svc-vsk6b
Jan 21 22:38:26.675: INFO: Got endpoints: latency-svc-vsk6b [154.344961ms]
Jan 21 22:38:26.680: INFO: Created: latency-svc-2sst8
Jan 21 22:38:26.687: INFO: Got endpoints: latency-svc-2sst8 [158.220497ms]
Jan 21 22:38:26.689: INFO: Created: latency-svc-bw7tr
Jan 21 22:38:26.696: INFO: Got endpoints: latency-svc-bw7tr [160.238088ms]
Jan 21 22:38:26.702: INFO: Created: latency-svc-p2cpl
Jan 21 22:38:26.709: INFO: Got endpoints: latency-svc-p2cpl [159.868519ms]
Jan 21 22:38:26.716: INFO: Created: latency-svc-b5tzx
Jan 21 22:38:26.722: INFO: Got endpoints: latency-svc-b5tzx [157.79673ms]
Jan 21 22:38:26.724: INFO: Created: latency-svc-2725d
Jan 21 22:38:26.732: INFO: Got endpoints: latency-svc-2725d [162.221591ms]
Jan 21 22:38:26.735: INFO: Created: latency-svc-qgcq8
Jan 21 22:38:26.740: INFO: Got endpoints: latency-svc-qgcq8 [161.757525ms]
Jan 21 22:38:26.746: INFO: Created: latency-svc-xm868
Jan 21 22:38:26.752: INFO: Got endpoints: latency-svc-xm868 [164.296009ms]
Jan 21 22:38:26.756: INFO: Created: latency-svc-p5l4v
Jan 21 22:38:26.763: INFO: Got endpoints: latency-svc-p5l4v [154.82386ms]
Jan 21 22:38:26.765: INFO: Created: latency-svc-vwk54
Jan 21 22:38:26.772: INFO: Got endpoints: latency-svc-vwk54 [153.554437ms]
Jan 21 22:38:26.776: INFO: Created: latency-svc-fp4wl
Jan 21 22:38:26.782: INFO: Got endpoints: latency-svc-fp4wl [153.486706ms]
Jan 21 22:38:26.784: INFO: Created: latency-svc-4wrtk
Jan 21 22:38:26.790: INFO: Got endpoints: latency-svc-4wrtk [154.115495ms]
Jan 21 22:38:26.795: INFO: Created: latency-svc-fk99r
Jan 21 22:38:26.802: INFO: Got endpoints: latency-svc-fk99r [157.015343ms]
Jan 21 22:38:26.805: INFO: Created: latency-svc-xq8zf
Jan 21 22:38:26.813: INFO: Got endpoints: latency-svc-xq8zf [153.997622ms]
Jan 21 22:38:26.817: INFO: Created: latency-svc-tz789
Jan 21 22:38:26.822: INFO: Got endpoints: latency-svc-tz789 [157.628707ms]
Jan 21 22:38:26.828: INFO: Created: latency-svc-k4ppt
Jan 21 22:38:26.840: INFO: Created: latency-svc-55nz7
Jan 21 22:38:26.850: INFO: Created: latency-svc-2qshp
Jan 21 22:38:26.851: INFO: Got endpoints: latency-svc-k4ppt [175.692704ms]
Jan 21 22:38:26.860: INFO: Created: latency-svc-jb7kn
Jan 21 22:38:26.875: INFO: Created: latency-svc-9tvtn
Jan 21 22:38:26.889: INFO: Created: latency-svc-km728
Jan 21 22:38:26.899: INFO: Created: latency-svc-7chnt
Jan 21 22:38:26.902: INFO: Got endpoints: latency-svc-55nz7 [215.025128ms]
Jan 21 22:38:26.909: INFO: Created: latency-svc-rlqkv
Jan 21 22:38:26.921: INFO: Created: latency-svc-7rvtv
Jan 21 22:38:26.928: INFO: Created: latency-svc-jvncx
Jan 21 22:38:26.939: INFO: Created: latency-svc-6zsdv
Jan 21 22:38:26.947: INFO: Created: latency-svc-t8mnh
Jan 21 22:38:26.951: INFO: Got endpoints: latency-svc-2qshp [254.778891ms]
Jan 21 22:38:26.960: INFO: Created: latency-svc-dtjr9
Jan 21 22:38:26.969: INFO: Created: latency-svc-ms5sl
Jan 21 22:38:26.977: INFO: Created: latency-svc-lmn4x
Jan 21 22:38:26.987: INFO: Created: latency-svc-8wch4
Jan 21 22:38:26.997: INFO: Created: latency-svc-74j88
Jan 21 22:38:27.001: INFO: Got endpoints: latency-svc-jb7kn [291.818132ms]
Jan 21 22:38:27.008: INFO: Created: latency-svc-vbwsr
Jan 21 22:38:27.024: INFO: Created: latency-svc-mv6kc
Jan 21 22:38:27.052: INFO: Got endpoints: latency-svc-9tvtn [330.442572ms]
Jan 21 22:38:27.075: INFO: Created: latency-svc-ktntm
Jan 21 22:38:27.103: INFO: Got endpoints: latency-svc-km728 [370.745592ms]
Jan 21 22:38:27.128: INFO: Created: latency-svc-62zh8
Jan 21 22:38:27.153: INFO: Got endpoints: latency-svc-7chnt [412.278366ms]
Jan 21 22:38:27.176: INFO: Created: latency-svc-2tjtz
Jan 21 22:38:27.202: INFO: Got endpoints: latency-svc-rlqkv [450.29764ms]
Jan 21 22:38:27.224: INFO: Created: latency-svc-v6trl
Jan 21 22:38:27.253: INFO: Got endpoints: latency-svc-7rvtv [489.631301ms]
Jan 21 22:38:27.277: INFO: Created: latency-svc-ftnkn
Jan 21 22:38:27.302: INFO: Got endpoints: latency-svc-jvncx [529.887786ms]
Jan 21 22:38:27.326: INFO: Created: latency-svc-8j5tz
Jan 21 22:38:27.352: INFO: Got endpoints: latency-svc-6zsdv [569.437461ms]
Jan 21 22:38:27.374: INFO: Created: latency-svc-fsj4q
Jan 21 22:38:27.402: INFO: Got endpoints: latency-svc-t8mnh [611.59841ms]
Jan 21 22:38:27.428: INFO: Created: latency-svc-rp9wm
Jan 21 22:38:27.454: INFO: Got endpoints: latency-svc-dtjr9 [652.203746ms]
Jan 21 22:38:27.480: INFO: Created: latency-svc-6dlht
Jan 21 22:38:27.503: INFO: Got endpoints: latency-svc-ms5sl [690.437011ms]
Jan 21 22:38:27.539: INFO: Created: latency-svc-xvslk
Jan 21 22:38:27.552: INFO: Got endpoints: latency-svc-lmn4x [728.975756ms]
Jan 21 22:38:27.585: INFO: Created: latency-svc-66m25
Jan 21 22:38:27.604: INFO: Got endpoints: latency-svc-8wch4 [752.812276ms]
Jan 21 22:38:27.627: INFO: Created: latency-svc-6t95x
Jan 21 22:38:27.652: INFO: Got endpoints: latency-svc-74j88 [749.939969ms]
Jan 21 22:38:27.675: INFO: Created: latency-svc-vrl8q
Jan 21 22:38:27.703: INFO: Got endpoints: latency-svc-vbwsr [751.158742ms]
Jan 21 22:38:27.726: INFO: Created: latency-svc-vq4sw
Jan 21 22:38:27.753: INFO: Got endpoints: latency-svc-mv6kc [751.357061ms]
Jan 21 22:38:27.776: INFO: Created: latency-svc-vgpdv
Jan 21 22:38:27.803: INFO: Got endpoints: latency-svc-ktntm [750.249726ms]
Jan 21 22:38:27.827: INFO: Created: latency-svc-pdqql
Jan 21 22:38:27.851: INFO: Got endpoints: latency-svc-62zh8 [747.593399ms]
Jan 21 22:38:27.874: INFO: Created: latency-svc-8lqng
Jan 21 22:38:27.902: INFO: Got endpoints: latency-svc-2tjtz [748.830184ms]
Jan 21 22:38:27.924: INFO: Created: latency-svc-j7mc2
Jan 21 22:38:27.953: INFO: Got endpoints: latency-svc-v6trl [750.214082ms]
Jan 21 22:38:27.976: INFO: Created: latency-svc-lksqt
Jan 21 22:38:28.001: INFO: Got endpoints: latency-svc-ftnkn [748.521693ms]
Jan 21 22:38:28.024: INFO: Created: latency-svc-plstz
Jan 21 22:38:28.052: INFO: Got endpoints: latency-svc-8j5tz [749.411896ms]
Jan 21 22:38:28.074: INFO: Created: latency-svc-929ww
Jan 21 22:38:28.103: INFO: Got endpoints: latency-svc-fsj4q [751.109768ms]
Jan 21 22:38:28.126: INFO: Created: latency-svc-xwm4c
Jan 21 22:38:28.155: INFO: Got endpoints: latency-svc-rp9wm [752.158818ms]
Jan 21 22:38:28.177: INFO: Created: latency-svc-xsdb5
Jan 21 22:38:28.203: INFO: Got endpoints: latency-svc-6dlht [748.621702ms]
Jan 21 22:38:28.225: INFO: Created: latency-svc-ffxlz
Jan 21 22:38:28.253: INFO: Got endpoints: latency-svc-xvslk [749.428812ms]
Jan 21 22:38:28.276: INFO: Created: latency-svc-gszqh
Jan 21 22:38:28.302: INFO: Got endpoints: latency-svc-66m25 [749.793788ms]
Jan 21 22:38:28.325: INFO: Created: latency-svc-xbn8r
Jan 21 22:38:28.353: INFO: Got endpoints: latency-svc-6t95x [748.822523ms]
Jan 21 22:38:28.374: INFO: Created: latency-svc-vns4m
Jan 21 22:38:28.401: INFO: Got endpoints: latency-svc-vrl8q [749.406861ms]
Jan 21 22:38:28.422: INFO: Created: latency-svc-twtw5
Jan 21 22:38:28.452: INFO: Got endpoints: latency-svc-vq4sw [749.304835ms]
Jan 21 22:38:28.478: INFO: Created: latency-svc-pvdls
Jan 21 22:38:28.506: INFO: Got endpoints: latency-svc-vgpdv [752.718764ms]
Jan 21 22:38:28.527: INFO: Created: latency-svc-bgpbq
Jan 21 22:38:28.553: INFO: Got endpoints: latency-svc-pdqql [750.111804ms]
Jan 21 22:38:28.578: INFO: Created: latency-svc-79f9c
Jan 21 22:38:28.602: INFO: Got endpoints: latency-svc-8lqng [750.884175ms]
Jan 21 22:38:28.624: INFO: Created: latency-svc-tkxnk
Jan 21 22:38:28.652: INFO: Got endpoints: latency-svc-j7mc2 [750.375769ms]
Jan 21 22:38:28.675: INFO: Created: latency-svc-4l55b
Jan 21 22:38:28.703: INFO: Got endpoints: latency-svc-lksqt [750.335377ms]
Jan 21 22:38:28.724: INFO: Created: latency-svc-fv22w
Jan 21 22:38:28.752: INFO: Got endpoints: latency-svc-plstz [749.837068ms]
Jan 21 22:38:28.773: INFO: Created: latency-svc-q9k8x
Jan 21 22:38:28.802: INFO: Got endpoints: latency-svc-929ww [749.866897ms]
Jan 21 22:38:28.824: INFO: Created: latency-svc-vsllq
Jan 21 22:38:28.852: INFO: Got endpoints: latency-svc-xwm4c [749.252708ms]
Jan 21 22:38:28.876: INFO: Created: latency-svc-j22zt
Jan 21 22:38:28.902: INFO: Got endpoints: latency-svc-xsdb5 [747.304945ms]
Jan 21 22:38:28.925: INFO: Created: latency-svc-hcsm9
Jan 21 22:38:28.953: INFO: Got endpoints: latency-svc-ffxlz [750.454418ms]
Jan 21 22:38:28.976: INFO: Created: latency-svc-mpzzt
Jan 21 22:38:29.002: INFO: Got endpoints: latency-svc-gszqh [749.120103ms]
Jan 21 22:38:29.025: INFO: Created: latency-svc-7cdbq
Jan 21 22:38:29.054: INFO: Got endpoints: latency-svc-xbn8r [752.218313ms]
Jan 21 22:38:29.080: INFO: Created: latency-svc-9m9c6
Jan 21 22:38:29.105: INFO: Got endpoints: latency-svc-vns4m [752.280826ms]
Jan 21 22:38:29.138: INFO: Created: latency-svc-5x5nd
Jan 21 22:38:29.152: INFO: Got endpoints: latency-svc-twtw5 [750.368407ms]
Jan 21 22:38:29.175: INFO: Created: latency-svc-6ccqw
Jan 21 22:38:29.202: INFO: Got endpoints: latency-svc-pvdls [749.508438ms]
Jan 21 22:38:29.225: INFO: Created: latency-svc-tgr2z
Jan 21 22:38:29.252: INFO: Got endpoints: latency-svc-bgpbq [746.278853ms]
Jan 21 22:38:29.275: INFO: Created: latency-svc-hhcw9
Jan 21 22:38:29.303: INFO: Got endpoints: latency-svc-79f9c [749.218917ms]
Jan 21 22:38:29.328: INFO: Created: latency-svc-hlwr6
Jan 21 22:38:29.352: INFO: Got endpoints: latency-svc-tkxnk [749.775447ms]
Jan 21 22:38:29.378: INFO: Created: latency-svc-7x5qf
Jan 21 22:38:29.404: INFO: Got endpoints: latency-svc-4l55b [751.41897ms]
Jan 21 22:38:29.427: INFO: Created: latency-svc-pfbcs
Jan 21 22:38:29.452: INFO: Got endpoints: latency-svc-fv22w [748.650715ms]
Jan 21 22:38:29.476: INFO: Created: latency-svc-n9t6s
Jan 21 22:38:29.502: INFO: Got endpoints: latency-svc-q9k8x [750.374687ms]
Jan 21 22:38:29.764: INFO: Created: latency-svc-d5gjv
Jan 21 22:38:29.765: INFO: Got endpoints: latency-svc-7cdbq [762.498423ms]
Jan 21 22:38:29.765: INFO: Got endpoints: latency-svc-hcsm9 [862.444225ms]
Jan 21 22:38:29.766: INFO: Got endpoints: latency-svc-vsllq [963.88842ms]
Jan 21 22:38:29.766: INFO: Got endpoints: latency-svc-j22zt [913.479991ms]
Jan 21 22:38:29.766: INFO: Got endpoints: latency-svc-mpzzt [812.845897ms]
Jan 21 22:38:29.789: INFO: Created: latency-svc-rqclj
Jan 21 22:38:29.799: INFO: Created: latency-svc-rfcrs
Jan 21 22:38:29.801: INFO: Got endpoints: latency-svc-9m9c6 [746.481189ms]
Jan 21 22:38:29.807: INFO: Created: latency-svc-w54dn
Jan 21 22:38:29.824: INFO: Created: latency-svc-zb26x
Jan 21 22:38:29.828: INFO: Created: latency-svc-t5w4k
Jan 21 22:38:29.836: INFO: Created: latency-svc-px8kl
Jan 21 22:38:29.852: INFO: Got endpoints: latency-svc-5x5nd [746.692435ms]
Jan 21 22:38:29.872: INFO: Created: latency-svc-5zbf2
Jan 21 22:38:29.902: INFO: Got endpoints: latency-svc-6ccqw [749.11837ms]
Jan 21 22:38:29.923: INFO: Created: latency-svc-dbkg6
Jan 21 22:38:29.953: INFO: Got endpoints: latency-svc-tgr2z [750.827905ms]
Jan 21 22:38:29.976: INFO: Created: latency-svc-88hsm
Jan 21 22:38:30.002: INFO: Got endpoints: latency-svc-hhcw9 [749.690633ms]
Jan 21 22:38:30.023: INFO: Created: latency-svc-d9hg2
Jan 21 22:38:30.053: INFO: Got endpoints: latency-svc-hlwr6 [749.975986ms]
Jan 21 22:38:30.076: INFO: Created: latency-svc-66vb5
Jan 21 22:38:30.102: INFO: Got endpoints: latency-svc-7x5qf [750.013571ms]
Jan 21 22:38:30.124: INFO: Created: latency-svc-v9l2n
Jan 21 22:38:30.152: INFO: Got endpoints: latency-svc-pfbcs [747.569921ms]
Jan 21 22:38:30.177: INFO: Created: latency-svc-k5g4p
Jan 21 22:38:30.201: INFO: Got endpoints: latency-svc-n9t6s [748.523366ms]
Jan 21 22:38:30.222: INFO: Created: latency-svc-csk4j
Jan 21 22:38:30.258: INFO: Got endpoints: latency-svc-d5gjv [755.29314ms]
Jan 21 22:38:30.283: INFO: Created: latency-svc-22ln6
Jan 21 22:38:30.303: INFO: Got endpoints: latency-svc-rqclj [537.864918ms]
Jan 21 22:38:30.327: INFO: Created: latency-svc-qhfxr
Jan 21 22:38:30.352: INFO: Got endpoints: latency-svc-rfcrs [586.677992ms]
Jan 21 22:38:30.378: INFO: Created: latency-svc-cxvzx
Jan 21 22:38:30.402: INFO: Got endpoints: latency-svc-w54dn [636.31796ms]
Jan 21 22:38:30.425: INFO: Created: latency-svc-wx2s9
Jan 21 22:38:30.452: INFO: Got endpoints: latency-svc-zb26x [686.721683ms]
Jan 21 22:38:30.478: INFO: Created: latency-svc-hw4vf
Jan 21 22:38:30.502: INFO: Got endpoints: latency-svc-t5w4k [735.742922ms]
Jan 21 22:38:30.526: INFO: Created: latency-svc-w5qgn
Jan 21 22:38:30.551: INFO: Got endpoints: latency-svc-px8kl [750.085115ms]
Jan 21 22:38:30.576: INFO: Created: latency-svc-7b8wk
Jan 21 22:38:30.603: INFO: Got endpoints: latency-svc-5zbf2 [751.07904ms]
Jan 21 22:38:30.641: INFO: Created: latency-svc-bcb5x
Jan 21 22:38:30.654: INFO: Got endpoints: latency-svc-dbkg6 [751.725352ms]
Jan 21 22:38:30.687: INFO: Created: latency-svc-gfcrc
Jan 21 22:38:30.702: INFO: Got endpoints: latency-svc-88hsm [749.088822ms]
Jan 21 22:38:30.726: INFO: Created: latency-svc-mhzpr
Jan 21 22:38:30.754: INFO: Got endpoints: latency-svc-d9hg2 [751.543833ms]
Jan 21 22:38:30.779: INFO: Created: latency-svc-bvrh7
Jan 21 22:38:30.803: INFO: Got endpoints: latency-svc-66vb5 [749.287306ms]
Jan 21 22:38:30.825: INFO: Created: latency-svc-mrlmb
Jan 21 22:38:30.856: INFO: Got endpoints: latency-svc-v9l2n [753.923347ms]
Jan 21 22:38:30.880: INFO: Created: latency-svc-686qd
Jan 21 22:38:30.902: INFO: Got endpoints: latency-svc-k5g4p [750.275441ms]
Jan 21 22:38:30.926: INFO: Created: latency-svc-xmlcz
Jan 21 22:38:30.952: INFO: Got endpoints: latency-svc-csk4j [751.166445ms]
Jan 21 22:38:30.976: INFO: Created: latency-svc-4p9zw
Jan 21 22:38:31.005: INFO: Got endpoints: latency-svc-22ln6 [747.186121ms]
Jan 21 22:38:31.030: INFO: Created: latency-svc-nmv6m
Jan 21 22:38:31.051: INFO: Got endpoints: latency-svc-qhfxr [748.042089ms]
Jan 21 22:38:31.076: INFO: Created: latency-svc-9rprs
Jan 21 22:38:31.103: INFO: Got endpoints: latency-svc-cxvzx [750.640519ms]
Jan 21 22:38:31.126: INFO: Created: latency-svc-tv7wd
Jan 21 22:38:31.152: INFO: Got endpoints: latency-svc-wx2s9 [748.894152ms]
Jan 21 22:38:31.174: INFO: Created: latency-svc-k9mvs
Jan 21 22:38:31.202: INFO: Got endpoints: latency-svc-hw4vf [750.051672ms]
Jan 21 22:38:31.225: INFO: Created: latency-svc-wctvm
Jan 21 22:38:31.254: INFO: Got endpoints: latency-svc-w5qgn [751.751139ms]
Jan 21 22:38:31.279: INFO: Created: latency-svc-wl46j
Jan 21 22:38:31.302: INFO: Got endpoints: latency-svc-7b8wk [750.038838ms]
Jan 21 22:38:31.325: INFO: Created: latency-svc-7wxmc
Jan 21 22:38:31.364: INFO: Got endpoints: latency-svc-bcb5x [760.911926ms]
Jan 21 22:38:31.395: INFO: Created: latency-svc-4jtn2
Jan 21 22:38:31.403: INFO: Got endpoints: latency-svc-gfcrc [749.333277ms]
Jan 21 22:38:31.428: INFO: Created: latency-svc-kw6m5
Jan 21 22:38:31.452: INFO: Got endpoints: latency-svc-mhzpr [749.735001ms]
Jan 21 22:38:31.479: INFO: Created: latency-svc-t7vtv
Jan 21 22:38:31.502: INFO: Got endpoints: latency-svc-bvrh7 [747.945465ms]
Jan 21 22:38:31.526: INFO: Created: latency-svc-kmkv6
Jan 21 22:38:31.553: INFO: Got endpoints: latency-svc-mrlmb [750.560799ms]
Jan 21 22:38:31.577: INFO: Created: latency-svc-ljksf
Jan 21 22:38:31.602: INFO: Got endpoints: latency-svc-686qd [745.950323ms]
Jan 21 22:38:31.626: INFO: Created: latency-svc-pb7rx
Jan 21 22:38:31.652: INFO: Got endpoints: latency-svc-xmlcz [749.39735ms]
Jan 21 22:38:31.673: INFO: Created: latency-svc-zwgw4
Jan 21 22:38:31.701: INFO: Got endpoints: latency-svc-4p9zw [748.319713ms]
Jan 21 22:38:31.723: INFO: Created: latency-svc-w5d9q
Jan 21 22:38:31.753: INFO: Got endpoints: latency-svc-nmv6m [747.920001ms]
Jan 21 22:38:31.784: INFO: Created: latency-svc-m2zp7
Jan 21 22:38:31.805: INFO: Got endpoints: latency-svc-9rprs [753.503055ms]
Jan 21 22:38:31.835: INFO: Created: latency-svc-hq4wz
Jan 21 22:38:31.852: INFO: Got endpoints: latency-svc-tv7wd [748.66381ms]
Jan 21 22:38:31.879: INFO: Created: latency-svc-wvqjf
Jan 21 22:38:31.902: INFO: Got endpoints: latency-svc-k9mvs [749.822302ms]
Jan 21 22:38:31.924: INFO: Created: latency-svc-7cf24
Jan 21 22:38:31.952: INFO: Got endpoints: latency-svc-wctvm [749.299579ms]
Jan 21 22:38:31.978: INFO: Created: latency-svc-ccgd9
Jan 21 22:38:32.010: INFO: Got endpoints: latency-svc-wl46j [754.937635ms]
Jan 21 22:38:32.032: INFO: Created: latency-svc-z5r8z
Jan 21 22:38:32.053: INFO: Got endpoints: latency-svc-7wxmc [750.879378ms]
Jan 21 22:38:32.075: INFO: Created: latency-svc-hjhcw
Jan 21 22:38:32.103: INFO: Got endpoints: latency-svc-4jtn2 [738.137161ms]
Jan 21 22:38:32.131: INFO: Created: latency-svc-b7r9p
Jan 21 22:38:32.152: INFO: Got endpoints: latency-svc-kw6m5 [748.128038ms]
Jan 21 22:38:32.178: INFO: Created: latency-svc-dm9fk
Jan 21 22:38:32.201: INFO: Got endpoints: latency-svc-t7vtv [748.362342ms]
Jan 21 22:38:32.222: INFO: Created: latency-svc-msxhs
Jan 21 22:38:32.252: INFO: Got endpoints: latency-svc-kmkv6 [749.549415ms]
Jan 21 22:38:32.274: INFO: Created: latency-svc-qwg72
Jan 21 22:38:32.302: INFO: Got endpoints: latency-svc-ljksf [748.266659ms]
Jan 21 22:38:32.326: INFO: Created: latency-svc-mkpvm
Jan 21 22:38:32.352: INFO: Got endpoints: latency-svc-pb7rx [749.676352ms]
Jan 21 22:38:32.376: INFO: Created: latency-svc-zt642
Jan 21 22:38:32.403: INFO: Got endpoints: latency-svc-zwgw4 [750.973621ms]
Jan 21 22:38:32.428: INFO: Created: latency-svc-49kd8
Jan 21 22:38:32.452: INFO: Got endpoints: latency-svc-w5d9q [751.240972ms]
Jan 21 22:38:32.475: INFO: Created: latency-svc-2wp25
Jan 21 22:38:32.502: INFO: Got endpoints: latency-svc-m2zp7 [748.595175ms]
Jan 21 22:38:32.528: INFO: Created: latency-svc-fdwsn
Jan 21 22:38:32.552: INFO: Got endpoints: latency-svc-hq4wz [746.96327ms]
Jan 21 22:38:32.580: INFO: Created: latency-svc-ggfcw
Jan 21 22:38:32.603: INFO: Got endpoints: latency-svc-wvqjf [749.351792ms]
Jan 21 22:38:32.627: INFO: Created: latency-svc-kwgzr
Jan 21 22:38:32.652: INFO: Got endpoints: latency-svc-7cf24 [750.408965ms]
Jan 21 22:38:32.674: INFO: Created: latency-svc-qwv22
Jan 21 22:38:32.702: INFO: Got endpoints: latency-svc-ccgd9 [749.942225ms]
Jan 21 22:38:32.724: INFO: Created: latency-svc-bdbvg
Jan 21 22:38:32.754: INFO: Got endpoints: latency-svc-z5r8z [743.915176ms]
Jan 21 22:38:32.776: INFO: Created: latency-svc-68rz9
Jan 21 22:38:32.802: INFO: Got endpoints: latency-svc-hjhcw [749.303449ms]
Jan 21 22:38:32.826: INFO: Created: latency-svc-hhb6w
Jan 21 22:38:32.854: INFO: Got endpoints: latency-svc-b7r9p [751.046087ms]
Jan 21 22:38:32.876: INFO: Created: latency-svc-p9lkp
Jan 21 22:38:32.902: INFO: Got endpoints: latency-svc-dm9fk [749.889623ms]
Jan 21 22:38:32.925: INFO: Created: latency-svc-4ldmc
Jan 21 22:38:32.952: INFO: Got endpoints: latency-svc-msxhs [750.740674ms]
Jan 21 22:38:32.978: INFO: Created: latency-svc-pf7rr
Jan 21 22:38:33.002: INFO: Got endpoints: latency-svc-qwg72 [749.488282ms]
Jan 21 22:38:33.034: INFO: Created: latency-svc-cp4r7
Jan 21 22:38:33.052: INFO: Got endpoints: latency-svc-mkpvm [750.157151ms]
Jan 21 22:38:33.075: INFO: Created: latency-svc-4pbff
Jan 21 22:38:33.102: INFO: Got endpoints: latency-svc-zt642 [749.558457ms]
Jan 21 22:38:33.127: INFO: Created: latency-svc-g8m9p
Jan 21 22:38:33.153: INFO: Got endpoints: latency-svc-49kd8 [749.12031ms]
Jan 21 22:38:33.178: INFO: Created: latency-svc-xwdtt
Jan 21 22:38:33.202: INFO: Got endpoints: latency-svc-2wp25 [750.175736ms]
Jan 21 22:38:33.225: INFO: Created: latency-svc-qrt7h
Jan 21 22:38:33.254: INFO: Got endpoints: latency-svc-fdwsn [751.585464ms]
Jan 21 22:38:33.278: INFO: Created: latency-svc-m2khw
Jan 21 22:38:33.302: INFO: Got endpoints: latency-svc-ggfcw [749.910373ms]
Jan 21 22:38:33.326: INFO: Created: latency-svc-sv8bv
Jan 21 22:38:33.352: INFO: Got endpoints: latency-svc-kwgzr [749.262274ms]
Jan 21 22:38:33.394: INFO: Created: latency-svc-hcggd
Jan 21 22:38:33.404: INFO: Got endpoints: latency-svc-qwv22 [752.197543ms]
Jan 21 22:38:33.428: INFO: Created: latency-svc-vplv2
Jan 21 22:38:33.452: INFO: Got endpoints: latency-svc-bdbvg [749.271778ms]
Jan 21 22:38:33.477: INFO: Created: latency-svc-zp69f
Jan 21 22:38:33.503: INFO: Got endpoints: latency-svc-68rz9 [749.611835ms]
Jan 21 22:38:33.529: INFO: Created: latency-svc-sbkp5
Jan 21 22:38:33.551: INFO: Got endpoints: latency-svc-hhb6w [748.652236ms]
Jan 21 22:38:33.576: INFO: Created: latency-svc-7kznx
Jan 21 22:38:33.603: INFO: Got endpoints: latency-svc-p9lkp [749.307247ms]
Jan 21 22:38:33.624: INFO: Created: latency-svc-h2q8x
Jan 21 22:38:33.652: INFO: Got endpoints: latency-svc-4ldmc [750.152919ms]
Jan 21 22:38:33.677: INFO: Created: latency-svc-7jg58
Jan 21 22:38:33.702: INFO: Got endpoints: latency-svc-pf7rr [749.750665ms]
Jan 21 22:38:33.725: INFO: Created: latency-svc-gt227
Jan 21 22:38:33.752: INFO: Got endpoints: latency-svc-cp4r7 [750.177077ms]
Jan 21 22:38:33.777: INFO: Created: latency-svc-v6wwr
Jan 21 22:38:33.802: INFO: Got endpoints: latency-svc-4pbff [749.765227ms]
Jan 21 22:38:33.826: INFO: Created: latency-svc-6m8nj
Jan 21 22:38:33.852: INFO: Got endpoints: latency-svc-g8m9p [750.015591ms]
Jan 21 22:38:33.875: INFO: Created: latency-svc-b5rfk
Jan 21 22:38:33.902: INFO: Got endpoints: latency-svc-xwdtt [748.463399ms]
Jan 21 22:38:33.923: INFO: Created: latency-svc-nz6sh
Jan 21 22:38:33.952: INFO: Got endpoints: latency-svc-qrt7h [748.536305ms]
Jan 21 22:38:33.976: INFO: Created: latency-svc-tlnzm
Jan 21 22:38:34.001: INFO: Got endpoints: latency-svc-m2khw [746.781496ms]
Jan 21 22:38:34.022: INFO: Created: latency-svc-rz4hs
Jan 21 22:38:34.053: INFO: Got endpoints: latency-svc-sv8bv [750.508689ms]
Jan 21 22:38:34.082: INFO: Created: latency-svc-gvwxv
Jan 21 22:38:34.104: INFO: Got endpoints: latency-svc-hcggd [752.280906ms]
Jan 21 22:38:34.134: INFO: Created: latency-svc-58t29
Jan 21 22:38:34.154: INFO: Got endpoints: latency-svc-vplv2 [749.228214ms]
Jan 21 22:38:34.176: INFO: Created: latency-svc-xfkbb
Jan 21 22:38:34.202: INFO: Got endpoints: latency-svc-zp69f [749.797453ms]
Jan 21 22:38:34.253: INFO: Got endpoints: latency-svc-sbkp5 [749.301895ms]
Jan 21 22:38:34.302: INFO: Got endpoints: latency-svc-7kznx [751.242275ms]
Jan 21 22:38:34.352: INFO: Got endpoints: latency-svc-h2q8x [748.41294ms]
Jan 21 22:38:34.401: INFO: Got endpoints: latency-svc-7jg58 [749.523396ms]
Jan 21 22:38:34.451: INFO: Got endpoints: latency-svc-gt227 [749.301733ms]
Jan 21 22:38:34.502: INFO: Got endpoints: latency-svc-v6wwr [749.388861ms]
Jan 21 22:38:34.565: INFO: Got endpoints: latency-svc-6m8nj [762.198985ms]
Jan 21 22:38:34.603: INFO: Got endpoints: latency-svc-b5rfk [750.400084ms]
Jan 21 22:38:34.652: INFO: Got endpoints: latency-svc-nz6sh [750.515037ms]
Jan 21 22:38:34.702: INFO: Got endpoints: latency-svc-tlnzm [749.522732ms]
Jan 21 22:38:34.752: INFO: Got endpoints: latency-svc-rz4hs [750.388917ms]
Jan 21 22:38:34.802: INFO: Got endpoints: latency-svc-gvwxv [748.728663ms]
Jan 21 22:38:34.853: INFO: Got endpoints: latency-svc-58t29 [748.592483ms]
Jan 21 22:38:34.902: INFO: Got endpoints: latency-svc-xfkbb [747.599115ms]
Jan 21 22:38:34.902: INFO: Latencies: [29.379802ms 96.732395ms 96.930606ms 97.231796ms 97.966118ms 100.613287ms 124.880352ms 133.026485ms 136.980354ms 138.450321ms 150.529335ms 151.463089ms 153.486706ms 153.554437ms 153.997622ms 154.115495ms 154.344961ms 154.82386ms 157.015343ms 157.628707ms 157.79673ms 157.947377ms 158.220497ms 158.759741ms 159.868519ms 160.238088ms 161.757525ms 162.221591ms 164.296009ms 164.754776ms 166.831893ms 168.855955ms 175.692704ms 178.882726ms 180.162742ms 194.895196ms 200.023749ms 209.02854ms 215.025128ms 217.963655ms 254.778891ms 291.818132ms 330.442572ms 370.745592ms 412.278366ms 450.29764ms 489.631301ms 529.887786ms 537.864918ms 569.437461ms 586.677992ms 611.59841ms 636.31796ms 652.203746ms 686.721683ms 690.437011ms 728.975756ms 735.742922ms 738.137161ms 743.915176ms 745.950323ms 746.278853ms 746.481189ms 746.692435ms 746.781496ms 746.96327ms 747.186121ms 747.304945ms 747.569921ms 747.593399ms 747.599115ms 747.920001ms 747.945465ms 748.042089ms 748.128038ms 748.266659ms 748.319713ms 748.362342ms 748.41294ms 748.463399ms 748.521693ms 748.523366ms 748.536305ms 748.592483ms 748.595175ms 748.621702ms 748.650715ms 748.652236ms 748.66381ms 748.728663ms 748.822523ms 748.830184ms 748.894152ms 749.088822ms 749.11837ms 749.120103ms 749.12031ms 749.218917ms 749.228214ms 749.252708ms 749.262274ms 749.271778ms 749.287306ms 749.299579ms 749.301733ms 749.301895ms 749.303449ms 749.304835ms 749.307247ms 749.333277ms 749.351792ms 749.388861ms 749.39735ms 749.406861ms 749.411896ms 749.428812ms 749.488282ms 749.508438ms 749.522732ms 749.523396ms 749.549415ms 749.558457ms 749.611835ms 749.676352ms 749.690633ms 749.735001ms 749.750665ms 749.765227ms 749.775447ms 749.793788ms 749.797453ms 749.822302ms 749.837068ms 749.866897ms 749.889623ms 749.910373ms 749.939969ms 749.942225ms 749.975986ms 750.013571ms 750.015591ms 750.038838ms 750.051672ms 750.085115ms 750.111804ms 750.152919ms 750.157151ms 750.175736ms 750.177077ms 750.214082ms 750.249726ms 750.275441ms 750.335377ms 750.368407ms 750.374687ms 750.375769ms 750.388917ms 750.400084ms 750.408965ms 750.454418ms 750.508689ms 750.515037ms 750.560799ms 750.640519ms 750.740674ms 750.827905ms 750.879378ms 750.884175ms 750.973621ms 751.046087ms 751.07904ms 751.109768ms 751.158742ms 751.166445ms 751.240972ms 751.242275ms 751.357061ms 751.41897ms 751.543833ms 751.585464ms 751.725352ms 751.751139ms 752.158818ms 752.197543ms 752.218313ms 752.280826ms 752.280906ms 752.718764ms 752.812276ms 753.503055ms 753.923347ms 754.937635ms 755.29314ms 760.911926ms 762.198985ms 762.498423ms 812.845897ms 862.444225ms 913.479991ms 963.88842ms]
Jan 21 22:38:34.902: INFO: 50 %ile: 749.262274ms
Jan 21 22:38:34.902: INFO: 90 %ile: 751.725352ms
Jan 21 22:38:34.902: INFO: 99 %ile: 913.479991ms
Jan 21 22:38:34.902: INFO: Total sample count: 200
[AfterEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 22:38:34.902: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-svc-latency-6n7rz" for this suite.
Jan 21 22:39:01.001: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 22:39:01.503: INFO: namespace: e2e-tests-svc-latency-6n7rz, resource: bindings, ignored listing per whitelist
Jan 21 22:39:01.521: INFO: namespace e2e-tests-svc-latency-6n7rz deletion completed in 26.556647444s

• [SLOW TEST:37.701 seconds]
[sig-network] Service endpoints latency
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should not be very high  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl rolling-update 
  should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 22:39:01.522: INFO: >>> kubeConfig: /tmp/kubeconfig-933165938
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-j7cfr
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1306
[It] should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Jan 21 22:39:01.861: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-933165938 run e2e-test-nginx-rc --image=docker.io/library/nginx:1.14-alpine --generator=run/v1 --namespace=e2e-tests-kubectl-j7cfr'
Jan 21 22:39:02.094: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl create instead.\n"
Jan 21 22:39:02.094: INFO: stdout: "replicationcontroller/e2e-test-nginx-rc created\n"
STEP: verifying the rc e2e-test-nginx-rc was created
Jan 21 22:39:02.107: INFO: Waiting for rc e2e-test-nginx-rc to stabilize, generation 1 observed generation 1 spec.replicas 1 status.replicas 0
STEP: rolling-update to same image controller
Jan 21 22:39:02.118: INFO: scanned /root for discovery docs: <nil>
Jan 21 22:39:02.118: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-933165938 rolling-update e2e-test-nginx-rc --update-period=1s --image=docker.io/library/nginx:1.14-alpine --image-pull-policy=IfNotPresent --namespace=e2e-tests-kubectl-j7cfr'
Jan 21 22:39:18.267: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Jan 21 22:39:18.267: INFO: stdout: "Created e2e-test-nginx-rc-fe44e4833223217440f0579ebaba8a0c\nScaling up e2e-test-nginx-rc-fe44e4833223217440f0579ebaba8a0c from 0 to 1, scaling down e2e-test-nginx-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-nginx-rc-fe44e4833223217440f0579ebaba8a0c up to 1\nScaling e2e-test-nginx-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-nginx-rc\nRenaming e2e-test-nginx-rc-fe44e4833223217440f0579ebaba8a0c to e2e-test-nginx-rc\nreplicationcontroller/e2e-test-nginx-rc rolling updated\n"
Jan 21 22:39:18.267: INFO: stdout: "Created e2e-test-nginx-rc-fe44e4833223217440f0579ebaba8a0c\nScaling up e2e-test-nginx-rc-fe44e4833223217440f0579ebaba8a0c from 0 to 1, scaling down e2e-test-nginx-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-nginx-rc-fe44e4833223217440f0579ebaba8a0c up to 1\nScaling e2e-test-nginx-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-nginx-rc\nRenaming e2e-test-nginx-rc-fe44e4833223217440f0579ebaba8a0c to e2e-test-nginx-rc\nreplicationcontroller/e2e-test-nginx-rc rolling updated\n"
STEP: waiting for all containers in run=e2e-test-nginx-rc pods to come up.
Jan 21 22:39:18.267: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-933165938 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l run=e2e-test-nginx-rc --namespace=e2e-tests-kubectl-j7cfr'
Jan 21 22:39:18.487: INFO: stderr: ""
Jan 21 22:39:18.487: INFO: stdout: "e2e-test-nginx-rc-fe44e4833223217440f0579ebaba8a0c-7lvzs "
Jan 21 22:39:18.487: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-933165938 get pods e2e-test-nginx-rc-fe44e4833223217440f0579ebaba8a0c-7lvzs -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "e2e-test-nginx-rc") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-j7cfr'
Jan 21 22:39:18.676: INFO: stderr: ""
Jan 21 22:39:18.676: INFO: stdout: "true"
Jan 21 22:39:18.676: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-933165938 get pods e2e-test-nginx-rc-fe44e4833223217440f0579ebaba8a0c-7lvzs -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "e2e-test-nginx-rc"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-j7cfr'
Jan 21 22:39:18.847: INFO: stderr: ""
Jan 21 22:39:18.847: INFO: stdout: "docker.io/library/nginx:1.14-alpine"
Jan 21 22:39:18.847: INFO: e2e-test-nginx-rc-fe44e4833223217440f0579ebaba8a0c-7lvzs is verified up and running
[AfterEach] [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1312
Jan 21 22:39:18.847: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-933165938 delete rc e2e-test-nginx-rc --namespace=e2e-tests-kubectl-j7cfr'
Jan 21 22:39:19.089: INFO: stderr: ""
Jan 21 22:39:19.089: INFO: stdout: "replicationcontroller \"e2e-test-nginx-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 22:39:19.089: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-j7cfr" for this suite.
Jan 21 22:39:43.145: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 22:39:43.295: INFO: namespace: e2e-tests-kubectl-j7cfr, resource: bindings, ignored listing per whitelist
Jan 21 22:39:43.551: INFO: namespace e2e-tests-kubectl-j7cfr deletion completed in 24.445302185s

• [SLOW TEST:42.030 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should support rolling-update to same image  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 22:39:43.551: INFO: >>> kubeConfig: /tmp/kubeconfig-933165938
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-p5qfw
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Jan 21 22:39:43.975: INFO: Waiting up to 5m0s for pod "downwardapi-volume-7297f168-1dcd-11e9-8130-be6597f3ae53" in namespace "e2e-tests-downward-api-p5qfw" to be "success or failure"
Jan 21 22:39:43.986: INFO: Pod "downwardapi-volume-7297f168-1dcd-11e9-8130-be6597f3ae53": Phase="Pending", Reason="", readiness=false. Elapsed: 10.206346ms
Jan 21 22:39:45.996: INFO: Pod "downwardapi-volume-7297f168-1dcd-11e9-8130-be6597f3ae53": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.021028645s
STEP: Saw pod success
Jan 21 22:39:45.996: INFO: Pod "downwardapi-volume-7297f168-1dcd-11e9-8130-be6597f3ae53" satisfied condition "success or failure"
Jan 21 22:39:46.006: INFO: Trying to get logs from node 10.191.28.59 pod downwardapi-volume-7297f168-1dcd-11e9-8130-be6597f3ae53 container client-container: <nil>
STEP: delete the pod
Jan 21 22:39:46.096: INFO: Waiting for pod downwardapi-volume-7297f168-1dcd-11e9-8130-be6597f3ae53 to disappear
Jan 21 22:39:46.106: INFO: Pod downwardapi-volume-7297f168-1dcd-11e9-8130-be6597f3ae53 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 22:39:46.106: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-p5qfw" for this suite.
Jan 21 22:39:52.155: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 22:39:52.239: INFO: namespace: e2e-tests-downward-api-p5qfw, resource: bindings, ignored listing per whitelist
Jan 21 22:39:52.579: INFO: namespace e2e-tests-downward-api-p5qfw deletion completed in 6.458942059s

• [SLOW TEST:9.028 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 22:39:52.580: INFO: >>> kubeConfig: /tmp/kubeconfig-933165938
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-gc-gw9cv
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the rs
STEP: Gathering metrics
W0121 22:40:23.619895      15 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Jan 21 22:40:23.619: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 22:40:23.620: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-gw9cv" for this suite.
Jan 21 22:40:29.706: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 22:40:29.807: INFO: namespace: e2e-tests-gc-gw9cv, resource: bindings, ignored listing per whitelist
Jan 21 22:40:30.113: INFO: namespace e2e-tests-gc-gw9cv deletion completed in 6.43773452s

• [SLOW TEST:37.533 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 22:40:30.114: INFO: >>> kubeConfig: /tmp/kubeconfig-933165938
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-subpath-8sfls
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with configmap pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-configmap-z9nk
STEP: Creating a pod to test atomic-volume-subpath
Jan 21 22:40:30.488: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-z9nk" in namespace "e2e-tests-subpath-8sfls" to be "success or failure"
Jan 21 22:40:30.501: INFO: Pod "pod-subpath-test-configmap-z9nk": Phase="Pending", Reason="", readiness=false. Elapsed: 12.749988ms
Jan 21 22:40:32.512: INFO: Pod "pod-subpath-test-configmap-z9nk": Phase="Pending", Reason="", readiness=false. Elapsed: 2.023900692s
Jan 21 22:40:34.524: INFO: Pod "pod-subpath-test-configmap-z9nk": Phase="Running", Reason="", readiness=false. Elapsed: 4.036037422s
Jan 21 22:40:36.538: INFO: Pod "pod-subpath-test-configmap-z9nk": Phase="Running", Reason="", readiness=false. Elapsed: 6.049934973s
Jan 21 22:40:38.550: INFO: Pod "pod-subpath-test-configmap-z9nk": Phase="Running", Reason="", readiness=false. Elapsed: 8.062385418s
Jan 21 22:40:40.561: INFO: Pod "pod-subpath-test-configmap-z9nk": Phase="Running", Reason="", readiness=false. Elapsed: 10.073562549s
Jan 21 22:40:42.575: INFO: Pod "pod-subpath-test-configmap-z9nk": Phase="Running", Reason="", readiness=false. Elapsed: 12.086629802s
Jan 21 22:40:44.586: INFO: Pod "pod-subpath-test-configmap-z9nk": Phase="Running", Reason="", readiness=false. Elapsed: 14.098149296s
Jan 21 22:40:46.596: INFO: Pod "pod-subpath-test-configmap-z9nk": Phase="Running", Reason="", readiness=false. Elapsed: 16.108180975s
Jan 21 22:40:48.607: INFO: Pod "pod-subpath-test-configmap-z9nk": Phase="Running", Reason="", readiness=false. Elapsed: 18.11929592s
Jan 21 22:40:50.619: INFO: Pod "pod-subpath-test-configmap-z9nk": Phase="Running", Reason="", readiness=false. Elapsed: 20.130684979s
Jan 21 22:40:52.630: INFO: Pod "pod-subpath-test-configmap-z9nk": Phase="Running", Reason="", readiness=false. Elapsed: 22.1422345s
Jan 21 22:40:54.645: INFO: Pod "pod-subpath-test-configmap-z9nk": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.156805049s
STEP: Saw pod success
Jan 21 22:40:54.645: INFO: Pod "pod-subpath-test-configmap-z9nk" satisfied condition "success or failure"
Jan 21 22:40:54.656: INFO: Trying to get logs from node 10.191.28.59 pod pod-subpath-test-configmap-z9nk container test-container-subpath-configmap-z9nk: <nil>
STEP: delete the pod
Jan 21 22:40:54.743: INFO: Waiting for pod pod-subpath-test-configmap-z9nk to disappear
Jan 21 22:40:54.753: INFO: Pod pod-subpath-test-configmap-z9nk no longer exists
STEP: Deleting pod pod-subpath-test-configmap-z9nk
Jan 21 22:40:54.753: INFO: Deleting pod "pod-subpath-test-configmap-z9nk" in namespace "e2e-tests-subpath-8sfls"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 22:40:54.764: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-8sfls" for this suite.
Jan 21 22:41:00.815: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 22:41:00.975: INFO: namespace: e2e-tests-subpath-8sfls, resource: bindings, ignored listing per whitelist
Jan 21 22:41:01.177: INFO: namespace e2e-tests-subpath-8sfls deletion completed in 6.399767048s

• [SLOW TEST:31.064 seconds]
[sig-storage] Subpath
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with configmap pod [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-apps] Daemon set [Serial] 
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 22:41:01.177: INFO: >>> kubeConfig: /tmp/kubeconfig-933165938
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-daemonsets-drl8x
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:98
[It] should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Jan 21 22:41:01.646: INFO: Number of nodes with available pods: 0
Jan 21 22:41:01.646: INFO: Node 10.191.28.39 is running more than one daemon pod
Jan 21 22:41:02.671: INFO: Number of nodes with available pods: 0
Jan 21 22:41:02.671: INFO: Node 10.191.28.39 is running more than one daemon pod
Jan 21 22:41:03.672: INFO: Number of nodes with available pods: 3
Jan 21 22:41:03.672: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Set a daemon pod's phase to 'Failed', check that the daemon pod is revived.
Jan 21 22:41:03.738: INFO: Number of nodes with available pods: 2
Jan 21 22:41:03.738: INFO: Node 10.191.28.45 is running more than one daemon pod
Jan 21 22:41:04.767: INFO: Number of nodes with available pods: 2
Jan 21 22:41:04.767: INFO: Node 10.191.28.45 is running more than one daemon pod
Jan 21 22:41:05.765: INFO: Number of nodes with available pods: 3
Jan 21 22:41:05.765: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Wait for the failed daemon pod to be completely deleted.
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:64
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting {extensions DaemonSet} daemon-set in namespace e2e-tests-daemonsets-drl8x, will wait for the garbage collector to delete the pods
Jan 21 22:41:05.923: INFO: Deleting {extensions DaemonSet} daemon-set took: 22.742378ms
Jan 21 22:41:06.023: INFO: Terminating {extensions DaemonSet} daemon-set pods took: 100.776601ms
Jan 21 22:41:42.534: INFO: Number of nodes with available pods: 0
Jan 21 22:41:42.534: INFO: Number of running nodes: 0, number of available pods: 0
Jan 21 22:41:42.542: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-drl8x/daemonsets","resourceVersion":"51277"},"items":null}

Jan 21 22:41:42.551: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-drl8x/pods","resourceVersion":"51277"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 22:41:42.596: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-drl8x" for this suite.
Jan 21 22:41:48.644: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 22:41:48.676: INFO: namespace: e2e-tests-daemonsets-drl8x, resource: bindings, ignored listing per whitelist
Jan 21 22:41:48.968: INFO: namespace e2e-tests-daemonsets-drl8x deletion completed in 6.360616339s

• [SLOW TEST:47.791 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run --rm job 
  should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 22:41:48.970: INFO: >>> kubeConfig: /tmp/kubeconfig-933165938
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-r24t7
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: executing a command with run --rm and attach with stdin
Jan 21 22:41:49.482: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-933165938 --namespace=e2e-tests-kubectl-r24t7 run e2e-test-rm-busybox-job --image=docker.io/library/busybox:1.29 --rm=true --generator=job/v1 --restart=OnFailure --attach=true --stdin -- sh -c cat && echo 'stdin closed''
Jan 21 22:41:51.111: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl create instead.\nIf you don't see a command prompt, try pressing enter.\n"
Jan 21 22:41:51.111: INFO: stdout: "abcd1234stdin closed\njob.batch \"e2e-test-rm-busybox-job\" deleted\n"
STEP: verifying the job e2e-test-rm-busybox-job was deleted
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 22:41:53.130: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-r24t7" for this suite.
Jan 21 22:41:59.181: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 22:41:59.523: INFO: namespace: e2e-tests-kubectl-r24t7, resource: bindings, ignored listing per whitelist
Jan 21 22:41:59.799: INFO: namespace e2e-tests-kubectl-r24t7 deletion completed in 6.654336554s

• [SLOW TEST:10.829 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run --rm job
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create a job from an image, then delete the job  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[k8s.io] [sig-node] Events 
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 22:41:59.802: INFO: >>> kubeConfig: /tmp/kubeconfig-933165938
STEP: Building a namespace api object, basename events
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-events-wkqb2
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: retrieving the pod
Jan 21 22:42:02.202: INFO: &Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:send-events-c3c32fc0-1dcd-11e9-8130-be6597f3ae53,GenerateName:,Namespace:e2e-tests-events-wkqb2,SelfLink:/api/v1/namespaces/e2e-tests-events-wkqb2/pods/send-events-c3c32fc0-1dcd-11e9-8130-be6597f3ae53,UID:c3c442c2-1dcd-11e9-903f-ee5d7ad9296f,ResourceVersion:51402,Generation:0,CreationTimestamp:2019-01-21 22:42:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: foo,time: 136092770,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-s8gfm {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-s8gfm,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{p gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1 [] []  [{ 0 80 TCP }] [] [] {map[] map[]} [{default-token-s8gfm true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*30,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.191.28.59,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc4208cc640} {node.kubernetes.io/unreachable Exists  NoExecute 0xc4208cc670}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-01-21 22:42:00 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-01-21 22:42:01 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-01-21 22:42:01 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-01-21 22:42:00 +0000 UTC  }],Message:,Reason:,HostIP:10.191.28.59,PodIP:172.30.156.154,StartTime:2019-01-21 22:42:00 +0000 UTC,ContainerStatuses:[{p {nil ContainerStateRunning{StartedAt:2019-01-21 22:42:01 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1 gcr.io/kubernetes-e2e-test-images/serve-hostname@sha256:bab70473a6d8ef65a22625dc9a1b0f0452e811530fdbe77e4408523460177ff1 containerd://45e7b4969718022d57cda675e1a94ce79a1bfd519711dbbc6940c96e0a7e2974}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}

STEP: checking for scheduler event about the pod
Jan 21 22:42:04.212: INFO: Saw scheduler event for our pod.
STEP: checking for kubelet event about the pod
Jan 21 22:42:06.221: INFO: Saw kubelet event for our pod.
STEP: deleting the pod
[AfterEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 22:42:06.271: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-events-wkqb2" for this suite.
Jan 21 22:42:46.326: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 22:42:46.747: INFO: namespace: e2e-tests-events-wkqb2, resource: bindings, ignored listing per whitelist
Jan 21 22:42:46.755: INFO: namespace e2e-tests-events-wkqb2 deletion completed in 40.469980217s

• [SLOW TEST:46.954 seconds]
[k8s.io] [sig-node] Events
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run job 
  should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 22:42:46.757: INFO: >>> kubeConfig: /tmp/kubeconfig-933165938
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-bbfc5
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Kubectl run job
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1402
[It] should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Jan 21 22:42:47.095: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-933165938 run e2e-test-nginx-job --restart=OnFailure --generator=job/v1 --image=docker.io/library/nginx:1.14-alpine --namespace=e2e-tests-kubectl-bbfc5'
Jan 21 22:42:47.301: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl create instead.\n"
Jan 21 22:42:47.301: INFO: stdout: "job.batch/e2e-test-nginx-job created\n"
STEP: verifying the job e2e-test-nginx-job was created
[AfterEach] [k8s.io] Kubectl run job
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1407
Jan 21 22:42:47.310: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-933165938 delete jobs e2e-test-nginx-job --namespace=e2e-tests-kubectl-bbfc5'
Jan 21 22:42:47.512: INFO: stderr: ""
Jan 21 22:42:47.512: INFO: stdout: "job.batch \"e2e-test-nginx-job\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 22:42:47.512: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-bbfc5" for this suite.
Jan 21 22:43:11.562: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 22:43:11.849: INFO: namespace: e2e-tests-kubectl-bbfc5, resource: bindings, ignored listing per whitelist
Jan 21 22:43:11.964: INFO: namespace e2e-tests-kubectl-bbfc5 deletion completed in 24.437226242s

• [SLOW TEST:25.207 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run job
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create a job from an image when restart is OnFailure  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 22:43:11.965: INFO: >>> kubeConfig: /tmp/kubeconfig-933165938
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-secrets-4k8p9
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-map-eecafff7-1dcd-11e9-8130-be6597f3ae53
STEP: Creating a pod to test consume secrets
Jan 21 22:43:12.359: INFO: Waiting up to 5m0s for pod "pod-secrets-eecc9265-1dcd-11e9-8130-be6597f3ae53" in namespace "e2e-tests-secrets-4k8p9" to be "success or failure"
Jan 21 22:43:12.382: INFO: Pod "pod-secrets-eecc9265-1dcd-11e9-8130-be6597f3ae53": Phase="Pending", Reason="", readiness=false. Elapsed: 22.571908ms
Jan 21 22:43:14.409: INFO: Pod "pod-secrets-eecc9265-1dcd-11e9-8130-be6597f3ae53": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.049174236s
STEP: Saw pod success
Jan 21 22:43:14.409: INFO: Pod "pod-secrets-eecc9265-1dcd-11e9-8130-be6597f3ae53" satisfied condition "success or failure"
Jan 21 22:43:14.420: INFO: Trying to get logs from node 10.191.28.59 pod pod-secrets-eecc9265-1dcd-11e9-8130-be6597f3ae53 container secret-volume-test: <nil>
STEP: delete the pod
Jan 21 22:43:14.490: INFO: Waiting for pod pod-secrets-eecc9265-1dcd-11e9-8130-be6597f3ae53 to disappear
Jan 21 22:43:14.500: INFO: Pod pod-secrets-eecc9265-1dcd-11e9-8130-be6597f3ae53 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 22:43:14.500: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-4k8p9" for this suite.
Jan 21 22:43:20.553: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 22:43:20.770: INFO: namespace: e2e-tests-secrets-4k8p9, resource: bindings, ignored listing per whitelist
Jan 21 22:43:20.894: INFO: namespace e2e-tests-secrets-4k8p9 deletion completed in 6.376734437s

• [SLOW TEST:8.929 seconds]
[sig-storage] Secrets
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-api-machinery] ConfigMap 
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 22:43:20.894: INFO: >>> kubeConfig: /tmp/kubeconfig-933165938
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-cphvt
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap e2e-tests-configmap-cphvt/configmap-test-f414a66f-1dcd-11e9-8130-be6597f3ae53
STEP: Creating a pod to test consume configMaps
Jan 21 22:43:21.228: INFO: Waiting up to 5m0s for pod "pod-configmaps-f4160cf6-1dcd-11e9-8130-be6597f3ae53" in namespace "e2e-tests-configmap-cphvt" to be "success or failure"
Jan 21 22:43:21.238: INFO: Pod "pod-configmaps-f4160cf6-1dcd-11e9-8130-be6597f3ae53": Phase="Pending", Reason="", readiness=false. Elapsed: 9.541059ms
Jan 21 22:43:23.273: INFO: Pod "pod-configmaps-f4160cf6-1dcd-11e9-8130-be6597f3ae53": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.044968774s
STEP: Saw pod success
Jan 21 22:43:23.273: INFO: Pod "pod-configmaps-f4160cf6-1dcd-11e9-8130-be6597f3ae53" satisfied condition "success or failure"
Jan 21 22:43:23.284: INFO: Trying to get logs from node 10.191.28.39 pod pod-configmaps-f4160cf6-1dcd-11e9-8130-be6597f3ae53 container env-test: <nil>
STEP: delete the pod
Jan 21 22:43:23.343: INFO: Waiting for pod pod-configmaps-f4160cf6-1dcd-11e9-8130-be6597f3ae53 to disappear
Jan 21 22:43:23.353: INFO: Pod pod-configmaps-f4160cf6-1dcd-11e9-8130-be6597f3ae53 no longer exists
[AfterEach] [sig-api-machinery] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 22:43:23.353: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-cphvt" for this suite.
Jan 21 22:43:29.399: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 22:43:29.708: INFO: namespace: e2e-tests-configmap-cphvt, resource: bindings, ignored listing per whitelist
Jan 21 22:43:29.785: INFO: namespace e2e-tests-configmap-cphvt deletion completed in 6.418701566s

• [SLOW TEST:8.891 seconds]
[sig-api-machinery] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:30
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Jan 21 22:43:29.788: INFO: >>> kubeConfig: /tmp/kubeconfig-933165938
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-85ntf
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0666 on node default medium
Jan 21 22:43:30.174: INFO: Waiting up to 5m0s for pod "pod-f96b3c93-1dcd-11e9-8130-be6597f3ae53" in namespace "e2e-tests-emptydir-85ntf" to be "success or failure"
Jan 21 22:43:30.185: INFO: Pod "pod-f96b3c93-1dcd-11e9-8130-be6597f3ae53": Phase="Pending", Reason="", readiness=false. Elapsed: 10.62863ms
Jan 21 22:43:32.197: INFO: Pod "pod-f96b3c93-1dcd-11e9-8130-be6597f3ae53": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.02327351s
STEP: Saw pod success
Jan 21 22:43:32.198: INFO: Pod "pod-f96b3c93-1dcd-11e9-8130-be6597f3ae53" satisfied condition "success or failure"
Jan 21 22:43:32.207: INFO: Trying to get logs from node 10.191.28.59 pod pod-f96b3c93-1dcd-11e9-8130-be6597f3ae53 container test-container: <nil>
STEP: delete the pod
Jan 21 22:43:32.269: INFO: Waiting for pod pod-f96b3c93-1dcd-11e9-8130-be6597f3ae53 to disappear
Jan 21 22:43:32.278: INFO: Pod pod-f96b3c93-1dcd-11e9-8130-be6597f3ae53 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Jan 21 22:43:32.278: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-85ntf" for this suite.
Jan 21 22:43:38.329: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jan 21 22:43:38.698: INFO: namespace: e2e-tests-emptydir-85ntf, resource: bindings, ignored listing per whitelist
Jan 21 22:43:38.707: INFO: namespace e2e-tests-emptydir-85ntf deletion completed in 6.41388486s

• [SLOW TEST:8.919 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSJan 21 22:43:38.710: INFO: Running AfterSuite actions on all node
Jan 21 22:43:38.710: INFO: Running AfterSuite actions on node 1
Jan 21 22:43:38.710: INFO: Skipping dumping logs from cluster

Ran 187 of 1814 Specs in 5034.520 seconds
SUCCESS! -- 187 Passed | 0 Failed | 0 Pending | 1627 Skipped PASS

Ginkgo ran 1 suite in 1h23m56.184108539s
Test Suite Passed
