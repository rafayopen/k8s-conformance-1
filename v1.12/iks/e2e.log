Feb  6 01:52:37.775: INFO: Overriding default scale value of zero to 1
Feb  6 01:52:37.775: INFO: Overriding default milliseconds value of zero to 5000
I0206 01:52:38.448590      15 test_context.go:385] Using a temporary kubeconfig file from in-cluster config : /tmp/kubeconfig-131423863
I0206 01:52:38.448674      15 e2e.go:304] Starting e2e run "e14770b0-29b1-11e9-9603-eaa511fa0b6c" on Ginkgo node 1
Running Suite: Kubernetes e2e suite
===================================
Random Seed: 1549417957 - Will randomize all specs
Will run 188 of 1814 specs

Feb  6 01:52:38.656: INFO: >>> kubeConfig: /tmp/kubeconfig-131423863
Feb  6 01:52:38.659: INFO: Waiting up to 30m0s for all (but 0) nodes to be schedulable
Feb  6 01:52:38.726: INFO: Waiting up to 10m0s for all pods (need at least 0) in namespace 'kube-system' to be running and ready
Feb  6 01:52:38.794: INFO: 23 / 23 pods in namespace 'kube-system' are running and ready (0 seconds elapsed)
Feb  6 01:52:38.794: INFO: expected 11 pod replicas in namespace 'kube-system', 11 are Running and Ready.
Feb  6 01:52:38.794: INFO: Waiting up to 5m0s for all daemonsets in namespace 'kube-system' to start
Feb  6 01:52:38.810: INFO: 3 / 3 pods ready in namespace 'kube-system' in daemonset 'calico-node' (0 seconds elapsed)
Feb  6 01:52:38.810: INFO: 3 / 3 pods ready in namespace 'kube-system' in daemonset 'ibm-keepalived-watcher' (0 seconds elapsed)
Feb  6 01:52:38.810: INFO: 3 / 3 pods ready in namespace 'kube-system' in daemonset 'ibm-kube-fluentd' (0 seconds elapsed)
Feb  6 01:52:38.810: INFO: 0 / 0 pods ready in namespace 'kube-system' in daemonset 'ibm-master-proxy' (0 seconds elapsed)
Feb  6 01:52:38.810: INFO: 0 / 0 pods ready in namespace 'kube-system' in daemonset 'nvidia-driver-installer' (0 seconds elapsed)
Feb  6 01:52:38.810: INFO: 0 / 0 pods ready in namespace 'kube-system' in daemonset 'nvidia-gpu-device-plugin' (0 seconds elapsed)
Feb  6 01:52:38.810: INFO: e2e test version: v1.12.1
Feb  6 01:52:38.813: INFO: kube-apiserver version: v1.12.5+IKS
[sig-apps] ReplicationController 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  6 01:52:38.813: INFO: >>> kubeConfig: /tmp/kubeconfig-131423863
STEP: Building a namespace api object, basename replication-controller
Feb  6 01:52:39.191: INFO: Found PodSecurityPolicies; assuming PodSecurityPolicy is enabled.
Feb  6 01:52:39.216: INFO: Found ClusterRoles; assuming RBAC is enabled.
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-replication-controller-g9skp
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating replication controller my-hostname-basic-e2417e54-29b1-11e9-9603-eaa511fa0b6c
Feb  6 01:52:39.368: INFO: Pod name my-hostname-basic-e2417e54-29b1-11e9-9603-eaa511fa0b6c: Found 0 pods out of 1
Feb  6 01:52:44.378: INFO: Pod name my-hostname-basic-e2417e54-29b1-11e9-9603-eaa511fa0b6c: Found 1 pods out of 1
Feb  6 01:52:44.378: INFO: Ensuring all pods for ReplicationController "my-hostname-basic-e2417e54-29b1-11e9-9603-eaa511fa0b6c" are running
Feb  6 01:52:44.388: INFO: Pod "my-hostname-basic-e2417e54-29b1-11e9-9603-eaa511fa0b6c-x25q7" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-02-06 01:52:39 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-02-06 01:52:41 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-02-06 01:52:41 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-02-06 01:52:39 +0000 UTC Reason: Message:}])
Feb  6 01:52:44.388: INFO: Trying to dial the pod
Feb  6 01:52:49.440: INFO: Controller my-hostname-basic-e2417e54-29b1-11e9-9603-eaa511fa0b6c: Got expected result from replica 1 [my-hostname-basic-e2417e54-29b1-11e9-9603-eaa511fa0b6c-x25q7]: "my-hostname-basic-e2417e54-29b1-11e9-9603-eaa511fa0b6c-x25q7", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  6 01:52:49.441: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-replication-controller-g9skp" for this suite.
Feb  6 01:52:55.483: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 01:52:55.701: INFO: namespace: e2e-tests-replication-controller-g9skp, resource: bindings, ignored listing per whitelist
Feb  6 01:52:55.940: INFO: namespace e2e-tests-replication-controller-g9skp deletion completed in 6.484517848s

• [SLOW TEST:17.127 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  6 01:52:55.941: INFO: >>> kubeConfig: /tmp/kubeconfig-131423863
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-wj7qs
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-map-ec550adb-29b1-11e9-9603-eaa511fa0b6c
STEP: Creating a pod to test consume configMaps
Feb  6 01:52:56.273: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-ec567008-29b1-11e9-9603-eaa511fa0b6c" in namespace "e2e-tests-projected-wj7qs" to be "success or failure"
Feb  6 01:52:56.283: INFO: Pod "pod-projected-configmaps-ec567008-29b1-11e9-9603-eaa511fa0b6c": Phase="Pending", Reason="", readiness=false. Elapsed: 9.010691ms
Feb  6 01:52:58.291: INFO: Pod "pod-projected-configmaps-ec567008-29b1-11e9-9603-eaa511fa0b6c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.017299979s
STEP: Saw pod success
Feb  6 01:52:58.291: INFO: Pod "pod-projected-configmaps-ec567008-29b1-11e9-9603-eaa511fa0b6c" satisfied condition "success or failure"
Feb  6 01:52:58.299: INFO: Trying to get logs from node 10.190.119.184 pod pod-projected-configmaps-ec567008-29b1-11e9-9603-eaa511fa0b6c container projected-configmap-volume-test: <nil>
STEP: delete the pod
Feb  6 01:52:58.391: INFO: Waiting for pod pod-projected-configmaps-ec567008-29b1-11e9-9603-eaa511fa0b6c to disappear
Feb  6 01:52:58.399: INFO: Pod pod-projected-configmaps-ec567008-29b1-11e9-9603-eaa511fa0b6c no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  6 01:52:58.399: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-wj7qs" for this suite.
Feb  6 01:53:04.437: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 01:53:04.621: INFO: namespace: e2e-tests-projected-wj7qs, resource: bindings, ignored listing per whitelist
Feb  6 01:53:04.907: INFO: namespace e2e-tests-projected-wj7qs deletion completed in 6.495256348s

• [SLOW TEST:8.966 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  6 01:53:04.908: INFO: >>> kubeConfig: /tmp/kubeconfig-131423863
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-gc-nhzsk
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the rc
STEP: delete the rc
STEP: wait for all pods to be garbage collected
STEP: Gathering metrics
W0206 01:53:15.316138      15 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Feb  6 01:53:15.316: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  6 01:53:15.316: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-nhzsk" for this suite.
Feb  6 01:53:21.421: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 01:53:21.846: INFO: namespace: e2e-tests-gc-nhzsk, resource: bindings, ignored listing per whitelist
Feb  6 01:53:21.868: INFO: namespace e2e-tests-gc-nhzsk deletion completed in 6.541393103s

• [SLOW TEST:16.960 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  6 01:53:21.868: INFO: >>> kubeConfig: /tmp/kubeconfig-131423863
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-b8xq5
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0666 on tmpfs
Feb  6 01:53:22.200: INFO: Waiting up to 5m0s for pod "pod-fbca90f8-29b1-11e9-9603-eaa511fa0b6c" in namespace "e2e-tests-emptydir-b8xq5" to be "success or failure"
Feb  6 01:53:22.208: INFO: Pod "pod-fbca90f8-29b1-11e9-9603-eaa511fa0b6c": Phase="Pending", Reason="", readiness=false. Elapsed: 8.104193ms
Feb  6 01:53:24.218: INFO: Pod "pod-fbca90f8-29b1-11e9-9603-eaa511fa0b6c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.018043227s
STEP: Saw pod success
Feb  6 01:53:24.218: INFO: Pod "pod-fbca90f8-29b1-11e9-9603-eaa511fa0b6c" satisfied condition "success or failure"
Feb  6 01:53:24.227: INFO: Trying to get logs from node 10.190.119.184 pod pod-fbca90f8-29b1-11e9-9603-eaa511fa0b6c container test-container: <nil>
STEP: delete the pod
Feb  6 01:53:24.276: INFO: Waiting for pod pod-fbca90f8-29b1-11e9-9603-eaa511fa0b6c to disappear
Feb  6 01:53:24.283: INFO: Pod pod-fbca90f8-29b1-11e9-9603-eaa511fa0b6c no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  6 01:53:24.283: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-b8xq5" for this suite.
Feb  6 01:53:30.322: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 01:53:30.586: INFO: namespace: e2e-tests-emptydir-b8xq5, resource: bindings, ignored listing per whitelist
Feb  6 01:53:30.688: INFO: namespace e2e-tests-emptydir-b8xq5 deletion completed in 6.392168958s

• [SLOW TEST:8.820 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[k8s.io] Probing container 
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  6 01:53:30.689: INFO: >>> kubeConfig: /tmp/kubeconfig-131423863
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-container-probe-9jkb7
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb  6 01:53:53.134: INFO: Container started at 2019-02-06 01:53:32 +0000 UTC, pod became ready at 2019-02-06 01:53:52 +0000 UTC
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  6 01:53:53.134: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-9jkb7" for this suite.
Feb  6 01:54:17.206: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 01:54:17.593: INFO: namespace: e2e-tests-container-probe-9jkb7, resource: bindings, ignored listing per whitelist
Feb  6 01:54:17.693: INFO: namespace e2e-tests-container-probe-9jkb7 deletion completed in 24.546338755s

• [SLOW TEST:47.004 seconds]
[k8s.io] Probing container
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  6 01:54:17.693: INFO: >>> kubeConfig: /tmp/kubeconfig-131423863
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-q46rc
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb  6 01:54:18.019: INFO: Waiting up to 5m0s for pod "downwardapi-volume-1d0fb3f9-29b2-11e9-9603-eaa511fa0b6c" in namespace "e2e-tests-downward-api-q46rc" to be "success or failure"
Feb  6 01:54:18.029: INFO: Pod "downwardapi-volume-1d0fb3f9-29b2-11e9-9603-eaa511fa0b6c": Phase="Pending", Reason="", readiness=false. Elapsed: 9.489485ms
Feb  6 01:54:20.040: INFO: Pod "downwardapi-volume-1d0fb3f9-29b2-11e9-9603-eaa511fa0b6c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.02055824s
STEP: Saw pod success
Feb  6 01:54:20.040: INFO: Pod "downwardapi-volume-1d0fb3f9-29b2-11e9-9603-eaa511fa0b6c" satisfied condition "success or failure"
Feb  6 01:54:20.048: INFO: Trying to get logs from node 10.190.119.143 pod downwardapi-volume-1d0fb3f9-29b2-11e9-9603-eaa511fa0b6c container client-container: <nil>
STEP: delete the pod
Feb  6 01:54:20.106: INFO: Waiting for pod downwardapi-volume-1d0fb3f9-29b2-11e9-9603-eaa511fa0b6c to disappear
Feb  6 01:54:20.114: INFO: Pod downwardapi-volume-1d0fb3f9-29b2-11e9-9603-eaa511fa0b6c no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  6 01:54:20.114: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-q46rc" for this suite.
Feb  6 01:54:26.160: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 01:54:26.423: INFO: namespace: e2e-tests-downward-api-q46rc, resource: bindings, ignored listing per whitelist
Feb  6 01:54:26.493: INFO: namespace e2e-tests-downward-api-q46rc deletion completed in 6.363103576s

• [SLOW TEST:8.800 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] Projected 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  6 01:54:26.494: INFO: >>> kubeConfig: /tmp/kubeconfig-131423863
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-vjcc9
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb  6 01:54:26.910: INFO: Waiting up to 5m0s for pod "downwardapi-volume-225c84e8-29b2-11e9-9603-eaa511fa0b6c" in namespace "e2e-tests-projected-vjcc9" to be "success or failure"
Feb  6 01:54:26.918: INFO: Pod "downwardapi-volume-225c84e8-29b2-11e9-9603-eaa511fa0b6c": Phase="Pending", Reason="", readiness=false. Elapsed: 7.77453ms
Feb  6 01:54:28.927: INFO: Pod "downwardapi-volume-225c84e8-29b2-11e9-9603-eaa511fa0b6c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.017020176s
STEP: Saw pod success
Feb  6 01:54:28.927: INFO: Pod "downwardapi-volume-225c84e8-29b2-11e9-9603-eaa511fa0b6c" satisfied condition "success or failure"
Feb  6 01:54:28.938: INFO: Trying to get logs from node 10.190.119.184 pod downwardapi-volume-225c84e8-29b2-11e9-9603-eaa511fa0b6c container client-container: <nil>
STEP: delete the pod
Feb  6 01:54:29.019: INFO: Waiting for pod downwardapi-volume-225c84e8-29b2-11e9-9603-eaa511fa0b6c to disappear
Feb  6 01:54:29.027: INFO: Pod downwardapi-volume-225c84e8-29b2-11e9-9603-eaa511fa0b6c no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  6 01:54:29.027: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-vjcc9" for this suite.
Feb  6 01:54:35.071: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 01:54:35.160: INFO: namespace: e2e-tests-projected-vjcc9, resource: bindings, ignored listing per whitelist
Feb  6 01:54:35.470: INFO: namespace e2e-tests-projected-vjcc9 deletion completed in 6.426240807s

• [SLOW TEST:8.976 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  6 01:54:35.471: INFO: >>> kubeConfig: /tmp/kubeconfig-131423863
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-28bp4
STEP: Waiting for a default service account to be provisioned in namespace
[It] binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-upd-27d859eb-29b2-11e9-9603-eaa511fa0b6c
STEP: Creating the pod
STEP: Waiting for pod with text data
STEP: Waiting for pod with binary data
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  6 01:54:38.188: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-28bp4" for this suite.
Feb  6 01:55:02.228: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 01:55:02.422: INFO: namespace: e2e-tests-configmap-28bp4, resource: bindings, ignored listing per whitelist
Feb  6 01:55:02.592: INFO: namespace e2e-tests-configmap-28bp4 deletion completed in 24.391960189s

• [SLOW TEST:27.121 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl patch 
  should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  6 01:55:02.592: INFO: >>> kubeConfig: /tmp/kubeconfig-131423863
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-54jcs
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating Redis RC
Feb  6 01:55:02.997: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-131423863 create -f - --namespace=e2e-tests-kubectl-54jcs'
Feb  6 01:55:03.501: INFO: stderr: ""
Feb  6 01:55:03.501: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
Feb  6 01:55:04.510: INFO: Selector matched 1 pods for map[app:redis]
Feb  6 01:55:04.510: INFO: Found 0 / 1
Feb  6 01:55:05.510: INFO: Selector matched 1 pods for map[app:redis]
Feb  6 01:55:05.510: INFO: Found 1 / 1
Feb  6 01:55:05.510: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
STEP: patching all pods
Feb  6 01:55:05.520: INFO: Selector matched 1 pods for map[app:redis]
Feb  6 01:55:05.520: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Feb  6 01:55:05.520: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-131423863 patch pod redis-master-z4pgc --namespace=e2e-tests-kubectl-54jcs -p {"metadata":{"annotations":{"x":"y"}}}'
Feb  6 01:55:05.658: INFO: stderr: ""
Feb  6 01:55:05.658: INFO: stdout: "pod/redis-master-z4pgc patched\n"
STEP: checking annotations
Feb  6 01:55:05.668: INFO: Selector matched 1 pods for map[app:redis]
Feb  6 01:55:05.668: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  6 01:55:05.668: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-54jcs" for this suite.
Feb  6 01:55:29.712: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 01:55:29.800: INFO: namespace: e2e-tests-kubectl-54jcs, resource: bindings, ignored listing per whitelist
Feb  6 01:55:30.536: INFO: namespace e2e-tests-kubectl-54jcs deletion completed in 24.851141794s

• [SLOW TEST:27.944 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl patch
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should add annotations for pods in rc  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Secrets 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  6 01:55:30.539: INFO: >>> kubeConfig: /tmp/kubeconfig-131423863
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-secrets-pmwpw
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating secret e2e-tests-secrets-pmwpw/secret-test-487e765a-29b2-11e9-9603-eaa511fa0b6c
STEP: Creating a pod to test consume secrets
Feb  6 01:55:30.921: INFO: Waiting up to 5m0s for pod "pod-configmaps-4883e28c-29b2-11e9-9603-eaa511fa0b6c" in namespace "e2e-tests-secrets-pmwpw" to be "success or failure"
Feb  6 01:55:30.929: INFO: Pod "pod-configmaps-4883e28c-29b2-11e9-9603-eaa511fa0b6c": Phase="Pending", Reason="", readiness=false. Elapsed: 7.865025ms
Feb  6 01:55:32.937: INFO: Pod "pod-configmaps-4883e28c-29b2-11e9-9603-eaa511fa0b6c": Phase="Running", Reason="", readiness=true. Elapsed: 2.016394738s
Feb  6 01:55:34.950: INFO: Pod "pod-configmaps-4883e28c-29b2-11e9-9603-eaa511fa0b6c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.029465959s
STEP: Saw pod success
Feb  6 01:55:34.951: INFO: Pod "pod-configmaps-4883e28c-29b2-11e9-9603-eaa511fa0b6c" satisfied condition "success or failure"
Feb  6 01:55:34.961: INFO: Trying to get logs from node 10.190.119.184 pod pod-configmaps-4883e28c-29b2-11e9-9603-eaa511fa0b6c container env-test: <nil>
STEP: delete the pod
Feb  6 01:55:35.015: INFO: Waiting for pod pod-configmaps-4883e28c-29b2-11e9-9603-eaa511fa0b6c to disappear
Feb  6 01:55:35.024: INFO: Pod pod-configmaps-4883e28c-29b2-11e9-9603-eaa511fa0b6c no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  6 01:55:35.024: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-pmwpw" for this suite.
Feb  6 01:55:41.221: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 01:55:41.291: INFO: namespace: e2e-tests-secrets-pmwpw, resource: bindings, ignored listing per whitelist
Feb  6 01:55:41.563: INFO: namespace e2e-tests-secrets-pmwpw deletion completed in 6.405071053s

• [SLOW TEST:11.023 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:31
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Projected 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  6 01:55:41.563: INFO: >>> kubeConfig: /tmp/kubeconfig-131423863
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-q8h9q
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating the pod
Feb  6 01:55:46.510: INFO: Successfully updated pod "labelsupdate4f0feb1d-29b2-11e9-9603-eaa511fa0b6c"
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  6 01:55:48.614: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-q8h9q" for this suite.
Feb  6 01:56:10.654: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 01:56:10.979: INFO: namespace: e2e-tests-projected-q8h9q, resource: bindings, ignored listing per whitelist
Feb  6 01:56:10.979: INFO: namespace e2e-tests-projected-q8h9q deletion completed in 22.35188643s

• [SLOW TEST:29.417 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod with mountPath of existing file [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  6 01:56:10.980: INFO: >>> kubeConfig: /tmp/kubeconfig-131423863
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-subpath-9jbkr
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with configmap pod with mountPath of existing file [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-configmap-q7bk
STEP: Creating a pod to test atomic-volume-subpath
Feb  6 01:56:11.315: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-q7bk" in namespace "e2e-tests-subpath-9jbkr" to be "success or failure"
Feb  6 01:56:11.325: INFO: Pod "pod-subpath-test-configmap-q7bk": Phase="Pending", Reason="", readiness=false. Elapsed: 9.442812ms
Feb  6 01:56:13.335: INFO: Pod "pod-subpath-test-configmap-q7bk": Phase="Pending", Reason="", readiness=false. Elapsed: 2.019070305s
Feb  6 01:56:15.358: INFO: Pod "pod-subpath-test-configmap-q7bk": Phase="Running", Reason="", readiness=false. Elapsed: 4.042107985s
Feb  6 01:56:17.366: INFO: Pod "pod-subpath-test-configmap-q7bk": Phase="Running", Reason="", readiness=false. Elapsed: 6.050509971s
Feb  6 01:56:19.376: INFO: Pod "pod-subpath-test-configmap-q7bk": Phase="Running", Reason="", readiness=false. Elapsed: 8.060113879s
Feb  6 01:56:21.385: INFO: Pod "pod-subpath-test-configmap-q7bk": Phase="Running", Reason="", readiness=false. Elapsed: 10.069623043s
Feb  6 01:56:23.396: INFO: Pod "pod-subpath-test-configmap-q7bk": Phase="Running", Reason="", readiness=false. Elapsed: 12.080719218s
Feb  6 01:56:25.419: INFO: Pod "pod-subpath-test-configmap-q7bk": Phase="Running", Reason="", readiness=false. Elapsed: 14.103346426s
Feb  6 01:56:27.428: INFO: Pod "pod-subpath-test-configmap-q7bk": Phase="Running", Reason="", readiness=false. Elapsed: 16.112120406s
Feb  6 01:56:29.436: INFO: Pod "pod-subpath-test-configmap-q7bk": Phase="Running", Reason="", readiness=false. Elapsed: 18.120785025s
Feb  6 01:56:31.447: INFO: Pod "pod-subpath-test-configmap-q7bk": Phase="Running", Reason="", readiness=false. Elapsed: 20.131345347s
Feb  6 01:56:33.456: INFO: Pod "pod-subpath-test-configmap-q7bk": Phase="Running", Reason="", readiness=false. Elapsed: 22.14012705s
Feb  6 01:56:35.479: INFO: Pod "pod-subpath-test-configmap-q7bk": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.16373192s
STEP: Saw pod success
Feb  6 01:56:35.479: INFO: Pod "pod-subpath-test-configmap-q7bk" satisfied condition "success or failure"
Feb  6 01:56:35.487: INFO: Trying to get logs from node 10.190.119.184 pod pod-subpath-test-configmap-q7bk container test-container-subpath-configmap-q7bk: <nil>
STEP: delete the pod
Feb  6 01:56:35.550: INFO: Waiting for pod pod-subpath-test-configmap-q7bk to disappear
Feb  6 01:56:35.559: INFO: Pod pod-subpath-test-configmap-q7bk no longer exists
STEP: Deleting pod pod-subpath-test-configmap-q7bk
Feb  6 01:56:35.559: INFO: Deleting pod "pod-subpath-test-configmap-q7bk" in namespace "e2e-tests-subpath-9jbkr"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  6 01:56:35.572: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-9jbkr" for this suite.
Feb  6 01:56:41.621: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 01:56:41.826: INFO: namespace: e2e-tests-subpath-9jbkr, resource: bindings, ignored listing per whitelist
Feb  6 01:56:41.986: INFO: namespace e2e-tests-subpath-9jbkr deletion completed in 6.401659068s

• [SLOW TEST:31.006 seconds]
[sig-storage] Subpath
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with configmap pod with mountPath of existing file [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  6 01:56:41.987: INFO: >>> kubeConfig: /tmp/kubeconfig-131423863
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-statefulset-v7vlr
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-v7vlr
[It] Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Looking for a node to schedule stateful set and pod
STEP: Creating pod with conflicting port in namespace e2e-tests-statefulset-v7vlr
STEP: Creating statefulset with conflicting port in namespace e2e-tests-statefulset-v7vlr
STEP: Waiting until pod test-pod will start running in namespace e2e-tests-statefulset-v7vlr
STEP: Waiting until stateful pod ss-0 will be recreated and deleted at least once in namespace e2e-tests-statefulset-v7vlr
Feb  6 01:56:44.571: INFO: Observed stateful pod in namespace: e2e-tests-statefulset-v7vlr, name: ss-0, uid: 741456ef-29b2-11e9-a275-52a9a0efac9f, status phase: Pending. Waiting for statefulset controller to delete.
Feb  6 01:56:44.954: INFO: Observed stateful pod in namespace: e2e-tests-statefulset-v7vlr, name: ss-0, uid: 741456ef-29b2-11e9-a275-52a9a0efac9f, status phase: Failed. Waiting for statefulset controller to delete.
Feb  6 01:56:44.972: INFO: Observed stateful pod in namespace: e2e-tests-statefulset-v7vlr, name: ss-0, uid: 741456ef-29b2-11e9-a275-52a9a0efac9f, status phase: Failed. Waiting for statefulset controller to delete.
Feb  6 01:56:44.985: INFO: Observed delete event for stateful pod ss-0 in namespace e2e-tests-statefulset-v7vlr
STEP: Removing pod with conflicting port in namespace e2e-tests-statefulset-v7vlr
STEP: Waiting when stateful pod ss-0 will be recreated in namespace e2e-tests-statefulset-v7vlr and will be in running state
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Feb  6 01:56:47.061: INFO: Deleting all statefulset in ns e2e-tests-statefulset-v7vlr
Feb  6 01:56:47.069: INFO: Scaling statefulset ss to 0
Feb  6 01:57:07.123: INFO: Waiting for statefulset status.replicas updated to 0
Feb  6 01:57:07.133: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  6 01:57:07.190: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-v7vlr" for this suite.
Feb  6 01:57:13.236: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 01:57:13.373: INFO: namespace: e2e-tests-statefulset-v7vlr, resource: bindings, ignored listing per whitelist
Feb  6 01:57:13.582: INFO: namespace e2e-tests-statefulset-v7vlr deletion completed in 6.378132399s

• [SLOW TEST:31.595 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    Should recreate evicted statefulset [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-network] Services 
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  6 01:57:13.583: INFO: >>> kubeConfig: /tmp/kubeconfig-131423863
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-services-hj52d
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:83
[It] should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating service endpoint-test2 in namespace e2e-tests-services-hj52d
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-hj52d to expose endpoints map[]
Feb  6 01:57:14.055: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-hj52d exposes endpoints map[] (8.257909ms elapsed)
STEP: Creating pod pod1 in namespace e2e-tests-services-hj52d
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-hj52d to expose endpoints map[pod1:[80]]
Feb  6 01:57:16.133: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-hj52d exposes endpoints map[pod1:[80]] (2.060281424s elapsed)
STEP: Creating pod pod2 in namespace e2e-tests-services-hj52d
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-hj52d to expose endpoints map[pod1:[80] pod2:[80]]
Feb  6 01:57:18.268: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-hj52d exposes endpoints map[pod1:[80] pod2:[80]] (2.117520669s elapsed)
STEP: Deleting pod pod1 in namespace e2e-tests-services-hj52d
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-hj52d to expose endpoints map[pod2:[80]]
Feb  6 01:57:18.304: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-hj52d exposes endpoints map[pod2:[80]] (18.214494ms elapsed)
STEP: Deleting pod pod2 in namespace e2e-tests-services-hj52d
STEP: waiting up to 3m0s for service endpoint-test2 in namespace e2e-tests-services-hj52d to expose endpoints map[]
Feb  6 01:57:18.391: INFO: successfully validated that service endpoint-test2 in namespace e2e-tests-services-hj52d exposes endpoints map[] (66.751511ms elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  6 01:57:18.452: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-services-hj52d" for this suite.
Feb  6 01:57:24.499: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 01:57:24.643: INFO: namespace: e2e-tests-services-hj52d, resource: bindings, ignored listing per whitelist
Feb  6 01:57:24.874: INFO: namespace e2e-tests-services-hj52d deletion completed in 6.402545411s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:88

• [SLOW TEST:11.291 seconds]
[sig-network] Services
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  6 01:57:24.874: INFO: >>> kubeConfig: /tmp/kubeconfig-131423863
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-6fjpc
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb  6 01:57:25.213: INFO: Waiting up to 5m0s for pod "downwardapi-volume-8ca35cb0-29b2-11e9-9603-eaa511fa0b6c" in namespace "e2e-tests-downward-api-6fjpc" to be "success or failure"
Feb  6 01:57:25.221: INFO: Pod "downwardapi-volume-8ca35cb0-29b2-11e9-9603-eaa511fa0b6c": Phase="Pending", Reason="", readiness=false. Elapsed: 8.266335ms
Feb  6 01:57:27.246: INFO: Pod "downwardapi-volume-8ca35cb0-29b2-11e9-9603-eaa511fa0b6c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.032478593s
Feb  6 01:57:29.254: INFO: Pod "downwardapi-volume-8ca35cb0-29b2-11e9-9603-eaa511fa0b6c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.040824059s
STEP: Saw pod success
Feb  6 01:57:29.254: INFO: Pod "downwardapi-volume-8ca35cb0-29b2-11e9-9603-eaa511fa0b6c" satisfied condition "success or failure"
Feb  6 01:57:29.264: INFO: Trying to get logs from node 10.190.119.143 pod downwardapi-volume-8ca35cb0-29b2-11e9-9603-eaa511fa0b6c container client-container: <nil>
STEP: delete the pod
Feb  6 01:57:29.324: INFO: Waiting for pod downwardapi-volume-8ca35cb0-29b2-11e9-9603-eaa511fa0b6c to disappear
Feb  6 01:57:29.335: INFO: Pod downwardapi-volume-8ca35cb0-29b2-11e9-9603-eaa511fa0b6c no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  6 01:57:29.335: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-6fjpc" for this suite.
Feb  6 01:57:35.377: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 01:57:35.526: INFO: namespace: e2e-tests-downward-api-6fjpc, resource: bindings, ignored listing per whitelist
Feb  6 01:57:35.789: INFO: namespace e2e-tests-downward-api-6fjpc deletion completed in 6.438380138s

• [SLOW TEST:10.915 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  6 01:57:35.789: INFO: >>> kubeConfig: /tmp/kubeconfig-131423863
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-lw8sv
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-9321bdba-29b2-11e9-9603-eaa511fa0b6c
STEP: Creating a pod to test consume configMaps
Feb  6 01:57:36.123: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-93238791-29b2-11e9-9603-eaa511fa0b6c" in namespace "e2e-tests-projected-lw8sv" to be "success or failure"
Feb  6 01:57:36.134: INFO: Pod "pod-projected-configmaps-93238791-29b2-11e9-9603-eaa511fa0b6c": Phase="Pending", Reason="", readiness=false. Elapsed: 10.024909ms
Feb  6 01:57:38.160: INFO: Pod "pod-projected-configmaps-93238791-29b2-11e9-9603-eaa511fa0b6c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.036670608s
STEP: Saw pod success
Feb  6 01:57:38.160: INFO: Pod "pod-projected-configmaps-93238791-29b2-11e9-9603-eaa511fa0b6c" satisfied condition "success or failure"
Feb  6 01:57:38.172: INFO: Trying to get logs from node 10.190.119.184 pod pod-projected-configmaps-93238791-29b2-11e9-9603-eaa511fa0b6c container projected-configmap-volume-test: <nil>
STEP: delete the pod
Feb  6 01:57:38.233: INFO: Waiting for pod pod-projected-configmaps-93238791-29b2-11e9-9603-eaa511fa0b6c to disappear
Feb  6 01:57:38.241: INFO: Pod pod-projected-configmaps-93238791-29b2-11e9-9603-eaa511fa0b6c no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  6 01:57:38.241: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-lw8sv" for this suite.
Feb  6 01:57:44.521: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 01:57:44.759: INFO: namespace: e2e-tests-projected-lw8sv, resource: bindings, ignored listing per whitelist
Feb  6 01:57:44.950: INFO: namespace e2e-tests-projected-lw8sv deletion completed in 6.68883924s

• [SLOW TEST:9.161 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  6 01:57:44.950: INFO: >>> kubeConfig: /tmp/kubeconfig-131423863
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-secrets-2q924
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-map-989d12c0-29b2-11e9-9603-eaa511fa0b6c
STEP: Creating a pod to test consume secrets
Feb  6 01:57:45.318: INFO: Waiting up to 5m0s for pod "pod-secrets-989ecec0-29b2-11e9-9603-eaa511fa0b6c" in namespace "e2e-tests-secrets-2q924" to be "success or failure"
Feb  6 01:57:45.326: INFO: Pod "pod-secrets-989ecec0-29b2-11e9-9603-eaa511fa0b6c": Phase="Pending", Reason="", readiness=false. Elapsed: 8.135523ms
Feb  6 01:57:47.336: INFO: Pod "pod-secrets-989ecec0-29b2-11e9-9603-eaa511fa0b6c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.018005527s
STEP: Saw pod success
Feb  6 01:57:47.336: INFO: Pod "pod-secrets-989ecec0-29b2-11e9-9603-eaa511fa0b6c" satisfied condition "success or failure"
Feb  6 01:57:47.345: INFO: Trying to get logs from node 10.190.119.133 pod pod-secrets-989ecec0-29b2-11e9-9603-eaa511fa0b6c container secret-volume-test: <nil>
STEP: delete the pod
Feb  6 01:57:47.646: INFO: Waiting for pod pod-secrets-989ecec0-29b2-11e9-9603-eaa511fa0b6c to disappear
Feb  6 01:57:47.691: INFO: Pod pod-secrets-989ecec0-29b2-11e9-9603-eaa511fa0b6c no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  6 01:57:47.691: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-2q924" for this suite.
Feb  6 01:57:53.736: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 01:57:53.828: INFO: namespace: e2e-tests-secrets-2q924, resource: bindings, ignored listing per whitelist
Feb  6 01:57:54.081: INFO: namespace e2e-tests-secrets-2q924 deletion completed in 6.374107336s

• [SLOW TEST:9.131 seconds]
[sig-storage] Secrets
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] EmptyDir volumes 
  volume on tmpfs should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  6 01:57:54.081: INFO: >>> kubeConfig: /tmp/kubeconfig-131423863
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-gqn9v
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on tmpfs should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir volume type on tmpfs
Feb  6 01:57:54.402: INFO: Waiting up to 5m0s for pod "pod-9e096e15-29b2-11e9-9603-eaa511fa0b6c" in namespace "e2e-tests-emptydir-gqn9v" to be "success or failure"
Feb  6 01:57:54.412: INFO: Pod "pod-9e096e15-29b2-11e9-9603-eaa511fa0b6c": Phase="Pending", Reason="", readiness=false. Elapsed: 9.529275ms
Feb  6 01:57:56.421: INFO: Pod "pod-9e096e15-29b2-11e9-9603-eaa511fa0b6c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.019004539s
STEP: Saw pod success
Feb  6 01:57:56.421: INFO: Pod "pod-9e096e15-29b2-11e9-9603-eaa511fa0b6c" satisfied condition "success or failure"
Feb  6 01:57:56.436: INFO: Trying to get logs from node 10.190.119.143 pod pod-9e096e15-29b2-11e9-9603-eaa511fa0b6c container test-container: <nil>
STEP: delete the pod
Feb  6 01:57:56.485: INFO: Waiting for pod pod-9e096e15-29b2-11e9-9603-eaa511fa0b6c to disappear
Feb  6 01:57:56.493: INFO: Pod pod-9e096e15-29b2-11e9-9603-eaa511fa0b6c no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  6 01:57:56.493: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-gqn9v" for this suite.
Feb  6 01:58:02.536: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 01:58:02.645: INFO: namespace: e2e-tests-emptydir-gqn9v, resource: bindings, ignored listing per whitelist
Feb  6 01:58:02.894: INFO: namespace e2e-tests-emptydir-gqn9v deletion completed in 6.387537734s

• [SLOW TEST:8.812 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  volume on tmpfs should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  6 01:58:02.894: INFO: >>> kubeConfig: /tmp/kubeconfig-131423863
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-daemonsets-dhdlt
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:98
[It] should run and stop complex daemon [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb  6 01:58:03.243: INFO: Creating daemon "daemon-set" with a node selector
STEP: Initially, daemon pods should not be running on any nodes.
Feb  6 01:58:03.261: INFO: Number of nodes with available pods: 0
Feb  6 01:58:03.261: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Change node label to blue, check that daemon pod is launched.
Feb  6 01:58:03.303: INFO: Number of nodes with available pods: 0
Feb  6 01:58:03.303: INFO: Node 10.190.119.133 is running more than one daemon pod
Feb  6 01:58:04.313: INFO: Number of nodes with available pods: 0
Feb  6 01:58:04.313: INFO: Node 10.190.119.133 is running more than one daemon pod
Feb  6 01:58:05.311: INFO: Number of nodes with available pods: 1
Feb  6 01:58:05.311: INFO: Number of running nodes: 1, number of available pods: 1
STEP: Update the node label to green, and wait for daemons to be unscheduled
Feb  6 01:58:05.354: INFO: Number of nodes with available pods: 1
Feb  6 01:58:05.354: INFO: Number of running nodes: 0, number of available pods: 1
Feb  6 01:58:06.363: INFO: Number of nodes with available pods: 0
Feb  6 01:58:06.363: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Update DaemonSet node selector to green, and change its update strategy to RollingUpdate
Feb  6 01:58:06.398: INFO: Number of nodes with available pods: 0
Feb  6 01:58:06.399: INFO: Node 10.190.119.133 is running more than one daemon pod
Feb  6 01:58:07.408: INFO: Number of nodes with available pods: 0
Feb  6 01:58:07.408: INFO: Node 10.190.119.133 is running more than one daemon pod
Feb  6 01:58:08.408: INFO: Number of nodes with available pods: 0
Feb  6 01:58:08.408: INFO: Node 10.190.119.133 is running more than one daemon pod
Feb  6 01:58:09.920: INFO: Number of nodes with available pods: 0
Feb  6 01:58:09.920: INFO: Node 10.190.119.133 is running more than one daemon pod
Feb  6 01:58:10.409: INFO: Number of nodes with available pods: 0
Feb  6 01:58:10.409: INFO: Node 10.190.119.133 is running more than one daemon pod
Feb  6 01:58:11.421: INFO: Number of nodes with available pods: 0
Feb  6 01:58:11.421: INFO: Node 10.190.119.133 is running more than one daemon pod
Feb  6 01:58:12.407: INFO: Number of nodes with available pods: 0
Feb  6 01:58:12.407: INFO: Node 10.190.119.133 is running more than one daemon pod
Feb  6 01:58:13.408: INFO: Number of nodes with available pods: 0
Feb  6 01:58:13.408: INFO: Node 10.190.119.133 is running more than one daemon pod
Feb  6 01:58:14.407: INFO: Number of nodes with available pods: 0
Feb  6 01:58:14.407: INFO: Node 10.190.119.133 is running more than one daemon pod
Feb  6 01:58:15.408: INFO: Number of nodes with available pods: 0
Feb  6 01:58:15.408: INFO: Node 10.190.119.133 is running more than one daemon pod
Feb  6 01:58:16.407: INFO: Number of nodes with available pods: 0
Feb  6 01:58:16.407: INFO: Node 10.190.119.133 is running more than one daemon pod
Feb  6 01:58:17.407: INFO: Number of nodes with available pods: 0
Feb  6 01:58:17.407: INFO: Node 10.190.119.133 is running more than one daemon pod
Feb  6 01:58:18.407: INFO: Number of nodes with available pods: 0
Feb  6 01:58:18.407: INFO: Node 10.190.119.133 is running more than one daemon pod
Feb  6 01:58:19.408: INFO: Number of nodes with available pods: 0
Feb  6 01:58:19.408: INFO: Node 10.190.119.133 is running more than one daemon pod
Feb  6 01:58:20.408: INFO: Number of nodes with available pods: 0
Feb  6 01:58:20.408: INFO: Node 10.190.119.133 is running more than one daemon pod
Feb  6 01:58:21.407: INFO: Number of nodes with available pods: 0
Feb  6 01:58:21.408: INFO: Node 10.190.119.133 is running more than one daemon pod
Feb  6 01:58:22.421: INFO: Number of nodes with available pods: 0
Feb  6 01:58:22.421: INFO: Node 10.190.119.133 is running more than one daemon pod
Feb  6 01:58:23.408: INFO: Number of nodes with available pods: 0
Feb  6 01:58:23.408: INFO: Node 10.190.119.133 is running more than one daemon pod
Feb  6 01:58:24.411: INFO: Number of nodes with available pods: 0
Feb  6 01:58:24.411: INFO: Node 10.190.119.133 is running more than one daemon pod
Feb  6 01:58:25.409: INFO: Number of nodes with available pods: 0
Feb  6 01:58:25.409: INFO: Node 10.190.119.133 is running more than one daemon pod
Feb  6 01:58:26.407: INFO: Number of nodes with available pods: 0
Feb  6 01:58:26.408: INFO: Node 10.190.119.133 is running more than one daemon pod
Feb  6 01:58:27.408: INFO: Number of nodes with available pods: 0
Feb  6 01:58:27.408: INFO: Node 10.190.119.133 is running more than one daemon pod
Feb  6 01:58:28.409: INFO: Number of nodes with available pods: 0
Feb  6 01:58:28.409: INFO: Node 10.190.119.133 is running more than one daemon pod
Feb  6 01:58:29.407: INFO: Number of nodes with available pods: 0
Feb  6 01:58:29.407: INFO: Node 10.190.119.133 is running more than one daemon pod
Feb  6 01:58:30.407: INFO: Number of nodes with available pods: 0
Feb  6 01:58:30.407: INFO: Node 10.190.119.133 is running more than one daemon pod
Feb  6 01:58:31.407: INFO: Number of nodes with available pods: 0
Feb  6 01:58:31.407: INFO: Node 10.190.119.133 is running more than one daemon pod
Feb  6 01:58:32.407: INFO: Number of nodes with available pods: 0
Feb  6 01:58:32.407: INFO: Node 10.190.119.133 is running more than one daemon pod
Feb  6 01:58:33.420: INFO: Number of nodes with available pods: 0
Feb  6 01:58:33.420: INFO: Node 10.190.119.133 is running more than one daemon pod
Feb  6 01:58:34.408: INFO: Number of nodes with available pods: 0
Feb  6 01:58:34.408: INFO: Node 10.190.119.133 is running more than one daemon pod
Feb  6 01:58:35.410: INFO: Number of nodes with available pods: 0
Feb  6 01:58:35.410: INFO: Node 10.190.119.133 is running more than one daemon pod
Feb  6 01:58:36.408: INFO: Number of nodes with available pods: 0
Feb  6 01:58:36.408: INFO: Node 10.190.119.133 is running more than one daemon pod
Feb  6 01:58:37.410: INFO: Number of nodes with available pods: 0
Feb  6 01:58:37.410: INFO: Node 10.190.119.133 is running more than one daemon pod
Feb  6 01:58:38.407: INFO: Number of nodes with available pods: 0
Feb  6 01:58:38.407: INFO: Node 10.190.119.133 is running more than one daemon pod
Feb  6 01:58:39.408: INFO: Number of nodes with available pods: 0
Feb  6 01:58:39.408: INFO: Node 10.190.119.133 is running more than one daemon pod
Feb  6 01:58:40.410: INFO: Number of nodes with available pods: 0
Feb  6 01:58:40.410: INFO: Node 10.190.119.133 is running more than one daemon pod
Feb  6 01:58:41.411: INFO: Number of nodes with available pods: 0
Feb  6 01:58:41.411: INFO: Node 10.190.119.133 is running more than one daemon pod
Feb  6 01:58:42.408: INFO: Number of nodes with available pods: 0
Feb  6 01:58:42.408: INFO: Node 10.190.119.133 is running more than one daemon pod
Feb  6 01:58:43.408: INFO: Number of nodes with available pods: 0
Feb  6 01:58:43.408: INFO: Node 10.190.119.133 is running more than one daemon pod
Feb  6 01:58:44.420: INFO: Number of nodes with available pods: 0
Feb  6 01:58:44.421: INFO: Node 10.190.119.133 is running more than one daemon pod
Feb  6 01:58:45.409: INFO: Number of nodes with available pods: 0
Feb  6 01:58:45.409: INFO: Node 10.190.119.133 is running more than one daemon pod
Feb  6 01:58:46.407: INFO: Number of nodes with available pods: 0
Feb  6 01:58:46.407: INFO: Node 10.190.119.133 is running more than one daemon pod
Feb  6 01:58:47.408: INFO: Number of nodes with available pods: 0
Feb  6 01:58:47.408: INFO: Node 10.190.119.133 is running more than one daemon pod
Feb  6 01:58:48.407: INFO: Number of nodes with available pods: 0
Feb  6 01:58:48.407: INFO: Node 10.190.119.133 is running more than one daemon pod
Feb  6 01:58:49.407: INFO: Number of nodes with available pods: 0
Feb  6 01:58:49.407: INFO: Node 10.190.119.133 is running more than one daemon pod
Feb  6 01:58:50.408: INFO: Number of nodes with available pods: 1
Feb  6 01:58:50.408: INFO: Number of running nodes: 1, number of available pods: 1
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:64
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting {extensions DaemonSet} daemon-set in namespace e2e-tests-daemonsets-dhdlt, will wait for the garbage collector to delete the pods
Feb  6 01:58:50.507: INFO: Deleting {extensions DaemonSet} daemon-set took: 22.248395ms
Feb  6 01:58:50.607: INFO: Terminating {extensions DaemonSet} daemon-set pods took: 100.360001ms
Feb  6 01:59:24.529: INFO: Number of nodes with available pods: 0
Feb  6 01:59:24.529: INFO: Number of running nodes: 0, number of available pods: 0
Feb  6 01:59:24.539: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-dhdlt/daemonsets","resourceVersion":"49587"},"items":null}

Feb  6 01:59:24.551: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-dhdlt/pods","resourceVersion":"49587"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  6 01:59:24.604: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-dhdlt" for this suite.
Feb  6 01:59:30.806: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 01:59:31.000: INFO: namespace: e2e-tests-daemonsets-dhdlt, resource: bindings, ignored listing per whitelist
Feb  6 01:59:31.264: INFO: namespace e2e-tests-daemonsets-dhdlt deletion completed in 6.649647837s

• [SLOW TEST:88.370 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  6 01:59:31.266: INFO: >>> kubeConfig: /tmp/kubeconfig-131423863
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-87x8l
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating the pod
Feb  6 01:59:34.308: INFO: Successfully updated pod "labelsupdated80d68f6-29b2-11e9-9603-eaa511fa0b6c"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  6 01:59:36.364: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-87x8l" for this suite.
Feb  6 02:00:00.417: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 02:00:00.505: INFO: namespace: e2e-tests-downward-api-87x8l, resource: bindings, ignored listing per whitelist
Feb  6 02:00:00.793: INFO: namespace e2e-tests-downward-api-87x8l deletion completed in 24.414656167s

• [SLOW TEST:29.528 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-storage] ConfigMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  6 02:00:00.794: INFO: >>> kubeConfig: /tmp/kubeconfig-131423863
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-7pcv2
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-upd-e992f9e8-29b2-11e9-9603-eaa511fa0b6c
STEP: Creating the pod
STEP: Updating configmap configmap-test-upd-e992f9e8-29b2-11e9-9603-eaa511fa0b6c
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  6 02:00:05.244: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-7pcv2" for this suite.
Feb  6 02:00:29.306: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 02:00:29.605: INFO: namespace: e2e-tests-configmap-7pcv2, resource: bindings, ignored listing per whitelist
Feb  6 02:00:29.758: INFO: namespace e2e-tests-configmap-7pcv2 deletion completed in 24.500963465s

• [SLOW TEST:28.964 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  6 02:00:29.758: INFO: >>> kubeConfig: /tmp/kubeconfig-131423863
STEP: Building a namespace api object, basename containers
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-containers-9jz7d
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test override all
Feb  6 02:00:30.110: INFO: Waiting up to 5m0s for pod "client-containers-fad4389d-29b2-11e9-9603-eaa511fa0b6c" in namespace "e2e-tests-containers-9jz7d" to be "success or failure"
Feb  6 02:00:30.123: INFO: Pod "client-containers-fad4389d-29b2-11e9-9603-eaa511fa0b6c": Phase="Pending", Reason="", readiness=false. Elapsed: 13.37669ms
Feb  6 02:00:32.146: INFO: Pod "client-containers-fad4389d-29b2-11e9-9603-eaa511fa0b6c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.036633718s
STEP: Saw pod success
Feb  6 02:00:32.146: INFO: Pod "client-containers-fad4389d-29b2-11e9-9603-eaa511fa0b6c" satisfied condition "success or failure"
Feb  6 02:00:32.155: INFO: Trying to get logs from node 10.190.119.143 pod client-containers-fad4389d-29b2-11e9-9603-eaa511fa0b6c container test-container: <nil>
STEP: delete the pod
Feb  6 02:00:32.231: INFO: Waiting for pod client-containers-fad4389d-29b2-11e9-9603-eaa511fa0b6c to disappear
Feb  6 02:00:32.240: INFO: Pod client-containers-fad4389d-29b2-11e9-9603-eaa511fa0b6c no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  6 02:00:32.240: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-9jz7d" for this suite.
Feb  6 02:00:38.282: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 02:00:38.613: INFO: namespace: e2e-tests-containers-9jz7d, resource: bindings, ignored listing per whitelist
Feb  6 02:00:38.666: INFO: namespace e2e-tests-containers-9jz7d deletion completed in 6.413215712s

• [SLOW TEST:8.908 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[k8s.io] Pods 
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  6 02:00:38.667: INFO: >>> kubeConfig: /tmp/kubeconfig-131423863
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-pods-2fzhs
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating pod
Feb  6 02:00:41.273: INFO: Pod pod-hostip-0049a93f-29b3-11e9-9603-eaa511fa0b6c has hostIP: 10.190.119.184
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  6 02:00:41.273: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-2fzhs" for this suite.
Feb  6 02:01:05.318: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 02:01:05.645: INFO: namespace: e2e-tests-pods-2fzhs, resource: bindings, ignored listing per whitelist
Feb  6 02:01:05.680: INFO: namespace e2e-tests-pods-2fzhs deletion completed in 24.388022388s

• [SLOW TEST:27.013 seconds]
[k8s.io] Pods
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  6 02:01:05.680: INFO: >>> kubeConfig: /tmp/kubeconfig-131423863
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-lg875
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0666 on tmpfs
Feb  6 02:01:06.022: INFO: Waiting up to 5m0s for pod "pod-103feb7f-29b3-11e9-9603-eaa511fa0b6c" in namespace "e2e-tests-emptydir-lg875" to be "success or failure"
Feb  6 02:01:06.031: INFO: Pod "pod-103feb7f-29b3-11e9-9603-eaa511fa0b6c": Phase="Pending", Reason="", readiness=false. Elapsed: 8.818473ms
Feb  6 02:01:08.041: INFO: Pod "pod-103feb7f-29b3-11e9-9603-eaa511fa0b6c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.018247703s
STEP: Saw pod success
Feb  6 02:01:08.041: INFO: Pod "pod-103feb7f-29b3-11e9-9603-eaa511fa0b6c" satisfied condition "success or failure"
Feb  6 02:01:08.049: INFO: Trying to get logs from node 10.190.119.133 pod pod-103feb7f-29b3-11e9-9603-eaa511fa0b6c container test-container: <nil>
STEP: delete the pod
Feb  6 02:01:08.119: INFO: Waiting for pod pod-103feb7f-29b3-11e9-9603-eaa511fa0b6c to disappear
Feb  6 02:01:08.126: INFO: Pod pod-103feb7f-29b3-11e9-9603-eaa511fa0b6c no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  6 02:01:08.126: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-lg875" for this suite.
Feb  6 02:01:14.166: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 02:01:15.227: INFO: namespace: e2e-tests-emptydir-lg875, resource: bindings, ignored listing per whitelist
Feb  6 02:01:15.301: INFO: namespace e2e-tests-emptydir-lg875 deletion completed in 7.16242179s

• [SLOW TEST:9.621 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0666,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-storage] Projected 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  6 02:01:15.303: INFO: >>> kubeConfig: /tmp/kubeconfig-131423863
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-7fhc7
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb  6 02:01:15.632: INFO: Waiting up to 5m0s for pod "downwardapi-volume-15fa7501-29b3-11e9-9603-eaa511fa0b6c" in namespace "e2e-tests-projected-7fhc7" to be "success or failure"
Feb  6 02:01:15.642: INFO: Pod "downwardapi-volume-15fa7501-29b3-11e9-9603-eaa511fa0b6c": Phase="Pending", Reason="", readiness=false. Elapsed: 9.203933ms
Feb  6 02:01:17.665: INFO: Pod "downwardapi-volume-15fa7501-29b3-11e9-9603-eaa511fa0b6c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.032742723s
Feb  6 02:01:19.684: INFO: Pod "downwardapi-volume-15fa7501-29b3-11e9-9603-eaa511fa0b6c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.051918233s
STEP: Saw pod success
Feb  6 02:01:19.684: INFO: Pod "downwardapi-volume-15fa7501-29b3-11e9-9603-eaa511fa0b6c" satisfied condition "success or failure"
Feb  6 02:01:19.693: INFO: Trying to get logs from node 10.190.119.143 pod downwardapi-volume-15fa7501-29b3-11e9-9603-eaa511fa0b6c container client-container: <nil>
STEP: delete the pod
Feb  6 02:01:19.743: INFO: Waiting for pod downwardapi-volume-15fa7501-29b3-11e9-9603-eaa511fa0b6c to disappear
Feb  6 02:01:19.800: INFO: Pod downwardapi-volume-15fa7501-29b3-11e9-9603-eaa511fa0b6c no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  6 02:01:19.800: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-7fhc7" for this suite.
Feb  6 02:01:25.840: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 02:01:26.036: INFO: namespace: e2e-tests-projected-7fhc7, resource: bindings, ignored listing per whitelist
Feb  6 02:01:26.190: INFO: namespace e2e-tests-projected-7fhc7 deletion completed in 6.376976972s

• [SLOW TEST:10.887 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] ConfigMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  6 02:01:26.190: INFO: >>> kubeConfig: /tmp/kubeconfig-131423863
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-cq44v
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name cm-test-opt-del-1c7d7041-29b3-11e9-9603-eaa511fa0b6c
STEP: Creating configMap with name cm-test-opt-upd-1c7d7088-29b3-11e9-9603-eaa511fa0b6c
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-1c7d7041-29b3-11e9-9603-eaa511fa0b6c
STEP: Updating configmap cm-test-opt-upd-1c7d7088-29b3-11e9-9603-eaa511fa0b6c
STEP: Creating configMap with name cm-test-opt-create-1c7d70a7-29b3-11e9-9603-eaa511fa0b6c
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  6 02:02:32.332: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-cq44v" for this suite.
Feb  6 02:02:56.375: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 02:02:56.610: INFO: namespace: e2e-tests-configmap-cq44v, resource: bindings, ignored listing per whitelist
Feb  6 02:02:57.118: INFO: namespace e2e-tests-configmap-cq44v deletion completed in 24.771098238s

• [SLOW TEST:90.928 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  6 02:02:57.119: INFO: >>> kubeConfig: /tmp/kubeconfig-131423863
STEP: Building a namespace api object, basename init-container
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-init-container-xp2z5
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
Feb  6 02:02:57.414: INFO: PodSpec: initContainers in spec.initContainers
Feb  6 02:03:45.246: INFO: init container has failed twice: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-init-52a8270d-29b3-11e9-9603-eaa511fa0b6c", GenerateName:"", Namespace:"e2e-tests-init-container-xp2z5", SelfLink:"/api/v1/namespaces/e2e-tests-init-container-xp2z5/pods/pod-init-52a8270d-29b3-11e9-9603-eaa511fa0b6c", UID:"52a96b86-29b3-11e9-bf83-6639c2940cda", ResourceVersion:"50378", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63685015377, loc:(*time.Location)(0x6c43b60)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"414743001"}, Annotations:map[string]string{"kubernetes.io/psp":"e2e-test-privileged-psp"}, OwnerReferences:[]v1.OwnerReference(nil), Initializers:(*v1.Initializers)(nil), Finalizers:[]string(nil), ClusterName:""}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"default-token-spw96", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(0xc421a42180), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil)}}}, InitContainers:[]v1.Container{v1.Container{Name:"init1", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/false"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-spw96", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}, v1.Container{Name:"init2", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/true"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-spw96", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, Containers:[]v1.Container{v1.Container{Name:"run1", Image:"k8s.gcr.io/pause:3.1", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}, Requests:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-spw96", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc420fbe808), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"10.190.119.184", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc421df0060), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc420fbe900)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc420fbe950)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc420fbe958), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil)}, Status:v1.PodStatus{Phase:"Pending", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63685015377, loc:(*time.Location)(0x6c43b60)}}, Reason:"ContainersNotInitialized", Message:"containers with incomplete status: [init1 init2]"}, v1.PodCondition{Type:"Ready", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63685015377, loc:(*time.Location)(0x6c43b60)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"ContainersReady", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63685015377, loc:(*time.Location)(0x6c43b60)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63685015377, loc:(*time.Location)(0x6c43b60)}}, Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"10.190.119.184", PodIP:"172.30.242.36", StartTime:(*v1.Time)(0xc420e52200), InitContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"init1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc42121c380)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc42121c460)}, Ready:false, RestartCount:3, Image:"docker.io/library/busybox:1.29", ImageID:"docker.io/library/busybox@sha256:8ccbac733d19c0dd4d70b4f0c1e12245b5fa3ad24758a11035ee505c629c0796", ContainerID:"containerd://247b7743960a61aec1ea3392cd660a98feeca21d6bff11a0a46e44e1182d6b29"}, v1.ContainerStatus{Name:"init2", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc420e52240), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"docker.io/library/busybox:1.29", ImageID:"", ContainerID:""}}, ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"run1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc420e52220), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"k8s.gcr.io/pause:3.1", ImageID:"", ContainerID:""}}, QOSClass:"Guaranteed"}}
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  6 02:03:45.246: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-init-container-xp2z5" for this suite.
Feb  6 02:04:07.321: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 02:04:07.548: INFO: namespace: e2e-tests-init-container-xp2z5, resource: bindings, ignored listing per whitelist
Feb  6 02:04:07.652: INFO: namespace e2e-tests-init-container-xp2z5 deletion completed in 22.376825737s

• [SLOW TEST:70.534 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl logs 
  should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  6 02:04:07.653: INFO: >>> kubeConfig: /tmp/kubeconfig-131423863
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-vt87s
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Kubectl logs
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1083
STEP: creating an rc
Feb  6 02:04:08.122: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-131423863 create -f - --namespace=e2e-tests-kubectl-vt87s'
Feb  6 02:04:08.450: INFO: stderr: ""
Feb  6 02:04:08.450: INFO: stdout: "replicationcontroller/redis-master created\n"
[It] should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Waiting for Redis master to start.
Feb  6 02:04:09.463: INFO: Selector matched 1 pods for map[app:redis]
Feb  6 02:04:09.463: INFO: Found 0 / 1
Feb  6 02:04:10.467: INFO: Selector matched 1 pods for map[app:redis]
Feb  6 02:04:10.467: INFO: Found 1 / 1
Feb  6 02:04:10.467: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Feb  6 02:04:10.480: INFO: Selector matched 1 pods for map[app:redis]
Feb  6 02:04:10.480: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
STEP: checking for a matching strings
Feb  6 02:04:10.480: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-131423863 logs redis-master-j6tvq redis-master --namespace=e2e-tests-kubectl-vt87s'
Feb  6 02:04:10.718: INFO: stderr: ""
Feb  6 02:04:10.718: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 06 Feb 02:04:09.482 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 06 Feb 02:04:09.482 # Server started, Redis version 3.2.12\n1:M 06 Feb 02:04:09.482 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 06 Feb 02:04:09.482 * The server is now ready to accept connections on port 6379\n"
STEP: limiting log lines
Feb  6 02:04:10.718: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-131423863 log redis-master-j6tvq redis-master --namespace=e2e-tests-kubectl-vt87s --tail=1'
Feb  6 02:04:10.866: INFO: stderr: ""
Feb  6 02:04:10.866: INFO: stdout: "1:M 06 Feb 02:04:09.482 * The server is now ready to accept connections on port 6379\n"
STEP: limiting log bytes
Feb  6 02:04:10.866: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-131423863 log redis-master-j6tvq redis-master --namespace=e2e-tests-kubectl-vt87s --limit-bytes=1'
Feb  6 02:04:11.008: INFO: stderr: ""
Feb  6 02:04:11.008: INFO: stdout: " "
STEP: exposing timestamps
Feb  6 02:04:11.008: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-131423863 log redis-master-j6tvq redis-master --namespace=e2e-tests-kubectl-vt87s --tail=1 --timestamps'
Feb  6 02:04:11.196: INFO: stderr: ""
Feb  6 02:04:11.196: INFO: stdout: "2019-02-06T02:04:09.482960683Z 1:M 06 Feb 02:04:09.482 * The server is now ready to accept connections on port 6379\n"
STEP: restricting to a time range
Feb  6 02:04:13.697: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-131423863 log redis-master-j6tvq redis-master --namespace=e2e-tests-kubectl-vt87s --since=1s'
Feb  6 02:04:13.916: INFO: stderr: ""
Feb  6 02:04:13.916: INFO: stdout: ""
Feb  6 02:04:13.916: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-131423863 log redis-master-j6tvq redis-master --namespace=e2e-tests-kubectl-vt87s --since=24h'
Feb  6 02:04:14.058: INFO: stderr: ""
Feb  6 02:04:14.058: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 06 Feb 02:04:09.482 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 06 Feb 02:04:09.482 # Server started, Redis version 3.2.12\n1:M 06 Feb 02:04:09.482 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 06 Feb 02:04:09.482 * The server is now ready to accept connections on port 6379\n"
[AfterEach] [k8s.io] Kubectl logs
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1088
STEP: using delete to clean up resources
Feb  6 02:04:14.058: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-131423863 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-vt87s'
Feb  6 02:04:14.216: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Feb  6 02:04:14.216: INFO: stdout: "replicationcontroller \"redis-master\" force deleted\n"
Feb  6 02:04:14.216: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-131423863 get rc,svc -l name=nginx --no-headers --namespace=e2e-tests-kubectl-vt87s'
Feb  6 02:04:14.356: INFO: stderr: "No resources found.\n"
Feb  6 02:04:14.356: INFO: stdout: ""
Feb  6 02:04:14.356: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-131423863 get pods -l name=nginx --namespace=e2e-tests-kubectl-vt87s -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Feb  6 02:04:14.539: INFO: stderr: ""
Feb  6 02:04:14.539: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  6 02:04:14.539: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-vt87s" for this suite.
Feb  6 02:04:20.580: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 02:04:20.704: INFO: namespace: e2e-tests-kubectl-vt87s, resource: bindings, ignored listing per whitelist
Feb  6 02:04:21.021: INFO: namespace e2e-tests-kubectl-vt87s deletion completed in 6.46593047s

• [SLOW TEST:13.368 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl logs
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should be able to retrieve and filter logs  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  6 02:04:21.021: INFO: >>> kubeConfig: /tmp/kubeconfig-131423863
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-container-lifecycle-hook-g5cwv
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Feb  6 02:04:25.455: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Feb  6 02:04:25.463: INFO: Pod pod-with-poststart-http-hook still exists
Feb  6 02:04:27.463: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Feb  6 02:04:27.473: INFO: Pod pod-with-poststart-http-hook still exists
Feb  6 02:04:29.463: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Feb  6 02:04:29.492: INFO: Pod pod-with-poststart-http-hook still exists
Feb  6 02:04:31.463: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Feb  6 02:04:31.473: INFO: Pod pod-with-poststart-http-hook still exists
Feb  6 02:04:33.463: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Feb  6 02:04:33.472: INFO: Pod pod-with-poststart-http-hook still exists
Feb  6 02:04:35.463: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Feb  6 02:04:35.473: INFO: Pod pod-with-poststart-http-hook still exists
Feb  6 02:04:37.463: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Feb  6 02:04:37.473: INFO: Pod pod-with-poststart-http-hook still exists
Feb  6 02:04:39.463: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Feb  6 02:04:39.472: INFO: Pod pod-with-poststart-http-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  6 02:04:39.472: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-lifecycle-hook-g5cwv" for this suite.
Feb  6 02:05:03.540: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 02:05:03.594: INFO: namespace: e2e-tests-container-lifecycle-hook-g5cwv, resource: bindings, ignored listing per whitelist
Feb  6 02:05:04.015: INFO: namespace e2e-tests-container-lifecycle-hook-g5cwv deletion completed in 24.530913983s

• [SLOW TEST:42.994 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when create a pod with lifecycle hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute poststart http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  6 02:05:04.017: INFO: >>> kubeConfig: /tmp/kubeconfig-131423863
STEP: Building a namespace api object, basename init-container
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-init-container-bv55w
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
Feb  6 02:05:04.424: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  6 02:05:07.616: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-init-container-bv55w" for this suite.
Feb  6 02:05:15.699: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 02:05:16.005: INFO: namespace: e2e-tests-init-container-bv55w, resource: bindings, ignored listing per whitelist
Feb  6 02:05:16.014: INFO: namespace e2e-tests-init-container-bv55w deletion completed in 8.38607336s

• [SLOW TEST:11.998 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Secrets 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  6 02:05:16.015: INFO: >>> kubeConfig: /tmp/kubeconfig-131423863
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-secrets-wd5c2
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name s-test-opt-del-a5eb00a4-29b3-11e9-9603-eaa511fa0b6c
STEP: Creating secret with name s-test-opt-upd-a5eb00ea-29b3-11e9-9603-eaa511fa0b6c
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-a5eb00a4-29b3-11e9-9603-eaa511fa0b6c
STEP: Updating secret s-test-opt-upd-a5eb00ea-29b3-11e9-9603-eaa511fa0b6c
STEP: Creating secret with name s-test-opt-create-a5eb0106-29b3-11e9-9603-eaa511fa0b6c
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  6 02:05:21.396: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-wd5c2" for this suite.
Feb  6 02:05:45.435: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 02:05:45.714: INFO: namespace: e2e-tests-secrets-wd5c2, resource: bindings, ignored listing per whitelist
Feb  6 02:05:45.787: INFO: namespace e2e-tests-secrets-wd5c2 deletion completed in 24.379260911s

• [SLOW TEST:29.772 seconds]
[sig-storage] Secrets
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Proxy server 
  should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  6 02:05:45.788: INFO: >>> kubeConfig: /tmp/kubeconfig-131423863
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-mst5l
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: starting the proxy server
Feb  6 02:05:46.204: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-131423863 proxy -p 0 --disable-filter'
STEP: curling proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  6 02:05:46.322: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-mst5l" for this suite.
Feb  6 02:05:52.422: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 02:05:52.973: INFO: namespace: e2e-tests-kubectl-mst5l, resource: bindings, ignored listing per whitelist
Feb  6 02:05:53.098: INFO: namespace e2e-tests-kubectl-mst5l deletion completed in 6.706320638s

• [SLOW TEST:7.310 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Proxy server
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should support proxy with --port 0  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  6 02:05:53.098: INFO: >>> kubeConfig: /tmp/kubeconfig-131423863
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-daemonsets-8d6vs
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:98
[It] should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb  6 02:05:53.521: INFO: Requires at least 2 nodes (not -1)
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:64
Feb  6 02:05:53.537: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-8d6vs/daemonsets","resourceVersion":"50831"},"items":null}

Feb  6 02:05:53.546: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-8d6vs/pods","resourceVersion":"50831"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  6 02:05:53.588: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-8d6vs" for this suite.
Feb  6 02:05:59.625: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 02:05:59.829: INFO: namespace: e2e-tests-daemonsets-8d6vs, resource: bindings, ignored listing per whitelist
Feb  6 02:05:59.980: INFO: namespace e2e-tests-daemonsets-8d6vs deletion completed in 6.38167054s

S [SKIPPING] [6.882 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should rollback without unnecessary restarts [Conformance] [It]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699

  Feb  6 02:05:53.521: Requires at least 2 nodes (not -1)

  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/util.go:292
------------------------------
SSSS
------------------------------
[sig-storage] Projected 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  6 02:05:59.980: INFO: >>> kubeConfig: /tmp/kubeconfig-131423863
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-4vxfh
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-bfa69064-29b3-11e9-9603-eaa511fa0b6c
STEP: Creating a pod to test consume configMaps
Feb  6 02:06:00.303: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-bfa81259-29b3-11e9-9603-eaa511fa0b6c" in namespace "e2e-tests-projected-4vxfh" to be "success or failure"
Feb  6 02:06:00.311: INFO: Pod "pod-projected-configmaps-bfa81259-29b3-11e9-9603-eaa511fa0b6c": Phase="Pending", Reason="", readiness=false. Elapsed: 7.676922ms
Feb  6 02:06:02.320: INFO: Pod "pod-projected-configmaps-bfa81259-29b3-11e9-9603-eaa511fa0b6c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.016400324s
STEP: Saw pod success
Feb  6 02:06:02.320: INFO: Pod "pod-projected-configmaps-bfa81259-29b3-11e9-9603-eaa511fa0b6c" satisfied condition "success or failure"
Feb  6 02:06:02.328: INFO: Trying to get logs from node 10.190.119.133 pod pod-projected-configmaps-bfa81259-29b3-11e9-9603-eaa511fa0b6c container projected-configmap-volume-test: <nil>
STEP: delete the pod
Feb  6 02:06:02.390: INFO: Waiting for pod pod-projected-configmaps-bfa81259-29b3-11e9-9603-eaa511fa0b6c to disappear
Feb  6 02:06:02.400: INFO: Pod pod-projected-configmaps-bfa81259-29b3-11e9-9603-eaa511fa0b6c no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  6 02:06:02.400: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-4vxfh" for this suite.
Feb  6 02:06:08.446: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 02:06:08.494: INFO: namespace: e2e-tests-projected-4vxfh, resource: bindings, ignored listing per whitelist
Feb  6 02:06:09.518: INFO: namespace e2e-tests-projected-4vxfh deletion completed in 7.102355583s

• [SLOW TEST:9.537 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl describe 
  should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  6 02:06:09.518: INFO: >>> kubeConfig: /tmp/kubeconfig-131423863
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-q7d56
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb  6 02:06:10.016: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-131423863 version --client'
Feb  6 02:06:10.088: INFO: stderr: ""
Feb  6 02:06:10.088: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"12\", GitVersion:\"v1.12.1\", GitCommit:\"4ed3216f3ec431b140b1d899130a69fc671678f4\", GitTreeState:\"clean\", BuildDate:\"2018-10-05T16:46:06Z\", GoVersion:\"go1.10.4\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
Feb  6 02:06:10.091: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-131423863 create -f - --namespace=e2e-tests-kubectl-q7d56'
Feb  6 02:06:10.670: INFO: stderr: ""
Feb  6 02:06:10.670: INFO: stdout: "replicationcontroller/redis-master created\n"
Feb  6 02:06:10.670: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-131423863 create -f - --namespace=e2e-tests-kubectl-q7d56'
Feb  6 02:06:11.073: INFO: stderr: ""
Feb  6 02:06:11.073: INFO: stdout: "service/redis-master created\n"
STEP: Waiting for Redis master to start.
Feb  6 02:06:12.082: INFO: Selector matched 1 pods for map[app:redis]
Feb  6 02:06:12.082: INFO: Found 0 / 1
Feb  6 02:06:13.085: INFO: Selector matched 1 pods for map[app:redis]
Feb  6 02:06:13.085: INFO: Found 1 / 1
Feb  6 02:06:13.085: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Feb  6 02:06:13.097: INFO: Selector matched 1 pods for map[app:redis]
Feb  6 02:06:13.097: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Feb  6 02:06:13.097: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-131423863 describe pod redis-master-9vr47 --namespace=e2e-tests-kubectl-q7d56'
Feb  6 02:06:13.253: INFO: stderr: ""
Feb  6 02:06:13.253: INFO: stdout: "Name:               redis-master-9vr47\nNamespace:          e2e-tests-kubectl-q7d56\nPriority:           0\nPriorityClassName:  <none>\nNode:               10.190.119.143/10.190.119.143\nStart Time:         Wed, 06 Feb 2019 02:06:10 +0000\nLabels:             app=redis\n                    role=master\nAnnotations:        kubernetes.io/psp: e2e-test-privileged-psp\nStatus:             Running\nIP:                 172.30.134.246\nControlled By:      ReplicationController/redis-master\nContainers:\n  redis-master:\n    Container ID:   containerd://5d7e006a38b3a98eb3bce4ee0f26d22ddd3cc45436c3b79c71c4ef46fec6205a\n    Image:          gcr.io/kubernetes-e2e-test-images/redis:1.0\n    Image ID:       gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830\n    Port:           6379/TCP\n    Host Port:      0/TCP\n    State:          Running\n      Started:      Wed, 06 Feb 2019 02:06:11 +0000\n    Ready:          True\n    Restart Count:  0\n    Environment:    <none>\n    Mounts:\n      /var/run/secrets/kubernetes.io/serviceaccount from default-token-tdpdb (ro)\nConditions:\n  Type              Status\n  Initialized       True \n  Ready             True \n  ContainersReady   True \n  PodScheduled      True \nVolumes:\n  default-token-tdpdb:\n    Type:        Secret (a volume populated by a Secret)\n    SecretName:  default-token-tdpdb\n    Optional:    false\nQoS Class:       BestEffort\nNode-Selectors:  <none>\nTolerations:     node.kubernetes.io/not-ready:NoExecute for 300s\n                 node.kubernetes.io/unreachable:NoExecute for 300s\nEvents:\n  Type    Reason     Age   From                     Message\n  ----    ------     ----  ----                     -------\n  Normal  Scheduled  3s    default-scheduler        Successfully assigned e2e-tests-kubectl-q7d56/redis-master-9vr47 to 10.190.119.143\n  Normal  Pulled     2s    kubelet, 10.190.119.143  Container image \"gcr.io/kubernetes-e2e-test-images/redis:1.0\" already present on machine\n  Normal  Created    2s    kubelet, 10.190.119.143  Created container\n  Normal  Started    2s    kubelet, 10.190.119.143  Started container\n"
Feb  6 02:06:13.253: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-131423863 describe rc redis-master --namespace=e2e-tests-kubectl-q7d56'
Feb  6 02:06:13.524: INFO: stderr: ""
Feb  6 02:06:13.524: INFO: stdout: "Name:         redis-master\nNamespace:    e2e-tests-kubectl-q7d56\nSelector:     app=redis,role=master\nLabels:       app=redis\n              role=master\nAnnotations:  <none>\nReplicas:     1 current / 1 desired\nPods Status:  1 Running / 0 Waiting / 0 Succeeded / 0 Failed\nPod Template:\n  Labels:  app=redis\n           role=master\n  Containers:\n   redis-master:\n    Image:        gcr.io/kubernetes-e2e-test-images/redis:1.0\n    Port:         6379/TCP\n    Host Port:    0/TCP\n    Environment:  <none>\n    Mounts:       <none>\n  Volumes:        <none>\nEvents:\n  Type    Reason            Age   From                    Message\n  ----    ------            ----  ----                    -------\n  Normal  SuccessfulCreate  3s    replication-controller  Created pod: redis-master-9vr47\n"
Feb  6 02:06:13.525: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-131423863 describe service redis-master --namespace=e2e-tests-kubectl-q7d56'
Feb  6 02:06:13.709: INFO: stderr: ""
Feb  6 02:06:13.709: INFO: stdout: "Name:              redis-master\nNamespace:         e2e-tests-kubectl-q7d56\nLabels:            app=redis\n                   role=master\nAnnotations:       <none>\nSelector:          app=redis,role=master\nType:              ClusterIP\nIP:                172.21.22.110\nPort:              <unset>  6379/TCP\nTargetPort:        redis-server/TCP\nEndpoints:         172.30.134.246:6379\nSession Affinity:  None\nEvents:            <none>\n"
Feb  6 02:06:13.722: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-131423863 describe node 10.190.119.133'
Feb  6 02:06:13.900: INFO: stderr: ""
Feb  6 02:06:13.900: INFO: stdout: "Name:               10.190.119.133\nRoles:              <none>\nLabels:             arch=amd64\n                    beta.kubernetes.io/arch=amd64\n                    beta.kubernetes.io/instance-type=u2c.2x4.encrypted\n                    beta.kubernetes.io/os=linux\n                    failure-domain.beta.kubernetes.io/region=us-east\n                    failure-domain.beta.kubernetes.io/zone=wdc07\n                    ibm-cloud.kubernetes.io/encrypted-docker-data=true\n                    ibm-cloud.kubernetes.io/ha-worker=true\n                    ibm-cloud.kubernetes.io/iaas-provider=softlayer\n                    ibm-cloud.kubernetes.io/machine-type=u2c.2x4.encrypted\n                    ibm-cloud.kubernetes.io/sgx-enabled=false\n                    ibm-cloud.kubernetes.io/worker-pool-id=f54ba0a8e6a945a29dcf052ae5eb4941-d44cb62\n                    ibm-cloud.kubernetes.io/worker-version=1.12.5_1537\n                    kubernetes.io/hostname=10.190.119.133\n                    privateVLAN=2540259\n                    publicVLAN=2540257\nAnnotations:        node.alpha.kubernetes.io/ttl: 0\n                    volumes.kubernetes.io/controller-managed-attach-detach: true\nCreationTimestamp:  Tue, 05 Feb 2019 20:41:39 +0000\nTaints:             <none>\nUnschedulable:      false\nConditions:\n  Type             Status  LastHeartbeatTime                 LastTransitionTime                Reason                       Message\n  ----             ------  -----------------                 ------------------                ------                       -------\n  OutOfDisk        False   Wed, 06 Feb 2019 02:06:04 +0000   Tue, 05 Feb 2019 20:41:39 +0000   KubeletHasSufficientDisk     kubelet has sufficient disk space available\n  MemoryPressure   False   Wed, 06 Feb 2019 02:06:04 +0000   Tue, 05 Feb 2019 20:41:39 +0000   KubeletHasSufficientMemory   kubelet has sufficient memory available\n  DiskPressure     False   Wed, 06 Feb 2019 02:06:04 +0000   Tue, 05 Feb 2019 20:41:39 +0000   KubeletHasNoDiskPressure     kubelet has no disk pressure\n  PIDPressure      False   Wed, 06 Feb 2019 02:06:04 +0000   Tue, 05 Feb 2019 20:41:39 +0000   KubeletHasSufficientPID      kubelet has sufficient PID available\n  Ready            True    Wed, 06 Feb 2019 02:06:04 +0000   Tue, 05 Feb 2019 20:41:59 +0000   KubeletReady                 kubelet is posting ready status. AppArmor enabled\nAddresses:\n  InternalIP:  10.190.119.133\n  ExternalIP:  169.61.92.98\n  Hostname:    10.190.119.133\nCapacity:\n cpu:                2\n ephemeral-storage:  103079200Ki\n hugepages-1Gi:      0\n hugepages-2Mi:      0\n memory:             4045056Ki\n pods:               110\nAllocatable:\n cpu:                1920m\n ephemeral-storage:  100275445682\n hugepages-1Gi:      0\n hugepages-2Mi:      0\n memory:             3538176Ki\n pods:               110\nSystem Info:\n Machine ID:                 266c2075dace453da02500b328c9e325\n System UUID:                1CF15A3E-10FE-992D-8533-B9E6445E91E8\n Boot ID:                    486dfbfe-cc39-4482-984c-da77f067702b\n Kernel Version:             4.4.0-141-generic\n OS Image:                   Ubuntu 16.04.5 LTS\n Operating System:           linux\n Architecture:               amd64\n Container Runtime Version:  containerd://1.1.5\n Kubelet Version:            v1.12.5+IKS\n Kube-Proxy Version:         v1.12.5+IKS\nProviderID:                  ibm://d18c889395112a40d2f4e3065f237a7d///f54ba0a8e6a945a29dcf052ae5eb4941/kube-wdc07-crf54ba0a8e6a945a29dcf052ae5eb4941-w1\nNon-terminated Pods:         (8 in total)\n  Namespace                  Name                                                               CPU Requests  CPU Limits  Memory Requests  Memory Limits\n  ---------                  ----                                                               ------------  ----------  ---------------  -------------\n  heptio-sonobuoy            sonobuoy-systemd-logs-daemon-set-d5b52e18812640c6-b9jsg            0 (0%)        0 (0%)      0 (0%)           0 (0%)\n  ibm-system                 ibm-cloud-provider-ip-169-61-69-214-6d655b596d-zg2pn               5m (0%)       0 (0%)      10Mi (0%)        0 (0%)\n  kube-system                calico-node-crvvm                                                  255m (13%)    0 (0%)      85Mi (2%)        0 (0%)\n  kube-system                ibm-keepalived-watcher-bsbdb                                       5m (0%)       0 (0%)      10Mi (0%)        0 (0%)\n  kube-system                ibm-kube-fluentd-64s4c                                             25m (1%)      300m (15%)  50Mi (1%)        800M (22%)\n  kube-system                ibm-master-proxy-static-10.190.119.133                             25m (1%)      300m (15%)  32M (0%)         512M (14%)\n  kube-system                kube-dns-amd64-fddfcc69-g2lwr                                      260m (13%)    0 (0%)      110Mi (3%)       170Mi (4%)\n  kube-system                public-crf54ba0a8e6a945a29dcf052ae5eb4941-alb1-6c9c6d49c8-mpnh2    0 (0%)        0 (0%)      0 (0%)           0 (0%)\nAllocated resources:\n  (Total limits may be over 100 percent, i.e., overcommitted.)\n  Resource  Requests       Limits\n  --------  --------       ------\n  cpu       575m (29%)     600m (31%)\n  memory    302610Ki (8%)  1490257920 (41%)\nEvents:     <none>\n"
Feb  6 02:06:13.900: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-131423863 describe namespace e2e-tests-kubectl-q7d56'
Feb  6 02:06:14.111: INFO: stderr: ""
Feb  6 02:06:14.111: INFO: stdout: "Name:         e2e-tests-kubectl-q7d56\nLabels:       e2e-framework=kubectl\n              e2e-run=e14770b0-29b1-11e9-9603-eaa511fa0b6c\nAnnotations:  <none>\nStatus:       Active\n\nNo resource quota.\n\nNo resource limits.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  6 02:06:14.111: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-q7d56" for this suite.
Feb  6 02:06:38.154: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 02:06:38.272: INFO: namespace: e2e-tests-kubectl-q7d56, resource: bindings, ignored listing per whitelist
Feb  6 02:06:38.530: INFO: namespace e2e-tests-kubectl-q7d56 deletion completed in 24.404943539s

• [SLOW TEST:29.012 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl describe
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should check if kubectl describe prints relevant information for rc and pods  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  6 02:06:38.530: INFO: >>> kubeConfig: /tmp/kubeconfig-131423863
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-subpath-jf99m
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with configmap pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-configmap-fgrd
STEP: Creating a pod to test atomic-volume-subpath
Feb  6 02:06:38.877: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-fgrd" in namespace "e2e-tests-subpath-jf99m" to be "success or failure"
Feb  6 02:06:38.886: INFO: Pod "pod-subpath-test-configmap-fgrd": Phase="Pending", Reason="", readiness=false. Elapsed: 9.428847ms
Feb  6 02:06:40.917: INFO: Pod "pod-subpath-test-configmap-fgrd": Phase="Pending", Reason="", readiness=false. Elapsed: 2.040114885s
Feb  6 02:06:43.315: INFO: Pod "pod-subpath-test-configmap-fgrd": Phase="Running", Reason="", readiness=false. Elapsed: 4.437746375s
Feb  6 02:06:45.324: INFO: Pod "pod-subpath-test-configmap-fgrd": Phase="Running", Reason="", readiness=false. Elapsed: 6.447271113s
Feb  6 02:06:47.401: INFO: Pod "pod-subpath-test-configmap-fgrd": Phase="Running", Reason="", readiness=false. Elapsed: 8.524466158s
Feb  6 02:06:49.410: INFO: Pod "pod-subpath-test-configmap-fgrd": Phase="Running", Reason="", readiness=false. Elapsed: 10.533356736s
Feb  6 02:06:51.434: INFO: Pod "pod-subpath-test-configmap-fgrd": Phase="Running", Reason="", readiness=false. Elapsed: 12.557449185s
Feb  6 02:06:53.443: INFO: Pod "pod-subpath-test-configmap-fgrd": Phase="Running", Reason="", readiness=false. Elapsed: 14.565852392s
Feb  6 02:06:55.453: INFO: Pod "pod-subpath-test-configmap-fgrd": Phase="Running", Reason="", readiness=false. Elapsed: 16.57594673s
Feb  6 02:06:57.466: INFO: Pod "pod-subpath-test-configmap-fgrd": Phase="Running", Reason="", readiness=false. Elapsed: 18.589411357s
Feb  6 02:06:59.480: INFO: Pod "pod-subpath-test-configmap-fgrd": Phase="Running", Reason="", readiness=false. Elapsed: 20.603247029s
Feb  6 02:07:02.074: INFO: Pod "pod-subpath-test-configmap-fgrd": Phase="Succeeded", Reason="", readiness=false. Elapsed: 23.19729126s
STEP: Saw pod success
Feb  6 02:07:02.074: INFO: Pod "pod-subpath-test-configmap-fgrd" satisfied condition "success or failure"
Feb  6 02:07:02.100: INFO: Trying to get logs from node 10.190.119.184 pod pod-subpath-test-configmap-fgrd container test-container-subpath-configmap-fgrd: <nil>
STEP: delete the pod
Feb  6 02:07:02.191: INFO: Waiting for pod pod-subpath-test-configmap-fgrd to disappear
Feb  6 02:07:02.199: INFO: Pod pod-subpath-test-configmap-fgrd no longer exists
STEP: Deleting pod pod-subpath-test-configmap-fgrd
Feb  6 02:07:02.199: INFO: Deleting pod "pod-subpath-test-configmap-fgrd" in namespace "e2e-tests-subpath-jf99m"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  6 02:07:02.208: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-jf99m" for this suite.
Feb  6 02:07:08.255: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 02:07:08.316: INFO: namespace: e2e-tests-subpath-jf99m, resource: bindings, ignored listing per whitelist
Feb  6 02:07:08.573: INFO: namespace e2e-tests-subpath-jf99m deletion completed in 6.352157029s

• [SLOW TEST:30.043 seconds]
[sig-storage] Subpath
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with configmap pod [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Projected 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  6 02:07:08.575: INFO: >>> kubeConfig: /tmp/kubeconfig-131423863
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-kf97l
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb  6 02:07:09.010: INFO: Waiting up to 5m0s for pod "downwardapi-volume-e88dba5c-29b3-11e9-9603-eaa511fa0b6c" in namespace "e2e-tests-projected-kf97l" to be "success or failure"
Feb  6 02:07:09.019: INFO: Pod "downwardapi-volume-e88dba5c-29b3-11e9-9603-eaa511fa0b6c": Phase="Pending", Reason="", readiness=false. Elapsed: 8.736708ms
Feb  6 02:07:11.029: INFO: Pod "downwardapi-volume-e88dba5c-29b3-11e9-9603-eaa511fa0b6c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.019225995s
STEP: Saw pod success
Feb  6 02:07:11.030: INFO: Pod "downwardapi-volume-e88dba5c-29b3-11e9-9603-eaa511fa0b6c" satisfied condition "success or failure"
Feb  6 02:07:11.038: INFO: Trying to get logs from node 10.190.119.133 pod downwardapi-volume-e88dba5c-29b3-11e9-9603-eaa511fa0b6c container client-container: <nil>
STEP: delete the pod
Feb  6 02:07:11.092: INFO: Waiting for pod downwardapi-volume-e88dba5c-29b3-11e9-9603-eaa511fa0b6c to disappear
Feb  6 02:07:11.101: INFO: Pod downwardapi-volume-e88dba5c-29b3-11e9-9603-eaa511fa0b6c no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  6 02:07:11.101: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-kf97l" for this suite.
Feb  6 02:07:17.219: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 02:07:17.581: INFO: namespace: e2e-tests-projected-kf97l, resource: bindings, ignored listing per whitelist
Feb  6 02:07:17.597: INFO: namespace e2e-tests-projected-kf97l deletion completed in 6.405074117s

• [SLOW TEST:9.022 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  6 02:07:17.601: INFO: >>> kubeConfig: /tmp/kubeconfig-131423863
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-vfks2
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating the pod
Feb  6 02:07:20.638: INFO: Successfully updated pod "annotationupdateedea95cf-29b3-11e9-9603-eaa511fa0b6c"
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  6 02:07:24.747: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-vfks2" for this suite.
Feb  6 02:07:49.146: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 02:07:49.498: INFO: namespace: e2e-tests-projected-vfks2, resource: bindings, ignored listing per whitelist
Feb  6 02:07:49.510: INFO: namespace e2e-tests-projected-vfks2 deletion completed in 24.749911222s

• [SLOW TEST:31.909 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] ConfigMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  6 02:07:49.511: INFO: >>> kubeConfig: /tmp/kubeconfig-131423863
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-cxwxp
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-00f248d3-29b4-11e9-9603-eaa511fa0b6c
STEP: Creating a pod to test consume configMaps
Feb  6 02:07:49.910: INFO: Waiting up to 5m0s for pod "pod-configmaps-00fc9e7a-29b4-11e9-9603-eaa511fa0b6c" in namespace "e2e-tests-configmap-cxwxp" to be "success or failure"
Feb  6 02:07:49.918: INFO: Pod "pod-configmaps-00fc9e7a-29b4-11e9-9603-eaa511fa0b6c": Phase="Pending", Reason="", readiness=false. Elapsed: 8.510349ms
Feb  6 02:07:51.934: INFO: Pod "pod-configmaps-00fc9e7a-29b4-11e9-9603-eaa511fa0b6c": Phase="Running", Reason="", readiness=true. Elapsed: 2.024021231s
Feb  6 02:07:53.945: INFO: Pod "pod-configmaps-00fc9e7a-29b4-11e9-9603-eaa511fa0b6c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.035057262s
STEP: Saw pod success
Feb  6 02:07:53.945: INFO: Pod "pod-configmaps-00fc9e7a-29b4-11e9-9603-eaa511fa0b6c" satisfied condition "success or failure"
Feb  6 02:07:53.954: INFO: Trying to get logs from node 10.190.119.184 pod pod-configmaps-00fc9e7a-29b4-11e9-9603-eaa511fa0b6c container configmap-volume-test: <nil>
STEP: delete the pod
Feb  6 02:07:54.005: INFO: Waiting for pod pod-configmaps-00fc9e7a-29b4-11e9-9603-eaa511fa0b6c to disappear
Feb  6 02:07:54.091: INFO: Pod pod-configmaps-00fc9e7a-29b4-11e9-9603-eaa511fa0b6c no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  6 02:07:54.091: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-cxwxp" for this suite.
Feb  6 02:08:00.144: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 02:08:01.145: INFO: namespace: e2e-tests-configmap-cxwxp, resource: bindings, ignored listing per whitelist
Feb  6 02:08:01.225: INFO: namespace e2e-tests-configmap-cxwxp deletion completed in 7.115844171s

• [SLOW TEST:11.714 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should support rollover [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  6 02:08:01.225: INFO: >>> kubeConfig: /tmp/kubeconfig-131423863
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-deployment-7qqf9
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should support rollover [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb  6 02:08:01.603: INFO: Pod name rollover-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Feb  6 02:08:03.628: INFO: Waiting for pods owned by replica set "test-rollover-controller" to become ready
Feb  6 02:08:05.635: INFO: Creating deployment "test-rollover-deployment"
Feb  6 02:08:05.656: INFO: Make sure deployment "test-rollover-deployment" performs scaling operations
Feb  6 02:08:08.399: INFO: Check revision of new replica set for deployment "test-rollover-deployment"
Feb  6 02:08:08.489: INFO: Ensure that both replica sets have 1 created replica
Feb  6 02:08:08.506: INFO: Rollover old replica sets for deployment "test-rollover-deployment" with new image update
Feb  6 02:08:08.527: INFO: Updating deployment test-rollover-deployment
Feb  6 02:08:08.527: INFO: Wait deployment "test-rollover-deployment" to be observed by the deployment controller
Feb  6 02:08:10.547: INFO: Wait for revision update of deployment "test-rollover-deployment" to 2
Feb  6 02:08:10.566: INFO: Make sure deployment "test-rollover-deployment" is complete
Feb  6 02:08:10.592: INFO: all replica sets need to contain the pod-template-hash label
Feb  6 02:08:10.592: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63685015685, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63685015685, loc:(*time.Location)(0x6c43b60)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63685015690, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63685015685, loc:(*time.Location)(0x6c43b60)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-5b76ff8c4\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb  6 02:08:12.610: INFO: all replica sets need to contain the pod-template-hash label
Feb  6 02:08:12.610: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63685015685, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63685015685, loc:(*time.Location)(0x6c43b60)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63685015690, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63685015685, loc:(*time.Location)(0x6c43b60)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-5b76ff8c4\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb  6 02:08:14.611: INFO: all replica sets need to contain the pod-template-hash label
Feb  6 02:08:14.611: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63685015685, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63685015685, loc:(*time.Location)(0x6c43b60)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63685015690, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63685015685, loc:(*time.Location)(0x6c43b60)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-5b76ff8c4\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb  6 02:08:16.610: INFO: all replica sets need to contain the pod-template-hash label
Feb  6 02:08:16.610: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63685015685, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63685015685, loc:(*time.Location)(0x6c43b60)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63685015690, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63685015685, loc:(*time.Location)(0x6c43b60)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-5b76ff8c4\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb  6 02:08:18.624: INFO: all replica sets need to contain the pod-template-hash label
Feb  6 02:08:18.624: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63685015685, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63685015685, loc:(*time.Location)(0x6c43b60)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63685015690, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63685015685, loc:(*time.Location)(0x6c43b60)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-5b76ff8c4\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb  6 02:08:20.610: INFO: 
Feb  6 02:08:20.610: INFO: Ensure that both old replica sets have no replicas
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Feb  6 02:08:20.633: INFO: Deployment "test-rollover-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment,GenerateName:,Namespace:e2e-tests-deployment-7qqf9,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-7qqf9/deployments/test-rollover-deployment,UID:0a5f4e02-29b4-11e9-bf83-6639c2940cda,ResourceVersion:51466,Generation:2,CreationTimestamp:2019-02-06 02:08:05 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:0,MaxSurge:1,},},MinReadySeconds:10,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[{Available True 2019-02-06 02:08:05 +0000 UTC 2019-02-06 02:08:05 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2019-02-06 02:08:20 +0000 UTC 2019-02-06 02:08:05 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-rollover-deployment-5b76ff8c4" has successfully progressed.}],ReadyReplicas:1,CollisionCount:nil,},}

Feb  6 02:08:20.641: INFO: New ReplicaSet "test-rollover-deployment-5b76ff8c4" of Deployment "test-rollover-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-5b76ff8c4,GenerateName:,Namespace:e2e-tests-deployment-7qqf9,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-7qqf9/replicasets/test-rollover-deployment-5b76ff8c4,UID:0c17f1ba-29b4-11e9-a275-52a9a0efac9f,ResourceVersion:51457,Generation:2,CreationTimestamp:2019-02-06 02:08:08 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 5b76ff8c4,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment 0a5f4e02-29b4-11e9-bf83-6639c2940cda 0xc422fadab7 0xc422fadab8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 5b76ff8c4,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 5b76ff8c4,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:2,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Feb  6 02:08:20.642: INFO: All old ReplicaSets of Deployment "test-rollover-deployment":
Feb  6 02:08:20.642: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-controller,GenerateName:,Namespace:e2e-tests-deployment-7qqf9,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-7qqf9/replicasets/test-rollover-controller,UID:07eeb9c3-29b4-11e9-bf83-6639c2940cda,ResourceVersion:51465,Generation:2,CreationTimestamp:2019-02-06 02:08:01 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod: nginx,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment 0a5f4e02-29b4-11e9-bf83-6639c2940cda 0xc422fad9de 0xc422fad9df}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Feb  6 02:08:20.642: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-6975f4fb87,GenerateName:,Namespace:e2e-tests-deployment-7qqf9,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-7qqf9/replicasets/test-rollover-deployment-6975f4fb87,UID:0a63c4c5-29b4-11e9-a275-52a9a0efac9f,ResourceVersion:51426,Generation:2,CreationTimestamp:2019-02-06 02:08:05 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6975f4fb87,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment 0a5f4e02-29b4-11e9-bf83-6639c2940cda 0xc422fadb77 0xc422fadb78}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 6975f4fb87,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 6975f4fb87,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis-slave gcr.io/google_samples/gb-redisslave:nonexistent [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Feb  6 02:08:20.691: INFO: Pod "test-rollover-deployment-5b76ff8c4-zkcvv" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-5b76ff8c4-zkcvv,GenerateName:test-rollover-deployment-5b76ff8c4-,Namespace:e2e-tests-deployment-7qqf9,SelfLink:/api/v1/namespaces/e2e-tests-deployment-7qqf9/pods/test-rollover-deployment-5b76ff8c4-zkcvv,UID:0c1d19b2-29b4-11e9-a275-52a9a0efac9f,ResourceVersion:51438,Generation:0,CreationTimestamp:2019-02-06 02:08:08 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 5b76ff8c4,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet test-rollover-deployment-5b76ff8c4 0c17f1ba-29b4-11e9-a275-52a9a0efac9f 0xc422e06670 0xc422e06671}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-2msdt {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-2msdt,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-2msdt true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.190.119.184,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc422e066e0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc422e06700}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-06 02:08:08 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-02-06 02:08:10 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-02-06 02:08:10 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-06 02:08:08 +0000 UTC  }],Message:,Reason:,HostIP:10.190.119.184,PodIP:172.30.242.43,StartTime:2019-02-06 02:08:08 +0000 UTC,ContainerStatuses:[{redis {nil ContainerStateRunning{StartedAt:2019-02-06 02:08:09 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/redis:1.0 gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830 containerd://5247ef680b7b7d98956a7036427681cbd007050e2d3bd139d8b6c3d75749b901}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  6 02:08:20.691: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-7qqf9" for this suite.
Feb  6 02:08:26.731: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 02:08:27.010: INFO: namespace: e2e-tests-deployment-7qqf9, resource: bindings, ignored listing per whitelist
Feb  6 02:08:27.197: INFO: namespace e2e-tests-deployment-7qqf9 deletion completed in 6.491976642s

• [SLOW TEST:25.972 seconds]
[sig-apps] Deployment
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  deployment should support rollover [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  6 02:08:27.198: INFO: >>> kubeConfig: /tmp/kubeconfig-131423863
STEP: Building a namespace api object, basename containers
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-containers-k6l6s
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test override arguments
Feb  6 02:08:27.608: INFO: Waiting up to 5m0s for pod "client-containers-17740efc-29b4-11e9-9603-eaa511fa0b6c" in namespace "e2e-tests-containers-k6l6s" to be "success or failure"
Feb  6 02:08:27.618: INFO: Pod "client-containers-17740efc-29b4-11e9-9603-eaa511fa0b6c": Phase="Pending", Reason="", readiness=false. Elapsed: 9.601118ms
Feb  6 02:08:29.641: INFO: Pod "client-containers-17740efc-29b4-11e9-9603-eaa511fa0b6c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.03276167s
Feb  6 02:08:31.700: INFO: Pod "client-containers-17740efc-29b4-11e9-9603-eaa511fa0b6c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.092269325s
STEP: Saw pod success
Feb  6 02:08:31.701: INFO: Pod "client-containers-17740efc-29b4-11e9-9603-eaa511fa0b6c" satisfied condition "success or failure"
Feb  6 02:08:31.709: INFO: Trying to get logs from node 10.190.119.133 pod client-containers-17740efc-29b4-11e9-9603-eaa511fa0b6c container test-container: <nil>
STEP: delete the pod
Feb  6 02:08:31.765: INFO: Waiting for pod client-containers-17740efc-29b4-11e9-9603-eaa511fa0b6c to disappear
Feb  6 02:08:31.772: INFO: Pod client-containers-17740efc-29b4-11e9-9603-eaa511fa0b6c no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  6 02:08:31.772: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-k6l6s" for this suite.
Feb  6 02:08:37.810: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 02:08:37.940: INFO: namespace: e2e-tests-containers-k6l6s, resource: bindings, ignored listing per whitelist
Feb  6 02:08:38.191: INFO: namespace e2e-tests-containers-k6l6s deletion completed in 6.405492628s

• [SLOW TEST:10.993 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  6 02:08:38.191: INFO: >>> kubeConfig: /tmp/kubeconfig-131423863
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-ls5ml
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-map-1e00f682-29b4-11e9-9603-eaa511fa0b6c
STEP: Creating a pod to test consume configMaps
Feb  6 02:08:38.601: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-1e023ef8-29b4-11e9-9603-eaa511fa0b6c" in namespace "e2e-tests-projected-ls5ml" to be "success or failure"
Feb  6 02:08:38.609: INFO: Pod "pod-projected-configmaps-1e023ef8-29b4-11e9-9603-eaa511fa0b6c": Phase="Pending", Reason="", readiness=false. Elapsed: 7.399191ms
Feb  6 02:08:40.638: INFO: Pod "pod-projected-configmaps-1e023ef8-29b4-11e9-9603-eaa511fa0b6c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.03694556s
STEP: Saw pod success
Feb  6 02:08:40.639: INFO: Pod "pod-projected-configmaps-1e023ef8-29b4-11e9-9603-eaa511fa0b6c" satisfied condition "success or failure"
Feb  6 02:08:40.647: INFO: Trying to get logs from node 10.190.119.143 pod pod-projected-configmaps-1e023ef8-29b4-11e9-9603-eaa511fa0b6c container projected-configmap-volume-test: <nil>
STEP: delete the pod
Feb  6 02:08:40.696: INFO: Waiting for pod pod-projected-configmaps-1e023ef8-29b4-11e9-9603-eaa511fa0b6c to disappear
Feb  6 02:08:40.704: INFO: Pod pod-projected-configmaps-1e023ef8-29b4-11e9-9603-eaa511fa0b6c no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  6 02:08:40.704: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-ls5ml" for this suite.
Feb  6 02:08:46.763: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 02:08:47.017: INFO: namespace: e2e-tests-projected-ls5ml, resource: bindings, ignored listing per whitelist
Feb  6 02:08:47.094: INFO: namespace e2e-tests-projected-ls5ml deletion completed in 6.370663641s

• [SLOW TEST:8.902 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  6 02:08:47.094: INFO: >>> kubeConfig: /tmp/kubeconfig-131423863
STEP: Building a namespace api object, basename namespaces
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-namespaces-w2wrx
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a test namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-nsdeletetest-tts8z
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a service in the namespace
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-nsdeletetest-4rklb
STEP: Verifying there is no service in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  6 02:08:54.068: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-namespaces-w2wrx" for this suite.
Feb  6 02:09:00.329: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 02:09:00.464: INFO: namespace: e2e-tests-namespaces-w2wrx, resource: bindings, ignored listing per whitelist
Feb  6 02:09:00.694: INFO: namespace e2e-tests-namespaces-w2wrx deletion completed in 6.393352651s
STEP: Destroying namespace "e2e-tests-nsdeletetest-tts8z" for this suite.
Feb  6 02:09:00.702: INFO: Namespace e2e-tests-nsdeletetest-tts8z was already deleted
STEP: Destroying namespace "e2e-tests-nsdeletetest-4rklb" for this suite.
Feb  6 02:09:08.790: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 02:09:08.977: INFO: namespace: e2e-tests-nsdeletetest-4rklb, resource: bindings, ignored listing per whitelist
Feb  6 02:09:09.500: INFO: namespace e2e-tests-nsdeletetest-4rklb deletion completed in 8.797543419s

• [SLOW TEST:22.406 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  6 02:09:09.506: INFO: >>> kubeConfig: /tmp/kubeconfig-131423863
STEP: Building a namespace api object, basename var-expansion
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-var-expansion-gnr47
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test env composition
Feb  6 02:09:09.843: INFO: Waiting up to 5m0s for pod "var-expansion-30a0bf40-29b4-11e9-9603-eaa511fa0b6c" in namespace "e2e-tests-var-expansion-gnr47" to be "success or failure"
Feb  6 02:09:09.854: INFO: Pod "var-expansion-30a0bf40-29b4-11e9-9603-eaa511fa0b6c": Phase="Pending", Reason="", readiness=false. Elapsed: 10.541559ms
Feb  6 02:09:11.862: INFO: Pod "var-expansion-30a0bf40-29b4-11e9-9603-eaa511fa0b6c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.019385721s
STEP: Saw pod success
Feb  6 02:09:11.862: INFO: Pod "var-expansion-30a0bf40-29b4-11e9-9603-eaa511fa0b6c" satisfied condition "success or failure"
Feb  6 02:09:11.871: INFO: Trying to get logs from node 10.190.119.184 pod var-expansion-30a0bf40-29b4-11e9-9603-eaa511fa0b6c container dapi-container: <nil>
STEP: delete the pod
Feb  6 02:09:11.931: INFO: Waiting for pod var-expansion-30a0bf40-29b4-11e9-9603-eaa511fa0b6c to disappear
Feb  6 02:09:11.941: INFO: Pod var-expansion-30a0bf40-29b4-11e9-9603-eaa511fa0b6c no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  6 02:09:11.941: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-var-expansion-gnr47" for this suite.
Feb  6 02:09:17.984: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 02:09:18.210: INFO: namespace: e2e-tests-var-expansion-gnr47, resource: bindings, ignored listing per whitelist
Feb  6 02:09:18.528: INFO: namespace e2e-tests-var-expansion-gnr47 deletion completed in 6.574123537s

• [SLOW TEST:9.022 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-api-machinery] ConfigMap 
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  6 02:09:18.528: INFO: >>> kubeConfig: /tmp/kubeconfig-131423863
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-p5ctj
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap e2e-tests-configmap-p5ctj/configmap-test-3601c66d-29b4-11e9-9603-eaa511fa0b6c
STEP: Creating a pod to test consume configMaps
Feb  6 02:09:18.873: INFO: Waiting up to 5m0s for pod "pod-configmaps-36031e16-29b4-11e9-9603-eaa511fa0b6c" in namespace "e2e-tests-configmap-p5ctj" to be "success or failure"
Feb  6 02:09:18.883: INFO: Pod "pod-configmaps-36031e16-29b4-11e9-9603-eaa511fa0b6c": Phase="Pending", Reason="", readiness=false. Elapsed: 9.636582ms
Feb  6 02:09:20.893: INFO: Pod "pod-configmaps-36031e16-29b4-11e9-9603-eaa511fa0b6c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.019492404s
STEP: Saw pod success
Feb  6 02:09:20.893: INFO: Pod "pod-configmaps-36031e16-29b4-11e9-9603-eaa511fa0b6c" satisfied condition "success or failure"
Feb  6 02:09:20.902: INFO: Trying to get logs from node 10.190.119.133 pod pod-configmaps-36031e16-29b4-11e9-9603-eaa511fa0b6c container env-test: <nil>
STEP: delete the pod
Feb  6 02:09:21.021: INFO: Waiting for pod pod-configmaps-36031e16-29b4-11e9-9603-eaa511fa0b6c to disappear
Feb  6 02:09:21.030: INFO: Pod pod-configmaps-36031e16-29b4-11e9-9603-eaa511fa0b6c no longer exists
[AfterEach] [sig-api-machinery] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  6 02:09:21.030: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-p5ctj" for this suite.
Feb  6 02:09:27.073: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 02:09:27.328: INFO: namespace: e2e-tests-configmap-p5ctj, resource: bindings, ignored listing per whitelist
Feb  6 02:09:27.373: INFO: namespace e2e-tests-configmap-p5ctj deletion completed in 6.327439894s

• [SLOW TEST:8.845 seconds]
[sig-api-machinery] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:30
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  6 02:09:27.374: INFO: >>> kubeConfig: /tmp/kubeconfig-131423863
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-wdxfw
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-map-3b446070-29b4-11e9-9603-eaa511fa0b6c
STEP: Creating a pod to test consume configMaps
Feb  6 02:09:27.698: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-3b459aa7-29b4-11e9-9603-eaa511fa0b6c" in namespace "e2e-tests-projected-wdxfw" to be "success or failure"
Feb  6 02:09:27.724: INFO: Pod "pod-projected-configmaps-3b459aa7-29b4-11e9-9603-eaa511fa0b6c": Phase="Pending", Reason="", readiness=false. Elapsed: 26.458087ms
Feb  6 02:09:29.734: INFO: Pod "pod-projected-configmaps-3b459aa7-29b4-11e9-9603-eaa511fa0b6c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.035925207s
STEP: Saw pod success
Feb  6 02:09:29.734: INFO: Pod "pod-projected-configmaps-3b459aa7-29b4-11e9-9603-eaa511fa0b6c" satisfied condition "success or failure"
Feb  6 02:09:29.744: INFO: Trying to get logs from node 10.190.119.184 pod pod-projected-configmaps-3b459aa7-29b4-11e9-9603-eaa511fa0b6c container projected-configmap-volume-test: <nil>
STEP: delete the pod
Feb  6 02:09:29.824: INFO: Waiting for pod pod-projected-configmaps-3b459aa7-29b4-11e9-9603-eaa511fa0b6c to disappear
Feb  6 02:09:29.833: INFO: Pod pod-projected-configmaps-3b459aa7-29b4-11e9-9603-eaa511fa0b6c no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  6 02:09:29.833: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-wdxfw" for this suite.
Feb  6 02:09:35.916: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 02:09:36.155: INFO: namespace: e2e-tests-projected-wdxfw, resource: bindings, ignored listing per whitelist
Feb  6 02:09:36.272: INFO: namespace e2e-tests-projected-wdxfw deletion completed in 6.425364966s

• [SLOW TEST:8.898 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on default medium should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  6 02:09:36.274: INFO: >>> kubeConfig: /tmp/kubeconfig-131423863
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-6rs8c
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on default medium should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir volume type on node default medium
Feb  6 02:09:36.602: INFO: Waiting up to 5m0s for pod "pod-4094ab8d-29b4-11e9-9603-eaa511fa0b6c" in namespace "e2e-tests-emptydir-6rs8c" to be "success or failure"
Feb  6 02:09:36.610: INFO: Pod "pod-4094ab8d-29b4-11e9-9603-eaa511fa0b6c": Phase="Pending", Reason="", readiness=false. Elapsed: 8.122725ms
Feb  6 02:09:38.621: INFO: Pod "pod-4094ab8d-29b4-11e9-9603-eaa511fa0b6c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.019183949s
STEP: Saw pod success
Feb  6 02:09:38.621: INFO: Pod "pod-4094ab8d-29b4-11e9-9603-eaa511fa0b6c" satisfied condition "success or failure"
Feb  6 02:09:38.629: INFO: Trying to get logs from node 10.190.119.184 pod pod-4094ab8d-29b4-11e9-9603-eaa511fa0b6c container test-container: <nil>
STEP: delete the pod
Feb  6 02:09:38.719: INFO: Waiting for pod pod-4094ab8d-29b4-11e9-9603-eaa511fa0b6c to disappear
Feb  6 02:09:38.727: INFO: Pod pod-4094ab8d-29b4-11e9-9603-eaa511fa0b6c no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  6 02:09:38.727: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-6rs8c" for this suite.
Feb  6 02:09:44.771: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 02:09:44.965: INFO: namespace: e2e-tests-emptydir-6rs8c, resource: bindings, ignored listing per whitelist
Feb  6 02:09:45.217: INFO: namespace e2e-tests-emptydir-6rs8c deletion completed in 6.473043514s

• [SLOW TEST:8.944 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  volume on default medium should have the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  6 02:09:45.218: INFO: >>> kubeConfig: /tmp/kubeconfig-131423863
STEP: Building a namespace api object, basename pod-network-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-pod-network-test-6scrj
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-6scrj
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Feb  6 02:09:45.544: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Feb  6 02:10:05.758: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://172.30.134.253:8080/dial?request=hostName&protocol=udp&host=172.30.176.63&port=8081&tries=1'] Namespace:e2e-tests-pod-network-test-6scrj PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb  6 02:10:05.758: INFO: >>> kubeConfig: /tmp/kubeconfig-131423863
Feb  6 02:10:06.090: INFO: Waiting for endpoints: map[]
Feb  6 02:10:06.099: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://172.30.134.253:8080/dial?request=hostName&protocol=udp&host=172.30.242.48&port=8081&tries=1'] Namespace:e2e-tests-pod-network-test-6scrj PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb  6 02:10:06.099: INFO: >>> kubeConfig: /tmp/kubeconfig-131423863
Feb  6 02:10:06.343: INFO: Waiting for endpoints: map[]
Feb  6 02:10:06.353: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://172.30.134.253:8080/dial?request=hostName&protocol=udp&host=172.30.134.252&port=8081&tries=1'] Namespace:e2e-tests-pod-network-test-6scrj PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb  6 02:10:06.353: INFO: >>> kubeConfig: /tmp/kubeconfig-131423863
Feb  6 02:10:06.830: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  6 02:10:06.830: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-6scrj" for this suite.
Feb  6 02:10:31.384: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 02:10:31.816: INFO: namespace: e2e-tests-pod-network-test-6scrj, resource: bindings, ignored listing per whitelist
Feb  6 02:10:31.841: INFO: namespace e2e-tests-pod-network-test-6scrj deletion completed in 24.495013453s

• [SLOW TEST:46.623 seconds]
[sig-network] Networking
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: udp [NodeConformance] [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  6 02:10:31.841: INFO: >>> kubeConfig: /tmp/kubeconfig-131423863
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-container-probe-4lvhp
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-http in namespace e2e-tests-container-probe-4lvhp
Feb  6 02:10:34.207: INFO: Started pod liveness-http in namespace e2e-tests-container-probe-4lvhp
STEP: checking the pod's current state and verifying that restartCount is present
Feb  6 02:10:34.215: INFO: Initial restart count of pod liveness-http is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  6 02:14:34.391: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-4lvhp" for this suite.
Feb  6 02:14:40.430: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 02:14:40.639: INFO: namespace: e2e-tests-container-probe-4lvhp, resource: bindings, ignored listing per whitelist
Feb  6 02:14:40.912: INFO: namespace e2e-tests-container-probe-4lvhp deletion completed in 6.508195199s

• [SLOW TEST:249.071 seconds]
[k8s.io] Probing container
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-api-machinery] Secrets 
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  6 02:14:40.912: INFO: >>> kubeConfig: /tmp/kubeconfig-131423863
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-secrets-vkpxx
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-f626ac8f-29b4-11e9-9603-eaa511fa0b6c
STEP: Creating a pod to test consume secrets
Feb  6 02:14:41.242: INFO: Waiting up to 5m0s for pod "pod-secrets-f628accd-29b4-11e9-9603-eaa511fa0b6c" in namespace "e2e-tests-secrets-vkpxx" to be "success or failure"
Feb  6 02:14:41.251: INFO: Pod "pod-secrets-f628accd-29b4-11e9-9603-eaa511fa0b6c": Phase="Pending", Reason="", readiness=false. Elapsed: 9.108624ms
Feb  6 02:14:43.261: INFO: Pod "pod-secrets-f628accd-29b4-11e9-9603-eaa511fa0b6c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.018403541s
STEP: Saw pod success
Feb  6 02:14:43.261: INFO: Pod "pod-secrets-f628accd-29b4-11e9-9603-eaa511fa0b6c" satisfied condition "success or failure"
Feb  6 02:14:43.270: INFO: Trying to get logs from node 10.190.119.133 pod pod-secrets-f628accd-29b4-11e9-9603-eaa511fa0b6c container secret-env-test: <nil>
STEP: delete the pod
Feb  6 02:14:43.391: INFO: Waiting for pod pod-secrets-f628accd-29b4-11e9-9603-eaa511fa0b6c to disappear
Feb  6 02:14:43.400: INFO: Pod pod-secrets-f628accd-29b4-11e9-9603-eaa511fa0b6c no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  6 02:14:43.400: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-vkpxx" for this suite.
Feb  6 02:14:49.445: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 02:14:49.591: INFO: namespace: e2e-tests-secrets-vkpxx, resource: bindings, ignored listing per whitelist
Feb  6 02:14:49.782: INFO: namespace e2e-tests-secrets-vkpxx deletion completed in 6.364131091s

• [SLOW TEST:8.870 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:31
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  6 02:14:49.784: INFO: >>> kubeConfig: /tmp/kubeconfig-131423863
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-b72gz
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-fb6fec27-29b4-11e9-9603-eaa511fa0b6c
STEP: Creating a pod to test consume configMaps
Feb  6 02:14:50.107: INFO: Waiting up to 5m0s for pod "pod-configmaps-fb7150d5-29b4-11e9-9603-eaa511fa0b6c" in namespace "e2e-tests-configmap-b72gz" to be "success or failure"
Feb  6 02:14:50.117: INFO: Pod "pod-configmaps-fb7150d5-29b4-11e9-9603-eaa511fa0b6c": Phase="Pending", Reason="", readiness=false. Elapsed: 9.969112ms
Feb  6 02:14:52.126: INFO: Pod "pod-configmaps-fb7150d5-29b4-11e9-9603-eaa511fa0b6c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.018744256s
STEP: Saw pod success
Feb  6 02:14:52.126: INFO: Pod "pod-configmaps-fb7150d5-29b4-11e9-9603-eaa511fa0b6c" satisfied condition "success or failure"
Feb  6 02:14:52.135: INFO: Trying to get logs from node 10.190.119.143 pod pod-configmaps-fb7150d5-29b4-11e9-9603-eaa511fa0b6c container configmap-volume-test: <nil>
STEP: delete the pod
Feb  6 02:14:52.223: INFO: Waiting for pod pod-configmaps-fb7150d5-29b4-11e9-9603-eaa511fa0b6c to disappear
Feb  6 02:14:52.231: INFO: Pod pod-configmaps-fb7150d5-29b4-11e9-9603-eaa511fa0b6c no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  6 02:14:52.231: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-b72gz" for this suite.
Feb  6 02:14:58.287: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 02:14:58.592: INFO: namespace: e2e-tests-configmap-b72gz, resource: bindings, ignored listing per whitelist
Feb  6 02:14:58.830: INFO: namespace e2e-tests-configmap-b72gz deletion completed in 6.586872199s

• [SLOW TEST:9.046 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  6 02:14:58.831: INFO: >>> kubeConfig: /tmp/kubeconfig-131423863
STEP: Building a namespace api object, basename var-expansion
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-var-expansion-jfkqw
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test substitution in container's command
Feb  6 02:14:59.225: INFO: Waiting up to 5m0s for pod "var-expansion-00dff561-29b5-11e9-9603-eaa511fa0b6c" in namespace "e2e-tests-var-expansion-jfkqw" to be "success or failure"
Feb  6 02:14:59.234: INFO: Pod "var-expansion-00dff561-29b5-11e9-9603-eaa511fa0b6c": Phase="Pending", Reason="", readiness=false. Elapsed: 8.597315ms
Feb  6 02:15:01.243: INFO: Pod "var-expansion-00dff561-29b5-11e9-9603-eaa511fa0b6c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.018244784s
STEP: Saw pod success
Feb  6 02:15:01.243: INFO: Pod "var-expansion-00dff561-29b5-11e9-9603-eaa511fa0b6c" satisfied condition "success or failure"
Feb  6 02:15:01.252: INFO: Trying to get logs from node 10.190.119.184 pod var-expansion-00dff561-29b5-11e9-9603-eaa511fa0b6c container dapi-container: <nil>
STEP: delete the pod
Feb  6 02:15:01.323: INFO: Waiting for pod var-expansion-00dff561-29b5-11e9-9603-eaa511fa0b6c to disappear
Feb  6 02:15:01.391: INFO: Pod var-expansion-00dff561-29b5-11e9-9603-eaa511fa0b6c no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  6 02:15:01.391: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-var-expansion-jfkqw" for this suite.
Feb  6 02:15:07.437: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 02:15:07.780: INFO: namespace: e2e-tests-var-expansion-jfkqw, resource: bindings, ignored listing per whitelist
Feb  6 02:15:07.780: INFO: namespace e2e-tests-var-expansion-jfkqw deletion completed in 6.374217698s

• [SLOW TEST:8.950 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-api-machinery] ConfigMap 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  6 02:15:07.782: INFO: >>> kubeConfig: /tmp/kubeconfig-131423863
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-qshnp
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap e2e-tests-configmap-qshnp/configmap-test-062a88a9-29b5-11e9-9603-eaa511fa0b6c
STEP: Creating a pod to test consume configMaps
Feb  6 02:15:08.103: INFO: Waiting up to 5m0s for pod "pod-configmaps-062bcd9c-29b5-11e9-9603-eaa511fa0b6c" in namespace "e2e-tests-configmap-qshnp" to be "success or failure"
Feb  6 02:15:08.111: INFO: Pod "pod-configmaps-062bcd9c-29b5-11e9-9603-eaa511fa0b6c": Phase="Pending", Reason="", readiness=false. Elapsed: 7.961578ms
Feb  6 02:15:10.148: INFO: Pod "pod-configmaps-062bcd9c-29b5-11e9-9603-eaa511fa0b6c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.044356877s
STEP: Saw pod success
Feb  6 02:15:10.148: INFO: Pod "pod-configmaps-062bcd9c-29b5-11e9-9603-eaa511fa0b6c" satisfied condition "success or failure"
Feb  6 02:15:10.156: INFO: Trying to get logs from node 10.190.119.133 pod pod-configmaps-062bcd9c-29b5-11e9-9603-eaa511fa0b6c container env-test: <nil>
STEP: delete the pod
Feb  6 02:15:10.224: INFO: Waiting for pod pod-configmaps-062bcd9c-29b5-11e9-9603-eaa511fa0b6c to disappear
Feb  6 02:15:10.236: INFO: Pod pod-configmaps-062bcd9c-29b5-11e9-9603-eaa511fa0b6c no longer exists
[AfterEach] [sig-api-machinery] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  6 02:15:10.237: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-qshnp" for this suite.
Feb  6 02:15:16.275: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 02:15:16.504: INFO: namespace: e2e-tests-configmap-qshnp, resource: bindings, ignored listing per whitelist
Feb  6 02:15:16.690: INFO: namespace e2e-tests-configmap-qshnp deletion completed in 6.441212001s

• [SLOW TEST:8.908 seconds]
[sig-api-machinery] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:30
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  6 02:15:16.690: INFO: >>> kubeConfig: /tmp/kubeconfig-131423863
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-zw7l6
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb  6 02:15:17.145: INFO: Waiting up to 5m0s for pod "downwardapi-volume-0b8ea3ed-29b5-11e9-9603-eaa511fa0b6c" in namespace "e2e-tests-downward-api-zw7l6" to be "success or failure"
Feb  6 02:15:17.152: INFO: Pod "downwardapi-volume-0b8ea3ed-29b5-11e9-9603-eaa511fa0b6c": Phase="Pending", Reason="", readiness=false. Elapsed: 7.679694ms
Feb  6 02:15:19.307: INFO: Pod "downwardapi-volume-0b8ea3ed-29b5-11e9-9603-eaa511fa0b6c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.162565427s
Feb  6 02:15:21.342: INFO: Pod "downwardapi-volume-0b8ea3ed-29b5-11e9-9603-eaa511fa0b6c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.197007996s
STEP: Saw pod success
Feb  6 02:15:21.342: INFO: Pod "downwardapi-volume-0b8ea3ed-29b5-11e9-9603-eaa511fa0b6c" satisfied condition "success or failure"
Feb  6 02:15:21.359: INFO: Trying to get logs from node 10.190.119.143 pod downwardapi-volume-0b8ea3ed-29b5-11e9-9603-eaa511fa0b6c container client-container: <nil>
STEP: delete the pod
Feb  6 02:15:21.409: INFO: Waiting for pod downwardapi-volume-0b8ea3ed-29b5-11e9-9603-eaa511fa0b6c to disappear
Feb  6 02:15:21.418: INFO: Pod downwardapi-volume-0b8ea3ed-29b5-11e9-9603-eaa511fa0b6c no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  6 02:15:21.418: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-zw7l6" for this suite.
Feb  6 02:15:27.459: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 02:15:27.594: INFO: namespace: e2e-tests-downward-api-zw7l6, resource: bindings, ignored listing per whitelist
Feb  6 02:15:27.864: INFO: namespace e2e-tests-downward-api-zw7l6 deletion completed in 6.433410039s

• [SLOW TEST:11.174 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-network] Service endpoints latency 
  should not be very high  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  6 02:15:27.866: INFO: >>> kubeConfig: /tmp/kubeconfig-131423863
STEP: Building a namespace api object, basename svc-latency
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-svc-latency-mg295
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be very high  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating replication controller svc-latency-rc in namespace e2e-tests-svc-latency-mg295
I0206 02:15:28.191790      15 runners.go:180] Created replication controller with name: svc-latency-rc, namespace: e2e-tests-svc-latency-mg295, replica count: 1
I0206 02:15:29.242926      15 runners.go:180] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0206 02:15:30.243244      15 runners.go:180] svc-latency-rc Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Feb  6 02:15:30.375: INFO: Created: latency-svc-fpfqx
Feb  6 02:15:30.391: INFO: Got endpoints: latency-svc-fpfqx [48.011653ms]
Feb  6 02:15:30.417: INFO: Created: latency-svc-5x8h6
Feb  6 02:15:30.429: INFO: Got endpoints: latency-svc-5x8h6 [37.899036ms]
Feb  6 02:15:30.433: INFO: Created: latency-svc-p5xp7
Feb  6 02:15:30.440: INFO: Got endpoints: latency-svc-p5xp7 [48.449521ms]
Feb  6 02:15:30.448: INFO: Created: latency-svc-74cdt
Feb  6 02:15:30.459: INFO: Got endpoints: latency-svc-74cdt [66.485876ms]
Feb  6 02:15:30.466: INFO: Created: latency-svc-d2hq8
Feb  6 02:15:30.473: INFO: Got endpoints: latency-svc-d2hq8 [80.597177ms]
Feb  6 02:15:30.479: INFO: Created: latency-svc-sbhlk
Feb  6 02:15:30.488: INFO: Got endpoints: latency-svc-sbhlk [96.161348ms]
Feb  6 02:15:30.495: INFO: Created: latency-svc-z2k49
Feb  6 02:15:30.501: INFO: Got endpoints: latency-svc-z2k49 [108.416805ms]
Feb  6 02:15:30.511: INFO: Created: latency-svc-2g5vd
Feb  6 02:15:30.521: INFO: Got endpoints: latency-svc-2g5vd [128.068371ms]
Feb  6 02:15:30.529: INFO: Created: latency-svc-v69rq
Feb  6 02:15:30.536: INFO: Got endpoints: latency-svc-v69rq [143.599294ms]
Feb  6 02:15:30.549: INFO: Created: latency-svc-qznr7
Feb  6 02:15:30.561: INFO: Got endpoints: latency-svc-qznr7 [168.01759ms]
Feb  6 02:15:30.569: INFO: Created: latency-svc-6gvcr
Feb  6 02:15:30.585: INFO: Created: latency-svc-rhfml
Feb  6 02:15:30.587: INFO: Got endpoints: latency-svc-6gvcr [193.619338ms]
Feb  6 02:15:30.594: INFO: Got endpoints: latency-svc-rhfml [201.319933ms]
Feb  6 02:15:30.602: INFO: Created: latency-svc-76krj
Feb  6 02:15:30.610: INFO: Got endpoints: latency-svc-76krj [217.523444ms]
Feb  6 02:15:30.620: INFO: Created: latency-svc-7gfdq
Feb  6 02:15:30.628: INFO: Got endpoints: latency-svc-7gfdq [235.524951ms]
Feb  6 02:15:30.635: INFO: Created: latency-svc-xr48c
Feb  6 02:15:30.645: INFO: Got endpoints: latency-svc-xr48c [251.314329ms]
Feb  6 02:15:30.651: INFO: Created: latency-svc-278h5
Feb  6 02:15:30.659: INFO: Got endpoints: latency-svc-278h5 [265.713936ms]
Feb  6 02:15:30.666: INFO: Created: latency-svc-hdxpr
Feb  6 02:15:30.676: INFO: Got endpoints: latency-svc-hdxpr [246.782368ms]
Feb  6 02:15:30.683: INFO: Created: latency-svc-z5m7w
Feb  6 02:15:30.690: INFO: Got endpoints: latency-svc-z5m7w [249.866504ms]
Feb  6 02:15:30.698: INFO: Created: latency-svc-lcv5b
Feb  6 02:15:30.705: INFO: Got endpoints: latency-svc-lcv5b [245.828897ms]
Feb  6 02:15:30.715: INFO: Created: latency-svc-2525p
Feb  6 02:15:30.727: INFO: Got endpoints: latency-svc-2525p [253.922852ms]
Feb  6 02:15:30.735: INFO: Created: latency-svc-w7zlf
Feb  6 02:15:30.743: INFO: Got endpoints: latency-svc-w7zlf [255.138184ms]
Feb  6 02:15:30.751: INFO: Created: latency-svc-8f7rc
Feb  6 02:15:30.757: INFO: Got endpoints: latency-svc-8f7rc [256.599491ms]
Feb  6 02:15:30.774: INFO: Created: latency-svc-m567k
Feb  6 02:15:30.781: INFO: Got endpoints: latency-svc-m567k [260.01384ms]
Feb  6 02:15:30.788: INFO: Created: latency-svc-rhzdk
Feb  6 02:15:30.796: INFO: Got endpoints: latency-svc-rhzdk [260.069917ms]
Feb  6 02:15:30.804: INFO: Created: latency-svc-5x24r
Feb  6 02:15:30.811: INFO: Got endpoints: latency-svc-5x24r [249.993403ms]
Feb  6 02:15:30.819: INFO: Created: latency-svc-kkb5m
Feb  6 02:15:30.825: INFO: Got endpoints: latency-svc-kkb5m [238.294663ms]
Feb  6 02:15:30.838: INFO: Created: latency-svc-sllp8
Feb  6 02:15:30.844: INFO: Got endpoints: latency-svc-sllp8 [250.475167ms]
Feb  6 02:15:30.852: INFO: Created: latency-svc-nwflk
Feb  6 02:15:30.860: INFO: Got endpoints: latency-svc-nwflk [249.499373ms]
Feb  6 02:15:30.868: INFO: Created: latency-svc-kjlr4
Feb  6 02:15:30.876: INFO: Got endpoints: latency-svc-kjlr4 [248.196226ms]
Feb  6 02:15:30.881: INFO: Created: latency-svc-mvn72
Feb  6 02:15:30.894: INFO: Got endpoints: latency-svc-mvn72 [248.799797ms]
Feb  6 02:15:30.902: INFO: Created: latency-svc-d267d
Feb  6 02:15:30.916: INFO: Got endpoints: latency-svc-d267d [256.424875ms]
Feb  6 02:15:30.923: INFO: Created: latency-svc-vlr26
Feb  6 02:15:30.931: INFO: Got endpoints: latency-svc-vlr26 [254.858852ms]
Feb  6 02:15:30.939: INFO: Created: latency-svc-jksw8
Feb  6 02:15:30.947: INFO: Got endpoints: latency-svc-jksw8 [256.946205ms]
Feb  6 02:15:30.954: INFO: Created: latency-svc-g74r5
Feb  6 02:15:30.962: INFO: Got endpoints: latency-svc-g74r5 [257.422853ms]
Feb  6 02:15:30.975: INFO: Created: latency-svc-cnd4q
Feb  6 02:15:30.983: INFO: Got endpoints: latency-svc-cnd4q [256.277383ms]
Feb  6 02:15:30.992: INFO: Created: latency-svc-7kkrb
Feb  6 02:15:31.003: INFO: Got endpoints: latency-svc-7kkrb [260.038689ms]
Feb  6 02:15:31.008: INFO: Created: latency-svc-ft9xv
Feb  6 02:15:31.015: INFO: Got endpoints: latency-svc-ft9xv [257.867984ms]
Feb  6 02:15:31.021: INFO: Created: latency-svc-zwrr6
Feb  6 02:15:31.029: INFO: Got endpoints: latency-svc-zwrr6 [247.618697ms]
Feb  6 02:15:31.038: INFO: Created: latency-svc-5fssd
Feb  6 02:15:31.044: INFO: Got endpoints: latency-svc-5fssd [247.118653ms]
Feb  6 02:15:31.050: INFO: Created: latency-svc-bv754
Feb  6 02:15:31.059: INFO: Got endpoints: latency-svc-bv754 [247.290646ms]
Feb  6 02:15:31.067: INFO: Created: latency-svc-qlqrv
Feb  6 02:15:31.076: INFO: Got endpoints: latency-svc-qlqrv [250.448071ms]
Feb  6 02:15:31.082: INFO: Created: latency-svc-7gddz
Feb  6 02:15:31.089: INFO: Got endpoints: latency-svc-7gddz [245.003065ms]
Feb  6 02:15:31.098: INFO: Created: latency-svc-jdnhj
Feb  6 02:15:31.107: INFO: Got endpoints: latency-svc-jdnhj [246.937802ms]
Feb  6 02:15:31.117: INFO: Created: latency-svc-qkwrb
Feb  6 02:15:31.134: INFO: Got endpoints: latency-svc-qkwrb [257.953661ms]
Feb  6 02:15:31.144: INFO: Created: latency-svc-qljf4
Feb  6 02:15:31.150: INFO: Got endpoints: latency-svc-qljf4 [256.64857ms]
Feb  6 02:15:31.159: INFO: Created: latency-svc-gj44g
Feb  6 02:15:31.181: INFO: Got endpoints: latency-svc-gj44g [265.560078ms]
Feb  6 02:15:31.185: INFO: Created: latency-svc-n74fv
Feb  6 02:15:31.203: INFO: Created: latency-svc-lmq4h
Feb  6 02:15:31.221: INFO: Created: latency-svc-l8tmd
Feb  6 02:15:31.232: INFO: Created: latency-svc-wh55s
Feb  6 02:15:31.234: INFO: Got endpoints: latency-svc-n74fv [303.031889ms]
Feb  6 02:15:31.250: INFO: Created: latency-svc-h85ln
Feb  6 02:15:31.268: INFO: Created: latency-svc-8l4gr
Feb  6 02:15:31.288: INFO: Created: latency-svc-9qbxp
Feb  6 02:15:31.292: INFO: Got endpoints: latency-svc-lmq4h [344.254704ms]
Feb  6 02:15:31.305: INFO: Created: latency-svc-qs7nk
Feb  6 02:15:31.323: INFO: Created: latency-svc-nbmzl
Feb  6 02:15:31.335: INFO: Got endpoints: latency-svc-l8tmd [373.08957ms]
Feb  6 02:15:31.345: INFO: Created: latency-svc-wqzhj
Feb  6 02:15:31.365: INFO: Created: latency-svc-6qz2c
Feb  6 02:15:31.383: INFO: Got endpoints: latency-svc-wh55s [400.476864ms]
Feb  6 02:15:31.384: INFO: Created: latency-svc-qgtpn
Feb  6 02:15:31.400: INFO: Created: latency-svc-mndmf
Feb  6 02:15:31.422: INFO: Created: latency-svc-ffg78
Feb  6 02:15:31.432: INFO: Got endpoints: latency-svc-h85ln [428.964267ms]
Feb  6 02:15:31.438: INFO: Created: latency-svc-7q586
Feb  6 02:15:31.460: INFO: Created: latency-svc-zpnkq
Feb  6 02:15:31.476: INFO: Created: latency-svc-87pkh
Feb  6 02:15:31.486: INFO: Got endpoints: latency-svc-8l4gr [470.352846ms]
Feb  6 02:15:31.495: INFO: Created: latency-svc-h8l2c
Feb  6 02:15:31.516: INFO: Created: latency-svc-vbsmj
Feb  6 02:15:31.532: INFO: Got endpoints: latency-svc-9qbxp [503.066633ms]
Feb  6 02:15:31.536: INFO: Created: latency-svc-nr665
Feb  6 02:15:31.553: INFO: Created: latency-svc-7xc4x
Feb  6 02:15:31.572: INFO: Created: latency-svc-zknk9
Feb  6 02:15:31.582: INFO: Got endpoints: latency-svc-qs7nk [538.696358ms]
Feb  6 02:15:31.613: INFO: Created: latency-svc-pgkgm
Feb  6 02:15:31.634: INFO: Got endpoints: latency-svc-nbmzl [575.526418ms]
Feb  6 02:15:31.663: INFO: Created: latency-svc-hdbvh
Feb  6 02:15:31.685: INFO: Got endpoints: latency-svc-wqzhj [609.374881ms]
Feb  6 02:15:31.714: INFO: Created: latency-svc-988h4
Feb  6 02:15:31.732: INFO: Got endpoints: latency-svc-6qz2c [642.145901ms]
Feb  6 02:15:31.759: INFO: Created: latency-svc-g5spv
Feb  6 02:15:31.782: INFO: Got endpoints: latency-svc-qgtpn [446.38083ms]
Feb  6 02:15:31.807: INFO: Created: latency-svc-5lc7h
Feb  6 02:15:31.832: INFO: Got endpoints: latency-svc-mndmf [725.40175ms]
Feb  6 02:15:31.859: INFO: Created: latency-svc-ntzbn
Feb  6 02:15:31.881: INFO: Got endpoints: latency-svc-ffg78 [746.774098ms]
Feb  6 02:15:31.907: INFO: Created: latency-svc-2dr9l
Feb  6 02:15:31.932: INFO: Got endpoints: latency-svc-7q586 [781.369319ms]
Feb  6 02:15:31.961: INFO: Created: latency-svc-s8l96
Feb  6 02:15:31.981: INFO: Got endpoints: latency-svc-zpnkq [799.983143ms]
Feb  6 02:15:32.007: INFO: Created: latency-svc-5ktdl
Feb  6 02:15:32.031: INFO: Got endpoints: latency-svc-87pkh [796.931813ms]
Feb  6 02:15:32.061: INFO: Created: latency-svc-gqlqg
Feb  6 02:15:32.292: INFO: Got endpoints: latency-svc-nr665 [859.11407ms]
Feb  6 02:15:32.292: INFO: Got endpoints: latency-svc-zknk9 [760.061756ms]
Feb  6 02:15:32.292: INFO: Got endpoints: latency-svc-vbsmj [908.934138ms]
Feb  6 02:15:32.293: INFO: Got endpoints: latency-svc-h8l2c [1.000891851s]
Feb  6 02:15:32.293: INFO: Got endpoints: latency-svc-7xc4x [807.075625ms]
Feb  6 02:15:32.320: INFO: Created: latency-svc-dz5dt
Feb  6 02:15:32.331: INFO: Got endpoints: latency-svc-pgkgm [748.912779ms]
Feb  6 02:15:32.334: INFO: Created: latency-svc-xj5n7
Feb  6 02:15:32.353: INFO: Created: latency-svc-nw95q
Feb  6 02:15:32.367: INFO: Created: latency-svc-6n8j5
Feb  6 02:15:32.381: INFO: Got endpoints: latency-svc-hdbvh [746.594814ms]
Feb  6 02:15:32.387: INFO: Created: latency-svc-6fnnv
Feb  6 02:15:32.403: INFO: Created: latency-svc-76vxs
Feb  6 02:15:32.421: INFO: Created: latency-svc-68bl4
Feb  6 02:15:32.431: INFO: Got endpoints: latency-svc-988h4 [746.40431ms]
Feb  6 02:15:32.459: INFO: Created: latency-svc-w26fx
Feb  6 02:15:32.481: INFO: Got endpoints: latency-svc-g5spv [749.185453ms]
Feb  6 02:15:32.508: INFO: Created: latency-svc-2www8
Feb  6 02:15:32.531: INFO: Got endpoints: latency-svc-5lc7h [749.412954ms]
Feb  6 02:15:32.557: INFO: Created: latency-svc-kkdlq
Feb  6 02:15:32.584: INFO: Got endpoints: latency-svc-ntzbn [751.033031ms]
Feb  6 02:15:32.613: INFO: Created: latency-svc-llvwr
Feb  6 02:15:32.631: INFO: Got endpoints: latency-svc-2dr9l [750.251118ms]
Feb  6 02:15:32.662: INFO: Created: latency-svc-d8rkh
Feb  6 02:15:32.681: INFO: Got endpoints: latency-svc-s8l96 [749.145598ms]
Feb  6 02:15:32.707: INFO: Created: latency-svc-rcm9v
Feb  6 02:15:32.732: INFO: Got endpoints: latency-svc-5ktdl [750.429317ms]
Feb  6 02:15:32.763: INFO: Created: latency-svc-zt547
Feb  6 02:15:32.782: INFO: Got endpoints: latency-svc-gqlqg [750.674965ms]
Feb  6 02:15:32.808: INFO: Created: latency-svc-lpdvw
Feb  6 02:15:32.833: INFO: Got endpoints: latency-svc-dz5dt [541.036425ms]
Feb  6 02:15:32.866: INFO: Created: latency-svc-dplx5
Feb  6 02:15:32.885: INFO: Got endpoints: latency-svc-xj5n7 [593.331957ms]
Feb  6 02:15:32.920: INFO: Created: latency-svc-zxtdt
Feb  6 02:15:32.932: INFO: Got endpoints: latency-svc-nw95q [639.60633ms]
Feb  6 02:15:32.960: INFO: Created: latency-svc-jb4px
Feb  6 02:15:32.981: INFO: Got endpoints: latency-svc-6n8j5 [688.372237ms]
Feb  6 02:15:33.007: INFO: Created: latency-svc-nmmml
Feb  6 02:15:33.032: INFO: Got endpoints: latency-svc-6fnnv [739.031272ms]
Feb  6 02:15:33.058: INFO: Created: latency-svc-pmtcv
Feb  6 02:15:33.081: INFO: Got endpoints: latency-svc-76vxs [749.668855ms]
Feb  6 02:15:33.109: INFO: Created: latency-svc-ddfvd
Feb  6 02:15:33.132: INFO: Got endpoints: latency-svc-68bl4 [750.147416ms]
Feb  6 02:15:33.158: INFO: Created: latency-svc-hprrm
Feb  6 02:15:33.181: INFO: Got endpoints: latency-svc-w26fx [749.566555ms]
Feb  6 02:15:33.208: INFO: Created: latency-svc-scpq5
Feb  6 02:15:33.231: INFO: Got endpoints: latency-svc-2www8 [750.50565ms]
Feb  6 02:15:33.261: INFO: Created: latency-svc-5vp4k
Feb  6 02:15:33.282: INFO: Got endpoints: latency-svc-kkdlq [750.900996ms]
Feb  6 02:15:33.311: INFO: Created: latency-svc-xktbz
Feb  6 02:15:33.336: INFO: Got endpoints: latency-svc-llvwr [752.413535ms]
Feb  6 02:15:33.361: INFO: Created: latency-svc-nk4ld
Feb  6 02:15:33.381: INFO: Got endpoints: latency-svc-d8rkh [749.425869ms]
Feb  6 02:15:33.408: INFO: Created: latency-svc-wlf9v
Feb  6 02:15:33.431: INFO: Got endpoints: latency-svc-rcm9v [749.633596ms]
Feb  6 02:15:33.455: INFO: Created: latency-svc-4q2xc
Feb  6 02:15:33.485: INFO: Got endpoints: latency-svc-zt547 [753.575279ms]
Feb  6 02:15:33.514: INFO: Created: latency-svc-rpqqt
Feb  6 02:15:33.531: INFO: Got endpoints: latency-svc-lpdvw [749.223166ms]
Feb  6 02:15:33.557: INFO: Created: latency-svc-zwlp9
Feb  6 02:15:33.583: INFO: Got endpoints: latency-svc-dplx5 [750.649835ms]
Feb  6 02:15:33.611: INFO: Created: latency-svc-6qzh9
Feb  6 02:15:33.632: INFO: Got endpoints: latency-svc-zxtdt [746.875221ms]
Feb  6 02:15:33.685: INFO: Got endpoints: latency-svc-jb4px [753.140705ms]
Feb  6 02:15:33.693: INFO: Created: latency-svc-kqwrl
Feb  6 02:15:33.716: INFO: Created: latency-svc-kzrcw
Feb  6 02:15:33.733: INFO: Got endpoints: latency-svc-nmmml [752.193424ms]
Feb  6 02:15:33.764: INFO: Created: latency-svc-c5nwk
Feb  6 02:15:33.783: INFO: Got endpoints: latency-svc-pmtcv [751.560444ms]
Feb  6 02:15:33.814: INFO: Created: latency-svc-ptvp5
Feb  6 02:15:33.832: INFO: Got endpoints: latency-svc-ddfvd [750.699526ms]
Feb  6 02:15:33.859: INFO: Created: latency-svc-qp5x5
Feb  6 02:15:33.881: INFO: Got endpoints: latency-svc-hprrm [749.504305ms]
Feb  6 02:15:33.908: INFO: Created: latency-svc-pf8gc
Feb  6 02:15:33.932: INFO: Got endpoints: latency-svc-scpq5 [750.804645ms]
Feb  6 02:15:33.959: INFO: Created: latency-svc-sb4vm
Feb  6 02:15:33.981: INFO: Got endpoints: latency-svc-5vp4k [749.934288ms]
Feb  6 02:15:34.012: INFO: Created: latency-svc-cfs4f
Feb  6 02:15:34.033: INFO: Got endpoints: latency-svc-xktbz [750.521177ms]
Feb  6 02:15:34.059: INFO: Created: latency-svc-zn8nf
Feb  6 02:15:34.081: INFO: Got endpoints: latency-svc-nk4ld [745.187628ms]
Feb  6 02:15:34.107: INFO: Created: latency-svc-nwcfv
Feb  6 02:15:34.132: INFO: Got endpoints: latency-svc-wlf9v [750.951666ms]
Feb  6 02:15:34.160: INFO: Created: latency-svc-29rfb
Feb  6 02:15:34.184: INFO: Got endpoints: latency-svc-4q2xc [753.50617ms]
Feb  6 02:15:34.213: INFO: Created: latency-svc-s4tqs
Feb  6 02:15:34.233: INFO: Got endpoints: latency-svc-rpqqt [748.054806ms]
Feb  6 02:15:34.261: INFO: Created: latency-svc-q992t
Feb  6 02:15:34.281: INFO: Got endpoints: latency-svc-zwlp9 [749.449725ms]
Feb  6 02:15:34.320: INFO: Created: latency-svc-zsfnd
Feb  6 02:15:34.335: INFO: Got endpoints: latency-svc-6qzh9 [752.000743ms]
Feb  6 02:15:34.364: INFO: Created: latency-svc-q4ggb
Feb  6 02:15:34.382: INFO: Got endpoints: latency-svc-kqwrl [749.557202ms]
Feb  6 02:15:34.409: INFO: Created: latency-svc-84sgd
Feb  6 02:15:34.431: INFO: Got endpoints: latency-svc-kzrcw [745.944854ms]
Feb  6 02:15:34.457: INFO: Created: latency-svc-ltchf
Feb  6 02:15:34.481: INFO: Got endpoints: latency-svc-c5nwk [748.163715ms]
Feb  6 02:15:34.508: INFO: Created: latency-svc-8bf9h
Feb  6 02:15:34.533: INFO: Got endpoints: latency-svc-ptvp5 [749.128363ms]
Feb  6 02:15:34.559: INFO: Created: latency-svc-hsv8z
Feb  6 02:15:34.584: INFO: Got endpoints: latency-svc-qp5x5 [751.870937ms]
Feb  6 02:15:34.611: INFO: Created: latency-svc-x75rb
Feb  6 02:15:34.633: INFO: Got endpoints: latency-svc-pf8gc [752.228213ms]
Feb  6 02:15:34.666: INFO: Created: latency-svc-j8w2j
Feb  6 02:15:34.681: INFO: Got endpoints: latency-svc-sb4vm [748.932962ms]
Feb  6 02:15:34.707: INFO: Created: latency-svc-s48t9
Feb  6 02:15:34.734: INFO: Got endpoints: latency-svc-cfs4f [752.553447ms]
Feb  6 02:15:34.764: INFO: Created: latency-svc-257l2
Feb  6 02:15:34.782: INFO: Got endpoints: latency-svc-zn8nf [748.543984ms]
Feb  6 02:15:34.811: INFO: Created: latency-svc-cpbzr
Feb  6 02:15:34.832: INFO: Got endpoints: latency-svc-nwcfv [750.464281ms]
Feb  6 02:15:34.858: INFO: Created: latency-svc-sfg9l
Feb  6 02:15:34.881: INFO: Got endpoints: latency-svc-29rfb [748.700414ms]
Feb  6 02:15:34.907: INFO: Created: latency-svc-4lt22
Feb  6 02:15:34.933: INFO: Got endpoints: latency-svc-s4tqs [748.783368ms]
Feb  6 02:15:34.982: INFO: Got endpoints: latency-svc-q992t [747.908755ms]
Feb  6 02:15:35.032: INFO: Got endpoints: latency-svc-zsfnd [750.874828ms]
Feb  6 02:15:35.092: INFO: Got endpoints: latency-svc-q4ggb [756.221845ms]
Feb  6 02:15:35.131: INFO: Got endpoints: latency-svc-84sgd [749.264731ms]
Feb  6 02:15:35.182: INFO: Got endpoints: latency-svc-ltchf [750.768569ms]
Feb  6 02:15:35.195: INFO: Created: latency-svc-z629c
Feb  6 02:15:35.227: INFO: Created: latency-svc-jljm6
Feb  6 02:15:35.231: INFO: Got endpoints: latency-svc-8bf9h [749.713635ms]
Feb  6 02:15:35.240: INFO: Created: latency-svc-wzsph
Feb  6 02:15:35.255: INFO: Created: latency-svc-whgdc
Feb  6 02:15:35.270: INFO: Created: latency-svc-hgn56
Feb  6 02:15:35.283: INFO: Got endpoints: latency-svc-hsv8z [750.517554ms]
Feb  6 02:15:35.287: INFO: Created: latency-svc-qgwlx
Feb  6 02:15:35.304: INFO: Created: latency-svc-vlktz
Feb  6 02:15:35.324: INFO: Created: latency-svc-2hhzh
Feb  6 02:15:35.332: INFO: Got endpoints: latency-svc-x75rb [748.731353ms]
Feb  6 02:15:35.360: INFO: Created: latency-svc-bjvqk
Feb  6 02:15:35.383: INFO: Got endpoints: latency-svc-j8w2j [749.987274ms]
Feb  6 02:15:35.419: INFO: Created: latency-svc-t6h2r
Feb  6 02:15:35.434: INFO: Got endpoints: latency-svc-s48t9 [752.558853ms]
Feb  6 02:15:35.463: INFO: Created: latency-svc-l87fb
Feb  6 02:15:35.482: INFO: Got endpoints: latency-svc-257l2 [747.600529ms]
Feb  6 02:15:35.511: INFO: Created: latency-svc-p68hs
Feb  6 02:15:35.533: INFO: Got endpoints: latency-svc-cpbzr [751.377962ms]
Feb  6 02:15:35.562: INFO: Created: latency-svc-pxqln
Feb  6 02:15:35.582: INFO: Got endpoints: latency-svc-sfg9l [749.908418ms]
Feb  6 02:15:35.612: INFO: Created: latency-svc-s67fh
Feb  6 02:15:35.635: INFO: Got endpoints: latency-svc-4lt22 [754.60751ms]
Feb  6 02:15:35.665: INFO: Created: latency-svc-xw8s5
Feb  6 02:15:35.681: INFO: Got endpoints: latency-svc-z629c [748.13768ms]
Feb  6 02:15:35.708: INFO: Created: latency-svc-4wblb
Feb  6 02:15:35.736: INFO: Got endpoints: latency-svc-jljm6 [753.829558ms]
Feb  6 02:15:35.766: INFO: Created: latency-svc-cj6sm
Feb  6 02:15:35.781: INFO: Got endpoints: latency-svc-wzsph [749.515468ms]
Feb  6 02:15:35.808: INFO: Created: latency-svc-kd9qz
Feb  6 02:15:35.831: INFO: Got endpoints: latency-svc-whgdc [739.618591ms]
Feb  6 02:15:35.861: INFO: Created: latency-svc-4d52v
Feb  6 02:15:35.881: INFO: Got endpoints: latency-svc-hgn56 [749.663568ms]
Feb  6 02:15:35.915: INFO: Created: latency-svc-sfs75
Feb  6 02:15:35.931: INFO: Got endpoints: latency-svc-qgwlx [749.084367ms]
Feb  6 02:15:35.957: INFO: Created: latency-svc-tnjtt
Feb  6 02:15:35.981: INFO: Got endpoints: latency-svc-vlktz [749.670002ms]
Feb  6 02:15:36.009: INFO: Created: latency-svc-gnrpz
Feb  6 02:15:36.032: INFO: Got endpoints: latency-svc-2hhzh [748.665904ms]
Feb  6 02:15:36.061: INFO: Created: latency-svc-z8k9b
Feb  6 02:15:36.082: INFO: Got endpoints: latency-svc-bjvqk [749.392582ms]
Feb  6 02:15:36.107: INFO: Created: latency-svc-ztmgh
Feb  6 02:15:36.131: INFO: Got endpoints: latency-svc-t6h2r [747.910692ms]
Feb  6 02:15:36.157: INFO: Created: latency-svc-bb6bg
Feb  6 02:15:36.184: INFO: Got endpoints: latency-svc-l87fb [750.344368ms]
Feb  6 02:15:36.209: INFO: Created: latency-svc-lmxl7
Feb  6 02:15:36.232: INFO: Got endpoints: latency-svc-p68hs [749.703444ms]
Feb  6 02:15:36.260: INFO: Created: latency-svc-f5wlf
Feb  6 02:15:36.281: INFO: Got endpoints: latency-svc-pxqln [748.230295ms]
Feb  6 02:15:36.332: INFO: Got endpoints: latency-svc-s67fh [750.176158ms]
Feb  6 02:15:36.385: INFO: Got endpoints: latency-svc-xw8s5 [749.628635ms]
Feb  6 02:15:36.434: INFO: Got endpoints: latency-svc-4wblb [752.555235ms]
Feb  6 02:15:36.491: INFO: Created: latency-svc-qcdr4
Feb  6 02:15:36.492: INFO: Created: latency-svc-vclfp
Feb  6 02:15:36.492: INFO: Got endpoints: latency-svc-cj6sm [756.089438ms]
Feb  6 02:15:36.503: INFO: Created: latency-svc-n9dz8
Feb  6 02:15:36.517: INFO: Created: latency-svc-kvd86
Feb  6 02:15:36.534: INFO: Created: latency-svc-msmp9
Feb  6 02:15:36.537: INFO: Got endpoints: latency-svc-kd9qz [755.168767ms]
Feb  6 02:15:36.563: INFO: Created: latency-svc-jnfjx
Feb  6 02:15:36.581: INFO: Got endpoints: latency-svc-4d52v [749.847871ms]
Feb  6 02:15:36.608: INFO: Created: latency-svc-kx6p2
Feb  6 02:15:36.631: INFO: Got endpoints: latency-svc-sfs75 [750.155725ms]
Feb  6 02:15:36.658: INFO: Created: latency-svc-mbwxd
Feb  6 02:15:36.682: INFO: Got endpoints: latency-svc-tnjtt [750.201674ms]
Feb  6 02:15:36.711: INFO: Created: latency-svc-q4hfb
Feb  6 02:15:36.732: INFO: Got endpoints: latency-svc-gnrpz [750.628045ms]
Feb  6 02:15:36.761: INFO: Created: latency-svc-btrqr
Feb  6 02:15:36.783: INFO: Got endpoints: latency-svc-z8k9b [750.609121ms]
Feb  6 02:15:36.808: INFO: Created: latency-svc-6l9zg
Feb  6 02:15:36.832: INFO: Got endpoints: latency-svc-ztmgh [749.756518ms]
Feb  6 02:15:36.863: INFO: Created: latency-svc-tbtzg
Feb  6 02:15:36.884: INFO: Got endpoints: latency-svc-bb6bg [752.339957ms]
Feb  6 02:15:36.916: INFO: Created: latency-svc-gsds6
Feb  6 02:15:36.931: INFO: Got endpoints: latency-svc-lmxl7 [746.965007ms]
Feb  6 02:15:36.956: INFO: Created: latency-svc-rbjwj
Feb  6 02:15:36.982: INFO: Got endpoints: latency-svc-f5wlf [750.324549ms]
Feb  6 02:15:37.009: INFO: Created: latency-svc-mr296
Feb  6 02:15:37.032: INFO: Got endpoints: latency-svc-vclfp [750.930051ms]
Feb  6 02:15:37.062: INFO: Created: latency-svc-lqcld
Feb  6 02:15:37.081: INFO: Got endpoints: latency-svc-qcdr4 [749.229623ms]
Feb  6 02:15:37.107: INFO: Created: latency-svc-7kfcn
Feb  6 02:15:37.135: INFO: Got endpoints: latency-svc-n9dz8 [749.647342ms]
Feb  6 02:15:37.163: INFO: Created: latency-svc-vgkrd
Feb  6 02:15:37.184: INFO: Got endpoints: latency-svc-kvd86 [692.391639ms]
Feb  6 02:15:37.219: INFO: Created: latency-svc-tb4c7
Feb  6 02:15:37.232: INFO: Got endpoints: latency-svc-msmp9 [797.862545ms]
Feb  6 02:15:37.259: INFO: Created: latency-svc-6kxwd
Feb  6 02:15:37.281: INFO: Got endpoints: latency-svc-jnfjx [744.637404ms]
Feb  6 02:15:37.310: INFO: Created: latency-svc-qxt8m
Feb  6 02:15:37.332: INFO: Got endpoints: latency-svc-kx6p2 [750.575977ms]
Feb  6 02:15:37.362: INFO: Created: latency-svc-4rx99
Feb  6 02:15:37.383: INFO: Got endpoints: latency-svc-mbwxd [751.303863ms]
Feb  6 02:15:37.412: INFO: Created: latency-svc-kwmmp
Feb  6 02:15:37.432: INFO: Got endpoints: latency-svc-q4hfb [750.315949ms]
Feb  6 02:15:37.459: INFO: Created: latency-svc-jm67w
Feb  6 02:15:37.481: INFO: Got endpoints: latency-svc-btrqr [749.063828ms]
Feb  6 02:15:37.511: INFO: Created: latency-svc-sd9kz
Feb  6 02:15:37.532: INFO: Got endpoints: latency-svc-6l9zg [749.339067ms]
Feb  6 02:15:37.559: INFO: Created: latency-svc-lq8s7
Feb  6 02:15:37.581: INFO: Got endpoints: latency-svc-tbtzg [749.139738ms]
Feb  6 02:15:37.608: INFO: Created: latency-svc-c47v5
Feb  6 02:15:37.634: INFO: Got endpoints: latency-svc-gsds6 [750.134208ms]
Feb  6 02:15:37.662: INFO: Created: latency-svc-w6jqt
Feb  6 02:15:37.681: INFO: Got endpoints: latency-svc-rbjwj [749.907775ms]
Feb  6 02:15:37.715: INFO: Created: latency-svc-xlmhn
Feb  6 02:15:37.732: INFO: Got endpoints: latency-svc-mr296 [749.831633ms]
Feb  6 02:15:37.759: INFO: Created: latency-svc-flfc9
Feb  6 02:15:37.781: INFO: Got endpoints: latency-svc-lqcld [748.800348ms]
Feb  6 02:15:37.808: INFO: Created: latency-svc-7mmh8
Feb  6 02:15:37.831: INFO: Got endpoints: latency-svc-7kfcn [749.841183ms]
Feb  6 02:15:37.858: INFO: Created: latency-svc-hghrb
Feb  6 02:15:37.881: INFO: Got endpoints: latency-svc-vgkrd [746.463037ms]
Feb  6 02:15:37.907: INFO: Created: latency-svc-zpcz8
Feb  6 02:15:37.932: INFO: Got endpoints: latency-svc-tb4c7 [747.229083ms]
Feb  6 02:15:37.957: INFO: Created: latency-svc-jt65l
Feb  6 02:15:37.981: INFO: Got endpoints: latency-svc-6kxwd [749.167134ms]
Feb  6 02:15:38.010: INFO: Created: latency-svc-gl5r7
Feb  6 02:15:38.032: INFO: Got endpoints: latency-svc-qxt8m [750.50377ms]
Feb  6 02:15:38.065: INFO: Created: latency-svc-2xqxg
Feb  6 02:15:38.081: INFO: Got endpoints: latency-svc-4rx99 [749.095972ms]
Feb  6 02:15:38.107: INFO: Created: latency-svc-jl6tz
Feb  6 02:15:38.133: INFO: Got endpoints: latency-svc-kwmmp [750.332888ms]
Feb  6 02:15:38.157: INFO: Created: latency-svc-sc6gk
Feb  6 02:15:38.181: INFO: Got endpoints: latency-svc-jm67w [749.058187ms]
Feb  6 02:15:38.221: INFO: Created: latency-svc-5bxrm
Feb  6 02:15:38.234: INFO: Got endpoints: latency-svc-sd9kz [752.716481ms]
Feb  6 02:15:38.282: INFO: Got endpoints: latency-svc-lq8s7 [749.868043ms]
Feb  6 02:15:38.331: INFO: Got endpoints: latency-svc-c47v5 [750.138588ms]
Feb  6 02:15:38.391: INFO: Got endpoints: latency-svc-w6jqt [757.089162ms]
Feb  6 02:15:38.432: INFO: Got endpoints: latency-svc-xlmhn [750.376527ms]
Feb  6 02:15:38.481: INFO: Got endpoints: latency-svc-flfc9 [749.445497ms]
Feb  6 02:15:38.532: INFO: Got endpoints: latency-svc-7mmh8 [750.70532ms]
Feb  6 02:15:38.582: INFO: Got endpoints: latency-svc-hghrb [750.456929ms]
Feb  6 02:15:38.632: INFO: Got endpoints: latency-svc-zpcz8 [750.809832ms]
Feb  6 02:15:38.682: INFO: Got endpoints: latency-svc-jt65l [750.003469ms]
Feb  6 02:15:38.731: INFO: Got endpoints: latency-svc-gl5r7 [750.117197ms]
Feb  6 02:15:38.781: INFO: Got endpoints: latency-svc-2xqxg [748.954984ms]
Feb  6 02:15:38.832: INFO: Got endpoints: latency-svc-jl6tz [750.246121ms]
Feb  6 02:15:38.882: INFO: Got endpoints: latency-svc-sc6gk [749.064479ms]
Feb  6 02:15:38.931: INFO: Got endpoints: latency-svc-5bxrm [750.14385ms]
Feb  6 02:15:38.931: INFO: Latencies: [37.899036ms 48.449521ms 66.485876ms 80.597177ms 96.161348ms 108.416805ms 128.068371ms 143.599294ms 168.01759ms 193.619338ms 201.319933ms 217.523444ms 235.524951ms 238.294663ms 245.003065ms 245.828897ms 246.782368ms 246.937802ms 247.118653ms 247.290646ms 247.618697ms 248.196226ms 248.799797ms 249.499373ms 249.866504ms 249.993403ms 250.448071ms 250.475167ms 251.314329ms 253.922852ms 254.858852ms 255.138184ms 256.277383ms 256.424875ms 256.599491ms 256.64857ms 256.946205ms 257.422853ms 257.867984ms 257.953661ms 260.01384ms 260.038689ms 260.069917ms 265.560078ms 265.713936ms 303.031889ms 344.254704ms 373.08957ms 400.476864ms 428.964267ms 446.38083ms 470.352846ms 503.066633ms 538.696358ms 541.036425ms 575.526418ms 593.331957ms 609.374881ms 639.60633ms 642.145901ms 688.372237ms 692.391639ms 725.40175ms 739.031272ms 739.618591ms 744.637404ms 745.187628ms 745.944854ms 746.40431ms 746.463037ms 746.594814ms 746.774098ms 746.875221ms 746.965007ms 747.229083ms 747.600529ms 747.908755ms 747.910692ms 748.054806ms 748.13768ms 748.163715ms 748.230295ms 748.543984ms 748.665904ms 748.700414ms 748.731353ms 748.783368ms 748.800348ms 748.912779ms 748.932962ms 748.954984ms 749.058187ms 749.063828ms 749.064479ms 749.084367ms 749.095972ms 749.128363ms 749.139738ms 749.145598ms 749.167134ms 749.185453ms 749.223166ms 749.229623ms 749.264731ms 749.339067ms 749.392582ms 749.412954ms 749.425869ms 749.445497ms 749.449725ms 749.504305ms 749.515468ms 749.557202ms 749.566555ms 749.628635ms 749.633596ms 749.647342ms 749.663568ms 749.668855ms 749.670002ms 749.703444ms 749.713635ms 749.756518ms 749.831633ms 749.841183ms 749.847871ms 749.868043ms 749.907775ms 749.908418ms 749.934288ms 749.987274ms 750.003469ms 750.117197ms 750.134208ms 750.138588ms 750.14385ms 750.147416ms 750.155725ms 750.176158ms 750.201674ms 750.246121ms 750.251118ms 750.315949ms 750.324549ms 750.332888ms 750.344368ms 750.376527ms 750.429317ms 750.456929ms 750.464281ms 750.50377ms 750.50565ms 750.517554ms 750.521177ms 750.575977ms 750.609121ms 750.628045ms 750.649835ms 750.674965ms 750.699526ms 750.70532ms 750.768569ms 750.804645ms 750.809832ms 750.874828ms 750.900996ms 750.930051ms 750.951666ms 751.033031ms 751.303863ms 751.377962ms 751.560444ms 751.870937ms 752.000743ms 752.193424ms 752.228213ms 752.339957ms 752.413535ms 752.553447ms 752.555235ms 752.558853ms 752.716481ms 753.140705ms 753.50617ms 753.575279ms 753.829558ms 754.60751ms 755.168767ms 756.089438ms 756.221845ms 757.089162ms 760.061756ms 781.369319ms 796.931813ms 797.862545ms 799.983143ms 807.075625ms 859.11407ms 908.934138ms 1.000891851s]
Feb  6 02:15:38.932: INFO: 50 %ile: 749.185453ms
Feb  6 02:15:38.932: INFO: 90 %ile: 752.558853ms
Feb  6 02:15:38.932: INFO: 99 %ile: 908.934138ms
Feb  6 02:15:38.932: INFO: Total sample count: 200
[AfterEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  6 02:15:38.932: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-svc-latency-mg295" for this suite.
Feb  6 02:16:05.005: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 02:16:05.417: INFO: namespace: e2e-tests-svc-latency-mg295, resource: bindings, ignored listing per whitelist
Feb  6 02:16:05.437: INFO: namespace e2e-tests-svc-latency-mg295 deletion completed in 26.490694028s

• [SLOW TEST:37.571 seconds]
[sig-network] Service endpoints latency
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should not be very high  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  6 02:16:05.440: INFO: >>> kubeConfig: /tmp/kubeconfig-131423863
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-daemonsets-k9lvm
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:98
[It] should run and stop simple daemon [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Feb  6 02:16:05.963: INFO: Number of nodes with available pods: 0
Feb  6 02:16:05.963: INFO: Node 10.190.119.133 is running more than one daemon pod
Feb  6 02:16:06.994: INFO: Number of nodes with available pods: 0
Feb  6 02:16:06.994: INFO: Node 10.190.119.133 is running more than one daemon pod
Feb  6 02:16:07.987: INFO: Number of nodes with available pods: 3
Feb  6 02:16:07.987: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Stop a daemon pod, check that the daemon pod is revived.
Feb  6 02:16:08.134: INFO: Number of nodes with available pods: 2
Feb  6 02:16:08.134: INFO: Node 10.190.119.184 is running more than one daemon pod
Feb  6 02:16:09.157: INFO: Number of nodes with available pods: 2
Feb  6 02:16:09.157: INFO: Node 10.190.119.184 is running more than one daemon pod
Feb  6 02:16:10.156: INFO: Number of nodes with available pods: 2
Feb  6 02:16:10.156: INFO: Node 10.190.119.184 is running more than one daemon pod
Feb  6 02:16:11.163: INFO: Number of nodes with available pods: 2
Feb  6 02:16:11.163: INFO: Node 10.190.119.184 is running more than one daemon pod
Feb  6 02:16:12.157: INFO: Number of nodes with available pods: 2
Feb  6 02:16:12.157: INFO: Node 10.190.119.184 is running more than one daemon pod
Feb  6 02:16:13.156: INFO: Number of nodes with available pods: 2
Feb  6 02:16:13.156: INFO: Node 10.190.119.184 is running more than one daemon pod
Feb  6 02:16:14.156: INFO: Number of nodes with available pods: 2
Feb  6 02:16:14.156: INFO: Node 10.190.119.184 is running more than one daemon pod
Feb  6 02:16:15.191: INFO: Number of nodes with available pods: 2
Feb  6 02:16:15.191: INFO: Node 10.190.119.184 is running more than one daemon pod
Feb  6 02:16:16.155: INFO: Number of nodes with available pods: 2
Feb  6 02:16:16.155: INFO: Node 10.190.119.184 is running more than one daemon pod
Feb  6 02:16:17.157: INFO: Number of nodes with available pods: 2
Feb  6 02:16:17.157: INFO: Node 10.190.119.184 is running more than one daemon pod
Feb  6 02:16:18.157: INFO: Number of nodes with available pods: 2
Feb  6 02:16:18.157: INFO: Node 10.190.119.184 is running more than one daemon pod
Feb  6 02:16:19.159: INFO: Number of nodes with available pods: 2
Feb  6 02:16:19.159: INFO: Node 10.190.119.184 is running more than one daemon pod
Feb  6 02:16:20.155: INFO: Number of nodes with available pods: 2
Feb  6 02:16:20.155: INFO: Node 10.190.119.184 is running more than one daemon pod
Feb  6 02:16:21.158: INFO: Number of nodes with available pods: 2
Feb  6 02:16:21.159: INFO: Node 10.190.119.184 is running more than one daemon pod
Feb  6 02:16:22.158: INFO: Number of nodes with available pods: 2
Feb  6 02:16:22.158: INFO: Node 10.190.119.184 is running more than one daemon pod
Feb  6 02:16:23.160: INFO: Number of nodes with available pods: 2
Feb  6 02:16:23.160: INFO: Node 10.190.119.184 is running more than one daemon pod
Feb  6 02:16:24.191: INFO: Number of nodes with available pods: 2
Feb  6 02:16:24.191: INFO: Node 10.190.119.184 is running more than one daemon pod
Feb  6 02:16:25.174: INFO: Number of nodes with available pods: 2
Feb  6 02:16:25.174: INFO: Node 10.190.119.184 is running more than one daemon pod
Feb  6 02:16:26.156: INFO: Number of nodes with available pods: 2
Feb  6 02:16:26.156: INFO: Node 10.190.119.184 is running more than one daemon pod
Feb  6 02:16:27.677: INFO: Number of nodes with available pods: 2
Feb  6 02:16:27.677: INFO: Node 10.190.119.184 is running more than one daemon pod
Feb  6 02:16:28.157: INFO: Number of nodes with available pods: 2
Feb  6 02:16:28.157: INFO: Node 10.190.119.184 is running more than one daemon pod
Feb  6 02:16:29.156: INFO: Number of nodes with available pods: 2
Feb  6 02:16:29.156: INFO: Node 10.190.119.184 is running more than one daemon pod
Feb  6 02:16:30.159: INFO: Number of nodes with available pods: 2
Feb  6 02:16:30.159: INFO: Node 10.190.119.184 is running more than one daemon pod
Feb  6 02:16:31.157: INFO: Number of nodes with available pods: 2
Feb  6 02:16:31.157: INFO: Node 10.190.119.184 is running more than one daemon pod
Feb  6 02:16:32.160: INFO: Number of nodes with available pods: 2
Feb  6 02:16:32.161: INFO: Node 10.190.119.184 is running more than one daemon pod
Feb  6 02:16:33.191: INFO: Number of nodes with available pods: 2
Feb  6 02:16:33.191: INFO: Node 10.190.119.184 is running more than one daemon pod
Feb  6 02:16:34.156: INFO: Number of nodes with available pods: 2
Feb  6 02:16:34.156: INFO: Node 10.190.119.184 is running more than one daemon pod
Feb  6 02:16:35.162: INFO: Number of nodes with available pods: 2
Feb  6 02:16:35.162: INFO: Node 10.190.119.184 is running more than one daemon pod
Feb  6 02:16:36.174: INFO: Number of nodes with available pods: 2
Feb  6 02:16:36.174: INFO: Node 10.190.119.184 is running more than one daemon pod
Feb  6 02:16:37.165: INFO: Number of nodes with available pods: 2
Feb  6 02:16:37.165: INFO: Node 10.190.119.184 is running more than one daemon pod
Feb  6 02:16:38.161: INFO: Number of nodes with available pods: 2
Feb  6 02:16:38.161: INFO: Node 10.190.119.184 is running more than one daemon pod
Feb  6 02:16:39.450: INFO: Number of nodes with available pods: 2
Feb  6 02:16:39.450: INFO: Node 10.190.119.184 is running more than one daemon pod
Feb  6 02:16:40.383: INFO: Number of nodes with available pods: 2
Feb  6 02:16:40.383: INFO: Node 10.190.119.184 is running more than one daemon pod
Feb  6 02:16:41.157: INFO: Number of nodes with available pods: 2
Feb  6 02:16:41.157: INFO: Node 10.190.119.184 is running more than one daemon pod
Feb  6 02:16:42.156: INFO: Number of nodes with available pods: 2
Feb  6 02:16:42.157: INFO: Node 10.190.119.184 is running more than one daemon pod
Feb  6 02:16:43.157: INFO: Number of nodes with available pods: 2
Feb  6 02:16:43.157: INFO: Node 10.190.119.184 is running more than one daemon pod
Feb  6 02:16:44.191: INFO: Number of nodes with available pods: 2
Feb  6 02:16:44.191: INFO: Node 10.190.119.184 is running more than one daemon pod
Feb  6 02:16:45.163: INFO: Number of nodes with available pods: 2
Feb  6 02:16:45.163: INFO: Node 10.190.119.184 is running more than one daemon pod
Feb  6 02:16:46.161: INFO: Number of nodes with available pods: 2
Feb  6 02:16:46.161: INFO: Node 10.190.119.184 is running more than one daemon pod
Feb  6 02:16:47.170: INFO: Number of nodes with available pods: 2
Feb  6 02:16:47.170: INFO: Node 10.190.119.184 is running more than one daemon pod
Feb  6 02:16:48.157: INFO: Number of nodes with available pods: 2
Feb  6 02:16:48.157: INFO: Node 10.190.119.184 is running more than one daemon pod
Feb  6 02:16:49.156: INFO: Number of nodes with available pods: 2
Feb  6 02:16:49.156: INFO: Node 10.190.119.184 is running more than one daemon pod
Feb  6 02:16:50.174: INFO: Number of nodes with available pods: 2
Feb  6 02:16:50.174: INFO: Node 10.190.119.184 is running more than one daemon pod
Feb  6 02:16:51.201: INFO: Number of nodes with available pods: 2
Feb  6 02:16:51.201: INFO: Node 10.190.119.184 is running more than one daemon pod
Feb  6 02:16:52.158: INFO: Number of nodes with available pods: 2
Feb  6 02:16:52.158: INFO: Node 10.190.119.184 is running more than one daemon pod
Feb  6 02:16:53.156: INFO: Number of nodes with available pods: 2
Feb  6 02:16:53.156: INFO: Node 10.190.119.184 is running more than one daemon pod
Feb  6 02:16:54.154: INFO: Number of nodes with available pods: 3
Feb  6 02:16:54.155: INFO: Number of running nodes: 3, number of available pods: 3
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:64
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting {extensions DaemonSet} daemon-set in namespace e2e-tests-daemonsets-k9lvm, will wait for the garbage collector to delete the pods
Feb  6 02:16:54.282: INFO: Deleting {extensions DaemonSet} daemon-set took: 23.390614ms
Feb  6 02:16:54.382: INFO: Terminating {extensions DaemonSet} daemon-set pods took: 100.236927ms
Feb  6 02:17:28.816: INFO: Number of nodes with available pods: 0
Feb  6 02:17:28.816: INFO: Number of running nodes: 0, number of available pods: 0
Feb  6 02:17:28.828: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-k9lvm/daemonsets","resourceVersion":"54409"},"items":null}

Feb  6 02:17:28.839: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-k9lvm/pods","resourceVersion":"54409"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  6 02:17:28.893: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-k9lvm" for this suite.
Feb  6 02:17:36.935: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 02:17:37.111: INFO: namespace: e2e-tests-daemonsets-k9lvm, resource: bindings, ignored listing per whitelist
Feb  6 02:17:37.267: INFO: namespace e2e-tests-daemonsets-k9lvm deletion completed in 8.361550373s

• [SLOW TEST:91.828 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  6 02:17:37.268: INFO: >>> kubeConfig: /tmp/kubeconfig-131423863
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-hblzx
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0777 on tmpfs
Feb  6 02:17:37.589: INFO: Waiting up to 5m0s for pod "pod-5f44b832-29b5-11e9-9603-eaa511fa0b6c" in namespace "e2e-tests-emptydir-hblzx" to be "success or failure"
Feb  6 02:17:37.597: INFO: Pod "pod-5f44b832-29b5-11e9-9603-eaa511fa0b6c": Phase="Pending", Reason="", readiness=false. Elapsed: 7.849896ms
Feb  6 02:17:39.620: INFO: Pod "pod-5f44b832-29b5-11e9-9603-eaa511fa0b6c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.030384462s
STEP: Saw pod success
Feb  6 02:17:39.620: INFO: Pod "pod-5f44b832-29b5-11e9-9603-eaa511fa0b6c" satisfied condition "success or failure"
Feb  6 02:17:39.628: INFO: Trying to get logs from node 10.190.119.133 pod pod-5f44b832-29b5-11e9-9603-eaa511fa0b6c container test-container: <nil>
STEP: delete the pod
Feb  6 02:17:39.691: INFO: Waiting for pod pod-5f44b832-29b5-11e9-9603-eaa511fa0b6c to disappear
Feb  6 02:17:39.701: INFO: Pod pod-5f44b832-29b5-11e9-9603-eaa511fa0b6c no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  6 02:17:39.701: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-hblzx" for this suite.
Feb  6 02:17:45.743: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 02:17:46.460: INFO: namespace: e2e-tests-emptydir-hblzx, resource: bindings, ignored listing per whitelist
Feb  6 02:17:46.561: INFO: namespace e2e-tests-emptydir-hblzx deletion completed in 6.844791597s

• [SLOW TEST:9.293 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  6 02:17:46.562: INFO: >>> kubeConfig: /tmp/kubeconfig-131423863
STEP: Building a namespace api object, basename sched-pred
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-sched-pred-rz7hs
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:78
Feb  6 02:17:47.426: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Feb  6 02:17:47.514: INFO: Waiting for terminating namespaces to be deleted...
Feb  6 02:17:47.522: INFO: 
Logging pods the kubelet thinks is on node 10.190.119.133 before test
Feb  6 02:17:47.553: INFO: ibm-master-proxy-static-10.190.119.133 from kube-system started at <nil> (0 container statuses recorded)
Feb  6 02:17:47.553: INFO: kube-dns-amd64-fddfcc69-g2lwr from kube-system started at 2019-02-05 20:42:13 +0000 UTC (3 container statuses recorded)
Feb  6 02:17:47.553: INFO: 	Container dnsmasq ready: true, restart count 0
Feb  6 02:17:47.553: INFO: 	Container kubedns ready: true, restart count 0
Feb  6 02:17:47.553: INFO: 	Container sidecar ready: true, restart count 0
Feb  6 02:17:47.553: INFO: public-crf54ba0a8e6a945a29dcf052ae5eb4941-alb1-6c9c6d49c8-mpnh2 from kube-system started at 2019-02-05 20:47:04 +0000 UTC (4 container statuses recorded)
Feb  6 02:17:47.553: INFO: 	Container ingress-auth-1 ready: true, restart count 0
Feb  6 02:17:47.553: INFO: 	Container ingress-auth-2 ready: true, restart count 0
Feb  6 02:17:47.553: INFO: 	Container ingress-auth-3 ready: true, restart count 0
Feb  6 02:17:47.553: INFO: 	Container nginx-ingress ready: true, restart count 0
Feb  6 02:17:47.553: INFO: ibm-cloud-provider-ip-169-61-69-214-6d655b596d-zg2pn from ibm-system started at 2019-02-05 20:43:56 +0000 UTC (1 container statuses recorded)
Feb  6 02:17:47.553: INFO: 	Container ibm-cloud-provider-ip-169-61-69-214 ready: true, restart count 0
Feb  6 02:17:47.553: INFO: ibm-kube-fluentd-64s4c from kube-system started at 2019-02-05 20:45:46 +0000 UTC (1 container statuses recorded)
Feb  6 02:17:47.553: INFO: 	Container fluentd ready: true, restart count 0
Feb  6 02:17:47.553: INFO: sonobuoy-systemd-logs-daemon-set-d5b52e18812640c6-b9jsg from heptio-sonobuoy started at 2019-02-06 01:52:35 +0000 UTC (2 container statuses recorded)
Feb  6 02:17:47.553: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 0
Feb  6 02:17:47.553: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Feb  6 02:17:47.553: INFO: ibm-keepalived-watcher-bsbdb from kube-system started at 2019-02-05 20:41:39 +0000 UTC (1 container statuses recorded)
Feb  6 02:17:47.553: INFO: 	Container keepalived-watcher ready: true, restart count 0
Feb  6 02:17:47.553: INFO: calico-node-crvvm from kube-system started at 2019-02-05 20:41:39 +0000 UTC (2 container statuses recorded)
Feb  6 02:17:47.553: INFO: 	Container calico-node ready: true, restart count 0
Feb  6 02:17:47.553: INFO: 	Container install-cni ready: true, restart count 0
Feb  6 02:17:47.553: INFO: 
Logging pods the kubelet thinks is on node 10.190.119.143 before test
Feb  6 02:17:47.580: INFO: ibm-master-proxy-static-10.190.119.143 from kube-system started at <nil> (0 container statuses recorded)
Feb  6 02:17:47.580: INFO: ibm-keepalived-watcher-mhfb7 from kube-system started at 2019-02-05 20:41:40 +0000 UTC (1 container statuses recorded)
Feb  6 02:17:47.580: INFO: 	Container keepalived-watcher ready: true, restart count 0
Feb  6 02:17:47.581: INFO: ibm-kube-fluentd-m6bg7 from kube-system started at 2019-02-05 20:45:46 +0000 UTC (1 container statuses recorded)
Feb  6 02:17:47.582: INFO: 	Container fluentd ready: true, restart count 0
Feb  6 02:17:47.582: INFO: public-crf54ba0a8e6a945a29dcf052ae5eb4941-alb1-6c9c6d49c8-v28fj from kube-system started at 2019-02-05 20:47:04 +0000 UTC (4 container statuses recorded)
Feb  6 02:17:47.582: INFO: 	Container ingress-auth-1 ready: true, restart count 0
Feb  6 02:17:47.582: INFO: 	Container ingress-auth-2 ready: true, restart count 0
Feb  6 02:17:47.582: INFO: 	Container ingress-auth-3 ready: true, restart count 0
Feb  6 02:17:47.582: INFO: 	Container nginx-ingress ready: true, restart count 0
Feb  6 02:17:47.582: INFO: ibm-cloud-provider-ip-169-61-69-214-6d655b596d-659s6 from ibm-system started at 2019-02-05 20:43:56 +0000 UTC (1 container statuses recorded)
Feb  6 02:17:47.582: INFO: 	Container ibm-cloud-provider-ip-169-61-69-214 ready: true, restart count 0
Feb  6 02:17:47.582: INFO: sonobuoy-systemd-logs-daemon-set-d5b52e18812640c6-ftvb9 from heptio-sonobuoy started at 2019-02-06 01:52:35 +0000 UTC (2 container statuses recorded)
Feb  6 02:17:47.582: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 0
Feb  6 02:17:47.582: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Feb  6 02:17:47.582: INFO: calico-node-552zb from kube-system started at 2019-02-05 20:41:40 +0000 UTC (2 container statuses recorded)
Feb  6 02:17:47.582: INFO: 	Container calico-node ready: true, restart count 0
Feb  6 02:17:47.582: INFO: 	Container install-cni ready: true, restart count 0
Feb  6 02:17:47.582: INFO: test-k8s-e2e-pvg-master-verification from default started at 2019-02-06 01:52:27 +0000 UTC (1 container statuses recorded)
Feb  6 02:17:47.582: INFO: 	Container test-k8s-e2e-pvg-master-verification ready: true, restart count 0
Feb  6 02:17:47.582: INFO: sonobuoy-e2e-job-0d701a7a98354698 from heptio-sonobuoy started at 2019-02-06 01:52:35 +0000 UTC (2 container statuses recorded)
Feb  6 02:17:47.582: INFO: 	Container e2e ready: true, restart count 0
Feb  6 02:17:47.582: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Feb  6 02:17:47.582: INFO: 
Logging pods the kubelet thinks is on node 10.190.119.184 before test
Feb  6 02:17:47.612: INFO: ibm-master-proxy-static-10.190.119.184 from kube-system started at <nil> (0 container statuses recorded)
Feb  6 02:17:47.612: INFO: calico-kube-controllers-5c699798bc-q5g5q from kube-system started at 2019-02-05 20:41:33 +0000 UTC (1 container statuses recorded)
Feb  6 02:17:47.612: INFO: 	Container calico-kube-controllers ready: true, restart count 0
Feb  6 02:17:47.612: INFO: kube-dns-amd64-fddfcc69-stz86 from kube-system started at 2019-02-05 20:41:33 +0000 UTC (3 container statuses recorded)
Feb  6 02:17:47.612: INFO: 	Container dnsmasq ready: true, restart count 0
Feb  6 02:17:47.612: INFO: 	Container kubedns ready: true, restart count 0
Feb  6 02:17:47.612: INFO: 	Container sidecar ready: true, restart count 0
Feb  6 02:17:47.612: INFO: metrics-server-58cf9b87b8-lqfd8 from kube-system started at 2019-02-05 20:41:53 +0000 UTC (2 container statuses recorded)
Feb  6 02:17:47.612: INFO: 	Container metrics-server ready: true, restart count 0
Feb  6 02:17:47.612: INFO: 	Container metrics-server-nanny ready: true, restart count 0
Feb  6 02:17:47.612: INFO: ibm-keepalived-watcher-zff5x from kube-system started at 2019-02-05 20:41:33 +0000 UTC (1 container statuses recorded)
Feb  6 02:17:47.612: INFO: 	Container keepalived-watcher ready: true, restart count 0
Feb  6 02:17:47.612: INFO: ibm-kube-fluentd-xhx62 from kube-system started at 2019-02-05 20:45:46 +0000 UTC (1 container statuses recorded)
Feb  6 02:17:47.612: INFO: 	Container fluentd ready: true, restart count 0
Feb  6 02:17:47.612: INFO: sonobuoy-systemd-logs-daemon-set-d5b52e18812640c6-jw4pz from heptio-sonobuoy started at 2019-02-06 01:52:35 +0000 UTC (2 container statuses recorded)
Feb  6 02:17:47.612: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 0
Feb  6 02:17:47.612: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Feb  6 02:17:47.612: INFO: kube-dns-autoscaler-587cd5cd44-gcztk from kube-system started at 2019-02-05 20:41:33 +0000 UTC (1 container statuses recorded)
Feb  6 02:17:47.612: INFO: 	Container autoscaler ready: true, restart count 0
Feb  6 02:17:47.612: INFO: ibm-storage-watcher-59744c5787-r9jsw from kube-system started at 2019-02-05 20:41:33 +0000 UTC (1 container statuses recorded)
Feb  6 02:17:47.612: INFO: 	Container ibm-storage-watcher-container ready: true, restart count 0
Feb  6 02:17:47.612: INFO: kubernetes-dashboard-b4bc7db5d-6txlp from kube-system started at 2019-02-05 20:41:33 +0000 UTC (1 container statuses recorded)
Feb  6 02:17:47.613: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
Feb  6 02:17:47.613: INFO: sonobuoy from heptio-sonobuoy started at 2019-02-06 01:52:33 +0000 UTC (1 container statuses recorded)
Feb  6 02:17:47.613: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Feb  6 02:17:47.613: INFO: vpn-6c6b45457f-dw7t6 from kube-system started at 2019-02-05 20:41:33 +0000 UTC (1 container statuses recorded)
Feb  6 02:17:47.613: INFO: 	Container vpn ready: true, restart count 0
Feb  6 02:17:47.613: INFO: ibm-file-plugin-7b5c95b4d-hcw67 from kube-system started at 2019-02-05 20:41:33 +0000 UTC (1 container statuses recorded)
Feb  6 02:17:47.613: INFO: 	Container ibm-file-plugin-container ready: true, restart count 0
Feb  6 02:17:47.613: INFO: calico-node-vk476 from kube-system started at 2019-02-05 20:41:33 +0000 UTC (2 container statuses recorded)
Feb  6 02:17:47.613: INFO: 	Container calico-node ready: true, restart count 0
Feb  6 02:17:47.613: INFO: 	Container install-cni ready: true, restart count 0
[It] validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Trying to launch a pod without a label to get a node which can launch it.
STEP: Explicitly delete pod here to free the resource it takes.
STEP: Trying to apply a random label on the found node.
STEP: verifying the node has the label kubernetes.io/e2e-668e4936-29b5-11e9-9603-eaa511fa0b6c 42
STEP: Trying to relaunch the pod, now with labels.
STEP: removing the label kubernetes.io/e2e-668e4936-29b5-11e9-9603-eaa511fa0b6c off the node 10.190.119.143
STEP: verifying the node doesn't have the label kubernetes.io/e2e-668e4936-29b5-11e9-9603-eaa511fa0b6c
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  6 02:17:51.895: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-sched-pred-rz7hs" for this suite.
Feb  6 02:18:13.935: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 02:18:14.220: INFO: namespace: e2e-tests-sched-pred-rz7hs, resource: bindings, ignored listing per whitelist
Feb  6 02:18:14.260: INFO: namespace e2e-tests-sched-pred-rz7hs deletion completed in 22.351855525s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:69

• [SLOW TEST:27.698 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run default 
  should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  6 02:18:14.261: INFO: >>> kubeConfig: /tmp/kubeconfig-131423863
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-n7pg6
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Kubectl run default
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1210
[It] should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Feb  6 02:18:14.563: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-131423863 run e2e-test-nginx-deployment --image=docker.io/library/nginx:1.14-alpine --namespace=e2e-tests-kubectl-n7pg6'
Feb  6 02:18:14.933: INFO: stderr: "kubectl run --generator=deployment/apps.v1beta1 is DEPRECATED and will be removed in a future version. Use kubectl create instead.\n"
Feb  6 02:18:14.933: INFO: stdout: "deployment.apps/e2e-test-nginx-deployment created\n"
STEP: verifying the pod controlled by e2e-test-nginx-deployment gets created
[AfterEach] [k8s.io] Kubectl run default
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1216
Feb  6 02:18:16.951: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-131423863 delete deployment e2e-test-nginx-deployment --namespace=e2e-tests-kubectl-n7pg6'
Feb  6 02:18:17.120: INFO: stderr: ""
Feb  6 02:18:17.120: INFO: stdout: "deployment.extensions \"e2e-test-nginx-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  6 02:18:17.120: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-n7pg6" for this suite.
Feb  6 02:18:41.158: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 02:18:41.795: INFO: namespace: e2e-tests-kubectl-n7pg6, resource: bindings, ignored listing per whitelist
Feb  6 02:18:41.827: INFO: namespace e2e-tests-kubectl-n7pg6 deletion completed in 24.695030836s

• [SLOW TEST:27.567 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run default
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create an rc or deployment from an image  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Projected 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  6 02:18:41.828: INFO: >>> kubeConfig: /tmp/kubeconfig-131423863
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-kftgf
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb  6 02:18:42.166: INFO: Waiting up to 5m0s for pod "downwardapi-volume-85c2c47a-29b5-11e9-9603-eaa511fa0b6c" in namespace "e2e-tests-projected-kftgf" to be "success or failure"
Feb  6 02:18:42.179: INFO: Pod "downwardapi-volume-85c2c47a-29b5-11e9-9603-eaa511fa0b6c": Phase="Pending", Reason="", readiness=false. Elapsed: 12.400502ms
Feb  6 02:18:44.188: INFO: Pod "downwardapi-volume-85c2c47a-29b5-11e9-9603-eaa511fa0b6c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.021250789s
STEP: Saw pod success
Feb  6 02:18:44.188: INFO: Pod "downwardapi-volume-85c2c47a-29b5-11e9-9603-eaa511fa0b6c" satisfied condition "success or failure"
Feb  6 02:18:44.198: INFO: Trying to get logs from node 10.190.119.133 pod downwardapi-volume-85c2c47a-29b5-11e9-9603-eaa511fa0b6c container client-container: <nil>
STEP: delete the pod
Feb  6 02:18:44.291: INFO: Waiting for pod downwardapi-volume-85c2c47a-29b5-11e9-9603-eaa511fa0b6c to disappear
Feb  6 02:18:44.300: INFO: Pod downwardapi-volume-85c2c47a-29b5-11e9-9603-eaa511fa0b6c no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  6 02:18:44.300: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-kftgf" for this suite.
Feb  6 02:18:50.393: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 02:18:50.526: INFO: namespace: e2e-tests-projected-kftgf, resource: bindings, ignored listing per whitelist
Feb  6 02:18:50.941: INFO: namespace e2e-tests-projected-kftgf deletion completed in 6.629079449s

• [SLOW TEST:9.114 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[k8s.io] [sig-node] Events 
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  6 02:18:50.942: INFO: >>> kubeConfig: /tmp/kubeconfig-131423863
STEP: Building a namespace api object, basename events
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-events-hbsr8
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: retrieving the pod
Feb  6 02:18:53.349: INFO: &Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:send-events-8b2dcd97-29b5-11e9-9603-eaa511fa0b6c,GenerateName:,Namespace:e2e-tests-events-hbsr8,SelfLink:/api/v1/namespaces/e2e-tests-events-hbsr8/pods/send-events-8b2dcd97-29b5-11e9-9603-eaa511fa0b6c,UID:8b37e6a4-29b5-11e9-bf83-6639c2940cda,ResourceVersion:54779,Generation:0,CreationTimestamp:2019-02-06 02:18:51 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: foo,time: 236501708,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-2cpgn {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-2cpgn,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{p gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1 [] []  [{ 0 80 TCP }] [] [] {map[] map[]} [{default-token-2cpgn true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*30,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.190.119.133,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc421b0ff60} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421b0ff80}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-06 02:18:51 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-02-06 02:18:52 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-02-06 02:18:52 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-06 02:18:51 +0000 UTC  }],Message:,Reason:,HostIP:10.190.119.133,PodIP:172.30.176.8,StartTime:2019-02-06 02:18:51 +0000 UTC,ContainerStatuses:[{p {nil ContainerStateRunning{StartedAt:2019-02-06 02:18:52 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1 gcr.io/kubernetes-e2e-test-images/serve-hostname@sha256:bab70473a6d8ef65a22625dc9a1b0f0452e811530fdbe77e4408523460177ff1 containerd://9db9a35f2d76d2318e967a9b5520bf7dbcd7d6981a0f042dab1739c8125881a0}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}

STEP: checking for scheduler event about the pod
Feb  6 02:18:55.359: INFO: Saw scheduler event for our pod.
STEP: checking for kubelet event about the pod
Feb  6 02:18:57.772: INFO: Saw kubelet event for our pod.
STEP: deleting the pod
[AfterEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  6 02:18:57.801: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-events-hbsr8" for this suite.
Feb  6 02:19:39.840: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 02:19:40.006: INFO: namespace: e2e-tests-events-hbsr8, resource: bindings, ignored listing per whitelist
Feb  6 02:19:40.204: INFO: namespace e2e-tests-events-hbsr8 deletion completed in 42.389123289s

• [SLOW TEST:49.262 seconds]
[k8s.io] [sig-node] Events
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  6 02:19:40.204: INFO: >>> kubeConfig: /tmp/kubeconfig-131423863
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-container-probe-gmnw6
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-exec in namespace e2e-tests-container-probe-gmnw6
Feb  6 02:19:42.641: INFO: Started pod liveness-exec in namespace e2e-tests-container-probe-gmnw6
STEP: checking the pod's current state and verifying that restartCount is present
Feb  6 02:19:42.650: INFO: Initial restart count of pod liveness-exec is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  6 02:23:44.416: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-gmnw6" for this suite.
Feb  6 02:23:50.519: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 02:23:50.724: INFO: namespace: e2e-tests-container-probe-gmnw6, resource: bindings, ignored listing per whitelist
Feb  6 02:23:51.002: INFO: namespace e2e-tests-container-probe-gmnw6 deletion completed in 6.509900732s

• [SLOW TEST:250.797 seconds]
[k8s.io] Probing container
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-api-machinery] Downward API 
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  6 02:23:51.003: INFO: >>> kubeConfig: /tmp/kubeconfig-131423863
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-6xhxz
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Feb  6 02:23:51.326: INFO: Waiting up to 5m0s for pod "downward-api-3e090c98-29b6-11e9-9603-eaa511fa0b6c" in namespace "e2e-tests-downward-api-6xhxz" to be "success or failure"
Feb  6 02:23:51.339: INFO: Pod "downward-api-3e090c98-29b6-11e9-9603-eaa511fa0b6c": Phase="Pending", Reason="", readiness=false. Elapsed: 12.844643ms
Feb  6 02:23:53.349: INFO: Pod "downward-api-3e090c98-29b6-11e9-9603-eaa511fa0b6c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.022534304s
STEP: Saw pod success
Feb  6 02:23:53.349: INFO: Pod "downward-api-3e090c98-29b6-11e9-9603-eaa511fa0b6c" satisfied condition "success or failure"
Feb  6 02:23:53.391: INFO: Trying to get logs from node 10.190.119.133 pod downward-api-3e090c98-29b6-11e9-9603-eaa511fa0b6c container dapi-container: <nil>
STEP: delete the pod
Feb  6 02:23:53.443: INFO: Waiting for pod downward-api-3e090c98-29b6-11e9-9603-eaa511fa0b6c to disappear
Feb  6 02:23:53.453: INFO: Pod downward-api-3e090c98-29b6-11e9-9603-eaa511fa0b6c no longer exists
[AfterEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  6 02:23:53.454: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-6xhxz" for this suite.
Feb  6 02:23:59.495: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 02:23:59.766: INFO: namespace: e2e-tests-downward-api-6xhxz, resource: bindings, ignored listing per whitelist
Feb  6 02:23:59.901: INFO: namespace e2e-tests-downward-api-6xhxz deletion completed in 6.436117134s

• [SLOW TEST:8.898 seconds]
[sig-api-machinery] Downward API
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-auth] ServiceAccounts 
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  6 02:23:59.902: INFO: >>> kubeConfig: /tmp/kubeconfig-131423863
STEP: Building a namespace api object, basename svcaccounts
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-svcaccounts-bq9j9
STEP: Waiting for a default service account to be provisioned in namespace
[It] should mount an API token into pods  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: getting the auto-created API token
STEP: Creating a pod to test consume service account token
Feb  6 02:24:00.859: INFO: Waiting up to 5m0s for pod "pod-service-account-43b6e0a7-29b6-11e9-9603-eaa511fa0b6c-n7hsr" in namespace "e2e-tests-svcaccounts-bq9j9" to be "success or failure"
Feb  6 02:24:00.875: INFO: Pod "pod-service-account-43b6e0a7-29b6-11e9-9603-eaa511fa0b6c-n7hsr": Phase="Pending", Reason="", readiness=false. Elapsed: 15.969352ms
Feb  6 02:24:02.885: INFO: Pod "pod-service-account-43b6e0a7-29b6-11e9-9603-eaa511fa0b6c-n7hsr": Phase="Running", Reason="", readiness=false. Elapsed: 2.02542396s
Feb  6 02:24:04.893: INFO: Pod "pod-service-account-43b6e0a7-29b6-11e9-9603-eaa511fa0b6c-n7hsr": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.034223278s
STEP: Saw pod success
Feb  6 02:24:04.893: INFO: Pod "pod-service-account-43b6e0a7-29b6-11e9-9603-eaa511fa0b6c-n7hsr" satisfied condition "success or failure"
Feb  6 02:24:04.901: INFO: Trying to get logs from node 10.190.119.143 pod pod-service-account-43b6e0a7-29b6-11e9-9603-eaa511fa0b6c-n7hsr container token-test: <nil>
STEP: delete the pod
Feb  6 02:24:04.993: INFO: Waiting for pod pod-service-account-43b6e0a7-29b6-11e9-9603-eaa511fa0b6c-n7hsr to disappear
Feb  6 02:24:05.001: INFO: Pod pod-service-account-43b6e0a7-29b6-11e9-9603-eaa511fa0b6c-n7hsr no longer exists
STEP: Creating a pod to test consume service account root CA
Feb  6 02:24:05.013: INFO: Waiting up to 5m0s for pod "pod-service-account-43b6e0a7-29b6-11e9-9603-eaa511fa0b6c-76vc9" in namespace "e2e-tests-svcaccounts-bq9j9" to be "success or failure"
Feb  6 02:24:05.023: INFO: Pod "pod-service-account-43b6e0a7-29b6-11e9-9603-eaa511fa0b6c-76vc9": Phase="Pending", Reason="", readiness=false. Elapsed: 9.233593ms
Feb  6 02:24:07.032: INFO: Pod "pod-service-account-43b6e0a7-29b6-11e9-9603-eaa511fa0b6c-76vc9": Phase="Pending", Reason="", readiness=false. Elapsed: 2.018194861s
Feb  6 02:24:09.054: INFO: Pod "pod-service-account-43b6e0a7-29b6-11e9-9603-eaa511fa0b6c-76vc9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.041154379s
STEP: Saw pod success
Feb  6 02:24:09.055: INFO: Pod "pod-service-account-43b6e0a7-29b6-11e9-9603-eaa511fa0b6c-76vc9" satisfied condition "success or failure"
Feb  6 02:24:09.063: INFO: Trying to get logs from node 10.190.119.184 pod pod-service-account-43b6e0a7-29b6-11e9-9603-eaa511fa0b6c-76vc9 container root-ca-test: <nil>
STEP: delete the pod
Feb  6 02:24:09.124: INFO: Waiting for pod pod-service-account-43b6e0a7-29b6-11e9-9603-eaa511fa0b6c-76vc9 to disappear
Feb  6 02:24:09.131: INFO: Pod pod-service-account-43b6e0a7-29b6-11e9-9603-eaa511fa0b6c-76vc9 no longer exists
STEP: Creating a pod to test consume service account namespace
Feb  6 02:24:09.146: INFO: Waiting up to 5m0s for pod "pod-service-account-43b6e0a7-29b6-11e9-9603-eaa511fa0b6c-tx8r2" in namespace "e2e-tests-svcaccounts-bq9j9" to be "success or failure"
Feb  6 02:24:09.155: INFO: Pod "pod-service-account-43b6e0a7-29b6-11e9-9603-eaa511fa0b6c-tx8r2": Phase="Pending", Reason="", readiness=false. Elapsed: 9.15502ms
Feb  6 02:24:11.166: INFO: Pod "pod-service-account-43b6e0a7-29b6-11e9-9603-eaa511fa0b6c-tx8r2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.019860616s
Feb  6 02:24:13.175: INFO: Pod "pod-service-account-43b6e0a7-29b6-11e9-9603-eaa511fa0b6c-tx8r2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.028777477s
STEP: Saw pod success
Feb  6 02:24:13.175: INFO: Pod "pod-service-account-43b6e0a7-29b6-11e9-9603-eaa511fa0b6c-tx8r2" satisfied condition "success or failure"
Feb  6 02:24:13.199: INFO: Trying to get logs from node 10.190.119.133 pod pod-service-account-43b6e0a7-29b6-11e9-9603-eaa511fa0b6c-tx8r2 container namespace-test: <nil>
STEP: delete the pod
Feb  6 02:24:13.246: INFO: Waiting for pod pod-service-account-43b6e0a7-29b6-11e9-9603-eaa511fa0b6c-tx8r2 to disappear
Feb  6 02:24:13.253: INFO: Pod pod-service-account-43b6e0a7-29b6-11e9-9603-eaa511fa0b6c-tx8r2 no longer exists
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  6 02:24:13.253: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-svcaccounts-bq9j9" for this suite.
Feb  6 02:24:19.309: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 02:24:19.647: INFO: namespace: e2e-tests-svcaccounts-bq9j9, resource: bindings, ignored listing per whitelist
Feb  6 02:24:19.741: INFO: namespace e2e-tests-svcaccounts-bq9j9 deletion completed in 6.472692343s

• [SLOW TEST:19.840 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:22
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  6 02:24:19.743: INFO: >>> kubeConfig: /tmp/kubeconfig-131423863
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-mpxj6
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-map-4f2cc95b-29b6-11e9-9603-eaa511fa0b6c
STEP: Creating a pod to test consume secrets
Feb  6 02:24:20.092: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-4f2e6086-29b6-11e9-9603-eaa511fa0b6c" in namespace "e2e-tests-projected-mpxj6" to be "success or failure"
Feb  6 02:24:20.101: INFO: Pod "pod-projected-secrets-4f2e6086-29b6-11e9-9603-eaa511fa0b6c": Phase="Pending", Reason="", readiness=false. Elapsed: 8.645379ms
Feb  6 02:24:22.110: INFO: Pod "pod-projected-secrets-4f2e6086-29b6-11e9-9603-eaa511fa0b6c": Phase="Running", Reason="", readiness=true. Elapsed: 2.017776361s
Feb  6 02:24:24.119: INFO: Pod "pod-projected-secrets-4f2e6086-29b6-11e9-9603-eaa511fa0b6c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.026890982s
STEP: Saw pod success
Feb  6 02:24:24.119: INFO: Pod "pod-projected-secrets-4f2e6086-29b6-11e9-9603-eaa511fa0b6c" satisfied condition "success or failure"
Feb  6 02:24:24.129: INFO: Trying to get logs from node 10.190.119.143 pod pod-projected-secrets-4f2e6086-29b6-11e9-9603-eaa511fa0b6c container projected-secret-volume-test: <nil>
STEP: delete the pod
Feb  6 02:24:24.192: INFO: Waiting for pod pod-projected-secrets-4f2e6086-29b6-11e9-9603-eaa511fa0b6c to disappear
Feb  6 02:24:24.202: INFO: Pod pod-projected-secrets-4f2e6086-29b6-11e9-9603-eaa511fa0b6c no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  6 02:24:24.202: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-mpxj6" for this suite.
Feb  6 02:24:32.239: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 02:24:32.454: INFO: namespace: e2e-tests-projected-mpxj6, resource: bindings, ignored listing per whitelist
Feb  6 02:24:32.607: INFO: namespace e2e-tests-projected-mpxj6 deletion completed in 8.393885196s

• [SLOW TEST:12.864 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with projected pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  6 02:24:32.607: INFO: >>> kubeConfig: /tmp/kubeconfig-131423863
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-subpath-k2bbj
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with projected pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-projected-xzlt
STEP: Creating a pod to test atomic-volume-subpath
Feb  6 02:24:32.964: INFO: Waiting up to 5m0s for pod "pod-subpath-test-projected-xzlt" in namespace "e2e-tests-subpath-k2bbj" to be "success or failure"
Feb  6 02:24:32.973: INFO: Pod "pod-subpath-test-projected-xzlt": Phase="Pending", Reason="", readiness=false. Elapsed: 9.319249ms
Feb  6 02:24:34.982: INFO: Pod "pod-subpath-test-projected-xzlt": Phase="Pending", Reason="", readiness=false. Elapsed: 2.018193977s
Feb  6 02:24:36.997: INFO: Pod "pod-subpath-test-projected-xzlt": Phase="Running", Reason="", readiness=false. Elapsed: 4.033375724s
Feb  6 02:24:39.006: INFO: Pod "pod-subpath-test-projected-xzlt": Phase="Running", Reason="", readiness=false. Elapsed: 6.042240922s
Feb  6 02:24:41.036: INFO: Pod "pod-subpath-test-projected-xzlt": Phase="Running", Reason="", readiness=false. Elapsed: 8.072435169s
Feb  6 02:24:43.045: INFO: Pod "pod-subpath-test-projected-xzlt": Phase="Running", Reason="", readiness=false. Elapsed: 10.081333103s
Feb  6 02:24:45.055: INFO: Pod "pod-subpath-test-projected-xzlt": Phase="Running", Reason="", readiness=false. Elapsed: 12.091343649s
Feb  6 02:24:47.066: INFO: Pod "pod-subpath-test-projected-xzlt": Phase="Running", Reason="", readiness=false. Elapsed: 14.102619676s
Feb  6 02:24:49.076: INFO: Pod "pod-subpath-test-projected-xzlt": Phase="Running", Reason="", readiness=false. Elapsed: 16.111994402s
Feb  6 02:24:51.096: INFO: Pod "pod-subpath-test-projected-xzlt": Phase="Running", Reason="", readiness=false. Elapsed: 18.13264944s
Feb  6 02:24:53.106: INFO: Pod "pod-subpath-test-projected-xzlt": Phase="Running", Reason="", readiness=false. Elapsed: 20.141900169s
Feb  6 02:24:55.115: INFO: Pod "pod-subpath-test-projected-xzlt": Phase="Running", Reason="", readiness=false. Elapsed: 22.151568702s
Feb  6 02:24:57.124: INFO: Pod "pod-subpath-test-projected-xzlt": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.160376371s
STEP: Saw pod success
Feb  6 02:24:57.124: INFO: Pod "pod-subpath-test-projected-xzlt" satisfied condition "success or failure"
Feb  6 02:24:57.133: INFO: Trying to get logs from node 10.190.119.143 pod pod-subpath-test-projected-xzlt container test-container-subpath-projected-xzlt: <nil>
STEP: delete the pod
Feb  6 02:24:57.191: INFO: Waiting for pod pod-subpath-test-projected-xzlt to disappear
Feb  6 02:24:57.204: INFO: Pod pod-subpath-test-projected-xzlt no longer exists
STEP: Deleting pod pod-subpath-test-projected-xzlt
Feb  6 02:24:57.204: INFO: Deleting pod "pod-subpath-test-projected-xzlt" in namespace "e2e-tests-subpath-k2bbj"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  6 02:24:57.212: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-k2bbj" for this suite.
Feb  6 02:25:05.260: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 02:25:05.534: INFO: namespace: e2e-tests-subpath-k2bbj, resource: bindings, ignored listing per whitelist
Feb  6 02:25:05.598: INFO: namespace e2e-tests-subpath-k2bbj deletion completed in 8.367581296s

• [SLOW TEST:32.991 seconds]
[sig-storage] Subpath
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with projected pod [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should scale a replication controller  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  6 02:25:05.599: INFO: >>> kubeConfig: /tmp/kubeconfig-131423863
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-8pjjs
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:293
[It] should scale a replication controller  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a replication controller
Feb  6 02:25:05.906: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-131423863 create -f - --namespace=e2e-tests-kubectl-8pjjs'
Feb  6 02:25:06.198: INFO: stderr: ""
Feb  6 02:25:06.198: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Feb  6 02:25:06.198: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-131423863 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-8pjjs'
Feb  6 02:25:06.348: INFO: stderr: ""
Feb  6 02:25:06.348: INFO: stdout: "update-demo-nautilus-96mj4 update-demo-nautilus-vvxmz "
Feb  6 02:25:06.348: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-131423863 get pods update-demo-nautilus-96mj4 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-8pjjs'
Feb  6 02:25:06.468: INFO: stderr: ""
Feb  6 02:25:06.468: INFO: stdout: ""
Feb  6 02:25:06.468: INFO: update-demo-nautilus-96mj4 is created but not running
Feb  6 02:25:11.468: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-131423863 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-8pjjs'
Feb  6 02:25:11.603: INFO: stderr: ""
Feb  6 02:25:11.603: INFO: stdout: "update-demo-nautilus-96mj4 update-demo-nautilus-vvxmz "
Feb  6 02:25:11.604: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-131423863 get pods update-demo-nautilus-96mj4 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-8pjjs'
Feb  6 02:25:11.724: INFO: stderr: ""
Feb  6 02:25:11.724: INFO: stdout: "true"
Feb  6 02:25:11.724: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-131423863 get pods update-demo-nautilus-96mj4 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-8pjjs'
Feb  6 02:25:11.849: INFO: stderr: ""
Feb  6 02:25:11.849: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Feb  6 02:25:11.849: INFO: validating pod update-demo-nautilus-96mj4
Feb  6 02:25:11.892: INFO: got data: {
  "image": "nautilus.jpg"
}

Feb  6 02:25:11.892: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Feb  6 02:25:11.892: INFO: update-demo-nautilus-96mj4 is verified up and running
Feb  6 02:25:11.892: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-131423863 get pods update-demo-nautilus-vvxmz -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-8pjjs'
Feb  6 02:25:12.037: INFO: stderr: ""
Feb  6 02:25:12.037: INFO: stdout: "true"
Feb  6 02:25:12.037: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-131423863 get pods update-demo-nautilus-vvxmz -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-8pjjs'
Feb  6 02:25:12.172: INFO: stderr: ""
Feb  6 02:25:12.172: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Feb  6 02:25:12.172: INFO: validating pod update-demo-nautilus-vvxmz
Feb  6 02:25:12.194: INFO: got data: {
  "image": "nautilus.jpg"
}

Feb  6 02:25:12.194: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Feb  6 02:25:12.194: INFO: update-demo-nautilus-vvxmz is verified up and running
STEP: scaling down the replication controller
Feb  6 02:25:12.196: INFO: scanned /root for discovery docs: <nil>
Feb  6 02:25:12.196: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-131423863 scale rc update-demo-nautilus --replicas=1 --timeout=5m --namespace=e2e-tests-kubectl-8pjjs'
Feb  6 02:25:13.386: INFO: stderr: ""
Feb  6 02:25:13.386: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Feb  6 02:25:13.386: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-131423863 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-8pjjs'
Feb  6 02:25:13.510: INFO: stderr: ""
Feb  6 02:25:13.510: INFO: stdout: "update-demo-nautilus-96mj4 update-demo-nautilus-vvxmz "
STEP: Replicas for name=update-demo: expected=1 actual=2
Feb  6 02:25:18.510: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-131423863 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-8pjjs'
Feb  6 02:25:18.642: INFO: stderr: ""
Feb  6 02:25:18.642: INFO: stdout: "update-demo-nautilus-vvxmz "
Feb  6 02:25:18.642: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-131423863 get pods update-demo-nautilus-vvxmz -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-8pjjs'
Feb  6 02:25:18.762: INFO: stderr: ""
Feb  6 02:25:18.763: INFO: stdout: "true"
Feb  6 02:25:18.763: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-131423863 get pods update-demo-nautilus-vvxmz -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-8pjjs'
Feb  6 02:25:18.903: INFO: stderr: ""
Feb  6 02:25:18.903: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Feb  6 02:25:18.903: INFO: validating pod update-demo-nautilus-vvxmz
Feb  6 02:25:18.919: INFO: got data: {
  "image": "nautilus.jpg"
}

Feb  6 02:25:18.919: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Feb  6 02:25:18.919: INFO: update-demo-nautilus-vvxmz is verified up and running
STEP: scaling up the replication controller
Feb  6 02:25:18.921: INFO: scanned /root for discovery docs: <nil>
Feb  6 02:25:18.921: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-131423863 scale rc update-demo-nautilus --replicas=2 --timeout=5m --namespace=e2e-tests-kubectl-8pjjs'
Feb  6 02:25:20.134: INFO: stderr: ""
Feb  6 02:25:20.134: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Feb  6 02:25:20.134: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-131423863 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-8pjjs'
Feb  6 02:25:20.262: INFO: stderr: ""
Feb  6 02:25:20.262: INFO: stdout: "update-demo-nautilus-bm952 update-demo-nautilus-vvxmz "
Feb  6 02:25:20.262: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-131423863 get pods update-demo-nautilus-bm952 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-8pjjs'
Feb  6 02:25:20.403: INFO: stderr: ""
Feb  6 02:25:20.403: INFO: stdout: ""
Feb  6 02:25:20.403: INFO: update-demo-nautilus-bm952 is created but not running
Feb  6 02:25:25.404: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-131423863 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-8pjjs'
Feb  6 02:25:25.538: INFO: stderr: ""
Feb  6 02:25:25.538: INFO: stdout: "update-demo-nautilus-bm952 update-demo-nautilus-vvxmz "
Feb  6 02:25:25.538: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-131423863 get pods update-demo-nautilus-bm952 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-8pjjs'
Feb  6 02:25:25.682: INFO: stderr: ""
Feb  6 02:25:25.682: INFO: stdout: "true"
Feb  6 02:25:25.682: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-131423863 get pods update-demo-nautilus-bm952 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-8pjjs'
Feb  6 02:25:25.819: INFO: stderr: ""
Feb  6 02:25:25.819: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Feb  6 02:25:25.819: INFO: validating pod update-demo-nautilus-bm952
Feb  6 02:25:25.859: INFO: got data: {
  "image": "nautilus.jpg"
}

Feb  6 02:25:25.859: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Feb  6 02:25:25.859: INFO: update-demo-nautilus-bm952 is verified up and running
Feb  6 02:25:25.859: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-131423863 get pods update-demo-nautilus-vvxmz -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-8pjjs'
Feb  6 02:25:26.000: INFO: stderr: ""
Feb  6 02:25:26.000: INFO: stdout: "true"
Feb  6 02:25:26.000: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-131423863 get pods update-demo-nautilus-vvxmz -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-8pjjs'
Feb  6 02:25:26.120: INFO: stderr: ""
Feb  6 02:25:26.120: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Feb  6 02:25:26.120: INFO: validating pod update-demo-nautilus-vvxmz
Feb  6 02:25:26.135: INFO: got data: {
  "image": "nautilus.jpg"
}

Feb  6 02:25:26.135: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Feb  6 02:25:26.135: INFO: update-demo-nautilus-vvxmz is verified up and running
STEP: using delete to clean up resources
Feb  6 02:25:26.135: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-131423863 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-8pjjs'
Feb  6 02:25:26.304: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Feb  6 02:25:26.304: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Feb  6 02:25:26.305: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-131423863 get rc,svc -l name=update-demo --no-headers --namespace=e2e-tests-kubectl-8pjjs'
Feb  6 02:25:27.121: INFO: stderr: "No resources found.\n"
Feb  6 02:25:27.121: INFO: stdout: ""
Feb  6 02:25:27.121: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-131423863 get pods -l name=update-demo --namespace=e2e-tests-kubectl-8pjjs -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Feb  6 02:25:27.283: INFO: stderr: ""
Feb  6 02:25:27.283: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  6 02:25:27.283: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-8pjjs" for this suite.
Feb  6 02:25:49.340: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 02:25:49.662: INFO: namespace: e2e-tests-kubectl-8pjjs, resource: bindings, ignored listing per whitelist
Feb  6 02:25:49.663: INFO: namespace e2e-tests-kubectl-8pjjs deletion completed in 22.365625274s

• [SLOW TEST:44.063 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Update Demo
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should scale a replication controller  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  6 02:25:49.664: INFO: >>> kubeConfig: /tmp/kubeconfig-131423863
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-statefulset-2gqz6
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-2gqz6
[It] should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a new StaefulSet
Feb  6 02:25:50.001: INFO: Found 0 stateful pods, waiting for 3
Feb  6 02:26:00.024: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Feb  6 02:26:00.024: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Feb  6 02:26:00.024: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Updating stateful set template: update image from docker.io/library/nginx:1.14-alpine to docker.io/library/nginx:1.15-alpine
Feb  6 02:26:00.129: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Not applying an update when the partition is greater than the number of replicas
STEP: Performing a canary update
Feb  6 02:26:10.290: INFO: Updating stateful set ss2
Feb  6 02:26:10.309: INFO: Waiting for Pod e2e-tests-statefulset-2gqz6/ss2-2 to have revision ss2-c79899b9 update revision ss2-787997d666
STEP: Restoring Pods to the correct revision when they are deleted
Feb  6 02:26:20.404: INFO: Found 1 stateful pods, waiting for 3
Feb  6 02:26:30.430: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Feb  6 02:26:30.430: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Feb  6 02:26:30.430: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Performing a phased rolling update
Feb  6 02:26:30.477: INFO: Updating stateful set ss2
Feb  6 02:26:30.503: INFO: Waiting for Pod e2e-tests-statefulset-2gqz6/ss2-1 to have revision ss2-c79899b9 update revision ss2-787997d666
Feb  6 02:26:40.534: INFO: Waiting for Pod e2e-tests-statefulset-2gqz6/ss2-1 to have revision ss2-c79899b9 update revision ss2-787997d666
Feb  6 02:26:50.887: INFO: Updating stateful set ss2
Feb  6 02:26:50.991: INFO: Waiting for StatefulSet e2e-tests-statefulset-2gqz6/ss2 to complete update
Feb  6 02:26:50.991: INFO: Waiting for Pod e2e-tests-statefulset-2gqz6/ss2-0 to have revision ss2-c79899b9 update revision ss2-787997d666
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Feb  6 02:27:01.030: INFO: Deleting all statefulset in ns e2e-tests-statefulset-2gqz6
Feb  6 02:27:01.038: INFO: Scaling statefulset ss2 to 0
Feb  6 02:27:31.085: INFO: Waiting for statefulset status.replicas updated to 0
Feb  6 02:27:31.093: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  6 02:27:31.199: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-2gqz6" for this suite.
Feb  6 02:27:37.248: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 02:27:37.566: INFO: namespace: e2e-tests-statefulset-2gqz6, resource: bindings, ignored listing per whitelist
Feb  6 02:27:37.592: INFO: namespace e2e-tests-statefulset-2gqz6 deletion completed in 6.376576852s

• [SLOW TEST:107.928 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should perform canary updates and phased rolling updates of template modifications [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  6 02:27:37.592: INFO: >>> kubeConfig: /tmp/kubeconfig-131423863
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-r7dwq
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-c51a2a0c-29b6-11e9-9603-eaa511fa0b6c
STEP: Creating a pod to test consume secrets
Feb  6 02:27:37.984: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-c522395c-29b6-11e9-9603-eaa511fa0b6c" in namespace "e2e-tests-projected-r7dwq" to be "success or failure"
Feb  6 02:27:37.994: INFO: Pod "pod-projected-secrets-c522395c-29b6-11e9-9603-eaa511fa0b6c": Phase="Pending", Reason="", readiness=false. Elapsed: 10.060842ms
Feb  6 02:27:40.003: INFO: Pod "pod-projected-secrets-c522395c-29b6-11e9-9603-eaa511fa0b6c": Phase="Running", Reason="", readiness=true. Elapsed: 2.019395371s
Feb  6 02:27:42.015: INFO: Pod "pod-projected-secrets-c522395c-29b6-11e9-9603-eaa511fa0b6c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.031598769s
STEP: Saw pod success
Feb  6 02:27:42.016: INFO: Pod "pod-projected-secrets-c522395c-29b6-11e9-9603-eaa511fa0b6c" satisfied condition "success or failure"
Feb  6 02:27:42.023: INFO: Trying to get logs from node 10.190.119.184 pod pod-projected-secrets-c522395c-29b6-11e9-9603-eaa511fa0b6c container projected-secret-volume-test: <nil>
STEP: delete the pod
Feb  6 02:27:42.068: INFO: Waiting for pod pod-projected-secrets-c522395c-29b6-11e9-9603-eaa511fa0b6c to disappear
Feb  6 02:27:42.099: INFO: Pod pod-projected-secrets-c522395c-29b6-11e9-9603-eaa511fa0b6c no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  6 02:27:42.100: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-r7dwq" for this suite.
Feb  6 02:27:50.140: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 02:27:50.341: INFO: namespace: e2e-tests-projected-r7dwq, resource: bindings, ignored listing per whitelist
Feb  6 02:27:50.774: INFO: namespace e2e-tests-projected-r7dwq deletion completed in 8.660445758s

• [SLOW TEST:13.182 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-storage] Projected 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  6 02:27:50.775: INFO: >>> kubeConfig: /tmp/kubeconfig-131423863
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-kvqmz
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name cm-test-opt-del-ccf41e9b-29b6-11e9-9603-eaa511fa0b6c
STEP: Creating configMap with name cm-test-opt-upd-ccf41eda-29b6-11e9-9603-eaa511fa0b6c
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-ccf41e9b-29b6-11e9-9603-eaa511fa0b6c
STEP: Updating configmap cm-test-opt-upd-ccf41eda-29b6-11e9-9603-eaa511fa0b6c
STEP: Creating configMap with name cm-test-opt-create-ccf41ef7-29b6-11e9-9603-eaa511fa0b6c
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  6 02:29:21.809: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-kvqmz" for this suite.
Feb  6 02:29:46.057: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 02:29:46.294: INFO: namespace: e2e-tests-projected-kvqmz, resource: bindings, ignored listing per whitelist
Feb  6 02:29:46.517: INFO: namespace e2e-tests-projected-kvqmz deletion completed in 24.697327938s

• [SLOW TEST:115.742 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  6 02:29:46.522: INFO: >>> kubeConfig: /tmp/kubeconfig-131423863
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-p66sl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name s-test-opt-del-11fc23f1-29b7-11e9-9603-eaa511fa0b6c
STEP: Creating secret with name s-test-opt-upd-11fc2441-29b7-11e9-9603-eaa511fa0b6c
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-11fc23f1-29b7-11e9-9603-eaa511fa0b6c
STEP: Updating secret s-test-opt-upd-11fc2441-29b7-11e9-9603-eaa511fa0b6c
STEP: Creating secret with name s-test-opt-create-11fc246a-29b7-11e9-9603-eaa511fa0b6c
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  6 02:30:56.430: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-p66sl" for this suite.
Feb  6 02:31:20.505: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 02:31:20.736: INFO: namespace: e2e-tests-projected-p66sl, resource: bindings, ignored listing per whitelist
Feb  6 02:31:20.881: INFO: namespace e2e-tests-projected-p66sl deletion completed in 24.437364447s

• [SLOW TEST:94.360 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-storage] Secrets 
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  6 02:31:20.883: INFO: >>> kubeConfig: /tmp/kubeconfig-131423863
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-secrets-8bhd7
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-secret-namespace-2sbdb
STEP: Creating secret with name secret-test-4a535d71-29b7-11e9-9603-eaa511fa0b6c
STEP: Creating a pod to test consume secrets
Feb  6 02:31:21.645: INFO: Waiting up to 5m0s for pod "pod-secrets-4a729cbc-29b7-11e9-9603-eaa511fa0b6c" in namespace "e2e-tests-secrets-8bhd7" to be "success or failure"
Feb  6 02:31:21.656: INFO: Pod "pod-secrets-4a729cbc-29b7-11e9-9603-eaa511fa0b6c": Phase="Pending", Reason="", readiness=false. Elapsed: 11.664717ms
Feb  6 02:31:23.666: INFO: Pod "pod-secrets-4a729cbc-29b7-11e9-9603-eaa511fa0b6c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.021418326s
STEP: Saw pod success
Feb  6 02:31:23.666: INFO: Pod "pod-secrets-4a729cbc-29b7-11e9-9603-eaa511fa0b6c" satisfied condition "success or failure"
Feb  6 02:31:23.676: INFO: Trying to get logs from node 10.190.119.184 pod pod-secrets-4a729cbc-29b7-11e9-9603-eaa511fa0b6c container secret-volume-test: <nil>
STEP: delete the pod
Feb  6 02:31:23.744: INFO: Waiting for pod pod-secrets-4a729cbc-29b7-11e9-9603-eaa511fa0b6c to disappear
Feb  6 02:31:23.752: INFO: Pod pod-secrets-4a729cbc-29b7-11e9-9603-eaa511fa0b6c no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  6 02:31:23.752: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-8bhd7" for this suite.
Feb  6 02:31:29.819: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 02:31:30.055: INFO: namespace: e2e-tests-secrets-8bhd7, resource: bindings, ignored listing per whitelist
Feb  6 02:31:30.284: INFO: namespace e2e-tests-secrets-8bhd7 deletion completed in 6.519055367s
STEP: Destroying namespace "e2e-tests-secret-namespace-2sbdb" for this suite.
Feb  6 02:31:36.327: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 02:31:36.806: INFO: namespace: e2e-tests-secret-namespace-2sbdb, resource: bindings, ignored listing per whitelist
Feb  6 02:31:36.814: INFO: namespace e2e-tests-secret-namespace-2sbdb deletion completed in 6.529952513s

• [SLOW TEST:15.931 seconds]
[sig-storage] Secrets
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run --rm job 
  should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  6 02:31:36.814: INFO: >>> kubeConfig: /tmp/kubeconfig-131423863
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-cxsgh
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: executing a command with run --rm and attach with stdin
Feb  6 02:31:37.189: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-131423863 --namespace=e2e-tests-kubectl-cxsgh run e2e-test-rm-busybox-job --image=docker.io/library/busybox:1.29 --rm=true --generator=job/v1 --restart=OnFailure --attach=true --stdin -- sh -c cat && echo 'stdin closed''
Feb  6 02:31:39.676: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl create instead.\nIf you don't see a command prompt, try pressing enter.\n"
Feb  6 02:31:39.676: INFO: stdout: "abcd1234stdin closed\njob.batch \"e2e-test-rm-busybox-job\" deleted\n"
STEP: verifying the job e2e-test-rm-busybox-job was deleted
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  6 02:31:41.695: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-cxsgh" for this suite.
Feb  6 02:31:49.741: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 02:31:49.799: INFO: namespace: e2e-tests-kubectl-cxsgh, resource: bindings, ignored listing per whitelist
Feb  6 02:31:50.409: INFO: namespace e2e-tests-kubectl-cxsgh deletion completed in 8.699419358s

• [SLOW TEST:13.595 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run --rm job
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create a job from an image, then delete the job  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[k8s.io] Probing container 
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  6 02:31:50.411: INFO: >>> kubeConfig: /tmp/kubeconfig-131423863
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-container-probe-zdkg8
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  6 02:32:50.929: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-zdkg8" for this suite.
Feb  6 02:33:14.976: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 02:33:15.103: INFO: namespace: e2e-tests-container-probe-zdkg8, resource: bindings, ignored listing per whitelist
Feb  6 02:33:15.414: INFO: namespace e2e-tests-container-probe-zdkg8 deletion completed in 24.46995151s

• [SLOW TEST:85.002 seconds]
[k8s.io] Probing container
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  6 02:33:15.414: INFO: >>> kubeConfig: /tmp/kubeconfig-131423863
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-sgbb9
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-8e7238c6-29b7-11e9-9603-eaa511fa0b6c
STEP: Creating a pod to test consume configMaps
Feb  6 02:33:15.814: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-8e7e72ce-29b7-11e9-9603-eaa511fa0b6c" in namespace "e2e-tests-projected-sgbb9" to be "success or failure"
Feb  6 02:33:15.823: INFO: Pod "pod-projected-configmaps-8e7e72ce-29b7-11e9-9603-eaa511fa0b6c": Phase="Pending", Reason="", readiness=false. Elapsed: 8.856494ms
Feb  6 02:33:17.832: INFO: Pod "pod-projected-configmaps-8e7e72ce-29b7-11e9-9603-eaa511fa0b6c": Phase="Running", Reason="", readiness=true. Elapsed: 2.018081074s
Feb  6 02:33:19.841: INFO: Pod "pod-projected-configmaps-8e7e72ce-29b7-11e9-9603-eaa511fa0b6c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.026961206s
STEP: Saw pod success
Feb  6 02:33:19.841: INFO: Pod "pod-projected-configmaps-8e7e72ce-29b7-11e9-9603-eaa511fa0b6c" satisfied condition "success or failure"
Feb  6 02:33:19.853: INFO: Trying to get logs from node 10.190.119.184 pod pod-projected-configmaps-8e7e72ce-29b7-11e9-9603-eaa511fa0b6c container projected-configmap-volume-test: <nil>
STEP: delete the pod
Feb  6 02:33:19.906: INFO: Waiting for pod pod-projected-configmaps-8e7e72ce-29b7-11e9-9603-eaa511fa0b6c to disappear
Feb  6 02:33:19.915: INFO: Pod pod-projected-configmaps-8e7e72ce-29b7-11e9-9603-eaa511fa0b6c no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  6 02:33:19.915: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-sgbb9" for this suite.
Feb  6 02:33:26.020: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 02:33:26.340: INFO: namespace: e2e-tests-projected-sgbb9, resource: bindings, ignored listing per whitelist
Feb  6 02:33:26.859: INFO: namespace e2e-tests-projected-sgbb9 deletion completed in 6.867157169s

• [SLOW TEST:11.445 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-api-machinery] Watchers 
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  6 02:33:26.859: INFO: >>> kubeConfig: /tmp/kubeconfig-131423863
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-watch-gjd2z
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a watch on configmaps with a certain label
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: changing the label value of the configmap
STEP: Expecting to observe a delete notification for the watched object
Feb  6 02:33:27.229: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-gjd2z,SelfLink:/api/v1/namespaces/e2e-tests-watch-gjd2z/configmaps/e2e-watch-test-label-changed,UID:9549c879-29b7-11e9-bf83-6639c2940cda,ResourceVersion:57354,Generation:0,CreationTimestamp:2019-02-06 02:33:27 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Feb  6 02:33:27.230: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-gjd2z,SelfLink:/api/v1/namespaces/e2e-tests-watch-gjd2z/configmaps/e2e-watch-test-label-changed,UID:9549c879-29b7-11e9-bf83-6639c2940cda,ResourceVersion:57355,Generation:0,CreationTimestamp:2019-02-06 02:33:27 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Feb  6 02:33:27.230: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-gjd2z,SelfLink:/api/v1/namespaces/e2e-tests-watch-gjd2z/configmaps/e2e-watch-test-label-changed,UID:9549c879-29b7-11e9-bf83-6639c2940cda,ResourceVersion:57356,Generation:0,CreationTimestamp:2019-02-06 02:33:27 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time
STEP: Expecting not to observe a notification because the object no longer meets the selector's requirements
STEP: changing the label value of the configmap back
STEP: modifying the configmap a third time
STEP: deleting the configmap
STEP: Expecting to observe an add notification for the watched object when the label value was restored
Feb  6 02:33:37.314: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-gjd2z,SelfLink:/api/v1/namespaces/e2e-tests-watch-gjd2z/configmaps/e2e-watch-test-label-changed,UID:9549c879-29b7-11e9-bf83-6639c2940cda,ResourceVersion:57374,Generation:0,CreationTimestamp:2019-02-06 02:33:27 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Feb  6 02:33:37.314: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-gjd2z,SelfLink:/api/v1/namespaces/e2e-tests-watch-gjd2z/configmaps/e2e-watch-test-label-changed,UID:9549c879-29b7-11e9-bf83-6639c2940cda,ResourceVersion:57375,Generation:0,CreationTimestamp:2019-02-06 02:33:27 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
Feb  6 02:33:37.314: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:e2e-tests-watch-gjd2z,SelfLink:/api/v1/namespaces/e2e-tests-watch-gjd2z/configmaps/e2e-watch-test-label-changed,UID:9549c879-29b7-11e9-bf83-6639c2940cda,ResourceVersion:57376,Generation:0,CreationTimestamp:2019-02-06 02:33:27 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  6 02:33:37.314: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-gjd2z" for this suite.
Feb  6 02:33:45.359: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 02:33:45.521: INFO: namespace: e2e-tests-watch-gjd2z, resource: bindings, ignored listing per whitelist
Feb  6 02:33:45.679: INFO: namespace e2e-tests-watch-gjd2z deletion completed in 8.351687309s

• [SLOW TEST:18.819 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Secrets 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  6 02:33:45.679: INFO: >>> kubeConfig: /tmp/kubeconfig-131423863
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-secrets-fxstd
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-a07d896d-29b7-11e9-9603-eaa511fa0b6c
STEP: Creating a pod to test consume secrets
Feb  6 02:33:46.018: INFO: Waiting up to 5m0s for pod "pod-secrets-a07f39ac-29b7-11e9-9603-eaa511fa0b6c" in namespace "e2e-tests-secrets-fxstd" to be "success or failure"
Feb  6 02:33:46.031: INFO: Pod "pod-secrets-a07f39ac-29b7-11e9-9603-eaa511fa0b6c": Phase="Pending", Reason="", readiness=false. Elapsed: 13.012423ms
Feb  6 02:33:48.054: INFO: Pod "pod-secrets-a07f39ac-29b7-11e9-9603-eaa511fa0b6c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.036470346s
STEP: Saw pod success
Feb  6 02:33:48.054: INFO: Pod "pod-secrets-a07f39ac-29b7-11e9-9603-eaa511fa0b6c" satisfied condition "success or failure"
Feb  6 02:33:48.063: INFO: Trying to get logs from node 10.190.119.184 pod pod-secrets-a07f39ac-29b7-11e9-9603-eaa511fa0b6c container secret-volume-test: <nil>
STEP: delete the pod
Feb  6 02:33:48.118: INFO: Waiting for pod pod-secrets-a07f39ac-29b7-11e9-9603-eaa511fa0b6c to disappear
Feb  6 02:33:48.191: INFO: Pod pod-secrets-a07f39ac-29b7-11e9-9603-eaa511fa0b6c no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  6 02:33:48.191: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-fxstd" for this suite.
Feb  6 02:33:54.241: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 02:33:54.515: INFO: namespace: e2e-tests-secrets-fxstd, resource: bindings, ignored listing per whitelist
Feb  6 02:33:54.594: INFO: namespace e2e-tests-secrets-fxstd deletion completed in 6.386947854s

• [SLOW TEST:8.915 seconds]
[sig-storage] Secrets
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run job 
  should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  6 02:33:54.594: INFO: >>> kubeConfig: /tmp/kubeconfig-131423863
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-v2hmr
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Kubectl run job
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1402
[It] should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Feb  6 02:33:54.900: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-131423863 run e2e-test-nginx-job --restart=OnFailure --generator=job/v1 --image=docker.io/library/nginx:1.14-alpine --namespace=e2e-tests-kubectl-v2hmr'
Feb  6 02:33:55.101: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl create instead.\n"
Feb  6 02:33:55.101: INFO: stdout: "job.batch/e2e-test-nginx-job created\n"
STEP: verifying the job e2e-test-nginx-job was created
[AfterEach] [k8s.io] Kubectl run job
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1407
Feb  6 02:33:55.111: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-131423863 delete jobs e2e-test-nginx-job --namespace=e2e-tests-kubectl-v2hmr'
Feb  6 02:33:55.321: INFO: stderr: ""
Feb  6 02:33:55.321: INFO: stdout: "job.batch \"e2e-test-nginx-job\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  6 02:33:55.321: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-v2hmr" for this suite.
Feb  6 02:34:01.421: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 02:34:01.677: INFO: namespace: e2e-tests-kubectl-v2hmr, resource: bindings, ignored listing per whitelist
Feb  6 02:34:01.909: INFO: namespace e2e-tests-kubectl-v2hmr deletion completed in 6.516896043s

• [SLOW TEST:7.314 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run job
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create a job from an image when restart is OnFailure  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl cluster-info 
  should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  6 02:34:01.912: INFO: >>> kubeConfig: /tmp/kubeconfig-131423863
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-wz5jr
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: validating cluster-info
Feb  6 02:34:02.214: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-131423863 cluster-info'
Feb  6 02:34:02.343: INFO: stderr: ""
Feb  6 02:34:02.343: INFO: stdout: "\x1b[0;32mKubernetes master\x1b[0m is running at \x1b[0;33mhttps://172.21.0.1:443\x1b[0m\n\x1b[0;32mKubeDNS\x1b[0m is running at \x1b[0;33mhttps://172.21.0.1:443/api/v1/namespaces/kube-system/services/kube-dns:dns/proxy\x1b[0m\n\x1b[0;32mkubernetes-dashboard\x1b[0m is running at \x1b[0;33mhttps://172.21.0.1:443/api/v1/namespaces/kube-system/services/https:kubernetes-dashboard:/proxy\x1b[0m\n\x1b[0;32mMetrics-server\x1b[0m is running at \x1b[0;33mhttps://172.21.0.1:443/api/v1/namespaces/kube-system/services/https:metrics-server:/proxy\x1b[0m\n\nTo further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  6 02:34:02.343: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-wz5jr" for this suite.
Feb  6 02:34:08.381: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 02:34:08.649: INFO: namespace: e2e-tests-kubectl-wz5jr, resource: bindings, ignored listing per whitelist
Feb  6 02:34:08.780: INFO: namespace e2e-tests-kubectl-wz5jr deletion completed in 6.42448682s

• [SLOW TEST:6.868 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl cluster-info
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should check if Kubernetes master services is included in cluster-info  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-apps] Deployment 
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  6 02:34:08.781: INFO: >>> kubeConfig: /tmp/kubeconfig-131423863
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-deployment-npshr
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb  6 02:34:09.176: INFO: Creating replica set "test-rolling-update-controller" (going to be adopted)
Feb  6 02:34:09.195: INFO: Pod name sample-pod: Found 0 pods out of 1
Feb  6 02:34:14.219: INFO: Pod name sample-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Feb  6 02:34:14.219: INFO: Creating deployment "test-rolling-update-deployment"
Feb  6 02:34:14.570: INFO: Ensuring deployment "test-rolling-update-deployment" gets the next revision from the one the adopted replica set "test-rolling-update-controller" has
Feb  6 02:34:14.599: INFO: deployment "test-rolling-update-deployment" doesn't have the required revision set
Feb  6 02:34:16.619: INFO: Ensuring status for deployment "test-rolling-update-deployment" is the expected
Feb  6 02:34:16.630: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:2, UpdatedReplicas:1, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63685017255, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63685017255, loc:(*time.Location)(0x6c43b60)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63685017255, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63685017255, loc:(*time.Location)(0x6c43b60)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rolling-update-deployment-65b7695dcf\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb  6 02:34:18.640: INFO: Ensuring deployment "test-rolling-update-deployment" has one old replica set (the one it adopted)
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Feb  6 02:34:18.709: INFO: Deployment "test-rolling-update-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment,GenerateName:,Namespace:e2e-tests-deployment-npshr,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-npshr/deployments/test-rolling-update-deployment,UID:b15249ac-29b7-11e9-bf83-6639c2940cda,ResourceVersion:57593,Generation:1,CreationTimestamp:2019-02-06 02:34:14 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,},Annotations:map[string]string{deployment.kubernetes.io/revision: 3546343826724305833,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[{Available True 2019-02-06 02:34:15 +0000 UTC 2019-02-06 02:34:15 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2019-02-06 02:34:16 +0000 UTC 2019-02-06 02:34:15 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-rolling-update-deployment-65b7695dcf" has successfully progressed.}],ReadyReplicas:1,CollisionCount:nil,},}

Feb  6 02:34:18.731: INFO: New ReplicaSet "test-rolling-update-deployment-65b7695dcf" of Deployment "test-rolling-update-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment-65b7695dcf,GenerateName:,Namespace:e2e-tests-deployment-npshr,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-npshr/replicasets/test-rolling-update-deployment-65b7695dcf,UID:b188a3bd-29b7-11e9-a275-52a9a0efac9f,ResourceVersion:57583,Generation:1,CreationTimestamp:2019-02-06 02:34:14 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 65b7695dcf,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 3546343826724305833,},OwnerReferences:[{apps/v1 Deployment test-rolling-update-deployment b15249ac-29b7-11e9-bf83-6639c2940cda 0xc4231881a7 0xc4231881a8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod-template-hash: 65b7695dcf,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 65b7695dcf,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Feb  6 02:34:18.731: INFO: All old ReplicaSets of Deployment "test-rolling-update-deployment":
Feb  6 02:34:18.731: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-controller,GenerateName:,Namespace:e2e-tests-deployment-npshr,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-npshr/replicasets/test-rolling-update-controller,UID:ae50c79f-29b7-11e9-bf83-6639c2940cda,ResourceVersion:57592,Generation:2,CreationTimestamp:2019-02-06 02:34:09 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod: nginx,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 3546343826724305832,},OwnerReferences:[{apps/v1 Deployment test-rolling-update-deployment b15249ac-29b7-11e9-bf83-6639c2940cda 0xc4231880de 0xc4231880df}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Feb  6 02:34:18.740: INFO: Pod "test-rolling-update-deployment-65b7695dcf-frg7n" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment-65b7695dcf-frg7n,GenerateName:test-rolling-update-deployment-65b7695dcf-,Namespace:e2e-tests-deployment-npshr,SelfLink:/api/v1/namespaces/e2e-tests-deployment-npshr/pods/test-rolling-update-deployment-65b7695dcf-frg7n,UID:b1da2abd-29b7-11e9-a275-52a9a0efac9f,ResourceVersion:57582,Generation:0,CreationTimestamp:2019-02-06 02:34:15 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 65b7695dcf,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet test-rolling-update-deployment-65b7695dcf b188a3bd-29b7-11e9-a275-52a9a0efac9f 0xc4214760d7 0xc4214760d8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-lp7kj {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-lp7kj,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-lp7kj true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.190.119.133,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc421476150} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421476170}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-06 02:34:15 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-02-06 02:34:16 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-02-06 02:34:16 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-06 02:34:15 +0000 UTC  }],Message:,Reason:,HostIP:10.190.119.133,PodIP:172.30.176.18,StartTime:2019-02-06 02:34:15 +0000 UTC,ContainerStatuses:[{redis {nil ContainerStateRunning{StartedAt:2019-02-06 02:34:16 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/redis:1.0 gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830 containerd://366755fb4b658e3ec9b8b02713510d1abaeff01463989292760ee19545b8fd88}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  6 02:34:18.740: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-npshr" for this suite.
Feb  6 02:34:24.803: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 02:34:25.090: INFO: namespace: e2e-tests-deployment-npshr, resource: bindings, ignored listing per whitelist
Feb  6 02:34:25.212: INFO: namespace e2e-tests-deployment-npshr deletion completed in 6.45827316s

• [SLOW TEST:16.431 seconds]
[sig-apps] Deployment
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  6 02:34:25.212: INFO: >>> kubeConfig: /tmp/kubeconfig-131423863
STEP: Building a namespace api object, basename pod-network-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-pod-network-test-9jz6t
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-9jz6t
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Feb  6 02:34:25.516: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Feb  6 02:34:43.860: INFO: ExecWithOptions {Command:[/bin/sh -c echo 'hostName' | timeout -t 2 nc -w 1 -u 172.30.242.57 8081 | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-9jz6t PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb  6 02:34:43.861: INFO: >>> kubeConfig: /tmp/kubeconfig-131423863
Feb  6 02:34:45.085: INFO: Found all expected endpoints: [netserver-0]
Feb  6 02:34:45.095: INFO: ExecWithOptions {Command:[/bin/sh -c echo 'hostName' | timeout -t 2 nc -w 1 -u 172.30.176.19 8081 | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-9jz6t PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb  6 02:34:45.095: INFO: >>> kubeConfig: /tmp/kubeconfig-131423863
Feb  6 02:34:46.286: INFO: Found all expected endpoints: [netserver-1]
Feb  6 02:34:46.309: INFO: ExecWithOptions {Command:[/bin/sh -c echo 'hostName' | timeout -t 2 nc -w 1 -u 172.30.134.210 8081 | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-9jz6t PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb  6 02:34:46.309: INFO: >>> kubeConfig: /tmp/kubeconfig-131423863
Feb  6 02:34:47.539: INFO: Found all expected endpoints: [netserver-2]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  6 02:34:47.540: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-9jz6t" for this suite.
Feb  6 02:35:11.620: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 02:35:11.709: INFO: namespace: e2e-tests-pod-network-test-9jz6t, resource: bindings, ignored listing per whitelist
Feb  6 02:35:12.017: INFO: namespace e2e-tests-pod-network-test-9jz6t deletion completed in 24.424869887s

• [SLOW TEST:46.805 seconds]
[sig-network] Networking
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: udp [NodeConformance] [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] version v1
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  6 02:35:12.019: INFO: >>> kubeConfig: /tmp/kubeconfig-131423863
STEP: Building a namespace api object, basename proxy
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-proxy-rp6n7
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb  6 02:35:12.359: INFO: (0) /api/v1/nodes/10.190.119.133/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 22.954688ms)
Feb  6 02:35:12.407: INFO: (1) /api/v1/nodes/10.190.119.133/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 47.913746ms)
Feb  6 02:35:12.423: INFO: (2) /api/v1/nodes/10.190.119.133/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 15.98705ms)
Feb  6 02:35:12.442: INFO: (3) /api/v1/nodes/10.190.119.133/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 18.618635ms)
Feb  6 02:35:12.457: INFO: (4) /api/v1/nodes/10.190.119.133/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 15.689448ms)
Feb  6 02:35:12.473: INFO: (5) /api/v1/nodes/10.190.119.133/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 15.662065ms)
Feb  6 02:35:12.490: INFO: (6) /api/v1/nodes/10.190.119.133/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 16.627871ms)
Feb  6 02:35:12.508: INFO: (7) /api/v1/nodes/10.190.119.133/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 17.801753ms)
Feb  6 02:35:12.523: INFO: (8) /api/v1/nodes/10.190.119.133/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 14.836452ms)
Feb  6 02:35:12.540: INFO: (9) /api/v1/nodes/10.190.119.133/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 17.831262ms)
Feb  6 02:35:12.556: INFO: (10) /api/v1/nodes/10.190.119.133/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 15.651164ms)
Feb  6 02:35:12.576: INFO: (11) /api/v1/nodes/10.190.119.133/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 19.633794ms)
Feb  6 02:35:12.591: INFO: (12) /api/v1/nodes/10.190.119.133/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 14.905564ms)
Feb  6 02:35:12.605: INFO: (13) /api/v1/nodes/10.190.119.133/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 14.063164ms)
Feb  6 02:35:12.619: INFO: (14) /api/v1/nodes/10.190.119.133/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 13.765553ms)
Feb  6 02:35:12.633: INFO: (15) /api/v1/nodes/10.190.119.133/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 13.924252ms)
Feb  6 02:35:12.647: INFO: (16) /api/v1/nodes/10.190.119.133/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 14.167737ms)
Feb  6 02:35:12.664: INFO: (17) /api/v1/nodes/10.190.119.133/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 16.713405ms)
Feb  6 02:35:12.678: INFO: (18) /api/v1/nodes/10.190.119.133/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 14.345172ms)
Feb  6 02:35:12.693: INFO: (19) /api/v1/nodes/10.190.119.133/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 14.356414ms)
[AfterEach] version v1
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  6 02:35:12.693: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-proxy-rp6n7" for this suite.
Feb  6 02:35:18.817: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 02:35:19.995: INFO: namespace: e2e-tests-proxy-rp6n7, resource: bindings, ignored listing per whitelist
Feb  6 02:35:20.019: INFO: namespace e2e-tests-proxy-rp6n7 deletion completed in 7.315652588s

• [SLOW TEST:8.000 seconds]
[sig-network] Proxy
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy logs on node using proxy subresource  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Burst scaling should run to completion even with unhealthy pods [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  6 02:35:20.020: INFO: >>> kubeConfig: /tmp/kubeconfig-131423863
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-statefulset-xn8x7
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-xn8x7
[It] Burst scaling should run to completion even with unhealthy pods [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating stateful set ss in namespace e2e-tests-statefulset-xn8x7
STEP: Waiting until all stateful set ss replicas will be running in namespace e2e-tests-statefulset-xn8x7
Feb  6 02:35:20.468: INFO: Found 0 stateful pods, waiting for 1
Feb  6 02:35:30.489: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will not halt with unhealthy stateful pod
Feb  6 02:35:30.498: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-131423863 exec --namespace=e2e-tests-statefulset-xn8x7 ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Feb  6 02:35:30.899: INFO: stderr: ""
Feb  6 02:35:30.899: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Feb  6 02:35:30.899: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Feb  6 02:35:30.909: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Feb  6 02:35:40.935: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Feb  6 02:35:40.935: INFO: Waiting for statefulset status.replicas updated to 0
Feb  6 02:35:40.979: INFO: POD   NODE            PHASE    GRACE  CONDITIONS
Feb  6 02:35:40.979: INFO: ss-0  10.190.119.133  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-06 02:35:20 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-06 02:35:31 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-06 02:35:31 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-06 02:35:20 +0000 UTC  }]
Feb  6 02:35:40.979: INFO: ss-1                  Pending         []
Feb  6 02:35:40.979: INFO: 
Feb  6 02:35:40.979: INFO: StatefulSet ss has not reached scale 3, at 2
Feb  6 02:35:41.989: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.984667959s
Feb  6 02:35:43.241: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.974825109s
Feb  6 02:35:44.251: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.722579524s
Feb  6 02:35:45.273: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.712276202s
Feb  6 02:35:46.285: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.69021762s
Feb  6 02:35:47.294: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.678541753s
Feb  6 02:35:48.304: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.669117621s
Feb  6 02:35:49.317: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.659442796s
Feb  6 02:35:50.328: INFO: Verifying statefulset ss doesn't scale past 3 for another 646.521277ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace e2e-tests-statefulset-xn8x7
Feb  6 02:35:51.356: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-131423863 exec --namespace=e2e-tests-statefulset-xn8x7 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb  6 02:35:51.727: INFO: stderr: ""
Feb  6 02:35:51.727: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Feb  6 02:35:51.727: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Feb  6 02:35:51.727: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-131423863 exec --namespace=e2e-tests-statefulset-xn8x7 ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb  6 02:35:52.062: INFO: stderr: "mv: can't rename '/tmp/index.html': No such file or directory\n"
Feb  6 02:35:52.063: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Feb  6 02:35:52.063: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Feb  6 02:35:52.063: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-131423863 exec --namespace=e2e-tests-statefulset-xn8x7 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb  6 02:35:52.408: INFO: stderr: "mv: can't rename '/tmp/index.html': No such file or directory\n"
Feb  6 02:35:52.408: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Feb  6 02:35:52.408: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-2: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Feb  6 02:35:52.492: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Feb  6 02:35:52.492: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Feb  6 02:35:52.492: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Scale down will not halt with unhealthy stateful pod
Feb  6 02:35:52.501: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-131423863 exec --namespace=e2e-tests-statefulset-xn8x7 ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Feb  6 02:35:52.853: INFO: stderr: ""
Feb  6 02:35:52.853: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Feb  6 02:35:52.853: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Feb  6 02:35:52.854: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-131423863 exec --namespace=e2e-tests-statefulset-xn8x7 ss-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Feb  6 02:35:53.220: INFO: stderr: ""
Feb  6 02:35:53.220: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Feb  6 02:35:53.220: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Feb  6 02:35:53.220: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-131423863 exec --namespace=e2e-tests-statefulset-xn8x7 ss-2 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Feb  6 02:35:53.617: INFO: stderr: ""
Feb  6 02:35:53.617: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Feb  6 02:35:53.617: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-2: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Feb  6 02:35:53.617: INFO: Waiting for statefulset status.replicas updated to 0
Feb  6 02:35:53.627: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 2
Feb  6 02:36:03.659: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Feb  6 02:36:03.659: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Feb  6 02:36:03.659: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Feb  6 02:36:03.701: INFO: POD   NODE            PHASE    GRACE  CONDITIONS
Feb  6 02:36:03.701: INFO: ss-0  10.190.119.133  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-06 02:35:20 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-06 02:35:52 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-06 02:35:52 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-06 02:35:20 +0000 UTC  }]
Feb  6 02:36:03.701: INFO: ss-1  10.190.119.143  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-06 02:35:40 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-06 02:35:53 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-06 02:35:53 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-06 02:35:40 +0000 UTC  }]
Feb  6 02:36:03.701: INFO: ss-2  10.190.119.184  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-06 02:35:40 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-06 02:35:54 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-06 02:35:54 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-06 02:35:40 +0000 UTC  }]
Feb  6 02:36:03.701: INFO: 
Feb  6 02:36:03.701: INFO: StatefulSet ss has not reached scale 0, at 3
Feb  6 02:36:04.711: INFO: POD   NODE            PHASE    GRACE  CONDITIONS
Feb  6 02:36:04.711: INFO: ss-0  10.190.119.133  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-06 02:35:20 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-06 02:35:52 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-06 02:35:52 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-06 02:35:20 +0000 UTC  }]
Feb  6 02:36:04.711: INFO: ss-1  10.190.119.143  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-06 02:35:40 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-06 02:35:53 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-06 02:35:53 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-06 02:35:40 +0000 UTC  }]
Feb  6 02:36:04.711: INFO: ss-2  10.190.119.184  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-06 02:35:40 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-06 02:35:54 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-06 02:35:54 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-06 02:35:40 +0000 UTC  }]
Feb  6 02:36:04.711: INFO: 
Feb  6 02:36:04.711: INFO: StatefulSet ss has not reached scale 0, at 3
Feb  6 02:36:05.721: INFO: POD   NODE            PHASE    GRACE  CONDITIONS
Feb  6 02:36:05.721: INFO: ss-0  10.190.119.133  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-06 02:35:20 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-06 02:35:52 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-06 02:35:52 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-06 02:35:20 +0000 UTC  }]
Feb  6 02:36:05.721: INFO: ss-1  10.190.119.143  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-06 02:35:40 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-06 02:35:53 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-06 02:35:53 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-06 02:35:40 +0000 UTC  }]
Feb  6 02:36:05.721: INFO: ss-2  10.190.119.184  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-06 02:35:40 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-06 02:35:54 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-06 02:35:54 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-06 02:35:40 +0000 UTC  }]
Feb  6 02:36:05.721: INFO: 
Feb  6 02:36:05.721: INFO: StatefulSet ss has not reached scale 0, at 3
Feb  6 02:36:06.731: INFO: POD   NODE            PHASE    GRACE  CONDITIONS
Feb  6 02:36:06.731: INFO: ss-0  10.190.119.133  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-06 02:35:20 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-06 02:35:52 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-06 02:35:52 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-06 02:35:20 +0000 UTC  }]
Feb  6 02:36:06.731: INFO: ss-1  10.190.119.143  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-06 02:35:40 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-06 02:35:53 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-06 02:35:53 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-06 02:35:40 +0000 UTC  }]
Feb  6 02:36:06.731: INFO: ss-2  10.190.119.184  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-06 02:35:40 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-06 02:35:54 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-06 02:35:54 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-06 02:35:40 +0000 UTC  }]
Feb  6 02:36:06.731: INFO: 
Feb  6 02:36:06.731: INFO: StatefulSet ss has not reached scale 0, at 3
Feb  6 02:36:07.740: INFO: POD   NODE            PHASE    GRACE  CONDITIONS
Feb  6 02:36:07.740: INFO: ss-0  10.190.119.133  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-06 02:35:20 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-06 02:35:52 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-06 02:35:52 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-06 02:35:20 +0000 UTC  }]
Feb  6 02:36:07.740: INFO: ss-1  10.190.119.143  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-06 02:35:40 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-06 02:35:53 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-06 02:35:53 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-06 02:35:40 +0000 UTC  }]
Feb  6 02:36:07.740: INFO: ss-2  10.190.119.184  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-06 02:35:40 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-06 02:35:54 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-06 02:35:54 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-06 02:35:40 +0000 UTC  }]
Feb  6 02:36:07.740: INFO: 
Feb  6 02:36:07.740: INFO: StatefulSet ss has not reached scale 0, at 3
Feb  6 02:36:08.804: INFO: POD   NODE            PHASE    GRACE  CONDITIONS
Feb  6 02:36:08.804: INFO: ss-2  10.190.119.184  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-06 02:35:40 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-06 02:35:54 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-06 02:35:54 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-06 02:35:40 +0000 UTC  }]
Feb  6 02:36:08.804: INFO: 
Feb  6 02:36:08.804: INFO: StatefulSet ss has not reached scale 0, at 1
Feb  6 02:36:09.814: INFO: POD   NODE            PHASE    GRACE  CONDITIONS
Feb  6 02:36:09.814: INFO: ss-2  10.190.119.184  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-06 02:35:40 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-06 02:35:54 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-06 02:35:54 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-06 02:35:40 +0000 UTC  }]
Feb  6 02:36:09.814: INFO: 
Feb  6 02:36:09.814: INFO: StatefulSet ss has not reached scale 0, at 1
Feb  6 02:36:10.824: INFO: POD   NODE            PHASE    GRACE  CONDITIONS
Feb  6 02:36:10.824: INFO: ss-2  10.190.119.184  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-06 02:35:40 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-06 02:35:54 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-06 02:35:54 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-06 02:35:40 +0000 UTC  }]
Feb  6 02:36:10.824: INFO: 
Feb  6 02:36:10.824: INFO: StatefulSet ss has not reached scale 0, at 1
Feb  6 02:36:11.833: INFO: Verifying statefulset ss doesn't scale past 0 for another 1.866822459s
Feb  6 02:36:12.842: INFO: Verifying statefulset ss doesn't scale past 0 for another 857.877009ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacee2e-tests-statefulset-xn8x7
Feb  6 02:36:13.871: INFO: Scaling statefulset ss to 0
Feb  6 02:36:13.898: INFO: Waiting for statefulset status.replicas updated to 0
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Feb  6 02:36:13.905: INFO: Deleting all statefulset in ns e2e-tests-statefulset-xn8x7
Feb  6 02:36:13.914: INFO: Scaling statefulset ss to 0
Feb  6 02:36:13.941: INFO: Waiting for statefulset status.replicas updated to 0
Feb  6 02:36:13.949: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  6 02:36:13.985: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-xn8x7" for this suite.
Feb  6 02:36:22.025: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 02:36:22.129: INFO: namespace: e2e-tests-statefulset-xn8x7, resource: bindings, ignored listing per whitelist
Feb  6 02:36:22.375: INFO: namespace e2e-tests-statefulset-xn8x7 deletion completed in 8.376802063s

• [SLOW TEST:62.356 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    Burst scaling should run to completion even with unhealthy pods [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-network] DNS 
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  6 02:36:22.377: INFO: >>> kubeConfig: /tmp/kubeconfig-131423863
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-dns-q2fhn
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(dig +notcp +noall +answer +search kubernetes.default A)" && echo OK > /results/wheezy_udp@kubernetes.default;test -n "$$(dig +tcp +noall +answer +search kubernetes.default A)" && echo OK > /results/wheezy_tcp@kubernetes.default;test -n "$$(dig +notcp +noall +answer +search kubernetes.default.svc A)" && echo OK > /results/wheezy_udp@kubernetes.default.svc;test -n "$$(dig +tcp +noall +answer +search kubernetes.default.svc A)" && echo OK > /results/wheezy_tcp@kubernetes.default.svc;test -n "$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && echo OK > /results/wheezy_udp@kubernetes.default.svc.cluster.local;test -n "$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && echo OK > /results/wheezy_tcp@kubernetes.default.svc.cluster.local;test -n "$$(getent hosts dns-querier-1.dns-test-service.e2e-tests-dns-q2fhn.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-1.dns-test-service.e2e-tests-dns-q2fhn.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/wheezy_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-q2fhn.pod.cluster.local"}');test -n "$$(dig +notcp +noall +answer +search $${podARec} A)" && echo OK > /results/wheezy_udp@PodARecord;test -n "$$(dig +tcp +noall +answer +search $${podARec} A)" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(dig +notcp +noall +answer +search kubernetes.default A)" && echo OK > /results/jessie_udp@kubernetes.default;test -n "$$(dig +tcp +noall +answer +search kubernetes.default A)" && echo OK > /results/jessie_tcp@kubernetes.default;test -n "$$(dig +notcp +noall +answer +search kubernetes.default.svc A)" && echo OK > /results/jessie_udp@kubernetes.default.svc;test -n "$$(dig +tcp +noall +answer +search kubernetes.default.svc A)" && echo OK > /results/jessie_tcp@kubernetes.default.svc;test -n "$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && echo OK > /results/jessie_udp@kubernetes.default.svc.cluster.local;test -n "$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && echo OK > /results/jessie_tcp@kubernetes.default.svc.cluster.local;test -n "$$(getent hosts dns-querier-1.dns-test-service.e2e-tests-dns-q2fhn.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-1.dns-test-service.e2e-tests-dns-q2fhn.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/jessie_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-q2fhn.pod.cluster.local"}');test -n "$$(dig +notcp +noall +answer +search $${podARec} A)" && echo OK > /results/jessie_udp@PodARecord;test -n "$$(dig +tcp +noall +answer +search $${podARec} A)" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Feb  6 02:36:37.100: INFO: DNS probes using e2e-tests-dns-q2fhn/dns-test-fde41f42-29b7-11e9-9603-eaa511fa0b6c succeeded

STEP: deleting the pod
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  6 02:36:37.134: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-dns-q2fhn" for this suite.
Feb  6 02:36:43.522: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 02:36:43.785: INFO: namespace: e2e-tests-dns-q2fhn, resource: bindings, ignored listing per whitelist
Feb  6 02:36:43.887: INFO: namespace e2e-tests-dns-q2fhn deletion completed in 6.397964674s

• [SLOW TEST:21.510 seconds]
[sig-network] DNS
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  6 02:36:43.888: INFO: >>> kubeConfig: /tmp/kubeconfig-131423863
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-m644h
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-map-0ac4a16c-29b8-11e9-9603-eaa511fa0b6c
STEP: Creating a pod to test consume configMaps
Feb  6 02:36:44.323: INFO: Waiting up to 5m0s for pod "pod-configmaps-0ac66d26-29b8-11e9-9603-eaa511fa0b6c" in namespace "e2e-tests-configmap-m644h" to be "success or failure"
Feb  6 02:36:44.333: INFO: Pod "pod-configmaps-0ac66d26-29b8-11e9-9603-eaa511fa0b6c": Phase="Pending", Reason="", readiness=false. Elapsed: 10.261962ms
Feb  6 02:36:46.341: INFO: Pod "pod-configmaps-0ac66d26-29b8-11e9-9603-eaa511fa0b6c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.0182473s
STEP: Saw pod success
Feb  6 02:36:46.341: INFO: Pod "pod-configmaps-0ac66d26-29b8-11e9-9603-eaa511fa0b6c" satisfied condition "success or failure"
Feb  6 02:36:46.350: INFO: Trying to get logs from node 10.190.119.143 pod pod-configmaps-0ac66d26-29b8-11e9-9603-eaa511fa0b6c container configmap-volume-test: <nil>
STEP: delete the pod
Feb  6 02:36:46.403: INFO: Waiting for pod pod-configmaps-0ac66d26-29b8-11e9-9603-eaa511fa0b6c to disappear
Feb  6 02:36:46.410: INFO: Pod pod-configmaps-0ac66d26-29b8-11e9-9603-eaa511fa0b6c no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  6 02:36:46.411: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-m644h" for this suite.
Feb  6 02:36:52.505: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 02:36:52.851: INFO: namespace: e2e-tests-configmap-m644h, resource: bindings, ignored listing per whitelist
Feb  6 02:36:52.904: INFO: namespace e2e-tests-configmap-m644h deletion completed in 6.482149684s

• [SLOW TEST:9.016 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  6 02:36:52.904: INFO: >>> kubeConfig: /tmp/kubeconfig-131423863
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-h7rc8
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name projected-configmap-test-volume-10134f1d-29b8-11e9-9603-eaa511fa0b6c
STEP: Creating a pod to test consume configMaps
Feb  6 02:36:53.222: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-1014b7a1-29b8-11e9-9603-eaa511fa0b6c" in namespace "e2e-tests-projected-h7rc8" to be "success or failure"
Feb  6 02:36:53.230: INFO: Pod "pod-projected-configmaps-1014b7a1-29b8-11e9-9603-eaa511fa0b6c": Phase="Pending", Reason="", readiness=false. Elapsed: 8.439924ms
Feb  6 02:36:55.243: INFO: Pod "pod-projected-configmaps-1014b7a1-29b8-11e9-9603-eaa511fa0b6c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.021193216s
Feb  6 02:36:57.252: INFO: Pod "pod-projected-configmaps-1014b7a1-29b8-11e9-9603-eaa511fa0b6c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.029875413s
STEP: Saw pod success
Feb  6 02:36:57.252: INFO: Pod "pod-projected-configmaps-1014b7a1-29b8-11e9-9603-eaa511fa0b6c" satisfied condition "success or failure"
Feb  6 02:36:57.260: INFO: Trying to get logs from node 10.190.119.184 pod pod-projected-configmaps-1014b7a1-29b8-11e9-9603-eaa511fa0b6c container projected-configmap-volume-test: <nil>
STEP: delete the pod
Feb  6 02:36:57.311: INFO: Waiting for pod pod-projected-configmaps-1014b7a1-29b8-11e9-9603-eaa511fa0b6c to disappear
Feb  6 02:36:57.318: INFO: Pod pod-projected-configmaps-1014b7a1-29b8-11e9-9603-eaa511fa0b6c no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  6 02:36:57.318: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-h7rc8" for this suite.
Feb  6 02:37:03.359: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 02:37:03.518: INFO: namespace: e2e-tests-projected-h7rc8, resource: bindings, ignored listing per whitelist
Feb  6 02:37:03.697: INFO: namespace e2e-tests-projected-h7rc8 deletion completed in 6.364986689s

• [SLOW TEST:10.793 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-storage] Projected 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  6 02:37:03.699: INFO: >>> kubeConfig: /tmp/kubeconfig-131423863
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-cm5gj
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name projected-secret-test-16b1e8ac-29b8-11e9-9603-eaa511fa0b6c
STEP: Creating a pod to test consume secrets
Feb  6 02:37:04.327: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-16b37579-29b8-11e9-9603-eaa511fa0b6c" in namespace "e2e-tests-projected-cm5gj" to be "success or failure"
Feb  6 02:37:04.337: INFO: Pod "pod-projected-secrets-16b37579-29b8-11e9-9603-eaa511fa0b6c": Phase="Pending", Reason="", readiness=false. Elapsed: 9.699882ms
Feb  6 02:37:06.345: INFO: Pod "pod-projected-secrets-16b37579-29b8-11e9-9603-eaa511fa0b6c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.017967275s
STEP: Saw pod success
Feb  6 02:37:06.346: INFO: Pod "pod-projected-secrets-16b37579-29b8-11e9-9603-eaa511fa0b6c" satisfied condition "success or failure"
Feb  6 02:37:06.354: INFO: Trying to get logs from node 10.190.119.133 pod pod-projected-secrets-16b37579-29b8-11e9-9603-eaa511fa0b6c container secret-volume-test: <nil>
STEP: delete the pod
Feb  6 02:37:06.417: INFO: Waiting for pod pod-projected-secrets-16b37579-29b8-11e9-9603-eaa511fa0b6c to disappear
Feb  6 02:37:06.425: INFO: Pod pod-projected-secrets-16b37579-29b8-11e9-9603-eaa511fa0b6c no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  6 02:37:06.426: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-cm5gj" for this suite.
Feb  6 02:37:12.468: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 02:37:12.711: INFO: namespace: e2e-tests-projected-cm5gj, resource: bindings, ignored listing per whitelist
Feb  6 02:37:12.778: INFO: namespace e2e-tests-projected-cm5gj deletion completed in 6.339300094s

• [SLOW TEST:9.080 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  6 02:37:12.780: INFO: >>> kubeConfig: /tmp/kubeconfig-131423863
STEP: Building a namespace api object, basename sched-pred
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-sched-pred-n8wtn
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:78
Feb  6 02:37:13.414: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Feb  6 02:37:13.440: INFO: Waiting for terminating namespaces to be deleted...
Feb  6 02:37:13.447: INFO: 
Logging pods the kubelet thinks is on node 10.190.119.133 before test
Feb  6 02:37:13.494: INFO: ibm-cloud-provider-ip-169-61-69-214-6d655b596d-zg2pn from ibm-system started at 2019-02-05 20:43:56 +0000 UTC (1 container statuses recorded)
Feb  6 02:37:13.494: INFO: 	Container ibm-cloud-provider-ip-169-61-69-214 ready: true, restart count 0
Feb  6 02:37:13.494: INFO: ibm-kube-fluentd-64s4c from kube-system started at 2019-02-05 20:45:46 +0000 UTC (1 container statuses recorded)
Feb  6 02:37:13.494: INFO: 	Container fluentd ready: true, restart count 0
Feb  6 02:37:13.494: INFO: sonobuoy-systemd-logs-daemon-set-d5b52e18812640c6-b9jsg from heptio-sonobuoy started at 2019-02-06 01:52:35 +0000 UTC (2 container statuses recorded)
Feb  6 02:37:13.494: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 0
Feb  6 02:37:13.494: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Feb  6 02:37:13.494: INFO: ibm-keepalived-watcher-bsbdb from kube-system started at 2019-02-05 20:41:39 +0000 UTC (1 container statuses recorded)
Feb  6 02:37:13.495: INFO: 	Container keepalived-watcher ready: true, restart count 0
Feb  6 02:37:13.495: INFO: calico-node-crvvm from kube-system started at 2019-02-05 20:41:39 +0000 UTC (2 container statuses recorded)
Feb  6 02:37:13.495: INFO: 	Container calico-node ready: true, restart count 0
Feb  6 02:37:13.495: INFO: 	Container install-cni ready: true, restart count 0
Feb  6 02:37:13.495: INFO: ibm-master-proxy-static-10.190.119.133 from kube-system started at <nil> (0 container statuses recorded)
Feb  6 02:37:13.495: INFO: kube-dns-amd64-fddfcc69-g2lwr from kube-system started at 2019-02-05 20:42:13 +0000 UTC (3 container statuses recorded)
Feb  6 02:37:13.495: INFO: 	Container dnsmasq ready: true, restart count 0
Feb  6 02:37:13.495: INFO: 	Container kubedns ready: true, restart count 0
Feb  6 02:37:13.495: INFO: 	Container sidecar ready: true, restart count 0
Feb  6 02:37:13.495: INFO: public-crf54ba0a8e6a945a29dcf052ae5eb4941-alb1-6c9c6d49c8-mpnh2 from kube-system started at 2019-02-05 20:47:04 +0000 UTC (4 container statuses recorded)
Feb  6 02:37:13.495: INFO: 	Container ingress-auth-1 ready: true, restart count 0
Feb  6 02:37:13.495: INFO: 	Container ingress-auth-2 ready: true, restart count 0
Feb  6 02:37:13.495: INFO: 	Container ingress-auth-3 ready: true, restart count 0
Feb  6 02:37:13.496: INFO: 	Container nginx-ingress ready: true, restart count 0
Feb  6 02:37:13.496: INFO: 
Logging pods the kubelet thinks is on node 10.190.119.143 before test
Feb  6 02:37:13.524: INFO: ibm-cloud-provider-ip-169-61-69-214-6d655b596d-659s6 from ibm-system started at 2019-02-05 20:43:56 +0000 UTC (1 container statuses recorded)
Feb  6 02:37:13.524: INFO: 	Container ibm-cloud-provider-ip-169-61-69-214 ready: true, restart count 0
Feb  6 02:37:13.524: INFO: sonobuoy-systemd-logs-daemon-set-d5b52e18812640c6-ftvb9 from heptio-sonobuoy started at 2019-02-06 01:52:35 +0000 UTC (2 container statuses recorded)
Feb  6 02:37:13.524: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 0
Feb  6 02:37:13.524: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Feb  6 02:37:13.524: INFO: calico-node-552zb from kube-system started at 2019-02-05 20:41:40 +0000 UTC (2 container statuses recorded)
Feb  6 02:37:13.524: INFO: 	Container calico-node ready: true, restart count 0
Feb  6 02:37:13.524: INFO: 	Container install-cni ready: true, restart count 0
Feb  6 02:37:13.524: INFO: test-k8s-e2e-pvg-master-verification from default started at 2019-02-06 01:52:27 +0000 UTC (1 container statuses recorded)
Feb  6 02:37:13.524: INFO: 	Container test-k8s-e2e-pvg-master-verification ready: true, restart count 0
Feb  6 02:37:13.524: INFO: sonobuoy-e2e-job-0d701a7a98354698 from heptio-sonobuoy started at 2019-02-06 01:52:35 +0000 UTC (2 container statuses recorded)
Feb  6 02:37:13.524: INFO: 	Container e2e ready: true, restart count 0
Feb  6 02:37:13.524: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Feb  6 02:37:13.524: INFO: ibm-master-proxy-static-10.190.119.143 from kube-system started at <nil> (0 container statuses recorded)
Feb  6 02:37:13.524: INFO: ibm-keepalived-watcher-mhfb7 from kube-system started at 2019-02-05 20:41:40 +0000 UTC (1 container statuses recorded)
Feb  6 02:37:13.524: INFO: 	Container keepalived-watcher ready: true, restart count 0
Feb  6 02:37:13.524: INFO: ibm-kube-fluentd-m6bg7 from kube-system started at 2019-02-05 20:45:46 +0000 UTC (1 container statuses recorded)
Feb  6 02:37:13.524: INFO: 	Container fluentd ready: true, restart count 0
Feb  6 02:37:13.524: INFO: public-crf54ba0a8e6a945a29dcf052ae5eb4941-alb1-6c9c6d49c8-v28fj from kube-system started at 2019-02-05 20:47:04 +0000 UTC (4 container statuses recorded)
Feb  6 02:37:13.524: INFO: 	Container ingress-auth-1 ready: true, restart count 0
Feb  6 02:37:13.524: INFO: 	Container ingress-auth-2 ready: true, restart count 0
Feb  6 02:37:13.524: INFO: 	Container ingress-auth-3 ready: true, restart count 0
Feb  6 02:37:13.524: INFO: 	Container nginx-ingress ready: true, restart count 0
Feb  6 02:37:13.524: INFO: 
Logging pods the kubelet thinks is on node 10.190.119.184 before test
Feb  6 02:37:13.552: INFO: kubernetes-dashboard-b4bc7db5d-6txlp from kube-system started at 2019-02-05 20:41:33 +0000 UTC (1 container statuses recorded)
Feb  6 02:37:13.552: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
Feb  6 02:37:13.552: INFO: ibm-keepalived-watcher-zff5x from kube-system started at 2019-02-05 20:41:33 +0000 UTC (1 container statuses recorded)
Feb  6 02:37:13.553: INFO: 	Container keepalived-watcher ready: true, restart count 0
Feb  6 02:37:13.553: INFO: ibm-kube-fluentd-xhx62 from kube-system started at 2019-02-05 20:45:46 +0000 UTC (1 container statuses recorded)
Feb  6 02:37:13.553: INFO: 	Container fluentd ready: true, restart count 0
Feb  6 02:37:13.553: INFO: sonobuoy-systemd-logs-daemon-set-d5b52e18812640c6-jw4pz from heptio-sonobuoy started at 2019-02-06 01:52:35 +0000 UTC (2 container statuses recorded)
Feb  6 02:37:13.553: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 0
Feb  6 02:37:13.553: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Feb  6 02:37:13.553: INFO: kube-dns-autoscaler-587cd5cd44-gcztk from kube-system started at 2019-02-05 20:41:33 +0000 UTC (1 container statuses recorded)
Feb  6 02:37:13.553: INFO: 	Container autoscaler ready: true, restart count 0
Feb  6 02:37:13.553: INFO: ibm-storage-watcher-59744c5787-r9jsw from kube-system started at 2019-02-05 20:41:33 +0000 UTC (1 container statuses recorded)
Feb  6 02:37:13.553: INFO: 	Container ibm-storage-watcher-container ready: true, restart count 0
Feb  6 02:37:13.553: INFO: calico-node-vk476 from kube-system started at 2019-02-05 20:41:33 +0000 UTC (2 container statuses recorded)
Feb  6 02:37:13.554: INFO: 	Container calico-node ready: true, restart count 0
Feb  6 02:37:13.554: INFO: 	Container install-cni ready: true, restart count 0
Feb  6 02:37:13.554: INFO: sonobuoy from heptio-sonobuoy started at 2019-02-06 01:52:33 +0000 UTC (1 container statuses recorded)
Feb  6 02:37:13.554: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Feb  6 02:37:13.554: INFO: vpn-6c6b45457f-dw7t6 from kube-system started at 2019-02-05 20:41:33 +0000 UTC (1 container statuses recorded)
Feb  6 02:37:13.554: INFO: 	Container vpn ready: true, restart count 0
Feb  6 02:37:13.554: INFO: ibm-file-plugin-7b5c95b4d-hcw67 from kube-system started at 2019-02-05 20:41:33 +0000 UTC (1 container statuses recorded)
Feb  6 02:37:13.554: INFO: 	Container ibm-file-plugin-container ready: true, restart count 0
Feb  6 02:37:13.554: INFO: ibm-master-proxy-static-10.190.119.184 from kube-system started at <nil> (0 container statuses recorded)
Feb  6 02:37:13.554: INFO: calico-kube-controllers-5c699798bc-q5g5q from kube-system started at 2019-02-05 20:41:33 +0000 UTC (1 container statuses recorded)
Feb  6 02:37:13.554: INFO: 	Container calico-kube-controllers ready: true, restart count 0
Feb  6 02:37:13.554: INFO: kube-dns-amd64-fddfcc69-stz86 from kube-system started at 2019-02-05 20:41:33 +0000 UTC (3 container statuses recorded)
Feb  6 02:37:13.555: INFO: 	Container dnsmasq ready: true, restart count 0
Feb  6 02:37:13.555: INFO: 	Container kubedns ready: true, restart count 0
Feb  6 02:37:13.555: INFO: 	Container sidecar ready: true, restart count 0
Feb  6 02:37:13.555: INFO: metrics-server-58cf9b87b8-lqfd8 from kube-system started at 2019-02-05 20:41:53 +0000 UTC (2 container statuses recorded)
Feb  6 02:37:13.555: INFO: 	Container metrics-server ready: true, restart count 0
Feb  6 02:37:13.555: INFO: 	Container metrics-server-nanny ready: true, restart count 0
[It] validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Trying to schedule Pod with nonempty NodeSelector.
STEP: Considering event: 
Type = [Warning], Name = [restricted-pod.1580a5db698b7643], Reason = [FailedScheduling], Message = [0/3 nodes are available: 3 node(s) didn't match node selector.]
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  6 02:37:14.613: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-sched-pred-n8wtn" for this suite.
Feb  6 02:37:20.679: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 02:37:20.947: INFO: namespace: e2e-tests-sched-pred-n8wtn, resource: bindings, ignored listing per whitelist
Feb  6 02:37:21.200: INFO: namespace e2e-tests-sched-pred-n8wtn deletion completed in 6.572003375s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:69

• [SLOW TEST:8.421 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  6 02:37:21.204: INFO: >>> kubeConfig: /tmp/kubeconfig-131423863
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-zdcnc
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:293
[It] should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the initial replication controller
Feb  6 02:37:21.510: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-131423863 create -f - --namespace=e2e-tests-kubectl-zdcnc'
Feb  6 02:37:21.856: INFO: stderr: ""
Feb  6 02:37:21.856: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Feb  6 02:37:21.856: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-131423863 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-zdcnc'
Feb  6 02:37:22.032: INFO: stderr: ""
Feb  6 02:37:22.032: INFO: stdout: "update-demo-nautilus-f84jk update-demo-nautilus-qx9l6 "
Feb  6 02:37:22.032: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-131423863 get pods update-demo-nautilus-f84jk -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-zdcnc'
Feb  6 02:37:22.189: INFO: stderr: ""
Feb  6 02:37:22.189: INFO: stdout: ""
Feb  6 02:37:22.189: INFO: update-demo-nautilus-f84jk is created but not running
Feb  6 02:37:27.189: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-131423863 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-zdcnc'
Feb  6 02:37:27.309: INFO: stderr: ""
Feb  6 02:37:27.309: INFO: stdout: "update-demo-nautilus-f84jk update-demo-nautilus-qx9l6 "
Feb  6 02:37:27.310: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-131423863 get pods update-demo-nautilus-f84jk -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-zdcnc'
Feb  6 02:37:27.427: INFO: stderr: ""
Feb  6 02:37:27.427: INFO: stdout: "true"
Feb  6 02:37:27.427: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-131423863 get pods update-demo-nautilus-f84jk -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-zdcnc'
Feb  6 02:37:27.576: INFO: stderr: ""
Feb  6 02:37:27.576: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Feb  6 02:37:27.576: INFO: validating pod update-demo-nautilus-f84jk
Feb  6 02:37:27.603: INFO: got data: {
  "image": "nautilus.jpg"
}

Feb  6 02:37:27.603: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Feb  6 02:37:27.603: INFO: update-demo-nautilus-f84jk is verified up and running
Feb  6 02:37:27.603: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-131423863 get pods update-demo-nautilus-qx9l6 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-zdcnc'
Feb  6 02:37:27.731: INFO: stderr: ""
Feb  6 02:37:27.731: INFO: stdout: "true"
Feb  6 02:37:27.731: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-131423863 get pods update-demo-nautilus-qx9l6 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-zdcnc'
Feb  6 02:37:27.901: INFO: stderr: ""
Feb  6 02:37:27.901: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Feb  6 02:37:27.901: INFO: validating pod update-demo-nautilus-qx9l6
Feb  6 02:37:27.922: INFO: got data: {
  "image": "nautilus.jpg"
}

Feb  6 02:37:27.922: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Feb  6 02:37:27.922: INFO: update-demo-nautilus-qx9l6 is verified up and running
STEP: rolling-update to new replication controller
Feb  6 02:37:27.923: INFO: scanned /root for discovery docs: <nil>
Feb  6 02:37:27.923: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-131423863 rolling-update update-demo-nautilus --update-period=1s -f - --namespace=e2e-tests-kubectl-zdcnc'
Feb  6 02:37:50.724: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Feb  6 02:37:50.724: INFO: stdout: "Created update-demo-kitten\nScaling up update-demo-kitten from 0 to 2, scaling down update-demo-nautilus from 2 to 0 (keep 2 pods available, don't exceed 3 pods)\nScaling update-demo-kitten up to 1\nScaling update-demo-nautilus down to 1\nScaling update-demo-kitten up to 2\nScaling update-demo-nautilus down to 0\nUpdate succeeded. Deleting old controller: update-demo-nautilus\nRenaming update-demo-kitten to update-demo-nautilus\nreplicationcontroller/update-demo-nautilus rolling updated\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Feb  6 02:37:50.724: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-131423863 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-zdcnc'
Feb  6 02:37:50.851: INFO: stderr: ""
Feb  6 02:37:50.851: INFO: stdout: "update-demo-kitten-p6vl6 update-demo-kitten-p8b7s "
Feb  6 02:37:50.851: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-131423863 get pods update-demo-kitten-p6vl6 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-zdcnc'
Feb  6 02:37:51.005: INFO: stderr: ""
Feb  6 02:37:51.005: INFO: stdout: "true"
Feb  6 02:37:51.005: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-131423863 get pods update-demo-kitten-p6vl6 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-zdcnc'
Feb  6 02:37:51.164: INFO: stderr: ""
Feb  6 02:37:51.164: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
Feb  6 02:37:51.164: INFO: validating pod update-demo-kitten-p6vl6
Feb  6 02:37:51.183: INFO: got data: {
  "image": "kitten.jpg"
}

Feb  6 02:37:51.183: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Feb  6 02:37:51.183: INFO: update-demo-kitten-p6vl6 is verified up and running
Feb  6 02:37:51.183: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-131423863 get pods update-demo-kitten-p8b7s -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-zdcnc'
Feb  6 02:37:51.311: INFO: stderr: ""
Feb  6 02:37:51.311: INFO: stdout: "true"
Feb  6 02:37:51.311: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-131423863 get pods update-demo-kitten-p8b7s -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-zdcnc'
Feb  6 02:37:51.458: INFO: stderr: ""
Feb  6 02:37:51.458: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
Feb  6 02:37:51.458: INFO: validating pod update-demo-kitten-p8b7s
Feb  6 02:37:51.491: INFO: got data: {
  "image": "kitten.jpg"
}

Feb  6 02:37:51.491: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Feb  6 02:37:51.491: INFO: update-demo-kitten-p8b7s is verified up and running
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  6 02:37:51.491: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-zdcnc" for this suite.
Feb  6 02:38:15.533: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 02:38:15.632: INFO: namespace: e2e-tests-kubectl-zdcnc, resource: bindings, ignored listing per whitelist
Feb  6 02:38:15.868: INFO: namespace e2e-tests-kubectl-zdcnc deletion completed in 24.362875943s

• [SLOW TEST:54.665 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Update Demo
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should do a rolling update of a replication controller  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  6 02:38:15.871: INFO: >>> kubeConfig: /tmp/kubeconfig-131423863
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-dvp6g
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-map-418b4f94-29b8-11e9-9603-eaa511fa0b6c
STEP: Creating a pod to test consume configMaps
Feb  6 02:38:16.216: INFO: Waiting up to 5m0s for pod "pod-configmaps-418cad8d-29b8-11e9-9603-eaa511fa0b6c" in namespace "e2e-tests-configmap-dvp6g" to be "success or failure"
Feb  6 02:38:16.225: INFO: Pod "pod-configmaps-418cad8d-29b8-11e9-9603-eaa511fa0b6c": Phase="Pending", Reason="", readiness=false. Elapsed: 8.028001ms
Feb  6 02:38:18.235: INFO: Pod "pod-configmaps-418cad8d-29b8-11e9-9603-eaa511fa0b6c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.018046539s
STEP: Saw pod success
Feb  6 02:38:18.235: INFO: Pod "pod-configmaps-418cad8d-29b8-11e9-9603-eaa511fa0b6c" satisfied condition "success or failure"
Feb  6 02:38:18.247: INFO: Trying to get logs from node 10.190.119.184 pod pod-configmaps-418cad8d-29b8-11e9-9603-eaa511fa0b6c container configmap-volume-test: <nil>
STEP: delete the pod
Feb  6 02:38:18.303: INFO: Waiting for pod pod-configmaps-418cad8d-29b8-11e9-9603-eaa511fa0b6c to disappear
Feb  6 02:38:18.312: INFO: Pod pod-configmaps-418cad8d-29b8-11e9-9603-eaa511fa0b6c no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  6 02:38:18.312: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-dvp6g" for this suite.
Feb  6 02:38:24.376: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 02:38:24.725: INFO: namespace: e2e-tests-configmap-dvp6g, resource: bindings, ignored listing per whitelist
Feb  6 02:38:24.790: INFO: namespace e2e-tests-configmap-dvp6g deletion completed in 6.456827895s

• [SLOW TEST:8.919 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume with mappings and Item mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-network] DNS 
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  6 02:38:24.790: INFO: >>> kubeConfig: /tmp/kubeconfig-131423863
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-dns-js2vp
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for services  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(dig +notcp +noall +answer +search dns-test-service A)" && echo OK > /results/wheezy_udp@dns-test-service;test -n "$$(dig +tcp +noall +answer +search dns-test-service A)" && echo OK > /results/wheezy_tcp@dns-test-service;test -n "$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-js2vp A)" && echo OK > /results/wheezy_udp@dns-test-service.e2e-tests-dns-js2vp;test -n "$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-js2vp A)" && echo OK > /results/wheezy_tcp@dns-test-service.e2e-tests-dns-js2vp;test -n "$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-js2vp.svc A)" && echo OK > /results/wheezy_udp@dns-test-service.e2e-tests-dns-js2vp.svc;test -n "$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-js2vp.svc A)" && echo OK > /results/wheezy_tcp@dns-test-service.e2e-tests-dns-js2vp.svc;test -n "$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-js2vp.svc SRV)" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.e2e-tests-dns-js2vp.svc;test -n "$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-js2vp.svc SRV)" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.e2e-tests-dns-js2vp.svc;test -n "$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-js2vp.svc SRV)" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.e2e-tests-dns-js2vp.svc;test -n "$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-js2vp.svc SRV)" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.e2e-tests-dns-js2vp.svc;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-js2vp.pod.cluster.local"}');test -n "$$(dig +notcp +noall +answer +search $${podARec} A)" && echo OK > /results/wheezy_udp@PodARecord;test -n "$$(dig +tcp +noall +answer +search $${podARec} A)" && echo OK > /results/wheezy_tcp@PodARecord;test -n "$$(dig +notcp +noall +answer +search 59.113.21.172.in-addr.arpa. PTR)" && echo OK > /results/172.21.113.59_udp@PTR;test -n "$$(dig +tcp +noall +answer +search 59.113.21.172.in-addr.arpa. PTR)" && echo OK > /results/172.21.113.59_tcp@PTR;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(dig +notcp +noall +answer +search dns-test-service A)" && echo OK > /results/jessie_udp@dns-test-service;test -n "$$(dig +tcp +noall +answer +search dns-test-service A)" && echo OK > /results/jessie_tcp@dns-test-service;test -n "$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-js2vp A)" && echo OK > /results/jessie_udp@dns-test-service.e2e-tests-dns-js2vp;test -n "$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-js2vp A)" && echo OK > /results/jessie_tcp@dns-test-service.e2e-tests-dns-js2vp;test -n "$$(dig +notcp +noall +answer +search dns-test-service.e2e-tests-dns-js2vp.svc A)" && echo OK > /results/jessie_udp@dns-test-service.e2e-tests-dns-js2vp.svc;test -n "$$(dig +tcp +noall +answer +search dns-test-service.e2e-tests-dns-js2vp.svc A)" && echo OK > /results/jessie_tcp@dns-test-service.e2e-tests-dns-js2vp.svc;test -n "$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-js2vp.svc SRV)" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.e2e-tests-dns-js2vp.svc;test -n "$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.e2e-tests-dns-js2vp.svc SRV)" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.e2e-tests-dns-js2vp.svc;test -n "$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-js2vp.svc SRV)" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.e2e-tests-dns-js2vp.svc;test -n "$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.e2e-tests-dns-js2vp.svc SRV)" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.e2e-tests-dns-js2vp.svc;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".e2e-tests-dns-js2vp.pod.cluster.local"}');test -n "$$(dig +notcp +noall +answer +search $${podARec} A)" && echo OK > /results/jessie_udp@PodARecord;test -n "$$(dig +tcp +noall +answer +search $${podARec} A)" && echo OK > /results/jessie_tcp@PodARecord;test -n "$$(dig +notcp +noall +answer +search 59.113.21.172.in-addr.arpa. PTR)" && echo OK > /results/172.21.113.59_udp@PTR;test -n "$$(dig +tcp +noall +answer +search 59.113.21.172.in-addr.arpa. PTR)" && echo OK > /results/172.21.113.59_tcp@PTR;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Feb  6 02:38:37.728: INFO: DNS probes using e2e-tests-dns-js2vp/dns-test-46f3ce93-29b8-11e9-9603-eaa511fa0b6c succeeded

STEP: deleting the pod
STEP: deleting the test service
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  6 02:38:37.854: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-dns-js2vp" for this suite.
Feb  6 02:38:43.896: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 02:38:44.088: INFO: namespace: e2e-tests-dns-js2vp, resource: bindings, ignored listing per whitelist
Feb  6 02:38:44.389: INFO: namespace e2e-tests-dns-js2vp deletion completed in 6.521693118s

• [SLOW TEST:19.598 seconds]
[sig-network] DNS
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-network] Services 
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  6 02:38:44.390: INFO: >>> kubeConfig: /tmp/kubeconfig-131423863
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-services-qrrgf
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:83
[It] should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating service multi-endpoint-test in namespace e2e-tests-services-qrrgf
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-qrrgf to expose endpoints map[]
Feb  6 02:38:45.101: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-qrrgf exposes endpoints map[] (10.630077ms elapsed)
STEP: Creating pod pod1 in namespace e2e-tests-services-qrrgf
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-qrrgf to expose endpoints map[pod1:[100]]
Feb  6 02:38:47.191: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-qrrgf exposes endpoints map[pod1:[100]] (2.066054399s elapsed)
STEP: Creating pod pod2 in namespace e2e-tests-services-qrrgf
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-qrrgf to expose endpoints map[pod1:[100] pod2:[101]]
Feb  6 02:38:49.359: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-qrrgf exposes endpoints map[pod2:[101] pod1:[100]] (2.156073451s elapsed)
STEP: Deleting pod pod1 in namespace e2e-tests-services-qrrgf
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-qrrgf to expose endpoints map[pod2:[101]]
Feb  6 02:38:49.412: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-qrrgf exposes endpoints map[pod2:[101]] (20.7986ms elapsed)
STEP: Deleting pod pod2 in namespace e2e-tests-services-qrrgf
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace e2e-tests-services-qrrgf to expose endpoints map[]
Feb  6 02:38:49.438: INFO: successfully validated that service multi-endpoint-test in namespace e2e-tests-services-qrrgf exposes endpoints map[] (8.496036ms elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  6 02:38:49.492: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-services-qrrgf" for this suite.
Feb  6 02:39:13.540: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 02:39:14.176: INFO: namespace: e2e-tests-services-qrrgf, resource: bindings, ignored listing per whitelist
Feb  6 02:39:14.906: INFO: namespace e2e-tests-services-qrrgf deletion completed in 25.400900157s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:88

• [SLOW TEST:30.516 seconds]
[sig-network] Services
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[k8s.io] Pods 
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  6 02:39:14.907: INFO: >>> kubeConfig: /tmp/kubeconfig-131423863
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-pods-smwts
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: setting up watch
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: verifying pod creation was observed
Feb  6 02:39:17.320: INFO: running pod: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-submit-remove-64b83b96-29b8-11e9-9603-eaa511fa0b6c", GenerateName:"", Namespace:"e2e-tests-pods-smwts", SelfLink:"/api/v1/namespaces/e2e-tests-pods-smwts/pods/pod-submit-remove-64b83b96-29b8-11e9-9603-eaa511fa0b6c", UID:"64bb69b3-29b8-11e9-bf83-6639c2940cda", ResourceVersion:"59002", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63685017555, loc:(*time.Location)(0x6c43b60)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"time":"202759119", "name":"foo"}, Annotations:map[string]string{"kubernetes.io/psp":"e2e-test-privileged-psp"}, OwnerReferences:[]v1.OwnerReference(nil), Initializers:(*v1.Initializers)(nil), Finalizers:[]string(nil), ClusterName:""}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"default-token-8tc6q", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(0xc42307cfc0), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil)}}}, InitContainers:[]v1.Container(nil), Containers:[]v1.Container{v1.Container{Name:"nginx", Image:"docker.io/library/nginx:1.14-alpine", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-8tc6q", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil)}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc423158198), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"10.190.119.133", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc42215a1e0), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc4231581e0)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc423158200)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc423158208), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil)}, Status:v1.PodStatus{Phase:"Running", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63685017555, loc:(*time.Location)(0x6c43b60)}}, Reason:"", Message:""}, v1.PodCondition{Type:"Ready", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63685017557, loc:(*time.Location)(0x6c43b60)}}, Reason:"", Message:""}, v1.PodCondition{Type:"ContainersReady", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63685017557, loc:(*time.Location)(0x6c43b60)}}, Reason:"", Message:""}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63685017555, loc:(*time.Location)(0x6c43b60)}}, Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"10.190.119.133", PodIP:"172.30.176.27", StartTime:(*v1.Time)(0xc42215cfa0), InitContainerStatuses:[]v1.ContainerStatus(nil), ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"nginx", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(0xc42215cfc0), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:true, RestartCount:0, Image:"docker.io/library/nginx:1.14-alpine", ImageID:"docker.io/library/nginx@sha256:b96aeeb1687703c49096f4969358d44f8520b671da94848309a3ba5be5b4c632", ContainerID:"containerd://aa7fb49c3aba5dfea2c373bcf9d7cdab1681a566a42cb0ff97c9c86f2b0d548f"}}, QOSClass:"BestEffort"}}
STEP: deleting the pod gracefully
STEP: verifying the kubelet observed the termination notice
STEP: verifying pod deletion was observed
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  6 02:39:28.042: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-smwts" for this suite.
Feb  6 02:39:34.096: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 02:39:34.363: INFO: namespace: e2e-tests-pods-smwts, resource: bindings, ignored listing per whitelist
Feb  6 02:39:34.484: INFO: namespace e2e-tests-pods-smwts deletion completed in 6.429062253s

• [SLOW TEST:19.578 seconds]
[k8s.io] Pods
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  6 02:39:34.486: INFO: >>> kubeConfig: /tmp/kubeconfig-131423863
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-secrets-l2mmw
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-map-7065a550-29b8-11e9-9603-eaa511fa0b6c
STEP: Creating a pod to test consume secrets
Feb  6 02:39:34.826: INFO: Waiting up to 5m0s for pod "pod-secrets-70675c55-29b8-11e9-9603-eaa511fa0b6c" in namespace "e2e-tests-secrets-l2mmw" to be "success or failure"
Feb  6 02:39:34.837: INFO: Pod "pod-secrets-70675c55-29b8-11e9-9603-eaa511fa0b6c": Phase="Pending", Reason="", readiness=false. Elapsed: 11.473308ms
Feb  6 02:39:36.847: INFO: Pod "pod-secrets-70675c55-29b8-11e9-9603-eaa511fa0b6c": Phase="Running", Reason="", readiness=true. Elapsed: 2.021442514s
Feb  6 02:39:38.855: INFO: Pod "pod-secrets-70675c55-29b8-11e9-9603-eaa511fa0b6c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.029649868s
STEP: Saw pod success
Feb  6 02:39:38.855: INFO: Pod "pod-secrets-70675c55-29b8-11e9-9603-eaa511fa0b6c" satisfied condition "success or failure"
Feb  6 02:39:38.864: INFO: Trying to get logs from node 10.190.119.143 pod pod-secrets-70675c55-29b8-11e9-9603-eaa511fa0b6c container secret-volume-test: <nil>
STEP: delete the pod
Feb  6 02:39:39.491: INFO: Waiting for pod pod-secrets-70675c55-29b8-11e9-9603-eaa511fa0b6c to disappear
Feb  6 02:39:39.499: INFO: Pod pod-secrets-70675c55-29b8-11e9-9603-eaa511fa0b6c no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  6 02:39:39.499: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-l2mmw" for this suite.
Feb  6 02:39:45.597: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 02:39:45.907: INFO: namespace: e2e-tests-secrets-l2mmw, resource: bindings, ignored listing per whitelist
Feb  6 02:39:46.006: INFO: namespace e2e-tests-secrets-l2mmw deletion completed in 6.45118009s

• [SLOW TEST:11.520 seconds]
[sig-storage] Secrets
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  6 02:39:46.007: INFO: >>> kubeConfig: /tmp/kubeconfig-131423863
STEP: Building a namespace api object, basename var-expansion
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-var-expansion-ffks4
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test substitution in container's args
Feb  6 02:39:46.325: INFO: Waiting up to 5m0s for pod "var-expansion-77421d14-29b8-11e9-9603-eaa511fa0b6c" in namespace "e2e-tests-var-expansion-ffks4" to be "success or failure"
Feb  6 02:39:46.391: INFO: Pod "var-expansion-77421d14-29b8-11e9-9603-eaa511fa0b6c": Phase="Pending", Reason="", readiness=false. Elapsed: 66.464812ms
Feb  6 02:39:48.400: INFO: Pod "var-expansion-77421d14-29b8-11e9-9603-eaa511fa0b6c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.075737314s
STEP: Saw pod success
Feb  6 02:39:48.401: INFO: Pod "var-expansion-77421d14-29b8-11e9-9603-eaa511fa0b6c" satisfied condition "success or failure"
Feb  6 02:39:48.409: INFO: Trying to get logs from node 10.190.119.184 pod var-expansion-77421d14-29b8-11e9-9603-eaa511fa0b6c container dapi-container: <nil>
STEP: delete the pod
Feb  6 02:39:48.492: INFO: Waiting for pod var-expansion-77421d14-29b8-11e9-9603-eaa511fa0b6c to disappear
Feb  6 02:39:48.500: INFO: Pod var-expansion-77421d14-29b8-11e9-9603-eaa511fa0b6c no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  6 02:39:48.500: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-var-expansion-ffks4" for this suite.
Feb  6 02:39:54.544: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 02:39:55.229: INFO: namespace: e2e-tests-var-expansion-ffks4, resource: bindings, ignored listing per whitelist
Feb  6 02:39:55.295: INFO: namespace e2e-tests-var-expansion-ffks4 deletion completed in 6.778966424s

• [SLOW TEST:9.288 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  6 02:39:55.298: INFO: >>> kubeConfig: /tmp/kubeconfig-131423863
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-mbndx
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-map-7d338324-29b8-11e9-9603-eaa511fa0b6c
STEP: Creating a pod to test consume secrets
Feb  6 02:39:56.314: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-7d3621da-29b8-11e9-9603-eaa511fa0b6c" in namespace "e2e-tests-projected-mbndx" to be "success or failure"
Feb  6 02:39:56.322: INFO: Pod "pod-projected-secrets-7d3621da-29b8-11e9-9603-eaa511fa0b6c": Phase="Pending", Reason="", readiness=false. Elapsed: 8.160193ms
Feb  6 02:39:58.335: INFO: Pod "pod-projected-secrets-7d3621da-29b8-11e9-9603-eaa511fa0b6c": Phase="Running", Reason="", readiness=true. Elapsed: 2.021321842s
Feb  6 02:40:00.345: INFO: Pod "pod-projected-secrets-7d3621da-29b8-11e9-9603-eaa511fa0b6c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.031060588s
STEP: Saw pod success
Feb  6 02:40:00.345: INFO: Pod "pod-projected-secrets-7d3621da-29b8-11e9-9603-eaa511fa0b6c" satisfied condition "success or failure"
Feb  6 02:40:00.391: INFO: Trying to get logs from node 10.190.119.133 pod pod-projected-secrets-7d3621da-29b8-11e9-9603-eaa511fa0b6c container projected-secret-volume-test: <nil>
STEP: delete the pod
Feb  6 02:40:00.833: INFO: Waiting for pod pod-projected-secrets-7d3621da-29b8-11e9-9603-eaa511fa0b6c to disappear
Feb  6 02:40:00.841: INFO: Pod pod-projected-secrets-7d3621da-29b8-11e9-9603-eaa511fa0b6c no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  6 02:40:00.841: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-mbndx" for this suite.
Feb  6 02:40:06.992: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 02:40:07.552: INFO: namespace: e2e-tests-projected-mbndx, resource: bindings, ignored listing per whitelist
Feb  6 02:40:07.708: INFO: namespace e2e-tests-projected-mbndx deletion completed in 6.815335928s

• [SLOW TEST:12.411 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume with mappings and Item Mode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl replace 
  should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  6 02:40:07.709: INFO: >>> kubeConfig: /tmp/kubeconfig-131423863
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-b5xch
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Kubectl replace
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1511
[It] should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Feb  6 02:40:08.042: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-131423863 run e2e-test-nginx-pod --generator=run-pod/v1 --image=docker.io/library/nginx:1.14-alpine --labels=run=e2e-test-nginx-pod --namespace=e2e-tests-kubectl-b5xch'
Feb  6 02:40:08.891: INFO: stderr: ""
Feb  6 02:40:08.891: INFO: stdout: "pod/e2e-test-nginx-pod created\n"
STEP: verifying the pod e2e-test-nginx-pod is running
STEP: verifying the pod e2e-test-nginx-pod was created
Feb  6 02:40:13.942: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-131423863 get pod e2e-test-nginx-pod --namespace=e2e-tests-kubectl-b5xch -o json'
Feb  6 02:40:14.103: INFO: stderr: ""
Feb  6 02:40:14.103: INFO: stdout: "{\n    \"apiVersion\": \"v1\",\n    \"kind\": \"Pod\",\n    \"metadata\": {\n        \"annotations\": {\n            \"kubernetes.io/psp\": \"e2e-test-privileged-psp\"\n        },\n        \"creationTimestamp\": \"2019-02-06T02:40:08Z\",\n        \"labels\": {\n            \"run\": \"e2e-test-nginx-pod\"\n        },\n        \"name\": \"e2e-test-nginx-pod\",\n        \"namespace\": \"e2e-tests-kubectl-b5xch\",\n        \"resourceVersion\": \"59253\",\n        \"selfLink\": \"/api/v1/namespaces/e2e-tests-kubectl-b5xch/pods/e2e-test-nginx-pod\",\n        \"uid\": \"84b59454-29b8-11e9-a275-52a9a0efac9f\"\n    },\n    \"spec\": {\n        \"containers\": [\n            {\n                \"image\": \"docker.io/library/nginx:1.14-alpine\",\n                \"imagePullPolicy\": \"IfNotPresent\",\n                \"name\": \"e2e-test-nginx-pod\",\n                \"resources\": {},\n                \"terminationMessagePath\": \"/dev/termination-log\",\n                \"terminationMessagePolicy\": \"File\",\n                \"volumeMounts\": [\n                    {\n                        \"mountPath\": \"/var/run/secrets/kubernetes.io/serviceaccount\",\n                        \"name\": \"default-token-m9h78\",\n                        \"readOnly\": true\n                    }\n                ]\n            }\n        ],\n        \"dnsPolicy\": \"ClusterFirst\",\n        \"nodeName\": \"10.190.119.133\",\n        \"priority\": 0,\n        \"restartPolicy\": \"Always\",\n        \"schedulerName\": \"default-scheduler\",\n        \"securityContext\": {},\n        \"serviceAccount\": \"default\",\n        \"serviceAccountName\": \"default\",\n        \"terminationGracePeriodSeconds\": 30,\n        \"tolerations\": [\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/not-ready\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            },\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/unreachable\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            }\n        ],\n        \"volumes\": [\n            {\n                \"name\": \"default-token-m9h78\",\n                \"secret\": {\n                    \"defaultMode\": 420,\n                    \"secretName\": \"default-token-m9h78\"\n                }\n            }\n        ]\n    },\n    \"status\": {\n        \"conditions\": [\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-02-06T02:40:08Z\",\n                \"status\": \"True\",\n                \"type\": \"Initialized\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-02-06T02:40:10Z\",\n                \"status\": \"True\",\n                \"type\": \"Ready\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-02-06T02:40:10Z\",\n                \"status\": \"True\",\n                \"type\": \"ContainersReady\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-02-06T02:40:08Z\",\n                \"status\": \"True\",\n                \"type\": \"PodScheduled\"\n            }\n        ],\n        \"containerStatuses\": [\n            {\n                \"containerID\": \"containerd://a6cc2fff38fb569379655404d3fc841d2d4a46564d8d88fec27f649c80687517\",\n                \"image\": \"docker.io/library/nginx:1.14-alpine\",\n                \"imageID\": \"docker.io/library/nginx@sha256:b96aeeb1687703c49096f4969358d44f8520b671da94848309a3ba5be5b4c632\",\n                \"lastState\": {},\n                \"name\": \"e2e-test-nginx-pod\",\n                \"ready\": true,\n                \"restartCount\": 0,\n                \"state\": {\n                    \"running\": {\n                        \"startedAt\": \"2019-02-06T02:40:09Z\"\n                    }\n                }\n            }\n        ],\n        \"hostIP\": \"10.190.119.133\",\n        \"phase\": \"Running\",\n        \"podIP\": \"172.30.176.34\",\n        \"qosClass\": \"BestEffort\",\n        \"startTime\": \"2019-02-06T02:40:08Z\"\n    }\n}\n"
STEP: replace the image in the pod
Feb  6 02:40:14.103: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-131423863 replace -f - --namespace=e2e-tests-kubectl-b5xch'
Feb  6 02:40:14.416: INFO: stderr: ""
Feb  6 02:40:14.416: INFO: stdout: "pod/e2e-test-nginx-pod replaced\n"
STEP: verifying the pod e2e-test-nginx-pod has the right image docker.io/library/busybox:1.29
[AfterEach] [k8s.io] Kubectl replace
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1516
Feb  6 02:40:14.426: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-131423863 delete pods e2e-test-nginx-pod --namespace=e2e-tests-kubectl-b5xch'
Feb  6 02:40:16.409: INFO: stderr: ""
Feb  6 02:40:16.409: INFO: stdout: "pod \"e2e-test-nginx-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  6 02:40:16.409: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-b5xch" for this suite.
Feb  6 02:40:22.519: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 02:40:22.840: INFO: namespace: e2e-tests-kubectl-b5xch, resource: bindings, ignored listing per whitelist
Feb  6 02:40:22.868: INFO: namespace e2e-tests-kubectl-b5xch deletion completed in 6.375949741s

• [SLOW TEST:15.159 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl replace
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should update a single-container pod's image  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  6 02:40:22.869: INFO: >>> kubeConfig: /tmp/kubeconfig-131423863
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-deployment-5sxvk
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb  6 02:40:23.177: INFO: Creating deployment "test-recreate-deployment"
Feb  6 02:40:23.192: INFO: Waiting deployment "test-recreate-deployment" to be updated to revision 1
Feb  6 02:40:23.212: INFO: deployment "test-recreate-deployment" doesn't have the required revision set
Feb  6 02:40:25.231: INFO: Waiting deployment "test-recreate-deployment" to complete
Feb  6 02:40:25.242: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63685017623, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63685017623, loc:(*time.Location)(0x6c43b60)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63685017623, loc:(*time.Location)(0x6c43b60)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63685017623, loc:(*time.Location)(0x6c43b60)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-recreate-deployment-79f694ff59\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb  6 02:40:27.257: INFO: Triggering a new rollout for deployment "test-recreate-deployment"
Feb  6 02:40:27.291: INFO: Updating deployment test-recreate-deployment
Feb  6 02:40:27.291: INFO: Watching deployment "test-recreate-deployment" to verify that new pods will not run with olds pods
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Feb  6 02:40:27.379: INFO: Deployment "test-recreate-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment,GenerateName:,Namespace:e2e-tests-deployment-5sxvk,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-5sxvk/deployments/test-recreate-deployment,UID:8d3d41c5-29b8-11e9-bf83-6639c2940cda,ResourceVersion:59355,Generation:2,CreationTimestamp:2019-02-06 02:40:23 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},Strategy:DeploymentStrategy{Type:Recreate,RollingUpdate:nil,},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:0,UnavailableReplicas:1,Conditions:[{Available False 2019-02-06 02:40:27 +0000 UTC 2019-02-06 02:40:27 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.} {Progressing True 2019-02-06 02:40:27 +0000 UTC 2019-02-06 02:40:23 +0000 UTC ReplicaSetUpdated ReplicaSet "test-recreate-deployment-7cf749666b" is progressing.}],ReadyReplicas:0,CollisionCount:nil,},}

Feb  6 02:40:27.386: INFO: New ReplicaSet "test-recreate-deployment-7cf749666b" of Deployment "test-recreate-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-7cf749666b,GenerateName:,Namespace:e2e-tests-deployment-5sxvk,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-5sxvk/replicasets/test-recreate-deployment-7cf749666b,UID:8fb5eaa1-29b8-11e9-a275-52a9a0efac9f,ResourceVersion:59354,Generation:1,CreationTimestamp:2019-02-06 02:40:27 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 7cf749666b,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 1,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment test-recreate-deployment 8d3d41c5-29b8-11e9-bf83-6639c2940cda 0xc4232183f7 0xc4232183f8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 7cf749666b,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 7cf749666b,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Feb  6 02:40:27.386: INFO: All old ReplicaSets of Deployment "test-recreate-deployment":
Feb  6 02:40:27.387: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-79f694ff59,GenerateName:,Namespace:e2e-tests-deployment-5sxvk,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-5sxvk/replicasets/test-recreate-deployment-79f694ff59,UID:8d3f8159-29b8-11e9-a275-52a9a0efac9f,ResourceVersion:59345,Generation:2,CreationTimestamp:2019-02-06 02:40:23 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 79f694ff59,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 1,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-recreate-deployment 8d3d41c5-29b8-11e9-bf83-6639c2940cda 0xc423218337 0xc423218338}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 79f694ff59,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 79f694ff59,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Feb  6 02:40:27.397: INFO: Pod "test-recreate-deployment-7cf749666b-vzxsw" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-7cf749666b-vzxsw,GenerateName:test-recreate-deployment-7cf749666b-,Namespace:e2e-tests-deployment-5sxvk,SelfLink:/api/v1/namespaces/e2e-tests-deployment-5sxvk/pods/test-recreate-deployment-7cf749666b-vzxsw,UID:8fb6eb8e-29b8-11e9-a275-52a9a0efac9f,ResourceVersion:59353,Generation:0,CreationTimestamp:2019-02-06 02:40:27 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 7cf749666b,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet test-recreate-deployment-7cf749666b 8fb5eaa1-29b8-11e9-a275-52a9a0efac9f 0xc423218be7 0xc423218be8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-2x4v5 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-2x4v5,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-2x4v5 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.190.119.133,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc423218c60} {node.kubernetes.io/unreachable Exists  NoExecute 0xc423218c80}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-06 02:40:27 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  6 02:40:27.397: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-5sxvk" for this suite.
Feb  6 02:40:33.443: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 02:40:33.768: INFO: namespace: e2e-tests-deployment-5sxvk, resource: bindings, ignored listing per whitelist
Feb  6 02:40:33.779: INFO: namespace e2e-tests-deployment-5sxvk deletion completed in 6.369501967s

• [SLOW TEST:10.911 seconds]
[sig-apps] Deployment
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  6 02:40:33.781: INFO: >>> kubeConfig: /tmp/kubeconfig-131423863
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-deployment-h7chp
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb  6 02:40:34.116: INFO: Pod name cleanup-pod: Found 0 pods out of 1
Feb  6 02:40:39.127: INFO: Pod name cleanup-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Feb  6 02:40:39.127: INFO: Creating deployment test-cleanup-deployment
STEP: Waiting for deployment test-cleanup-deployment history to be cleaned up
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Feb  6 02:40:39.176: INFO: Deployment "test-cleanup-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-deployment,GenerateName:,Namespace:e2e-tests-deployment-h7chp,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-h7chp/deployments/test-cleanup-deployment,UID:96c05082-29b8-11e9-bf83-6639c2940cda,ResourceVersion:59439,Generation:1,CreationTimestamp:2019-02-06 02:40:39 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*0,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:0,Replicas:0,UpdatedReplicas:0,AvailableReplicas:0,UnavailableReplicas:0,Conditions:[],ReadyReplicas:0,CollisionCount:nil,},}

Feb  6 02:40:39.185: INFO: New ReplicaSet "test-cleanup-deployment-755f6b95cc" of Deployment "test-cleanup-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-deployment-755f6b95cc,GenerateName:,Namespace:e2e-tests-deployment-h7chp,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-h7chp/replicasets/test-cleanup-deployment-755f6b95cc,UID:96c519fa-29b8-11e9-a275-52a9a0efac9f,ResourceVersion:59441,Generation:1,CreationTimestamp:2019-02-06 02:40:39 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod-template-hash: 755f6b95cc,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-cleanup-deployment 96c05082-29b8-11e9-bf83-6639c2940cda 0xc4231b1217 0xc4231b1218}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,pod-template-hash: 755f6b95cc,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod-template-hash: 755f6b95cc,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:0,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Feb  6 02:40:39.185: INFO: All old ReplicaSets of Deployment "test-cleanup-deployment":
Feb  6 02:40:39.185: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-controller,GenerateName:,Namespace:e2e-tests-deployment-h7chp,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-h7chp/replicasets/test-cleanup-controller,UID:93becb02-29b8-11e9-bf83-6639c2940cda,ResourceVersion:59440,Generation:1,CreationTimestamp:2019-02-06 02:40:34 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 Deployment test-cleanup-deployment 96c05082-29b8-11e9-bf83-6639c2940cda 0xc4231b1077 0xc4231b1078}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Feb  6 02:40:39.194: INFO: Pod "test-cleanup-controller-j727n" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-controller-j727n,GenerateName:test-cleanup-controller-,Namespace:e2e-tests-deployment-h7chp,SelfLink:/api/v1/namespaces/e2e-tests-deployment-h7chp/pods/test-cleanup-controller-j727n,UID:93c24c72-29b8-11e9-a275-52a9a0efac9f,ResourceVersion:59430,Generation:0,CreationTimestamp:2019-02-06 02:40:34 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod: nginx,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet test-cleanup-controller 93becb02-29b8-11e9-bf83-6639c2940cda 0xc4231b1cf7 0xc4231b1cf8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-558b4 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-558b4,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-558b4 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.190.119.143,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc4231b1d70} {node.kubernetes.io/unreachable Exists  NoExecute 0xc4231b1d90}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-06 02:40:34 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-02-06 02:40:35 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-02-06 02:40:35 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-06 02:40:34 +0000 UTC  }],Message:,Reason:,HostIP:10.190.119.143,PodIP:172.30.134.217,StartTime:2019-02-06 02:40:34 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-02-06 02:40:35 +0000 UTC,} nil} {nil nil nil} true 0 docker.io/library/nginx:1.14-alpine docker.io/library/nginx@sha256:b96aeeb1687703c49096f4969358d44f8520b671da94848309a3ba5be5b4c632 containerd://1e72a75d7338b6379b7d9b5cdc1664ae521eb0b20dd825f1d683902386badc1c}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb  6 02:40:39.194: INFO: Pod "test-cleanup-deployment-755f6b95cc-fqrfq" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-deployment-755f6b95cc-fqrfq,GenerateName:test-cleanup-deployment-755f6b95cc-,Namespace:e2e-tests-deployment-h7chp,SelfLink:/api/v1/namespaces/e2e-tests-deployment-h7chp/pods/test-cleanup-deployment-755f6b95cc-fqrfq,UID:96c62de1-29b8-11e9-a275-52a9a0efac9f,ResourceVersion:59444,Generation:0,CreationTimestamp:2019-02-06 02:40:39 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod-template-hash: 755f6b95cc,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet test-cleanup-deployment-755f6b95cc 96c519fa-29b8-11e9-a275-52a9a0efac9f 0xc421476027 0xc421476028}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-558b4 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-558b4,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-558b4 true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc421476090} {node.kubernetes.io/unreachable Exists  NoExecute 0xc4214760b0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  6 02:40:39.194: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-h7chp" for this suite.
Feb  6 02:40:45.234: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 02:40:46.029: INFO: namespace: e2e-tests-deployment-h7chp, resource: bindings, ignored listing per whitelist
Feb  6 02:40:46.071: INFO: namespace e2e-tests-deployment-h7chp deletion completed in 6.864132363s

• [SLOW TEST:12.290 seconds]
[sig-apps] Deployment
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  6 02:40:46.074: INFO: >>> kubeConfig: /tmp/kubeconfig-131423863
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-4d4mj
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb  6 02:40:46.406: INFO: Waiting up to 5m0s for pod "downwardapi-volume-9b120c0b-29b8-11e9-9603-eaa511fa0b6c" in namespace "e2e-tests-downward-api-4d4mj" to be "success or failure"
Feb  6 02:40:46.415: INFO: Pod "downwardapi-volume-9b120c0b-29b8-11e9-9603-eaa511fa0b6c": Phase="Pending", Reason="", readiness=false. Elapsed: 8.331688ms
Feb  6 02:40:48.425: INFO: Pod "downwardapi-volume-9b120c0b-29b8-11e9-9603-eaa511fa0b6c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.018463881s
Feb  6 02:40:50.434: INFO: Pod "downwardapi-volume-9b120c0b-29b8-11e9-9603-eaa511fa0b6c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.027263459s
STEP: Saw pod success
Feb  6 02:40:50.434: INFO: Pod "downwardapi-volume-9b120c0b-29b8-11e9-9603-eaa511fa0b6c" satisfied condition "success or failure"
Feb  6 02:40:50.444: INFO: Trying to get logs from node 10.190.119.133 pod downwardapi-volume-9b120c0b-29b8-11e9-9603-eaa511fa0b6c container client-container: <nil>
STEP: delete the pod
Feb  6 02:40:50.519: INFO: Waiting for pod downwardapi-volume-9b120c0b-29b8-11e9-9603-eaa511fa0b6c to disappear
Feb  6 02:40:50.531: INFO: Pod downwardapi-volume-9b120c0b-29b8-11e9-9603-eaa511fa0b6c no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  6 02:40:50.531: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-4d4mj" for this suite.
Feb  6 02:40:56.577: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 02:40:56.694: INFO: namespace: e2e-tests-downward-api-4d4mj, resource: bindings, ignored listing per whitelist
Feb  6 02:40:56.978: INFO: namespace e2e-tests-downward-api-4d4mj deletion completed in 6.430783013s

• [SLOW TEST:10.904 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-api-machinery] Watchers 
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  6 02:40:56.978: INFO: >>> kubeConfig: /tmp/kubeconfig-131423863
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-watch-82kgl
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a watch on configmaps
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: closing the watch once it receives two notifications
Feb  6 02:40:57.304: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-82kgl,SelfLink:/api/v1/namespaces/e2e-tests-watch-82kgl/configmaps/e2e-watch-test-watch-closed,UID:a190593a-29b8-11e9-bf83-6639c2940cda,ResourceVersion:59573,Generation:0,CreationTimestamp:2019-02-06 02:40:57 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Feb  6 02:40:57.304: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-82kgl,SelfLink:/api/v1/namespaces/e2e-tests-watch-82kgl/configmaps/e2e-watch-test-watch-closed,UID:a190593a-29b8-11e9-bf83-6639c2940cda,ResourceVersion:59574,Generation:0,CreationTimestamp:2019-02-06 02:40:57 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time, while the watch is closed
STEP: creating a new watch on configmaps from the last resource version observed by the first watch
STEP: deleting the configmap
STEP: Expecting to observe notifications for all changes to the configmap since the first watch closed
Feb  6 02:40:57.341: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-82kgl,SelfLink:/api/v1/namespaces/e2e-tests-watch-82kgl/configmaps/e2e-watch-test-watch-closed,UID:a190593a-29b8-11e9-bf83-6639c2940cda,ResourceVersion:59575,Generation:0,CreationTimestamp:2019-02-06 02:40:57 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Feb  6 02:40:57.341: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:e2e-tests-watch-82kgl,SelfLink:/api/v1/namespaces/e2e-tests-watch-82kgl/configmaps/e2e-watch-test-watch-closed,UID:a190593a-29b8-11e9-bf83-6639c2940cda,ResourceVersion:59576,Generation:0,CreationTimestamp:2019-02-06 02:40:57 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  6 02:40:57.341: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-82kgl" for this suite.
Feb  6 02:41:03.393: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 02:41:03.515: INFO: namespace: e2e-tests-watch-82kgl, resource: bindings, ignored listing per whitelist
Feb  6 02:41:03.904: INFO: namespace e2e-tests-watch-82kgl deletion completed in 6.551598403s

• [SLOW TEST:6.926 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  6 02:41:03.905: INFO: >>> kubeConfig: /tmp/kubeconfig-131423863
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-container-probe-q44pd
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-exec in namespace e2e-tests-container-probe-q44pd
Feb  6 02:41:06.401: INFO: Started pod liveness-exec in namespace e2e-tests-container-probe-q44pd
STEP: checking the pod's current state and verifying that restartCount is present
Feb  6 02:41:06.410: INFO: Initial restart count of pod liveness-exec is 0
Feb  6 02:41:59.012: INFO: Restart count of pod e2e-tests-container-probe-q44pd/liveness-exec is now 1 (52.602795948s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  6 02:41:59.045: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-q44pd" for this suite.
Feb  6 02:42:05.102: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 02:42:05.349: INFO: namespace: e2e-tests-container-probe-q44pd, resource: bindings, ignored listing per whitelist
Feb  6 02:42:05.477: INFO: namespace e2e-tests-container-probe-q44pd deletion completed in 6.418978069s

• [SLOW TEST:61.572 seconds]
[k8s.io] Probing container
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  6 02:42:05.478: INFO: >>> kubeConfig: /tmp/kubeconfig-131423863
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-pods-8xn6d
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb  6 02:42:07.885: INFO: Waiting up to 5m0s for pod "client-envvars-cba3801e-29b8-11e9-9603-eaa511fa0b6c" in namespace "e2e-tests-pods-8xn6d" to be "success or failure"
Feb  6 02:42:07.903: INFO: Pod "client-envvars-cba3801e-29b8-11e9-9603-eaa511fa0b6c": Phase="Pending", Reason="", readiness=false. Elapsed: 18.059772ms
Feb  6 02:42:09.911: INFO: Pod "client-envvars-cba3801e-29b8-11e9-9603-eaa511fa0b6c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.026875422s
STEP: Saw pod success
Feb  6 02:42:09.911: INFO: Pod "client-envvars-cba3801e-29b8-11e9-9603-eaa511fa0b6c" satisfied condition "success or failure"
Feb  6 02:42:09.924: INFO: Trying to get logs from node 10.190.119.143 pod client-envvars-cba3801e-29b8-11e9-9603-eaa511fa0b6c container env3cont: <nil>
STEP: delete the pod
Feb  6 02:42:09.992: INFO: Waiting for pod client-envvars-cba3801e-29b8-11e9-9603-eaa511fa0b6c to disappear
Feb  6 02:42:10.000: INFO: Pod client-envvars-cba3801e-29b8-11e9-9603-eaa511fa0b6c no longer exists
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  6 02:42:10.001: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-8xn6d" for this suite.
Feb  6 02:42:50.040: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 02:42:50.143: INFO: namespace: e2e-tests-pods-8xn6d, resource: bindings, ignored listing per whitelist
Feb  6 02:42:50.377: INFO: namespace e2e-tests-pods-8xn6d deletion completed in 40.364736666s

• [SLOW TEST:44.899 seconds]
[k8s.io] Pods
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-api-machinery] Garbage collector 
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  6 02:42:50.378: INFO: >>> kubeConfig: /tmp/kubeconfig-131423863
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-gc-kqqsd
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the rc1
STEP: create the rc2
STEP: set half of pods created by rc simpletest-rc-to-be-deleted to have rc simpletest-rc-to-stay as owner as well
STEP: delete the rc simpletest-rc-to-be-deleted
STEP: wait for the rc to be deleted
STEP: Gathering metrics
W0206 02:43:01.793704      15 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Feb  6 02:43:01.793: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  6 02:43:01.793: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-kqqsd" for this suite.
Feb  6 02:43:09.832: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 02:43:09.892: INFO: namespace: e2e-tests-gc-kqqsd, resource: bindings, ignored listing per whitelist
Feb  6 02:43:10.207: INFO: namespace e2e-tests-gc-kqqsd deletion completed in 8.401598189s

• [SLOW TEST:19.829 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-apps] Deployment 
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  6 02:43:10.207: INFO: >>> kubeConfig: /tmp/kubeconfig-131423863
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-deployment-z2qgr
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:65
[It] deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb  6 02:43:10.521: INFO: Creating deployment "nginx-deployment"
Feb  6 02:43:10.535: INFO: Waiting for observed generation 1
Feb  6 02:43:12.572: INFO: Waiting for all required pods to come up
Feb  6 02:43:12.585: INFO: Pod name nginx: Found 10 pods out of 10
STEP: ensuring each pod is running
Feb  6 02:43:14.603: INFO: Waiting for deployment "nginx-deployment" to complete
Feb  6 02:43:14.622: INFO: Updating deployment "nginx-deployment" with a non-existent image
Feb  6 02:43:14.646: INFO: Updating deployment nginx-deployment
Feb  6 02:43:14.646: INFO: Waiting for observed generation 2
Feb  6 02:43:16.667: INFO: Waiting for the first rollout's replicaset to have .status.availableReplicas = 8
Feb  6 02:43:16.677: INFO: Waiting for the first rollout's replicaset to have .spec.replicas = 8
Feb  6 02:43:16.688: INFO: Waiting for the first rollout's replicaset of deployment "nginx-deployment" to have desired number of replicas
Feb  6 02:43:16.715: INFO: Verifying that the second rollout's replicaset has .status.availableReplicas = 0
Feb  6 02:43:16.715: INFO: Waiting for the second rollout's replicaset to have .spec.replicas = 5
Feb  6 02:43:16.722: INFO: Waiting for the second rollout's replicaset of deployment "nginx-deployment" to have desired number of replicas
Feb  6 02:43:16.736: INFO: Verifying that deployment "nginx-deployment" has minimum required number of available replicas
Feb  6 02:43:16.736: INFO: Scaling up the deployment "nginx-deployment" from 10 to 30
Feb  6 02:43:16.760: INFO: Updating deployment nginx-deployment
Feb  6 02:43:16.760: INFO: Waiting for the replicasets of deployment "nginx-deployment" to have desired number of replicas
Feb  6 02:43:16.775: INFO: Verifying that first rollout's replicaset has .spec.replicas = 20
Feb  6 02:43:18.792: INFO: Verifying that second rollout's replicaset has .spec.replicas = 13
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:59
Feb  6 02:43:18.811: INFO: Deployment "nginx-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment,GenerateName:,Namespace:e2e-tests-deployment-z2qgr,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-z2qgr/deployments/nginx-deployment,UID:f0fb605d-29b8-11e9-bf83-6639c2940cda,ResourceVersion:60756,Generation:3,CreationTimestamp:2019-02-06 02:43:10 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:DeploymentSpec{Replicas:*30,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:2,MaxSurge:3,},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:3,Replicas:33,UpdatedReplicas:13,AvailableReplicas:9,UnavailableReplicas:24,Conditions:[{Available False 2019-02-06 02:43:16 +0000 UTC 2019-02-06 02:43:16 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.} {Progressing True 2019-02-06 02:43:18 +0000 UTC 2019-02-06 02:43:10 +0000 UTC ReplicaSetUpdated ReplicaSet "nginx-deployment-7dc8f79789" is progressing.}],ReadyReplicas:9,CollisionCount:nil,},}

Feb  6 02:43:18.819: INFO: New ReplicaSet "nginx-deployment-7dc8f79789" of Deployment "nginx-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789,GenerateName:,Namespace:e2e-tests-deployment-z2qgr,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-z2qgr/replicasets/nginx-deployment-7dc8f79789,UID:f3700fee-29b8-11e9-a275-52a9a0efac9f,ResourceVersion:60573,Generation:3,CreationTimestamp:2019-02-06 02:43:14 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 30,deployment.kubernetes.io/max-replicas: 33,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment nginx-deployment f0fb605d-29b8-11e9-bf83-6639c2940cda 0xc42158bc27 0xc42158bc28}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*13,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:13,FullyLabeledReplicas:13,ObservedGeneration:3,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Feb  6 02:43:18.819: INFO: All old ReplicaSets of Deployment "nginx-deployment":
Feb  6 02:43:18.819: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b,GenerateName:,Namespace:e2e-tests-deployment-z2qgr,SelfLink:/apis/apps/v1/namespaces/e2e-tests-deployment-z2qgr/replicasets/nginx-deployment-7f9675fb8b,UID:f0fdbab9-29b8-11e9-a275-52a9a0efac9f,ResourceVersion:60768,Generation:3,CreationTimestamp:2019-02-06 02:43:10 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 30,deployment.kubernetes.io/max-replicas: 33,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment nginx-deployment f0fb605d-29b8-11e9-bf83-6639c2940cda 0xc42158bce7 0xc42158bce8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicaSetSpec{Replicas:*20,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:20,FullyLabeledReplicas:20,ObservedGeneration:3,ReadyReplicas:10,AvailableReplicas:10,Conditions:[],},}
Feb  6 02:43:18.835: INFO: Pod "nginx-deployment-7dc8f79789-25qnv" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-25qnv,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-z2qgr,SelfLink:/api/v1/namespaces/e2e-tests-deployment-z2qgr/pods/nginx-deployment-7dc8f79789-25qnv,UID:f4b871a0-29b8-11e9-a275-52a9a0efac9f,ResourceVersion:60753,Generation:0,CreationTimestamp:2019-02-06 02:43:16 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 f3700fee-29b8-11e9-a275-52a9a0efac9f 0xc420db3857 0xc420db3858}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-dn52m {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-dn52m,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-dn52m true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.190.119.143,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc420db3940} {node.kubernetes.io/unreachable Exists  NoExecute 0xc420db3960}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-06 02:43:16 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-06 02:43:16 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-06 02:43:16 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-06 02:43:16 +0000 UTC  }],Message:,Reason:,HostIP:10.190.119.143,PodIP:172.30.134.232,StartTime:2019-02-06 02:43:16 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = failed to resolve image "docker.io/library/nginx:404": docker.io/library/nginx:404 not found,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb  6 02:43:18.835: INFO: Pod "nginx-deployment-7dc8f79789-9sh8g" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-9sh8g,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-z2qgr,SelfLink:/api/v1/namespaces/e2e-tests-deployment-z2qgr/pods/nginx-deployment-7dc8f79789-9sh8g,UID:f3731db1-29b8-11e9-a275-52a9a0efac9f,ResourceVersion:60506,Generation:0,CreationTimestamp:2019-02-06 02:43:14 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 f3700fee-29b8-11e9-a275-52a9a0efac9f 0xc420db3b80 0xc420db3b81}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-dn52m {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-dn52m,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-dn52m true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.190.119.143,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc420db3d00} {node.kubernetes.io/unreachable Exists  NoExecute 0xc420db3d20}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-06 02:43:14 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-06 02:43:14 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-06 02:43:14 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-06 02:43:14 +0000 UTC  }],Message:,Reason:,HostIP:10.190.119.143,PodIP:172.30.134.228,StartTime:2019-02-06 02:43:14 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = failed to resolve image "docker.io/library/nginx:404": docker.io/library/nginx:404 not found,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb  6 02:43:18.836: INFO: Pod "nginx-deployment-7dc8f79789-c2t46" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-c2t46,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-z2qgr,SelfLink:/api/v1/namespaces/e2e-tests-deployment-z2qgr/pods/nginx-deployment-7dc8f79789-c2t46,UID:f4b80b9a-29b8-11e9-a275-52a9a0efac9f,ResourceVersion:60591,Generation:0,CreationTimestamp:2019-02-06 02:43:16 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 f3700fee-29b8-11e9-a275-52a9a0efac9f 0xc420db3f10 0xc420db3f11}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-dn52m {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-dn52m,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-dn52m true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.190.119.133,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc421a828a0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421a828c0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-06 02:43:16 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-06 02:43:16 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-06 02:43:16 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-06 02:43:16 +0000 UTC  }],Message:,Reason:,HostIP:10.190.119.133,PodIP:,StartTime:2019-02-06 02:43:16 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb  6 02:43:18.836: INFO: Pod "nginx-deployment-7dc8f79789-cggkl" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-cggkl,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-z2qgr,SelfLink:/api/v1/namespaces/e2e-tests-deployment-z2qgr/pods/nginx-deployment-7dc8f79789-cggkl,UID:f3712b06-29b8-11e9-a275-52a9a0efac9f,ResourceVersion:60726,Generation:0,CreationTimestamp:2019-02-06 02:43:14 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 f3700fee-29b8-11e9-a275-52a9a0efac9f 0xc421a82a10 0xc421a82a11}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-dn52m {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-dn52m,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-dn52m true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.190.119.184,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc421a82b00} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421a82b20}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-06 02:43:14 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-06 02:43:14 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-06 02:43:14 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-06 02:43:14 +0000 UTC  }],Message:,Reason:,HostIP:10.190.119.184,PodIP:172.30.242.29,StartTime:2019-02-06 02:43:14 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = failed to resolve image "docker.io/library/nginx:404": docker.io/library/nginx:404 not found,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb  6 02:43:18.836: INFO: Pod "nginx-deployment-7dc8f79789-cl4q4" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-cl4q4,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-z2qgr,SelfLink:/api/v1/namespaces/e2e-tests-deployment-z2qgr/pods/nginx-deployment-7dc8f79789-cl4q4,UID:f4b63b1d-29b8-11e9-a275-52a9a0efac9f,ResourceVersion:60632,Generation:0,CreationTimestamp:2019-02-06 02:43:16 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 f3700fee-29b8-11e9-a275-52a9a0efac9f 0xc421a82ef0 0xc421a82ef1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-dn52m {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-dn52m,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-dn52m true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.190.119.133,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc421a83300} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421a83320}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-06 02:43:16 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-06 02:43:16 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-06 02:43:16 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-06 02:43:16 +0000 UTC  }],Message:,Reason:,HostIP:10.190.119.133,PodIP:,StartTime:2019-02-06 02:43:16 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb  6 02:43:18.837: INFO: Pod "nginx-deployment-7dc8f79789-dcmbk" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-dcmbk,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-z2qgr,SelfLink:/api/v1/namespaces/e2e-tests-deployment-z2qgr/pods/nginx-deployment-7dc8f79789-dcmbk,UID:f3732741-29b8-11e9-a275-52a9a0efac9f,ResourceVersion:60513,Generation:0,CreationTimestamp:2019-02-06 02:43:14 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 f3700fee-29b8-11e9-a275-52a9a0efac9f 0xc421a835f0 0xc421a835f1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-dn52m {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-dn52m,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-dn52m true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.190.119.133,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc421a83670} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421a836b0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-06 02:43:14 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-06 02:43:14 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-06 02:43:14 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-06 02:43:14 +0000 UTC  }],Message:,Reason:,HostIP:10.190.119.133,PodIP:172.30.176.39,StartTime:2019-02-06 02:43:14 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = failed to resolve image "docker.io/library/nginx:404": docker.io/library/nginx:404 not found,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb  6 02:43:18.837: INFO: Pod "nginx-deployment-7dc8f79789-gcw99" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-gcw99,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-z2qgr,SelfLink:/api/v1/namespaces/e2e-tests-deployment-z2qgr/pods/nginx-deployment-7dc8f79789-gcw99,UID:f4b629b5-29b8-11e9-a275-52a9a0efac9f,ResourceVersion:60583,Generation:0,CreationTimestamp:2019-02-06 02:43:16 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 f3700fee-29b8-11e9-a275-52a9a0efac9f 0xc421a83930 0xc421a83931}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-dn52m {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-dn52m,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-dn52m true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.190.119.133,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc421a83ae0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421a83b00}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-06 02:43:16 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-06 02:43:16 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-06 02:43:16 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-06 02:43:16 +0000 UTC  }],Message:,Reason:,HostIP:10.190.119.133,PodIP:,StartTime:2019-02-06 02:43:16 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb  6 02:43:18.837: INFO: Pod "nginx-deployment-7dc8f79789-k798l" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-k798l,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-z2qgr,SelfLink:/api/v1/namespaces/e2e-tests-deployment-z2qgr/pods/nginx-deployment-7dc8f79789-k798l,UID:f4b48672-29b8-11e9-a275-52a9a0efac9f,ResourceVersion:60752,Generation:0,CreationTimestamp:2019-02-06 02:43:16 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 f3700fee-29b8-11e9-a275-52a9a0efac9f 0xc421a83bc0 0xc421a83bc1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-dn52m {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-dn52m,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-dn52m true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.190.119.143,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc421a83d90} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421a83db0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-06 02:43:16 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-06 02:43:16 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-06 02:43:16 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-06 02:43:16 +0000 UTC  }],Message:,Reason:,HostIP:10.190.119.143,PodIP:172.30.134.229,StartTime:2019-02-06 02:43:16 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = failed to resolve image "docker.io/library/nginx:404": docker.io/library/nginx:404 not found,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb  6 02:43:18.837: INFO: Pod "nginx-deployment-7dc8f79789-lg9q6" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-lg9q6,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-z2qgr,SelfLink:/api/v1/namespaces/e2e-tests-deployment-z2qgr/pods/nginx-deployment-7dc8f79789-lg9q6,UID:f4b81119-29b8-11e9-a275-52a9a0efac9f,ResourceVersion:60602,Generation:0,CreationTimestamp:2019-02-06 02:43:16 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 f3700fee-29b8-11e9-a275-52a9a0efac9f 0xc421a83f10 0xc421a83f11}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-dn52m {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-dn52m,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-dn52m true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.190.119.184,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc4201ea040} {node.kubernetes.io/unreachable Exists  NoExecute 0xc4201ea060}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-06 02:43:16 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-06 02:43:16 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-06 02:43:16 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-06 02:43:16 +0000 UTC  }],Message:,Reason:,HostIP:10.190.119.184,PodIP:,StartTime:2019-02-06 02:43:16 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb  6 02:43:18.838: INFO: Pod "nginx-deployment-7dc8f79789-sdkwl" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-sdkwl,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-z2qgr,SelfLink:/api/v1/namespaces/e2e-tests-deployment-z2qgr/pods/nginx-deployment-7dc8f79789-sdkwl,UID:f4ba70f6-29b8-11e9-a275-52a9a0efac9f,ResourceVersion:60609,Generation:0,CreationTimestamp:2019-02-06 02:43:16 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 f3700fee-29b8-11e9-a275-52a9a0efac9f 0xc4201ea1c0 0xc4201ea1c1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-dn52m {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-dn52m,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-dn52m true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.190.119.184,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc4201ea240} {node.kubernetes.io/unreachable Exists  NoExecute 0xc4201ea260}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-06 02:43:16 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-06 02:43:16 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-06 02:43:16 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-06 02:43:16 +0000 UTC  }],Message:,Reason:,HostIP:10.190.119.184,PodIP:,StartTime:2019-02-06 02:43:16 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb  6 02:43:18.838: INFO: Pod "nginx-deployment-7dc8f79789-vjxff" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-vjxff,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-z2qgr,SelfLink:/api/v1/namespaces/e2e-tests-deployment-z2qgr/pods/nginx-deployment-7dc8f79789-vjxff,UID:f379249d-29b8-11e9-a275-52a9a0efac9f,ResourceVersion:60516,Generation:0,CreationTimestamp:2019-02-06 02:43:14 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 f3700fee-29b8-11e9-a275-52a9a0efac9f 0xc4201ea3d0 0xc4201ea3d1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-dn52m {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-dn52m,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-dn52m true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.190.119.133,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc4201ea450} {node.kubernetes.io/unreachable Exists  NoExecute 0xc4201ea480}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-06 02:43:14 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-06 02:43:14 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-06 02:43:14 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-06 02:43:14 +0000 UTC  }],Message:,Reason:,HostIP:10.190.119.133,PodIP:172.30.176.38,StartTime:2019-02-06 02:43:14 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = failed to resolve image "docker.io/library/nginx:404": docker.io/library/nginx:404 not found,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb  6 02:43:18.838: INFO: Pod "nginx-deployment-7dc8f79789-wwd9q" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-wwd9q,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-z2qgr,SelfLink:/api/v1/namespaces/e2e-tests-deployment-z2qgr/pods/nginx-deployment-7dc8f79789-wwd9q,UID:f4b813ce-29b8-11e9-a275-52a9a0efac9f,ResourceVersion:60599,Generation:0,CreationTimestamp:2019-02-06 02:43:16 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 f3700fee-29b8-11e9-a275-52a9a0efac9f 0xc4201ea5d0 0xc4201ea5d1}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-dn52m {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-dn52m,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-dn52m true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.190.119.143,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc4201ea790} {node.kubernetes.io/unreachable Exists  NoExecute 0xc4201ea7b0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-06 02:43:16 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-06 02:43:16 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-06 02:43:16 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-06 02:43:16 +0000 UTC  }],Message:,Reason:,HostIP:10.190.119.143,PodIP:,StartTime:2019-02-06 02:43:16 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb  6 02:43:18.838: INFO: Pod "nginx-deployment-7dc8f79789-xrc8z" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7dc8f79789-xrc8z,GenerateName:nginx-deployment-7dc8f79789-,Namespace:e2e-tests-deployment-z2qgr,SelfLink:/api/v1/namespaces/e2e-tests-deployment-z2qgr/pods/nginx-deployment-7dc8f79789-xrc8z,UID:f37b232e-29b8-11e9-a275-52a9a0efac9f,ResourceVersion:60499,Generation:0,CreationTimestamp:2019-02-06 02:43:14 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7dc8f79789,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7dc8f79789 f3700fee-29b8-11e9-a275-52a9a0efac9f 0xc4201ea870 0xc4201ea871}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-dn52m {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-dn52m,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-dn52m true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.190.119.184,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc4201ea970} {node.kubernetes.io/unreachable Exists  NoExecute 0xc4201ea990}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-06 02:43:14 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-06 02:43:14 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-06 02:43:14 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-06 02:43:14 +0000 UTC  }],Message:,Reason:,HostIP:10.190.119.184,PodIP:172.30.242.28,StartTime:2019-02-06 02:43:14 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = failed to resolve image "docker.io/library/nginx:404": docker.io/library/nginx:404 not found,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb  6 02:43:18.839: INFO: Pod "nginx-deployment-7f9675fb8b-474pf" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-474pf,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-z2qgr,SelfLink:/api/v1/namespaces/e2e-tests-deployment-z2qgr/pods/nginx-deployment-7f9675fb8b-474pf,UID:f4b731b4-29b8-11e9-a275-52a9a0efac9f,ResourceVersion:60754,Generation:0,CreationTimestamp:2019-02-06 02:43:16 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b f0fdbab9-29b8-11e9-a275-52a9a0efac9f 0xc4201eaa80 0xc4201eaa81}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-dn52m {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-dn52m,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-dn52m true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.190.119.143,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc4201eabc0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc4201eabe0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-06 02:43:16 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-02-06 02:43:18 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-02-06 02:43:18 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-06 02:43:16 +0000 UTC  }],Message:,Reason:,HostIP:10.190.119.143,PodIP:172.30.134.233,StartTime:2019-02-06 02:43:16 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-02-06 02:43:18 +0000 UTC,} nil} {nil nil nil} true 0 docker.io/library/nginx:1.14-alpine docker.io/library/nginx@sha256:b96aeeb1687703c49096f4969358d44f8520b671da94848309a3ba5be5b4c632 containerd://910ff7a5c6e52cf408f6822813f8fb881e505d474e59f3ecc2a0004ccf89064a}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb  6 02:43:18.839: INFO: Pod "nginx-deployment-7f9675fb8b-4wsdj" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-4wsdj,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-z2qgr,SelfLink:/api/v1/namespaces/e2e-tests-deployment-z2qgr/pods/nginx-deployment-7f9675fb8b-4wsdj,UID:f4b94092-29b8-11e9-a275-52a9a0efac9f,ResourceVersion:60714,Generation:0,CreationTimestamp:2019-02-06 02:43:16 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b f0fdbab9-29b8-11e9-a275-52a9a0efac9f 0xc4201eacb7 0xc4201eacb8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-dn52m {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-dn52m,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-dn52m true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.190.119.133,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc4201ead90} {node.kubernetes.io/unreachable Exists  NoExecute 0xc4201eadb0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-06 02:43:16 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-06 02:43:16 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-06 02:43:16 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-06 02:43:16 +0000 UTC  }],Message:,Reason:,HostIP:10.190.119.133,PodIP:,StartTime:2019-02-06 02:43:16 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb  6 02:43:18.839: INFO: Pod "nginx-deployment-7f9675fb8b-65npw" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-65npw,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-z2qgr,SelfLink:/api/v1/namespaces/e2e-tests-deployment-z2qgr/pods/nginx-deployment-7f9675fb8b-65npw,UID:f1075ef2-29b8-11e9-a275-52a9a0efac9f,ResourceVersion:60396,Generation:0,CreationTimestamp:2019-02-06 02:43:10 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b f0fdbab9-29b8-11e9-a275-52a9a0efac9f 0xc4201eaed7 0xc4201eaed8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-dn52m {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-dn52m,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-dn52m true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.190.119.143,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc4201eaf70} {node.kubernetes.io/unreachable Exists  NoExecute 0xc4201eaf90}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-06 02:43:10 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-02-06 02:43:11 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-02-06 02:43:11 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-06 02:43:10 +0000 UTC  }],Message:,Reason:,HostIP:10.190.119.143,PodIP:172.30.134.222,StartTime:2019-02-06 02:43:10 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-02-06 02:43:11 +0000 UTC,} nil} {nil nil nil} true 0 docker.io/library/nginx:1.14-alpine docker.io/library/nginx@sha256:b96aeeb1687703c49096f4969358d44f8520b671da94848309a3ba5be5b4c632 containerd://ed0a3454f32b53f9ac0d9f2e73fac1423db6aa217b7472fd7a5297f46e45505d}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb  6 02:43:18.839: INFO: Pod "nginx-deployment-7f9675fb8b-6fwcb" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-6fwcb,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-z2qgr,SelfLink:/api/v1/namespaces/e2e-tests-deployment-z2qgr/pods/nginx-deployment-7f9675fb8b-6fwcb,UID:f10342ab-29b8-11e9-a275-52a9a0efac9f,ResourceVersion:60402,Generation:0,CreationTimestamp:2019-02-06 02:43:10 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b f0fdbab9-29b8-11e9-a275-52a9a0efac9f 0xc4201eb0d7 0xc4201eb0d8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-dn52m {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-dn52m,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-dn52m true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.190.119.133,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc4201eb150} {node.kubernetes.io/unreachable Exists  NoExecute 0xc4201eb170}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-06 02:43:10 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-02-06 02:43:12 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-02-06 02:43:12 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-06 02:43:10 +0000 UTC  }],Message:,Reason:,HostIP:10.190.119.133,PodIP:172.30.176.37,StartTime:2019-02-06 02:43:10 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-02-06 02:43:11 +0000 UTC,} nil} {nil nil nil} true 0 docker.io/library/nginx:1.14-alpine docker.io/library/nginx@sha256:b96aeeb1687703c49096f4969358d44f8520b671da94848309a3ba5be5b4c632 containerd://5bce2fcc4c41fec919f67f17485926368681d752c7fcafedc446b5e13a9eb011}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb  6 02:43:18.840: INFO: Pod "nginx-deployment-7f9675fb8b-6qj7p" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-6qj7p,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-z2qgr,SelfLink:/api/v1/namespaces/e2e-tests-deployment-z2qgr/pods/nginx-deployment-7f9675fb8b-6qj7p,UID:f1055ee8-29b8-11e9-a275-52a9a0efac9f,ResourceVersion:60393,Generation:0,CreationTimestamp:2019-02-06 02:43:10 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b f0fdbab9-29b8-11e9-a275-52a9a0efac9f 0xc4201eb287 0xc4201eb288}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-dn52m {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-dn52m,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-dn52m true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.190.119.143,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc4201eb300} {node.kubernetes.io/unreachable Exists  NoExecute 0xc4201eb320}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-06 02:43:10 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-02-06 02:43:11 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-02-06 02:43:11 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-06 02:43:10 +0000 UTC  }],Message:,Reason:,HostIP:10.190.119.143,PodIP:172.30.134.225,StartTime:2019-02-06 02:43:10 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-02-06 02:43:11 +0000 UTC,} nil} {nil nil nil} true 0 docker.io/library/nginx:1.14-alpine docker.io/library/nginx@sha256:b96aeeb1687703c49096f4969358d44f8520b671da94848309a3ba5be5b4c632 containerd://6dbd059c60bc36551f7fa0b6c6ebfcffb1f6ff0d68384c9a89eb4784e39d2f51}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb  6 02:43:18.840: INFO: Pod "nginx-deployment-7f9675fb8b-7lrm8" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-7lrm8,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-z2qgr,SelfLink:/api/v1/namespaces/e2e-tests-deployment-z2qgr/pods/nginx-deployment-7f9675fb8b-7lrm8,UID:f4b72e08-29b8-11e9-a275-52a9a0efac9f,ResourceVersion:60596,Generation:0,CreationTimestamp:2019-02-06 02:43:16 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b f0fdbab9-29b8-11e9-a275-52a9a0efac9f 0xc4201eb3e7 0xc4201eb3e8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-dn52m {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-dn52m,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-dn52m true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.190.119.184,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc4201eb460} {node.kubernetes.io/unreachable Exists  NoExecute 0xc4201eb490}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-06 02:43:16 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-06 02:43:16 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-06 02:43:16 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-06 02:43:16 +0000 UTC  }],Message:,Reason:,HostIP:10.190.119.184,PodIP:,StartTime:2019-02-06 02:43:16 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb  6 02:43:18.840: INFO: Pod "nginx-deployment-7f9675fb8b-bcx4w" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-bcx4w,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-z2qgr,SelfLink:/api/v1/namespaces/e2e-tests-deployment-z2qgr/pods/nginx-deployment-7f9675fb8b-bcx4w,UID:f1076535-29b8-11e9-a275-52a9a0efac9f,ResourceVersion:60405,Generation:0,CreationTimestamp:2019-02-06 02:43:10 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b f0fdbab9-29b8-11e9-a275-52a9a0efac9f 0xc4201eb547 0xc4201eb548}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-dn52m {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-dn52m,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-dn52m true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.190.119.133,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc4201eb5c0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc4201eb5e0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-06 02:43:10 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-02-06 02:43:12 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-02-06 02:43:12 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-06 02:43:10 +0000 UTC  }],Message:,Reason:,HostIP:10.190.119.133,PodIP:172.30.176.33,StartTime:2019-02-06 02:43:10 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-02-06 02:43:11 +0000 UTC,} nil} {nil nil nil} true 0 docker.io/library/nginx:1.14-alpine docker.io/library/nginx@sha256:b96aeeb1687703c49096f4969358d44f8520b671da94848309a3ba5be5b4c632 containerd://0e411c6892d6dec074efe4f72184bc0001cdf517864243a3596fdd2d04745e16}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb  6 02:43:18.840: INFO: Pod "nginx-deployment-7f9675fb8b-bs497" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-bs497,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-z2qgr,SelfLink:/api/v1/namespaces/e2e-tests-deployment-z2qgr/pods/nginx-deployment-7f9675fb8b-bs497,UID:f4b97e12-29b8-11e9-a275-52a9a0efac9f,ResourceVersion:60614,Generation:0,CreationTimestamp:2019-02-06 02:43:16 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b f0fdbab9-29b8-11e9-a275-52a9a0efac9f 0xc4201eb6a7 0xc4201eb6a8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-dn52m {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-dn52m,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-dn52m true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.190.119.133,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc4201eb730} {node.kubernetes.io/unreachable Exists  NoExecute 0xc4201eb750}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-06 02:43:16 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-06 02:43:16 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-06 02:43:16 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-06 02:43:16 +0000 UTC  }],Message:,Reason:,HostIP:10.190.119.133,PodIP:,StartTime:2019-02-06 02:43:16 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb  6 02:43:18.840: INFO: Pod "nginx-deployment-7f9675fb8b-ct8nx" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-ct8nx,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-z2qgr,SelfLink:/api/v1/namespaces/e2e-tests-deployment-z2qgr/pods/nginx-deployment-7f9675fb8b-ct8nx,UID:f4b94ba1-29b8-11e9-a275-52a9a0efac9f,ResourceVersion:60623,Generation:0,CreationTimestamp:2019-02-06 02:43:16 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b f0fdbab9-29b8-11e9-a275-52a9a0efac9f 0xc4201eb827 0xc4201eb828}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-dn52m {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-dn52m,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-dn52m true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.190.119.184,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc4201eb8b0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc4201eb8d0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-06 02:43:16 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-06 02:43:16 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-06 02:43:16 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-06 02:43:16 +0000 UTC  }],Message:,Reason:,HostIP:10.190.119.184,PodIP:,StartTime:2019-02-06 02:43:16 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb  6 02:43:18.841: INFO: Pod "nginx-deployment-7f9675fb8b-fdr49" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-fdr49,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-z2qgr,SelfLink:/api/v1/namespaces/e2e-tests-deployment-z2qgr/pods/nginx-deployment-7f9675fb8b-fdr49,UID:f4b916bb-29b8-11e9-a275-52a9a0efac9f,ResourceVersion:60601,Generation:0,CreationTimestamp:2019-02-06 02:43:16 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b f0fdbab9-29b8-11e9-a275-52a9a0efac9f 0xc4201eb987 0xc4201eb988}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-dn52m {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-dn52m,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-dn52m true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.190.119.143,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc4201eba00} {node.kubernetes.io/unreachable Exists  NoExecute 0xc4201eba20}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-06 02:43:16 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-06 02:43:16 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-06 02:43:16 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-06 02:43:16 +0000 UTC  }],Message:,Reason:,HostIP:10.190.119.143,PodIP:,StartTime:2019-02-06 02:43:16 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb  6 02:43:18.841: INFO: Pod "nginx-deployment-7f9675fb8b-fwkwr" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-fwkwr,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-z2qgr,SelfLink:/api/v1/namespaces/e2e-tests-deployment-z2qgr/pods/nginx-deployment-7f9675fb8b-fwkwr,UID:f10565d2-29b8-11e9-a275-52a9a0efac9f,ResourceVersion:60383,Generation:0,CreationTimestamp:2019-02-06 02:43:10 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b f0fdbab9-29b8-11e9-a275-52a9a0efac9f 0xc4201ebb07 0xc4201ebb08}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-dn52m {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-dn52m,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-dn52m true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.190.119.184,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc4201ebba0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc4201ebbc0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-06 02:43:10 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-02-06 02:43:11 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-02-06 02:43:11 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-06 02:43:10 +0000 UTC  }],Message:,Reason:,HostIP:10.190.119.184,PodIP:172.30.242.26,StartTime:2019-02-06 02:43:10 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-02-06 02:43:11 +0000 UTC,} nil} {nil nil nil} true 0 docker.io/library/nginx:1.14-alpine docker.io/library/nginx@sha256:b96aeeb1687703c49096f4969358d44f8520b671da94848309a3ba5be5b4c632 containerd://e24f52c217a327fc72ceebefc9ed6820be5dce6967f901d2bde98f8ecdc8013d}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb  6 02:43:18.841: INFO: Pod "nginx-deployment-7f9675fb8b-h7bs2" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-h7bs2,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-z2qgr,SelfLink:/api/v1/namespaces/e2e-tests-deployment-z2qgr/pods/nginx-deployment-7f9675fb8b-h7bs2,UID:f4b72272-29b8-11e9-a275-52a9a0efac9f,ResourceVersion:60671,Generation:0,CreationTimestamp:2019-02-06 02:43:16 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b f0fdbab9-29b8-11e9-a275-52a9a0efac9f 0xc4201ebc87 0xc4201ebc88}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-dn52m {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-dn52m,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-dn52m true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.190.119.184,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc4201ebd00} {node.kubernetes.io/unreachable Exists  NoExecute 0xc4201ebd20}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-06 02:43:16 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-06 02:43:16 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-06 02:43:16 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-06 02:43:16 +0000 UTC  }],Message:,Reason:,HostIP:10.190.119.184,PodIP:,StartTime:2019-02-06 02:43:16 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb  6 02:43:18.841: INFO: Pod "nginx-deployment-7f9675fb8b-jq2qw" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-jq2qw,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-z2qgr,SelfLink:/api/v1/namespaces/e2e-tests-deployment-z2qgr/pods/nginx-deployment-7f9675fb8b-jq2qw,UID:f1075ba1-29b8-11e9-a275-52a9a0efac9f,ResourceVersion:60390,Generation:0,CreationTimestamp:2019-02-06 02:43:10 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b f0fdbab9-29b8-11e9-a275-52a9a0efac9f 0xc4201ebdd7 0xc4201ebdd8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-dn52m {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-dn52m,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-dn52m true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.190.119.143,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc4201ebe50} {node.kubernetes.io/unreachable Exists  NoExecute 0xc4201ebe70}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-06 02:43:10 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-02-06 02:43:11 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-02-06 02:43:11 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-06 02:43:10 +0000 UTC  }],Message:,Reason:,HostIP:10.190.119.143,PodIP:172.30.134.227,StartTime:2019-02-06 02:43:10 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-02-06 02:43:11 +0000 UTC,} nil} {nil nil nil} true 0 docker.io/library/nginx:1.14-alpine docker.io/library/nginx@sha256:b96aeeb1687703c49096f4969358d44f8520b671da94848309a3ba5be5b4c632 containerd://f0f9d691be6fe3b0ca593c6ff6d2345ed8fb838d151a11263f278a8916367618}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb  6 02:43:18.842: INFO: Pod "nginx-deployment-7f9675fb8b-lsf8s" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-lsf8s,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-z2qgr,SelfLink:/api/v1/namespaces/e2e-tests-deployment-z2qgr/pods/nginx-deployment-7f9675fb8b-lsf8s,UID:f1056a2c-29b8-11e9-a275-52a9a0efac9f,ResourceVersion:60386,Generation:0,CreationTimestamp:2019-02-06 02:43:10 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b f0fdbab9-29b8-11e9-a275-52a9a0efac9f 0xc4201ebf37 0xc4201ebf38}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-dn52m {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-dn52m,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-dn52m true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.190.119.184,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc4201ebfb0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc4201ebfd0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-06 02:43:10 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-02-06 02:43:11 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-02-06 02:43:11 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-06 02:43:10 +0000 UTC  }],Message:,Reason:,HostIP:10.190.119.184,PodIP:172.30.242.27,StartTime:2019-02-06 02:43:10 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-02-06 02:43:11 +0000 UTC,} nil} {nil nil nil} true 0 docker.io/library/nginx:1.14-alpine docker.io/library/nginx@sha256:b96aeeb1687703c49096f4969358d44f8520b671da94848309a3ba5be5b4c632 containerd://082e8294e006179cb9d3e62bed8dafde2f8e6a8e753ae4359a9ba0a8a128db57}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb  6 02:43:18.842: INFO: Pod "nginx-deployment-7f9675fb8b-lzdtt" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-lzdtt,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-z2qgr,SelfLink:/api/v1/namespaces/e2e-tests-deployment-z2qgr/pods/nginx-deployment-7f9675fb8b-lzdtt,UID:f4b9436f-29b8-11e9-a275-52a9a0efac9f,ResourceVersion:60604,Generation:0,CreationTimestamp:2019-02-06 02:43:16 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b f0fdbab9-29b8-11e9-a275-52a9a0efac9f 0xc421bc80a7 0xc421bc80a8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-dn52m {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-dn52m,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-dn52m true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.190.119.184,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc421bc8120} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421bc8140}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-06 02:43:16 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-06 02:43:16 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-06 02:43:16 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-06 02:43:16 +0000 UTC  }],Message:,Reason:,HostIP:10.190.119.184,PodIP:,StartTime:2019-02-06 02:43:16 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb  6 02:43:18.842: INFO: Pod "nginx-deployment-7f9675fb8b-mrjkm" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-mrjkm,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-z2qgr,SelfLink:/api/v1/namespaces/e2e-tests-deployment-z2qgr/pods/nginx-deployment-7f9675fb8b-mrjkm,UID:f4b3af65-29b8-11e9-a275-52a9a0efac9f,ResourceVersion:60548,Generation:0,CreationTimestamp:2019-02-06 02:43:16 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b f0fdbab9-29b8-11e9-a275-52a9a0efac9f 0xc421bc84e7 0xc421bc84e8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-dn52m {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-dn52m,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-dn52m true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.190.119.133,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc421bc8590} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421bc85b0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-06 02:43:16 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-06 02:43:16 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-06 02:43:16 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-06 02:43:16 +0000 UTC  }],Message:,Reason:,HostIP:10.190.119.133,PodIP:,StartTime:2019-02-06 02:43:16 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb  6 02:43:18.842: INFO: Pod "nginx-deployment-7f9675fb8b-q4qhc" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-q4qhc,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-z2qgr,SelfLink:/api/v1/namespaces/e2e-tests-deployment-z2qgr/pods/nginx-deployment-7f9675fb8b-q4qhc,UID:f4b52e92-29b8-11e9-a275-52a9a0efac9f,ResourceVersion:60585,Generation:0,CreationTimestamp:2019-02-06 02:43:16 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b f0fdbab9-29b8-11e9-a275-52a9a0efac9f 0xc421bc87f7 0xc421bc87f8}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-dn52m {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-dn52m,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-dn52m true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.190.119.184,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc421bc8870} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421bc8890}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-06 02:43:16 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-06 02:43:16 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-06 02:43:16 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-06 02:43:16 +0000 UTC  }],Message:,Reason:,HostIP:10.190.119.184,PodIP:,StartTime:2019-02-06 02:43:16 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb  6 02:43:18.842: INFO: Pod "nginx-deployment-7f9675fb8b-qm27t" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-qm27t,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-z2qgr,SelfLink:/api/v1/namespaces/e2e-tests-deployment-z2qgr/pods/nginx-deployment-7f9675fb8b-qm27t,UID:f1019308-29b8-11e9-a275-52a9a0efac9f,ResourceVersion:60379,Generation:0,CreationTimestamp:2019-02-06 02:43:10 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b f0fdbab9-29b8-11e9-a275-52a9a0efac9f 0xc421bc8947 0xc421bc8948}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-dn52m {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-dn52m,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-dn52m true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.190.119.184,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc421bc8a80} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421bc8aa0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-06 02:43:10 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-02-06 02:43:11 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-02-06 02:43:11 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-06 02:43:10 +0000 UTC  }],Message:,Reason:,HostIP:10.190.119.184,PodIP:172.30.242.25,StartTime:2019-02-06 02:43:10 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-02-06 02:43:11 +0000 UTC,} nil} {nil nil nil} true 0 docker.io/library/nginx:1.14-alpine docker.io/library/nginx@sha256:b96aeeb1687703c49096f4969358d44f8520b671da94848309a3ba5be5b4c632 containerd://d5e1e4eedd0011e58327ff1c88823f8ebbd366e9fd0fe440edd14f97ee10827a}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb  6 02:43:18.843: INFO: Pod "nginx-deployment-7f9675fb8b-r6fqj" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-r6fqj,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-z2qgr,SelfLink:/api/v1/namespaces/e2e-tests-deployment-z2qgr/pods/nginx-deployment-7f9675fb8b-r6fqj,UID:f4b73513-29b8-11e9-a275-52a9a0efac9f,ResourceVersion:60597,Generation:0,CreationTimestamp:2019-02-06 02:43:16 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b f0fdbab9-29b8-11e9-a275-52a9a0efac9f 0xc421bc8c87 0xc421bc8c88}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-dn52m {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-dn52m,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-dn52m true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.190.119.133,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc421bc8f90} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421bc8fb0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-06 02:43:16 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-02-06 02:43:16 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-02-06 02:43:16 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-06 02:43:16 +0000 UTC  }],Message:,Reason:,HostIP:10.190.119.133,PodIP:,StartTime:2019-02-06 02:43:16 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Feb  6 02:43:18.843: INFO: Pod "nginx-deployment-7f9675fb8b-xqvft" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7f9675fb8b-xqvft,GenerateName:nginx-deployment-7f9675fb8b-,Namespace:e2e-tests-deployment-z2qgr,SelfLink:/api/v1/namespaces/e2e-tests-deployment-z2qgr/pods/nginx-deployment-7f9675fb8b-xqvft,UID:f4b53393-29b8-11e9-a275-52a9a0efac9f,ResourceVersion:60767,Generation:0,CreationTimestamp:2019-02-06 02:43:16 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7f9675fb8b,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7f9675fb8b f0fdbab9-29b8-11e9-a275-52a9a0efac9f 0xc421bc9167 0xc421bc9168}],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[{default-token-dn52m {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-dn52m,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-dn52m true /var/run/secrets/kubernetes.io/serviceaccount  <nil>}] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.190.119.143,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc421bc9310} {node.kubernetes.io/unreachable Exists  NoExecute 0xc421bc9340}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-02-06 02:43:16 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-02-06 02:43:18 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-02-06 02:43:18 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-02-06 02:43:16 +0000 UTC  }],Message:,Reason:,HostIP:10.190.119.143,PodIP:172.30.134.230,StartTime:2019-02-06 02:43:16 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-02-06 02:43:18 +0000 UTC,} nil} {nil nil nil} true 0 docker.io/library/nginx:1.14-alpine docker.io/library/nginx@sha256:b96aeeb1687703c49096f4969358d44f8520b671da94848309a3ba5be5b4c632 containerd://38716e4f5698e8583ca29e817d591aee06ad3140feeab2cc7c2d7325dd184ee0}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  6 02:43:18.843: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-deployment-z2qgr" for this suite.
Feb  6 02:43:28.916: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 02:43:29.023: INFO: namespace: e2e-tests-deployment-z2qgr, resource: bindings, ignored listing per whitelist
Feb  6 02:43:29.358: INFO: namespace e2e-tests-deployment-z2qgr deletion completed in 10.466845399s

• [SLOW TEST:19.151 seconds]
[sig-apps] Deployment
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[k8s.io] KubeletManagedEtcHosts 
  should test kubelet managed /etc/hosts file [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  6 02:43:29.358: INFO: >>> kubeConfig: /tmp/kubeconfig-131423863
STEP: Building a namespace api object, basename e2e-kubelet-etc-hosts
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-e2e-kubelet-etc-hosts-ng2qp
STEP: Waiting for a default service account to be provisioned in namespace
[It] should test kubelet managed /etc/hosts file [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Setting up the test
STEP: Creating hostNetwork=false pod
STEP: Creating hostNetwork=true pod
STEP: Running the test
STEP: Verifying /etc/hosts of container is kubelet-managed for pod with hostNetwork=false
Feb  6 02:43:33.794: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-ng2qp PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb  6 02:43:33.794: INFO: >>> kubeConfig: /tmp/kubeconfig-131423863
Feb  6 02:43:34.008: INFO: Exec stderr: ""
Feb  6 02:43:34.008: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-ng2qp PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb  6 02:43:34.008: INFO: >>> kubeConfig: /tmp/kubeconfig-131423863
Feb  6 02:43:34.267: INFO: Exec stderr: ""
Feb  6 02:43:34.267: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-ng2qp PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb  6 02:43:34.267: INFO: >>> kubeConfig: /tmp/kubeconfig-131423863
Feb  6 02:43:34.699: INFO: Exec stderr: ""
Feb  6 02:43:34.699: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-ng2qp PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb  6 02:43:34.699: INFO: >>> kubeConfig: /tmp/kubeconfig-131423863
Feb  6 02:43:34.912: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts of container is not kubelet-managed since container specifies /etc/hosts mount
Feb  6 02:43:34.912: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-ng2qp PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb  6 02:43:34.912: INFO: >>> kubeConfig: /tmp/kubeconfig-131423863
Feb  6 02:43:35.217: INFO: Exec stderr: ""
Feb  6 02:43:35.218: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-ng2qp PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb  6 02:43:35.218: INFO: >>> kubeConfig: /tmp/kubeconfig-131423863
Feb  6 02:43:35.407: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts content of container is not kubelet-managed for pod with hostNetwork=true
Feb  6 02:43:35.407: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-ng2qp PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb  6 02:43:35.407: INFO: >>> kubeConfig: /tmp/kubeconfig-131423863
Feb  6 02:43:35.674: INFO: Exec stderr: ""
Feb  6 02:43:35.674: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-ng2qp PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb  6 02:43:35.674: INFO: >>> kubeConfig: /tmp/kubeconfig-131423863
Feb  6 02:43:35.884: INFO: Exec stderr: ""
Feb  6 02:43:35.884: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-tests-e2e-kubelet-etc-hosts-ng2qp PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb  6 02:43:35.884: INFO: >>> kubeConfig: /tmp/kubeconfig-131423863
Feb  6 02:43:36.093: INFO: Exec stderr: ""
Feb  6 02:43:36.093: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-tests-e2e-kubelet-etc-hosts-ng2qp PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb  6 02:43:36.093: INFO: >>> kubeConfig: /tmp/kubeconfig-131423863
Feb  6 02:43:36.294: INFO: Exec stderr: ""
[AfterEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  6 02:43:36.294: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-e2e-kubelet-etc-hosts-ng2qp" for this suite.
Feb  6 02:44:24.334: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 02:44:25.024: INFO: namespace: e2e-tests-e2e-kubelet-etc-hosts-ng2qp, resource: bindings, ignored listing per whitelist
Feb  6 02:44:25.278: INFO: namespace e2e-tests-e2e-kubelet-etc-hosts-ng2qp deletion completed in 48.97079893s

• [SLOW TEST:55.919 seconds]
[k8s.io] KubeletManagedEtcHosts
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should test kubelet managed /etc/hosts file [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  6 02:44:25.281: INFO: >>> kubeConfig: /tmp/kubeconfig-131423863
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-pfwn9
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0777 on tmpfs
Feb  6 02:44:25.596: INFO: Waiting up to 5m0s for pod "pod-1db80c5b-29b9-11e9-9603-eaa511fa0b6c" in namespace "e2e-tests-emptydir-pfwn9" to be "success or failure"
Feb  6 02:44:25.606: INFO: Pod "pod-1db80c5b-29b9-11e9-9603-eaa511fa0b6c": Phase="Pending", Reason="", readiness=false. Elapsed: 9.95545ms
Feb  6 02:44:27.621: INFO: Pod "pod-1db80c5b-29b9-11e9-9603-eaa511fa0b6c": Phase="Running", Reason="", readiness=true. Elapsed: 2.024496757s
Feb  6 02:44:29.630: INFO: Pod "pod-1db80c5b-29b9-11e9-9603-eaa511fa0b6c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.033179349s
STEP: Saw pod success
Feb  6 02:44:29.630: INFO: Pod "pod-1db80c5b-29b9-11e9-9603-eaa511fa0b6c" satisfied condition "success or failure"
Feb  6 02:44:29.637: INFO: Trying to get logs from node 10.190.119.143 pod pod-1db80c5b-29b9-11e9-9603-eaa511fa0b6c container test-container: <nil>
STEP: delete the pod
Feb  6 02:44:29.712: INFO: Waiting for pod pod-1db80c5b-29b9-11e9-9603-eaa511fa0b6c to disappear
Feb  6 02:44:29.720: INFO: Pod pod-1db80c5b-29b9-11e9-9603-eaa511fa0b6c no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  6 02:44:29.720: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-pfwn9" for this suite.
Feb  6 02:44:35.763: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 02:44:35.947: INFO: namespace: e2e-tests-emptydir-pfwn9, resource: bindings, ignored listing per whitelist
Feb  6 02:44:36.063: INFO: namespace e2e-tests-emptydir-pfwn9 deletion completed in 6.328078443s

• [SLOW TEST:10.781 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0777,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Proxy server 
  should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  6 02:44:36.063: INFO: >>> kubeConfig: /tmp/kubeconfig-131423863
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-4zw9t
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Starting the proxy
Feb  6 02:44:36.356: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-131423863 proxy --unix-socket=/tmp/kubectl-proxy-unix498244970/test'
STEP: retrieving proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  6 02:44:36.423: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-4zw9t" for this suite.
Feb  6 02:44:42.519: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 02:44:42.691: INFO: namespace: e2e-tests-kubectl-4zw9t, resource: bindings, ignored listing per whitelist
Feb  6 02:44:42.911: INFO: namespace e2e-tests-kubectl-4zw9t deletion completed in 6.475554066s

• [SLOW TEST:6.849 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Proxy server
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should support --unix-socket=/path  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Downward API volume 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  6 02:44:42.912: INFO: >>> kubeConfig: /tmp/kubeconfig-131423863
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-bsg9k
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating the pod
Feb  6 02:44:46.005: INFO: Successfully updated pod "annotationupdate285482af-29b9-11e9-9603-eaa511fa0b6c"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  6 02:44:48.348: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-bsg9k" for this suite.
Feb  6 02:45:12.388: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 02:45:12.540: INFO: namespace: e2e-tests-downward-api-bsg9k, resource: bindings, ignored listing per whitelist
Feb  6 02:45:12.772: INFO: namespace e2e-tests-downward-api-bsg9k deletion completed in 24.411376784s

• [SLOW TEST:29.860 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  6 02:45:12.772: INFO: >>> kubeConfig: /tmp/kubeconfig-131423863
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-container-lifecycle-hook-msd4d
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Feb  6 02:45:19.227: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Feb  6 02:45:19.239: INFO: Pod pod-with-poststart-exec-hook still exists
Feb  6 02:45:21.239: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Feb  6 02:45:21.248: INFO: Pod pod-with-poststart-exec-hook still exists
Feb  6 02:45:23.239: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Feb  6 02:45:23.250: INFO: Pod pod-with-poststart-exec-hook still exists
Feb  6 02:45:25.239: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Feb  6 02:45:25.249: INFO: Pod pod-with-poststart-exec-hook still exists
Feb  6 02:45:27.239: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Feb  6 02:45:27.261: INFO: Pod pod-with-poststart-exec-hook still exists
Feb  6 02:45:29.239: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Feb  6 02:45:29.247: INFO: Pod pod-with-poststart-exec-hook still exists
Feb  6 02:45:31.239: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Feb  6 02:45:31.253: INFO: Pod pod-with-poststart-exec-hook still exists
Feb  6 02:45:33.239: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Feb  6 02:45:33.248: INFO: Pod pod-with-poststart-exec-hook still exists
Feb  6 02:45:35.239: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Feb  6 02:45:35.248: INFO: Pod pod-with-poststart-exec-hook still exists
Feb  6 02:45:37.239: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Feb  6 02:45:37.253: INFO: Pod pod-with-poststart-exec-hook still exists
Feb  6 02:45:39.239: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Feb  6 02:45:39.261: INFO: Pod pod-with-poststart-exec-hook still exists
Feb  6 02:45:41.239: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Feb  6 02:45:41.255: INFO: Pod pod-with-poststart-exec-hook still exists
Feb  6 02:45:43.239: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Feb  6 02:45:43.248: INFO: Pod pod-with-poststart-exec-hook still exists
Feb  6 02:45:45.239: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Feb  6 02:45:45.248: INFO: Pod pod-with-poststart-exec-hook still exists
Feb  6 02:45:47.239: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Feb  6 02:45:47.247: INFO: Pod pod-with-poststart-exec-hook still exists
Feb  6 02:45:49.239: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Feb  6 02:45:49.248: INFO: Pod pod-with-poststart-exec-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  6 02:45:49.248: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-lifecycle-hook-msd4d" for this suite.
Feb  6 02:46:13.334: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 02:46:13.570: INFO: namespace: e2e-tests-container-lifecycle-hook-msd4d, resource: bindings, ignored listing per whitelist
Feb  6 02:46:13.796: INFO: namespace e2e-tests-container-lifecycle-hook-msd4d deletion completed in 24.536923959s

• [SLOW TEST:61.024 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when create a pod with lifecycle hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute poststart exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl expose 
  should create services for rc  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  6 02:46:13.796: INFO: >>> kubeConfig: /tmp/kubeconfig-131423863
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-nqtfv
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should create services for rc  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating Redis RC
Feb  6 02:46:14.594: INFO: namespace e2e-tests-kubectl-nqtfv
Feb  6 02:46:14.594: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-131423863 create -f - --namespace=e2e-tests-kubectl-nqtfv'
Feb  6 02:46:14.979: INFO: stderr: ""
Feb  6 02:46:14.979: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
Feb  6 02:46:15.988: INFO: Selector matched 1 pods for map[app:redis]
Feb  6 02:46:15.988: INFO: Found 1 / 1
Feb  6 02:46:15.988: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Feb  6 02:46:15.999: INFO: Selector matched 1 pods for map[app:redis]
Feb  6 02:46:15.999: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Feb  6 02:46:15.999: INFO: wait on redis-master startup in e2e-tests-kubectl-nqtfv 
Feb  6 02:46:15.999: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-131423863 logs redis-master-47kck redis-master --namespace=e2e-tests-kubectl-nqtfv'
Feb  6 02:46:16.157: INFO: stderr: ""
Feb  6 02:46:16.157: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 06 Feb 02:46:15.901 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 06 Feb 02:46:15.901 # Server started, Redis version 3.2.12\n1:M 06 Feb 02:46:15.901 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 06 Feb 02:46:15.901 * The server is now ready to accept connections on port 6379\n"
STEP: exposing RC
Feb  6 02:46:16.157: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-131423863 expose rc redis-master --name=rm2 --port=1234 --target-port=6379 --namespace=e2e-tests-kubectl-nqtfv'
Feb  6 02:46:16.319: INFO: stderr: ""
Feb  6 02:46:16.319: INFO: stdout: "service/rm2 exposed\n"
Feb  6 02:46:16.391: INFO: Service rm2 in namespace e2e-tests-kubectl-nqtfv found.
STEP: exposing service
Feb  6 02:46:18.411: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-131423863 expose service rm2 --name=rm3 --port=2345 --target-port=6379 --namespace=e2e-tests-kubectl-nqtfv'
Feb  6 02:46:18.632: INFO: stderr: ""
Feb  6 02:46:18.632: INFO: stdout: "service/rm3 exposed\n"
Feb  6 02:46:18.643: INFO: Service rm3 in namespace e2e-tests-kubectl-nqtfv found.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  6 02:46:20.663: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-nqtfv" for this suite.
Feb  6 02:46:44.704: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 02:46:45.063: INFO: namespace: e2e-tests-kubectl-nqtfv, resource: bindings, ignored listing per whitelist
Feb  6 02:46:45.195: INFO: namespace e2e-tests-kubectl-nqtfv deletion completed in 24.516970201s

• [SLOW TEST:31.398 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl expose
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create services for rc  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  6 02:46:45.195: INFO: >>> kubeConfig: /tmp/kubeconfig-131423863
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-jskbn
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0644 on tmpfs
Feb  6 02:46:45.739: INFO: Waiting up to 5m0s for pod "pod-71403775-29b9-11e9-9603-eaa511fa0b6c" in namespace "e2e-tests-emptydir-jskbn" to be "success or failure"
Feb  6 02:46:45.746: INFO: Pod "pod-71403775-29b9-11e9-9603-eaa511fa0b6c": Phase="Pending", Reason="", readiness=false. Elapsed: 7.425465ms
Feb  6 02:46:48.353: INFO: Pod "pod-71403775-29b9-11e9-9603-eaa511fa0b6c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.613878279s
STEP: Saw pod success
Feb  6 02:46:48.353: INFO: Pod "pod-71403775-29b9-11e9-9603-eaa511fa0b6c" satisfied condition "success or failure"
Feb  6 02:46:48.362: INFO: Trying to get logs from node 10.190.119.184 pod pod-71403775-29b9-11e9-9603-eaa511fa0b6c container test-container: <nil>
STEP: delete the pod
Feb  6 02:46:48.424: INFO: Waiting for pod pod-71403775-29b9-11e9-9603-eaa511fa0b6c to disappear
Feb  6 02:46:48.432: INFO: Pod pod-71403775-29b9-11e9-9603-eaa511fa0b6c no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  6 02:46:48.432: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-jskbn" for this suite.
Feb  6 02:46:54.470: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 02:46:54.757: INFO: namespace: e2e-tests-emptydir-jskbn, resource: bindings, ignored listing per whitelist
Feb  6 02:46:54.784: INFO: namespace e2e-tests-emptydir-jskbn deletion completed in 6.34030251s

• [SLOW TEST:9.589 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  6 02:46:54.784: INFO: >>> kubeConfig: /tmp/kubeconfig-131423863
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-container-lifecycle-hook-4rvvm
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Feb  6 02:46:59.335: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Feb  6 02:46:59.344: INFO: Pod pod-with-prestop-exec-hook still exists
Feb  6 02:47:01.344: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Feb  6 02:47:01.353: INFO: Pod pod-with-prestop-exec-hook still exists
Feb  6 02:47:03.344: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Feb  6 02:47:03.353: INFO: Pod pod-with-prestop-exec-hook still exists
Feb  6 02:47:05.344: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Feb  6 02:47:05.424: INFO: Pod pod-with-prestop-exec-hook still exists
Feb  6 02:47:07.344: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Feb  6 02:47:07.353: INFO: Pod pod-with-prestop-exec-hook still exists
Feb  6 02:47:09.344: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Feb  6 02:47:09.356: INFO: Pod pod-with-prestop-exec-hook still exists
Feb  6 02:47:11.344: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Feb  6 02:47:11.353: INFO: Pod pod-with-prestop-exec-hook still exists
Feb  6 02:47:13.344: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Feb  6 02:47:13.356: INFO: Pod pod-with-prestop-exec-hook still exists
Feb  6 02:47:15.344: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Feb  6 02:47:15.353: INFO: Pod pod-with-prestop-exec-hook still exists
Feb  6 02:47:17.344: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Feb  6 02:47:17.372: INFO: Pod pod-with-prestop-exec-hook still exists
Feb  6 02:47:19.344: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Feb  6 02:47:19.353: INFO: Pod pod-with-prestop-exec-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  6 02:47:19.380: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-lifecycle-hook-4rvvm" for this suite.
Feb  6 02:47:43.420: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 02:47:43.518: INFO: namespace: e2e-tests-container-lifecycle-hook-4rvvm, resource: bindings, ignored listing per whitelist
Feb  6 02:47:43.893: INFO: namespace e2e-tests-container-lifecycle-hook-4rvvm deletion completed in 24.500493043s

• [SLOW TEST:49.109 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when create a pod with lifecycle hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute prestop exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  6 02:47:43.893: INFO: >>> kubeConfig: /tmp/kubeconfig-131423863
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-xn5tg
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb  6 02:47:44.305: INFO: Waiting up to 5m0s for pod "downwardapi-volume-9427f8d5-29b9-11e9-9603-eaa511fa0b6c" in namespace "e2e-tests-downward-api-xn5tg" to be "success or failure"
Feb  6 02:47:44.317: INFO: Pod "downwardapi-volume-9427f8d5-29b9-11e9-9603-eaa511fa0b6c": Phase="Pending", Reason="", readiness=false. Elapsed: 11.10812ms
Feb  6 02:47:46.326: INFO: Pod "downwardapi-volume-9427f8d5-29b9-11e9-9603-eaa511fa0b6c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.020164186s
STEP: Saw pod success
Feb  6 02:47:46.326: INFO: Pod "downwardapi-volume-9427f8d5-29b9-11e9-9603-eaa511fa0b6c" satisfied condition "success or failure"
Feb  6 02:47:46.333: INFO: Trying to get logs from node 10.190.119.184 pod downwardapi-volume-9427f8d5-29b9-11e9-9603-eaa511fa0b6c container client-container: <nil>
STEP: delete the pod
Feb  6 02:47:46.381: INFO: Waiting for pod downwardapi-volume-9427f8d5-29b9-11e9-9603-eaa511fa0b6c to disappear
Feb  6 02:47:46.388: INFO: Pod downwardapi-volume-9427f8d5-29b9-11e9-9603-eaa511fa0b6c no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  6 02:47:46.388: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-xn5tg" for this suite.
Feb  6 02:47:52.519: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 02:47:52.600: INFO: namespace: e2e-tests-downward-api-xn5tg, resource: bindings, ignored listing per whitelist
Feb  6 02:47:52.977: INFO: namespace e2e-tests-downward-api-xn5tg deletion completed in 6.484878362s

• [SLOW TEST:9.084 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] Projected 
  should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  6 02:47:52.978: INFO: >>> kubeConfig: /tmp/kubeconfig-131423863
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-j9t8s
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb  6 02:47:53.531: INFO: Waiting up to 5m0s for pod "downwardapi-volume-99a8481d-29b9-11e9-9603-eaa511fa0b6c" in namespace "e2e-tests-projected-j9t8s" to be "success or failure"
Feb  6 02:47:53.541: INFO: Pod "downwardapi-volume-99a8481d-29b9-11e9-9603-eaa511fa0b6c": Phase="Pending", Reason="", readiness=false. Elapsed: 10.1411ms
Feb  6 02:47:55.869: INFO: Pod "downwardapi-volume-99a8481d-29b9-11e9-9603-eaa511fa0b6c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.338488293s
STEP: Saw pod success
Feb  6 02:47:55.869: INFO: Pod "downwardapi-volume-99a8481d-29b9-11e9-9603-eaa511fa0b6c" satisfied condition "success or failure"
Feb  6 02:47:55.887: INFO: Trying to get logs from node 10.190.119.133 pod downwardapi-volume-99a8481d-29b9-11e9-9603-eaa511fa0b6c container client-container: <nil>
STEP: delete the pod
Feb  6 02:47:55.940: INFO: Waiting for pod downwardapi-volume-99a8481d-29b9-11e9-9603-eaa511fa0b6c to disappear
Feb  6 02:47:55.951: INFO: Pod downwardapi-volume-99a8481d-29b9-11e9-9603-eaa511fa0b6c no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  6 02:47:55.951: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-j9t8s" for this suite.
Feb  6 02:48:02.012: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 02:48:02.857: INFO: namespace: e2e-tests-projected-j9t8s, resource: bindings, ignored listing per whitelist
Feb  6 02:48:02.857: INFO: namespace e2e-tests-projected-j9t8s deletion completed in 6.891238571s

• [SLOW TEST:9.879 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Guestbook application 
  should create and stop a working application  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  6 02:48:02.858: INFO: >>> kubeConfig: /tmp/kubeconfig-131423863
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-25px8
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should create and stop a working application  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating all guestbook components
Feb  6 02:48:03.160: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-slave
  labels:
    app: redis
    role: slave
    tier: backend
spec:
  ports:
  - port: 6379
  selector:
    app: redis
    role: slave
    tier: backend

Feb  6 02:48:03.160: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-131423863 create -f - --namespace=e2e-tests-kubectl-25px8'
Feb  6 02:48:03.407: INFO: stderr: ""
Feb  6 02:48:03.407: INFO: stdout: "service/redis-slave created\n"
Feb  6 02:48:03.407: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-master
  labels:
    app: redis
    role: master
    tier: backend
spec:
  ports:
  - port: 6379
    targetPort: 6379
  selector:
    app: redis
    role: master
    tier: backend

Feb  6 02:48:03.407: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-131423863 create -f - --namespace=e2e-tests-kubectl-25px8'
Feb  6 02:48:03.656: INFO: stderr: ""
Feb  6 02:48:03.656: INFO: stdout: "service/redis-master created\n"
Feb  6 02:48:03.656: INFO: apiVersion: v1
kind: Service
metadata:
  name: frontend
  labels:
    app: guestbook
    tier: frontend
spec:
  # if your cluster supports it, uncomment the following to automatically create
  # an external load-balanced IP for the frontend service.
  # type: LoadBalancer
  ports:
  - port: 80
  selector:
    app: guestbook
    tier: frontend

Feb  6 02:48:03.656: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-131423863 create -f - --namespace=e2e-tests-kubectl-25px8'
Feb  6 02:48:03.897: INFO: stderr: ""
Feb  6 02:48:03.897: INFO: stdout: "service/frontend created\n"
Feb  6 02:48:03.897: INFO: apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: frontend
spec:
  replicas: 3
  template:
    metadata:
      labels:
        app: guestbook
        tier: frontend
    spec:
      containers:
      - name: php-redis
        image: gcr.io/google-samples/gb-frontend:v6
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access environment variables to find service host
          # info, comment out the 'value: dns' line above, and uncomment the
          # line below:
          # value: env
        ports:
        - containerPort: 80

Feb  6 02:48:03.897: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-131423863 create -f - --namespace=e2e-tests-kubectl-25px8'
Feb  6 02:48:04.183: INFO: stderr: ""
Feb  6 02:48:04.183: INFO: stdout: "deployment.extensions/frontend created\n"
Feb  6 02:48:04.183: INFO: apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: redis-master
spec:
  replicas: 1
  template:
    metadata:
      labels:
        app: redis
        role: master
        tier: backend
    spec:
      containers:
      - name: master
        image: gcr.io/kubernetes-e2e-test-images/redis:1.0
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        ports:
        - containerPort: 6379

Feb  6 02:48:04.183: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-131423863 create -f - --namespace=e2e-tests-kubectl-25px8'
Feb  6 02:48:04.524: INFO: stderr: ""
Feb  6 02:48:04.524: INFO: stdout: "deployment.extensions/redis-master created\n"
Feb  6 02:48:04.524: INFO: apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: redis-slave
spec:
  replicas: 2
  template:
    metadata:
      labels:
        app: redis
        role: slave
        tier: backend
    spec:
      containers:
      - name: slave
        image: gcr.io/google-samples/gb-redisslave:v3
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access an environment variable to find the master
          # service's host, comment out the 'value: dns' line above, and
          # uncomment the line below:
          # value: env
        ports:
        - containerPort: 6379

Feb  6 02:48:04.524: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-131423863 create -f - --namespace=e2e-tests-kubectl-25px8'
Feb  6 02:48:04.807: INFO: stderr: ""
Feb  6 02:48:04.807: INFO: stdout: "deployment.extensions/redis-slave created\n"
STEP: validating guestbook app
Feb  6 02:48:04.807: INFO: Waiting for all frontend pods to be Running.
Feb  6 02:48:09.858: INFO: Waiting for frontend to serve content.
Feb  6 02:48:09.896: INFO: Trying to add a new entry to the guestbook.
Feb  6 02:48:09.920: INFO: Verifying that added entry can be retrieved.
Feb  6 02:48:09.943: INFO: Failed to get response from guestbook. err: <nil>, response: {"data": ""}
Feb  6 02:48:15.004: INFO: Failed to get response from guestbook. err: <nil>, response: {"data": ""}
Feb  6 02:48:20.035: INFO: Failed to get response from guestbook. err: <nil>, response: {"data": ""}
STEP: using delete to clean up resources
Feb  6 02:48:25.081: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-131423863 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-25px8'
Feb  6 02:48:25.254: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Feb  6 02:48:25.254: INFO: stdout: "service \"redis-slave\" force deleted\n"
STEP: using delete to clean up resources
Feb  6 02:48:25.255: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-131423863 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-25px8'
Feb  6 02:48:25.439: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Feb  6 02:48:25.439: INFO: stdout: "service \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
Feb  6 02:48:25.439: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-131423863 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-25px8'
Feb  6 02:48:25.629: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Feb  6 02:48:25.629: INFO: stdout: "service \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Feb  6 02:48:25.629: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-131423863 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-25px8'
Feb  6 02:48:25.800: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Feb  6 02:48:25.800: INFO: stdout: "deployment.extensions \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Feb  6 02:48:25.800: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-131423863 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-25px8'
Feb  6 02:48:25.995: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Feb  6 02:48:25.995: INFO: stdout: "deployment.extensions \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
Feb  6 02:48:25.995: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-131423863 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-25px8'
Feb  6 02:48:26.324: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Feb  6 02:48:26.324: INFO: stdout: "deployment.extensions \"redis-slave\" force deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  6 02:48:26.324: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-25px8" for this suite.
Feb  6 02:49:08.374: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 02:49:08.556: INFO: namespace: e2e-tests-kubectl-25px8, resource: bindings, ignored listing per whitelist
Feb  6 02:49:08.790: INFO: namespace e2e-tests-kubectl-25px8 deletion completed in 42.451205588s

• [SLOW TEST:65.933 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Guestbook application
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create and stop a working application  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[k8s.io] Pods 
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  6 02:49:08.792: INFO: >>> kubeConfig: /tmp/kubeconfig-131423863
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-pods-vwfbq
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Feb  6 02:49:11.777: INFO: Successfully updated pod "pod-update-activedeadlineseconds-c6b58ccd-29b9-11e9-9603-eaa511fa0b6c"
Feb  6 02:49:11.777: INFO: Waiting up to 5m0s for pod "pod-update-activedeadlineseconds-c6b58ccd-29b9-11e9-9603-eaa511fa0b6c" in namespace "e2e-tests-pods-vwfbq" to be "terminated due to deadline exceeded"
Feb  6 02:49:11.786: INFO: Pod "pod-update-activedeadlineseconds-c6b58ccd-29b9-11e9-9603-eaa511fa0b6c": Phase="Running", Reason="", readiness=true. Elapsed: 8.82272ms
Feb  6 02:49:13.794: INFO: Pod "pod-update-activedeadlineseconds-c6b58ccd-29b9-11e9-9603-eaa511fa0b6c": Phase="Running", Reason="", readiness=true. Elapsed: 2.01756428s
Feb  6 02:49:15.803: INFO: Pod "pod-update-activedeadlineseconds-c6b58ccd-29b9-11e9-9603-eaa511fa0b6c": Phase="Failed", Reason="DeadlineExceeded", readiness=false. Elapsed: 4.026557428s
Feb  6 02:49:15.803: INFO: Pod "pod-update-activedeadlineseconds-c6b58ccd-29b9-11e9-9603-eaa511fa0b6c" satisfied condition "terminated due to deadline exceeded"
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  6 02:49:15.803: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-vwfbq" for this suite.
Feb  6 02:49:21.860: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 02:49:22.091: INFO: namespace: e2e-tests-pods-vwfbq, resource: bindings, ignored listing per whitelist
Feb  6 02:49:22.172: INFO: namespace e2e-tests-pods-vwfbq deletion completed in 6.356533958s

• [SLOW TEST:13.380 seconds]
[k8s.io] Pods
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with downward pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  6 02:49:22.173: INFO: >>> kubeConfig: /tmp/kubeconfig-131423863
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-subpath-fl7ng
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with downward pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-downwardapi-7hsf
STEP: Creating a pod to test atomic-volume-subpath
Feb  6 02:49:23.235: INFO: Waiting up to 5m0s for pod "pod-subpath-test-downwardapi-7hsf" in namespace "e2e-tests-subpath-fl7ng" to be "success or failure"
Feb  6 02:49:23.245: INFO: Pod "pod-subpath-test-downwardapi-7hsf": Phase="Pending", Reason="", readiness=false. Elapsed: 10.372877ms
Feb  6 02:49:25.257: INFO: Pod "pod-subpath-test-downwardapi-7hsf": Phase="Pending", Reason="", readiness=false. Elapsed: 2.022834349s
Feb  6 02:49:27.265: INFO: Pod "pod-subpath-test-downwardapi-7hsf": Phase="Running", Reason="", readiness=false. Elapsed: 4.030928536s
Feb  6 02:49:29.276: INFO: Pod "pod-subpath-test-downwardapi-7hsf": Phase="Running", Reason="", readiness=false. Elapsed: 6.041174251s
Feb  6 02:49:31.285: INFO: Pod "pod-subpath-test-downwardapi-7hsf": Phase="Running", Reason="", readiness=false. Elapsed: 8.050239908s
Feb  6 02:49:33.470: INFO: Pod "pod-subpath-test-downwardapi-7hsf": Phase="Running", Reason="", readiness=false. Elapsed: 10.235771125s
Feb  6 02:49:35.480: INFO: Pod "pod-subpath-test-downwardapi-7hsf": Phase="Running", Reason="", readiness=false. Elapsed: 12.245066811s
Feb  6 02:49:37.494: INFO: Pod "pod-subpath-test-downwardapi-7hsf": Phase="Running", Reason="", readiness=false. Elapsed: 14.259154177s
Feb  6 02:49:39.507: INFO: Pod "pod-subpath-test-downwardapi-7hsf": Phase="Running", Reason="", readiness=false. Elapsed: 16.272640708s
Feb  6 02:49:41.517: INFO: Pod "pod-subpath-test-downwardapi-7hsf": Phase="Running", Reason="", readiness=false. Elapsed: 18.282366341s
Feb  6 02:49:43.541: INFO: Pod "pod-subpath-test-downwardapi-7hsf": Phase="Running", Reason="", readiness=false. Elapsed: 20.306074415s
Feb  6 02:49:45.550: INFO: Pod "pod-subpath-test-downwardapi-7hsf": Phase="Running", Reason="", readiness=false. Elapsed: 22.315836095s
Feb  6 02:49:47.560: INFO: Pod "pod-subpath-test-downwardapi-7hsf": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.325090505s
STEP: Saw pod success
Feb  6 02:49:47.560: INFO: Pod "pod-subpath-test-downwardapi-7hsf" satisfied condition "success or failure"
Feb  6 02:49:47.569: INFO: Trying to get logs from node 10.190.119.184 pod pod-subpath-test-downwardapi-7hsf container test-container-subpath-downwardapi-7hsf: <nil>
STEP: delete the pod
Feb  6 02:49:47.624: INFO: Waiting for pod pod-subpath-test-downwardapi-7hsf to disappear
Feb  6 02:49:47.632: INFO: Pod pod-subpath-test-downwardapi-7hsf no longer exists
STEP: Deleting pod pod-subpath-test-downwardapi-7hsf
Feb  6 02:49:47.632: INFO: Deleting pod "pod-subpath-test-downwardapi-7hsf" in namespace "e2e-tests-subpath-fl7ng"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  6 02:49:47.699: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-fl7ng" for this suite.
Feb  6 02:49:55.740: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 02:49:56.058: INFO: namespace: e2e-tests-subpath-fl7ng, resource: bindings, ignored listing per whitelist
Feb  6 02:49:56.109: INFO: namespace e2e-tests-subpath-fl7ng deletion completed in 8.397187496s

• [SLOW TEST:33.936 seconds]
[sig-storage] Subpath
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with downward pod [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  6 02:49:56.111: INFO: >>> kubeConfig: /tmp/kubeconfig-131423863
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-secrets-2x54k
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-e2f64a22-29b9-11e9-9603-eaa511fa0b6c
STEP: Creating a pod to test consume secrets
Feb  6 02:49:56.532: INFO: Waiting up to 5m0s for pod "pod-secrets-e2f81d2a-29b9-11e9-9603-eaa511fa0b6c" in namespace "e2e-tests-secrets-2x54k" to be "success or failure"
Feb  6 02:49:56.547: INFO: Pod "pod-secrets-e2f81d2a-29b9-11e9-9603-eaa511fa0b6c": Phase="Pending", Reason="", readiness=false. Elapsed: 14.98413ms
Feb  6 02:49:58.556: INFO: Pod "pod-secrets-e2f81d2a-29b9-11e9-9603-eaa511fa0b6c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.0238229s
STEP: Saw pod success
Feb  6 02:49:58.556: INFO: Pod "pod-secrets-e2f81d2a-29b9-11e9-9603-eaa511fa0b6c" satisfied condition "success or failure"
Feb  6 02:49:58.564: INFO: Trying to get logs from node 10.190.119.133 pod pod-secrets-e2f81d2a-29b9-11e9-9603-eaa511fa0b6c container secret-volume-test: <nil>
STEP: delete the pod
Feb  6 02:49:58.609: INFO: Waiting for pod pod-secrets-e2f81d2a-29b9-11e9-9603-eaa511fa0b6c to disappear
Feb  6 02:49:58.619: INFO: Pod pod-secrets-e2f81d2a-29b9-11e9-9603-eaa511fa0b6c no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  6 02:49:58.619: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-2x54k" for this suite.
Feb  6 02:50:04.757: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 02:50:04.804: INFO: namespace: e2e-tests-secrets-2x54k, resource: bindings, ignored listing per whitelist
Feb  6 02:50:05.135: INFO: namespace e2e-tests-secrets-2x54k deletion completed in 6.430960231s

• [SLOW TEST:9.024 seconds]
[sig-storage] Secrets
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-api-machinery] CustomResourceDefinition resources Simple CustomResourceDefinition 
  creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  6 02:50:05.136: INFO: >>> kubeConfig: /tmp/kubeconfig-131423863
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-custom-resource-definition-xtczs
STEP: Waiting for a default service account to be provisioned in namespace
[It] creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb  6 02:50:05.432: INFO: >>> kubeConfig: /tmp/kubeconfig-131423863
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  6 02:50:06.829: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-custom-resource-definition-xtczs" for this suite.
Feb  6 02:50:12.868: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 02:50:13.212: INFO: namespace: e2e-tests-custom-resource-definition-xtczs, resource: bindings, ignored listing per whitelist
Feb  6 02:50:13.249: INFO: namespace e2e-tests-custom-resource-definition-xtczs deletion completed in 6.407266298s

• [SLOW TEST:8.114 seconds]
[sig-api-machinery] CustomResourceDefinition resources
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  Simple CustomResourceDefinition
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/custom_resource_definition.go:35
    creating/deleting custom resource definition objects works  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  6 02:50:13.251: INFO: >>> kubeConfig: /tmp/kubeconfig-131423863
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-gc-rgtn9
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the pods
STEP: Gathering metrics
W0206 02:50:54.351288      15 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Feb  6 02:50:54.351: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  6 02:50:54.351: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-rgtn9" for this suite.
Feb  6 02:51:02.409: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 02:51:02.509: INFO: namespace: e2e-tests-gc-rgtn9, resource: bindings, ignored listing per whitelist
Feb  6 02:51:02.801: INFO: namespace e2e-tests-gc-rgtn9 deletion completed in 8.429159925s

• [SLOW TEST:49.550 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  6 02:51:02.801: INFO: >>> kubeConfig: /tmp/kubeconfig-131423863
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-8wnzq
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-0aba0f37-29ba-11e9-9603-eaa511fa0b6c
STEP: Creating a pod to test consume secrets
Feb  6 02:51:03.241: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-0abbbfa3-29ba-11e9-9603-eaa511fa0b6c" in namespace "e2e-tests-projected-8wnzq" to be "success or failure"
Feb  6 02:51:03.250: INFO: Pod "pod-projected-secrets-0abbbfa3-29ba-11e9-9603-eaa511fa0b6c": Phase="Pending", Reason="", readiness=false. Elapsed: 8.717916ms
Feb  6 02:51:05.276: INFO: Pod "pod-projected-secrets-0abbbfa3-29ba-11e9-9603-eaa511fa0b6c": Phase="Running", Reason="", readiness=true. Elapsed: 2.03418008s
Feb  6 02:51:07.287: INFO: Pod "pod-projected-secrets-0abbbfa3-29ba-11e9-9603-eaa511fa0b6c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.045588744s
STEP: Saw pod success
Feb  6 02:51:07.287: INFO: Pod "pod-projected-secrets-0abbbfa3-29ba-11e9-9603-eaa511fa0b6c" satisfied condition "success or failure"
Feb  6 02:51:07.298: INFO: Trying to get logs from node 10.190.119.184 pod pod-projected-secrets-0abbbfa3-29ba-11e9-9603-eaa511fa0b6c container projected-secret-volume-test: <nil>
STEP: delete the pod
Feb  6 02:51:07.392: INFO: Waiting for pod pod-projected-secrets-0abbbfa3-29ba-11e9-9603-eaa511fa0b6c to disappear
Feb  6 02:51:07.404: INFO: Pod pod-projected-secrets-0abbbfa3-29ba-11e9-9603-eaa511fa0b6c no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  6 02:51:07.404: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-8wnzq" for this suite.
Feb  6 02:51:13.450: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 02:51:13.570: INFO: namespace: e2e-tests-projected-8wnzq, resource: bindings, ignored listing per whitelist
Feb  6 02:51:13.897: INFO: namespace e2e-tests-projected-8wnzq deletion completed in 6.478474698s

• [SLOW TEST:11.096 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  6 02:51:13.897: INFO: >>> kubeConfig: /tmp/kubeconfig-131423863
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-n582h
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0644 on node default medium
Feb  6 02:51:14.233: INFO: Waiting up to 5m0s for pod "pod-1148e52f-29ba-11e9-9603-eaa511fa0b6c" in namespace "e2e-tests-emptydir-n582h" to be "success or failure"
Feb  6 02:51:14.241: INFO: Pod "pod-1148e52f-29ba-11e9-9603-eaa511fa0b6c": Phase="Pending", Reason="", readiness=false. Elapsed: 8.02981ms
Feb  6 02:51:16.263: INFO: Pod "pod-1148e52f-29ba-11e9-9603-eaa511fa0b6c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.029796323s
STEP: Saw pod success
Feb  6 02:51:16.263: INFO: Pod "pod-1148e52f-29ba-11e9-9603-eaa511fa0b6c" satisfied condition "success or failure"
Feb  6 02:51:16.271: INFO: Trying to get logs from node 10.190.119.133 pod pod-1148e52f-29ba-11e9-9603-eaa511fa0b6c container test-container: <nil>
STEP: delete the pod
Feb  6 02:51:16.334: INFO: Waiting for pod pod-1148e52f-29ba-11e9-9603-eaa511fa0b6c to disappear
Feb  6 02:51:16.399: INFO: Pod pod-1148e52f-29ba-11e9-9603-eaa511fa0b6c no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  6 02:51:16.399: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-n582h" for this suite.
Feb  6 02:51:22.442: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 02:51:22.710: INFO: namespace: e2e-tests-emptydir-n582h, resource: bindings, ignored listing per whitelist
Feb  6 02:51:22.789: INFO: namespace e2e-tests-emptydir-n582h deletion completed in 6.376492968s

• [SLOW TEST:8.892 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl api-versions 
  should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  6 02:51:22.792: INFO: >>> kubeConfig: /tmp/kubeconfig-131423863
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-zvvgn
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: validating api versions
Feb  6 02:51:23.093: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-131423863 api-versions'
Feb  6 02:51:23.215: INFO: stderr: ""
Feb  6 02:51:23.215: INFO: stdout: "admissionregistration.k8s.io/v1alpha1\nadmissionregistration.k8s.io/v1beta1\napiextensions.k8s.io/v1beta1\napiregistration.k8s.io/v1\napiregistration.k8s.io/v1beta1\napps/v1\napps/v1beta1\napps/v1beta2\nauthentication.k8s.io/v1\nauthentication.k8s.io/v1beta1\nauthorization.k8s.io/v1\nauthorization.k8s.io/v1beta1\nautoscaling/v1\nautoscaling/v2beta1\nautoscaling/v2beta2\nbatch/v1\nbatch/v1beta1\nbatch/v2alpha1\ncertificates.k8s.io/v1beta1\ncoordination.k8s.io/v1beta1\nevents.k8s.io/v1beta1\nextensions/v1beta1\nmetrics.k8s.io/v1beta1\nnetworking.k8s.io/v1\npolicy/v1beta1\nrbac.authorization.k8s.io/v1\nrbac.authorization.k8s.io/v1beta1\nscheduling.k8s.io/v1beta1\nstorage.k8s.io/v1\nstorage.k8s.io/v1beta1\nv1\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  6 02:51:23.215: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-zvvgn" for this suite.
Feb  6 02:51:31.254: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 02:51:31.596: INFO: namespace: e2e-tests-kubectl-zvvgn, resource: bindings, ignored listing per whitelist
Feb  6 02:51:31.596: INFO: namespace e2e-tests-kubectl-zvvgn deletion completed in 8.369278465s

• [SLOW TEST:8.804 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl api-versions
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should check if v1 is in available api versions  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-api-machinery] Garbage collector 
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  6 02:51:31.596: INFO: >>> kubeConfig: /tmp/kubeconfig-131423863
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-gc-fvn95
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb  6 02:51:32.005: INFO: pod1.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod3", UID:"1bdfc4f2-29ba-11e9-bf83-6639c2940cda", Controller:(*bool)(0xc421b53362), BlockOwnerDeletion:(*bool)(0xc421b53363)}}
Feb  6 02:51:32.022: INFO: pod2.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod1", UID:"1bda9717-29ba-11e9-bf83-6639c2940cda", Controller:(*bool)(0xc420df8696), BlockOwnerDeletion:(*bool)(0xc420df8697)}}
Feb  6 02:51:32.036: INFO: pod3.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod2", UID:"1bdd5297-29ba-11e9-bf83-6639c2940cda", Controller:(*bool)(0xc420df639e), BlockOwnerDeletion:(*bool)(0xc420df639f)}}
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  6 02:51:37.201: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-fvn95" for this suite.
Feb  6 02:51:44.208: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 02:51:44.713: INFO: namespace: e2e-tests-gc-fvn95, resource: bindings, ignored listing per whitelist
Feb  6 02:51:44.912: INFO: namespace e2e-tests-gc-fvn95 deletion completed in 7.165020803s

• [SLOW TEST:13.316 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Downward API 
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  6 02:51:44.913: INFO: >>> kubeConfig: /tmp/kubeconfig-131423863
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-ljw9s
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Feb  6 02:51:45.439: INFO: Waiting up to 5m0s for pod "downward-api-23e2747c-29ba-11e9-9603-eaa511fa0b6c" in namespace "e2e-tests-downward-api-ljw9s" to be "success or failure"
Feb  6 02:51:45.448: INFO: Pod "downward-api-23e2747c-29ba-11e9-9603-eaa511fa0b6c": Phase="Pending", Reason="", readiness=false. Elapsed: 8.578749ms
Feb  6 02:51:47.459: INFO: Pod "downward-api-23e2747c-29ba-11e9-9603-eaa511fa0b6c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.02001792s
Feb  6 02:51:49.487: INFO: Pod "downward-api-23e2747c-29ba-11e9-9603-eaa511fa0b6c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.048019654s
STEP: Saw pod success
Feb  6 02:51:49.487: INFO: Pod "downward-api-23e2747c-29ba-11e9-9603-eaa511fa0b6c" satisfied condition "success or failure"
Feb  6 02:51:49.498: INFO: Trying to get logs from node 10.190.119.143 pod downward-api-23e2747c-29ba-11e9-9603-eaa511fa0b6c container dapi-container: <nil>
STEP: delete the pod
Feb  6 02:51:49.908: INFO: Waiting for pod downward-api-23e2747c-29ba-11e9-9603-eaa511fa0b6c to disappear
Feb  6 02:51:49.919: INFO: Pod downward-api-23e2747c-29ba-11e9-9603-eaa511fa0b6c no longer exists
[AfterEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  6 02:51:49.919: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-ljw9s" for this suite.
Feb  6 02:51:56.571: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 02:51:56.758: INFO: namespace: e2e-tests-downward-api-ljw9s, resource: bindings, ignored listing per whitelist
Feb  6 02:51:56.959: INFO: namespace e2e-tests-downward-api-ljw9s deletion completed in 7.020170967s

• [SLOW TEST:12.046 seconds]
[sig-api-machinery] Downward API
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] Projected 
  should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  6 02:51:56.961: INFO: >>> kubeConfig: /tmp/kubeconfig-131423863
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-5psqz
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb  6 02:51:57.308: INFO: Waiting up to 5m0s for pod "downwardapi-volume-2af570a5-29ba-11e9-9603-eaa511fa0b6c" in namespace "e2e-tests-projected-5psqz" to be "success or failure"
Feb  6 02:51:57.316: INFO: Pod "downwardapi-volume-2af570a5-29ba-11e9-9603-eaa511fa0b6c": Phase="Pending", Reason="", readiness=false. Elapsed: 8.160152ms
Feb  6 02:51:59.326: INFO: Pod "downwardapi-volume-2af570a5-29ba-11e9-9603-eaa511fa0b6c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.017928549s
STEP: Saw pod success
Feb  6 02:51:59.326: INFO: Pod "downwardapi-volume-2af570a5-29ba-11e9-9603-eaa511fa0b6c" satisfied condition "success or failure"
Feb  6 02:51:59.333: INFO: Trying to get logs from node 10.190.119.184 pod downwardapi-volume-2af570a5-29ba-11e9-9603-eaa511fa0b6c container client-container: <nil>
STEP: delete the pod
Feb  6 02:51:59.394: INFO: Waiting for pod downwardapi-volume-2af570a5-29ba-11e9-9603-eaa511fa0b6c to disappear
Feb  6 02:51:59.403: INFO: Pod downwardapi-volume-2af570a5-29ba-11e9-9603-eaa511fa0b6c no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  6 02:51:59.403: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-5psqz" for this suite.
Feb  6 02:52:05.449: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 02:52:05.499: INFO: namespace: e2e-tests-projected-5psqz, resource: bindings, ignored listing per whitelist
Feb  6 02:52:05.816: INFO: namespace e2e-tests-projected-5psqz deletion completed in 6.397150883s

• [SLOW TEST:8.855 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should set DefaultMode on files [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  6 02:52:05.816: INFO: >>> kubeConfig: /tmp/kubeconfig-131423863
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-container-lifecycle-hook-sq9m9
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:61
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Feb  6 02:52:10.292: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Feb  6 02:52:10.303: INFO: Pod pod-with-prestop-http-hook still exists
Feb  6 02:52:12.303: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Feb  6 02:52:12.327: INFO: Pod pod-with-prestop-http-hook still exists
Feb  6 02:52:14.303: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Feb  6 02:52:14.731: INFO: Pod pod-with-prestop-http-hook still exists
Feb  6 02:52:16.303: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Feb  6 02:52:16.312: INFO: Pod pod-with-prestop-http-hook still exists
Feb  6 02:52:18.303: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Feb  6 02:52:18.313: INFO: Pod pod-with-prestop-http-hook still exists
Feb  6 02:52:20.303: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Feb  6 02:52:20.318: INFO: Pod pod-with-prestop-http-hook still exists
Feb  6 02:52:22.303: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Feb  6 02:52:22.312: INFO: Pod pod-with-prestop-http-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  6 02:52:22.339: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-lifecycle-hook-sq9m9" for this suite.
Feb  6 02:52:46.394: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 02:52:46.592: INFO: namespace: e2e-tests-container-lifecycle-hook-sq9m9, resource: bindings, ignored listing per whitelist
Feb  6 02:52:46.868: INFO: namespace e2e-tests-container-lifecycle-hook-sq9m9 deletion completed in 24.502787231s

• [SLOW TEST:41.053 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  when create a pod with lifecycle hook
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:40
    should execute prestop http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  6 02:52:46.870: INFO: >>> kubeConfig: /tmp/kubeconfig-131423863
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-watch-fjg67
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a watch on configmaps with label A
STEP: creating a watch on configmaps with label B
STEP: creating a watch on configmaps with label A or B
STEP: creating a configmap with label A and ensuring the correct watchers observe the notification
Feb  6 02:52:47.230: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-fjg67,SelfLink:/api/v1/namespaces/e2e-tests-watch-fjg67/configmaps/e2e-watch-test-configmap-a,UID:48b8ccd9-29ba-11e9-bf83-6639c2940cda,ResourceVersion:63598,Generation:0,CreationTimestamp:2019-02-06 02:52:47 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Feb  6 02:52:47.230: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-fjg67,SelfLink:/api/v1/namespaces/e2e-tests-watch-fjg67/configmaps/e2e-watch-test-configmap-a,UID:48b8ccd9-29ba-11e9-bf83-6639c2940cda,ResourceVersion:63598,Generation:0,CreationTimestamp:2019-02-06 02:52:47 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: modifying configmap A and ensuring the correct watchers observe the notification
Feb  6 02:52:57.260: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-fjg67,SelfLink:/api/v1/namespaces/e2e-tests-watch-fjg67/configmaps/e2e-watch-test-configmap-a,UID:48b8ccd9-29ba-11e9-bf83-6639c2940cda,ResourceVersion:63613,Generation:0,CreationTimestamp:2019-02-06 02:52:47 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Feb  6 02:52:57.260: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-fjg67,SelfLink:/api/v1/namespaces/e2e-tests-watch-fjg67/configmaps/e2e-watch-test-configmap-a,UID:48b8ccd9-29ba-11e9-bf83-6639c2940cda,ResourceVersion:63613,Generation:0,CreationTimestamp:2019-02-06 02:52:47 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying configmap A again and ensuring the correct watchers observe the notification
Feb  6 02:53:07.289: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-fjg67,SelfLink:/api/v1/namespaces/e2e-tests-watch-fjg67/configmaps/e2e-watch-test-configmap-a,UID:48b8ccd9-29ba-11e9-bf83-6639c2940cda,ResourceVersion:63630,Generation:0,CreationTimestamp:2019-02-06 02:52:47 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Feb  6 02:53:07.289: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-fjg67,SelfLink:/api/v1/namespaces/e2e-tests-watch-fjg67/configmaps/e2e-watch-test-configmap-a,UID:48b8ccd9-29ba-11e9-bf83-6639c2940cda,ResourceVersion:63630,Generation:0,CreationTimestamp:2019-02-06 02:52:47 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: deleting configmap A and ensuring the correct watchers observe the notification
Feb  6 02:53:17.320: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-fjg67,SelfLink:/api/v1/namespaces/e2e-tests-watch-fjg67/configmaps/e2e-watch-test-configmap-a,UID:48b8ccd9-29ba-11e9-bf83-6639c2940cda,ResourceVersion:63647,Generation:0,CreationTimestamp:2019-02-06 02:52:47 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Feb  6 02:53:17.320: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:e2e-tests-watch-fjg67,SelfLink:/api/v1/namespaces/e2e-tests-watch-fjg67/configmaps/e2e-watch-test-configmap-a,UID:48b8ccd9-29ba-11e9-bf83-6639c2940cda,ResourceVersion:63647,Generation:0,CreationTimestamp:2019-02-06 02:52:47 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: creating a configmap with label B and ensuring the correct watchers observe the notification
Feb  6 02:53:27.354: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-fjg67,SelfLink:/api/v1/namespaces/e2e-tests-watch-fjg67/configmaps/e2e-watch-test-configmap-b,UID:60a1e606-29ba-11e9-bf83-6639c2940cda,ResourceVersion:63664,Generation:0,CreationTimestamp:2019-02-06 02:53:27 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Feb  6 02:53:27.354: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-fjg67,SelfLink:/api/v1/namespaces/e2e-tests-watch-fjg67/configmaps/e2e-watch-test-configmap-b,UID:60a1e606-29ba-11e9-bf83-6639c2940cda,ResourceVersion:63664,Generation:0,CreationTimestamp:2019-02-06 02:53:27 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: deleting configmap B and ensuring the correct watchers observe the notification
Feb  6 02:53:37.390: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-fjg67,SelfLink:/api/v1/namespaces/e2e-tests-watch-fjg67/configmaps/e2e-watch-test-configmap-b,UID:60a1e606-29ba-11e9-bf83-6639c2940cda,ResourceVersion:63684,Generation:0,CreationTimestamp:2019-02-06 02:53:27 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
Feb  6 02:53:37.390: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:e2e-tests-watch-fjg67,SelfLink:/api/v1/namespaces/e2e-tests-watch-fjg67/configmaps/e2e-watch-test-configmap-b,UID:60a1e606-29ba-11e9-bf83-6639c2940cda,ResourceVersion:63684,Generation:0,CreationTimestamp:2019-02-06 02:53:27 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  6 02:53:47.391: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-fjg67" for this suite.
Feb  6 02:53:55.445: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 02:53:55.683: INFO: namespace: e2e-tests-watch-fjg67, resource: bindings, ignored listing per whitelist
Feb  6 02:53:55.804: INFO: namespace e2e-tests-watch-fjg67 deletion completed in 8.386099582s

• [SLOW TEST:68.935 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  6 02:53:55.805: INFO: >>> kubeConfig: /tmp/kubeconfig-131423863
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-f24tt
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0666 on node default medium
Feb  6 02:53:56.333: INFO: Waiting up to 5m0s for pod "pod-71e76095-29ba-11e9-9603-eaa511fa0b6c" in namespace "e2e-tests-emptydir-f24tt" to be "success or failure"
Feb  6 02:53:56.342: INFO: Pod "pod-71e76095-29ba-11e9-9603-eaa511fa0b6c": Phase="Pending", Reason="", readiness=false. Elapsed: 9.065135ms
Feb  6 02:53:58.366: INFO: Pod "pod-71e76095-29ba-11e9-9603-eaa511fa0b6c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.032967321s
Feb  6 02:54:00.375: INFO: Pod "pod-71e76095-29ba-11e9-9603-eaa511fa0b6c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.042065805s
STEP: Saw pod success
Feb  6 02:54:00.375: INFO: Pod "pod-71e76095-29ba-11e9-9603-eaa511fa0b6c" satisfied condition "success or failure"
Feb  6 02:54:00.384: INFO: Trying to get logs from node 10.190.119.184 pod pod-71e76095-29ba-11e9-9603-eaa511fa0b6c container test-container: <nil>
STEP: delete the pod
Feb  6 02:54:00.437: INFO: Waiting for pod pod-71e76095-29ba-11e9-9603-eaa511fa0b6c to disappear
Feb  6 02:54:00.444: INFO: Pod pod-71e76095-29ba-11e9-9603-eaa511fa0b6c no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  6 02:54:00.445: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-f24tt" for this suite.
Feb  6 02:54:06.484: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 02:54:06.712: INFO: namespace: e2e-tests-emptydir-f24tt, resource: bindings, ignored listing per whitelist
Feb  6 02:54:06.868: INFO: namespace e2e-tests-emptydir-f24tt deletion completed in 6.411664996s

• [SLOW TEST:11.064 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[k8s.io] Probing container 
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  6 02:54:06.869: INFO: >>> kubeConfig: /tmp/kubeconfig-131423863
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-container-probe-5rtgt
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-http in namespace e2e-tests-container-probe-5rtgt
Feb  6 02:54:09.261: INFO: Started pod liveness-http in namespace e2e-tests-container-probe-5rtgt
STEP: checking the pod's current state and verifying that restartCount is present
Feb  6 02:54:09.275: INFO: Initial restart count of pod liveness-http is 0
Feb  6 02:54:27.452: INFO: Restart count of pod e2e-tests-container-probe-5rtgt/liveness-http is now 1 (18.176854223s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  6 02:54:27.480: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-5rtgt" for this suite.
Feb  6 02:54:33.525: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 02:54:33.951: INFO: namespace: e2e-tests-container-probe-5rtgt, resource: bindings, ignored listing per whitelist
Feb  6 02:54:33.975: INFO: namespace e2e-tests-container-probe-5rtgt deletion completed in 6.480646534s

• [SLOW TEST:27.106 seconds]
[k8s.io] Probing container
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  6 02:54:33.976: INFO: >>> kubeConfig: /tmp/kubeconfig-131423863
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-ddhln
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb  6 02:54:34.311: INFO: Waiting up to 5m0s for pod "downwardapi-volume-8889a260-29ba-11e9-9603-eaa511fa0b6c" in namespace "e2e-tests-downward-api-ddhln" to be "success or failure"
Feb  6 02:54:34.325: INFO: Pod "downwardapi-volume-8889a260-29ba-11e9-9603-eaa511fa0b6c": Phase="Pending", Reason="", readiness=false. Elapsed: 14.012049ms
Feb  6 02:54:36.335: INFO: Pod "downwardapi-volume-8889a260-29ba-11e9-9603-eaa511fa0b6c": Phase="Running", Reason="", readiness=true. Elapsed: 2.023625725s
Feb  6 02:54:38.344: INFO: Pod "downwardapi-volume-8889a260-29ba-11e9-9603-eaa511fa0b6c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.033111787s
STEP: Saw pod success
Feb  6 02:54:38.344: INFO: Pod "downwardapi-volume-8889a260-29ba-11e9-9603-eaa511fa0b6c" satisfied condition "success or failure"
Feb  6 02:54:38.353: INFO: Trying to get logs from node 10.190.119.143 pod downwardapi-volume-8889a260-29ba-11e9-9603-eaa511fa0b6c container client-container: <nil>
STEP: delete the pod
Feb  6 02:54:38.405: INFO: Waiting for pod downwardapi-volume-8889a260-29ba-11e9-9603-eaa511fa0b6c to disappear
Feb  6 02:54:38.416: INFO: Pod downwardapi-volume-8889a260-29ba-11e9-9603-eaa511fa0b6c no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  6 02:54:38.416: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-ddhln" for this suite.
Feb  6 02:54:44.460: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 02:54:44.591: INFO: namespace: e2e-tests-downward-api-ddhln, resource: bindings, ignored listing per whitelist
Feb  6 02:54:44.771: INFO: namespace e2e-tests-downward-api-ddhln deletion completed in 6.337041127s

• [SLOW TEST:10.796 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  6 02:54:44.772: INFO: >>> kubeConfig: /tmp/kubeconfig-131423863
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-4c5rx
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-map-8ef96080-29ba-11e9-9603-eaa511fa0b6c
STEP: Creating a pod to test consume configMaps
Feb  6 02:54:45.116: INFO: Waiting up to 5m0s for pod "pod-configmaps-8efab617-29ba-11e9-9603-eaa511fa0b6c" in namespace "e2e-tests-configmap-4c5rx" to be "success or failure"
Feb  6 02:54:45.124: INFO: Pod "pod-configmaps-8efab617-29ba-11e9-9603-eaa511fa0b6c": Phase="Pending", Reason="", readiness=false. Elapsed: 8.192033ms
Feb  6 02:54:47.135: INFO: Pod "pod-configmaps-8efab617-29ba-11e9-9603-eaa511fa0b6c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.019134042s
STEP: Saw pod success
Feb  6 02:54:47.135: INFO: Pod "pod-configmaps-8efab617-29ba-11e9-9603-eaa511fa0b6c" satisfied condition "success or failure"
Feb  6 02:54:47.203: INFO: Trying to get logs from node 10.190.119.184 pod pod-configmaps-8efab617-29ba-11e9-9603-eaa511fa0b6c container configmap-volume-test: <nil>
STEP: delete the pod
Feb  6 02:54:47.262: INFO: Waiting for pod pod-configmaps-8efab617-29ba-11e9-9603-eaa511fa0b6c to disappear
Feb  6 02:54:47.273: INFO: Pod pod-configmaps-8efab617-29ba-11e9-9603-eaa511fa0b6c no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  6 02:54:47.273: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-4c5rx" for this suite.
Feb  6 02:54:53.313: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 02:54:53.547: INFO: namespace: e2e-tests-configmap-4c5rx, resource: bindings, ignored listing per whitelist
Feb  6 02:54:53.768: INFO: namespace e2e-tests-configmap-4c5rx deletion completed in 6.483587539s

• [SLOW TEST:8.996 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  6 02:54:53.768: INFO: >>> kubeConfig: /tmp/kubeconfig-131423863
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-gc-tmmfl
STEP: Waiting for a default service account to be provisioned in namespace
[It] should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: Gathering metrics
W0206 02:55:00.165697      15 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Feb  6 02:55:00.165: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  6 02:55:00.165: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-tmmfl" for this suite.
Feb  6 02:55:08.235: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 02:55:08.544: INFO: namespace: e2e-tests-gc-tmmfl, resource: bindings, ignored listing per whitelist
Feb  6 02:55:08.670: INFO: namespace e2e-tests-gc-tmmfl deletion completed in 8.465867609s

• [SLOW TEST:14.902 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  6 02:55:08.671: INFO: >>> kubeConfig: /tmp/kubeconfig-131423863
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-pctt5
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb  6 02:55:09.000: INFO: Waiting up to 5m0s for pod "downwardapi-volume-9d361bbf-29ba-11e9-9603-eaa511fa0b6c" in namespace "e2e-tests-downward-api-pctt5" to be "success or failure"
Feb  6 02:55:09.008: INFO: Pod "downwardapi-volume-9d361bbf-29ba-11e9-9603-eaa511fa0b6c": Phase="Pending", Reason="", readiness=false. Elapsed: 7.722169ms
Feb  6 02:55:11.018: INFO: Pod "downwardapi-volume-9d361bbf-29ba-11e9-9603-eaa511fa0b6c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.018121626s
Feb  6 02:55:13.047: INFO: Pod "downwardapi-volume-9d361bbf-29ba-11e9-9603-eaa511fa0b6c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.046750005s
STEP: Saw pod success
Feb  6 02:55:13.047: INFO: Pod "downwardapi-volume-9d361bbf-29ba-11e9-9603-eaa511fa0b6c" satisfied condition "success or failure"
Feb  6 02:55:13.056: INFO: Trying to get logs from node 10.190.119.143 pod downwardapi-volume-9d361bbf-29ba-11e9-9603-eaa511fa0b6c container client-container: <nil>
STEP: delete the pod
Feb  6 02:55:13.192: INFO: Waiting for pod downwardapi-volume-9d361bbf-29ba-11e9-9603-eaa511fa0b6c to disappear
Feb  6 02:55:13.200: INFO: Pod downwardapi-volume-9d361bbf-29ba-11e9-9603-eaa511fa0b6c no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  6 02:55:13.200: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-pctt5" for this suite.
Feb  6 02:55:19.241: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 02:55:19.756: INFO: namespace: e2e-tests-downward-api-pctt5, resource: bindings, ignored listing per whitelist
Feb  6 02:55:19.837: INFO: namespace e2e-tests-downward-api-pctt5 deletion completed in 6.624575861s

• [SLOW TEST:11.167 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-storage] Projected 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  6 02:55:19.839: INFO: >>> kubeConfig: /tmp/kubeconfig-131423863
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-4sw7b
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with secret that has name projected-secret-test-a3e5e598-29ba-11e9-9603-eaa511fa0b6c
STEP: Creating a pod to test consume secrets
Feb  6 02:55:20.224: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-a3e7c9ac-29ba-11e9-9603-eaa511fa0b6c" in namespace "e2e-tests-projected-4sw7b" to be "success or failure"
Feb  6 02:55:20.233: INFO: Pod "pod-projected-secrets-a3e7c9ac-29ba-11e9-9603-eaa511fa0b6c": Phase="Pending", Reason="", readiness=false. Elapsed: 8.508773ms
Feb  6 02:55:22.242: INFO: Pod "pod-projected-secrets-a3e7c9ac-29ba-11e9-9603-eaa511fa0b6c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.017466103s
STEP: Saw pod success
Feb  6 02:55:22.242: INFO: Pod "pod-projected-secrets-a3e7c9ac-29ba-11e9-9603-eaa511fa0b6c" satisfied condition "success or failure"
Feb  6 02:55:22.251: INFO: Trying to get logs from node 10.190.119.184 pod pod-projected-secrets-a3e7c9ac-29ba-11e9-9603-eaa511fa0b6c container projected-secret-volume-test: <nil>
STEP: delete the pod
Feb  6 02:55:22.300: INFO: Waiting for pod pod-projected-secrets-a3e7c9ac-29ba-11e9-9603-eaa511fa0b6c to disappear
Feb  6 02:55:22.309: INFO: Pod pod-projected-secrets-a3e7c9ac-29ba-11e9-9603-eaa511fa0b6c no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  6 02:55:22.309: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-4sw7b" for this suite.
Feb  6 02:55:30.416: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 02:55:30.771: INFO: namespace: e2e-tests-projected-4sw7b, resource: bindings, ignored listing per whitelist
Feb  6 02:55:30.789: INFO: namespace e2e-tests-projected-4sw7b deletion completed in 8.397168727s

• [SLOW TEST:10.950 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  6 02:55:30.789: INFO: >>> kubeConfig: /tmp/kubeconfig-131423863
STEP: Building a namespace api object, basename pod-network-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-pod-network-test-sk56s
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-sk56s
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Feb  6 02:55:31.091: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Feb  6 02:55:53.434: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://172.30.134.196:8080/dial?request=hostName&protocol=http&host=172.30.242.58&port=8080&tries=1'] Namespace:e2e-tests-pod-network-test-sk56s PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb  6 02:55:53.434: INFO: >>> kubeConfig: /tmp/kubeconfig-131423863
Feb  6 02:55:53.716: INFO: Waiting for endpoints: map[]
Feb  6 02:55:53.802: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://172.30.134.196:8080/dial?request=hostName&protocol=http&host=172.30.176.63&port=8080&tries=1'] Namespace:e2e-tests-pod-network-test-sk56s PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb  6 02:55:53.802: INFO: >>> kubeConfig: /tmp/kubeconfig-131423863
Feb  6 02:55:54.032: INFO: Waiting for endpoints: map[]
Feb  6 02:55:54.091: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://172.30.134.196:8080/dial?request=hostName&protocol=http&host=172.30.134.255&port=8080&tries=1'] Namespace:e2e-tests-pod-network-test-sk56s PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb  6 02:55:54.091: INFO: >>> kubeConfig: /tmp/kubeconfig-131423863
Feb  6 02:55:54.322: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  6 02:55:54.322: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-sk56s" for this suite.
Feb  6 02:56:18.363: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 02:56:18.508: INFO: namespace: e2e-tests-pod-network-test-sk56s, resource: bindings, ignored listing per whitelist
Feb  6 02:56:18.848: INFO: namespace e2e-tests-pod-network-test-sk56s deletion completed in 24.511263283s

• [SLOW TEST:48.059 seconds]
[sig-network] Networking
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: http [NodeConformance] [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  6 02:56:18.848: INFO: >>> kubeConfig: /tmp/kubeconfig-131423863
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-secrets-lx2qz
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-c711c692-29ba-11e9-9603-eaa511fa0b6c
STEP: Creating a pod to test consume secrets
Feb  6 02:56:19.291: INFO: Waiting up to 5m0s for pod "pod-secrets-c713dcb7-29ba-11e9-9603-eaa511fa0b6c" in namespace "e2e-tests-secrets-lx2qz" to be "success or failure"
Feb  6 02:56:19.299: INFO: Pod "pod-secrets-c713dcb7-29ba-11e9-9603-eaa511fa0b6c": Phase="Pending", Reason="", readiness=false. Elapsed: 8.353071ms
Feb  6 02:56:21.322: INFO: Pod "pod-secrets-c713dcb7-29ba-11e9-9603-eaa511fa0b6c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.031047356s
STEP: Saw pod success
Feb  6 02:56:21.322: INFO: Pod "pod-secrets-c713dcb7-29ba-11e9-9603-eaa511fa0b6c" satisfied condition "success or failure"
Feb  6 02:56:21.331: INFO: Trying to get logs from node 10.190.119.184 pod pod-secrets-c713dcb7-29ba-11e9-9603-eaa511fa0b6c container secret-volume-test: <nil>
STEP: delete the pod
Feb  6 02:56:21.383: INFO: Waiting for pod pod-secrets-c713dcb7-29ba-11e9-9603-eaa511fa0b6c to disappear
Feb  6 02:56:21.391: INFO: Pod pod-secrets-c713dcb7-29ba-11e9-9603-eaa511fa0b6c no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  6 02:56:21.391: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-lx2qz" for this suite.
Feb  6 02:56:27.436: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 02:56:27.913: INFO: namespace: e2e-tests-secrets-lx2qz, resource: bindings, ignored listing per whitelist
Feb  6 02:56:28.053: INFO: namespace e2e-tests-secrets-lx2qz deletion completed in 6.643058514s

• [SLOW TEST:9.205 seconds]
[sig-storage] Secrets
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-auth] ServiceAccounts 
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  6 02:56:28.053: INFO: >>> kubeConfig: /tmp/kubeconfig-131423863
STEP: Building a namespace api object, basename svcaccounts
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-svcaccounts-6pwc2
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: getting the auto-created API token
Feb  6 02:56:28.948: INFO: created pod pod-service-account-defaultsa
Feb  6 02:56:28.948: INFO: pod pod-service-account-defaultsa service account token volume mount: true
Feb  6 02:56:28.959: INFO: created pod pod-service-account-mountsa
Feb  6 02:56:28.959: INFO: pod pod-service-account-mountsa service account token volume mount: true
Feb  6 02:56:28.992: INFO: created pod pod-service-account-nomountsa
Feb  6 02:56:28.992: INFO: pod pod-service-account-nomountsa service account token volume mount: false
Feb  6 02:56:29.004: INFO: created pod pod-service-account-defaultsa-mountspec
Feb  6 02:56:29.004: INFO: pod pod-service-account-defaultsa-mountspec service account token volume mount: true
Feb  6 02:56:29.016: INFO: created pod pod-service-account-mountsa-mountspec
Feb  6 02:56:29.016: INFO: pod pod-service-account-mountsa-mountspec service account token volume mount: true
Feb  6 02:56:29.045: INFO: created pod pod-service-account-nomountsa-mountspec
Feb  6 02:56:29.045: INFO: pod pod-service-account-nomountsa-mountspec service account token volume mount: true
Feb  6 02:56:29.058: INFO: created pod pod-service-account-defaultsa-nomountspec
Feb  6 02:56:29.058: INFO: pod pod-service-account-defaultsa-nomountspec service account token volume mount: false
Feb  6 02:56:29.085: INFO: created pod pod-service-account-mountsa-nomountspec
Feb  6 02:56:29.085: INFO: pod pod-service-account-mountsa-nomountspec service account token volume mount: false
Feb  6 02:56:29.101: INFO: created pod pod-service-account-nomountsa-nomountspec
Feb  6 02:56:29.101: INFO: pod pod-service-account-nomountsa-nomountspec service account token volume mount: false
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  6 02:56:29.101: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-svcaccounts-6pwc2" for this suite.
Feb  6 02:56:35.152: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 02:56:35.391: INFO: namespace: e2e-tests-svcaccounts-6pwc2, resource: bindings, ignored listing per whitelist
Feb  6 02:56:35.469: INFO: namespace e2e-tests-svcaccounts-6pwc2 deletion completed in 6.352312777s

• [SLOW TEST:7.417 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:22
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  6 02:56:35.470: INFO: >>> kubeConfig: /tmp/kubeconfig-131423863
STEP: Building a namespace api object, basename init-container
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-init-container-dkwzw
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
Feb  6 02:56:35.792: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  6 02:56:39.743: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-init-container-dkwzw" for this suite.
Feb  6 02:56:45.823: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 02:56:45.989: INFO: namespace: e2e-tests-init-container-dkwzw, resource: bindings, ignored listing per whitelist
Feb  6 02:56:46.306: INFO: namespace e2e-tests-init-container-dkwzw deletion completed in 6.512427742s

• [SLOW TEST:10.836 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  6 02:56:46.306: INFO: >>> kubeConfig: /tmp/kubeconfig-131423863
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-ckqlk
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-d7691111-29ba-11e9-9603-eaa511fa0b6c
STEP: Creating a pod to test consume configMaps
Feb  6 02:56:46.718: INFO: Waiting up to 5m0s for pod "pod-configmaps-d776036f-29ba-11e9-9603-eaa511fa0b6c" in namespace "e2e-tests-configmap-ckqlk" to be "success or failure"
Feb  6 02:56:46.726: INFO: Pod "pod-configmaps-d776036f-29ba-11e9-9603-eaa511fa0b6c": Phase="Pending", Reason="", readiness=false. Elapsed: 8.574063ms
Feb  6 02:56:48.736: INFO: Pod "pod-configmaps-d776036f-29ba-11e9-9603-eaa511fa0b6c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.017810848s
STEP: Saw pod success
Feb  6 02:56:48.736: INFO: Pod "pod-configmaps-d776036f-29ba-11e9-9603-eaa511fa0b6c" satisfied condition "success or failure"
Feb  6 02:56:48.747: INFO: Trying to get logs from node 10.190.119.143 pod pod-configmaps-d776036f-29ba-11e9-9603-eaa511fa0b6c container configmap-volume-test: <nil>
STEP: delete the pod
Feb  6 02:56:48.802: INFO: Waiting for pod pod-configmaps-d776036f-29ba-11e9-9603-eaa511fa0b6c to disappear
Feb  6 02:56:48.809: INFO: Pod pod-configmaps-d776036f-29ba-11e9-9603-eaa511fa0b6c no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  6 02:56:48.815: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-ckqlk" for this suite.
Feb  6 02:56:54.879: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 02:56:54.964: INFO: namespace: e2e-tests-configmap-ckqlk, resource: bindings, ignored listing per whitelist
Feb  6 02:56:55.241: INFO: namespace e2e-tests-configmap-ckqlk deletion completed in 6.409024111s

• [SLOW TEST:8.935 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl rolling-update 
  should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  6 02:56:55.241: INFO: >>> kubeConfig: /tmp/kubeconfig-131423863
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-xnqpj
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1306
[It] should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Feb  6 02:56:55.532: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-131423863 run e2e-test-nginx-rc --image=docker.io/library/nginx:1.14-alpine --generator=run/v1 --namespace=e2e-tests-kubectl-xnqpj'
Feb  6 02:56:55.830: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl create instead.\n"
Feb  6 02:56:55.830: INFO: stdout: "replicationcontroller/e2e-test-nginx-rc created\n"
STEP: verifying the rc e2e-test-nginx-rc was created
Feb  6 02:56:55.845: INFO: Waiting for rc e2e-test-nginx-rc to stabilize, generation 1 observed generation 0 spec.replicas 1 status.replicas 0
Feb  6 02:56:55.852: INFO: Waiting for rc e2e-test-nginx-rc to stabilize, generation 1 observed generation 1 spec.replicas 1 status.replicas 0
STEP: rolling-update to same image controller
Feb  6 02:56:55.864: INFO: scanned /root for discovery docs: <nil>
Feb  6 02:56:55.864: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-131423863 rolling-update e2e-test-nginx-rc --update-period=1s --image=docker.io/library/nginx:1.14-alpine --image-pull-policy=IfNotPresent --namespace=e2e-tests-kubectl-xnqpj'
Feb  6 02:57:11.801: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Feb  6 02:57:11.801: INFO: stdout: "Created e2e-test-nginx-rc-76caa54282570a79792aa688e0e7cbf0\nScaling up e2e-test-nginx-rc-76caa54282570a79792aa688e0e7cbf0 from 0 to 1, scaling down e2e-test-nginx-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-nginx-rc-76caa54282570a79792aa688e0e7cbf0 up to 1\nScaling e2e-test-nginx-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-nginx-rc\nRenaming e2e-test-nginx-rc-76caa54282570a79792aa688e0e7cbf0 to e2e-test-nginx-rc\nreplicationcontroller/e2e-test-nginx-rc rolling updated\n"
Feb  6 02:57:11.801: INFO: stdout: "Created e2e-test-nginx-rc-76caa54282570a79792aa688e0e7cbf0\nScaling up e2e-test-nginx-rc-76caa54282570a79792aa688e0e7cbf0 from 0 to 1, scaling down e2e-test-nginx-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-nginx-rc-76caa54282570a79792aa688e0e7cbf0 up to 1\nScaling e2e-test-nginx-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-nginx-rc\nRenaming e2e-test-nginx-rc-76caa54282570a79792aa688e0e7cbf0 to e2e-test-nginx-rc\nreplicationcontroller/e2e-test-nginx-rc rolling updated\n"
STEP: waiting for all containers in run=e2e-test-nginx-rc pods to come up.
Feb  6 02:57:11.801: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-131423863 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l run=e2e-test-nginx-rc --namespace=e2e-tests-kubectl-xnqpj'
Feb  6 02:57:11.995: INFO: stderr: ""
Feb  6 02:57:11.995: INFO: stdout: "e2e-test-nginx-rc-76caa54282570a79792aa688e0e7cbf0-996g7 "
Feb  6 02:57:11.995: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-131423863 get pods e2e-test-nginx-rc-76caa54282570a79792aa688e0e7cbf0-996g7 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "e2e-test-nginx-rc") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-xnqpj'
Feb  6 02:57:12.152: INFO: stderr: ""
Feb  6 02:57:12.152: INFO: stdout: "true"
Feb  6 02:57:12.152: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-131423863 get pods e2e-test-nginx-rc-76caa54282570a79792aa688e0e7cbf0-996g7 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "e2e-test-nginx-rc"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-xnqpj'
Feb  6 02:57:12.286: INFO: stderr: ""
Feb  6 02:57:12.286: INFO: stdout: "docker.io/library/nginx:1.14-alpine"
Feb  6 02:57:12.286: INFO: e2e-test-nginx-rc-76caa54282570a79792aa688e0e7cbf0-996g7 is verified up and running
[AfterEach] [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1312
Feb  6 02:57:12.286: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-131423863 delete rc e2e-test-nginx-rc --namespace=e2e-tests-kubectl-xnqpj'
Feb  6 02:57:12.432: INFO: stderr: ""
Feb  6 02:57:12.432: INFO: stdout: "replicationcontroller \"e2e-test-nginx-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  6 02:57:12.432: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-xnqpj" for this suite.
Feb  6 02:57:18.475: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 02:57:18.735: INFO: namespace: e2e-tests-kubectl-xnqpj, resource: bindings, ignored listing per whitelist
Feb  6 02:57:18.793: INFO: namespace e2e-tests-kubectl-xnqpj deletion completed in 6.348898822s

• [SLOW TEST:23.552 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should support rolling-update to same image  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  6 02:57:18.794: INFO: >>> kubeConfig: /tmp/kubeconfig-131423863
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-statefulset-rhg5g
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-rhg5g
[It] should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a new StatefulSet
Feb  6 02:57:19.679: INFO: Found 0 stateful pods, waiting for 3
Feb  6 02:57:29.778: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Feb  6 02:57:29.778: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Feb  6 02:57:29.778: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
Feb  6 02:57:29.807: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-131423863 exec --namespace=e2e-tests-statefulset-rhg5g ss2-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Feb  6 02:57:30.320: INFO: stderr: ""
Feb  6 02:57:30.320: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Feb  6 02:57:30.320: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss2-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

STEP: Updating StatefulSet template: update image from docker.io/library/nginx:1.14-alpine to docker.io/library/nginx:1.15-alpine
Feb  6 02:57:40.411: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Updating Pods in reverse ordinal order
Feb  6 02:57:50.492: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-131423863 exec --namespace=e2e-tests-statefulset-rhg5g ss2-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb  6 02:57:50.861: INFO: stderr: ""
Feb  6 02:57:50.861: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Feb  6 02:57:50.861: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss2-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

STEP: Rolling back to a previous revision
Feb  6 02:58:10.938: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-131423863 exec --namespace=e2e-tests-statefulset-rhg5g ss2-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Feb  6 02:58:11.289: INFO: stderr: ""
Feb  6 02:58:11.289: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Feb  6 02:58:11.289: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss2-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Feb  6 02:58:21.376: INFO: Updating stateful set ss2
STEP: Rolling back update in reverse ordinal order
Feb  6 02:58:31.437: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-131423863 exec --namespace=e2e-tests-statefulset-rhg5g ss2-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb  6 02:58:31.848: INFO: stderr: ""
Feb  6 02:58:31.848: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Feb  6 02:58:31.848: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss2-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Feb  6 02:58:51.915: INFO: Deleting all statefulset in ns e2e-tests-statefulset-rhg5g
Feb  6 02:58:51.923: INFO: Scaling statefulset ss2 to 0
Feb  6 02:59:11.959: INFO: Waiting for statefulset status.replicas updated to 0
Feb  6 02:59:11.968: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  6 02:59:12.024: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-rhg5g" for this suite.
Feb  6 02:59:18.250: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 02:59:18.344: INFO: namespace: e2e-tests-statefulset-rhg5g, resource: bindings, ignored listing per whitelist
Feb  6 02:59:18.732: INFO: namespace e2e-tests-statefulset-rhg5g deletion completed in 6.640267524s

• [SLOW TEST:119.938 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should perform rolling updates and roll backs of template modifications [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run pod 
  should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  6 02:59:18.732: INFO: >>> kubeConfig: /tmp/kubeconfig-131423863
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-pwpfc
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Kubectl run pod
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1475
[It] should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Feb  6 02:59:19.299: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-131423863 run e2e-test-nginx-pod --restart=Never --generator=run-pod/v1 --image=docker.io/library/nginx:1.14-alpine --namespace=e2e-tests-kubectl-pwpfc'
Feb  6 02:59:19.449: INFO: stderr: ""
Feb  6 02:59:19.449: INFO: stdout: "pod/e2e-test-nginx-pod created\n"
STEP: verifying the pod e2e-test-nginx-pod was created
[AfterEach] [k8s.io] Kubectl run pod
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1480
Feb  6 02:59:19.457: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-131423863 delete pods e2e-test-nginx-pod --namespace=e2e-tests-kubectl-pwpfc'
Feb  6 02:59:28.730: INFO: stderr: ""
Feb  6 02:59:28.730: INFO: stdout: "pod \"e2e-test-nginx-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  6 02:59:28.730: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-pwpfc" for this suite.
Feb  6 02:59:34.786: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 02:59:34.932: INFO: namespace: e2e-tests-kubectl-pwpfc, resource: bindings, ignored listing per whitelist
Feb  6 02:59:35.172: INFO: namespace e2e-tests-kubectl-pwpfc deletion completed in 6.412786842s

• [SLOW TEST:16.440 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run pod
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create a pod from an image when restart is Never  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[k8s.io] [sig-node] Pods Extended [k8s.io] Pods Set QOS Class 
  should be submitted and removed  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  6 02:59:35.174: INFO: >>> kubeConfig: /tmp/kubeconfig-131423863
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-pods-4zzgx
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pods.go:204
[It] should be submitted and removed  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying QOS class is set on the pod
[AfterEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  6 02:59:35.503: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-4zzgx" for this suite.
Feb  6 02:59:59.623: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 02:59:59.712: INFO: namespace: e2e-tests-pods-4zzgx, resource: bindings, ignored listing per whitelist
Feb  6 03:00:00.274: INFO: namespace e2e-tests-pods-4zzgx deletion completed in 24.681915377s

• [SLOW TEST:25.100 seconds]
[k8s.io] [sig-node] Pods Extended
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should be submitted and removed  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  6 03:00:00.274: INFO: >>> kubeConfig: /tmp/kubeconfig-131423863
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-daemonsets-2z2sm
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:98
[It] should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Feb  6 03:00:00.661: INFO: Number of nodes with available pods: 0
Feb  6 03:00:00.661: INFO: Node 10.190.119.133 is running more than one daemon pod
Feb  6 03:00:01.703: INFO: Number of nodes with available pods: 0
Feb  6 03:00:01.703: INFO: Node 10.190.119.133 is running more than one daemon pod
Feb  6 03:00:02.687: INFO: Number of nodes with available pods: 3
Feb  6 03:00:02.687: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Set a daemon pod's phase to 'Failed', check that the daemon pod is revived.
Feb  6 03:00:02.745: INFO: Number of nodes with available pods: 2
Feb  6 03:00:02.745: INFO: Node 10.190.119.143 is running more than one daemon pod
Feb  6 03:00:03.767: INFO: Number of nodes with available pods: 2
Feb  6 03:00:03.767: INFO: Node 10.190.119.143 is running more than one daemon pod
Feb  6 03:00:04.773: INFO: Number of nodes with available pods: 3
Feb  6 03:00:04.773: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Wait for the failed daemon pod to be completely deleted.
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:64
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting {extensions DaemonSet} daemon-set in namespace e2e-tests-daemonsets-2z2sm, will wait for the garbage collector to delete the pods
Feb  6 03:00:04.885: INFO: Deleting {extensions DaemonSet} daemon-set took: 35.161971ms
Feb  6 03:00:04.985: INFO: Terminating {extensions DaemonSet} daemon-set pods took: 100.19652ms
Feb  6 03:00:48.814: INFO: Number of nodes with available pods: 0
Feb  6 03:00:48.814: INFO: Number of running nodes: 0, number of available pods: 0
Feb  6 03:00:48.824: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-2z2sm/daemonsets","resourceVersion":"66025"},"items":null}

Feb  6 03:00:48.832: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-2z2sm/pods","resourceVersion":"66025"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  6 03:00:48.881: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-2z2sm" for this suite.
Feb  6 03:00:56.920: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 03:00:57.106: INFO: namespace: e2e-tests-daemonsets-2z2sm, resource: bindings, ignored listing per whitelist
Feb  6 03:00:57.256: INFO: namespace e2e-tests-daemonsets-2z2sm deletion completed in 8.362640386s

• [SLOW TEST:56.982 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-network] Proxy version v1 
  should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] version v1
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  6 03:00:57.256: INFO: >>> kubeConfig: /tmp/kubeconfig-131423863
STEP: Building a namespace api object, basename proxy
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-proxy-t4nnc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: starting an echo server on multiple ports
STEP: creating replication controller proxy-service-65xpj in namespace e2e-tests-proxy-t4nnc
I0206 03:00:57.692955      15 runners.go:180] Created replication controller with name: proxy-service-65xpj, namespace: e2e-tests-proxy-t4nnc, replica count: 1
I0206 03:00:58.743454      15 runners.go:180] proxy-service-65xpj Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0206 03:00:59.743651      15 runners.go:180] proxy-service-65xpj Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0206 03:01:00.743882      15 runners.go:180] proxy-service-65xpj Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0206 03:01:01.744107      15 runners.go:180] proxy-service-65xpj Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0206 03:01:02.744330      15 runners.go:180] proxy-service-65xpj Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0206 03:01:03.744501      15 runners.go:180] proxy-service-65xpj Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Feb  6 03:01:03.771: INFO: setup took 6.161690244s, starting test cases
STEP: running 16 cases, 20 attempts per case, 320 total attempts
Feb  6 03:01:03.802: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-t4nnc/services/http:proxy-service-65xpj:portname1/proxy/: foo (200; 30.707222ms)
Feb  6 03:01:03.803: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-t4nnc/pods/proxy-service-65xpj-ws4xh/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-t4nnc/pods/proxy-service-65xpj-ws4xh/proxy/rewriteme"... (200; 31.211642ms)
Feb  6 03:01:03.803: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-t4nnc/pods/http:proxy-service-65xpj-ws4xh:160/proxy/: foo (200; 31.339394ms)
Feb  6 03:01:03.803: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-t4nnc/pods/proxy-service-65xpj-ws4xh:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-t4nnc/pods/proxy-service-65xpj-ws4xh:1080/proxy/rewri... (200; 31.591204ms)
Feb  6 03:01:03.807: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-t4nnc/pods/http:proxy-service-65xpj-ws4xh:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-t4nnc/pods/http:proxy-service-65xpj-ws4xh:1080/proxy/... (200; 35.332142ms)
Feb  6 03:01:03.807: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-t4nnc/pods/http:proxy-service-65xpj-ws4xh:162/proxy/: bar (200; 35.527977ms)
Feb  6 03:01:03.807: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-t4nnc/services/proxy-service-65xpj:portname1/proxy/: foo (200; 35.364939ms)
Feb  6 03:01:03.818: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-t4nnc/services/http:proxy-service-65xpj:portname2/proxy/: bar (200; 47.04795ms)
Feb  6 03:01:03.818: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-t4nnc/services/proxy-service-65xpj:portname2/proxy/: bar (200; 47.100469ms)
Feb  6 03:01:03.824: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-t4nnc/pods/https:proxy-service-65xpj-ws4xh:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-t4nnc/pods/https:proxy-service-65xpj-ws4xh:443/proxy/... (200; 52.385286ms)
Feb  6 03:01:03.829: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-t4nnc/pods/https:proxy-service-65xpj-ws4xh:460/proxy/: tls baz (200; 57.080515ms)
Feb  6 03:01:03.829: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-t4nnc/services/https:proxy-service-65xpj:tlsportname2/proxy/: tls qux (200; 57.071436ms)
Feb  6 03:01:03.829: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-t4nnc/pods/https:proxy-service-65xpj-ws4xh:462/proxy/: tls qux (200; 56.944582ms)
Feb  6 03:01:03.833: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-t4nnc/services/https:proxy-service-65xpj:tlsportname1/proxy/: tls baz (200; 61.927253ms)
Feb  6 03:01:04.008: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-t4nnc/pods/proxy-service-65xpj-ws4xh:162/proxy/: bar (200; 236.676398ms)
Feb  6 03:01:04.009: INFO: (0) /api/v1/namespaces/e2e-tests-proxy-t4nnc/pods/proxy-service-65xpj-ws4xh:160/proxy/: foo (200; 237.069036ms)
Feb  6 03:01:04.022: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-t4nnc/pods/http:proxy-service-65xpj-ws4xh:160/proxy/: foo (200; 13.675353ms)
Feb  6 03:01:04.026: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-t4nnc/pods/proxy-service-65xpj-ws4xh:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-t4nnc/pods/proxy-service-65xpj-ws4xh:1080/proxy/rewri... (200; 16.871591ms)
Feb  6 03:01:04.026: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-t4nnc/pods/https:proxy-service-65xpj-ws4xh:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-t4nnc/pods/https:proxy-service-65xpj-ws4xh:443/proxy/... (200; 17.256803ms)
Feb  6 03:01:04.026: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-t4nnc/pods/http:proxy-service-65xpj-ws4xh:162/proxy/: bar (200; 17.47883ms)
Feb  6 03:01:04.030: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-t4nnc/pods/proxy-service-65xpj-ws4xh:162/proxy/: bar (200; 20.394164ms)
Feb  6 03:01:04.030: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-t4nnc/pods/http:proxy-service-65xpj-ws4xh:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-t4nnc/pods/http:proxy-service-65xpj-ws4xh:1080/proxy/... (200; 20.708305ms)
Feb  6 03:01:04.029: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-t4nnc/pods/proxy-service-65xpj-ws4xh:160/proxy/: foo (200; 20.48917ms)
Feb  6 03:01:04.030: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-t4nnc/pods/https:proxy-service-65xpj-ws4xh:460/proxy/: tls baz (200; 21.196014ms)
Feb  6 03:01:04.030: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-t4nnc/pods/proxy-service-65xpj-ws4xh/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-t4nnc/pods/proxy-service-65xpj-ws4xh/proxy/rewriteme"... (200; 21.154587ms)
Feb  6 03:01:04.030: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-t4nnc/pods/https:proxy-service-65xpj-ws4xh:462/proxy/: tls qux (200; 21.096169ms)
Feb  6 03:01:04.032: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-t4nnc/services/https:proxy-service-65xpj:tlsportname1/proxy/: tls baz (200; 23.562636ms)
Feb  6 03:01:04.037: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-t4nnc/services/proxy-service-65xpj:portname2/proxy/: bar (200; 27.422543ms)
Feb  6 03:01:04.038: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-t4nnc/services/http:proxy-service-65xpj:portname2/proxy/: bar (200; 28.812111ms)
Feb  6 03:01:04.038: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-t4nnc/services/http:proxy-service-65xpj:portname1/proxy/: foo (200; 28.696374ms)
Feb  6 03:01:04.038: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-t4nnc/services/proxy-service-65xpj:portname1/proxy/: foo (200; 28.682098ms)
Feb  6 03:01:04.091: INFO: (1) /api/v1/namespaces/e2e-tests-proxy-t4nnc/services/https:proxy-service-65xpj:tlsportname2/proxy/: tls qux (200; 81.805544ms)
Feb  6 03:01:04.117: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-t4nnc/pods/http:proxy-service-65xpj-ws4xh:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-t4nnc/pods/http:proxy-service-65xpj-ws4xh:1080/proxy/... (200; 24.908159ms)
Feb  6 03:01:04.117: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-t4nnc/pods/proxy-service-65xpj-ws4xh:160/proxy/: foo (200; 25.272197ms)
Feb  6 03:01:04.117: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-t4nnc/pods/https:proxy-service-65xpj-ws4xh:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-t4nnc/pods/https:proxy-service-65xpj-ws4xh:443/proxy/... (200; 24.950994ms)
Feb  6 03:01:04.119: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-t4nnc/pods/https:proxy-service-65xpj-ws4xh:462/proxy/: tls qux (200; 27.784136ms)
Feb  6 03:01:04.119: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-t4nnc/services/https:proxy-service-65xpj:tlsportname2/proxy/: tls qux (200; 26.884622ms)
Feb  6 03:01:04.119: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-t4nnc/services/proxy-service-65xpj:portname1/proxy/: foo (200; 27.229951ms)
Feb  6 03:01:04.119: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-t4nnc/services/https:proxy-service-65xpj:tlsportname1/proxy/: tls baz (200; 27.968912ms)
Feb  6 03:01:04.119: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-t4nnc/pods/http:proxy-service-65xpj-ws4xh:160/proxy/: foo (200; 27.850062ms)
Feb  6 03:01:04.119: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-t4nnc/pods/proxy-service-65xpj-ws4xh/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-t4nnc/pods/proxy-service-65xpj-ws4xh/proxy/rewriteme"... (200; 27.23235ms)
Feb  6 03:01:04.119: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-t4nnc/pods/http:proxy-service-65xpj-ws4xh:162/proxy/: bar (200; 27.853679ms)
Feb  6 03:01:04.119: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-t4nnc/pods/proxy-service-65xpj-ws4xh:162/proxy/: bar (200; 27.145705ms)
Feb  6 03:01:04.120: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-t4nnc/pods/https:proxy-service-65xpj-ws4xh:460/proxy/: tls baz (200; 27.558727ms)
Feb  6 03:01:04.120: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-t4nnc/pods/proxy-service-65xpj-ws4xh:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-t4nnc/pods/proxy-service-65xpj-ws4xh:1080/proxy/rewri... (200; 28.218125ms)
Feb  6 03:01:04.122: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-t4nnc/services/proxy-service-65xpj:portname2/proxy/: bar (200; 30.687663ms)
Feb  6 03:01:04.122: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-t4nnc/services/http:proxy-service-65xpj:portname2/proxy/: bar (200; 30.618919ms)
Feb  6 03:01:04.123: INFO: (2) /api/v1/namespaces/e2e-tests-proxy-t4nnc/services/http:proxy-service-65xpj:portname1/proxy/: foo (200; 31.507413ms)
Feb  6 03:01:04.138: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-t4nnc/pods/http:proxy-service-65xpj-ws4xh:162/proxy/: bar (200; 14.669004ms)
Feb  6 03:01:04.140: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-t4nnc/pods/https:proxy-service-65xpj-ws4xh:462/proxy/: tls qux (200; 16.377866ms)
Feb  6 03:01:04.140: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-t4nnc/pods/http:proxy-service-65xpj-ws4xh:160/proxy/: foo (200; 16.697274ms)
Feb  6 03:01:04.140: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-t4nnc/pods/https:proxy-service-65xpj-ws4xh:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-t4nnc/pods/https:proxy-service-65xpj-ws4xh:443/proxy/... (200; 16.532778ms)
Feb  6 03:01:04.141: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-t4nnc/pods/http:proxy-service-65xpj-ws4xh:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-t4nnc/pods/http:proxy-service-65xpj-ws4xh:1080/proxy/... (200; 17.622157ms)
Feb  6 03:01:04.142: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-t4nnc/pods/proxy-service-65xpj-ws4xh:160/proxy/: foo (200; 18.099618ms)
Feb  6 03:01:04.142: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-t4nnc/pods/proxy-service-65xpj-ws4xh:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-t4nnc/pods/proxy-service-65xpj-ws4xh:1080/proxy/rewri... (200; 17.726207ms)
Feb  6 03:01:04.144: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-t4nnc/pods/https:proxy-service-65xpj-ws4xh:460/proxy/: tls baz (200; 20.039685ms)
Feb  6 03:01:04.144: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-t4nnc/pods/proxy-service-65xpj-ws4xh:162/proxy/: bar (200; 20.040954ms)
Feb  6 03:01:04.144: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-t4nnc/pods/proxy-service-65xpj-ws4xh/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-t4nnc/pods/proxy-service-65xpj-ws4xh/proxy/rewriteme"... (200; 20.259244ms)
Feb  6 03:01:04.149: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-t4nnc/services/https:proxy-service-65xpj:tlsportname1/proxy/: tls baz (200; 25.761726ms)
Feb  6 03:01:04.149: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-t4nnc/services/proxy-service-65xpj:portname2/proxy/: bar (200; 25.817753ms)
Feb  6 03:01:04.149: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-t4nnc/services/http:proxy-service-65xpj:portname1/proxy/: foo (200; 25.541581ms)
Feb  6 03:01:04.149: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-t4nnc/services/https:proxy-service-65xpj:tlsportname2/proxy/: tls qux (200; 25.656187ms)
Feb  6 03:01:04.149: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-t4nnc/services/proxy-service-65xpj:portname1/proxy/: foo (200; 25.73041ms)
Feb  6 03:01:04.152: INFO: (3) /api/v1/namespaces/e2e-tests-proxy-t4nnc/services/http:proxy-service-65xpj:portname2/proxy/: bar (200; 28.918515ms)
Feb  6 03:01:04.166: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-t4nnc/pods/proxy-service-65xpj-ws4xh/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-t4nnc/pods/proxy-service-65xpj-ws4xh/proxy/rewriteme"... (200; 13.495959ms)
Feb  6 03:01:04.170: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-t4nnc/pods/proxy-service-65xpj-ws4xh:162/proxy/: bar (200; 16.54072ms)
Feb  6 03:01:04.175: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-t4nnc/pods/http:proxy-service-65xpj-ws4xh:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-t4nnc/pods/http:proxy-service-65xpj-ws4xh:1080/proxy/... (200; 21.690249ms)
Feb  6 03:01:04.175: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-t4nnc/pods/proxy-service-65xpj-ws4xh:160/proxy/: foo (200; 21.870798ms)
Feb  6 03:01:04.175: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-t4nnc/pods/http:proxy-service-65xpj-ws4xh:162/proxy/: bar (200; 22.485253ms)
Feb  6 03:01:04.175: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-t4nnc/pods/https:proxy-service-65xpj-ws4xh:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-t4nnc/pods/https:proxy-service-65xpj-ws4xh:443/proxy/... (200; 21.999938ms)
Feb  6 03:01:04.175: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-t4nnc/pods/https:proxy-service-65xpj-ws4xh:460/proxy/: tls baz (200; 22.162489ms)
Feb  6 03:01:04.175: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-t4nnc/pods/https:proxy-service-65xpj-ws4xh:462/proxy/: tls qux (200; 21.858708ms)
Feb  6 03:01:04.177: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-t4nnc/pods/proxy-service-65xpj-ws4xh:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-t4nnc/pods/proxy-service-65xpj-ws4xh:1080/proxy/rewri... (200; 24.832224ms)
Feb  6 03:01:04.178: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-t4nnc/pods/http:proxy-service-65xpj-ws4xh:160/proxy/: foo (200; 25.081945ms)
Feb  6 03:01:04.184: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-t4nnc/services/http:proxy-service-65xpj:portname2/proxy/: bar (200; 31.228975ms)
Feb  6 03:01:04.184: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-t4nnc/services/https:proxy-service-65xpj:tlsportname2/proxy/: tls qux (200; 31.543359ms)
Feb  6 03:01:04.184: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-t4nnc/services/http:proxy-service-65xpj:portname1/proxy/: foo (200; 31.709405ms)
Feb  6 03:01:04.184: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-t4nnc/services/proxy-service-65xpj:portname2/proxy/: bar (200; 31.465621ms)
Feb  6 03:01:04.184: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-t4nnc/services/proxy-service-65xpj:portname1/proxy/: foo (200; 31.306733ms)
Feb  6 03:01:04.184: INFO: (4) /api/v1/namespaces/e2e-tests-proxy-t4nnc/services/https:proxy-service-65xpj:tlsportname1/proxy/: tls baz (200; 31.088218ms)
Feb  6 03:01:04.200: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-t4nnc/pods/https:proxy-service-65xpj-ws4xh:462/proxy/: tls qux (200; 15.82413ms)
Feb  6 03:01:04.211: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-t4nnc/pods/https:proxy-service-65xpj-ws4xh:460/proxy/: tls baz (200; 25.700412ms)
Feb  6 03:01:04.211: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-t4nnc/pods/https:proxy-service-65xpj-ws4xh:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-t4nnc/pods/https:proxy-service-65xpj-ws4xh:443/proxy/... (200; 25.651333ms)
Feb  6 03:01:04.211: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-t4nnc/pods/http:proxy-service-65xpj-ws4xh:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-t4nnc/pods/http:proxy-service-65xpj-ws4xh:1080/proxy/... (200; 25.761547ms)
Feb  6 03:01:04.211: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-t4nnc/pods/http:proxy-service-65xpj-ws4xh:160/proxy/: foo (200; 25.935477ms)
Feb  6 03:01:04.211: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-t4nnc/pods/proxy-service-65xpj-ws4xh/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-t4nnc/pods/proxy-service-65xpj-ws4xh/proxy/rewriteme"... (200; 26.325496ms)
Feb  6 03:01:04.213: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-t4nnc/pods/proxy-service-65xpj-ws4xh:162/proxy/: bar (200; 28.413643ms)
Feb  6 03:01:04.213: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-t4nnc/pods/proxy-service-65xpj-ws4xh:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-t4nnc/pods/proxy-service-65xpj-ws4xh:1080/proxy/rewri... (200; 28.433451ms)
Feb  6 03:01:04.213: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-t4nnc/pods/proxy-service-65xpj-ws4xh:160/proxy/: foo (200; 28.433296ms)
Feb  6 03:01:04.214: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-t4nnc/pods/http:proxy-service-65xpj-ws4xh:162/proxy/: bar (200; 29.017636ms)
Feb  6 03:01:04.217: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-t4nnc/services/https:proxy-service-65xpj:tlsportname1/proxy/: tls baz (200; 32.17296ms)
Feb  6 03:01:04.222: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-t4nnc/services/proxy-service-65xpj:portname1/proxy/: foo (200; 37.056436ms)
Feb  6 03:01:04.222: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-t4nnc/services/http:proxy-service-65xpj:portname2/proxy/: bar (200; 37.057631ms)
Feb  6 03:01:04.222: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-t4nnc/services/https:proxy-service-65xpj:tlsportname2/proxy/: tls qux (200; 37.665289ms)
Feb  6 03:01:04.222: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-t4nnc/services/proxy-service-65xpj:portname2/proxy/: bar (200; 37.43741ms)
Feb  6 03:01:04.222: INFO: (5) /api/v1/namespaces/e2e-tests-proxy-t4nnc/services/http:proxy-service-65xpj:portname1/proxy/: foo (200; 37.520831ms)
Feb  6 03:01:04.249: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-t4nnc/pods/http:proxy-service-65xpj-ws4xh:160/proxy/: foo (200; 26.010094ms)
Feb  6 03:01:04.249: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-t4nnc/pods/proxy-service-65xpj-ws4xh/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-t4nnc/pods/proxy-service-65xpj-ws4xh/proxy/rewriteme"... (200; 25.496267ms)
Feb  6 03:01:04.250: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-t4nnc/pods/https:proxy-service-65xpj-ws4xh:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-t4nnc/pods/https:proxy-service-65xpj-ws4xh:443/proxy/... (200; 25.221921ms)
Feb  6 03:01:04.251: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-t4nnc/pods/http:proxy-service-65xpj-ws4xh:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-t4nnc/pods/http:proxy-service-65xpj-ws4xh:1080/proxy/... (200; 26.364464ms)
Feb  6 03:01:04.253: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-t4nnc/pods/proxy-service-65xpj-ws4xh:160/proxy/: foo (200; 29.755143ms)
Feb  6 03:01:04.253: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-t4nnc/pods/https:proxy-service-65xpj-ws4xh:460/proxy/: tls baz (200; 28.847213ms)
Feb  6 03:01:04.253: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-t4nnc/pods/https:proxy-service-65xpj-ws4xh:462/proxy/: tls qux (200; 30.253746ms)
Feb  6 03:01:04.253: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-t4nnc/pods/proxy-service-65xpj-ws4xh:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-t4nnc/pods/proxy-service-65xpj-ws4xh:1080/proxy/rewri... (200; 30.13009ms)
Feb  6 03:01:04.254: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-t4nnc/pods/proxy-service-65xpj-ws4xh:162/proxy/: bar (200; 29.527936ms)
Feb  6 03:01:04.255: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-t4nnc/services/https:proxy-service-65xpj:tlsportname2/proxy/: tls qux (200; 30.79236ms)
Feb  6 03:01:04.259: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-t4nnc/pods/http:proxy-service-65xpj-ws4xh:162/proxy/: bar (200; 36.262229ms)
Feb  6 03:01:04.259: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-t4nnc/services/https:proxy-service-65xpj:tlsportname1/proxy/: tls baz (200; 36.57943ms)
Feb  6 03:01:04.260: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-t4nnc/services/http:proxy-service-65xpj:portname2/proxy/: bar (200; 36.09802ms)
Feb  6 03:01:04.266: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-t4nnc/services/http:proxy-service-65xpj:portname1/proxy/: foo (200; 42.398049ms)
Feb  6 03:01:04.266: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-t4nnc/services/proxy-service-65xpj:portname1/proxy/: foo (200; 42.004439ms)
Feb  6 03:01:04.266: INFO: (6) /api/v1/namespaces/e2e-tests-proxy-t4nnc/services/proxy-service-65xpj:portname2/proxy/: bar (200; 42.882491ms)
Feb  6 03:01:04.289: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-t4nnc/pods/proxy-service-65xpj-ws4xh:162/proxy/: bar (200; 21.431973ms)
Feb  6 03:01:04.291: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-t4nnc/pods/http:proxy-service-65xpj-ws4xh:160/proxy/: foo (200; 23.437545ms)
Feb  6 03:01:04.291: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-t4nnc/pods/https:proxy-service-65xpj-ws4xh:460/proxy/: tls baz (200; 24.513341ms)
Feb  6 03:01:04.291: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-t4nnc/pods/proxy-service-65xpj-ws4xh:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-t4nnc/pods/proxy-service-65xpj-ws4xh:1080/proxy/rewri... (200; 23.840483ms)
Feb  6 03:01:04.292: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-t4nnc/pods/proxy-service-65xpj-ws4xh/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-t4nnc/pods/proxy-service-65xpj-ws4xh/proxy/rewriteme"... (200; 24.967034ms)
Feb  6 03:01:04.296: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-t4nnc/pods/http:proxy-service-65xpj-ws4xh:162/proxy/: bar (200; 28.26154ms)
Feb  6 03:01:04.296: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-t4nnc/services/proxy-service-65xpj:portname1/proxy/: foo (200; 29.143431ms)
Feb  6 03:01:04.296: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-t4nnc/pods/http:proxy-service-65xpj-ws4xh:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-t4nnc/pods/http:proxy-service-65xpj-ws4xh:1080/proxy/... (200; 29.597211ms)
Feb  6 03:01:04.296: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-t4nnc/pods/proxy-service-65xpj-ws4xh:160/proxy/: foo (200; 28.922415ms)
Feb  6 03:01:04.296: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-t4nnc/pods/https:proxy-service-65xpj-ws4xh:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-t4nnc/pods/https:proxy-service-65xpj-ws4xh:443/proxy/... (200; 29.208489ms)
Feb  6 03:01:04.296: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-t4nnc/pods/https:proxy-service-65xpj-ws4xh:462/proxy/: tls qux (200; 29.862453ms)
Feb  6 03:01:04.299: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-t4nnc/services/https:proxy-service-65xpj:tlsportname1/proxy/: tls baz (200; 31.463744ms)
Feb  6 03:01:04.299: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-t4nnc/services/proxy-service-65xpj:portname2/proxy/: bar (200; 31.021753ms)
Feb  6 03:01:04.301: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-t4nnc/services/http:proxy-service-65xpj:portname2/proxy/: bar (200; 33.717243ms)
Feb  6 03:01:04.301: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-t4nnc/services/http:proxy-service-65xpj:portname1/proxy/: foo (200; 33.251084ms)
Feb  6 03:01:04.302: INFO: (7) /api/v1/namespaces/e2e-tests-proxy-t4nnc/services/https:proxy-service-65xpj:tlsportname2/proxy/: tls qux (200; 35.412206ms)
Feb  6 03:01:04.324: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-t4nnc/pods/http:proxy-service-65xpj-ws4xh:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-t4nnc/pods/http:proxy-service-65xpj-ws4xh:1080/proxy/... (200; 21.16563ms)
Feb  6 03:01:04.325: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-t4nnc/pods/https:proxy-service-65xpj-ws4xh:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-t4nnc/pods/https:proxy-service-65xpj-ws4xh:443/proxy/... (200; 21.778599ms)
Feb  6 03:01:04.325: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-t4nnc/pods/http:proxy-service-65xpj-ws4xh:160/proxy/: foo (200; 22.61794ms)
Feb  6 03:01:04.326: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-t4nnc/pods/https:proxy-service-65xpj-ws4xh:462/proxy/: tls qux (200; 22.551833ms)
Feb  6 03:01:04.326: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-t4nnc/pods/https:proxy-service-65xpj-ws4xh:460/proxy/: tls baz (200; 23.102667ms)
Feb  6 03:01:04.326: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-t4nnc/pods/proxy-service-65xpj-ws4xh:160/proxy/: foo (200; 23.316501ms)
Feb  6 03:01:04.327: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-t4nnc/pods/proxy-service-65xpj-ws4xh/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-t4nnc/pods/proxy-service-65xpj-ws4xh/proxy/rewriteme"... (200; 22.956278ms)
Feb  6 03:01:04.327: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-t4nnc/pods/proxy-service-65xpj-ws4xh:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-t4nnc/pods/proxy-service-65xpj-ws4xh:1080/proxy/rewri... (200; 24.869892ms)
Feb  6 03:01:04.328: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-t4nnc/pods/proxy-service-65xpj-ws4xh:162/proxy/: bar (200; 24.988879ms)
Feb  6 03:01:04.329: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-t4nnc/pods/http:proxy-service-65xpj-ws4xh:162/proxy/: bar (200; 25.695338ms)
Feb  6 03:01:04.333: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-t4nnc/services/https:proxy-service-65xpj:tlsportname2/proxy/: tls qux (200; 30.064058ms)
Feb  6 03:01:04.333: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-t4nnc/services/proxy-service-65xpj:portname1/proxy/: foo (200; 30.124185ms)
Feb  6 03:01:04.333: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-t4nnc/services/proxy-service-65xpj:portname2/proxy/: bar (200; 29.935188ms)
Feb  6 03:01:04.333: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-t4nnc/services/http:proxy-service-65xpj:portname2/proxy/: bar (200; 30.728352ms)
Feb  6 03:01:04.334: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-t4nnc/services/https:proxy-service-65xpj:tlsportname1/proxy/: tls baz (200; 30.25911ms)
Feb  6 03:01:04.334: INFO: (8) /api/v1/namespaces/e2e-tests-proxy-t4nnc/services/http:proxy-service-65xpj:portname1/proxy/: foo (200; 30.128984ms)
Feb  6 03:01:04.348: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-t4nnc/pods/proxy-service-65xpj-ws4xh:162/proxy/: bar (200; 14.195866ms)
Feb  6 03:01:04.353: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-t4nnc/pods/https:proxy-service-65xpj-ws4xh:462/proxy/: tls qux (200; 18.325764ms)
Feb  6 03:01:04.353: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-t4nnc/pods/proxy-service-65xpj-ws4xh/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-t4nnc/pods/proxy-service-65xpj-ws4xh/proxy/rewriteme"... (200; 18.638235ms)
Feb  6 03:01:04.353: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-t4nnc/pods/https:proxy-service-65xpj-ws4xh:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-t4nnc/pods/https:proxy-service-65xpj-ws4xh:443/proxy/... (200; 18.777411ms)
Feb  6 03:01:04.353: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-t4nnc/pods/http:proxy-service-65xpj-ws4xh:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-t4nnc/pods/http:proxy-service-65xpj-ws4xh:1080/proxy/... (200; 18.938982ms)
Feb  6 03:01:04.353: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-t4nnc/pods/http:proxy-service-65xpj-ws4xh:160/proxy/: foo (200; 19.068855ms)
Feb  6 03:01:04.353: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-t4nnc/pods/https:proxy-service-65xpj-ws4xh:460/proxy/: tls baz (200; 19.080506ms)
Feb  6 03:01:04.353: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-t4nnc/pods/proxy-service-65xpj-ws4xh:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-t4nnc/pods/proxy-service-65xpj-ws4xh:1080/proxy/rewri... (200; 19.515632ms)
Feb  6 03:01:04.353: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-t4nnc/pods/proxy-service-65xpj-ws4xh:160/proxy/: foo (200; 19.331949ms)
Feb  6 03:01:04.354: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-t4nnc/pods/http:proxy-service-65xpj-ws4xh:162/proxy/: bar (200; 19.586642ms)
Feb  6 03:01:04.357: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-t4nnc/services/http:proxy-service-65xpj:portname1/proxy/: foo (200; 23.106497ms)
Feb  6 03:01:04.359: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-t4nnc/services/proxy-service-65xpj:portname2/proxy/: bar (200; 25.248124ms)
Feb  6 03:01:04.360: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-t4nnc/services/https:proxy-service-65xpj:tlsportname1/proxy/: tls baz (200; 25.332849ms)
Feb  6 03:01:04.360: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-t4nnc/services/https:proxy-service-65xpj:tlsportname2/proxy/: tls qux (200; 25.987216ms)
Feb  6 03:01:04.360: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-t4nnc/services/http:proxy-service-65xpj:portname2/proxy/: bar (200; 25.757946ms)
Feb  6 03:01:04.360: INFO: (9) /api/v1/namespaces/e2e-tests-proxy-t4nnc/services/proxy-service-65xpj:portname1/proxy/: foo (200; 25.557086ms)
Feb  6 03:01:04.373: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-t4nnc/pods/https:proxy-service-65xpj-ws4xh:462/proxy/: tls qux (200; 12.631597ms)
Feb  6 03:01:04.373: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-t4nnc/pods/http:proxy-service-65xpj-ws4xh:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-t4nnc/pods/http:proxy-service-65xpj-ws4xh:1080/proxy/... (200; 12.912607ms)
Feb  6 03:01:04.378: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-t4nnc/pods/proxy-service-65xpj-ws4xh:160/proxy/: foo (200; 17.297363ms)
Feb  6 03:01:04.378: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-t4nnc/pods/proxy-service-65xpj-ws4xh:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-t4nnc/pods/proxy-service-65xpj-ws4xh:1080/proxy/rewri... (200; 17.570908ms)
Feb  6 03:01:04.379: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-t4nnc/pods/proxy-service-65xpj-ws4xh/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-t4nnc/pods/proxy-service-65xpj-ws4xh/proxy/rewriteme"... (200; 18.094744ms)
Feb  6 03:01:04.379: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-t4nnc/pods/https:proxy-service-65xpj-ws4xh:460/proxy/: tls baz (200; 18.274967ms)
Feb  6 03:01:04.379: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-t4nnc/pods/http:proxy-service-65xpj-ws4xh:162/proxy/: bar (200; 18.348678ms)
Feb  6 03:01:04.379: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-t4nnc/pods/https:proxy-service-65xpj-ws4xh:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-t4nnc/pods/https:proxy-service-65xpj-ws4xh:443/proxy/... (200; 18.493049ms)
Feb  6 03:01:04.379: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-t4nnc/pods/http:proxy-service-65xpj-ws4xh:160/proxy/: foo (200; 18.50269ms)
Feb  6 03:01:04.379: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-t4nnc/pods/proxy-service-65xpj-ws4xh:162/proxy/: bar (200; 18.777649ms)
Feb  6 03:01:04.382: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-t4nnc/services/http:proxy-service-65xpj:portname1/proxy/: foo (200; 21.867328ms)
Feb  6 03:01:04.385: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-t4nnc/services/https:proxy-service-65xpj:tlsportname1/proxy/: tls baz (200; 24.211503ms)
Feb  6 03:01:04.385: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-t4nnc/services/http:proxy-service-65xpj:portname2/proxy/: bar (200; 24.185542ms)
Feb  6 03:01:04.385: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-t4nnc/services/proxy-service-65xpj:portname2/proxy/: bar (200; 24.349979ms)
Feb  6 03:01:04.386: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-t4nnc/services/proxy-service-65xpj:portname1/proxy/: foo (200; 25.544588ms)
Feb  6 03:01:04.387: INFO: (10) /api/v1/namespaces/e2e-tests-proxy-t4nnc/services/https:proxy-service-65xpj:tlsportname2/proxy/: tls qux (200; 26.42084ms)
Feb  6 03:01:04.400: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-t4nnc/pods/https:proxy-service-65xpj-ws4xh:462/proxy/: tls qux (200; 13.226953ms)
Feb  6 03:01:04.406: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-t4nnc/pods/http:proxy-service-65xpj-ws4xh:162/proxy/: bar (200; 18.873464ms)
Feb  6 03:01:04.407: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-t4nnc/pods/proxy-service-65xpj-ws4xh:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-t4nnc/pods/proxy-service-65xpj-ws4xh:1080/proxy/rewri... (200; 19.804496ms)
Feb  6 03:01:04.407: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-t4nnc/pods/proxy-service-65xpj-ws4xh/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-t4nnc/pods/proxy-service-65xpj-ws4xh/proxy/rewriteme"... (200; 19.719012ms)
Feb  6 03:01:04.407: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-t4nnc/pods/http:proxy-service-65xpj-ws4xh:160/proxy/: foo (200; 20.040691ms)
Feb  6 03:01:04.407: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-t4nnc/pods/https:proxy-service-65xpj-ws4xh:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-t4nnc/pods/https:proxy-service-65xpj-ws4xh:443/proxy/... (200; 19.778437ms)
Feb  6 03:01:04.408: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-t4nnc/pods/proxy-service-65xpj-ws4xh:162/proxy/: bar (200; 20.16371ms)
Feb  6 03:01:04.408: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-t4nnc/pods/https:proxy-service-65xpj-ws4xh:460/proxy/: tls baz (200; 20.237414ms)
Feb  6 03:01:04.408: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-t4nnc/pods/http:proxy-service-65xpj-ws4xh:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-t4nnc/pods/http:proxy-service-65xpj-ws4xh:1080/proxy/... (200; 20.310089ms)
Feb  6 03:01:04.408: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-t4nnc/pods/proxy-service-65xpj-ws4xh:160/proxy/: foo (200; 20.055748ms)
Feb  6 03:01:04.412: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-t4nnc/services/https:proxy-service-65xpj:tlsportname1/proxy/: tls baz (200; 24.70937ms)
Feb  6 03:01:04.412: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-t4nnc/services/proxy-service-65xpj:portname1/proxy/: foo (200; 24.970652ms)
Feb  6 03:01:04.412: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-t4nnc/services/http:proxy-service-65xpj:portname1/proxy/: foo (200; 24.770908ms)
Feb  6 03:01:04.412: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-t4nnc/services/proxy-service-65xpj:portname2/proxy/: bar (200; 24.866382ms)
Feb  6 03:01:04.412: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-t4nnc/services/http:proxy-service-65xpj:portname2/proxy/: bar (200; 24.761205ms)
Feb  6 03:01:04.413: INFO: (11) /api/v1/namespaces/e2e-tests-proxy-t4nnc/services/https:proxy-service-65xpj:tlsportname2/proxy/: tls qux (200; 25.396489ms)
Feb  6 03:01:04.426: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-t4nnc/pods/proxy-service-65xpj-ws4xh/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-t4nnc/pods/proxy-service-65xpj-ws4xh/proxy/rewriteme"... (200; 13.052503ms)
Feb  6 03:01:04.431: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-t4nnc/pods/https:proxy-service-65xpj-ws4xh:462/proxy/: tls qux (200; 17.627326ms)
Feb  6 03:01:04.431: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-t4nnc/pods/proxy-service-65xpj-ws4xh:162/proxy/: bar (200; 17.440954ms)
Feb  6 03:01:04.431: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-t4nnc/pods/https:proxy-service-65xpj-ws4xh:460/proxy/: tls baz (200; 18.453821ms)
Feb  6 03:01:04.432: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-t4nnc/pods/https:proxy-service-65xpj-ws4xh:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-t4nnc/pods/https:proxy-service-65xpj-ws4xh:443/proxy/... (200; 19.155525ms)
Feb  6 03:01:04.435: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-t4nnc/pods/proxy-service-65xpj-ws4xh:160/proxy/: foo (200; 21.655166ms)
Feb  6 03:01:04.435: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-t4nnc/pods/http:proxy-service-65xpj-ws4xh:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-t4nnc/pods/http:proxy-service-65xpj-ws4xh:1080/proxy/... (200; 21.946119ms)
Feb  6 03:01:04.435: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-t4nnc/pods/http:proxy-service-65xpj-ws4xh:160/proxy/: foo (200; 21.814511ms)
Feb  6 03:01:04.439: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-t4nnc/pods/proxy-service-65xpj-ws4xh:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-t4nnc/pods/proxy-service-65xpj-ws4xh:1080/proxy/rewri... (200; 25.791424ms)
Feb  6 03:01:04.439: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-t4nnc/pods/http:proxy-service-65xpj-ws4xh:162/proxy/: bar (200; 25.971833ms)
Feb  6 03:01:04.443: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-t4nnc/services/https:proxy-service-65xpj:tlsportname2/proxy/: tls qux (200; 29.647778ms)
Feb  6 03:01:04.446: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-t4nnc/services/http:proxy-service-65xpj:portname1/proxy/: foo (200; 32.521959ms)
Feb  6 03:01:04.446: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-t4nnc/services/proxy-service-65xpj:portname2/proxy/: bar (200; 32.709959ms)
Feb  6 03:01:04.446: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-t4nnc/services/http:proxy-service-65xpj:portname2/proxy/: bar (200; 32.705508ms)
Feb  6 03:01:04.447: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-t4nnc/services/https:proxy-service-65xpj:tlsportname1/proxy/: tls baz (200; 33.712038ms)
Feb  6 03:01:04.447: INFO: (12) /api/v1/namespaces/e2e-tests-proxy-t4nnc/services/proxy-service-65xpj:portname1/proxy/: foo (200; 33.523989ms)
Feb  6 03:01:04.462: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-t4nnc/pods/https:proxy-service-65xpj-ws4xh:462/proxy/: tls qux (200; 15.310487ms)
Feb  6 03:01:04.466: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-t4nnc/pods/https:proxy-service-65xpj-ws4xh:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-t4nnc/pods/https:proxy-service-65xpj-ws4xh:443/proxy/... (200; 18.845348ms)
Feb  6 03:01:04.467: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-t4nnc/pods/proxy-service-65xpj-ws4xh:160/proxy/: foo (200; 20.129244ms)
Feb  6 03:01:04.467: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-t4nnc/pods/https:proxy-service-65xpj-ws4xh:460/proxy/: tls baz (200; 20.135012ms)
Feb  6 03:01:04.467: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-t4nnc/pods/http:proxy-service-65xpj-ws4xh:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-t4nnc/pods/http:proxy-service-65xpj-ws4xh:1080/proxy/... (200; 20.117509ms)
Feb  6 03:01:04.467: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-t4nnc/pods/proxy-service-65xpj-ws4xh:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-t4nnc/pods/proxy-service-65xpj-ws4xh:1080/proxy/rewri... (200; 20.534061ms)
Feb  6 03:01:04.468: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-t4nnc/pods/http:proxy-service-65xpj-ws4xh:160/proxy/: foo (200; 20.835063ms)
Feb  6 03:01:04.467: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-t4nnc/pods/proxy-service-65xpj-ws4xh/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-t4nnc/pods/proxy-service-65xpj-ws4xh/proxy/rewriteme"... (200; 20.017758ms)
Feb  6 03:01:04.468: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-t4nnc/pods/proxy-service-65xpj-ws4xh:162/proxy/: bar (200; 20.33865ms)
Feb  6 03:01:04.468: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-t4nnc/pods/http:proxy-service-65xpj-ws4xh:162/proxy/: bar (200; 20.673501ms)
Feb  6 03:01:04.474: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-t4nnc/services/proxy-service-65xpj:portname1/proxy/: foo (200; 27.263081ms)
Feb  6 03:01:04.475: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-t4nnc/services/https:proxy-service-65xpj:tlsportname2/proxy/: tls qux (200; 28.065298ms)
Feb  6 03:01:04.475: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-t4nnc/services/http:proxy-service-65xpj:portname2/proxy/: bar (200; 28.228511ms)
Feb  6 03:01:04.478: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-t4nnc/services/https:proxy-service-65xpj:tlsportname1/proxy/: tls baz (200; 30.694234ms)
Feb  6 03:01:04.478: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-t4nnc/services/http:proxy-service-65xpj:portname1/proxy/: foo (200; 30.523774ms)
Feb  6 03:01:04.478: INFO: (13) /api/v1/namespaces/e2e-tests-proxy-t4nnc/services/proxy-service-65xpj:portname2/proxy/: bar (200; 30.634478ms)
Feb  6 03:01:04.497: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-t4nnc/pods/http:proxy-service-65xpj-ws4xh:162/proxy/: bar (200; 18.299303ms)
Feb  6 03:01:04.497: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-t4nnc/pods/https:proxy-service-65xpj-ws4xh:460/proxy/: tls baz (200; 17.85493ms)
Feb  6 03:01:04.497: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-t4nnc/pods/proxy-service-65xpj-ws4xh:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-t4nnc/pods/proxy-service-65xpj-ws4xh:1080/proxy/rewri... (200; 17.57356ms)
Feb  6 03:01:04.497: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-t4nnc/pods/https:proxy-service-65xpj-ws4xh:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-t4nnc/pods/https:proxy-service-65xpj-ws4xh:443/proxy/... (200; 17.811081ms)
Feb  6 03:01:04.497: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-t4nnc/pods/https:proxy-service-65xpj-ws4xh:462/proxy/: tls qux (200; 17.911044ms)
Feb  6 03:01:04.497: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-t4nnc/pods/proxy-service-65xpj-ws4xh:162/proxy/: bar (200; 18.303204ms)
Feb  6 03:01:04.497: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-t4nnc/pods/http:proxy-service-65xpj-ws4xh:160/proxy/: foo (200; 18.705511ms)
Feb  6 03:01:04.497: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-t4nnc/pods/http:proxy-service-65xpj-ws4xh:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-t4nnc/pods/http:proxy-service-65xpj-ws4xh:1080/proxy/... (200; 18.27946ms)
Feb  6 03:01:04.497: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-t4nnc/pods/proxy-service-65xpj-ws4xh/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-t4nnc/pods/proxy-service-65xpj-ws4xh/proxy/rewriteme"... (200; 18.445966ms)
Feb  6 03:01:04.499: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-t4nnc/pods/proxy-service-65xpj-ws4xh:160/proxy/: foo (200; 21.012107ms)
Feb  6 03:01:04.499: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-t4nnc/services/https:proxy-service-65xpj:tlsportname2/proxy/: tls qux (200; 21.39148ms)
Feb  6 03:01:04.513: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-t4nnc/services/proxy-service-65xpj:portname1/proxy/: foo (200; 34.825188ms)
Feb  6 03:01:04.518: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-t4nnc/services/https:proxy-service-65xpj:tlsportname1/proxy/: tls baz (200; 38.68669ms)
Feb  6 03:01:04.518: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-t4nnc/services/http:proxy-service-65xpj:portname2/proxy/: bar (200; 39.650658ms)
Feb  6 03:01:04.518: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-t4nnc/services/http:proxy-service-65xpj:portname1/proxy/: foo (200; 39.892072ms)
Feb  6 03:01:04.538: INFO: (14) /api/v1/namespaces/e2e-tests-proxy-t4nnc/services/proxy-service-65xpj:portname2/proxy/: bar (200; 60.404306ms)
Feb  6 03:01:04.553: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-t4nnc/pods/proxy-service-65xpj-ws4xh:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-t4nnc/pods/proxy-service-65xpj-ws4xh:1080/proxy/rewri... (200; 14.20512ms)
Feb  6 03:01:04.557: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-t4nnc/pods/https:proxy-service-65xpj-ws4xh:460/proxy/: tls baz (200; 17.647758ms)
Feb  6 03:01:04.558: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-t4nnc/pods/proxy-service-65xpj-ws4xh:160/proxy/: foo (200; 18.778785ms)
Feb  6 03:01:04.558: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-t4nnc/pods/http:proxy-service-65xpj-ws4xh:160/proxy/: foo (200; 18.823128ms)
Feb  6 03:01:04.558: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-t4nnc/pods/https:proxy-service-65xpj-ws4xh:462/proxy/: tls qux (200; 18.958293ms)
Feb  6 03:01:04.559: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-t4nnc/pods/http:proxy-service-65xpj-ws4xh:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-t4nnc/pods/http:proxy-service-65xpj-ws4xh:1080/proxy/... (200; 19.656085ms)
Feb  6 03:01:04.559: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-t4nnc/pods/https:proxy-service-65xpj-ws4xh:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-t4nnc/pods/https:proxy-service-65xpj-ws4xh:443/proxy/... (200; 19.973464ms)
Feb  6 03:01:04.560: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-t4nnc/pods/proxy-service-65xpj-ws4xh:162/proxy/: bar (200; 21.019734ms)
Feb  6 03:01:04.560: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-t4nnc/pods/proxy-service-65xpj-ws4xh/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-t4nnc/pods/proxy-service-65xpj-ws4xh/proxy/rewriteme"... (200; 21.130411ms)
Feb  6 03:01:04.560: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-t4nnc/pods/http:proxy-service-65xpj-ws4xh:162/proxy/: bar (200; 20.63746ms)
Feb  6 03:01:04.564: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-t4nnc/services/http:proxy-service-65xpj:portname1/proxy/: foo (200; 24.800208ms)
Feb  6 03:01:04.564: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-t4nnc/services/proxy-service-65xpj:portname1/proxy/: foo (200; 24.553877ms)
Feb  6 03:01:04.564: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-t4nnc/services/proxy-service-65xpj:portname2/proxy/: bar (200; 24.339352ms)
Feb  6 03:01:04.564: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-t4nnc/services/https:proxy-service-65xpj:tlsportname2/proxy/: tls qux (200; 25.021096ms)
Feb  6 03:01:04.564: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-t4nnc/services/https:proxy-service-65xpj:tlsportname1/proxy/: tls baz (200; 24.691802ms)
Feb  6 03:01:04.564: INFO: (15) /api/v1/namespaces/e2e-tests-proxy-t4nnc/services/http:proxy-service-65xpj:portname2/proxy/: bar (200; 24.882931ms)
Feb  6 03:01:04.583: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-t4nnc/pods/https:proxy-service-65xpj-ws4xh:460/proxy/: tls baz (200; 18.567512ms)
Feb  6 03:01:04.587: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-t4nnc/pods/proxy-service-65xpj-ws4xh/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-t4nnc/pods/proxy-service-65xpj-ws4xh/proxy/rewriteme"... (200; 22.09315ms)
Feb  6 03:01:04.588: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-t4nnc/pods/https:proxy-service-65xpj-ws4xh:462/proxy/: tls qux (200; 22.826783ms)
Feb  6 03:01:04.588: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-t4nnc/pods/https:proxy-service-65xpj-ws4xh:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-t4nnc/pods/https:proxy-service-65xpj-ws4xh:443/proxy/... (200; 22.892759ms)
Feb  6 03:01:04.588: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-t4nnc/pods/proxy-service-65xpj-ws4xh:162/proxy/: bar (200; 23.404705ms)
Feb  6 03:01:04.588: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-t4nnc/pods/http:proxy-service-65xpj-ws4xh:162/proxy/: bar (200; 23.897698ms)
Feb  6 03:01:04.589: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-t4nnc/pods/http:proxy-service-65xpj-ws4xh:160/proxy/: foo (200; 23.569652ms)
Feb  6 03:01:04.589: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-t4nnc/pods/proxy-service-65xpj-ws4xh:160/proxy/: foo (200; 23.797563ms)
Feb  6 03:01:04.589: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-t4nnc/pods/proxy-service-65xpj-ws4xh:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-t4nnc/pods/proxy-service-65xpj-ws4xh:1080/proxy/rewri... (200; 24.545501ms)
Feb  6 03:01:04.589: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-t4nnc/pods/http:proxy-service-65xpj-ws4xh:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-t4nnc/pods/http:proxy-service-65xpj-ws4xh:1080/proxy/... (200; 24.194201ms)
Feb  6 03:01:04.592: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-t4nnc/services/proxy-service-65xpj:portname1/proxy/: foo (200; 27.398713ms)
Feb  6 03:01:04.601: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-t4nnc/services/http:proxy-service-65xpj:portname2/proxy/: bar (200; 36.045048ms)
Feb  6 03:01:04.601: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-t4nnc/services/proxy-service-65xpj:portname2/proxy/: bar (200; 36.14624ms)
Feb  6 03:01:04.601: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-t4nnc/services/https:proxy-service-65xpj:tlsportname2/proxy/: tls qux (200; 36.958924ms)
Feb  6 03:01:04.601: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-t4nnc/services/http:proxy-service-65xpj:portname1/proxy/: foo (200; 36.727128ms)
Feb  6 03:01:04.601: INFO: (16) /api/v1/namespaces/e2e-tests-proxy-t4nnc/services/https:proxy-service-65xpj:tlsportname1/proxy/: tls baz (200; 36.482143ms)
Feb  6 03:01:04.614: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-t4nnc/pods/proxy-service-65xpj-ws4xh:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-t4nnc/pods/proxy-service-65xpj-ws4xh:1080/proxy/rewri... (200; 12.174645ms)
Feb  6 03:01:04.620: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-t4nnc/pods/https:proxy-service-65xpj-ws4xh:460/proxy/: tls baz (200; 18.457215ms)
Feb  6 03:01:04.621: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-t4nnc/pods/http:proxy-service-65xpj-ws4xh:160/proxy/: foo (200; 18.831703ms)
Feb  6 03:01:04.621: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-t4nnc/pods/proxy-service-65xpj-ws4xh:160/proxy/: foo (200; 18.896275ms)
Feb  6 03:01:04.621: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-t4nnc/pods/proxy-service-65xpj-ws4xh/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-t4nnc/pods/proxy-service-65xpj-ws4xh/proxy/rewriteme"... (200; 18.681643ms)
Feb  6 03:01:04.621: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-t4nnc/pods/https:proxy-service-65xpj-ws4xh:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-t4nnc/pods/https:proxy-service-65xpj-ws4xh:443/proxy/... (200; 18.938755ms)
Feb  6 03:01:04.621: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-t4nnc/pods/proxy-service-65xpj-ws4xh:162/proxy/: bar (200; 19.002225ms)
Feb  6 03:01:04.621: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-t4nnc/pods/http:proxy-service-65xpj-ws4xh:162/proxy/: bar (200; 19.213285ms)
Feb  6 03:01:04.621: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-t4nnc/pods/http:proxy-service-65xpj-ws4xh:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-t4nnc/pods/http:proxy-service-65xpj-ws4xh:1080/proxy/... (200; 18.935109ms)
Feb  6 03:01:04.621: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-t4nnc/pods/https:proxy-service-65xpj-ws4xh:462/proxy/: tls qux (200; 18.883218ms)
Feb  6 03:01:04.624: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-t4nnc/services/proxy-service-65xpj:portname1/proxy/: foo (200; 22.793993ms)
Feb  6 03:01:04.631: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-t4nnc/services/http:proxy-service-65xpj:portname1/proxy/: foo (200; 29.47859ms)
Feb  6 03:01:04.631: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-t4nnc/services/proxy-service-65xpj:portname2/proxy/: bar (200; 29.705176ms)
Feb  6 03:01:04.632: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-t4nnc/services/https:proxy-service-65xpj:tlsportname2/proxy/: tls qux (200; 30.112325ms)
Feb  6 03:01:04.632: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-t4nnc/services/http:proxy-service-65xpj:portname2/proxy/: bar (200; 29.939586ms)
Feb  6 03:01:04.632: INFO: (17) /api/v1/namespaces/e2e-tests-proxy-t4nnc/services/https:proxy-service-65xpj:tlsportname1/proxy/: tls baz (200; 29.860313ms)
Feb  6 03:01:04.653: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-t4nnc/pods/proxy-service-65xpj-ws4xh:162/proxy/: bar (200; 20.829477ms)
Feb  6 03:01:04.653: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-t4nnc/pods/https:proxy-service-65xpj-ws4xh:460/proxy/: tls baz (200; 21.053124ms)
Feb  6 03:01:04.653: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-t4nnc/pods/proxy-service-65xpj-ws4xh/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-t4nnc/pods/proxy-service-65xpj-ws4xh/proxy/rewriteme"... (200; 21.147436ms)
Feb  6 03:01:04.653: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-t4nnc/pods/proxy-service-65xpj-ws4xh:160/proxy/: foo (200; 20.98284ms)
Feb  6 03:01:04.653: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-t4nnc/pods/https:proxy-service-65xpj-ws4xh:462/proxy/: tls qux (200; 21.027808ms)
Feb  6 03:01:04.653: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-t4nnc/pods/http:proxy-service-65xpj-ws4xh:160/proxy/: foo (200; 20.993785ms)
Feb  6 03:01:04.654: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-t4nnc/pods/https:proxy-service-65xpj-ws4xh:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-t4nnc/pods/https:proxy-service-65xpj-ws4xh:443/proxy/... (200; 21.21916ms)
Feb  6 03:01:04.654: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-t4nnc/pods/proxy-service-65xpj-ws4xh:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-t4nnc/pods/proxy-service-65xpj-ws4xh:1080/proxy/rewri... (200; 21.577744ms)
Feb  6 03:01:04.654: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-t4nnc/pods/http:proxy-service-65xpj-ws4xh:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-t4nnc/pods/http:proxy-service-65xpj-ws4xh:1080/proxy/... (200; 21.38151ms)
Feb  6 03:01:04.654: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-t4nnc/pods/http:proxy-service-65xpj-ws4xh:162/proxy/: bar (200; 21.125256ms)
Feb  6 03:01:04.657: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-t4nnc/services/https:proxy-service-65xpj:tlsportname2/proxy/: tls qux (200; 25.069943ms)
Feb  6 03:01:04.657: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-t4nnc/services/http:proxy-service-65xpj:portname1/proxy/: foo (200; 25.614505ms)
Feb  6 03:01:04.661: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-t4nnc/services/proxy-service-65xpj:portname1/proxy/: foo (200; 29.236336ms)
Feb  6 03:01:04.662: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-t4nnc/services/http:proxy-service-65xpj:portname2/proxy/: bar (200; 29.362988ms)
Feb  6 03:01:04.662: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-t4nnc/services/proxy-service-65xpj:portname2/proxy/: bar (200; 29.584007ms)
Feb  6 03:01:04.662: INFO: (18) /api/v1/namespaces/e2e-tests-proxy-t4nnc/services/https:proxy-service-65xpj:tlsportname1/proxy/: tls baz (200; 30.158255ms)
Feb  6 03:01:04.678: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-t4nnc/pods/http:proxy-service-65xpj-ws4xh:162/proxy/: bar (200; 15.568877ms)
Feb  6 03:01:04.678: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-t4nnc/pods/https:proxy-service-65xpj-ws4xh:462/proxy/: tls qux (200; 15.392139ms)
Feb  6 03:01:04.683: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-t4nnc/pods/proxy-service-65xpj-ws4xh/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-t4nnc/pods/proxy-service-65xpj-ws4xh/proxy/rewriteme"... (200; 20.088623ms)
Feb  6 03:01:04.683: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-t4nnc/pods/proxy-service-65xpj-ws4xh:162/proxy/: bar (200; 20.207089ms)
Feb  6 03:01:04.683: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-t4nnc/pods/https:proxy-service-65xpj-ws4xh:443/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-t4nnc/pods/https:proxy-service-65xpj-ws4xh:443/proxy/... (200; 20.382855ms)
Feb  6 03:01:04.683: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-t4nnc/pods/proxy-service-65xpj-ws4xh:160/proxy/: foo (200; 20.06149ms)
Feb  6 03:01:04.684: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-t4nnc/pods/https:proxy-service-65xpj-ws4xh:460/proxy/: tls baz (200; 20.56394ms)
Feb  6 03:01:04.684: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-t4nnc/pods/http:proxy-service-65xpj-ws4xh:160/proxy/: foo (200; 20.264775ms)
Feb  6 03:01:04.684: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-t4nnc/pods/http:proxy-service-65xpj-ws4xh:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-t4nnc/pods/http:proxy-service-65xpj-ws4xh:1080/proxy/... (200; 20.804805ms)
Feb  6 03:01:04.684: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-t4nnc/pods/proxy-service-65xpj-ws4xh:1080/proxy/: <a href="/api/v1/namespaces/e2e-tests-proxy-t4nnc/pods/proxy-service-65xpj-ws4xh:1080/proxy/rewri... (200; 20.963163ms)
Feb  6 03:01:04.686: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-t4nnc/services/https:proxy-service-65xpj:tlsportname2/proxy/: tls qux (200; 22.951704ms)
Feb  6 03:01:04.690: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-t4nnc/services/https:proxy-service-65xpj:tlsportname1/proxy/: tls baz (200; 27.795377ms)
Feb  6 03:01:04.690: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-t4nnc/services/http:proxy-service-65xpj:portname1/proxy/: foo (200; 27.722185ms)
Feb  6 03:01:04.691: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-t4nnc/services/proxy-service-65xpj:portname1/proxy/: foo (200; 27.786573ms)
Feb  6 03:01:04.691: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-t4nnc/services/http:proxy-service-65xpj:portname2/proxy/: bar (200; 27.67998ms)
Feb  6 03:01:04.691: INFO: (19) /api/v1/namespaces/e2e-tests-proxy-t4nnc/services/proxy-service-65xpj:portname2/proxy/: bar (200; 27.819096ms)
STEP: deleting { ReplicationController} proxy-service-65xpj in namespace e2e-tests-proxy-t4nnc, will wait for the garbage collector to delete the pods
Feb  6 03:01:04.777: INFO: Deleting { ReplicationController} proxy-service-65xpj took: 26.18719ms
Feb  6 03:01:04.877: INFO: Terminating { ReplicationController} proxy-service-65xpj pods took: 100.232443ms
[AfterEach] version v1
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  6 03:01:18.078: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-proxy-t4nnc" for this suite.
Feb  6 03:01:24.151: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 03:01:24.477: INFO: namespace: e2e-tests-proxy-t4nnc, resource: bindings, ignored listing per whitelist
Feb  6 03:01:24.606: INFO: namespace e2e-tests-proxy-t4nnc deletion completed in 6.481719395s

• [SLOW TEST:27.350 seconds]
[sig-network] Proxy
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy through a service and a pod  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  6 03:01:24.606: INFO: >>> kubeConfig: /tmp/kubeconfig-131423863
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-daemonsets-z7xxh
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:98
[It] should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb  6 03:01:25.022: INFO: Creating simple daemon set daemon-set
STEP: Check that daemon pods launch on every node of the cluster.
Feb  6 03:01:25.061: INFO: Number of nodes with available pods: 0
Feb  6 03:01:25.062: INFO: Node 10.190.119.133 is running more than one daemon pod
Feb  6 03:01:26.091: INFO: Number of nodes with available pods: 0
Feb  6 03:01:26.091: INFO: Node 10.190.119.133 is running more than one daemon pod
Feb  6 03:01:27.101: INFO: Number of nodes with available pods: 1
Feb  6 03:01:27.101: INFO: Node 10.190.119.133 is running more than one daemon pod
Feb  6 03:01:28.088: INFO: Number of nodes with available pods: 3
Feb  6 03:01:28.088: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Update daemon pods image.
STEP: Check that daemon pods images are updated.
Feb  6 03:01:28.173: INFO: Wrong image for pod: daemon-set-9njtt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:01:28.173: INFO: Wrong image for pod: daemon-set-mjmss. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:01:28.173: INFO: Wrong image for pod: daemon-set-xt4bf. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:01:29.194: INFO: Wrong image for pod: daemon-set-9njtt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:01:29.194: INFO: Wrong image for pod: daemon-set-mjmss. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:01:29.194: INFO: Wrong image for pod: daemon-set-xt4bf. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:01:30.194: INFO: Wrong image for pod: daemon-set-9njtt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:01:30.194: INFO: Wrong image for pod: daemon-set-mjmss. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:01:30.194: INFO: Wrong image for pod: daemon-set-xt4bf. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:01:31.196: INFO: Wrong image for pod: daemon-set-9njtt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:01:31.196: INFO: Wrong image for pod: daemon-set-mjmss. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:01:31.196: INFO: Wrong image for pod: daemon-set-xt4bf. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:01:32.194: INFO: Wrong image for pod: daemon-set-9njtt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:01:32.194: INFO: Wrong image for pod: daemon-set-mjmss. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:01:32.194: INFO: Wrong image for pod: daemon-set-xt4bf. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:01:33.195: INFO: Wrong image for pod: daemon-set-9njtt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:01:33.195: INFO: Wrong image for pod: daemon-set-mjmss. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:01:33.195: INFO: Wrong image for pod: daemon-set-xt4bf. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:01:34.194: INFO: Wrong image for pod: daemon-set-9njtt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:01:34.195: INFO: Wrong image for pod: daemon-set-mjmss. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:01:34.195: INFO: Wrong image for pod: daemon-set-xt4bf. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:01:35.196: INFO: Wrong image for pod: daemon-set-9njtt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:01:35.196: INFO: Wrong image for pod: daemon-set-mjmss. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:01:35.196: INFO: Wrong image for pod: daemon-set-xt4bf. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:01:36.195: INFO: Wrong image for pod: daemon-set-9njtt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:01:36.195: INFO: Wrong image for pod: daemon-set-mjmss. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:01:36.195: INFO: Wrong image for pod: daemon-set-xt4bf. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:01:37.194: INFO: Wrong image for pod: daemon-set-9njtt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:01:37.194: INFO: Wrong image for pod: daemon-set-mjmss. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:01:37.195: INFO: Wrong image for pod: daemon-set-xt4bf. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:01:38.223: INFO: Wrong image for pod: daemon-set-9njtt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:01:38.223: INFO: Wrong image for pod: daemon-set-mjmss. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:01:38.223: INFO: Wrong image for pod: daemon-set-xt4bf. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:01:39.197: INFO: Wrong image for pod: daemon-set-9njtt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:01:39.197: INFO: Wrong image for pod: daemon-set-mjmss. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:01:39.197: INFO: Wrong image for pod: daemon-set-xt4bf. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:01:40.234: INFO: Wrong image for pod: daemon-set-9njtt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:01:40.234: INFO: Wrong image for pod: daemon-set-mjmss. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:01:40.234: INFO: Wrong image for pod: daemon-set-xt4bf. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:01:41.194: INFO: Wrong image for pod: daemon-set-9njtt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:01:41.194: INFO: Wrong image for pod: daemon-set-mjmss. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:01:41.194: INFO: Wrong image for pod: daemon-set-xt4bf. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:01:42.193: INFO: Wrong image for pod: daemon-set-9njtt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:01:42.194: INFO: Wrong image for pod: daemon-set-mjmss. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:01:42.194: INFO: Wrong image for pod: daemon-set-xt4bf. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:01:43.195: INFO: Wrong image for pod: daemon-set-9njtt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:01:43.195: INFO: Wrong image for pod: daemon-set-mjmss. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:01:43.195: INFO: Wrong image for pod: daemon-set-xt4bf. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:01:44.194: INFO: Wrong image for pod: daemon-set-9njtt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:01:44.194: INFO: Wrong image for pod: daemon-set-mjmss. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:01:44.194: INFO: Wrong image for pod: daemon-set-xt4bf. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:01:45.194: INFO: Wrong image for pod: daemon-set-9njtt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:01:45.194: INFO: Wrong image for pod: daemon-set-mjmss. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:01:45.194: INFO: Wrong image for pod: daemon-set-xt4bf. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:01:46.194: INFO: Wrong image for pod: daemon-set-9njtt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:01:46.194: INFO: Wrong image for pod: daemon-set-mjmss. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:01:46.194: INFO: Wrong image for pod: daemon-set-xt4bf. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:01:47.196: INFO: Wrong image for pod: daemon-set-9njtt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:01:47.196: INFO: Wrong image for pod: daemon-set-mjmss. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:01:47.196: INFO: Wrong image for pod: daemon-set-xt4bf. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:01:48.194: INFO: Wrong image for pod: daemon-set-9njtt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:01:48.194: INFO: Wrong image for pod: daemon-set-mjmss. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:01:48.194: INFO: Wrong image for pod: daemon-set-xt4bf. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:01:49.209: INFO: Wrong image for pod: daemon-set-9njtt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:01:49.209: INFO: Wrong image for pod: daemon-set-mjmss. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:01:49.209: INFO: Wrong image for pod: daemon-set-xt4bf. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:01:50.195: INFO: Wrong image for pod: daemon-set-9njtt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:01:50.195: INFO: Wrong image for pod: daemon-set-mjmss. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:01:50.195: INFO: Wrong image for pod: daemon-set-xt4bf. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:01:51.194: INFO: Wrong image for pod: daemon-set-9njtt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:01:51.194: INFO: Wrong image for pod: daemon-set-mjmss. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:01:51.194: INFO: Wrong image for pod: daemon-set-xt4bf. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:01:52.198: INFO: Wrong image for pod: daemon-set-9njtt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:01:52.198: INFO: Wrong image for pod: daemon-set-mjmss. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:01:52.198: INFO: Wrong image for pod: daemon-set-xt4bf. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:01:53.194: INFO: Wrong image for pod: daemon-set-9njtt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:01:53.194: INFO: Wrong image for pod: daemon-set-mjmss. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:01:53.194: INFO: Wrong image for pod: daemon-set-xt4bf. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:01:54.197: INFO: Wrong image for pod: daemon-set-9njtt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:01:54.197: INFO: Wrong image for pod: daemon-set-mjmss. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:01:54.197: INFO: Wrong image for pod: daemon-set-xt4bf. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:01:55.194: INFO: Wrong image for pod: daemon-set-9njtt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:01:55.194: INFO: Wrong image for pod: daemon-set-mjmss. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:01:55.194: INFO: Wrong image for pod: daemon-set-xt4bf. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:01:56.194: INFO: Wrong image for pod: daemon-set-9njtt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:01:56.194: INFO: Wrong image for pod: daemon-set-mjmss. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:01:56.194: INFO: Wrong image for pod: daemon-set-xt4bf. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:01:57.194: INFO: Wrong image for pod: daemon-set-9njtt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:01:57.194: INFO: Wrong image for pod: daemon-set-mjmss. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:01:57.194: INFO: Wrong image for pod: daemon-set-xt4bf. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:01:58.197: INFO: Wrong image for pod: daemon-set-9njtt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:01:58.197: INFO: Wrong image for pod: daemon-set-mjmss. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:01:58.197: INFO: Wrong image for pod: daemon-set-xt4bf. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:01:59.197: INFO: Wrong image for pod: daemon-set-9njtt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:01:59.197: INFO: Wrong image for pod: daemon-set-mjmss. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:01:59.197: INFO: Wrong image for pod: daemon-set-xt4bf. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:02:00.193: INFO: Wrong image for pod: daemon-set-9njtt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:02:00.193: INFO: Wrong image for pod: daemon-set-mjmss. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:02:00.193: INFO: Pod daemon-set-mjmss is not available
Feb  6 03:02:00.193: INFO: Wrong image for pod: daemon-set-xt4bf. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:02:01.195: INFO: Wrong image for pod: daemon-set-9njtt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:02:01.195: INFO: Wrong image for pod: daemon-set-mjmss. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:02:01.195: INFO: Pod daemon-set-mjmss is not available
Feb  6 03:02:01.195: INFO: Wrong image for pod: daemon-set-xt4bf. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:02:02.194: INFO: Wrong image for pod: daemon-set-9njtt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:02:02.194: INFO: Wrong image for pod: daemon-set-mjmss. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:02:02.194: INFO: Pod daemon-set-mjmss is not available
Feb  6 03:02:02.194: INFO: Wrong image for pod: daemon-set-xt4bf. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:02:03.194: INFO: Wrong image for pod: daemon-set-9njtt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:02:03.194: INFO: Wrong image for pod: daemon-set-mjmss. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:02:03.194: INFO: Pod daemon-set-mjmss is not available
Feb  6 03:02:03.194: INFO: Wrong image for pod: daemon-set-xt4bf. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:02:04.194: INFO: Wrong image for pod: daemon-set-9njtt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:02:04.194: INFO: Wrong image for pod: daemon-set-mjmss. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:02:04.194: INFO: Pod daemon-set-mjmss is not available
Feb  6 03:02:04.194: INFO: Wrong image for pod: daemon-set-xt4bf. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:02:05.195: INFO: Wrong image for pod: daemon-set-9njtt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:02:05.195: INFO: Wrong image for pod: daemon-set-mjmss. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:02:05.195: INFO: Pod daemon-set-mjmss is not available
Feb  6 03:02:05.195: INFO: Wrong image for pod: daemon-set-xt4bf. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:02:06.193: INFO: Wrong image for pod: daemon-set-9njtt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:02:06.193: INFO: Wrong image for pod: daemon-set-mjmss. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:02:06.193: INFO: Pod daemon-set-mjmss is not available
Feb  6 03:02:06.193: INFO: Wrong image for pod: daemon-set-xt4bf. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:02:07.198: INFO: Wrong image for pod: daemon-set-9njtt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:02:07.198: INFO: Wrong image for pod: daemon-set-mjmss. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:02:07.198: INFO: Pod daemon-set-mjmss is not available
Feb  6 03:02:07.198: INFO: Wrong image for pod: daemon-set-xt4bf. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:02:08.194: INFO: Wrong image for pod: daemon-set-9njtt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:02:08.194: INFO: Pod daemon-set-c56qm is not available
Feb  6 03:02:08.194: INFO: Wrong image for pod: daemon-set-xt4bf. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:02:09.291: INFO: Wrong image for pod: daemon-set-9njtt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:02:09.292: INFO: Wrong image for pod: daemon-set-xt4bf. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:02:10.194: INFO: Wrong image for pod: daemon-set-9njtt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:02:10.194: INFO: Wrong image for pod: daemon-set-xt4bf. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:02:11.194: INFO: Wrong image for pod: daemon-set-9njtt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:02:11.194: INFO: Wrong image for pod: daemon-set-xt4bf. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:02:12.195: INFO: Wrong image for pod: daemon-set-9njtt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:02:12.195: INFO: Wrong image for pod: daemon-set-xt4bf. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:02:13.194: INFO: Wrong image for pod: daemon-set-9njtt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:02:13.195: INFO: Wrong image for pod: daemon-set-xt4bf. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:02:14.194: INFO: Wrong image for pod: daemon-set-9njtt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:02:14.194: INFO: Wrong image for pod: daemon-set-xt4bf. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:02:15.194: INFO: Wrong image for pod: daemon-set-9njtt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:02:15.194: INFO: Wrong image for pod: daemon-set-xt4bf. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:02:16.196: INFO: Wrong image for pod: daemon-set-9njtt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:02:16.196: INFO: Wrong image for pod: daemon-set-xt4bf. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:02:17.194: INFO: Wrong image for pod: daemon-set-9njtt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:02:17.194: INFO: Wrong image for pod: daemon-set-xt4bf. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:02:18.205: INFO: Wrong image for pod: daemon-set-9njtt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:02:18.205: INFO: Wrong image for pod: daemon-set-xt4bf. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:02:19.195: INFO: Wrong image for pod: daemon-set-9njtt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:02:19.195: INFO: Wrong image for pod: daemon-set-xt4bf. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:02:20.209: INFO: Wrong image for pod: daemon-set-9njtt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:02:20.209: INFO: Wrong image for pod: daemon-set-xt4bf. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:02:21.194: INFO: Wrong image for pod: daemon-set-9njtt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:02:21.194: INFO: Wrong image for pod: daemon-set-xt4bf. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:02:22.195: INFO: Wrong image for pod: daemon-set-9njtt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:02:22.195: INFO: Wrong image for pod: daemon-set-xt4bf. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:02:23.194: INFO: Wrong image for pod: daemon-set-9njtt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:02:23.194: INFO: Wrong image for pod: daemon-set-xt4bf. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:02:24.195: INFO: Wrong image for pod: daemon-set-9njtt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:02:24.196: INFO: Wrong image for pod: daemon-set-xt4bf. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:02:25.194: INFO: Wrong image for pod: daemon-set-9njtt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:02:25.194: INFO: Wrong image for pod: daemon-set-xt4bf. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:02:26.194: INFO: Wrong image for pod: daemon-set-9njtt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:02:26.194: INFO: Wrong image for pod: daemon-set-xt4bf. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:02:27.195: INFO: Wrong image for pod: daemon-set-9njtt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:02:27.195: INFO: Wrong image for pod: daemon-set-xt4bf. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:02:28.194: INFO: Wrong image for pod: daemon-set-9njtt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:02:28.194: INFO: Wrong image for pod: daemon-set-xt4bf. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:02:29.194: INFO: Wrong image for pod: daemon-set-9njtt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:02:29.195: INFO: Wrong image for pod: daemon-set-xt4bf. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:02:30.194: INFO: Wrong image for pod: daemon-set-9njtt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:02:30.194: INFO: Wrong image for pod: daemon-set-xt4bf. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:02:31.209: INFO: Wrong image for pod: daemon-set-9njtt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:02:31.209: INFO: Wrong image for pod: daemon-set-xt4bf. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:02:32.194: INFO: Wrong image for pod: daemon-set-9njtt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:02:32.194: INFO: Wrong image for pod: daemon-set-xt4bf. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:02:33.193: INFO: Wrong image for pod: daemon-set-9njtt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:02:33.193: INFO: Wrong image for pod: daemon-set-xt4bf. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:02:34.196: INFO: Wrong image for pod: daemon-set-9njtt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:02:34.196: INFO: Wrong image for pod: daemon-set-xt4bf. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:02:35.194: INFO: Wrong image for pod: daemon-set-9njtt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:02:35.194: INFO: Wrong image for pod: daemon-set-xt4bf. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:02:36.197: INFO: Wrong image for pod: daemon-set-9njtt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:02:36.197: INFO: Wrong image for pod: daemon-set-xt4bf. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:02:37.194: INFO: Wrong image for pod: daemon-set-9njtt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:02:37.194: INFO: Wrong image for pod: daemon-set-xt4bf. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:02:38.203: INFO: Wrong image for pod: daemon-set-9njtt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:02:38.203: INFO: Wrong image for pod: daemon-set-xt4bf. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:02:39.194: INFO: Wrong image for pod: daemon-set-9njtt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:02:39.194: INFO: Wrong image for pod: daemon-set-xt4bf. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:02:40.194: INFO: Wrong image for pod: daemon-set-9njtt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:02:40.194: INFO: Wrong image for pod: daemon-set-xt4bf. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:02:40.194: INFO: Pod daemon-set-xt4bf is not available
Feb  6 03:02:41.195: INFO: Wrong image for pod: daemon-set-9njtt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:02:41.196: INFO: Wrong image for pod: daemon-set-xt4bf. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:02:41.196: INFO: Pod daemon-set-xt4bf is not available
Feb  6 03:02:42.213: INFO: Wrong image for pod: daemon-set-9njtt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:02:42.213: INFO: Wrong image for pod: daemon-set-xt4bf. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:02:42.213: INFO: Pod daemon-set-xt4bf is not available
Feb  6 03:02:43.196: INFO: Wrong image for pod: daemon-set-9njtt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:02:43.196: INFO: Wrong image for pod: daemon-set-xt4bf. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:02:43.196: INFO: Pod daemon-set-xt4bf is not available
Feb  6 03:02:44.193: INFO: Wrong image for pod: daemon-set-9njtt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:02:44.194: INFO: Wrong image for pod: daemon-set-xt4bf. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:02:44.194: INFO: Pod daemon-set-xt4bf is not available
Feb  6 03:02:45.194: INFO: Wrong image for pod: daemon-set-9njtt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:02:45.194: INFO: Wrong image for pod: daemon-set-xt4bf. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:02:45.194: INFO: Pod daemon-set-xt4bf is not available
Feb  6 03:02:46.198: INFO: Wrong image for pod: daemon-set-9njtt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:02:46.198: INFO: Wrong image for pod: daemon-set-xt4bf. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:02:46.198: INFO: Pod daemon-set-xt4bf is not available
Feb  6 03:02:47.196: INFO: Wrong image for pod: daemon-set-9njtt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:02:47.196: INFO: Wrong image for pod: daemon-set-xt4bf. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:02:47.196: INFO: Pod daemon-set-xt4bf is not available
Feb  6 03:02:48.197: INFO: Wrong image for pod: daemon-set-9njtt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:02:48.198: INFO: Wrong image for pod: daemon-set-xt4bf. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:02:48.198: INFO: Pod daemon-set-xt4bf is not available
Feb  6 03:02:49.194: INFO: Wrong image for pod: daemon-set-9njtt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:02:49.194: INFO: Wrong image for pod: daemon-set-xt4bf. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:02:49.194: INFO: Pod daemon-set-xt4bf is not available
Feb  6 03:02:50.195: INFO: Wrong image for pod: daemon-set-9njtt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:02:50.195: INFO: Wrong image for pod: daemon-set-xt4bf. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:02:50.195: INFO: Pod daemon-set-xt4bf is not available
Feb  6 03:02:51.195: INFO: Wrong image for pod: daemon-set-9njtt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:02:51.195: INFO: Wrong image for pod: daemon-set-xt4bf. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:02:51.195: INFO: Pod daemon-set-xt4bf is not available
Feb  6 03:02:52.195: INFO: Wrong image for pod: daemon-set-9njtt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:02:52.195: INFO: Pod daemon-set-zzgp2 is not available
Feb  6 03:02:53.207: INFO: Wrong image for pod: daemon-set-9njtt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:02:54.196: INFO: Wrong image for pod: daemon-set-9njtt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:02:55.195: INFO: Wrong image for pod: daemon-set-9njtt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:02:56.194: INFO: Wrong image for pod: daemon-set-9njtt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:02:57.194: INFO: Wrong image for pod: daemon-set-9njtt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:02:58.194: INFO: Wrong image for pod: daemon-set-9njtt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:02:59.287: INFO: Wrong image for pod: daemon-set-9njtt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:03:00.196: INFO: Wrong image for pod: daemon-set-9njtt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:03:01.194: INFO: Wrong image for pod: daemon-set-9njtt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:03:02.198: INFO: Wrong image for pod: daemon-set-9njtt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:03:03.195: INFO: Wrong image for pod: daemon-set-9njtt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:03:04.333: INFO: Wrong image for pod: daemon-set-9njtt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:03:05.199: INFO: Wrong image for pod: daemon-set-9njtt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:03:06.194: INFO: Wrong image for pod: daemon-set-9njtt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:03:07.196: INFO: Wrong image for pod: daemon-set-9njtt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:03:08.194: INFO: Wrong image for pod: daemon-set-9njtt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:03:09.194: INFO: Wrong image for pod: daemon-set-9njtt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:03:10.196: INFO: Wrong image for pod: daemon-set-9njtt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:03:11.194: INFO: Wrong image for pod: daemon-set-9njtt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:03:12.195: INFO: Wrong image for pod: daemon-set-9njtt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:03:13.308: INFO: Wrong image for pod: daemon-set-9njtt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:03:14.194: INFO: Wrong image for pod: daemon-set-9njtt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:03:15.210: INFO: Wrong image for pod: daemon-set-9njtt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:03:16.193: INFO: Wrong image for pod: daemon-set-9njtt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:03:17.194: INFO: Wrong image for pod: daemon-set-9njtt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:03:18.194: INFO: Wrong image for pod: daemon-set-9njtt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:03:19.196: INFO: Wrong image for pod: daemon-set-9njtt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:03:20.194: INFO: Wrong image for pod: daemon-set-9njtt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:03:21.194: INFO: Wrong image for pod: daemon-set-9njtt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:03:22.194: INFO: Wrong image for pod: daemon-set-9njtt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:03:23.208: INFO: Wrong image for pod: daemon-set-9njtt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:03:24.196: INFO: Wrong image for pod: daemon-set-9njtt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:03:24.197: INFO: Pod daemon-set-9njtt is not available
Feb  6 03:03:25.194: INFO: Wrong image for pod: daemon-set-9njtt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:03:25.194: INFO: Pod daemon-set-9njtt is not available
Feb  6 03:03:26.209: INFO: Wrong image for pod: daemon-set-9njtt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:03:26.209: INFO: Pod daemon-set-9njtt is not available
Feb  6 03:03:27.195: INFO: Wrong image for pod: daemon-set-9njtt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:03:27.195: INFO: Pod daemon-set-9njtt is not available
Feb  6 03:03:28.194: INFO: Wrong image for pod: daemon-set-9njtt. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1.
Feb  6 03:03:28.194: INFO: Pod daemon-set-9njtt is not available
Feb  6 03:03:29.201: INFO: Pod daemon-set-nttbz is not available
STEP: Check that daemon pods are still running on every node of the cluster.
Feb  6 03:03:29.234: INFO: Number of nodes with available pods: 2
Feb  6 03:03:29.234: INFO: Node 10.190.119.143 is running more than one daemon pod
Feb  6 03:03:30.255: INFO: Number of nodes with available pods: 2
Feb  6 03:03:30.255: INFO: Node 10.190.119.143 is running more than one daemon pod
Feb  6 03:03:31.291: INFO: Number of nodes with available pods: 3
Feb  6 03:03:31.291: INFO: Number of running nodes: 3, number of available pods: 3
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:64
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting {extensions DaemonSet} daemon-set in namespace e2e-tests-daemonsets-z7xxh, will wait for the garbage collector to delete the pods
Feb  6 03:03:31.424: INFO: Deleting {extensions DaemonSet} daemon-set took: 20.868396ms
Feb  6 03:03:31.524: INFO: Terminating {extensions DaemonSet} daemon-set pods took: 100.233382ms
Feb  6 03:03:42.289: INFO: Number of nodes with available pods: 0
Feb  6 03:03:42.289: INFO: Number of running nodes: 0, number of available pods: 0
Feb  6 03:03:42.298: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/e2e-tests-daemonsets-z7xxh/daemonsets","resourceVersion":"66579"},"items":null}

Feb  6 03:03:42.307: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/e2e-tests-daemonsets-z7xxh/pods","resourceVersion":"66579"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  6 03:03:42.411: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-daemonsets-z7xxh" for this suite.
Feb  6 03:03:48.453: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 03:03:48.558: INFO: namespace: e2e-tests-daemonsets-z7xxh, resource: bindings, ignored listing per whitelist
Feb  6 03:03:48.790: INFO: namespace e2e-tests-daemonsets-z7xxh deletion completed in 6.368058218s

• [SLOW TEST:144.184 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  6 03:03:48.794: INFO: >>> kubeConfig: /tmp/kubeconfig-131423863
STEP: Building a namespace api object, basename pod-network-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-pod-network-test-6t2pn
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Performing setup for networking test in namespace e2e-tests-pod-network-test-6t2pn
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Feb  6 03:03:49.110: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Feb  6 03:04:11.450: INFO: ExecWithOptions {Command:[/bin/sh -c timeout -t 15 curl -g -q -s --connect-timeout 1 http://172.30.176.15:8080/hostName | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-6t2pn PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb  6 03:04:11.450: INFO: >>> kubeConfig: /tmp/kubeconfig-131423863
Feb  6 03:04:11.818: INFO: Found all expected endpoints: [netserver-0]
Feb  6 03:04:11.827: INFO: ExecWithOptions {Command:[/bin/sh -c timeout -t 15 curl -g -q -s --connect-timeout 1 http://172.30.134.208:8080/hostName | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-6t2pn PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb  6 03:04:11.827: INFO: >>> kubeConfig: /tmp/kubeconfig-131423863
Feb  6 03:04:12.116: INFO: Found all expected endpoints: [netserver-1]
Feb  6 03:04:12.199: INFO: ExecWithOptions {Command:[/bin/sh -c timeout -t 15 curl -g -q -s --connect-timeout 1 http://172.30.242.14:8080/hostName | grep -v '^\s*$'] Namespace:e2e-tests-pod-network-test-6t2pn PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb  6 03:04:12.199: INFO: >>> kubeConfig: /tmp/kubeconfig-131423863
Feb  6 03:04:12.407: INFO: Found all expected endpoints: [netserver-2]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  6 03:04:12.408: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pod-network-test-6t2pn" for this suite.
Feb  6 03:04:36.447: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 03:04:37.574: INFO: namespace: e2e-tests-pod-network-test-6t2pn, resource: bindings, ignored listing per whitelist
Feb  6 03:04:37.635: INFO: namespace e2e-tests-pod-network-test-6t2pn deletion completed in 25.214445437s

• [SLOW TEST:48.841 seconds]
[sig-network] Networking
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: http [NodeConformance] [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Projected 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  6 03:04:37.636: INFO: >>> kubeConfig: /tmp/kubeconfig-131423863
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-57t7k
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb  6 03:04:37.965: INFO: Waiting up to 5m0s for pod "downwardapi-volume-f058b781-29bb-11e9-9603-eaa511fa0b6c" in namespace "e2e-tests-projected-57t7k" to be "success or failure"
Feb  6 03:04:37.973: INFO: Pod "downwardapi-volume-f058b781-29bb-11e9-9603-eaa511fa0b6c": Phase="Pending", Reason="", readiness=false. Elapsed: 8.425745ms
Feb  6 03:04:39.983: INFO: Pod "downwardapi-volume-f058b781-29bb-11e9-9603-eaa511fa0b6c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.017888057s
STEP: Saw pod success
Feb  6 03:04:39.983: INFO: Pod "downwardapi-volume-f058b781-29bb-11e9-9603-eaa511fa0b6c" satisfied condition "success or failure"
Feb  6 03:04:39.992: INFO: Trying to get logs from node 10.190.119.133 pod downwardapi-volume-f058b781-29bb-11e9-9603-eaa511fa0b6c container client-container: <nil>
STEP: delete the pod
Feb  6 03:04:40.043: INFO: Waiting for pod downwardapi-volume-f058b781-29bb-11e9-9603-eaa511fa0b6c to disappear
Feb  6 03:04:40.091: INFO: Pod downwardapi-volume-f058b781-29bb-11e9-9603-eaa511fa0b6c no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  6 03:04:40.091: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-57t7k" for this suite.
Feb  6 03:04:46.139: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 03:04:46.229: INFO: namespace: e2e-tests-projected-57t7k, resource: bindings, ignored listing per whitelist
Feb  6 03:04:46.493: INFO: namespace e2e-tests-projected-57t7k deletion completed in 6.383653554s

• [SLOW TEST:8.857 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  6 03:04:46.494: INFO: >>> kubeConfig: /tmp/kubeconfig-131423863
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-z9n6z
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb  6 03:04:46.833: INFO: Waiting up to 5m0s for pod "downwardapi-volume-f5a1a16f-29bb-11e9-9603-eaa511fa0b6c" in namespace "e2e-tests-downward-api-z9n6z" to be "success or failure"
Feb  6 03:04:46.891: INFO: Pod "downwardapi-volume-f5a1a16f-29bb-11e9-9603-eaa511fa0b6c": Phase="Pending", Reason="", readiness=false. Elapsed: 58.546246ms
Feb  6 03:04:48.899: INFO: Pod "downwardapi-volume-f5a1a16f-29bb-11e9-9603-eaa511fa0b6c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.066615385s
STEP: Saw pod success
Feb  6 03:04:48.899: INFO: Pod "downwardapi-volume-f5a1a16f-29bb-11e9-9603-eaa511fa0b6c" satisfied condition "success or failure"
Feb  6 03:04:48.907: INFO: Trying to get logs from node 10.190.119.143 pod downwardapi-volume-f5a1a16f-29bb-11e9-9603-eaa511fa0b6c container client-container: <nil>
STEP: delete the pod
Feb  6 03:04:48.968: INFO: Waiting for pod downwardapi-volume-f5a1a16f-29bb-11e9-9603-eaa511fa0b6c to disappear
Feb  6 03:04:48.985: INFO: Pod downwardapi-volume-f5a1a16f-29bb-11e9-9603-eaa511fa0b6c no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  6 03:04:48.985: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-z9n6z" for this suite.
Feb  6 03:04:55.037: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 03:04:55.380: INFO: namespace: e2e-tests-downward-api-z9n6z, resource: bindings, ignored listing per whitelist
Feb  6 03:04:55.490: INFO: namespace e2e-tests-downward-api-z9n6z deletion completed in 6.482969003s

• [SLOW TEST:8.996 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  6 03:04:55.491: INFO: >>> kubeConfig: /tmp/kubeconfig-131423863
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-tng8p
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0777 on node default medium
Feb  6 03:04:55.891: INFO: Waiting up to 5m0s for pod "pod-fafc7bfe-29bb-11e9-9603-eaa511fa0b6c" in namespace "e2e-tests-emptydir-tng8p" to be "success or failure"
Feb  6 03:04:55.902: INFO: Pod "pod-fafc7bfe-29bb-11e9-9603-eaa511fa0b6c": Phase="Pending", Reason="", readiness=false. Elapsed: 10.145438ms
Feb  6 03:04:58.260: INFO: Pod "pod-fafc7bfe-29bb-11e9-9603-eaa511fa0b6c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.368277484s
STEP: Saw pod success
Feb  6 03:04:58.260: INFO: Pod "pod-fafc7bfe-29bb-11e9-9603-eaa511fa0b6c" satisfied condition "success or failure"
Feb  6 03:04:58.274: INFO: Trying to get logs from node 10.190.119.184 pod pod-fafc7bfe-29bb-11e9-9603-eaa511fa0b6c container test-container: <nil>
STEP: delete the pod
Feb  6 03:04:58.333: INFO: Waiting for pod pod-fafc7bfe-29bb-11e9-9603-eaa511fa0b6c to disappear
Feb  6 03:04:58.342: INFO: Pod pod-fafc7bfe-29bb-11e9-9603-eaa511fa0b6c no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  6 03:04:58.342: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-tng8p" for this suite.
Feb  6 03:05:04.385: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 03:05:04.808: INFO: namespace: e2e-tests-emptydir-tng8p, resource: bindings, ignored listing per whitelist
Feb  6 03:05:04.816: INFO: namespace e2e-tests-emptydir-tng8p deletion completed in 6.460293372s

• [SLOW TEST:9.325 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  6 03:05:04.816: INFO: >>> kubeConfig: /tmp/kubeconfig-131423863
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-4pb4g
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb  6 03:05:05.137: INFO: Waiting up to 5m0s for pod "downwardapi-volume-008aaeaf-29bc-11e9-9603-eaa511fa0b6c" in namespace "e2e-tests-downward-api-4pb4g" to be "success or failure"
Feb  6 03:05:05.200: INFO: Pod "downwardapi-volume-008aaeaf-29bc-11e9-9603-eaa511fa0b6c": Phase="Pending", Reason="", readiness=false. Elapsed: 63.731897ms
Feb  6 03:05:07.209: INFO: Pod "downwardapi-volume-008aaeaf-29bc-11e9-9603-eaa511fa0b6c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.072582004s
Feb  6 03:05:09.232: INFO: Pod "downwardapi-volume-008aaeaf-29bc-11e9-9603-eaa511fa0b6c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.095067764s
STEP: Saw pod success
Feb  6 03:05:09.232: INFO: Pod "downwardapi-volume-008aaeaf-29bc-11e9-9603-eaa511fa0b6c" satisfied condition "success or failure"
Feb  6 03:05:09.241: INFO: Trying to get logs from node 10.190.119.133 pod downwardapi-volume-008aaeaf-29bc-11e9-9603-eaa511fa0b6c container client-container: <nil>
STEP: delete the pod
Feb  6 03:05:09.303: INFO: Waiting for pod downwardapi-volume-008aaeaf-29bc-11e9-9603-eaa511fa0b6c to disappear
Feb  6 03:05:09.314: INFO: Pod downwardapi-volume-008aaeaf-29bc-11e9-9603-eaa511fa0b6c no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  6 03:05:09.314: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-4pb4g" for this suite.
Feb  6 03:05:15.422: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 03:05:15.605: INFO: namespace: e2e-tests-downward-api-4pb4g, resource: bindings, ignored listing per whitelist
Feb  6 03:05:15.953: INFO: namespace e2e-tests-downward-api-4pb4g deletion completed in 6.560769817s

• [SLOW TEST:11.138 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should set mode on item file [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  6 03:05:15.955: INFO: >>> kubeConfig: /tmp/kubeconfig-131423863
STEP: Building a namespace api object, basename containers
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-containers-2xtjs
STEP: Waiting for a default service account to be provisioned in namespace
[It] should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test use defaults
Feb  6 03:05:16.314: INFO: Waiting up to 5m0s for pod "client-containers-073456d8-29bc-11e9-9603-eaa511fa0b6c" in namespace "e2e-tests-containers-2xtjs" to be "success or failure"
Feb  6 03:05:16.400: INFO: Pod "client-containers-073456d8-29bc-11e9-9603-eaa511fa0b6c": Phase="Pending", Reason="", readiness=false. Elapsed: 86.175236ms
Feb  6 03:05:18.410: INFO: Pod "client-containers-073456d8-29bc-11e9-9603-eaa511fa0b6c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.095879532s
STEP: Saw pod success
Feb  6 03:05:18.410: INFO: Pod "client-containers-073456d8-29bc-11e9-9603-eaa511fa0b6c" satisfied condition "success or failure"
Feb  6 03:05:18.420: INFO: Trying to get logs from node 10.190.119.143 pod client-containers-073456d8-29bc-11e9-9603-eaa511fa0b6c container test-container: <nil>
STEP: delete the pod
Feb  6 03:05:18.491: INFO: Waiting for pod client-containers-073456d8-29bc-11e9-9603-eaa511fa0b6c to disappear
Feb  6 03:05:18.500: INFO: Pod client-containers-073456d8-29bc-11e9-9603-eaa511fa0b6c no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  6 03:05:18.500: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-2xtjs" for this suite.
Feb  6 03:05:24.540: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 03:05:24.645: INFO: namespace: e2e-tests-containers-2xtjs, resource: bindings, ignored listing per whitelist
Feb  6 03:05:24.919: INFO: namespace e2e-tests-containers-2xtjs deletion completed in 6.404959731s

• [SLOW TEST:8.964 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  6 03:05:24.919: INFO: >>> kubeConfig: /tmp/kubeconfig-131423863
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-sx6vz
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0666 on node default medium
Feb  6 03:05:25.311: INFO: Waiting up to 5m0s for pod "pod-0c85715c-29bc-11e9-9603-eaa511fa0b6c" in namespace "e2e-tests-emptydir-sx6vz" to be "success or failure"
Feb  6 03:05:25.321: INFO: Pod "pod-0c85715c-29bc-11e9-9603-eaa511fa0b6c": Phase="Pending", Reason="", readiness=false. Elapsed: 9.17507ms
Feb  6 03:05:27.329: INFO: Pod "pod-0c85715c-29bc-11e9-9603-eaa511fa0b6c": Phase="Running", Reason="", readiness=true. Elapsed: 2.017931514s
Feb  6 03:05:29.338: INFO: Pod "pod-0c85715c-29bc-11e9-9603-eaa511fa0b6c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.026342961s
STEP: Saw pod success
Feb  6 03:05:29.338: INFO: Pod "pod-0c85715c-29bc-11e9-9603-eaa511fa0b6c" satisfied condition "success or failure"
Feb  6 03:05:29.348: INFO: Trying to get logs from node 10.190.119.184 pod pod-0c85715c-29bc-11e9-9603-eaa511fa0b6c container test-container: <nil>
STEP: delete the pod
Feb  6 03:05:29.401: INFO: Waiting for pod pod-0c85715c-29bc-11e9-9603-eaa511fa0b6c to disappear
Feb  6 03:05:29.408: INFO: Pod pod-0c85715c-29bc-11e9-9603-eaa511fa0b6c no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  6 03:05:29.408: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-sx6vz" for this suite.
Feb  6 03:05:35.630: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 03:05:35.822: INFO: namespace: e2e-tests-emptydir-sx6vz, resource: bindings, ignored listing per whitelist
Feb  6 03:05:35.990: INFO: namespace e2e-tests-emptydir-sx6vz deletion completed in 6.561426611s

• [SLOW TEST:11.071 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0666,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  6 03:05:35.992: INFO: >>> kubeConfig: /tmp/kubeconfig-131423863
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-kckpl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:293
[It] should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a replication controller
Feb  6 03:05:36.392: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-131423863 create -f - --namespace=e2e-tests-kubectl-kckpl'
Feb  6 03:05:36.703: INFO: stderr: ""
Feb  6 03:05:36.703: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Feb  6 03:05:36.703: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-131423863 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-kckpl'
Feb  6 03:05:36.852: INFO: stderr: ""
Feb  6 03:05:36.852: INFO: stdout: "update-demo-nautilus-nl5lz update-demo-nautilus-xtb4c "
Feb  6 03:05:36.852: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-131423863 get pods update-demo-nautilus-nl5lz -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-kckpl'
Feb  6 03:05:36.991: INFO: stderr: ""
Feb  6 03:05:36.991: INFO: stdout: ""
Feb  6 03:05:36.991: INFO: update-demo-nautilus-nl5lz is created but not running
Feb  6 03:05:41.991: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-131423863 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=e2e-tests-kubectl-kckpl'
Feb  6 03:05:42.196: INFO: stderr: ""
Feb  6 03:05:42.196: INFO: stdout: "update-demo-nautilus-nl5lz update-demo-nautilus-xtb4c "
Feb  6 03:05:42.196: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-131423863 get pods update-demo-nautilus-nl5lz -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-kckpl'
Feb  6 03:05:42.370: INFO: stderr: ""
Feb  6 03:05:42.370: INFO: stdout: "true"
Feb  6 03:05:42.370: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-131423863 get pods update-demo-nautilus-nl5lz -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-kckpl'
Feb  6 03:05:42.523: INFO: stderr: ""
Feb  6 03:05:42.524: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Feb  6 03:05:42.524: INFO: validating pod update-demo-nautilus-nl5lz
Feb  6 03:05:42.545: INFO: got data: {
  "image": "nautilus.jpg"
}

Feb  6 03:05:42.545: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Feb  6 03:05:42.545: INFO: update-demo-nautilus-nl5lz is verified up and running
Feb  6 03:05:42.545: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-131423863 get pods update-demo-nautilus-xtb4c -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-kckpl'
Feb  6 03:05:42.681: INFO: stderr: ""
Feb  6 03:05:42.681: INFO: stdout: "true"
Feb  6 03:05:42.681: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-131423863 get pods update-demo-nautilus-xtb4c -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=e2e-tests-kubectl-kckpl'
Feb  6 03:05:42.849: INFO: stderr: ""
Feb  6 03:05:42.849: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Feb  6 03:05:42.849: INFO: validating pod update-demo-nautilus-xtb4c
Feb  6 03:05:42.866: INFO: got data: {
  "image": "nautilus.jpg"
}

Feb  6 03:05:42.866: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Feb  6 03:05:42.866: INFO: update-demo-nautilus-xtb4c is verified up and running
STEP: using delete to clean up resources
Feb  6 03:05:42.866: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-131423863 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-kckpl'
Feb  6 03:05:43.023: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Feb  6 03:05:43.023: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Feb  6 03:05:43.023: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-131423863 get rc,svc -l name=update-demo --no-headers --namespace=e2e-tests-kubectl-kckpl'
Feb  6 03:05:43.178: INFO: stderr: "No resources found.\n"
Feb  6 03:05:43.178: INFO: stdout: ""
Feb  6 03:05:43.178: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-131423863 get pods -l name=update-demo --namespace=e2e-tests-kubectl-kckpl -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Feb  6 03:05:43.333: INFO: stderr: ""
Feb  6 03:05:43.333: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  6 03:05:43.333: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-kckpl" for this suite.
Feb  6 03:05:49.374: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 03:05:49.680: INFO: namespace: e2e-tests-kubectl-kckpl, resource: bindings, ignored listing per whitelist
Feb  6 03:05:49.771: INFO: namespace e2e-tests-kubectl-kckpl deletion completed in 6.423034938s

• [SLOW TEST:13.779 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Update Demo
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create and stop a replication controller  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  6 03:05:49.771: INFO: >>> kubeConfig: /tmp/kubeconfig-131423863
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-dl87m
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0777 on node default medium
Feb  6 03:05:50.113: INFO: Waiting up to 5m0s for pod "pod-1b596f2f-29bc-11e9-9603-eaa511fa0b6c" in namespace "e2e-tests-emptydir-dl87m" to be "success or failure"
Feb  6 03:05:50.127: INFO: Pod "pod-1b596f2f-29bc-11e9-9603-eaa511fa0b6c": Phase="Pending", Reason="", readiness=false. Elapsed: 13.750668ms
Feb  6 03:05:52.137: INFO: Pod "pod-1b596f2f-29bc-11e9-9603-eaa511fa0b6c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.023519994s
STEP: Saw pod success
Feb  6 03:05:52.137: INFO: Pod "pod-1b596f2f-29bc-11e9-9603-eaa511fa0b6c" satisfied condition "success or failure"
Feb  6 03:05:52.145: INFO: Trying to get logs from node 10.190.119.184 pod pod-1b596f2f-29bc-11e9-9603-eaa511fa0b6c container test-container: <nil>
STEP: delete the pod
Feb  6 03:05:52.192: INFO: Waiting for pod pod-1b596f2f-29bc-11e9-9603-eaa511fa0b6c to disappear
Feb  6 03:05:52.199: INFO: Pod pod-1b596f2f-29bc-11e9-9603-eaa511fa0b6c no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  6 03:05:52.199: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-dl87m" for this suite.
Feb  6 03:05:58.251: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 03:05:58.533: INFO: namespace: e2e-tests-emptydir-dl87m, resource: bindings, ignored listing per whitelist
Feb  6 03:05:58.575: INFO: namespace e2e-tests-emptydir-dl87m deletion completed in 6.36165128s

• [SLOW TEST:8.804 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0777,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  6 03:05:58.577: INFO: >>> kubeConfig: /tmp/kubeconfig-131423863
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-tlc5s
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0644 on node default medium
Feb  6 03:05:58.961: INFO: Waiting up to 5m0s for pod "pod-209f3f31-29bc-11e9-9603-eaa511fa0b6c" in namespace "e2e-tests-emptydir-tlc5s" to be "success or failure"
Feb  6 03:05:58.991: INFO: Pod "pod-209f3f31-29bc-11e9-9603-eaa511fa0b6c": Phase="Pending", Reason="", readiness=false. Elapsed: 30.763552ms
Feb  6 03:06:01.000: INFO: Pod "pod-209f3f31-29bc-11e9-9603-eaa511fa0b6c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.039090976s
STEP: Saw pod success
Feb  6 03:06:01.000: INFO: Pod "pod-209f3f31-29bc-11e9-9603-eaa511fa0b6c" satisfied condition "success or failure"
Feb  6 03:06:01.008: INFO: Trying to get logs from node 10.190.119.133 pod pod-209f3f31-29bc-11e9-9603-eaa511fa0b6c container test-container: <nil>
STEP: delete the pod
Feb  6 03:06:01.058: INFO: Waiting for pod pod-209f3f31-29bc-11e9-9603-eaa511fa0b6c to disappear
Feb  6 03:06:01.091: INFO: Pod pod-209f3f31-29bc-11e9-9603-eaa511fa0b6c no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  6 03:06:01.091: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-tlc5s" for this suite.
Feb  6 03:06:07.130: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 03:06:08.185: INFO: namespace: e2e-tests-emptydir-tlc5s, resource: bindings, ignored listing per whitelist
Feb  6 03:06:08.493: INFO: namespace e2e-tests-emptydir-tlc5s deletion completed in 7.390088266s

• [SLOW TEST:9.917 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0644,default) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should have monotonically increasing restart count [Slow][NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  6 03:06:08.494: INFO: >>> kubeConfig: /tmp/kubeconfig-131423863
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-container-probe-bpj47
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:48
[It] should have monotonically increasing restart count [Slow][NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod liveness-http in namespace e2e-tests-container-probe-bpj47
Feb  6 03:06:11.008: INFO: Started pod liveness-http in namespace e2e-tests-container-probe-bpj47
STEP: checking the pod's current state and verifying that restartCount is present
Feb  6 03:06:11.016: INFO: Initial restart count of pod liveness-http is 0
Feb  6 03:06:23.101: INFO: Restart count of pod e2e-tests-container-probe-bpj47/liveness-http is now 1 (12.084522589s elapsed)
Feb  6 03:06:43.237: INFO: Restart count of pod e2e-tests-container-probe-bpj47/liveness-http is now 2 (32.22043235s elapsed)
Feb  6 03:07:03.356: INFO: Restart count of pod e2e-tests-container-probe-bpj47/liveness-http is now 3 (52.339604167s elapsed)
Feb  6 03:07:23.781: INFO: Restart count of pod e2e-tests-container-probe-bpj47/liveness-http is now 4 (1m12.764985293s elapsed)
Feb  6 03:08:24.162: INFO: Restart count of pod e2e-tests-container-probe-bpj47/liveness-http is now 5 (2m13.145365308s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  6 03:08:24.198: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-container-probe-bpj47" for this suite.
Feb  6 03:08:30.321: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 03:08:31.124: INFO: namespace: e2e-tests-container-probe-bpj47, resource: bindings, ignored listing per whitelist
Feb  6 03:08:31.229: INFO: namespace e2e-tests-container-probe-bpj47 deletion completed in 6.93617887s

• [SLOW TEST:142.735 seconds]
[k8s.io] Probing container
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should have monotonically increasing restart count [Slow][NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Projected 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  6 03:08:31.231: INFO: >>> kubeConfig: /tmp/kubeconfig-131423863
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-22q4l
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb  6 03:08:31.567: INFO: Waiting up to 5m0s for pod "downwardapi-volume-7b950b70-29bc-11e9-9603-eaa511fa0b6c" in namespace "e2e-tests-projected-22q4l" to be "success or failure"
Feb  6 03:08:31.577: INFO: Pod "downwardapi-volume-7b950b70-29bc-11e9-9603-eaa511fa0b6c": Phase="Pending", Reason="", readiness=false. Elapsed: 9.983889ms
Feb  6 03:08:33.585: INFO: Pod "downwardapi-volume-7b950b70-29bc-11e9-9603-eaa511fa0b6c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.018192725s
STEP: Saw pod success
Feb  6 03:08:33.585: INFO: Pod "downwardapi-volume-7b950b70-29bc-11e9-9603-eaa511fa0b6c" satisfied condition "success or failure"
Feb  6 03:08:33.594: INFO: Trying to get logs from node 10.190.119.184 pod downwardapi-volume-7b950b70-29bc-11e9-9603-eaa511fa0b6c container client-container: <nil>
STEP: delete the pod
Feb  6 03:08:33.792: INFO: Waiting for pod downwardapi-volume-7b950b70-29bc-11e9-9603-eaa511fa0b6c to disappear
Feb  6 03:08:33.801: INFO: Pod downwardapi-volume-7b950b70-29bc-11e9-9603-eaa511fa0b6c no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  6 03:08:33.801: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-22q4l" for this suite.
Feb  6 03:08:39.859: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 03:08:40.274: INFO: namespace: e2e-tests-projected-22q4l, resource: bindings, ignored listing per whitelist
Feb  6 03:08:40.430: INFO: namespace e2e-tests-projected-22q4l deletion completed in 6.615846192s

• [SLOW TEST:9.200 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl label 
  should update the label on a resource  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  6 03:08:40.431: INFO: >>> kubeConfig: /tmp/kubeconfig-131423863
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-dsfdd
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Kubectl label
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1042
STEP: creating the pod
Feb  6 03:08:40.737: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-131423863 create -f - --namespace=e2e-tests-kubectl-dsfdd'
Feb  6 03:08:41.183: INFO: stderr: ""
Feb  6 03:08:41.183: INFO: stdout: "pod/pause created\n"
Feb  6 03:08:41.183: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [pause]
Feb  6 03:08:41.183: INFO: Waiting up to 5m0s for pod "pause" in namespace "e2e-tests-kubectl-dsfdd" to be "running and ready"
Feb  6 03:08:41.191: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 8.194641ms
Feb  6 03:08:43.200: INFO: Pod "pause": Phase="Running", Reason="", readiness=true. Elapsed: 2.016435949s
Feb  6 03:08:43.200: INFO: Pod "pause" satisfied condition "running and ready"
Feb  6 03:08:43.200: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [pause]
[It] should update the label on a resource  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: adding the label testing-label with value testing-label-value to a pod
Feb  6 03:08:43.200: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-131423863 label pods pause testing-label=testing-label-value --namespace=e2e-tests-kubectl-dsfdd'
Feb  6 03:08:43.404: INFO: stderr: ""
Feb  6 03:08:43.404: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod has the label testing-label with the value testing-label-value
Feb  6 03:08:43.404: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-131423863 get pod pause -L testing-label --namespace=e2e-tests-kubectl-dsfdd'
Feb  6 03:08:43.549: INFO: stderr: ""
Feb  6 03:08:43.549: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          2s    testing-label-value\n"
STEP: removing the label testing-label of a pod
Feb  6 03:08:43.549: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-131423863 label pods pause testing-label- --namespace=e2e-tests-kubectl-dsfdd'
Feb  6 03:08:43.795: INFO: stderr: ""
Feb  6 03:08:43.795: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod doesn't have the label testing-label
Feb  6 03:08:43.795: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-131423863 get pod pause -L testing-label --namespace=e2e-tests-kubectl-dsfdd'
Feb  6 03:08:43.930: INFO: stderr: ""
Feb  6 03:08:43.930: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          2s    \n"
[AfterEach] [k8s.io] Kubectl label
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1048
STEP: using delete to clean up resources
Feb  6 03:08:43.930: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-131423863 delete --grace-period=0 --force -f - --namespace=e2e-tests-kubectl-dsfdd'
Feb  6 03:08:44.088: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Feb  6 03:08:44.088: INFO: stdout: "pod \"pause\" force deleted\n"
Feb  6 03:08:44.088: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-131423863 get rc,svc -l name=pause --no-headers --namespace=e2e-tests-kubectl-dsfdd'
Feb  6 03:08:44.305: INFO: stderr: "No resources found.\n"
Feb  6 03:08:44.305: INFO: stdout: ""
Feb  6 03:08:44.305: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-131423863 get pods -l name=pause --namespace=e2e-tests-kubectl-dsfdd -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Feb  6 03:08:44.444: INFO: stderr: ""
Feb  6 03:08:44.444: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  6 03:08:44.444: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-dsfdd" for this suite.
Feb  6 03:08:52.486: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 03:08:52.756: INFO: namespace: e2e-tests-kubectl-dsfdd, resource: bindings, ignored listing per whitelist
Feb  6 03:08:52.851: INFO: namespace e2e-tests-kubectl-dsfdd deletion completed in 8.394585378s

• [SLOW TEST:12.421 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl label
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should update the label on a resource  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  6 03:08:52.855: INFO: >>> kubeConfig: /tmp/kubeconfig-131423863
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-configmap-tddrj
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-test-volume-8881e948-29bc-11e9-9603-eaa511fa0b6c
STEP: Creating a pod to test consume configMaps
Feb  6 03:08:53.263: INFO: Waiting up to 5m0s for pod "pod-configmaps-88839c06-29bc-11e9-9603-eaa511fa0b6c" in namespace "e2e-tests-configmap-tddrj" to be "success or failure"
Feb  6 03:08:53.271: INFO: Pod "pod-configmaps-88839c06-29bc-11e9-9603-eaa511fa0b6c": Phase="Pending", Reason="", readiness=false. Elapsed: 7.334316ms
Feb  6 03:08:55.279: INFO: Pod "pod-configmaps-88839c06-29bc-11e9-9603-eaa511fa0b6c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015947059s
Feb  6 03:08:57.289: INFO: Pod "pod-configmaps-88839c06-29bc-11e9-9603-eaa511fa0b6c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.025440776s
STEP: Saw pod success
Feb  6 03:08:57.289: INFO: Pod "pod-configmaps-88839c06-29bc-11e9-9603-eaa511fa0b6c" satisfied condition "success or failure"
Feb  6 03:08:57.297: INFO: Trying to get logs from node 10.190.119.143 pod pod-configmaps-88839c06-29bc-11e9-9603-eaa511fa0b6c container configmap-volume-test: <nil>
STEP: delete the pod
Feb  6 03:08:57.351: INFO: Waiting for pod pod-configmaps-88839c06-29bc-11e9-9603-eaa511fa0b6c to disappear
Feb  6 03:08:57.359: INFO: Pod pod-configmaps-88839c06-29bc-11e9-9603-eaa511fa0b6c no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  6 03:08:57.359: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-configmap-tddrj" for this suite.
Feb  6 03:09:03.451: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 03:09:03.583: INFO: namespace: e2e-tests-configmap-tddrj, resource: bindings, ignored listing per whitelist
Feb  6 03:09:03.765: INFO: namespace e2e-tests-configmap-tddrj deletion completed in 6.393154261s

• [SLOW TEST:10.910 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Projected 
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  6 03:09:03.765: INFO: >>> kubeConfig: /tmp/kubeconfig-131423863
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-fnvgw
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating configMap with name configmap-projected-all-test-volume-8ef92765-29bc-11e9-9603-eaa511fa0b6c
STEP: Creating secret with name secret-projected-all-test-volume-8ef92745-29bc-11e9-9603-eaa511fa0b6c
STEP: Creating a pod to test Check all projections for projected volume plugin
Feb  6 03:09:04.122: INFO: Waiting up to 5m0s for pod "projected-volume-8ef92704-29bc-11e9-9603-eaa511fa0b6c" in namespace "e2e-tests-projected-fnvgw" to be "success or failure"
Feb  6 03:09:04.131: INFO: Pod "projected-volume-8ef92704-29bc-11e9-9603-eaa511fa0b6c": Phase="Pending", Reason="", readiness=false. Elapsed: 8.835742ms
Feb  6 03:09:06.141: INFO: Pod "projected-volume-8ef92704-29bc-11e9-9603-eaa511fa0b6c": Phase="Running", Reason="", readiness=true. Elapsed: 2.019065663s
Feb  6 03:09:08.150: INFO: Pod "projected-volume-8ef92704-29bc-11e9-9603-eaa511fa0b6c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.027951129s
STEP: Saw pod success
Feb  6 03:09:08.150: INFO: Pod "projected-volume-8ef92704-29bc-11e9-9603-eaa511fa0b6c" satisfied condition "success or failure"
Feb  6 03:09:08.158: INFO: Trying to get logs from node 10.190.119.184 pod projected-volume-8ef92704-29bc-11e9-9603-eaa511fa0b6c container projected-all-volume-test: <nil>
STEP: delete the pod
Feb  6 03:09:08.226: INFO: Waiting for pod projected-volume-8ef92704-29bc-11e9-9603-eaa511fa0b6c to disappear
Feb  6 03:09:08.247: INFO: Pod projected-volume-8ef92704-29bc-11e9-9603-eaa511fa0b6c no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  6 03:09:08.247: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-fnvgw" for this suite.
Feb  6 03:09:14.291: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 03:09:14.591: INFO: namespace: e2e-tests-projected-fnvgw, resource: bindings, ignored listing per whitelist
Feb  6 03:09:14.804: INFO: namespace e2e-tests-projected-fnvgw deletion completed in 6.544833881s

• [SLOW TEST:11.039 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  6 03:09:14.805: INFO: >>> kubeConfig: /tmp/kubeconfig-131423863
STEP: Building a namespace api object, basename namespaces
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-namespaces-k9tlf
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a test namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-nsdeletetest-rcz4t
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a pod in the namespace
STEP: Waiting for the pod to have running status
STEP: Creating an uninitialized pod in the namespace
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
Feb  6 03:09:25.366: INFO: error from create uninitialized namespace: Internal error occurred: object deleted while waiting for creation
STEP: Recreating the namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-nsdeletetest-58cwv
STEP: Verifying there are no pods in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  6 03:09:43.603: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-namespaces-k9tlf" for this suite.
Feb  6 03:09:49.646: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 03:09:49.693: INFO: namespace: e2e-tests-namespaces-k9tlf, resource: bindings, ignored listing per whitelist
Feb  6 03:09:49.975: INFO: namespace e2e-tests-namespaces-k9tlf deletion completed in 6.355381412s
STEP: Destroying namespace "e2e-tests-nsdeletetest-rcz4t" for this suite.
Feb  6 03:09:49.982: INFO: Namespace e2e-tests-nsdeletetest-rcz4t was already deleted
STEP: Destroying namespace "e2e-tests-nsdeletetest-58cwv" for this suite.
Feb  6 03:09:56.009: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 03:09:56.277: INFO: namespace: e2e-tests-nsdeletetest-58cwv, resource: bindings, ignored listing per whitelist
Feb  6 03:09:56.300: INFO: namespace e2e-tests-nsdeletetest-58cwv deletion completed in 6.317983909s

• [SLOW TEST:41.495 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run rc 
  should create an rc from an image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  6 03:09:56.300: INFO: >>> kubeConfig: /tmp/kubeconfig-131423863
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-klnnz
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Kubectl run rc
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1246
[It] should create an rc from an image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Feb  6 03:09:56.602: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-131423863 run e2e-test-nginx-rc --image=docker.io/library/nginx:1.14-alpine --generator=run/v1 --namespace=e2e-tests-kubectl-klnnz'
Feb  6 03:09:56.763: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl create instead.\n"
Feb  6 03:09:56.763: INFO: stdout: "replicationcontroller/e2e-test-nginx-rc created\n"
STEP: verifying the rc e2e-test-nginx-rc was created
STEP: verifying the pod controlled by rc e2e-test-nginx-rc was created
STEP: confirm that you can get logs from an rc
Feb  6 03:09:56.787: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [e2e-test-nginx-rc-mzxqw]
Feb  6 03:09:56.787: INFO: Waiting up to 5m0s for pod "e2e-test-nginx-rc-mzxqw" in namespace "e2e-tests-kubectl-klnnz" to be "running and ready"
Feb  6 03:09:56.798: INFO: Pod "e2e-test-nginx-rc-mzxqw": Phase="Pending", Reason="", readiness=false. Elapsed: 10.820672ms
Feb  6 03:09:58.807: INFO: Pod "e2e-test-nginx-rc-mzxqw": Phase="Running", Reason="", readiness=true. Elapsed: 2.019688016s
Feb  6 03:09:58.807: INFO: Pod "e2e-test-nginx-rc-mzxqw" satisfied condition "running and ready"
Feb  6 03:09:58.807: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [e2e-test-nginx-rc-mzxqw]
Feb  6 03:09:58.807: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-131423863 logs rc/e2e-test-nginx-rc --namespace=e2e-tests-kubectl-klnnz'
Feb  6 03:09:59.099: INFO: stderr: ""
Feb  6 03:09:59.099: INFO: stdout: ""
[AfterEach] [k8s.io] Kubectl run rc
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1251
Feb  6 03:09:59.099: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-131423863 delete rc e2e-test-nginx-rc --namespace=e2e-tests-kubectl-klnnz'
Feb  6 03:09:59.303: INFO: stderr: ""
Feb  6 03:09:59.303: INFO: stdout: "replicationcontroller \"e2e-test-nginx-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  6 03:09:59.303: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-klnnz" for this suite.
Feb  6 03:10:23.344: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 03:10:23.649: INFO: namespace: e2e-tests-kubectl-klnnz, resource: bindings, ignored listing per whitelist
Feb  6 03:10:23.671: INFO: namespace e2e-tests-kubectl-klnnz deletion completed in 24.354934674s

• [SLOW TEST:27.371 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run rc
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create an rc from an image  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  6 03:10:23.674: INFO: >>> kubeConfig: /tmp/kubeconfig-131423863
STEP: Building a namespace api object, basename init-container
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-init-container-4h8v2
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:43
[It] should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
Feb  6 03:10:23.972: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  6 03:10:27.386: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-init-container-4h8v2" for this suite.
Feb  6 03:10:49.458: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 03:10:49.776: INFO: namespace: e2e-tests-init-container-4h8v2, resource: bindings, ignored listing per whitelist
Feb  6 03:10:49.870: INFO: namespace e2e-tests-init-container-4h8v2 deletion completed in 22.454846286s

• [SLOW TEST:26.196 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run deployment 
  should create a deployment from an image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  6 03:10:49.870: INFO: >>> kubeConfig: /tmp/kubeconfig-131423863
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-6whkx
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[BeforeEach] [k8s.io] Kubectl run deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1347
[It] should create a deployment from an image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: running the image docker.io/library/nginx:1.14-alpine
Feb  6 03:10:50.192: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-131423863 run e2e-test-nginx-deployment --image=docker.io/library/nginx:1.14-alpine --generator=deployment/v1beta1 --namespace=e2e-tests-kubectl-6whkx'
Feb  6 03:10:50.331: INFO: stderr: "kubectl run --generator=deployment/v1beta1 is DEPRECATED and will be removed in a future version. Use kubectl create instead.\n"
Feb  6 03:10:50.331: INFO: stdout: "deployment.extensions/e2e-test-nginx-deployment created\n"
STEP: verifying the deployment e2e-test-nginx-deployment was created
STEP: verifying the pod controlled by deployment e2e-test-nginx-deployment was created
[AfterEach] [k8s.io] Kubectl run deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1352
Feb  6 03:10:52.400: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-131423863 delete deployment e2e-test-nginx-deployment --namespace=e2e-tests-kubectl-6whkx'
Feb  6 03:10:52.600: INFO: stderr: ""
Feb  6 03:10:52.600: INFO: stdout: "deployment.extensions \"e2e-test-nginx-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  6 03:10:52.600: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-6whkx" for this suite.
Feb  6 03:11:14.641: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 03:11:15.059: INFO: namespace: e2e-tests-kubectl-6whkx, resource: bindings, ignored listing per whitelist
Feb  6 03:11:15.193: INFO: namespace e2e-tests-kubectl-6whkx deletion completed in 22.57949256s

• [SLOW TEST:25.323 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl run deployment
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should create a deployment from an image  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] version v1
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  6 03:11:15.194: INFO: >>> kubeConfig: /tmp/kubeconfig-131423863
STEP: Building a namespace api object, basename proxy
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-proxy-9m9gl
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb  6 03:11:15.542: INFO: (0) /api/v1/nodes/10.190.119.133:10250/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 22.103699ms)
Feb  6 03:11:15.559: INFO: (1) /api/v1/nodes/10.190.119.133:10250/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 17.184832ms)
Feb  6 03:11:15.575: INFO: (2) /api/v1/nodes/10.190.119.133:10250/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 15.67798ms)
Feb  6 03:11:15.592: INFO: (3) /api/v1/nodes/10.190.119.133:10250/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 16.659454ms)
Feb  6 03:11:15.606: INFO: (4) /api/v1/nodes/10.190.119.133:10250/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 14.196231ms)
Feb  6 03:11:15.620: INFO: (5) /api/v1/nodes/10.190.119.133:10250/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 14.014581ms)
Feb  6 03:11:15.640: INFO: (6) /api/v1/nodes/10.190.119.133:10250/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 19.164475ms)
Feb  6 03:11:15.654: INFO: (7) /api/v1/nodes/10.190.119.133:10250/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 14.410171ms)
Feb  6 03:11:15.672: INFO: (8) /api/v1/nodes/10.190.119.133:10250/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 17.940831ms)
Feb  6 03:11:15.688: INFO: (9) /api/v1/nodes/10.190.119.133:10250/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 15.736511ms)
Feb  6 03:11:15.703: INFO: (10) /api/v1/nodes/10.190.119.133:10250/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 15.051394ms)
Feb  6 03:11:15.720: INFO: (11) /api/v1/nodes/10.190.119.133:10250/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 16.457038ms)
Feb  6 03:11:15.735: INFO: (12) /api/v1/nodes/10.190.119.133:10250/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 15.367137ms)
Feb  6 03:11:15.753: INFO: (13) /api/v1/nodes/10.190.119.133:10250/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 17.168896ms)
Feb  6 03:11:15.791: INFO: (14) /api/v1/nodes/10.190.119.133:10250/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 38.301516ms)
Feb  6 03:11:15.805: INFO: (15) /api/v1/nodes/10.190.119.133:10250/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 14.199021ms)
Feb  6 03:11:15.820: INFO: (16) /api/v1/nodes/10.190.119.133:10250/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 14.320586ms)
Feb  6 03:11:15.834: INFO: (17) /api/v1/nodes/10.190.119.133:10250/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 14.413721ms)
Feb  6 03:11:15.850: INFO: (18) /api/v1/nodes/10.190.119.133:10250/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 15.398047ms)
Feb  6 03:11:15.867: INFO: (19) /api/v1/nodes/10.190.119.133:10250/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 16.881792ms)
[AfterEach] version v1
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  6 03:11:15.867: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-proxy-9m9gl" for this suite.
Feb  6 03:11:21.904: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 03:11:22.319: INFO: namespace: e2e-tests-proxy-9m9gl, resource: bindings, ignored listing per whitelist
Feb  6 03:11:22.384: INFO: namespace e2e-tests-proxy-9m9gl deletion completed in 6.50642539s

• [SLOW TEST:7.190 seconds]
[sig-network] Proxy
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  version v1
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:56
    should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-apps] ReplicaSet 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  6 03:11:22.384: INFO: >>> kubeConfig: /tmp/kubeconfig-131423863
STEP: Building a namespace api object, basename replicaset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-replicaset-rrfhr
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb  6 03:11:22.699: INFO: Creating ReplicaSet my-hostname-basic-e198df83-29bc-11e9-9603-eaa511fa0b6c
Feb  6 03:11:22.715: INFO: Pod name my-hostname-basic-e198df83-29bc-11e9-9603-eaa511fa0b6c: Found 0 pods out of 1
Feb  6 03:11:27.726: INFO: Pod name my-hostname-basic-e198df83-29bc-11e9-9603-eaa511fa0b6c: Found 1 pods out of 1
Feb  6 03:11:27.726: INFO: Ensuring a pod for ReplicaSet "my-hostname-basic-e198df83-29bc-11e9-9603-eaa511fa0b6c" is running
Feb  6 03:11:27.736: INFO: Pod "my-hostname-basic-e198df83-29bc-11e9-9603-eaa511fa0b6c-c6pgx" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-02-06 03:11:22 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-02-06 03:11:24 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-02-06 03:11:24 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-02-06 03:11:22 +0000 UTC Reason: Message:}])
Feb  6 03:11:27.736: INFO: Trying to dial the pod
Feb  6 03:11:32.796: INFO: Controller my-hostname-basic-e198df83-29bc-11e9-9603-eaa511fa0b6c: Got expected result from replica 1 [my-hostname-basic-e198df83-29bc-11e9-9603-eaa511fa0b6c-c6pgx]: "my-hostname-basic-e198df83-29bc-11e9-9603-eaa511fa0b6c-c6pgx", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  6 03:11:32.796: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-replicaset-rrfhr" for this suite.
Feb  6 03:11:38.855: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 03:11:39.278: INFO: namespace: e2e-tests-replicaset-rrfhr, resource: bindings, ignored listing per whitelist
Feb  6 03:11:39.471: INFO: namespace e2e-tests-replicaset-rrfhr deletion completed in 6.66080415s

• [SLOW TEST:17.087 seconds]
[sig-apps] ReplicaSet
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[k8s.io] [sig-node] PreStop 
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  6 03:11:39.472: INFO: >>> kubeConfig: /tmp/kubeconfig-131423863
STEP: Building a namespace api object, basename prestop
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-prestop-w94l8
STEP: Waiting for a default service account to be provisioned in namespace
[It] should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating server pod server in namespace e2e-tests-prestop-w94l8
STEP: Waiting for pods to come up.
STEP: Creating tester pod tester in namespace e2e-tests-prestop-w94l8
STEP: Deleting pre-stop pod
Feb  6 03:11:48.965: INFO: Saw: {
	"Hostname": "server",
	"Sent": null,
	"Received": {
		"prestop": 1
	},
	"Errors": null,
	"Log": [
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up."
	],
	"StillContactingPeers": true
}
STEP: Deleting the server pod
[AfterEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  6 03:11:48.980: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-prestop-w94l8" for this suite.
Feb  6 03:12:29.035: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 03:12:29.257: INFO: namespace: e2e-tests-prestop-w94l8, resource: bindings, ignored listing per whitelist
Feb  6 03:12:29.428: INFO: namespace e2e-tests-prestop-w94l8 deletion completed in 40.424197662s

• [SLOW TEST:49.956 seconds]
[k8s.io] [sig-node] PreStop
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with secret pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  6 03:12:29.428: INFO: >>> kubeConfig: /tmp/kubeconfig-131423863
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-subpath-hng4q
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with secret pod [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating pod pod-subpath-test-secret-r964
STEP: Creating a pod to test atomic-volume-subpath
Feb  6 03:12:29.842: INFO: Waiting up to 5m0s for pod "pod-subpath-test-secret-r964" in namespace "e2e-tests-subpath-hng4q" to be "success or failure"
Feb  6 03:12:29.853: INFO: Pod "pod-subpath-test-secret-r964": Phase="Pending", Reason="", readiness=false. Elapsed: 10.310724ms
Feb  6 03:12:31.862: INFO: Pod "pod-subpath-test-secret-r964": Phase="Pending", Reason="", readiness=false. Elapsed: 2.019920905s
Feb  6 03:12:33.872: INFO: Pod "pod-subpath-test-secret-r964": Phase="Running", Reason="", readiness=false. Elapsed: 4.029673475s
Feb  6 03:12:35.881: INFO: Pod "pod-subpath-test-secret-r964": Phase="Running", Reason="", readiness=false. Elapsed: 6.038893033s
Feb  6 03:12:37.928: INFO: Pod "pod-subpath-test-secret-r964": Phase="Running", Reason="", readiness=false. Elapsed: 8.085955091s
Feb  6 03:12:39.952: INFO: Pod "pod-subpath-test-secret-r964": Phase="Running", Reason="", readiness=false. Elapsed: 10.109789688s
Feb  6 03:12:41.961: INFO: Pod "pod-subpath-test-secret-r964": Phase="Running", Reason="", readiness=false. Elapsed: 12.118731364s
Feb  6 03:12:43.970: INFO: Pod "pod-subpath-test-secret-r964": Phase="Running", Reason="", readiness=false. Elapsed: 14.127605441s
Feb  6 03:12:45.980: INFO: Pod "pod-subpath-test-secret-r964": Phase="Running", Reason="", readiness=false. Elapsed: 16.137891153s
Feb  6 03:12:47.995: INFO: Pod "pod-subpath-test-secret-r964": Phase="Running", Reason="", readiness=false. Elapsed: 18.152978745s
Feb  6 03:12:50.017: INFO: Pod "pod-subpath-test-secret-r964": Phase="Running", Reason="", readiness=false. Elapsed: 20.174547141s
Feb  6 03:12:52.029: INFO: Pod "pod-subpath-test-secret-r964": Phase="Running", Reason="", readiness=false. Elapsed: 22.186467144s
Feb  6 03:12:54.038: INFO: Pod "pod-subpath-test-secret-r964": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.195851855s
STEP: Saw pod success
Feb  6 03:12:54.038: INFO: Pod "pod-subpath-test-secret-r964" satisfied condition "success or failure"
Feb  6 03:12:54.047: INFO: Trying to get logs from node 10.190.119.143 pod pod-subpath-test-secret-r964 container test-container-subpath-secret-r964: <nil>
STEP: delete the pod
Feb  6 03:12:54.096: INFO: Waiting for pod pod-subpath-test-secret-r964 to disappear
Feb  6 03:12:54.191: INFO: Pod pod-subpath-test-secret-r964 no longer exists
STEP: Deleting pod pod-subpath-test-secret-r964
Feb  6 03:12:54.191: INFO: Deleting pod "pod-subpath-test-secret-r964" in namespace "e2e-tests-subpath-hng4q"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  6 03:12:54.200: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-subpath-hng4q" for this suite.
Feb  6 03:13:00.255: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 03:13:00.452: INFO: namespace: e2e-tests-subpath-hng4q, resource: bindings, ignored listing per whitelist
Feb  6 03:13:00.678: INFO: namespace e2e-tests-subpath-hng4q deletion completed in 6.46572252s

• [SLOW TEST:31.250 seconds]
[sig-storage] Subpath
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with secret pod [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
S
------------------------------
[sig-api-machinery] Garbage collector 
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  6 03:13:00.678: INFO: >>> kubeConfig: /tmp/kubeconfig-131423863
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-gc-jdrv9
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for all rs to be garbage collected
STEP: expected 0 rs, got 1 rs
STEP: expected 0 pods, got 2 pods
STEP: Gathering metrics
W0206 03:13:02.806567      15 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Feb  6 03:13:02.806: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  6 03:13:02.806: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-jdrv9" for this suite.
Feb  6 03:13:08.891: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 03:13:09.143: INFO: namespace: e2e-tests-gc-jdrv9, resource: bindings, ignored listing per whitelist
Feb  6 03:13:09.173: INFO: namespace e2e-tests-gc-jdrv9 deletion completed in 6.356243485s

• [SLOW TEST:8.495 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Downward API 
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  6 03:13:09.175: INFO: >>> kubeConfig: /tmp/kubeconfig-131423863
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-pnczl
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Feb  6 03:13:09.530: INFO: Waiting up to 5m0s for pod "downward-api-2143568e-29bd-11e9-9603-eaa511fa0b6c" in namespace "e2e-tests-downward-api-pnczl" to be "success or failure"
Feb  6 03:13:09.539: INFO: Pod "downward-api-2143568e-29bd-11e9-9603-eaa511fa0b6c": Phase="Pending", Reason="", readiness=false. Elapsed: 8.331151ms
Feb  6 03:13:11.563: INFO: Pod "downward-api-2143568e-29bd-11e9-9603-eaa511fa0b6c": Phase="Running", Reason="", readiness=true. Elapsed: 2.032483361s
Feb  6 03:13:13.572: INFO: Pod "downward-api-2143568e-29bd-11e9-9603-eaa511fa0b6c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.041535924s
STEP: Saw pod success
Feb  6 03:13:13.572: INFO: Pod "downward-api-2143568e-29bd-11e9-9603-eaa511fa0b6c" satisfied condition "success or failure"
Feb  6 03:13:13.585: INFO: Trying to get logs from node 10.190.119.143 pod downward-api-2143568e-29bd-11e9-9603-eaa511fa0b6c container dapi-container: <nil>
STEP: delete the pod
Feb  6 03:13:13.642: INFO: Waiting for pod downward-api-2143568e-29bd-11e9-9603-eaa511fa0b6c to disappear
Feb  6 03:13:13.652: INFO: Pod downward-api-2143568e-29bd-11e9-9603-eaa511fa0b6c no longer exists
[AfterEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  6 03:13:13.652: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-pnczl" for this suite.
Feb  6 03:13:19.703: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 03:13:19.796: INFO: namespace: e2e-tests-downward-api-pnczl, resource: bindings, ignored listing per whitelist
Feb  6 03:13:20.076: INFO: namespace e2e-tests-downward-api-pnczl deletion completed in 6.409353834s

• [SLOW TEST:10.901 seconds]
[sig-api-machinery] Downward API
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-api-machinery] Watchers 
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  6 03:13:20.076: INFO: >>> kubeConfig: /tmp/kubeconfig-131423863
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-watch-rdmzm
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: modifying the configmap a second time
STEP: deleting the configmap
STEP: creating a watch on configmaps from the resource version returned by the first update
STEP: Expecting to observe notifications for all changes to the configmap after the first update
Feb  6 03:13:20.442: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-resource-version,GenerateName:,Namespace:e2e-tests-watch-rdmzm,SelfLink:/api/v1/namespaces/e2e-tests-watch-rdmzm/configmaps/e2e-watch-test-resource-version,UID:27be6634-29bd-11e9-bf83-6639c2940cda,ResourceVersion:68845,Generation:0,CreationTimestamp:2019-02-06 03:13:20 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: from-resource-version,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Feb  6 03:13:20.443: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-resource-version,GenerateName:,Namespace:e2e-tests-watch-rdmzm,SelfLink:/api/v1/namespaces/e2e-tests-watch-rdmzm/configmaps/e2e-watch-test-resource-version,UID:27be6634-29bd-11e9-bf83-6639c2940cda,ResourceVersion:68846,Generation:0,CreationTimestamp:2019-02-06 03:13:20 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: from-resource-version,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  6 03:13:20.443: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-watch-rdmzm" for this suite.
Feb  6 03:13:26.487: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 03:13:26.668: INFO: namespace: e2e-tests-watch-rdmzm, resource: bindings, ignored listing per whitelist
Feb  6 03:13:26.917: INFO: namespace e2e-tests-watch-rdmzm deletion completed in 6.457855757s

• [SLOW TEST:6.841 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  6 03:13:26.917: INFO: >>> kubeConfig: /tmp/kubeconfig-131423863
STEP: Building a namespace api object, basename sched-pred
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-sched-pred-qts2q
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:78
Feb  6 03:13:27.208: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Feb  6 03:13:27.232: INFO: Waiting for terminating namespaces to be deleted...
Feb  6 03:13:27.239: INFO: 
Logging pods the kubelet thinks is on node 10.190.119.133 before test
Feb  6 03:13:27.274: INFO: public-crf54ba0a8e6a945a29dcf052ae5eb4941-alb1-6c9c6d49c8-mpnh2 from kube-system started at 2019-02-05 20:47:04 +0000 UTC (4 container statuses recorded)
Feb  6 03:13:27.274: INFO: 	Container ingress-auth-1 ready: true, restart count 0
Feb  6 03:13:27.274: INFO: 	Container ingress-auth-2 ready: true, restart count 0
Feb  6 03:13:27.274: INFO: 	Container ingress-auth-3 ready: true, restart count 0
Feb  6 03:13:27.274: INFO: 	Container nginx-ingress ready: true, restart count 0
Feb  6 03:13:27.274: INFO: ibm-master-proxy-static-10.190.119.133 from kube-system started at <nil> (0 container statuses recorded)
Feb  6 03:13:27.274: INFO: kube-dns-amd64-fddfcc69-g2lwr from kube-system started at 2019-02-05 20:42:13 +0000 UTC (3 container statuses recorded)
Feb  6 03:13:27.274: INFO: 	Container dnsmasq ready: true, restart count 0
Feb  6 03:13:27.274: INFO: 	Container kubedns ready: true, restart count 0
Feb  6 03:13:27.274: INFO: 	Container sidecar ready: true, restart count 0
Feb  6 03:13:27.274: INFO: sonobuoy-systemd-logs-daemon-set-d5b52e18812640c6-b9jsg from heptio-sonobuoy started at 2019-02-06 01:52:35 +0000 UTC (2 container statuses recorded)
Feb  6 03:13:27.274: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 1
Feb  6 03:13:27.274: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Feb  6 03:13:27.274: INFO: ibm-cloud-provider-ip-169-61-69-214-6d655b596d-zg2pn from ibm-system started at 2019-02-05 20:43:56 +0000 UTC (1 container statuses recorded)
Feb  6 03:13:27.274: INFO: 	Container ibm-cloud-provider-ip-169-61-69-214 ready: true, restart count 0
Feb  6 03:13:27.274: INFO: ibm-kube-fluentd-64s4c from kube-system started at 2019-02-05 20:45:46 +0000 UTC (1 container statuses recorded)
Feb  6 03:13:27.274: INFO: 	Container fluentd ready: true, restart count 0
Feb  6 03:13:27.274: INFO: ibm-keepalived-watcher-bsbdb from kube-system started at 2019-02-05 20:41:39 +0000 UTC (1 container statuses recorded)
Feb  6 03:13:27.274: INFO: 	Container keepalived-watcher ready: true, restart count 0
Feb  6 03:13:27.274: INFO: calico-node-crvvm from kube-system started at 2019-02-05 20:41:39 +0000 UTC (2 container statuses recorded)
Feb  6 03:13:27.274: INFO: 	Container calico-node ready: true, restart count 0
Feb  6 03:13:27.274: INFO: 	Container install-cni ready: true, restart count 0
Feb  6 03:13:27.274: INFO: 
Logging pods the kubelet thinks is on node 10.190.119.143 before test
Feb  6 03:13:27.304: INFO: ibm-master-proxy-static-10.190.119.143 from kube-system started at <nil> (0 container statuses recorded)
Feb  6 03:13:27.305: INFO: ibm-keepalived-watcher-mhfb7 from kube-system started at 2019-02-05 20:41:40 +0000 UTC (1 container statuses recorded)
Feb  6 03:13:27.305: INFO: 	Container keepalived-watcher ready: true, restart count 0
Feb  6 03:13:27.305: INFO: ibm-kube-fluentd-m6bg7 from kube-system started at 2019-02-05 20:45:46 +0000 UTC (1 container statuses recorded)
Feb  6 03:13:27.305: INFO: 	Container fluentd ready: true, restart count 0
Feb  6 03:13:27.305: INFO: public-crf54ba0a8e6a945a29dcf052ae5eb4941-alb1-6c9c6d49c8-v28fj from kube-system started at 2019-02-05 20:47:04 +0000 UTC (4 container statuses recorded)
Feb  6 03:13:27.305: INFO: 	Container ingress-auth-1 ready: true, restart count 0
Feb  6 03:13:27.305: INFO: 	Container ingress-auth-2 ready: true, restart count 0
Feb  6 03:13:27.305: INFO: 	Container ingress-auth-3 ready: true, restart count 0
Feb  6 03:13:27.305: INFO: 	Container nginx-ingress ready: true, restart count 0
Feb  6 03:13:27.305: INFO: ibm-cloud-provider-ip-169-61-69-214-6d655b596d-659s6 from ibm-system started at 2019-02-05 20:43:56 +0000 UTC (1 container statuses recorded)
Feb  6 03:13:27.305: INFO: 	Container ibm-cloud-provider-ip-169-61-69-214 ready: true, restart count 0
Feb  6 03:13:27.305: INFO: sonobuoy-systemd-logs-daemon-set-d5b52e18812640c6-ftvb9 from heptio-sonobuoy started at 2019-02-06 01:52:35 +0000 UTC (2 container statuses recorded)
Feb  6 03:13:27.305: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 1
Feb  6 03:13:27.305: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Feb  6 03:13:27.305: INFO: calico-node-552zb from kube-system started at 2019-02-05 20:41:40 +0000 UTC (2 container statuses recorded)
Feb  6 03:13:27.305: INFO: 	Container calico-node ready: true, restart count 0
Feb  6 03:13:27.305: INFO: 	Container install-cni ready: true, restart count 0
Feb  6 03:13:27.305: INFO: test-k8s-e2e-pvg-master-verification from default started at 2019-02-06 01:52:27 +0000 UTC (1 container statuses recorded)
Feb  6 03:13:27.305: INFO: 	Container test-k8s-e2e-pvg-master-verification ready: true, restart count 0
Feb  6 03:13:27.305: INFO: sonobuoy-e2e-job-0d701a7a98354698 from heptio-sonobuoy started at 2019-02-06 01:52:35 +0000 UTC (2 container statuses recorded)
Feb  6 03:13:27.305: INFO: 	Container e2e ready: true, restart count 0
Feb  6 03:13:27.306: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Feb  6 03:13:27.306: INFO: 
Logging pods the kubelet thinks is on node 10.190.119.184 before test
Feb  6 03:13:27.341: INFO: calico-node-vk476 from kube-system started at 2019-02-05 20:41:33 +0000 UTC (2 container statuses recorded)
Feb  6 03:13:27.341: INFO: 	Container calico-node ready: true, restart count 0
Feb  6 03:13:27.341: INFO: 	Container install-cni ready: true, restart count 0
Feb  6 03:13:27.341: INFO: sonobuoy from heptio-sonobuoy started at 2019-02-06 01:52:33 +0000 UTC (1 container statuses recorded)
Feb  6 03:13:27.341: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Feb  6 03:13:27.341: INFO: vpn-6c6b45457f-dw7t6 from kube-system started at 2019-02-05 20:41:33 +0000 UTC (1 container statuses recorded)
Feb  6 03:13:27.341: INFO: 	Container vpn ready: true, restart count 0
Feb  6 03:13:27.341: INFO: ibm-file-plugin-7b5c95b4d-hcw67 from kube-system started at 2019-02-05 20:41:33 +0000 UTC (1 container statuses recorded)
Feb  6 03:13:27.341: INFO: 	Container ibm-file-plugin-container ready: true, restart count 0
Feb  6 03:13:27.341: INFO: ibm-master-proxy-static-10.190.119.184 from kube-system started at <nil> (0 container statuses recorded)
Feb  6 03:13:27.342: INFO: calico-kube-controllers-5c699798bc-q5g5q from kube-system started at 2019-02-05 20:41:33 +0000 UTC (1 container statuses recorded)
Feb  6 03:13:27.342: INFO: 	Container calico-kube-controllers ready: true, restart count 0
Feb  6 03:13:27.342: INFO: kube-dns-amd64-fddfcc69-stz86 from kube-system started at 2019-02-05 20:41:33 +0000 UTC (3 container statuses recorded)
Feb  6 03:13:27.342: INFO: 	Container dnsmasq ready: true, restart count 0
Feb  6 03:13:27.342: INFO: 	Container kubedns ready: true, restart count 0
Feb  6 03:13:27.342: INFO: 	Container sidecar ready: true, restart count 0
Feb  6 03:13:27.342: INFO: metrics-server-58cf9b87b8-lqfd8 from kube-system started at 2019-02-05 20:41:53 +0000 UTC (2 container statuses recorded)
Feb  6 03:13:27.342: INFO: 	Container metrics-server ready: true, restart count 0
Feb  6 03:13:27.342: INFO: 	Container metrics-server-nanny ready: true, restart count 0
Feb  6 03:13:27.342: INFO: kubernetes-dashboard-b4bc7db5d-6txlp from kube-system started at 2019-02-05 20:41:33 +0000 UTC (1 container statuses recorded)
Feb  6 03:13:27.342: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
Feb  6 03:13:27.342: INFO: ibm-keepalived-watcher-zff5x from kube-system started at 2019-02-05 20:41:33 +0000 UTC (1 container statuses recorded)
Feb  6 03:13:27.342: INFO: 	Container keepalived-watcher ready: true, restart count 0
Feb  6 03:13:27.342: INFO: ibm-kube-fluentd-xhx62 from kube-system started at 2019-02-05 20:45:46 +0000 UTC (1 container statuses recorded)
Feb  6 03:13:27.342: INFO: 	Container fluentd ready: true, restart count 0
Feb  6 03:13:27.342: INFO: sonobuoy-systemd-logs-daemon-set-d5b52e18812640c6-jw4pz from heptio-sonobuoy started at 2019-02-06 01:52:35 +0000 UTC (2 container statuses recorded)
Feb  6 03:13:27.342: INFO: 	Container sonobuoy-systemd-logs-config ready: true, restart count 1
Feb  6 03:13:27.342: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Feb  6 03:13:27.342: INFO: kube-dns-autoscaler-587cd5cd44-gcztk from kube-system started at 2019-02-05 20:41:33 +0000 UTC (1 container statuses recorded)
Feb  6 03:13:27.342: INFO: 	Container autoscaler ready: true, restart count 0
Feb  6 03:13:27.342: INFO: ibm-storage-watcher-59744c5787-r9jsw from kube-system started at 2019-02-05 20:41:33 +0000 UTC (1 container statuses recorded)
Feb  6 03:13:27.343: INFO: 	Container ibm-storage-watcher-container ready: true, restart count 0
[It] validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: verifying the node has the label node 10.190.119.133
STEP: verifying the node has the label node 10.190.119.143
STEP: verifying the node has the label node 10.190.119.184
Feb  6 03:13:27.490: INFO: Pod test-k8s-e2e-pvg-master-verification requesting resource cpu=0m on Node 10.190.119.143
Feb  6 03:13:27.490: INFO: Pod sonobuoy requesting resource cpu=0m on Node 10.190.119.184
Feb  6 03:13:27.490: INFO: Pod sonobuoy-e2e-job-0d701a7a98354698 requesting resource cpu=0m on Node 10.190.119.143
Feb  6 03:13:27.490: INFO: Pod sonobuoy-systemd-logs-daemon-set-d5b52e18812640c6-b9jsg requesting resource cpu=0m on Node 10.190.119.133
Feb  6 03:13:27.490: INFO: Pod sonobuoy-systemd-logs-daemon-set-d5b52e18812640c6-ftvb9 requesting resource cpu=0m on Node 10.190.119.143
Feb  6 03:13:27.490: INFO: Pod sonobuoy-systemd-logs-daemon-set-d5b52e18812640c6-jw4pz requesting resource cpu=0m on Node 10.190.119.184
Feb  6 03:13:27.490: INFO: Pod ibm-cloud-provider-ip-169-61-69-214-6d655b596d-659s6 requesting resource cpu=5m on Node 10.190.119.143
Feb  6 03:13:27.490: INFO: Pod ibm-cloud-provider-ip-169-61-69-214-6d655b596d-zg2pn requesting resource cpu=5m on Node 10.190.119.133
Feb  6 03:13:27.490: INFO: Pod calico-kube-controllers-5c699798bc-q5g5q requesting resource cpu=10m on Node 10.190.119.184
Feb  6 03:13:27.490: INFO: Pod calico-node-552zb requesting resource cpu=255m on Node 10.190.119.143
Feb  6 03:13:27.490: INFO: Pod calico-node-crvvm requesting resource cpu=255m on Node 10.190.119.133
Feb  6 03:13:27.490: INFO: Pod calico-node-vk476 requesting resource cpu=255m on Node 10.190.119.184
Feb  6 03:13:27.490: INFO: Pod ibm-file-plugin-7b5c95b4d-hcw67 requesting resource cpu=50m on Node 10.190.119.184
Feb  6 03:13:27.490: INFO: Pod ibm-keepalived-watcher-bsbdb requesting resource cpu=5m on Node 10.190.119.133
Feb  6 03:13:27.491: INFO: Pod ibm-keepalived-watcher-mhfb7 requesting resource cpu=5m on Node 10.190.119.143
Feb  6 03:13:27.491: INFO: Pod ibm-keepalived-watcher-zff5x requesting resource cpu=5m on Node 10.190.119.184
Feb  6 03:13:27.491: INFO: Pod ibm-kube-fluentd-64s4c requesting resource cpu=25m on Node 10.190.119.133
Feb  6 03:13:27.491: INFO: Pod ibm-kube-fluentd-m6bg7 requesting resource cpu=25m on Node 10.190.119.143
Feb  6 03:13:27.491: INFO: Pod ibm-kube-fluentd-xhx62 requesting resource cpu=25m on Node 10.190.119.184
Feb  6 03:13:27.491: INFO: Pod ibm-master-proxy-static-10.190.119.133 requesting resource cpu=25m on Node 10.190.119.133
Feb  6 03:13:27.491: INFO: Pod ibm-master-proxy-static-10.190.119.143 requesting resource cpu=25m on Node 10.190.119.143
Feb  6 03:13:27.491: INFO: Pod ibm-master-proxy-static-10.190.119.184 requesting resource cpu=25m on Node 10.190.119.184
Feb  6 03:13:27.491: INFO: Pod ibm-storage-watcher-59744c5787-r9jsw requesting resource cpu=50m on Node 10.190.119.184
Feb  6 03:13:27.491: INFO: Pod kube-dns-amd64-fddfcc69-g2lwr requesting resource cpu=260m on Node 10.190.119.133
Feb  6 03:13:27.491: INFO: Pod kube-dns-amd64-fddfcc69-stz86 requesting resource cpu=260m on Node 10.190.119.184
Feb  6 03:13:27.491: INFO: Pod kube-dns-autoscaler-587cd5cd44-gcztk requesting resource cpu=20m on Node 10.190.119.184
Feb  6 03:13:27.491: INFO: Pod kubernetes-dashboard-b4bc7db5d-6txlp requesting resource cpu=50m on Node 10.190.119.184
Feb  6 03:13:27.491: INFO: Pod metrics-server-58cf9b87b8-lqfd8 requesting resource cpu=53m on Node 10.190.119.184
Feb  6 03:13:27.491: INFO: Pod public-crf54ba0a8e6a945a29dcf052ae5eb4941-alb1-6c9c6d49c8-mpnh2 requesting resource cpu=0m on Node 10.190.119.133
Feb  6 03:13:27.491: INFO: Pod public-crf54ba0a8e6a945a29dcf052ae5eb4941-alb1-6c9c6d49c8-v28fj requesting resource cpu=0m on Node 10.190.119.143
Feb  6 03:13:27.492: INFO: Pod vpn-6c6b45457f-dw7t6 requesting resource cpu=5m on Node 10.190.119.184
STEP: Starting Pods to consume most of the cluster CPU.
STEP: Creating another pod that requires unavailable amount of CPU.
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-2bfabe47-29bd-11e9-9603-eaa511fa0b6c.1580a7d59143966c], Reason = [Scheduled], Message = [Successfully assigned e2e-tests-sched-pred-qts2q/filler-pod-2bfabe47-29bd-11e9-9603-eaa511fa0b6c to 10.190.119.133]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-2bfabe47-29bd-11e9-9603-eaa511fa0b6c.1580a7d5c370735b], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-2bfabe47-29bd-11e9-9603-eaa511fa0b6c.1580a7d5c65bf528], Reason = [Created], Message = [Created container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-2bfabe47-29bd-11e9-9603-eaa511fa0b6c.1580a7d5cd631387], Reason = [Started], Message = [Started container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-2bfe0a51-29bd-11e9-9603-eaa511fa0b6c.1580a7d59264f8e9], Reason = [Scheduled], Message = [Successfully assigned e2e-tests-sched-pred-qts2q/filler-pod-2bfe0a51-29bd-11e9-9603-eaa511fa0b6c to 10.190.119.143]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-2bfe0a51-29bd-11e9-9603-eaa511fa0b6c.1580a7d5bf6c5c07], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-2bfe0a51-29bd-11e9-9603-eaa511fa0b6c.1580a7d5c170b146], Reason = [Created], Message = [Created container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-2bfe0a51-29bd-11e9-9603-eaa511fa0b6c.1580a7d5ca4bdc5d], Reason = [Started], Message = [Started container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-2c00827e-29bd-11e9-9603-eaa511fa0b6c.1580a7d592f1af6d], Reason = [Scheduled], Message = [Successfully assigned e2e-tests-sched-pred-qts2q/filler-pod-2c00827e-29bd-11e9-9603-eaa511fa0b6c to 10.190.119.184]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-2c00827e-29bd-11e9-9603-eaa511fa0b6c.1580a7d5c345e752], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-2c00827e-29bd-11e9-9603-eaa511fa0b6c.1580a7d5c607a462], Reason = [Created], Message = [Created container]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-2c00827e-29bd-11e9-9603-eaa511fa0b6c.1580a7d5cdcf1be0], Reason = [Started], Message = [Started container]
STEP: Considering event: 
Type = [Warning], Name = [additional-pod.1580a7d60de6e925], Reason = [FailedScheduling], Message = [0/3 nodes are available: 3 Insufficient cpu.]
STEP: removing the label node off the node 10.190.119.143
STEP: verifying the node doesn't have the label node
STEP: removing the label node off the node 10.190.119.184
STEP: verifying the node doesn't have the label node
STEP: removing the label node off the node 10.190.119.133
STEP: verifying the node doesn't have the label node
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  6 03:13:30.802: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-sched-pred-qts2q" for this suite.
Feb  6 03:13:38.844: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 03:13:39.209: INFO: namespace: e2e-tests-sched-pred-qts2q, resource: bindings, ignored listing per whitelist
Feb  6 03:13:39.230: INFO: namespace e2e-tests-sched-pred-qts2q deletion completed in 8.416685601s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:69

• [SLOW TEST:12.313 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:22
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl version 
  should check is all data is printed  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  6 03:13:39.230: INFO: >>> kubeConfig: /tmp/kubeconfig-131423863
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-kubectl-lb6lg
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:241
[It] should check is all data is printed  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
Feb  6 03:13:39.604: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-131423863 version'
Feb  6 03:13:39.729: INFO: stderr: ""
Feb  6 03:13:39.729: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"12\", GitVersion:\"v1.12.1\", GitCommit:\"4ed3216f3ec431b140b1d899130a69fc671678f4\", GitTreeState:\"clean\", BuildDate:\"2018-10-05T16:46:06Z\", GoVersion:\"go1.10.4\", Compiler:\"gc\", Platform:\"linux/amd64\"}\nServer Version: version.Info{Major:\"1\", Minor:\"12\", GitVersion:\"v1.12.5+IKS\", GitCommit:\"4b76e71fd0eed7d9bda8f51ef5d61afe113d04ad\", GitTreeState:\"clean\", BuildDate:\"2019-02-01T10:26:11Z\", GoVersion:\"go1.10.7\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  6 03:13:39.729: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-kubectl-lb6lg" for this suite.
Feb  6 03:13:45.769: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 03:13:45.922: INFO: namespace: e2e-tests-kubectl-lb6lg, resource: bindings, ignored listing per whitelist
Feb  6 03:13:46.165: INFO: namespace e2e-tests-kubectl-lb6lg deletion completed in 6.422663014s

• [SLOW TEST:6.935 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:22
  [k8s.io] Kubectl version
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    should check is all data is printed  [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[sig-network] Services 
  should provide secure master service  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  6 03:13:46.165: INFO: >>> kubeConfig: /tmp/kubeconfig-131423863
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-services-7b54s
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:83
[It] should provide secure master service  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[AfterEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  6 03:13:46.463: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-services-7b54s" for this suite.
Feb  6 03:13:54.520: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 03:13:54.914: INFO: namespace: e2e-tests-services-7b54s, resource: bindings, ignored listing per whitelist
Feb  6 03:13:54.940: INFO: namespace e2e-tests-services-7b54s deletion completed in 8.46366493s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:88

• [SLOW TEST:8.775 seconds]
[sig-network] Services
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:22
  should provide secure master service  [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  6 03:13:54.940: INFO: >>> kubeConfig: /tmp/kubeconfig-131423863
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-emptydir-t5xl6
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test emptydir 0644 on tmpfs
Feb  6 03:13:55.312: INFO: Waiting up to 5m0s for pod "pod-3c8cbd2c-29bd-11e9-9603-eaa511fa0b6c" in namespace "e2e-tests-emptydir-t5xl6" to be "success or failure"
Feb  6 03:13:55.320: INFO: Pod "pod-3c8cbd2c-29bd-11e9-9603-eaa511fa0b6c": Phase="Pending", Reason="", readiness=false. Elapsed: 8.134154ms
Feb  6 03:13:57.330: INFO: Pod "pod-3c8cbd2c-29bd-11e9-9603-eaa511fa0b6c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.017901573s
STEP: Saw pod success
Feb  6 03:13:57.330: INFO: Pod "pod-3c8cbd2c-29bd-11e9-9603-eaa511fa0b6c" satisfied condition "success or failure"
Feb  6 03:13:57.340: INFO: Trying to get logs from node 10.190.119.184 pod pod-3c8cbd2c-29bd-11e9-9603-eaa511fa0b6c container test-container: <nil>
STEP: delete the pod
Feb  6 03:13:57.417: INFO: Waiting for pod pod-3c8cbd2c-29bd-11e9-9603-eaa511fa0b6c to disappear
Feb  6 03:13:57.424: INFO: Pod pod-3c8cbd2c-29bd-11e9-9603-eaa511fa0b6c no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  6 03:13:57.424: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-emptydir-t5xl6" for this suite.
Feb  6 03:14:03.463: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 03:14:03.787: INFO: namespace: e2e-tests-emptydir-t5xl6, resource: bindings, ignored listing per whitelist
Feb  6 03:14:03.804: INFO: namespace e2e-tests-emptydir-t5xl6 deletion completed in 6.366679819s

• [SLOW TEST:8.864 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0644,tmpfs) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  6 03:14:03.805: INFO: >>> kubeConfig: /tmp/kubeconfig-131423863
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-secrets-lrdb9
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating secret with name secret-test-41e8a834-29bd-11e9-9603-eaa511fa0b6c
STEP: Creating a pod to test consume secrets
Feb  6 03:14:04.320: INFO: Waiting up to 5m0s for pod "pod-secrets-41ebadd2-29bd-11e9-9603-eaa511fa0b6c" in namespace "e2e-tests-secrets-lrdb9" to be "success or failure"
Feb  6 03:14:04.329: INFO: Pod "pod-secrets-41ebadd2-29bd-11e9-9603-eaa511fa0b6c": Phase="Pending", Reason="", readiness=false. Elapsed: 9.095418ms
Feb  6 03:14:06.352: INFO: Pod "pod-secrets-41ebadd2-29bd-11e9-9603-eaa511fa0b6c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.031955834s
STEP: Saw pod success
Feb  6 03:14:06.352: INFO: Pod "pod-secrets-41ebadd2-29bd-11e9-9603-eaa511fa0b6c" satisfied condition "success or failure"
Feb  6 03:14:06.360: INFO: Trying to get logs from node 10.190.119.133 pod pod-secrets-41ebadd2-29bd-11e9-9603-eaa511fa0b6c container secret-volume-test: <nil>
STEP: delete the pod
Feb  6 03:14:06.413: INFO: Waiting for pod pod-secrets-41ebadd2-29bd-11e9-9603-eaa511fa0b6c to disappear
Feb  6 03:14:06.421: INFO: Pod pod-secrets-41ebadd2-29bd-11e9-9603-eaa511fa0b6c no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  6 03:14:06.421: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-secrets-lrdb9" for this suite.
Feb  6 03:14:12.462: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 03:14:12.560: INFO: namespace: e2e-tests-secrets-lrdb9, resource: bindings, ignored listing per whitelist
Feb  6 03:14:12.802: INFO: namespace e2e-tests-secrets-lrdb9 deletion completed in 6.368514561s

• [SLOW TEST:8.998 seconds]
[sig-storage] Secrets
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume with defaultMode set [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  6 03:14:12.804: INFO: >>> kubeConfig: /tmp/kubeconfig-131423863
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-statefulset-wmvf5
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:59
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:74
STEP: Creating service test in namespace e2e-tests-statefulset-wmvf5
[It] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Initializing watcher for selector baz=blah,foo=bar
STEP: Creating stateful set ss in namespace e2e-tests-statefulset-wmvf5
STEP: Waiting until all stateful set ss replicas will be running in namespace e2e-tests-statefulset-wmvf5
Feb  6 03:14:13.250: INFO: Found 0 stateful pods, waiting for 1
Feb  6 03:14:23.274: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will halt with unhealthy stateful pod
Feb  6 03:14:23.288: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-131423863 exec --namespace=e2e-tests-statefulset-wmvf5 ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Feb  6 03:14:23.676: INFO: stderr: ""
Feb  6 03:14:23.676: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Feb  6 03:14:23.676: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Feb  6 03:14:23.687: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Feb  6 03:14:33.709: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Feb  6 03:14:33.709: INFO: Waiting for statefulset status.replicas updated to 0
Feb  6 03:14:33.748: INFO: Verifying statefulset ss doesn't scale past 1 for another 9.999998978s
Feb  6 03:14:34.757: INFO: Verifying statefulset ss doesn't scale past 1 for another 8.989091801s
Feb  6 03:14:35.767: INFO: Verifying statefulset ss doesn't scale past 1 for another 7.979285311s
Feb  6 03:14:36.776: INFO: Verifying statefulset ss doesn't scale past 1 for another 6.969916735s
Feb  6 03:14:37.825: INFO: Verifying statefulset ss doesn't scale past 1 for another 5.960466684s
Feb  6 03:14:38.834: INFO: Verifying statefulset ss doesn't scale past 1 for another 4.91153991s
Feb  6 03:14:39.844: INFO: Verifying statefulset ss doesn't scale past 1 for another 3.903120467s
Feb  6 03:14:40.853: INFO: Verifying statefulset ss doesn't scale past 1 for another 2.893197804s
Feb  6 03:14:41.863: INFO: Verifying statefulset ss doesn't scale past 1 for another 1.883376564s
Feb  6 03:14:42.873: INFO: Verifying statefulset ss doesn't scale past 1 for another 873.679504ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace e2e-tests-statefulset-wmvf5
Feb  6 03:14:43.909: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-131423863 exec --namespace=e2e-tests-statefulset-wmvf5 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb  6 03:14:44.299: INFO: stderr: ""
Feb  6 03:14:44.299: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Feb  6 03:14:44.299: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Feb  6 03:14:44.400: INFO: Found 1 stateful pods, waiting for 3
Feb  6 03:14:54.424: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Feb  6 03:14:54.424: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Feb  6 03:14:54.424: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Verifying that stateful set ss was scaled up in order
STEP: Scale down will halt with unhealthy stateful pod
Feb  6 03:14:54.437: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-131423863 exec --namespace=e2e-tests-statefulset-wmvf5 ss-0 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Feb  6 03:14:54.898: INFO: stderr: ""
Feb  6 03:14:54.898: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Feb  6 03:14:54.898: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Feb  6 03:14:54.898: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-131423863 exec --namespace=e2e-tests-statefulset-wmvf5 ss-1 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Feb  6 03:14:55.284: INFO: stderr: ""
Feb  6 03:14:55.284: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Feb  6 03:14:55.284: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Feb  6 03:14:55.284: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-131423863 exec --namespace=e2e-tests-statefulset-wmvf5 ss-2 -- /bin/sh -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Feb  6 03:14:55.669: INFO: stderr: ""
Feb  6 03:14:55.669: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Feb  6 03:14:55.669: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-2: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Feb  6 03:14:55.669: INFO: Waiting for statefulset status.replicas updated to 0
Feb  6 03:14:55.677: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 2
Feb  6 03:15:05.891: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Feb  6 03:15:05.891: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Feb  6 03:15:05.891: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Feb  6 03:15:05.921: INFO: Verifying statefulset ss doesn't scale past 3 for another 9.999999029s
Feb  6 03:15:06.931: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.990489192s
Feb  6 03:15:07.941: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.980660367s
Feb  6 03:15:08.951: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.970694222s
Feb  6 03:15:09.961: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.960430206s
Feb  6 03:15:10.970: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.950499669s
Feb  6 03:15:11.982: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.941692269s
Feb  6 03:15:12.992: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.929438379s
Feb  6 03:15:14.002: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.919245297s
Feb  6 03:15:15.012: INFO: Verifying statefulset ss doesn't scale past 3 for another 909.601259ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacee2e-tests-statefulset-wmvf5
Feb  6 03:15:16.035: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-131423863 exec --namespace=e2e-tests-statefulset-wmvf5 ss-0 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb  6 03:15:16.411: INFO: stderr: ""
Feb  6 03:15:16.411: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Feb  6 03:15:16.411: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Feb  6 03:15:16.411: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-131423863 exec --namespace=e2e-tests-statefulset-wmvf5 ss-1 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb  6 03:15:16.810: INFO: stderr: ""
Feb  6 03:15:16.810: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Feb  6 03:15:16.810: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Feb  6 03:15:16.810: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-131423863 exec --namespace=e2e-tests-statefulset-wmvf5 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb  6 03:15:17.111: INFO: rc: 1
Feb  6 03:15:17.111: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-131423863 exec --namespace=e2e-tests-statefulset-wmvf5 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  error: Internal error occurred: error executing command in container: failed to exec in container: failed to load task: no running task found: not found
 [] <nil> 0xc4220c6db0 exit status 1 <nil> <nil> true [0xc421697a68 0xc421697a90 0xc421697ad0] [0xc421697a68 0xc421697a90 0xc421697ad0] [0xc421697a88 0xc421697ab0] [0x8fd520 0x8fd520] 0xc421b6baa0 <nil>}:
Command stdout:

stderr:
error: Internal error occurred: error executing command in container: failed to exec in container: failed to load task: no running task found: not found

error:
exit status 1

Feb  6 03:15:27.112: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-131423863 exec --namespace=e2e-tests-statefulset-wmvf5 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb  6 03:15:27.396: INFO: rc: 1
Feb  6 03:15:27.396: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-131423863 exec --namespace=e2e-tests-statefulset-wmvf5 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  error: unable to upgrade connection: container not found ("nginx")
 [] <nil> 0xc4220c71a0 exit status 1 <nil> <nil> true [0xc421697ad8 0xc421697b00 0xc421697b28] [0xc421697ad8 0xc421697b00 0xc421697b28] [0xc421697ae8 0xc421697b20] [0x8fd520 0x8fd520] 0xc421b6bbc0 <nil>}:
Command stdout:

stderr:
error: unable to upgrade connection: container not found ("nginx")

error:
exit status 1

Feb  6 03:15:37.397: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-131423863 exec --namespace=e2e-tests-statefulset-wmvf5 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb  6 03:15:37.527: INFO: rc: 1
Feb  6 03:15:37.527: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-131423863 exec --namespace=e2e-tests-statefulset-wmvf5 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc422f58420 exit status 1 <nil> <nil> true [0xc421ffc000 0xc421ffc018 0xc421ffc030] [0xc421ffc000 0xc421ffc018 0xc421ffc030] [0xc421ffc010 0xc421ffc028] [0x8fd520 0x8fd520] 0xc42181a060 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Feb  6 03:15:47.527: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-131423863 exec --namespace=e2e-tests-statefulset-wmvf5 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb  6 03:15:47.657: INFO: rc: 1
Feb  6 03:15:47.657: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-131423863 exec --namespace=e2e-tests-statefulset-wmvf5 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc422f58810 exit status 1 <nil> <nil> true [0xc421ffc038 0xc421ffc050 0xc421ffc068] [0xc421ffc038 0xc421ffc050 0xc421ffc068] [0xc421ffc048 0xc421ffc060] [0x8fd520 0x8fd520] 0xc42181a180 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Feb  6 03:15:57.657: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-131423863 exec --namespace=e2e-tests-statefulset-wmvf5 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb  6 03:15:57.828: INFO: rc: 1
Feb  6 03:15:57.828: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-131423863 exec --namespace=e2e-tests-statefulset-wmvf5 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc422f79b00 exit status 1 <nil> <nil> true [0xc420a7e010 0xc420a7e2b0 0xc420a7e398] [0xc420a7e010 0xc420a7e2b0 0xc420a7e398] [0xc420a7e268 0xc420a7e340] [0x8fd520 0x8fd520] 0xc421b4c060 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Feb  6 03:16:07.829: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-131423863 exec --namespace=e2e-tests-statefulset-wmvf5 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb  6 03:16:08.028: INFO: rc: 1
Feb  6 03:16:08.028: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-131423863 exec --namespace=e2e-tests-statefulset-wmvf5 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc422f79f80 exit status 1 <nil> <nil> true [0xc420a7e3d0 0xc420a7e7a0 0xc420a7e898] [0xc420a7e3d0 0xc420a7e7a0 0xc420a7e898] [0xc420a7e728 0xc420a7e838] [0x8fd520 0x8fd520] 0xc421b4c180 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Feb  6 03:16:18.028: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-131423863 exec --namespace=e2e-tests-statefulset-wmvf5 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb  6 03:16:18.151: INFO: rc: 1
Feb  6 03:16:18.151: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-131423863 exec --namespace=e2e-tests-statefulset-wmvf5 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc422f58e40 exit status 1 <nil> <nil> true [0xc421ffc070 0xc421ffc088 0xc421ffc0a0] [0xc421ffc070 0xc421ffc088 0xc421ffc0a0] [0xc421ffc080 0xc421ffc098] [0x8fd520 0x8fd520] 0xc42181a2a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Feb  6 03:16:28.152: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-131423863 exec --namespace=e2e-tests-statefulset-wmvf5 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb  6 03:16:28.307: INFO: rc: 1
Feb  6 03:16:28.307: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-131423863 exec --namespace=e2e-tests-statefulset-wmvf5 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc422f592c0 exit status 1 <nil> <nil> true [0xc421ffc0a8 0xc421ffc0c0 0xc421ffc0d8] [0xc421ffc0a8 0xc421ffc0c0 0xc421ffc0d8] [0xc421ffc0b8 0xc421ffc0d0] [0x8fd520 0x8fd520] 0xc42181a3c0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Feb  6 03:16:38.307: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-131423863 exec --namespace=e2e-tests-statefulset-wmvf5 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb  6 03:16:38.427: INFO: rc: 1
Feb  6 03:16:38.427: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-131423863 exec --namespace=e2e-tests-statefulset-wmvf5 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc42209e3c0 exit status 1 <nil> <nil> true [0xc420a7e8c0 0xc420a7e940 0xc420a7e998] [0xc420a7e8c0 0xc420a7e940 0xc420a7e998] [0xc420a7e918 0xc420a7e970] [0x8fd520 0x8fd520] 0xc421b4c2a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Feb  6 03:16:48.427: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-131423863 exec --namespace=e2e-tests-statefulset-wmvf5 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb  6 03:16:48.549: INFO: rc: 1
Feb  6 03:16:48.549: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-131423863 exec --namespace=e2e-tests-statefulset-wmvf5 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc422f59aa0 exit status 1 <nil> <nil> true [0xc421ffc0e0 0xc421ffc0f8 0xc421ffc110] [0xc421ffc0e0 0xc421ffc0f8 0xc421ffc110] [0xc421ffc0f0 0xc421ffc108] [0x8fd520 0x8fd520] 0xc42181a4e0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Feb  6 03:16:58.549: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-131423863 exec --namespace=e2e-tests-statefulset-wmvf5 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb  6 03:16:58.693: INFO: rc: 1
Feb  6 03:16:58.693: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-131423863 exec --namespace=e2e-tests-statefulset-wmvf5 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc422f59f20 exit status 1 <nil> <nil> true [0xc421ffc118 0xc421ffc130 0xc421ffc148] [0xc421ffc118 0xc421ffc130 0xc421ffc148] [0xc421ffc128 0xc421ffc140] [0x8fd520 0x8fd520] 0xc42181a600 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Feb  6 03:17:08.694: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-131423863 exec --namespace=e2e-tests-statefulset-wmvf5 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb  6 03:17:08.828: INFO: rc: 1
Feb  6 03:17:08.828: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-131423863 exec --namespace=e2e-tests-statefulset-wmvf5 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc42209e8a0 exit status 1 <nil> <nil> true [0xc420a7e9d8 0xc420a7ea40 0xc420a7eb50] [0xc420a7e9d8 0xc420a7ea40 0xc420a7eb50] [0xc420a7ea28 0xc420a7eaf0] [0x8fd520 0x8fd520] 0xc421b4c3c0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Feb  6 03:17:18.828: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-131423863 exec --namespace=e2e-tests-statefulset-wmvf5 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb  6 03:17:18.969: INFO: rc: 1
Feb  6 03:17:18.969: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-131423863 exec --namespace=e2e-tests-statefulset-wmvf5 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc422cf4690 exit status 1 <nil> <nil> true [0xc421ffc150 0xc421ffc170 0xc421ffc188] [0xc421ffc150 0xc421ffc170 0xc421ffc188] [0xc421ffc168 0xc421ffc180] [0x8fd520 0x8fd520] 0xc42181a780 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Feb  6 03:17:28.970: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-131423863 exec --namespace=e2e-tests-statefulset-wmvf5 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb  6 03:17:29.121: INFO: rc: 1
Feb  6 03:17:29.121: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-131423863 exec --namespace=e2e-tests-statefulset-wmvf5 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc422cf4cc0 exit status 1 <nil> <nil> true [0xc421ffc190 0xc421ffc1a8 0xc421ffc1c0] [0xc421ffc190 0xc421ffc1a8 0xc421ffc1c0] [0xc421ffc1a0 0xc421ffc1b8] [0x8fd520 0x8fd520] 0xc42181a8a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Feb  6 03:17:39.121: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-131423863 exec --namespace=e2e-tests-statefulset-wmvf5 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb  6 03:17:39.293: INFO: rc: 1
Feb  6 03:17:39.293: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-131423863 exec --namespace=e2e-tests-statefulset-wmvf5 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc422f79bf0 exit status 1 <nil> <nil> true [0xc421ffc008 0xc421ffc020 0xc421ffc038] [0xc421ffc008 0xc421ffc020 0xc421ffc038] [0xc421ffc018 0xc421ffc030] [0x8fd520 0x8fd520] 0xc42181a060 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Feb  6 03:17:49.293: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-131423863 exec --namespace=e2e-tests-statefulset-wmvf5 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb  6 03:17:49.412: INFO: rc: 1
Feb  6 03:17:49.413: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-131423863 exec --namespace=e2e-tests-statefulset-wmvf5 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc422f58030 exit status 1 <nil> <nil> true [0xc421ffc040 0xc421ffc058 0xc421ffc070] [0xc421ffc040 0xc421ffc058 0xc421ffc070] [0xc421ffc050 0xc421ffc068] [0x8fd520 0x8fd520] 0xc42181a180 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Feb  6 03:17:59.413: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-131423863 exec --namespace=e2e-tests-statefulset-wmvf5 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb  6 03:17:59.601: INFO: rc: 1
Feb  6 03:17:59.601: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-131423863 exec --namespace=e2e-tests-statefulset-wmvf5 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc422cf46f0 exit status 1 <nil> <nil> true [0xc420a7e010 0xc420a7e2b0 0xc420a7e398] [0xc420a7e010 0xc420a7e2b0 0xc420a7e398] [0xc420a7e268 0xc420a7e340] [0x8fd520 0x8fd520] 0xc421b4c060 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Feb  6 03:18:09.601: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-131423863 exec --namespace=e2e-tests-statefulset-wmvf5 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb  6 03:18:09.737: INFO: rc: 1
Feb  6 03:18:09.737: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-131423863 exec --namespace=e2e-tests-statefulset-wmvf5 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc422cf4d20 exit status 1 <nil> <nil> true [0xc420a7e3d0 0xc420a7e7a0 0xc420a7e898] [0xc420a7e3d0 0xc420a7e7a0 0xc420a7e898] [0xc420a7e728 0xc420a7e838] [0x8fd520 0x8fd520] 0xc421b4c180 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Feb  6 03:18:19.737: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-131423863 exec --namespace=e2e-tests-statefulset-wmvf5 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb  6 03:18:19.870: INFO: rc: 1
Feb  6 03:18:19.870: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-131423863 exec --namespace=e2e-tests-statefulset-wmvf5 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc422f58480 exit status 1 <nil> <nil> true [0xc421ffc078 0xc421ffc090 0xc421ffc0a8] [0xc421ffc078 0xc421ffc090 0xc421ffc0a8] [0xc421ffc088 0xc421ffc0a0] [0x8fd520 0x8fd520] 0xc42181a2a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Feb  6 03:18:29.870: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-131423863 exec --namespace=e2e-tests-statefulset-wmvf5 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb  6 03:18:29.999: INFO: rc: 1
Feb  6 03:18:29.999: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-131423863 exec --namespace=e2e-tests-statefulset-wmvf5 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc422f588a0 exit status 1 <nil> <nil> true [0xc421ffc0b0 0xc421ffc0c8 0xc421ffc0e0] [0xc421ffc0b0 0xc421ffc0c8 0xc421ffc0e0] [0xc421ffc0c0 0xc421ffc0d8] [0x8fd520 0x8fd520] 0xc42181a3c0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Feb  6 03:18:39.999: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-131423863 exec --namespace=e2e-tests-statefulset-wmvf5 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb  6 03:18:40.141: INFO: rc: 1
Feb  6 03:18:40.141: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-131423863 exec --namespace=e2e-tests-statefulset-wmvf5 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc422f58ed0 exit status 1 <nil> <nil> true [0xc421ffc0e8 0xc421ffc100 0xc421ffc118] [0xc421ffc0e8 0xc421ffc100 0xc421ffc118] [0xc421ffc0f8 0xc421ffc110] [0x8fd520 0x8fd520] 0xc42181a4e0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Feb  6 03:18:50.142: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-131423863 exec --namespace=e2e-tests-statefulset-wmvf5 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb  6 03:18:50.276: INFO: rc: 1
Feb  6 03:18:50.276: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-131423863 exec --namespace=e2e-tests-statefulset-wmvf5 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc422cf5140 exit status 1 <nil> <nil> true [0xc420a7e8c0 0xc420a7e940 0xc420a7e998] [0xc420a7e8c0 0xc420a7e940 0xc420a7e998] [0xc420a7e918 0xc420a7e970] [0x8fd520 0x8fd520] 0xc421b4c2a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Feb  6 03:19:00.276: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-131423863 exec --namespace=e2e-tests-statefulset-wmvf5 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb  6 03:19:00.690: INFO: rc: 1
Feb  6 03:19:00.691: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-131423863 exec --namespace=e2e-tests-statefulset-wmvf5 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc422f59560 exit status 1 <nil> <nil> true [0xc421ffc120 0xc421ffc138 0xc421ffc150] [0xc421ffc120 0xc421ffc138 0xc421ffc150] [0xc421ffc130 0xc421ffc148] [0x8fd520 0x8fd520] 0xc42181a600 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Feb  6 03:19:10.691: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-131423863 exec --namespace=e2e-tests-statefulset-wmvf5 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb  6 03:19:11.240: INFO: rc: 1
Feb  6 03:19:11.240: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-131423863 exec --namespace=e2e-tests-statefulset-wmvf5 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc422cf5560 exit status 1 <nil> <nil> true [0xc420a7e9d8 0xc420a7ea40 0xc420a7eb50] [0xc420a7e9d8 0xc420a7ea40 0xc420a7eb50] [0xc420a7ea28 0xc420a7eaf0] [0x8fd520 0x8fd520] 0xc421b4c3c0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Feb  6 03:19:21.240: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-131423863 exec --namespace=e2e-tests-statefulset-wmvf5 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb  6 03:19:21.368: INFO: rc: 1
Feb  6 03:19:21.368: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-131423863 exec --namespace=e2e-tests-statefulset-wmvf5 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc422f59bf0 exit status 1 <nil> <nil> true [0xc421ffc160 0xc421ffc178 0xc421ffc190] [0xc421ffc160 0xc421ffc178 0xc421ffc190] [0xc421ffc170 0xc421ffc188] [0x8fd520 0x8fd520] 0xc42181a780 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Feb  6 03:19:31.369: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-131423863 exec --namespace=e2e-tests-statefulset-wmvf5 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb  6 03:19:31.500: INFO: rc: 1
Feb  6 03:19:31.500: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-131423863 exec --namespace=e2e-tests-statefulset-wmvf5 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc422cf5950 exit status 1 <nil> <nil> true [0xc420a7eb68 0xc420a7ebf0 0xc420a7ec58] [0xc420a7eb68 0xc420a7ebf0 0xc420a7ec58] [0xc420a7ebd8 0xc420a7ec18] [0x8fd520 0x8fd520] 0xc421b4c4e0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Feb  6 03:19:41.500: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-131423863 exec --namespace=e2e-tests-statefulset-wmvf5 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb  6 03:19:41.618: INFO: rc: 1
Feb  6 03:19:41.618: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-131423863 exec --namespace=e2e-tests-statefulset-wmvf5 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc422f79b00 exit status 1 <nil> <nil> true [0xc421ffc008 0xc421ffc020 0xc421ffc038] [0xc421ffc008 0xc421ffc020 0xc421ffc038] [0xc421ffc018 0xc421ffc030] [0x8fd520 0x8fd520] 0xc42181a060 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Feb  6 03:19:51.618: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-131423863 exec --namespace=e2e-tests-statefulset-wmvf5 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb  6 03:19:51.764: INFO: rc: 1
Feb  6 03:19:51.764: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-131423863 exec --namespace=e2e-tests-statefulset-wmvf5 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc422f58450 exit status 1 <nil> <nil> true [0xc420a7e010 0xc420a7e2b0 0xc420a7e398] [0xc420a7e010 0xc420a7e2b0 0xc420a7e398] [0xc420a7e268 0xc420a7e340] [0x8fd520 0x8fd520] 0xc421b4c060 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Feb  6 03:20:01.764: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-131423863 exec --namespace=e2e-tests-statefulset-wmvf5 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb  6 03:20:01.899: INFO: rc: 1
Feb  6 03:20:01.899: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-131423863 exec --namespace=e2e-tests-statefulset-wmvf5 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc422f58870 exit status 1 <nil> <nil> true [0xc420a7e3d0 0xc420a7e7a0 0xc420a7e898] [0xc420a7e3d0 0xc420a7e7a0 0xc420a7e898] [0xc420a7e728 0xc420a7e838] [0x8fd520 0x8fd520] 0xc421b4c180 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Feb  6 03:20:11.900: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-131423863 exec --namespace=e2e-tests-statefulset-wmvf5 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb  6 03:20:12.049: INFO: rc: 1
Feb  6 03:20:12.049: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-131423863 exec --namespace=e2e-tests-statefulset-wmvf5 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc422cf4030 exit status 1 <nil> <nil> true [0xc421ffc040 0xc421ffc058 0xc421ffc070] [0xc421ffc040 0xc421ffc058 0xc421ffc070] [0xc421ffc050 0xc421ffc068] [0x8fd520 0x8fd520] 0xc42181a180 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1

Feb  6 03:20:22.050: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-131423863 exec --namespace=e2e-tests-statefulset-wmvf5 ss-2 -- /bin/sh -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Feb  6 03:20:22.180: INFO: rc: 1
Feb  6 03:20:22.180: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-2: 
Feb  6 03:20:22.180: INFO: Scaling statefulset ss to 0
STEP: Verifying that stateful set ss was scaled down in reverse order
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:85
Feb  6 03:20:22.237: INFO: Deleting all statefulset in ns e2e-tests-statefulset-wmvf5
Feb  6 03:20:22.246: INFO: Scaling statefulset ss to 0
Feb  6 03:20:22.273: INFO: Waiting for statefulset status.replicas updated to 0
Feb  6 03:20:22.281: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  6 03:20:22.324: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-statefulset-wmvf5" for this suite.
Feb  6 03:20:28.365: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 03:20:28.393: INFO: namespace: e2e-tests-statefulset-wmvf5, resource: bindings, ignored listing per whitelist
Feb  6 03:20:28.698: INFO: namespace e2e-tests-statefulset-wmvf5 deletion completed in 6.361303589s

• [SLOW TEST:375.894 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:22
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
    Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
    /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSS
------------------------------
[sig-api-machinery] Downward API 
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  6 03:20:28.699: INFO: >>> kubeConfig: /tmp/kubeconfig-131423863
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-kpl2j
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Feb  6 03:20:29.307: INFO: Waiting up to 5m0s for pod "downward-api-276400cb-29be-11e9-9603-eaa511fa0b6c" in namespace "e2e-tests-downward-api-kpl2j" to be "success or failure"
Feb  6 03:20:29.316: INFO: Pod "downward-api-276400cb-29be-11e9-9603-eaa511fa0b6c": Phase="Pending", Reason="", readiness=false. Elapsed: 8.693764ms
Feb  6 03:20:31.324: INFO: Pod "downward-api-276400cb-29be-11e9-9603-eaa511fa0b6c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.017424886s
Feb  6 03:20:33.347: INFO: Pod "downward-api-276400cb-29be-11e9-9603-eaa511fa0b6c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.040067003s
STEP: Saw pod success
Feb  6 03:20:33.347: INFO: Pod "downward-api-276400cb-29be-11e9-9603-eaa511fa0b6c" satisfied condition "success or failure"
Feb  6 03:20:33.358: INFO: Trying to get logs from node 10.190.119.143 pod downward-api-276400cb-29be-11e9-9603-eaa511fa0b6c container dapi-container: <nil>
STEP: delete the pod
Feb  6 03:20:33.410: INFO: Waiting for pod downward-api-276400cb-29be-11e9-9603-eaa511fa0b6c to disappear
Feb  6 03:20:33.417: INFO: Pod downward-api-276400cb-29be-11e9-9603-eaa511fa0b6c no longer exists
[AfterEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  6 03:20:33.418: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-kpl2j" for this suite.
Feb  6 03:20:39.461: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 03:20:39.561: INFO: namespace: e2e-tests-downward-api-kpl2j, resource: bindings, ignored listing per whitelist
Feb  6 03:20:39.763: INFO: namespace e2e-tests-downward-api-kpl2j deletion completed in 6.329178005s

• [SLOW TEST:11.065 seconds]
[sig-api-machinery] Downward API
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  6 03:20:39.766: INFO: >>> kubeConfig: /tmp/kubeconfig-131423863
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-pxwq8
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward API volume plugin
Feb  6 03:20:40.110: INFO: Waiting up to 5m0s for pod "downwardapi-volume-2dd42f61-29be-11e9-9603-eaa511fa0b6c" in namespace "e2e-tests-projected-pxwq8" to be "success or failure"
Feb  6 03:20:40.120: INFO: Pod "downwardapi-volume-2dd42f61-29be-11e9-9603-eaa511fa0b6c": Phase="Pending", Reason="", readiness=false. Elapsed: 9.166575ms
Feb  6 03:20:42.129: INFO: Pod "downwardapi-volume-2dd42f61-29be-11e9-9603-eaa511fa0b6c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.018302667s
STEP: Saw pod success
Feb  6 03:20:42.129: INFO: Pod "downwardapi-volume-2dd42f61-29be-11e9-9603-eaa511fa0b6c" satisfied condition "success or failure"
Feb  6 03:20:42.137: INFO: Trying to get logs from node 10.190.119.184 pod downwardapi-volume-2dd42f61-29be-11e9-9603-eaa511fa0b6c container client-container: <nil>
STEP: delete the pod
Feb  6 03:20:42.192: INFO: Waiting for pod downwardapi-volume-2dd42f61-29be-11e9-9603-eaa511fa0b6c to disappear
Feb  6 03:20:42.201: INFO: Pod downwardapi-volume-2dd42f61-29be-11e9-9603-eaa511fa0b6c no longer exists
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  6 03:20:42.201: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-pxwq8" for this suite.
Feb  6 03:20:48.305: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 03:20:48.685: INFO: namespace: e2e-tests-projected-pxwq8, resource: bindings, ignored listing per whitelist
Feb  6 03:20:48.694: INFO: namespace e2e-tests-projected-pxwq8 deletion completed in 6.480494572s

• [SLOW TEST:8.928 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  6 03:20:48.695: INFO: >>> kubeConfig: /tmp/kubeconfig-131423863
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-pods-wvqxc
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:132
[It] should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Feb  6 03:20:51.653: INFO: Successfully updated pod "pod-update-33255e18-29be-11e9-9603-eaa511fa0b6c"
STEP: verifying the updated pod is in kubernetes
Feb  6 03:20:51.682: INFO: Pod update OK
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  6 03:20:51.682: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-pods-wvqxc" for this suite.
Feb  6 03:21:15.735: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 03:21:15.893: INFO: namespace: e2e-tests-pods-wvqxc, resource: bindings, ignored listing per whitelist
Feb  6 03:21:16.150: INFO: namespace e2e-tests-pods-wvqxc deletion completed in 24.441902487s

• [SLOW TEST:27.455 seconds]
[k8s.io] Pods
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
[sig-storage] Projected 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  6 03:21:16.151: INFO: >>> kubeConfig: /tmp/kubeconfig-131423863
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-projected-h98nq
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:858
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating projection with configMap that has name projected-configmap-test-upd-43824296-29be-11e9-9603-eaa511fa0b6c
STEP: Creating the pod
STEP: Updating configmap projected-configmap-test-upd-43824296-29be-11e9-9603-eaa511fa0b6c
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  6 03:21:20.680: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-projected-h98nq" for this suite.
Feb  6 03:21:44.738: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 03:21:45.590: INFO: namespace: e2e-tests-projected-h98nq, resource: bindings, ignored listing per whitelist
Feb  6 03:21:45.598: INFO: namespace e2e-tests-projected-h98nq deletion completed in 24.90393511s

• [SLOW TEST:29.448 seconds]
[sig-storage] Projected
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected.go:35
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  6 03:21:45.599: INFO: >>> kubeConfig: /tmp/kubeconfig-131423863
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-gc-9744f
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the rs
STEP: Gathering metrics
W0206 03:22:16.631585      15 metrics_grabber.go:81] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Feb  6 03:22:16.631: INFO: For apiserver_request_count:
For apiserver_request_latencies_summary:
For etcd_helper_cache_entry_count:
For etcd_helper_cache_hit_count:
For etcd_helper_cache_miss_count:
For etcd_request_cache_add_latencies_summary:
For etcd_request_cache_get_latencies_summary:
For etcd_request_latencies_summary:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  6 03:22:16.631: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-gc-9744f" for this suite.
Feb  6 03:22:22.725: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 03:22:22.991: INFO: namespace: e2e-tests-gc-9744f, resource: bindings, ignored listing per whitelist
Feb  6 03:22:23.096: INFO: namespace e2e-tests-gc-9744f deletion completed in 6.404669785s

• [SLOW TEST:37.497 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:22
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSS
------------------------------
[sig-api-machinery] Downward API 
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  6 03:22:23.096: INFO: >>> kubeConfig: /tmp/kubeconfig-131423863
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-downward-api-w87p5
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test downward api env vars
Feb  6 03:22:23.438: INFO: Waiting up to 5m0s for pod "downward-api-6b69cb3a-29be-11e9-9603-eaa511fa0b6c" in namespace "e2e-tests-downward-api-w87p5" to be "success or failure"
Feb  6 03:22:23.449: INFO: Pod "downward-api-6b69cb3a-29be-11e9-9603-eaa511fa0b6c": Phase="Pending", Reason="", readiness=false. Elapsed: 10.790376ms
Feb  6 03:22:25.459: INFO: Pod "downward-api-6b69cb3a-29be-11e9-9603-eaa511fa0b6c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.021000269s
STEP: Saw pod success
Feb  6 03:22:25.459: INFO: Pod "downward-api-6b69cb3a-29be-11e9-9603-eaa511fa0b6c" satisfied condition "success or failure"
Feb  6 03:22:25.468: INFO: Trying to get logs from node 10.190.119.143 pod downward-api-6b69cb3a-29be-11e9-9603-eaa511fa0b6c container dapi-container: <nil>
STEP: delete the pod
Feb  6 03:22:25.521: INFO: Waiting for pod downward-api-6b69cb3a-29be-11e9-9603-eaa511fa0b6c to disappear
Feb  6 03:22:25.529: INFO: Pod downward-api-6b69cb3a-29be-11e9-9603-eaa511fa0b6c no longer exists
[AfterEach] [sig-api-machinery] Downward API
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  6 03:22:25.529: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-downward-api-w87p5" for this suite.
Feb  6 03:22:31.571: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 03:22:31.944: INFO: namespace: e2e-tests-downward-api-w87p5, resource: bindings, ignored listing per whitelist
Feb  6 03:22:32.074: INFO: namespace e2e-tests-downward-api-w87p5 deletion completed in 6.529693475s

• [SLOW TEST:8.979 seconds]
[sig-api-machinery] Downward API
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:38
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] HostPath 
  should give a volume the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  6 03:22:32.077: INFO: >>> kubeConfig: /tmp/kubeconfig-131423863
STEP: Building a namespace api object, basename hostpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-hostpath-hnjmg
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:37
[It] should give a volume the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test hostPath mode
Feb  6 03:22:32.408: INFO: Waiting up to 5m0s for pod "pod-host-path-test" in namespace "e2e-tests-hostpath-hnjmg" to be "success or failure"
Feb  6 03:22:32.419: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 11.007472ms
Feb  6 03:22:34.433: INFO: Pod "pod-host-path-test": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.024964057s
STEP: Saw pod success
Feb  6 03:22:34.433: INFO: Pod "pod-host-path-test" satisfied condition "success or failure"
Feb  6 03:22:34.441: INFO: Trying to get logs from node 10.190.119.143 pod pod-host-path-test container test-container-1: <nil>
STEP: delete the pod
Feb  6 03:22:34.510: INFO: Waiting for pod pod-host-path-test to disappear
Feb  6 03:22:34.523: INFO: Pod pod-host-path-test no longer exists
[AfterEach] [sig-storage] HostPath
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  6 03:22:34.523: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-hostpath-hnjmg" for this suite.
Feb  6 03:22:40.567: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 03:22:40.923: INFO: namespace: e2e-tests-hostpath-hnjmg, resource: bindings, ignored listing per whitelist
Feb  6 03:22:41.121: INFO: namespace e2e-tests-hostpath-hnjmg deletion completed in 6.583432133s

• [SLOW TEST:9.045 seconds]
[sig-storage] HostPath
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:34
  should give a volume the correct mode [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:147
STEP: Creating a kubernetes client
Feb  6 03:22:41.121: INFO: >>> kubeConfig: /tmp/kubeconfig-131423863
STEP: Building a namespace api object, basename containers
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-tests-containers-q4c98
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
STEP: Creating a pod to test override command
Feb  6 03:22:41.492: INFO: Waiting up to 5m0s for pod "client-containers-76274d61-29be-11e9-9603-eaa511fa0b6c" in namespace "e2e-tests-containers-q4c98" to be "success or failure"
Feb  6 03:22:41.504: INFO: Pod "client-containers-76274d61-29be-11e9-9603-eaa511fa0b6c": Phase="Pending", Reason="", readiness=false. Elapsed: 11.908155ms
Feb  6 03:22:43.513: INFO: Pod "client-containers-76274d61-29be-11e9-9603-eaa511fa0b6c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.020446353s
STEP: Saw pod success
Feb  6 03:22:43.513: INFO: Pod "client-containers-76274d61-29be-11e9-9603-eaa511fa0b6c" satisfied condition "success or failure"
Feb  6 03:22:43.521: INFO: Trying to get logs from node 10.190.119.133 pod client-containers-76274d61-29be-11e9-9603-eaa511fa0b6c container test-container: <nil>
STEP: delete the pod
Feb  6 03:22:43.591: INFO: Waiting for pod client-containers-76274d61-29be-11e9-9603-eaa511fa0b6c to disappear
Feb  6 03:22:43.599: INFO: Pod client-containers-76274d61-29be-11e9-9603-eaa511fa0b6c no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:148
Feb  6 03:22:43.600: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-tests-containers-q4c98" for this suite.
Feb  6 03:22:49.664: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb  6 03:22:50.004: INFO: namespace: e2e-tests-containers-q4c98, resource: bindings, ignored listing per whitelist
Feb  6 03:22:50.208: INFO: namespace e2e-tests-containers-q4c98 deletion completed in 6.595646586s

• [SLOW TEST:9.087 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:694
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.12.1-beta.0.52+4ed3216f3ec431/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:699
------------------------------
SSSSSSSSSSSSFeb  6 03:22:50.208: INFO: Running AfterSuite actions on all node
Feb  6 03:22:50.208: INFO: Running AfterSuite actions on node 1
Feb  6 03:22:50.208: INFO: Skipping dumping logs from cluster

Ran 187 of 1814 Specs in 5411.553 seconds
SUCCESS! -- 187 Passed | 0 Failed | 0 Pending | 1627 Skipped PASS

Ginkgo ran 1 suite in 1h30m12.632861537s
Test Suite Passed
